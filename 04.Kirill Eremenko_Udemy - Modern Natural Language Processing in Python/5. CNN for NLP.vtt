WEBVTT
1
00:00:00.270 --> 00:00:01.110
Hi and welcome back.

2
00:00:01.110 --> 00:00:08.130
He's in there because so now that we have what seems to be valid inputs for CNN coming from Texas we

3
00:00:08.130 --> 00:00:14.340
want to see how it does when we apply CNN to it and what will be the changes that we will have to make

4
00:00:14.700 --> 00:00:17.850
in order to have CNN that works for Texas.

5
00:00:17.880 --> 00:00:23.520
So for that we will use this stunning architecture of CNN for Texas and we will go through the different

6
00:00:23.520 --> 00:00:30.790
steps trying to see if there is a difference between CNN for comes to vision and CNN for the so the

7
00:00:30.790 --> 00:00:35.860
first question that we have to ask ourselves is what is the difference between the matrix that comes

8
00:00:35.860 --> 00:00:38.560
from an image and the metrics that comes from the tests.

9
00:00:38.590 --> 00:00:43.510
Well for any reach the two dimensions of the metrics mean the rows and the columns.

10
00:00:43.570 --> 00:00:47.760
They actually kind of share the same role the convey the same meaning.

11
00:00:47.920 --> 00:00:54.790
If you go from one element to another in your image as metrics whether you go from left to right or

12
00:00:54.790 --> 00:01:01.030
from top to bottom you actually do the same thing you just move through space and you're off to going

13
00:01:01.030 --> 00:01:02.680
from a big cell to another.

14
00:01:02.940 --> 00:01:09.340
But that's not the same sentence because for a sentence in a matrix representation of a sentence Each

15
00:01:09.340 --> 00:01:16.260
row represents a word each column well represents nothing really meaningful it's just column number

16
00:01:16.270 --> 00:01:21.490
I will represent the dimension I in the vector representation of each of our words.

17
00:01:21.790 --> 00:01:28.450
So if you go from an element of our matrix and we go to what's the right doesn't mean the same as going

18
00:01:28.520 --> 00:01:29.620
toward the button.

19
00:01:29.620 --> 00:01:35.350
So that brings a question to us does it really make sense to have a theater of size let's say two by

20
00:01:35.350 --> 00:01:41.090
two and to make it go through our whole matrix from left to right and from top to bottom.

21
00:01:41.110 --> 00:01:42.870
Well the answer actually is no.

22
00:01:42.940 --> 00:01:48.460
Of course it makes sense to search for local features amongst small groups of words but among small

23
00:01:48.460 --> 00:01:54.070
groups of embedding dimensions it doesn't make sense and even though it made sense we would not want

24
00:01:54.070 --> 00:01:57.140
to do this as we also go through groups of words.

25
00:01:57.160 --> 00:02:03.070
So having a small feature detector that would go through our sentence matrix in all directions would

26
00:02:03.070 --> 00:02:05.100
not make sense it would not perform well.

27
00:02:05.200 --> 00:02:10.090
So that is why if you have a loop here you can see that's all the feature detectors that you can see

28
00:02:10.090 --> 00:02:14.710
there have the same width and this is actually the dimension of our model.

29
00:02:14.710 --> 00:02:22.090
So this is the first main difference that we see matching the CNN for AP and the CNN for image is that's

30
00:02:22.150 --> 00:02:23.120
our filter.

31
00:02:23.140 --> 00:02:24.780
We have the same with us all.

32
00:02:24.790 --> 00:02:25.970
Sentence matrix.

33
00:02:26.110 --> 00:02:31.530
And it will only go through top to bottom so it will only go through groups of words.

34
00:02:31.780 --> 00:02:37.300
Actually another way that we could do that and that would work perfectly well it just that in this architect.

35
00:02:37.360 --> 00:02:38.710
This is what we chose.

36
00:02:38.710 --> 00:02:44.590
But one other way to do that is to have feature detectors that are only vectors so instead of taking

37
00:02:44.800 --> 00:02:50.410
the same with as the sentence matrix we take a width of only one and that will be OK because we just

38
00:02:50.410 --> 00:02:56.350
say that there is a feature detector that works only in one dimension and we want to apply it among

39
00:02:56.530 --> 00:02:57.570
all the dimensions.

40
00:02:57.580 --> 00:03:03.010
This is quite different from having a filter that takes into account several dimensions at once and

41
00:03:03.010 --> 00:03:07.570
shifting it's one by one given meaning to a group of dimensions.

42
00:03:07.930 --> 00:03:09.800
So that's another way to do that.

43
00:03:09.850 --> 00:03:10.890
That's also possible.

44
00:03:10.900 --> 00:03:14.240
But we will work with filters of which the model.

45
00:03:14.290 --> 00:03:19.990
Actually that's an implementation detail but that means that we want to apply as layers intensive flow

46
00:03:20.260 --> 00:03:26.020
convolution all to these layers but convolution or one delay is because we will only pass the filter

47
00:03:26.080 --> 00:03:27.560
among one dimension.

48
00:03:27.560 --> 00:03:32.980
Another difference that we can see compared to CNN that's what I've seen before for images is that doing

49
00:03:32.980 --> 00:03:39.970
the pooling phase we only take one element which means that we only take the maximum of the outputs

50
00:03:40.000 --> 00:03:45.320
of our conventional face or each convolution or filter we take the maximum of the results.

51
00:03:45.460 --> 00:03:51.100
It is just because in a sentence the position of the feature is less important than in an image knowing

52
00:03:51.100 --> 00:03:55.850
where a feature is in a sentence is less important than knowing where it is in an image.

53
00:03:55.900 --> 00:04:01.840
And more specifically the position on relations between the features that we are detecting is less important

54
00:04:01.870 --> 00:04:03.860
in a text than in an image.

55
00:04:03.880 --> 00:04:09.690
What we really care about is whether the feature is activated somewhere in the sentence or not.

56
00:04:09.700 --> 00:04:16.090
And finally if we have a look at the convolution or face you can see that we can see different types

57
00:04:16.090 --> 00:04:19.040
of features that AP and they have different size.

58
00:04:19.150 --> 00:04:24.640
And the reason is that in this architecture what they decided to do is that they want to apply filters

59
00:04:24.700 --> 00:04:30.970
of different size for the CNN architecture that we saw before for the images all our filters had the

60
00:04:30.970 --> 00:04:31.730
same size.

61
00:04:31.840 --> 00:04:34.420
But here we will have three different sides of filters.

62
00:04:34.420 --> 00:04:40.000
We have filters that will have a height of four others those that will have height of three and all

63
00:04:40.000 --> 00:04:42.370
those that we have high of two.

64
00:04:42.370 --> 00:04:50.410
So that means that we wanted to detect local filters in groups of two words three words and forwards.

65
00:04:50.590 --> 00:04:54.540
And of course same thing as for images for each side of data.

66
00:04:54.630 --> 00:05:00.870
We will have several filters several types of those feature detectors that of course the model we learned

67
00:05:00.870 --> 00:05:03.220
to tune during the training process.

68
00:05:03.220 --> 00:05:08.950
So hey they say that we have two different filters of size for two different features of size three

69
00:05:09.190 --> 00:05:14.890
and two different filters of size two but in all implementation we can add many more photos.

70
00:05:14.890 --> 00:05:20.980
Of course we will use for instance 50 filters for group of forwards 50 filters for a group of three

71
00:05:20.980 --> 00:05:27.480
words and sending four groups of two which so this just comes from the realization that that's in all

72
00:05:27.480 --> 00:05:28.350
language.

73
00:05:28.350 --> 00:05:34.770
Some information is conveyed by group of two words some are conveyed by a group of more words.

74
00:05:34.770 --> 00:05:41.640
And so it's clever to actually try to detect features and to find useful information in groups of words

75
00:05:41.730 --> 00:05:42.840
of different size.

76
00:05:42.840 --> 00:05:49.890
Finally last more detail is that as we apply ones you can volitional layers instead of to decode volitional

77
00:05:49.890 --> 00:05:50.740
layers.

78
00:05:50.760 --> 00:05:53.220
The output is not a matrix it's a vector.

79
00:05:53.400 --> 00:05:57.800
So we don't need a flattening phase as we did four images.

80
00:05:57.900 --> 00:06:03.450
We just need to concatenate all of our results in order to have a vector that we can give to a feed

81
00:06:03.450 --> 00:06:04.560
for a network.

82
00:06:04.560 --> 00:06:08.420
So that was it for the differences between CNN for images and for text.

83
00:06:08.430 --> 00:06:14.070
The main thing to keep in mind is that as rows and columns don't have the same meaning in the matrix

84
00:06:14.070 --> 00:06:18.740
for a sentence we need to change the way we apply conversational filters.

85
00:06:18.750 --> 00:06:24.600
So in this example we apply them only among the dimension that represents the sequence of words and

86
00:06:24.600 --> 00:06:27.690
the width is exactly the dimension of our embedding.

87
00:06:27.690 --> 00:06:29.560
So that's the main thing to keep in mind.

88
00:06:29.610 --> 00:06:34.000
Others are implementing detail that we will see again during the applications.

89
00:06:34.170 --> 00:06:40.800
That actually is the next spots because we are done here with the intuition of CNN for A.P. so we will

90
00:06:40.890 --> 00:06:46.580
implement this very architecture and what we will implement is a sentimental analyzer.

91
00:06:46.740 --> 00:06:53.750
So an AI that will tell us whether any text any sentence conveys a positive or negative sentiments and

92
00:06:53.750 --> 00:07:00.690
negative feeling that can be for in any moderation tasks in forms or in charts or whatever.

93
00:07:00.690 --> 00:07:06.120
Also if you're going to want to know what people think of its new products on Twitter for instance you

94
00:07:06.120 --> 00:07:10.720
can use this to automatically detect whether the thing good or bad of these brands.

95
00:07:10.830 --> 00:07:12.390
So hope you are excited about that.

96
00:07:12.630 --> 00:07:15.460
Let's start off first obligation right now and see you soon.
