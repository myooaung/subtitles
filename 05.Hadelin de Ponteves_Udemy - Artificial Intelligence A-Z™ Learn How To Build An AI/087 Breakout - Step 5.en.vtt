WEBVTT
1
00:00:00.330 --> 00:00:02.320
Hello and welcome to the story.

2
00:00:02.460 --> 00:00:09.240
All right so after we made these four convolutions and the LCN we now have an encoded state that is

3
00:00:09.240 --> 00:00:14.500
going to be the input of these two neural networks that we're going to make for the actor and the critic.

4
00:00:14.790 --> 00:00:20.730
And speaking of them the only thing that we have to do now is just create tools in our full connections.

5
00:00:20.730 --> 00:00:22.880
One for the actor and one for the critic.

6
00:00:23.190 --> 00:00:27.260
But before we do that we need to get the number of possible actions.

7
00:00:27.290 --> 00:00:32.520
And so I'm going to call you variable here that is not going to be a variable of the object.

8
00:00:32.520 --> 00:00:38.970
So I'm not going to use self here but I'm going to create viable non outputs which will represent a

9
00:00:38.970 --> 00:00:41.610
number of possible actions and to get it.

10
00:00:41.760 --> 00:00:44.520
Well we can get it from the action space.

11
00:00:44.520 --> 00:00:51.330
So we take our action space which will be the input of the function when we create the object.

12
00:00:51.510 --> 00:00:56.300
And then we add that and to get this number of possible actions.

13
00:00:56.580 --> 00:01:03.180
And now the actor and the critic will take separately the same input that is the output of this whole

14
00:01:03.180 --> 00:01:06.290
process here with the convolutions and GLSEN.

15
00:01:06.500 --> 00:01:12.900
So it will take the same input which is an encoded state but then they will have two different linear

16
00:01:13.110 --> 00:01:19.000
connections so that we get eventually actually two neural networks one for the two and one for a critic.

17
00:01:19.020 --> 00:01:21.030
So let's make these two separate neural networks.

18
00:01:21.060 --> 00:01:27.360
But since we already did the big job with the encoding here well what we simply need to do is just create

19
00:01:27.360 --> 00:01:33.640
two objects one in the full connection for the actor and one other linear connection for the critic.

20
00:01:33.660 --> 00:01:35.430
And so that's exactly what I'm going to do.

21
00:01:35.490 --> 00:01:42.560
I'm going to create two objects now a first object for the linear connection of the critic which I'm

22
00:01:42.570 --> 00:01:49.210
going to call critic and the score Linnie are and to create this linear connection.

23
00:01:49.380 --> 00:01:55.020
You know how to do it we simply need to take the engine module and then the linear class to which we

24
00:01:55.020 --> 00:01:55.800
have two inputs.

25
00:01:55.880 --> 00:02:01.800
Well the input neurons which are the outputs of all this including here with the convolutions and the

26
00:02:01.910 --> 00:02:05.190
GM that is 256 neurons.

27
00:02:05.190 --> 00:02:12.120
So when I put two hundred and fifty six here and then we're going to have one output because remember

28
00:02:12.210 --> 00:02:17.940
the output of the neural network for the critic is the value of the function applied to the input state

29
00:02:18.080 --> 00:02:20.960
to the inputs encoded states that we made here.

30
00:02:21.180 --> 00:02:28.680
So if we call the input state s that is the output of all this well the output of the neural network

31
00:02:28.680 --> 00:02:32.530
of the critic will be VS and therefore it has one dimension.

32
00:02:32.550 --> 00:02:33.710
It's just a value.

33
00:02:33.870 --> 00:02:36.320
And so here we put one.

34
00:02:36.510 --> 00:02:43.020
And remember this is what is shared among the actors so that they can get some common information that

35
00:02:43.020 --> 00:02:46.590
they can use to play their action in a more relevant way.

36
00:02:46.980 --> 00:02:50.430
OK so that's for the neural network of the critic.

37
00:02:50.580 --> 00:02:59.820
And now let's make the new network of the actor and therefore I'm in here self taught actor linear and

38
00:02:59.850 --> 00:03:02.830
same we already have the inputs encoded States.

39
00:03:02.850 --> 00:03:08.430
So now we simply need to add a linear connection and therefore saying we take the in a module then the

40
00:03:08.430 --> 00:03:15.870
linear class and now saying this new network of the actor will take the encoded state that has the size

41
00:03:15.870 --> 00:03:19.840
of 256 so 256 here.

42
00:03:20.070 --> 00:03:26.010
But then the output is going to be different because of course you know that the output of the neural

43
00:03:26.010 --> 00:03:30.790
network for the actor other key involves the key values of input states.

44
00:03:30.860 --> 00:03:33.620
The one that we could hear and the action plate.

45
00:03:33.810 --> 00:03:40.980
So again if we call this encoded state that we mean here as an action played a the output of this neural

46
00:03:40.980 --> 00:03:44.480
network actually there will be q as a.

47
00:03:44.880 --> 00:03:50.010
And since you know we have one huge value for each action then therefore we have no outputs.

48
00:03:50.010 --> 00:03:57.680
Q values and therefore the output here is going to be non outputs because no output is actually the

49
00:03:57.680 --> 00:03:59.380
number of humans.

50
00:03:59.840 --> 00:04:01.100
Okay perfect.

51
00:04:01.130 --> 00:04:05.360
So if you want I can write for you output here.

52
00:04:05.390 --> 00:04:18.410
The critic is the s well as is the encoded state and for the actor the output is cute as all right.

53
00:04:18.410 --> 00:04:23.750
So that's very important to understand this distinction here and to understand that we therefore have

54
00:04:23.900 --> 00:04:25.370
two separate news networks.

55
00:04:25.370 --> 00:04:29.370
One for the critic and one for the actor Okay perfect.

56
00:04:29.380 --> 00:04:32.080
So we are almost done with this function.

57
00:04:32.170 --> 00:04:33.920
Now the most important thing is done.

58
00:04:34.030 --> 00:04:39.370
The only remaining thing that we have to do is to initialize all the weights of those two neural networks

59
00:04:39.790 --> 00:04:40.830
and all the bias.

60
00:04:40.860 --> 00:04:45.800
And of course to do that we're going to use the two functions that we made earlier that is normalized

61
00:04:45.900 --> 00:04:48.480
columns initialiser and the weights in it.

62
00:04:48.490 --> 00:04:49.720
So let's do that quickly.

63
00:04:49.870 --> 00:04:52.180
It's going to be pretty easy and pretty fast.

64
00:04:52.180 --> 00:04:56.590
So first we're going to initialize some random weights and to do this we're going to apply the weights

65
00:04:56.590 --> 00:04:58.420
in it function to our object.

66
00:04:58.420 --> 00:05:03.150
So here we have to take self to get our object and to object.

67
00:05:03.160 --> 00:05:06.440
We apply the weight in its function.

68
00:05:06.620 --> 00:05:14.200
Therefore inside we just need to put the weights in that function and then we get that will apply this

69
00:05:14.200 --> 00:05:20.080
function to our object and by doing this we are just initializing some random weights to get a future

70
00:05:20.140 --> 00:05:21.930
optimal learning of these weights.

71
00:05:22.000 --> 00:05:27.460
And now what we have to do is make a special normalization for the actor and the critic.

72
00:05:27.670 --> 00:05:33.700
But remember I think I told this in the previous tutorials we're not going to set a same variance for

73
00:05:33.780 --> 00:05:38.890
the X in acrylic yakked you will get a small standard deviation small variance.

74
00:05:38.890 --> 00:05:40.840
And the critics will get a big one.

75
00:05:40.840 --> 00:05:41.800
And why do we do this.

76
00:05:41.800 --> 00:05:47.560
What's the purpose of giving a small standard deviation of the weights for the actor and the large standard

77
00:05:47.560 --> 00:05:49.320
deviation of the way for the critic.

78
00:05:49.510 --> 00:05:53.830
Well that allows to manage to deal exploration vs exploitation.

79
00:05:53.830 --> 00:05:58.620
That's exactly the purpose of doing this by giving a small variance to the actor in a larger audience

80
00:05:58.630 --> 00:05:59.460
to critique.

81
00:05:59.490 --> 00:06:04.510
We will have a good management of exploration vs exploitation.

82
00:06:04.600 --> 00:06:07.510
So let's do this let's first take care of the actor.

83
00:06:07.510 --> 00:06:14.170
So we take self or object then we're going to take the neural network of our actor which is actor Linnea

84
00:06:14.270 --> 00:06:20.350
are then we are going to access the weights of this new network of the actor and remember to access

85
00:06:20.350 --> 00:06:23.360
the data of the weights we need that data.

86
00:06:23.410 --> 00:06:24.280
All right.

87
00:06:24.280 --> 00:06:31.000
So with this we get the weights and now we're going to use our function normalized comb's initialiser.

88
00:06:31.390 --> 00:06:36.520
So I'm copying this pasting here and we're going to enter an argument.

89
00:06:36.520 --> 00:06:38.810
The standard deviation we want these weights to have.

90
00:06:39.160 --> 00:06:42.130
But first remember this function takes two arguments.

91
00:06:42.200 --> 00:06:45.280
First the way we want to initialize.

92
00:06:45.280 --> 00:06:49.750
So we simply need to take that again and base that here.

93
00:06:49.870 --> 00:06:53.010
And the second argument is the standard deviation.

94
00:06:53.170 --> 00:06:54.420
We want these weights to have.

95
00:06:54.580 --> 00:07:02.880
So as we said we want a small standard deviation to the actor in a small one it's going to be 0.01 perfect.

96
00:07:02.890 --> 00:07:05.880
So that's where the weights of the neural network of the actor.

97
00:07:05.900 --> 00:07:09.610
Now let's take care of the bias of the new that work of the actor.

98
00:07:09.850 --> 00:07:15.460
And therefore here we're going to do almost the same thing we're going to copy this paste that below.

99
00:07:15.520 --> 00:07:26.470
Replace weight by buyers to access the buyers and after data we're simply going to add fill and remember

100
00:07:26.560 --> 00:07:31.170
inside when put zero because we want all devices to be initialized with zero.

101
00:07:31.510 --> 00:07:37.840
So actually I don't think this line is necessary because as you remember the buyers are already initialized

102
00:07:37.840 --> 00:07:41.400
to zero with this fill function in the wait function.

103
00:07:41.620 --> 00:07:47.560
So you know we're doing this just to make sure that the buyers are actually initialized to zero.

104
00:07:47.560 --> 00:07:49.490
But I think it's already done here.

105
00:07:49.690 --> 00:07:52.720
But anyway now we are 100 percent sure.

106
00:07:53.050 --> 00:07:55.990
All right now we're going to do the same for the critic.

107
00:07:56.050 --> 00:07:59.660
So let's be efficient and let's cover these two lines.

108
00:08:00.220 --> 00:08:07.180
Let's face them here and here we're just going to replace actor by critic.

109
00:08:07.180 --> 00:08:08.400
Same here.

110
00:08:08.540 --> 00:08:13.600
And now the only thing that we have to change is just the standard deviation we want the weights of

111
00:08:13.600 --> 00:08:15.680
the neural network for the critic to have.

112
00:08:15.970 --> 00:08:23.310
And as you remember once this time a large standard deviation instead of open or one we will input one

113
00:08:23.830 --> 00:08:29.680
so there we go we have a small standard deviation for the weights of the new work of the actor and a

114
00:08:29.680 --> 00:08:31.610
large standard deviation for the weights.

115
00:08:31.630 --> 00:08:33.290
And then when we get at the critic.

116
00:08:33.370 --> 00:08:37.560
And of course that's something we get to replace active here by credit.

117
00:08:37.980 --> 00:08:40.460
All right now we get cool.

118
00:08:40.510 --> 00:08:46.300
So now we have two remaining things to do first is to initialize also the bias of the team and to do

119
00:08:46.300 --> 00:08:53.500
this we take our object self because the LACMA belongs to our object and we'd say or as T.N. then that

120
00:08:53.870 --> 00:08:57.980
and then we're going to get the two types of buyers that are in the last.

121
00:08:58.180 --> 00:09:04.650
That's bias and the score by age and the other one is based on the score age age.

122
00:09:04.660 --> 00:09:09.880
That's the two types of bias in the CME and same there are going to be initialized to zero.

123
00:09:09.880 --> 00:09:18.810
So first we access to the data and then we use the fill underscore function to fill all these buyers

124
00:09:18.850 --> 00:09:21.940
with zeroes initialize them with yours.

125
00:09:21.940 --> 00:09:22.320
Right.

126
00:09:22.360 --> 00:09:31.500
And now for the second group of buyers we are here the same get replaced by age by age age.

127
00:09:31.500 --> 00:09:32.430
All right.

128
00:09:32.570 --> 00:09:39.560
That's initialises the bias of the zeros and now the last thing we need to do is to use a method that

129
00:09:39.560 --> 00:09:43.090
is inherited from the end and that module that is the train method.

130
00:09:43.220 --> 00:09:47.360
And basically there is just a method that puts the module in treatment.

131
00:09:47.540 --> 00:09:48.760
So what's the use of it.

132
00:09:48.890 --> 00:09:55.440
Well the use is that it allows to activate if there is any drop out in the bathroom ligations.

133
00:09:55.550 --> 00:10:03.100
And so to use it we just add self thought train and that puts the module in trammeled perfect.

134
00:10:03.170 --> 00:10:05.650
So we're done with the init function.

135
00:10:05.720 --> 00:10:11.210
We have our convolutions we have the CME we have our two separate neural networks for the critic and

136
00:10:11.210 --> 00:10:15.400
the actor and all the weights and bias are well initialized.

137
00:10:15.620 --> 00:10:16.940
So that's all good.

138
00:10:16.940 --> 00:10:21.860
We are ready to move on to the next step which is to make the forward function that will of course forward

139
00:10:21.890 --> 00:10:27.230
propagate the signal from the very beginning with the original input images throughout all the brain

140
00:10:27.230 --> 00:10:28.640
until we get the output.

141
00:10:29.000 --> 00:10:30.770
So let's do that in the next tutorial.

142
00:10:30.800 --> 00:10:32.330
And until then enjoy AI.
