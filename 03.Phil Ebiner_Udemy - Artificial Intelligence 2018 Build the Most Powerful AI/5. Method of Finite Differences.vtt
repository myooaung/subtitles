WEBVTT
ï»¿1
00:00:00.360 --> 00:00:03.660
Hello and welcome back to the course on augmented random search.

2
00:00:03.930 --> 00:00:08.230
And in today's tutorial we're talking about the method of finite differences.

3
00:00:08.230 --> 00:00:14.910
Now bear in mind that this is an advanced tutorial so feel free to skip it and proceed with the other

4
00:00:14.910 --> 00:00:17.230
intuition tutorials and the practical tutorials.

5
00:00:17.340 --> 00:00:27.100
And that should be totally sufficient for you to have a good grasp of what area is all about and code.

6
00:00:27.420 --> 00:00:28.680
Along with the code I'd love.

7
00:00:28.710 --> 00:00:32.120
However if you would like to proceed with historial then feel free to do so.

8
00:00:32.190 --> 00:00:37.800
But be prepared that we are going to be some complex topics that we going to be covering of and therefore

9
00:00:37.830 --> 00:00:43.610
it might take some time and it might be a bit harder to get your head around than usual.

10
00:00:43.650 --> 00:00:47.920
Definitely took me quite a bit of thinking to wrap my own head around this.

11
00:00:47.940 --> 00:00:53.240
So yeah that's that's my view although you might find it very easy on the other hand.

12
00:00:53.460 --> 00:00:55.080
All right so let's have a look.

13
00:00:55.130 --> 00:00:56.520
The method of finite differences.

14
00:00:56.520 --> 00:00:57.650
How does this work.

15
00:00:57.690 --> 00:01:00.350
So this is where we left off last time.

16
00:01:00.900 --> 00:01:04.060
We have the AI that's performing these episodes.

17
00:01:04.070 --> 00:01:11.040
It's so every episode is from start to finish where there is falls over time or runs out or reaches

18
00:01:11.040 --> 00:01:19.350
a certain goal and basically after the episode is finished the AI takes the reward from the environment

19
00:01:19.710 --> 00:01:28.440
and uses that reward to make adjustments to the weights in order to understand how to become better

20
00:01:28.480 --> 00:01:34.530
how to evolve how to work better how to run better how to do all the things that are required from it

21
00:01:34.680 --> 00:01:36.050
better.

22
00:01:36.270 --> 00:01:41.200
And so today we're going to discuss how exactly does it use this reward to adjust its weight.

23
00:01:41.210 --> 00:01:45.830
What is the principle in doing this for the Erris.

24
00:01:45.930 --> 00:01:53.400
Now before we proceed what I wanted to mention is that the environment actually provides a reward after

25
00:01:53.430 --> 00:01:59.070
every single action not just at the end of an episode but after every single action and that has nothing

26
00:01:59.070 --> 00:02:02.570
to do with the algorithm itself because the environment is separate.

27
00:02:02.570 --> 00:02:07.650
This for instance the Mujica environment is coded is prepared and anybody can apply any kind of model

28
00:02:07.650 --> 00:02:12.050
to it and we'll talk more about this in one of the final tutorials in intuition part of the course.

29
00:02:12.060 --> 00:02:17.510
But I just wanted to make sure that we're on the same page that they don't actually provide rewards

30
00:02:17.520 --> 00:02:18.510
after every action.

31
00:02:18.540 --> 00:02:27.950
The arrest algorithm actually chooses to work with that aggregate report a reward for the whole episode.

32
00:02:28.020 --> 00:02:31.620
Again we'll we'll discuss this a bit further down but just a heads up on that.

33
00:02:31.630 --> 00:02:34.470
So really going to affect us right now.

34
00:02:34.470 --> 00:02:42.480
For now we just know that there was an episode the AI model went from from the start to towards the

35
00:02:42.480 --> 00:02:45.920
finish or somewhere there and then it got a reward for that.

36
00:02:45.940 --> 00:02:53.790
And so basically the further the AI managed to walk the higher the reward will be the longer it managed

37
00:02:53.790 --> 00:03:00.490
to stay upright the higher the reward will be and the faster it walked the higher reward will be.

38
00:03:00.600 --> 00:03:02.280
Again depends on the environment itself.

39
00:03:02.280 --> 00:03:08.760
But conceptually the more the court the closer the AI is to what we want it to do the higher the reward

40
00:03:08.760 --> 00:03:10.120
the further away it is.

41
00:03:10.170 --> 00:03:13.160
If it's falling all right at the start it was going to be very low.

42
00:03:13.650 --> 00:03:14.180
All right.

43
00:03:14.250 --> 00:03:15.870
So we get a reward.

44
00:03:15.870 --> 00:03:16.580
We are just the it is.

45
00:03:16.590 --> 00:03:19.020
Let's talk about how exactly do I just do it.

46
00:03:19.290 --> 00:03:22.800
Now there are different ways of doing this.

47
00:03:22.800 --> 00:03:30.440
For example usually in artificial intelligence what is used is called the gradient descent method.

48
00:03:30.690 --> 00:03:41.430
And it is a method in which we take a direct calculation of the differentiation of the loss.

49
00:03:41.430 --> 00:03:46.820
For instance over the weight or in this case it would be the reward.

50
00:03:46.830 --> 00:03:53.220
We differentiate the reward over the weights but that's something that were other artificial intelligence

51
00:03:53.250 --> 00:03:54.180
our use.

52
00:03:54.300 --> 00:03:58.770
And for example if you've been in our artificial intelligence a dessert course and we discussed that

53
00:03:58.770 --> 00:04:04.620
in detail we're not going to dive into it here because the Erris actually use something else called

54
00:04:04.950 --> 00:04:08.610
the method of finite differences and the formulas over here.

55
00:04:09.060 --> 00:04:12.770
So it's not actually proper differentiation it's something else.

56
00:04:12.930 --> 00:04:15.900
So that's what we're going to be talking about today.

57
00:04:15.900 --> 00:04:21.930
All right let's have a look at some point during the training process.

58
00:04:21.930 --> 00:04:27.950
The artificial intelligence that our aerosol urine has this matrix of weights as rediscuss is a perception

59
00:04:27.960 --> 00:04:33.480
it has a matrix of weights and those weights are applied to the inputs or there's a matrix operation

60
00:04:33.900 --> 00:04:37.710
applied to the inputs with these weights and then we get the outputs.

61
00:04:37.830 --> 00:04:43.700
And so during the training process how will the AI know how to update these weights.

62
00:04:43.710 --> 00:04:45.140
What what will it.

63
00:04:45.390 --> 00:04:47.310
What will its next weights be.

64
00:04:47.370 --> 00:04:55.050
And so what the aerosol algorithm does is it takes perturbations like very tiny perturbations of these

65
00:04:55.050 --> 00:04:55.690
weights.

66
00:04:55.770 --> 00:05:04.210
So basically takes a set of random numbers or a matrix with random small small tiny values and it adds

67
00:05:04.210 --> 00:05:05.480
them to these weights.

68
00:05:05.530 --> 00:05:07.950
And on the other hand it subtracts them from these weights.

69
00:05:07.960 --> 00:05:12.860
So basically it's the same values but in one case the matrix is added in case and subtract.

70
00:05:12.970 --> 00:05:19.390
And so as a result we have two new matrices with perturbative weights so the weights are the same but

71
00:05:19.390 --> 00:05:21.130
not exactly just slightly different.

72
00:05:21.130 --> 00:05:26.020
So these weights are here all slightly larger than the ones we had just before.

73
00:05:26.110 --> 00:05:28.970
And these are all slightly smaller than the ones we had before.

74
00:05:29.050 --> 00:05:32.700
And also there's actually a coefficient here the coefficients called acceleration noise.

75
00:05:32.710 --> 00:05:37.720
We're not going to add it here so that we don't clutter up our calculations you are going to have it

76
00:05:37.720 --> 00:05:45.460
though you'll see in the research paper and you also have it in the practical tutorials so not to worry

77
00:05:45.490 --> 00:05:50.050
we're not going to leave it out completely just for the sake of simplicity and the intuition part of

78
00:05:50.050 --> 00:05:50.720
things.

79
00:05:51.100 --> 00:05:54.940
All right so now that we have these perturbative waits what happens next.

80
00:05:54.940 --> 00:05:59.690
Well in reality we actually have several sets of these perturbative weights.

81
00:05:59.800 --> 00:06:03.460
So we're going to replace these values with the letter D.

82
00:06:03.490 --> 00:06:04.150
So there it is.

83
00:06:04.180 --> 00:06:06.580
That's our positive report perturbative waits.

84
00:06:06.610 --> 00:06:12.430
And here are negative it negatively perturbative weights and then we actually have several sets of these.

85
00:06:12.430 --> 00:06:16.910
So in practical terms you'll see that we actually have 16 sets.

86
00:06:16.930 --> 00:06:21.880
So 32 in total we have 16 positive and 60 negative and they all have the letter D but they have another

87
00:06:21.910 --> 00:06:26.510
index I didn't want to clutter up so I just use different letters so we have D E F G.

88
00:06:26.560 --> 00:06:30.110
And here we have negative deid negative negative negative G.

89
00:06:30.250 --> 00:06:38.160
And so now we have in the case of our intuition tutorials we have eight matrices of perturbative weights

90
00:06:38.170 --> 00:06:43.050
again these weights are very similar to what we had just previously in the training process are they.

91
00:06:43.240 --> 00:06:47.150
But they're slightly different slightly larger or slightly smaller and smaller.

92
00:06:47.170 --> 00:06:49.700
So what is the AIU going to do.

93
00:06:49.720 --> 00:06:51.140
What is there going to do now.

94
00:06:51.310 --> 00:06:55.970
Was going to run an episode with each one of these weights.

95
00:06:55.990 --> 00:07:02.440
So the this matrix of weights will get its own episode this matrix of weights will get its own episode

96
00:07:02.710 --> 00:07:06.200
this matrix of weights will get its own episode and so on.

97
00:07:06.520 --> 00:07:15.400
And so as you can see the image is the same here but in reality is just to illustrate that this matrix

98
00:07:15.400 --> 00:07:17.070
of weights is run with its own opposite.

99
00:07:17.080 --> 00:07:24.910
In reality the image will be different so every time we see the humanoid doing different action because

100
00:07:24.910 --> 00:07:31.990
these these weights as we remember through the matrix operation provide the outputs and outputs tell

101
00:07:31.990 --> 00:07:38.830
the humanoid which muscles to move should it move its legs should move its hands or arms or feet or

102
00:07:38.830 --> 00:07:44.360
neck or whatever shoulders back and so out of all of its 22 degrees of freedom.

103
00:07:44.500 --> 00:07:49.750
And so basically every time is going to be slightly different resolved maybe maybe even drastically

104
00:07:49.750 --> 00:07:55.450
different because maybe some some of these might make a small change in ways that might make a huge

105
00:07:55.450 --> 00:07:58.070
change in the outcome.

106
00:07:58.480 --> 00:08:03.810
So thats what is happening and in reality I wanted to make common here that is just one.

107
00:08:03.820 --> 00:08:08.460
So each one of these ways is perturbative sense of where its going to get.

108
00:08:08.530 --> 00:08:14.710
Just like one episode is actually going to get quite of like a whole cycle of episodes to run with these

109
00:08:14.720 --> 00:08:17.020
weights and then it's all going to be averaged out.

110
00:08:17.020 --> 00:08:21.890
You'll see that in the research paper and you'll see that in the practical terms of unknowns as well.

111
00:08:21.970 --> 00:08:27.820
But for our intuition purposes which is going to stick with one episode so these weights these Wadewitz

112
00:08:27.850 --> 00:08:35.280
are going to have one episode of the AI kind of like floating quotations of quote unquote playing the

113
00:08:35.290 --> 00:08:38.980
environment playing in the environment to see how far it can go.

114
00:08:39.010 --> 00:08:45.340
And then the same the same with these with these in some cases as you can tell as you can imagine the

115
00:08:45.340 --> 00:08:50.680
result will be better than with the original set of weights which was w 1 1 1 2 and so on.

116
00:08:50.680 --> 00:08:55.040
Without the perturbations some cases the result will be better in some case the result will be worse

117
00:08:55.060 --> 00:08:58.890
maybe you might be worse you might better might be better might better might be better might be worse

118
00:08:58.900 --> 00:08:59.540
and so on.

119
00:08:59.830 --> 00:09:03.450
We can't predict yet but what will tell us how the result went.

120
00:09:03.460 --> 00:09:05.370
Are the rewards.

121
00:09:05.380 --> 00:09:07.010
So in each case we'll get a reward.

122
00:09:07.010 --> 00:09:12.260
So in this case for instance ardy pause RDNA are are you Paul are in eg.

123
00:09:12.360 --> 00:09:12.980
RF pause.

124
00:09:13.000 --> 00:09:13.650
R f neg.

125
00:09:13.660 --> 00:09:14.660
RG pause are.

126
00:09:14.680 --> 00:09:15.360
Gina.

127
00:09:15.550 --> 00:09:23.230
And by the way this neg doesn't mean that it's negative where it just stands to signify that this reward

128
00:09:23.560 --> 00:09:29.200
is associated with this negative perturbation of weights and this reward is associated with this positive

129
00:09:29.200 --> 00:09:30.140
perturbation of.

130
00:09:30.250 --> 00:09:34.250
So all of these are in the the letter that's used usually is D.

131
00:09:34.320 --> 00:09:35.130
So Delta.

132
00:09:35.120 --> 00:09:40.720
So these are positive delta these a negative deltas positive deltas negative Delton's positive as negative.

133
00:09:41.090 --> 00:09:43.040
I just use some other letters as well.

134
00:09:43.360 --> 00:09:48.020
And so that's what we have we have these perturbations of weight.

135
00:09:48.100 --> 00:09:51.300
Let's recap we have we had original set of weights the double use.

136
00:09:51.340 --> 00:09:57.370
Now we have positive perturbation here net and negative perturbation positive perturbation same prediction

137
00:09:57.460 --> 00:09:59.390
but negative here positive perturbations say.

138
00:09:59.390 --> 00:10:05.670
But you posit perturbation same but if you average one we've run an episode and we got a reward.

139
00:10:05.740 --> 00:10:08.090
There are these rewards are illusory.

140
00:10:08.590 --> 00:10:13.540
Now what's the AI going to do with all this information of all of these rewards all these ways.

141
00:10:13.540 --> 00:10:15.770
How is it going to decide what good was that.

142
00:10:15.940 --> 00:10:21.010
Well we were it established that some of these perturbations are going to be in the right direction.

143
00:10:21.010 --> 00:10:25.300
Some of these producers are going to yield better results than before like it's because we're searching

144
00:10:25.300 --> 00:10:31.420
randomly and that's why the hologram is actually called the random search because we're randomly searching

145
00:10:31.660 --> 00:10:33.490
for new weights.

146
00:10:33.550 --> 00:10:34.150
We're searching.

147
00:10:34.150 --> 00:10:34.390
OK.

148
00:10:34.420 --> 00:10:37.350
Maybe these will work better maybe it is or maybe these will work better.

149
00:10:37.350 --> 00:10:38.420
Maybe these will work.

150
00:10:38.650 --> 00:10:42.940
And so the let's say these worked very well.

151
00:10:43.310 --> 00:10:45.330
And now how do we know.

152
00:10:45.340 --> 00:10:49.840
So the reward was very puzzled how do we adjust our actual weights.

153
00:10:49.840 --> 00:10:53.000
This is just oleic like a little exercise they do.

154
00:10:53.020 --> 00:10:55.200
But now it needs to finally adjust the weights.

155
00:10:55.270 --> 00:10:57.950
Right so it needs to decide how we're going to adjust the way.

156
00:10:58.210 --> 00:11:06.280
Well let's see how the eyes are going to pick out the best results out of all of these examples that

157
00:11:06.280 --> 00:11:07.020
it has.

158
00:11:07.180 --> 00:11:12.610
And this is where the formula comes in the formula for the method of finite differences.

159
00:11:12.610 --> 00:11:12.880
All right.

160
00:11:12.880 --> 00:11:17.920
So this is probably the most complex part of this whole practical as we can get through this.

161
00:11:17.920 --> 00:11:20.630
You can get through the whole Arison no problem.

162
00:11:21.010 --> 00:11:24.470
So here we've got the weights the initial weights.

163
00:11:24.550 --> 00:11:25.840
They're going to be overridden.

164
00:11:25.840 --> 00:11:30.490
So we've got to put a new value in them and we're going to put in there is we're going to put in the

165
00:11:30.490 --> 00:11:38.680
same weight that we had plus a certain cerned Delta Delta CRN change a certain adjustment.

166
00:11:38.680 --> 00:11:43.930
So basically as you see we just taking the old ways were overriding with them with themselves plus something

167
00:11:44.620 --> 00:11:50.770
small but some some adjustments and this adjustment is going to be obviously calculated from this.

168
00:11:50.770 --> 00:11:57.610
So from all of these experiments that the AI has done is going to calculate adjustment and adjust the

169
00:11:57.800 --> 00:12:07.960
existing weights in the direction that turned out to be the most the most the most the best results

170
00:12:08.080 --> 00:12:11.420
the most lucrative direction of adjusting the width.

171
00:12:11.430 --> 00:12:13.140
How is it going to find that direction.

172
00:12:13.390 --> 00:12:19.980
Well it's going to apply the following format which is the method of finite differences we're going

173
00:12:19.980 --> 00:12:27.720
to take our day positive a minus R R D negative and multiply by the Delta participations for D then

174
00:12:27.730 --> 00:12:33.040
we're going to take r e positive minus our negative and multiply by that Delta perturbations for E.

175
00:12:33.330 --> 00:12:38.010
We're going to take the R of positive month subtract the R of negative multiply by the Delta perturbations

176
00:12:38.010 --> 00:12:42.090
for F and then we're going to take the R.G. positive minus R.G. negative.

177
00:12:42.090 --> 00:12:45.470
Multiply it by the Delta perturbations for G.

178
00:12:45.630 --> 00:12:46.120
You can.

179
00:12:46.160 --> 00:12:49.740
I can understand this is quite a lot to take in right away.

180
00:12:49.830 --> 00:12:52.650
But let's break this down slowly go through this.

181
00:12:52.650 --> 00:12:54.210
Why does this formula work.

182
00:12:54.210 --> 00:12:59.400
Why is it going to make our AI evolve in the right direction.

183
00:12:59.400 --> 00:13:02.130
Let's try to understand this in more detail.

184
00:13:02.340 --> 00:13:08.880
So in order to understand that what I recommend doing is mentally open up these brackets.

185
00:13:08.880 --> 00:13:13.850
So if you take this ARDE positive and you multiply if you open this bracket then what you'll have is

186
00:13:13.890 --> 00:13:20.470
already positive multiplied by this minus R.G. negative multiplied by this again.

187
00:13:20.500 --> 00:13:25.680
Right and simplest things here are positive multiplied by this matrix minus are in negative multiply

188
00:13:25.680 --> 00:13:27.180
by this matrix and so on.

189
00:13:27.570 --> 00:13:33.540
But let's focus on this first part what that will mean is that we're taking that original set of weights

190
00:13:33.870 --> 00:13:39.030
and we're adding the word to beta the perturbations Delta perturbations.

191
00:13:39.090 --> 00:13:43.680
But we're not just adding them we're adding them multiplied by R.G. positive.

192
00:13:43.890 --> 00:13:48.130
And then we're also subtract subtracting the Delta positive perturbations.

193
00:13:48.150 --> 00:13:52.900
But we're not just subtracting them we're subtracting them multiplied by R.G. negative.

194
00:13:53.090 --> 00:13:59.070
And so if we go back to this result over here basically what we're doing is instead of just adding the

195
00:13:59.070 --> 00:14:06.660
Delta Delta like they are here they're added but with a coefficient of d positive and instead of subtracting

196
00:14:06.660 --> 00:14:09.340
the Deltas as they are here they are subtracted.

197
00:14:09.360 --> 00:14:11.460
But with a coefficient of R.G. negative.

198
00:14:11.670 --> 00:14:17.190
And what that means is that basically if we didn't have any of these if these conditions are the same

199
00:14:17.190 --> 00:14:21.130
that would cancel each other out you know plus minus would cancel each other.

200
00:14:21.210 --> 00:14:28.210
But because these rewards are different because for instance the say This reward is much greater for

201
00:14:28.280 --> 00:14:30.390
example could be like a hundred for example.

202
00:14:30.390 --> 00:14:34.070
That's just making up numbers here has nothing do with reality.

203
00:14:34.230 --> 00:14:42.010
But if this was like 100 or stand then that means this result is orders of disorder where we reward

204
00:14:42.010 --> 00:14:43.930
is 100 risk reward is 1.

205
00:14:44.100 --> 00:14:47.680
So that means this result is a hundred times better than this one.

206
00:14:47.730 --> 00:14:53.760
And that's why we want to move 100 times more in the direction of the positive part to purchase nations

207
00:14:54.150 --> 00:14:58.050
then in the direction of the negative perturbations.

208
00:14:58.050 --> 00:14:59.280
And same for all of these.

209
00:14:59.280 --> 00:15:05.690
So basically where we're essentially doing the same exact operation we're adding or subtracting.

210
00:15:05.760 --> 00:15:16.830
But with the coefficient with a coefficient which equals to the reward that the AI was given by the

211
00:15:16.830 --> 00:15:19.450
environment for that specific experiment.

212
00:15:19.470 --> 00:15:26.610
So this experiment had a greater reward then the AI is going to evolve in that direction with a huge

213
00:15:26.610 --> 00:15:27.400
coefficient.

214
00:15:27.420 --> 00:15:33.300
If this experiment had a bad reward very low reward then it is going to evolve in that direction to

215
00:15:33.300 --> 00:15:34.410
follow.

216
00:15:34.650 --> 00:15:38.700
We're very low coefficient So that's all it is.

217
00:15:38.700 --> 00:15:42.770
So if we go back here if you open up the brackets that's exactly what's going on.

218
00:15:42.810 --> 00:15:43.690
We're taking the weight.

219
00:15:43.710 --> 00:15:47.300
And we were performing the experiments that we did.

220
00:15:47.310 --> 00:15:53.070
But all at the same time and with coefficients to make sure that or as we did the experiments we know

221
00:15:53.520 --> 00:15:57.100
which ones yielded great rewards which you don't feel not so great.

222
00:15:57.190 --> 00:16:04.020
So let's let's let those rewards guide the evolution of the artificial intelligence.

223
00:16:04.020 --> 00:16:05.670
And that's why it's called.

224
00:16:05.670 --> 00:16:10.860
On one hand it's called the random search algorithm because you're searching for these perturbations

225
00:16:10.860 --> 00:16:11.520
randomly.

226
00:16:11.520 --> 00:16:17.070
On the other hand it's also called the evolution strategies algorithm because you're evolving as a strategy

227
00:16:17.070 --> 00:16:19.630
of how to evolve the artificial intelligence.

228
00:16:20.190 --> 00:16:22.130
So that's all it is.

229
00:16:22.200 --> 00:16:25.930
And then in addition to that there's also another confusion here.

230
00:16:25.940 --> 00:16:27.550
I didn't include it on purpose.

231
00:16:27.810 --> 00:16:34.620
It's the learning rate divided by the number of these perturbations that we have included so that the

232
00:16:34.770 --> 00:16:36.860
slider wouldn't be cluttered up too much.

233
00:16:36.990 --> 00:16:43.620
But don't worry it is in the research paper and it is it will be in your practical tutorials we're going

234
00:16:43.620 --> 00:16:45.080
to have that connection there.

235
00:16:45.540 --> 00:16:46.120
OK.

236
00:16:46.140 --> 00:16:49.980
So that's in a nutshell how the Airbus algorithm works.

237
00:16:49.980 --> 00:16:53.370
This method is called the metho fight differences.

238
00:16:53.430 --> 00:16:54.890
This is the intuition behind it.

239
00:16:54.900 --> 00:17:02.670
So we have positive perturbations negative perturbations we get certain rewards for the positive for

240
00:17:02.670 --> 00:17:07.980
the negative and then we apply all of those perturbations so that we run those experiments we find out

241
00:17:08.100 --> 00:17:13.590
the rewards and then we apply those perturbations to update the weights but we take into account the

242
00:17:13.590 --> 00:17:19.820
rewards that we got in the experiments so that our AI is evolving in the best possible direction the

243
00:17:19.820 --> 00:17:23.730
best direction that we found that we search for.

244
00:17:23.960 --> 00:17:28.660
And so that's Erris in a nutshell.

245
00:17:28.690 --> 00:17:37.730
The research paper talks more about this in in detail and that's another reason why to jump into it

246
00:17:37.760 --> 00:17:40.430
and this is finally where we're going to reference it.

247
00:17:40.490 --> 00:17:49.020
This is the research paper by Horia mania and Ereli guy and their supervisor been wrecked.

248
00:17:49.220 --> 00:17:56.620
And this paper is called a simple random search provides a competitive approach to reinforcement learning.

249
00:17:56.640 --> 00:17:57.720
It's 2018.

250
00:17:57.710 --> 00:17:59.330
It's very recent.

251
00:17:59.330 --> 00:18:02.110
You find it in the course notes also on archive.

252
00:18:02.120 --> 00:18:05.650
So you'll find the same link on the course not where you just click on it.

253
00:18:05.870 --> 00:18:09.060
It's also an archive just like that.

254
00:18:09.080 --> 00:18:16.820
Finally after all what we've discussed about A.S. we are ready to proceed with this research paper so

255
00:18:17.080 --> 00:18:18.400
I highly recommend checking out.

256
00:18:18.410 --> 00:18:19.830
Very interesting.

257
00:18:19.910 --> 00:18:26.150
Interesting the riddle and I'm sure that these tutorials that you've successfully completed a review

258
00:18:26.150 --> 00:18:32.060
in this course are going to help guide you through this research paper and plus you going to be actually

259
00:18:32.300 --> 00:18:36.710
walking through it when you're coding for lunch is going to be walking you through the research paper

260
00:18:37.010 --> 00:18:43.190
and you're going to be quoting it together so this is a good opportunity to get a preview of what is

261
00:18:43.190 --> 00:18:44.410
to come.

262
00:18:44.420 --> 00:18:45.710
I hope you enjoyed this tutorial.

263
00:18:45.710 --> 00:18:47.290
Congratulations on powering through.

264
00:18:47.290 --> 00:18:52.870
That was the most the most complex tutorial yet in this course.

265
00:18:53.030 --> 00:18:55.510
And I look forward to seeing you back here next time.

266
00:18:55.550 --> 00:18:57.320
Until then enjoy AI.

