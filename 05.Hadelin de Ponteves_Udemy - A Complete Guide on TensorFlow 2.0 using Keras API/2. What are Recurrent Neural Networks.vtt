WEBVTT
1
00:00:00.330 --> 00:00:02.850
Hello and welcome back to the course on deep learning.

2
00:00:02.850 --> 00:00:09.570
Today we're kicking off this section for recurrent neural networks and I'm very excited about this section.

3
00:00:09.690 --> 00:00:12.660
There's going to be quite some interesting tutorials.

4
00:00:12.660 --> 00:00:19.340
This is a one of the most advanced algorithms that exists in the world of supervised deep learning.

5
00:00:19.350 --> 00:00:21.660
So let's get started.

6
00:00:21.690 --> 00:00:27.930
We have our little breakdown of supervised versus unsupervised Deep Learning branches.

7
00:00:27.930 --> 00:00:32.130
And here we've got artificial neural networks which we've already talked about.

8
00:00:32.160 --> 00:00:36.000
We've already talked about convolution all neural networks as well.

9
00:00:36.000 --> 00:00:38.760
And today we're talking about recurrent neural networks.

10
00:00:38.790 --> 00:00:45.000
So they're just so that we see where we are in the big picture of things slowly getting to the unsupervised

11
00:00:45.270 --> 00:00:46.240
part of the course.

12
00:00:46.320 --> 00:00:49.750
But nevertheless that's focused on are announced today.

13
00:00:49.770 --> 00:00:50.040
All right.

14
00:00:50.040 --> 00:00:55.170
So now that we know where we are on the map in terms of a list let's have a look where we are on the

15
00:00:55.170 --> 00:00:56.960
map in terms of the human brain.

16
00:00:57.270 --> 00:00:58.620
And so why are we doing this.

17
00:00:58.620 --> 00:01:02.340
Why are we looking at the human brain as as if it's a map of the world.

18
00:01:02.340 --> 00:01:09.690
Well the reason for that is the whole concept behind deep learning is to try mimic the human brain and

19
00:01:09.750 --> 00:01:17.490
get kind of similar functions as a human human brain has and leverage the things that evolution has

20
00:01:17.490 --> 00:01:18.910
already developed for us.

21
00:01:18.930 --> 00:01:26.490
And I thought it'd be pretty cool if we can somehow link the different branches of deep learning that

22
00:01:26.490 --> 00:01:27.080
we've discussed.

23
00:01:27.090 --> 00:01:31.560
So we've talked about or the algorithms that we discussed we've talked about AFN CNN and we're talking

24
00:01:31.560 --> 00:01:37.830
about RNA and if we could link those to certain parts of the human brain and if if it would make sense.

25
00:01:37.830 --> 00:01:39.920
So let's have a look here.

26
00:01:39.930 --> 00:01:45.330
We've got the brain the human brain has got three parts so we've got the cerebrum which has all of this

27
00:01:45.330 --> 00:01:46.220
colored part.

28
00:01:46.290 --> 00:01:50.400
Then we've got the cerebellum which is underneath there and that's the little brain actually looked

29
00:01:50.400 --> 00:01:52.680
it up in Latin that does mean little brain.

30
00:01:52.680 --> 00:01:53.980
How funny is that.

31
00:01:54.060 --> 00:02:00.900
And we've already looked at a section of the cerebellum in the pilot we talk about and ends that orange

32
00:02:00.900 --> 00:02:06.780
that big room the big orange picture where we saw all of those little neurons that we were trying to

33
00:02:07.140 --> 00:02:09.350
kind of gauge how many there are there.

34
00:02:09.390 --> 00:02:11.670
There's millions of neurons in the brain.

35
00:02:12.570 --> 00:02:20.040
And then we've got the brain stem over here which connects the brain to the organs and heart arms and

36
00:02:20.040 --> 00:02:25.060
legs and so on and so that's how the brain.

37
00:02:25.070 --> 00:02:26.850
Oh those are the main three parts of the brain.

38
00:02:26.860 --> 00:02:31.080
Now the Siri broom has four lobes and they're colored in here.

39
00:02:31.090 --> 00:02:33.670
So it's got the frontal lobe.

40
00:02:33.670 --> 00:02:35.070
It's got the temporal lobe.

41
00:02:35.080 --> 00:02:39.340
It's got the parietal lobe and it's got the exceptional lobe and.

42
00:02:39.910 --> 00:02:41.470
Now how do we link these.

43
00:02:41.500 --> 00:02:41.740
Right.

44
00:02:41.740 --> 00:02:46.010
So we've got a and then we've already discussed CNN and Ireland.

45
00:02:46.180 --> 00:02:52.960
And the interesting with the horizontal probably was to start off with and then because what is the

46
00:02:52.960 --> 00:02:54.250
main advantage of it.

47
00:02:54.280 --> 00:02:59.740
Well the main advantage the main breakthrough in and ends is apart from the back propagation algorithm

48
00:02:59.740 --> 00:03:01.460
which kind of applies to all of them.

49
00:03:01.480 --> 00:03:05.730
And in fact whatever applies Gene and applies to everything here.

50
00:03:05.740 --> 00:03:14.470
But for me I think the main thing about an ends and it wouldn't even exist without thing saying this

51
00:03:14.470 --> 00:03:22.840
whole concept of deploring when you and exist are the weights the fact that a man's can learn through

52
00:03:22.900 --> 00:03:29.410
prior experience or through prior epochs and prior observations that's extremely valuable.

53
00:03:29.440 --> 00:03:32.740
And so what do those those weights represent.

54
00:03:32.740 --> 00:03:38.110
And moreover the weights of course are present across all neurons in the brain but we're going to try

55
00:03:38.110 --> 00:03:43.480
to take away the main philosophical underlying notion there and that is that weights represent long

56
00:03:43.480 --> 00:03:48.850
term memory that once you run you in an end and you've trained it you can switch it off you can come

57
00:03:48.850 --> 00:03:54.550
back later It's trained up you know the weights and so whatever inputs you put into it it will process

58
00:03:54.550 --> 00:03:59.290
it the same way as it would yesterday as it will tomorrow as it will the day after.

59
00:03:59.290 --> 00:04:05.860
So the weights are long term memory of a neural network and that's why weights or the airmen go into

60
00:04:05.860 --> 00:04:08.650
temporal lobe again and the weights exist across the whole brain.

61
00:04:08.650 --> 00:04:15.070
But philosophically and Ns are a start to deep learning and they represent long term memory.

62
00:04:15.070 --> 00:04:21.220
So we're going to put them in the temporal lobe because the temporal lobe lobe is responsible for long

63
00:04:21.220 --> 00:04:26.320
term memory Hence it's called the temporal lobe meaning it that lasts things lost through time in their

64
00:04:27.100 --> 00:04:31.090
brain is very complex and of course other parts also responsible for memory as well.

65
00:04:31.210 --> 00:04:37.630
But we're going to simplify things and say an ad is like the temporal lobe then CNN is much easier it's

66
00:04:37.630 --> 00:04:41.410
vision recognition of images and objects and so on.

67
00:04:41.410 --> 00:04:43.170
So that's a super low.

68
00:04:43.390 --> 00:04:49.480
And today we're talking about R and ends and as you'll find out R and ends are like short term memory

69
00:04:49.630 --> 00:04:55.300
they can remember things that just happened in the previous couple of observations and apply that knowledge

70
00:04:55.300 --> 00:04:56.580
in that going forward.

71
00:04:56.830 --> 00:04:58.980
Giving away so much already.

72
00:04:59.090 --> 00:05:01.060
You're right you're pretty much no there.

73
00:05:01.060 --> 00:05:03.630
So this tutorial but nevertheless.

74
00:05:03.760 --> 00:05:08.560
So that's the frontal lobe that's where we have a lot of the short term memory and of course the frontal

75
00:05:08.560 --> 00:05:14.770
lobe also like a quick breakdown of the frontal lobe also responds it's responsible for personality

76
00:05:14.770 --> 00:05:17.500
behavior motor cortex working memory.

77
00:05:17.910 --> 00:05:23.140
And like lots of other things but in our purposes the main thing that we're looking out for is the short

78
00:05:23.140 --> 00:05:25.810
term memory by the way if you're interested.

79
00:05:25.810 --> 00:05:31.150
Temporal lobe is the temporal lobe is concerned with cognition memory.

80
00:05:31.810 --> 00:05:38.560
That's our long term memory parietal lobe is and these are from wikipedia the parietal lobe is responsible

81
00:05:38.560 --> 00:05:45.370
for sensation and perception and constructing a spatial coordination system to represent the world around

82
00:05:45.370 --> 00:05:45.920
us.

83
00:05:46.210 --> 00:05:52.990
And we are yet to create a neural network which would fit into that category and occipital is vision.

84
00:05:52.990 --> 00:05:53.260
All right.

85
00:05:53.290 --> 00:06:00.050
So there we go a bit of neuroscience so let's move on to our favorite neural networks.

86
00:06:00.070 --> 00:06:04.260
So here we've got a simple artificial neural network three inputs to outputs one and there.

87
00:06:05.560 --> 00:06:07.570
What does a r an end do.

88
00:06:07.570 --> 00:06:11.710
How do we represent this as how do we represent or turn this into an R in it.

89
00:06:11.710 --> 00:06:14.860
Well we squash it we squash it all together.

90
00:06:14.890 --> 00:06:22.180
So there is still there but we think of it as if we're looking from underneath for from underneath this

91
00:06:23.530 --> 00:06:24.220
neural network.

92
00:06:24.220 --> 00:06:25.920
So we're looking at a new dimension.

93
00:06:25.930 --> 00:06:26.110
Right.

94
00:06:26.110 --> 00:06:29.650
So we're looking it's still there it's just flat enough.

95
00:06:29.680 --> 00:06:34.540
We're looking at it we're adding a new dimension to all of this but remember that those neurons the

96
00:06:34.540 --> 00:06:35.650
whole network is still there.

97
00:06:35.650 --> 00:06:36.260
Nothing change.

98
00:06:36.260 --> 00:06:41.560
We just a question for our purposes then to simplify things which is going to change these multiple

99
00:06:41.560 --> 00:06:42.360
hours into two.

100
00:06:42.370 --> 00:06:46.900
Then we're gonna twist this whole thing make it vertical because that's the standard representation

101
00:06:47.260 --> 00:06:49.990
then in terms of neural networks were going to color them instead of green.

102
00:06:49.990 --> 00:06:51.790
We're going to color the hidden layers in blue.

103
00:06:52.390 --> 00:06:54.690
And there we go and we're gonna add this line.

104
00:06:54.820 --> 00:06:56.530
And what does that line do.

105
00:06:56.530 --> 00:07:04.540
Well that line is the temporal loop and this is an old school representation of our ends and basically

106
00:07:04.540 --> 00:07:11.050
means that this hidden layer not only gives an output but also feeds back into itself.

107
00:07:11.050 --> 00:07:12.880
So again this is an optical representation.

108
00:07:12.880 --> 00:07:21.930
So the common kind of approach is now to unwind this or unroll this temporal loop and represent and

109
00:07:21.930 --> 00:07:27.350
ends in the following manner like that so you can see that again.

110
00:07:27.360 --> 00:07:31.220
Don't forget that we've got we've got lots of these things happening right.

111
00:07:31.230 --> 00:07:37.110
So you're looking in a new dimension that the layers are actually still there they're still there but

112
00:07:37.290 --> 00:07:38.830
we're just not focusing on them.

113
00:07:38.850 --> 00:07:44.450
We just remember that each one of these circles is not a one you're on it's a whole layer of neurons.

114
00:07:44.550 --> 00:07:48.750
And so what is happening is you've got inputs coming into the neurons.

115
00:07:48.750 --> 00:07:53.960
Then you've got outputs but also the neurons are connecting to themselves through time.

116
00:07:54.090 --> 00:07:59.880
So that's a whole concept that they have some sort of memory short term memory that they remember what

117
00:07:59.880 --> 00:08:02.280
was in that neuron just previously or.

118
00:08:02.940 --> 00:08:06.610
And then the one before they'd remember or before that it used to remember what was previous.

119
00:08:06.610 --> 00:08:14.940
And that allows them to pass information onto themselves in the future and analyze things kind of like

120
00:08:15.690 --> 00:08:17.640
when you're you know when you're watching this course.

121
00:08:17.640 --> 00:08:17.910
Right.

122
00:08:17.910 --> 00:08:24.150
So it would be very sad if you could not remember what was happening in the previous tutorial.

123
00:08:24.150 --> 00:08:24.360
Right.

124
00:08:24.360 --> 00:08:30.810
Even if we break time down discreetly through not by seconds but like continuously by seconds by discretely

125
00:08:30.810 --> 00:08:36.990
through tutorials and we say like every moment in time as a new tutorial it would be very sad if you

126
00:08:36.990 --> 00:08:41.460
did not remember what we had in the previous tutorial or in the previous section or in the previous

127
00:08:41.460 --> 00:08:42.480
part of the course.

128
00:08:42.510 --> 00:08:46.390
Right because then this whole new recurring neural networks part wouldn't makes any sense.

129
00:08:46.570 --> 00:08:50.550
You wouldn't have memory of what a neuron is what an activation function is.

130
00:08:50.640 --> 00:08:53.550
But because you do remember those things you can understand this.

131
00:08:53.550 --> 00:08:54.240
And same thing here.

132
00:08:54.240 --> 00:09:03.260
So how why would we deprive a artificial construct which is supposed to be a synthetic human brain or

133
00:09:03.320 --> 00:09:09.180
like mimicking the human brain why would be deprived of something so powerful as short term memory long

134
00:09:09.180 --> 00:09:14.160
term memory is great but short term memory is so powerful why would we not give it that opportunity

135
00:09:14.160 --> 00:09:16.410
and that's where recurrent neural networks come in.

136
00:09:16.410 --> 00:09:19.010
That's the gap that they fill it.

137
00:09:19.140 --> 00:09:20.840
And so let's have a look at a couple examples.

138
00:09:20.840 --> 00:09:27.870
So a huge shout out to the capacity blog capacity I'd get hub that I owe some of these examples from

139
00:09:27.870 --> 00:09:28.590
here.

140
00:09:28.590 --> 00:09:33.750
So one to many relationship this is when you have one input and have multiple outputs.

141
00:09:33.750 --> 00:09:41.240
Example of this is an image where a computer describes the image you have one input the image and that

142
00:09:41.250 --> 00:09:47.520
would go through a CNN and then would be fed into an R.A. and then the computer would come up with words

143
00:09:47.520 --> 00:09:48.290
to describe the image.

144
00:09:48.300 --> 00:09:51.810
And this is an actual computer describing image.

145
00:09:51.810 --> 00:09:54.780
How accurate is that black and white dog jumps over a bar.

146
00:09:54.780 --> 00:09:59.370
This is a computer looked at this image and it is like up it's a black and white dot based on what it's

147
00:09:59.370 --> 00:10:00.330
previously learned.

148
00:10:00.330 --> 00:10:09.390
You know the long term memory allowed it to come up with weights and come up with certain feature feature

149
00:10:09.510 --> 00:10:14.940
feature recognition system and come up with the filters come up with everything that is required in

150
00:10:14.940 --> 00:10:18.870
a CNN and then the orange and allows it to make sense out of the sentence.

151
00:10:18.870 --> 00:10:19.050
Right.

152
00:10:19.070 --> 00:10:26.520
So you can see that the sentence actually flows you know there's a there's an and there's a link over

153
00:10:26.520 --> 00:10:30.160
the bar and then there's like a verb there's a noun and so on.

154
00:10:30.160 --> 00:10:37.050
So basically it allows the irony is what allows it to put a sentence together in this case then a many

155
00:10:37.050 --> 00:10:37.980
to one word.

156
00:10:37.980 --> 00:10:40.620
An example would be a sentiment analysis.

157
00:10:40.620 --> 00:10:48.270
So when you have a lot of text and from that text you kind of need to gauge is it other people.

158
00:10:48.270 --> 00:10:52.680
Is this like a positive comment or is it a negative common what what's the chance that it's positive

159
00:10:52.680 --> 00:10:55.220
or how positive or how negative is that common.

160
00:10:55.290 --> 00:10:58.000
And you've got an example here as well.

161
00:10:58.020 --> 00:11:01.500
Again there's lots of other different examples these are just some.

162
00:11:01.500 --> 00:11:03.040
Then we've got many too many.

163
00:11:03.220 --> 00:11:05.660
For instance I wanted to show you this one.

164
00:11:06.450 --> 00:11:12.680
So here we've got an example of Google translator and I don't know if Google translator users are Anons

165
00:11:12.690 --> 00:11:13.050
or not.

166
00:11:13.050 --> 00:11:18.840
I know that they have very sophisticated deep learning and Google mind and I've heard that they've used

167
00:11:18.840 --> 00:11:21.450
that in their Android systems and so on.

168
00:11:21.450 --> 00:11:23.210
I'm not sure if they use our hands here or not.

169
00:11:23.220 --> 00:11:24.990
But the concept through remains.

170
00:11:25.020 --> 00:11:33.180
So if I say here from English to check I say I am a boy who likes to learn a Sam look to gratitude.

171
00:11:33.260 --> 00:11:33.560
Right.

172
00:11:33.570 --> 00:11:42.090
And basically in other languages in some other languages it is important what's gender you're a person

173
00:11:42.090 --> 00:11:42.300
is.

174
00:11:42.300 --> 00:11:42.510
Right.

175
00:11:42.510 --> 00:11:43.890
So here a boy is male.

176
00:11:43.890 --> 00:11:45.870
So that's why he's got category.

177
00:11:45.870 --> 00:11:46.670
Right.

178
00:11:46.680 --> 00:11:54.390
And if you see if I change this to girl in English the other words don't change but in check the other

179
00:11:54.390 --> 00:11:56.530
words change you Sam Holcomb.

180
00:11:56.560 --> 00:12:00.380
Tara a rather sell it so you can see right away.

181
00:12:00.390 --> 00:12:03.410
Now it's not a theory right.

182
00:12:03.420 --> 00:12:10.650
It's Tara meaning that these words they depend on the gender of this word Hawker and a whole car is

183
00:12:10.650 --> 00:12:13.540
a girl and therefore this becomes Tara rather.

184
00:12:13.540 --> 00:12:21.300
And again I don't know if Google Translate is our friend and I'm going to comment on that but basically

185
00:12:21.300 --> 00:12:28.420
the concept is the same that you need short term information about the previous word in order to translate

186
00:12:28.420 --> 00:12:29.210
the next word right.

187
00:12:29.230 --> 00:12:31.730
You can't just translate word by word.

188
00:12:31.790 --> 00:12:32.770
It's just a simple example.

189
00:12:32.770 --> 00:12:36.750
Of course like it makes to make a sentence makes sense.

190
00:12:36.760 --> 00:12:41.920
You didn't do need a information about the prisoners but like a very visual example we have here is

191
00:12:41.980 --> 00:12:48.970
at the at the least you need to know the gender of this word to in order to translate the following

192
00:12:48.970 --> 00:12:54.850
words for the sentence to make sense and that's where our own ends have power because they have short

193
00:12:54.850 --> 00:12:58.110
term memory and they can do these things.

194
00:12:58.180 --> 00:13:01.900
So there we go that's a many to many you put in lots of words and then you get lots of words out that

195
00:13:01.910 --> 00:13:06.730
translation and of course not every example has to be related to text or images.

196
00:13:06.730 --> 00:13:11.320
There can be lots and lots of different implications of our nouns for instance many many you can use

197
00:13:11.320 --> 00:13:14.070
our own ends to subtitle movies.

198
00:13:14.140 --> 00:13:21.350
Meaning that you can have running subtitles so basically or describe every single frame in a movie and

199
00:13:21.670 --> 00:13:27.130
that is something you can simply do with a CNN or other neural networks because if you're watching a

200
00:13:27.130 --> 00:13:32.710
movie you need context about what happened previously to describe what's happening now and so you need

201
00:13:32.710 --> 00:13:33.790
that short term memory.

202
00:13:33.790 --> 00:13:39.300
You can't just run through a million movies and kind of understand the whole plot that is going to happen

203
00:13:39.310 --> 00:13:44.710
you need short term memory of the plot to be able to comment on every single frame.

204
00:13:44.710 --> 00:13:48.370
And speaking of movies today we don't have additional reading to do.

205
00:13:48.370 --> 00:13:57.170
We have additional watching so a movie called some spring in 2016 directed by Oscar Sharpe and Scott.

206
00:13:57.190 --> 00:14:02.800
You might know this actor Thomas middle age from TV show Silicon Valley and this movie was entirely

207
00:14:02.800 --> 00:14:10.540
written by Benjamin who is a Arnon and Ellis team to be specific so I'm going to show you this movie

208
00:14:10.570 --> 00:14:12.240
now.

209
00:14:12.940 --> 00:14:13.740
Well I'm not gonna play it.

210
00:14:13.750 --> 00:14:16.350
I'm doing a show which find it so unique because Ars Technica.

211
00:14:16.390 --> 00:14:17.620
It's only nine minutes long.

212
00:14:17.620 --> 00:14:18.670
I highly recommend it.

213
00:14:18.670 --> 00:14:19.990
I've seen it twice.

214
00:14:19.990 --> 00:14:21.520
It's so it's so fun.

215
00:14:21.530 --> 00:14:24.970
Like you will find that a couple of things.

216
00:14:24.990 --> 00:14:28.960
There's a great description here as well so it's worth reading through it there's actually an interview

217
00:14:29.000 --> 00:14:31.600
Benjamin and he actually gave himself the name of Benjamin.

218
00:14:31.600 --> 00:14:33.310
That's where they call him Benjamin.

219
00:14:33.310 --> 00:14:40.120
Is this really cool to see these things and what you'll find about the movie is the acting is amazing

220
00:14:40.120 --> 00:14:48.760
just amazing like I had shivers down my spine towards and it got in the top 10 in London in the Loddon

221
00:14:48.760 --> 00:14:55.870
sci fi in the sci fi London Festival and then what you'll find is that Benjamin is able to construct

222
00:14:55.870 --> 00:15:02.440
sentences which kind of like makes sense for the most part which is good but what he lacks is kind of

223
00:15:02.440 --> 00:15:08.940
the bigger picture where he cannot come up with like a plot that constantly makes sense even though

224
00:15:09.040 --> 00:15:14.140
even though the actors do a great job about putting it together and it does look amazing in the end

225
00:15:14.410 --> 00:15:19.540
but you will notice and kind of look out for this separate when you're watching separate the sentences

226
00:15:19.630 --> 00:15:24.240
and you'll see that each sentence on its own more or less 90 percent the time makes sense.

227
00:15:24.280 --> 00:15:29.680
But overall he cannot properly link sentence together and that's that's the next step for iron ends

228
00:15:29.680 --> 00:15:34.900
where you know this is still quite a new technology or it's only picking up recently so it'll be developed

229
00:15:34.900 --> 00:15:40.030
very soon and maybe when you're watching this tutorial you're laughing in then in the future five years

230
00:15:40.030 --> 00:15:44.080
from now you're laughing to yourself and you're saying oh oh we've already passed that milestone and

231
00:15:44.080 --> 00:15:49.450
probably we will very soon but this is where things are now and highly recommend checking this out only

232
00:15:49.450 --> 00:15:50.380
nine minutes long.

233
00:15:51.550 --> 00:15:52.050
So there we go.

234
00:15:52.050 --> 00:15:53.360
That's what our ends are.

235
00:15:53.380 --> 00:15:58.600
In a nutshell and in the next trial we will continue digging deeper.

236
00:15:58.600 --> 00:15:59.700
I look forward to seeing next time.

237
00:15:59.710 --> 00:16:01.210
Until then enjoy deep learning.
