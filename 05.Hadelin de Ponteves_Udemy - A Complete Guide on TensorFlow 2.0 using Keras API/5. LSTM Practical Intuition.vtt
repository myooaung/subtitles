WEBVTT
1
00:00:00.750 --> 00:00:03.660
Hello and welcome back to the course on deep learning.

2
00:00:03.660 --> 00:00:08.520
Now that we know a bit more about Ellis teams and how they work and what their architecture is like

3
00:00:08.520 --> 00:00:15.120
today we're going to look at some practical applications or specifically you're going to look at how

4
00:00:15.120 --> 00:00:21.840
Ellis teams work inside practical applications and it's quite interesting and at the same time a bit

5
00:00:21.840 --> 00:00:22.800
magical I would say.

6
00:00:22.800 --> 00:00:31.350
So let's get started here we've got the Ellis Elysium architecture and we're going to be to start off

7
00:00:31.350 --> 00:00:41.160
we're going to be looking at this tangent function and how it fires up so according to some of the images

8
00:00:41.160 --> 00:00:45.780
were going to be using are all from Andrew Card parties blog.

9
00:00:45.780 --> 00:00:51.840
So thank you very much to Andrei for doing all of this amazing research so you can see here.

10
00:00:51.840 --> 00:00:53.460
It's just incredible.

11
00:00:53.610 --> 00:00:59.850
They've got some examples where they've created some bogus linear algebra using trained up Alice teams

12
00:01:00.330 --> 00:01:03.450
and then lots and lots of stuff.

13
00:01:03.450 --> 00:01:08.250
So here these are the images we're going to be looking at just now these ones as well.

14
00:01:08.250 --> 00:01:12.330
And there's lots of information here lots of comments so definitely check it out.

15
00:01:12.330 --> 00:01:16.730
We'll link to these at the end of the tutorial.

16
00:01:16.740 --> 00:01:20.270
This blog is called unreasonable effectiveness of recurrent neural networks.

17
00:01:20.430 --> 00:01:27.030
And the paper that Andrew published along with that will also linked to that paper as well.

18
00:01:27.030 --> 00:01:33.360
So basically bill again this tangent function to start off with and according to the paper minus one

19
00:01:33.750 --> 00:01:37.100
means is going to be read plus one is going to be blue.

20
00:01:37.110 --> 00:01:39.270
So let's get started.

21
00:01:39.270 --> 00:01:39.600
All right.

22
00:01:39.630 --> 00:01:47.670
So here is some text which was given to an hour and then which learned to read text and kind of create

23
00:01:47.670 --> 00:01:50.100
text and predict what text is coming.

24
00:01:50.130 --> 00:01:55.180
And here this is a snippet from the No.

25
00:01:55.230 --> 00:01:56.610
War and Peace.

26
00:01:56.820 --> 00:02:01.050
The huge novel by Tolstoy.

27
00:02:01.200 --> 00:02:05.980
And so here you can see that this neuron is activating.

28
00:02:06.150 --> 00:02:09.360
Well it is sensitive to as it says here is sensitive to position and light.

29
00:02:09.360 --> 00:02:13.500
So you can see that when you get towards the end of the line it's activating and how does it know when

30
00:02:13.800 --> 00:02:14.520
it's the end of the line.

31
00:02:14.520 --> 00:02:23.520
Well in this novel you have about 80 symbols per line approximately.

32
00:02:23.520 --> 00:02:28.500
So it's counting how many symbols have passed and that way it's trying to predict when the new line

33
00:02:28.500 --> 00:02:32.240
character is coming up because the new line New Line is a just a character.

34
00:02:32.350 --> 00:02:36.810
It's an invisible character and it's trying to predict where that character is going to appear.

35
00:02:36.810 --> 00:02:39.660
Then you've got a cell that turns on inside quotes.

36
00:02:39.780 --> 00:02:44.910
Well this is inside because I think it's actually outside quotes because here you see it says You mean

37
00:02:44.910 --> 00:02:47.670
to imply that I have nothing to eat out of.

38
00:02:47.670 --> 00:02:49.460
On the contrary I can supply.

39
00:02:49.470 --> 00:02:53.200
So basically somebody is talking and then warmly replied Chicago.

40
00:02:53.560 --> 00:03:03.030
She Shug of Chicago of having read that in a long time who tried to buy who tried by every word.

41
00:03:03.030 --> 00:03:07.620
So basically this is the inside the quotes is outside the quotes I'm not sure if this is correct but

42
00:03:08.580 --> 00:03:13.110
in either case one way or another it's activating either inside the quotes or outside the quotes and

43
00:03:13.440 --> 00:03:17.790
you can see so this one is keeping track of what's happening and so very similar to what we discussed

44
00:03:17.790 --> 00:03:25.740
previously where we were keeping track of the subject when that would help us understand if the subject

45
00:03:25.740 --> 00:03:31.500
is male or female or we would be able to understand things like if it's a singular or plural and that

46
00:03:31.500 --> 00:03:34.260
would affect our verbs in our translation similar thing.

47
00:03:34.260 --> 00:03:40.080
So it's important to know if you're inside or outside of course because that affects the rest of the

48
00:03:40.080 --> 00:03:40.520
text.

49
00:03:40.530 --> 00:03:45.870
And for instance the easiest way you can think of that effects text that if you're inside the quotes

50
00:03:45.900 --> 00:03:48.090
then there has to be another quote to close the quote.

51
00:03:48.090 --> 00:03:57.420
So you're anticipating another quote something that here's another one where the the what the input

52
00:03:57.420 --> 00:04:01.680
was the code of the Linux operating system.

53
00:04:01.680 --> 00:04:07.950
And here you can see that a cell activates inside if statement.

54
00:04:07.950 --> 00:04:13.770
So it's completely dormant everywhere else but as soon as you have an if statement it activates if statement

55
00:04:13.770 --> 00:04:15.790
it activates if statement it activates.

56
00:04:15.960 --> 00:04:25.260
So and if it is active you can see it stops being active over here at the next at the actual body of

57
00:04:25.260 --> 00:04:31.430
the if statement so it's only active for the main part or for the condition of the if statement and

58
00:04:32.030 --> 00:04:38.130
you know that that can be important because you are anticipating that the condition is going to close

59
00:04:38.130 --> 00:04:40.050
if a bracket and then is to be a bracket.

60
00:04:40.050 --> 00:04:44.300
Curly brace to open up the body of the if statement.

61
00:04:44.340 --> 00:04:50.970
That's pretty cool and then here you've got another one where this sensitive this cell is sensitive

62
00:04:50.970 --> 00:04:54.010
to how deep you are inside of a nested expression.

63
00:04:55.130 --> 00:04:59.640
So as you go deeper and you get the expression is more and more nested.

64
00:04:59.720 --> 00:05:06.380
This cell keeps track of that so it's using this memory to keep trying and it's very important to remember

65
00:05:06.380 --> 00:05:11.690
that none of this is actually hardcoded into the neural network.

66
00:05:11.690 --> 00:05:14.380
All of this is learned by the network itself.

67
00:05:14.380 --> 00:05:16.900
There are thousands and thousands thousands of iterations.

68
00:05:17.120 --> 00:05:18.580
It learns.

69
00:05:18.630 --> 00:05:19.960
That's okay.

70
00:05:20.000 --> 00:05:23.290
I have this many hidden states I have.

71
00:05:23.480 --> 00:05:29.270
And out of them I need to identify what's important in the text to keep track of and identifies for

72
00:05:29.270 --> 00:05:31.230
instance in this case that it has.

73
00:05:31.280 --> 00:05:40.010
That's being understanding how deep you are inside a that statement is important and therefore it assigns

74
00:05:40.340 --> 00:05:43.400
a one of its hidden states to keep track of that.

75
00:05:43.710 --> 00:05:52.820
So it has these resources hidden states or the actual memory cells and it assigns them to keep track

76
00:05:52.820 --> 00:05:55.190
of certain things based on what it thinks is important.

77
00:05:55.190 --> 00:06:01.010
So it's like it's really evolving like that on its own and deciding what's important what's not and

78
00:06:01.100 --> 00:06:03.980
how to allocate its resources to best complete the task.

79
00:06:04.010 --> 00:06:07.190
I think that's very fascinating.

80
00:06:07.550 --> 00:06:11.700
And then here's an example of a cell that you can really understand what it's doing.

81
00:06:11.720 --> 00:06:16.810
And according to Andrew capacity about 95 percent of the cells are like this.

82
00:06:16.800 --> 00:06:22.130
They're they're doing something but there's just not not obvious to us what is happening.

83
00:06:22.130 --> 00:06:29.160
And it's like that example of CNN's where the filters or the features that we're looking out for there.

84
00:06:29.300 --> 00:06:34.100
By the time they get to the last layer they're completely unrecognizable to the human eye but they make

85
00:06:34.100 --> 00:06:34.970
sense to the machine.

86
00:06:34.970 --> 00:06:35.570
Same thing here.

87
00:06:35.570 --> 00:06:39.740
So most of the time native apps on time you can't really tell what's going on.

88
00:06:39.770 --> 00:06:45.920
But those folks at the time those were exams so we've looked at and they should be helpful to better

89
00:06:45.920 --> 00:06:54.160
understand what is kind of going on in in the neural network when it's processing for instance text.

90
00:06:54.830 --> 00:06:59.150
So again now we're back at our architecture.

91
00:06:59.150 --> 00:07:04.760
And now what we're going to be looking at is that we're going to be looking at the actual output.

92
00:07:04.790 --> 00:07:06.670
So we're going to be looking at this value.

93
00:07:06.700 --> 00:07:12.710
So after it's gone through the tangent the R evolve or the output gate and now we're going to be looking

94
00:07:12.710 --> 00:07:14.890
at what's being produced over here.

95
00:07:14.990 --> 00:07:23.180
So here's an example again from Carpathians or under a Carpathians blog and we're looking at a neural

96
00:07:23.270 --> 00:07:25.100
network that is reading.

97
00:07:25.130 --> 00:07:27.890
So this is a bit this is a bit more detail.

98
00:07:27.890 --> 00:07:31.650
So here it's not just showing us if it's active or not.

99
00:07:31.850 --> 00:07:35.720
You can see that you've got at the top if it's active or not.

100
00:07:35.810 --> 00:07:44.290
Every first line and then another five lines it is saying what's the neural network is predicting that's

101
00:07:44.300 --> 00:07:45.460
going to happen next.

102
00:07:45.470 --> 00:07:48.200
What letter is going to come next what symbol is going to come next.

103
00:07:48.440 --> 00:07:52.180
So you've got the combination of the two here and just by looking at this word.

104
00:07:52.300 --> 00:07:53.600
What do you think is predicting.

105
00:07:53.600 --> 00:08:00.200
So I'm going to I'm going to outline the colors green means for the top line.

106
00:08:00.200 --> 00:08:05.930
Green means active and blue means not active and red means a very likely prediction.

107
00:08:05.990 --> 00:08:08.200
And later red means unlikely prediction.

108
00:08:08.210 --> 00:08:10.780
So let's talk about the top line.

109
00:08:10.790 --> 00:08:16.580
What do you think this specific hidden state in the neural network is looking out for when do you think

110
00:08:16.580 --> 00:08:17.660
it's been activated.

111
00:08:17.660 --> 00:08:19.280
Well I guess this one is pretty obvious.

112
00:08:19.280 --> 00:08:21.830
It's activating inside your cells.

113
00:08:21.860 --> 00:08:29.450
So here you can see that inside w w w the hidden state is is being activated just like we saw in the

114
00:08:29.450 --> 00:08:36.710
previous examples foreign piece and the Linux kernel here you can see that it's been it's activated

115
00:08:36.800 --> 00:08:41.750
inside your else but now we have some additional stuff to look at.

116
00:08:41.750 --> 00:08:45.140
Now we can see what it's actually predicting that's going to be the next character.

117
00:08:45.140 --> 00:08:51.170
So for instance under this w you can see that it's predicting that the next character is going to be

118
00:08:51.170 --> 00:08:57.680
a W of the highest probability and it's correct it is a W then under this w you can see that it's predicting

119
00:08:57.680 --> 00:08:59.670
another W and it is correct.

120
00:08:59.810 --> 00:09:03.870
And then under this w the whole this is what the whole neural network is predicting.

121
00:09:05.440 --> 00:09:06.990
Under this W..

122
00:09:07.180 --> 00:09:11.070
What you are seeing is a dot and that is correct.

123
00:09:11.080 --> 00:09:11.940
It is predicted.

124
00:09:11.980 --> 00:09:19.960
So that's that's how it's gone up to here and then after this dot it it thinks the next let a letter

125
00:09:19.960 --> 00:09:21.480
be will be a B but it's actually a Y.

126
00:09:21.510 --> 00:09:25.870
But now knowing that it's a y it thinks they're going to be in a now knowing it's an AIDS thing is going

127
00:09:25.870 --> 00:09:32.320
to be and you can see that these are less these are not as red as these because it's not sure about

128
00:09:32.320 --> 00:09:33.580
this prediction that's fair enough.

129
00:09:33.580 --> 00:09:35.170
It could be absolutely any website.

130
00:09:35.170 --> 00:09:37.640
Why would it be a B could be in any upside.

131
00:09:37.750 --> 00:09:38.480
You can't tell.

132
00:09:38.770 --> 00:09:39.490
Maybe it could.

133
00:09:39.490 --> 00:09:41.990
Based on the context but still it's very hard.

134
00:09:42.960 --> 00:09:50.670
But then when it gets to Y NET new and e w it predicts and S with a very high likelihood and it is indeed

135
00:09:50.670 --> 00:09:56.940
and has because it kind of knows that the word after you have new very likely you will have an S or

136
00:09:56.940 --> 00:09:59.320
based on everything it's learned before.

137
00:09:59.400 --> 00:10:01.490
That's in this particular type of tax.

138
00:10:01.620 --> 00:10:08.220
It's news is mentioned quite often because this is actually as far as I understand this is Wikipedia.

139
00:10:08.230 --> 00:10:15.910
Tax and then you have a dot then after a dot it predicts c it is a C after a C predicts an O.

140
00:10:16.510 --> 00:10:22.050
It's an O after an old predicts an M It is an M and then slash and is a slash so beautiful.

141
00:10:22.060 --> 00:10:25.640
So and then it's done its job and it's not active anymore.

142
00:10:26.140 --> 00:10:28.750
And then this is what this is.

143
00:10:28.790 --> 00:10:32.590
The neuron that we're looking at is not active on anymore but the neural network is still predicting

144
00:10:32.620 --> 00:10:32.880
things.

145
00:10:32.880 --> 00:10:36.210
So here you can see E and then and so it's incorrect.

146
00:10:36.220 --> 00:10:42.460
And then after the N O after the is incorrect after n after has e n it predicts a G It's a G and then

147
00:10:42.460 --> 00:10:47.200
it becomes more confident that its the word English language you can see that the predictions become

148
00:10:47.200 --> 00:10:47.820
more confident.

149
00:10:47.830 --> 00:10:54.400
So after the l didn't predict correctly but after the L.A. it's really predicting and G and so on and

150
00:10:54.400 --> 00:10:59.320
so on so on so it can actually predict the whole world based on just a few first letters websites on

151
00:10:59.350 --> 00:11:05.860
and so on to see the actual neuron is still dormant still dormant and then here you've got again off

152
00:11:05.860 --> 00:11:06.160
we go.

153
00:11:06.160 --> 00:11:09.910
W w w it's predicting and this one is getting activated.

154
00:11:09.910 --> 00:11:15.490
This one was pretty interesting because it goes C O and then Prince and M but it's not an M It's a dot

155
00:11:16.090 --> 00:11:20.170
and it's like the neural network or this.

156
00:11:20.320 --> 00:11:26.080
Oh yeah there's the neural network is probably a bit upset at this stage thinking well where's my M

157
00:11:26.410 --> 00:11:33.700
and then then it takes another shot it says okay so probably you because dot com dot uk that's that's

158
00:11:33.700 --> 00:11:42.580
the UK website but here instead of a U is got an eye and an L for Israel.

159
00:11:42.580 --> 00:11:49.240
That code that I L and therefore it kind of like didn't guess this though but its problem is it's not

160
00:11:49.240 --> 00:11:53.530
even trying to guess you can see it's only been trying to guess an I because from what it's learned

161
00:11:53.740 --> 00:12:00.520
that code that UK are made much more likely to come up then dot dot L and we're not even looking at

162
00:12:00.520 --> 00:12:04.470
these other ones here which you could look at them.

163
00:12:04.780 --> 00:12:09.400
They are the second best guess the third best guess fourth and fifth which you can see that they're

164
00:12:09.400 --> 00:12:18.550
not that red and that it would it will always put the highest likeliest guests at the top on the second

165
00:12:18.550 --> 00:12:20.470
line overall.

166
00:12:20.470 --> 00:12:20.920
So there we go.

167
00:12:20.920 --> 00:12:26.700
This is how to look at these pictures that Andrei has created and for more.

168
00:12:26.740 --> 00:12:31.840
Check out his blog Carpathia dot get hub dot I O there's a couple more of these examples there and more

169
00:12:31.840 --> 00:12:34.270
of the previous examples I looked at.

170
00:12:35.290 --> 00:12:43.330
And yeah so hopefully this is helpful to show you what's going on inside the neural network when it's

171
00:12:43.390 --> 00:12:50.050
when it's thinking and when it's processing information in terms of references and additional reading

172
00:12:50.170 --> 00:12:57.020
we've got and undertaker party blog and will link to it in the resources for this course.

173
00:12:57.280 --> 00:13:06.970
This is this is the URL otherwise and also we've got the Drake our party and others research paper which

174
00:13:07.090 --> 00:13:09.100
was published in 2015.

175
00:13:09.100 --> 00:13:12.970
It's called visualizing and understanding recurrent networks.

176
00:13:12.970 --> 00:13:20.140
Very interesting read actually because though like if if you're there's not too much math then you can

177
00:13:20.140 --> 00:13:20.910
probably skip it.

178
00:13:20.920 --> 00:13:29.320
But even the insights pirates and chapters are very interesting they make you kind of feel that they

179
00:13:29.590 --> 00:13:33.750
and they say this in the paper that they like neuroscientists trying to understand what's going on.

180
00:13:33.750 --> 00:13:40.290
So they open up the brain of the neural network and monitor what's happening in one specific neuron

181
00:13:40.290 --> 00:13:43.920
on or other or different or different neurons.

182
00:13:43.930 --> 00:13:51.130
And and you actually feel from the language the way that it's written that it's as if they're exploring

183
00:13:51.130 --> 00:13:57.220
some alien as if they're exploring some kind of extraterrestrial being and how it thinks.

184
00:13:57.220 --> 00:14:02.980
Because if you think about it humans created these LSD Amazon are announced these are just things that

185
00:14:02.980 --> 00:14:10.510
work on our computers but because they are so advanced because they involve so many different elements

186
00:14:10.510 --> 00:14:17.920
so many different parts to them and they are so complex we now need to after we've created them now

187
00:14:17.920 --> 00:14:24.760
we need to study them as if they're separate beings separate something something that exists on its

188
00:14:24.790 --> 00:14:31.600
own and it's just reading through it kind of like if you think of it that way it gives you this mysterious

189
00:14:31.600 --> 00:14:35.500
feeling or magic if you feel like it's something magical is happening at the same time you feel that

190
00:14:35.860 --> 00:14:38.800
fume few more years or maybe a decade from now.

191
00:14:39.010 --> 00:14:41.730
These things are going to be able to think completely on their own.

192
00:14:41.830 --> 00:14:49.210
So if if you want to have some fun reading a research paper This one's pretty cool I think maybe you

193
00:14:49.210 --> 00:14:54.660
know you don't have to read them off skip the math and really dig into the math myself.

194
00:14:55.060 --> 00:14:55.320
Yeah.

195
00:14:55.350 --> 00:14:57.030
So that's pretty much it.

196
00:14:57.030 --> 00:15:02.490
Hope you enjoyed today's tutorial and hopefully that gives you a bit of a better understanding of how

197
00:15:02.880 --> 00:15:06.660
the architecture actually plays out in practice.

198
00:15:06.660 --> 00:15:08.250
And I look forward to seeing you next time.

199
00:15:08.250 --> 00:15:09.840
Until then enjoy deep learning.
