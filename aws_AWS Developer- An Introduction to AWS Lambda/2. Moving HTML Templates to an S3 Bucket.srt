1
00:00:01,550 --> 00:00:05,180
In this demo, we'll need to spend a little bit of extra time preparing things

2
00:00:05,180 --> 00:00:07,970
before we can get started creating our function package.

3
00:00:07,970 --> 00:00:12,050
We'll add some HTML templates to S3 using the Command Line Interface,

4
00:00:12,050 --> 00:00:15,700
and then we'll verify some emails with the Simple Email Service.

5
00:00:15,700 --> 00:00:16,560
After that,

6
00:00:16,560 --> 00:00:20,230
we'll review the cuckoo.py file that contains all of our

7
00:00:20,230 --> 00:00:24,070
function code. Then, we'll create an IAM role that we can

8
00:00:24,070 --> 00:00:25,820
then assign to our Lambda function,

9
00:00:25,820 --> 00:00:28,290
and that'll have to have all the permissions that we need to

10
00:00:28,290 --> 00:00:31,190
access S3 and the Simple Email Service.

11
00:00:31,190 --> 00:00:34,830
From there, we'll go about creating our Lambda function. We'll

12
00:00:34,830 --> 00:00:37,870
install Jinja2 and then test out our code.

13
00:00:37,870 --> 00:00:42,560
Then we'll run the setup.sh script to create our package.zip file, and

14
00:00:42,560 --> 00:00:46,550
then we use the AWS CLI to create our function and also setup

15
00:00:46,550 --> 00:00:49,410
everything else to trigger our function and have it run at a

16
00:00:49,410 --> 00:00:52,340
particular time of day throughout the week.

17
00:00:52,340 --> 00:00:55,550
So let's get started. Over here in my terminal,

18
00:00:55,550 --> 00:00:58,440
I've gone ahead and loaded up all the code for this demo.

19
00:00:58,440 --> 00:01:00,770
You can get this from the downloads for this course.

20
00:01:00,770 --> 00:01:05,590
Just look for the cuckoo folder inside of the module files for this course.

21
00:01:05,590 --> 00:01:08,710
Then go ahead and open up the cuckoo.py file.

22
00:01:08,710 --> 00:01:10,680
I'm not going to look through the whole thing right now,

23
00:01:10,680 --> 00:01:15,180
but one important thing that you'll need to change will be down here on line 33.

24
00:01:15,180 --> 00:01:17,550
This will be the S3 bucket that you're creating,

25
00:01:17,550 --> 00:01:21,220
and I'll show you how to do that right now. Inside of my command line,

26
00:01:21,220 --> 00:01:26,330
I'm going to run aws s3 and then mb, for make bucket.

27
00:01:26,330 --> 00:01:29,550
Then I'm going to specify the syntax for creating an S3 bucket,

28
00:01:29,550 --> 00:01:35,150
which starts with s3://, and then we'll give this bucket a name.

29
00:01:35,150 --> 00:01:37,540
Now, I want to make my bucket match what I have in my

30
00:01:37,540 --> 00:01:42,180
cuckoo.py file, so I'm going to go gpc, for Globomantics Pet

31
00:01:42,180 --> 00:01:45,690
Care, ‑email and then ‑templates.

32
00:01:45,690 --> 00:01:45,910
Now,

33
00:01:45,910 --> 00:01:49,680
one thing I want to distinguish here is that this bucket is globally

34
00:01:49,680 --> 00:01:53,170
unique across AWS accounts, so you're not going to be able to create a

35
00:01:53,170 --> 00:01:56,520
bucket with the same name. So keep that in mind. You're going to have to

36
00:01:56,520 --> 00:02:02,080
go into this file in cuckoo.py and change the value of TEMPLATE_S3_BUCKET

37
00:02:02,080 --> 00:02:04,190
to whatever you name your bucket.

38
00:02:04,190 --> 00:02:06,740
In order to make sure that this command has been successful,

39
00:02:06,740 --> 00:02:10,550
you can then run aws s3 ls, for list,

40
00:02:10,550 --> 00:02:12,420
and this will tell you all the buckets that you

41
00:02:12,420 --> 00:02:15,180
have created in your AWS account.

42
00:02:15,180 --> 00:02:16,230
Now, from here,

43
00:02:16,230 --> 00:02:19,420
you can move all the contents of your templates into

44
00:02:19,420 --> 00:02:21,660
the S3 bucket you just created.

45
00:02:21,660 --> 00:02:21,790
Now,

46
00:02:21,790 --> 00:02:25,420
keep in mind that from now on you'll need to replace GPC email

47
00:02:25,420 --> 00:02:29,140
templates with whatever the name of your bucket is.

48
00:02:29,140 --> 00:02:31,750
Now, if you want help going through each of these commands,

49
00:02:31,750 --> 00:02:36,360
I have a commands_help.txt file that should explain everything I'm doing

50
00:02:36,360 --> 00:02:40,340
throughout this demo, step‑by‑step, and all of the commands associated with

51
00:02:40,340 --> 00:02:43,560
it. It'll also give you notes on when to replace things, like the

52
00:02:43,560 --> 00:02:47,330
TEMPLATE_S3_BUCKET value, inside of your commands.

53
00:02:47,330 --> 00:02:49,930
So you can use that as a cheat sheet from here on out.

54
00:02:49,930 --> 00:02:54,245
So now that I know this bucket has been created when I ran aws s3 ls,

55
00:02:54,245 --> 00:03:00,400
we can run aws S3 cp, for copy, and then I'll need to specify where I

56
00:03:00,400 --> 00:03:03,250
want the objects copied from. In this case,

57
00:03:03,250 --> 00:03:07,700
I want to specify ./templates because I want everything inside of

58
00:03:07,700 --> 00:03:11,300
this templates directory to be copied into S3.

59
00:03:11,300 --> 00:03:12,250
Specifically,

60
00:03:12,250 --> 00:03:17,060
I want the come_to_work and the daily_tasks and the pickup files all to be

61
00:03:17,060 --> 00:03:22,040
moved into S3 to be used as email templates. The license and the notice here

62
00:03:22,040 --> 00:03:25,930
I've included because these email templates are open source, and I'm required

63
00:03:25,930 --> 00:03:28,470
to buy their license. Now from here,

64
00:03:28,470 --> 00:03:32,820
after typing the aws s3 cp command and entering in the location of

65
00:03:32,820 --> 00:03:36,520
everything we need, now we can enter where we want this to go.

66
00:03:36,520 --> 00:03:37,030
In this case,

67
00:03:37,030 --> 00:03:43,000
we'll need to start with s3:// to specify we want this to go into an S3 bucket.

68
00:03:43,000 --> 00:03:44,770
Then we'll have to give the name of the bucket,

69
00:03:44,770 --> 00:03:48,940
which in this case is gpc‑email‑templates.

70
00:03:48,940 --> 00:03:50,230
Now, after we type that out,

71
00:03:50,230 --> 00:03:54,190
we can just say that we want this to recursively copy everything in the

72
00:03:54,190 --> 00:04:00,650
templates folder, and we'll do this with the ‑‑recursive flag here.

73
00:04:00,650 --> 00:04:03,280
So now I can hit Enter and see this process copy

74
00:04:03,280 --> 00:04:06,400
everything in templates into my S3 bucket.

75
00:04:06,400 --> 00:04:08,830
Now, if I wanted to check if this process had worked,

76
00:04:08,830 --> 00:04:13,310
I could run the aws s3 ls command and then specify the name of the

77
00:04:13,310 --> 00:04:16,110
bucket that I wanted to see inside of; in this case,

78
00:04:16,110 --> 00:04:19,420
gpc‑email‑templates.

79
00:04:19,420 --> 00:04:20,540
Now I can hit Enter,

80
00:04:20,540 --> 00:04:24,280
and I'll see all the different objects that I just uploaded into S3.

81
00:04:24,280 --> 00:04:32,000
So this is exactly what we want, and now we can go back into the AWS Console and configure SES.

