WEBVTT
1

00:00:00.750  -->  00:00:03.020
Hello and welcome back to the course on machine learning.

2

00:00:03.090  -->  00:00:05.800
Today we're talking about the polynomial regression.

3

00:00:06.030  -->  00:00:07.800
So let's get straight into it.

4

00:00:07.830  -->  00:00:11.700
We already know a couple of types of regressions we know the simple thing or aggression which we can

5

00:00:11.700  -->  00:00:12.500
see over here.

6

00:00:12.720  -->  00:00:17.680
There have also discussed the multiple linear regression which is written out over here.

7

00:00:18.000  -->  00:00:22.120
And finally we've got the polynomial linear regression which is recent out here.

8

00:00:22.260  -->  00:00:28.130
So notice how it's very similar to the multiple linear regression but at the same time instead of the

9

00:00:28.130  -->  00:00:36.990
different variables like x 2 x 3 x 4 and so on X and we have the same variable x 1 but it is in a different

10

00:00:37.050  -->  00:00:37.470
power.

11

00:00:37.470  -->  00:00:42.380
So instead of X to have x 1 squared instead of x 3 we would have x 1 cube.

12

00:00:42.660  -->  00:00:45.590
And so instead of X and we would have x 1 to power.

13

00:00:45.630  -->  00:00:51.440
And so basically we're using one variable but we're using the different powers of that bear.

14

00:00:51.630  -->  00:00:55.900
So let's have a look at when you'd use a polynomial regression when it would come in handy.

15

00:00:56.250  -->  00:01:03.360
Let's say you've got a observation a set of directions which are abs then the line that fits this data

16

00:01:03.450  -->  00:01:05.480
is always simple in your aggression.

17

00:01:05.490  -->  00:01:07.260
You can see it filters fitted quite well.

18

00:01:07.530  -->  00:01:11.970
But let's for a change say that the data set looked something like this.

19

00:01:11.970  -->  00:01:17.100
So if we try to use a simple linear regression here where is expressed like that you'll see that it

20

00:01:17.100  -->  00:01:23.490
doesn't fit quite well so in the middle you've got data underneath and then as you go further the data

21

00:01:23.670  -->  00:01:25.050
will be above the line.

22

00:01:25.050  -->  00:01:26.640
So how can we correct that.

23

00:01:26.640  -->  00:01:30.960
Well we can try to correct that by using a polynomial or regression Let's have a look.

24

00:01:30.960  -->  00:01:36.810
So instead of the linear regression we're going to conductive Pono regression and that's in this case

25

00:01:36.810  -->  00:01:38.020
fits perfectly.

26

00:01:38.220  -->  00:01:39.660
And what is the formula.

27

00:01:39.720  -->  00:01:45.300
Well that is a formula for this particular case y equals Bizarros and that's a constant Buzby 1 x1.

28

00:01:45.300  -->  00:01:51.360
So that's a simple English but but then we're adding the beat to X1 squared and the BE to X on squared

29

00:01:51.690  -->  00:01:58.560
gives that parabolic effect or that the curve becomes parabolic and therefore it will fit the data better

30

00:01:58.570  -->  00:01:58.750
.

31

00:01:59.040  -->  00:02:03.540
As you can see polynomial regression is a bit different to symbole in your regression.

32

00:02:03.720  -->  00:02:09.270
And at the same time it has its own use cases so it's all comes on a case by case basis.

33

00:02:09.570  -->  00:02:15.300
You have a problem and then you might try a simple in your regression of multiple integration the many

34

00:02:15.300  -->  00:02:20.970
variables or you might try a polynomial linear regression and see what happens and sometimes the polynomial

35

00:02:21.060  -->  00:02:22.950
regressions do work better.

36

00:02:22.950  -->  00:02:31.250
For example they're used to describe how diseases spread or pandemics and epidemics spread across territory

37

00:02:31.310  -->  00:02:37.530
or across population polynomial regressions can be handy there and they also have other use cases so

38

00:02:37.740  -->  00:02:42.320
it's a matter of what works best so it's always good to have more tools in your arsenal.

39

00:02:42.630  -->  00:02:44.970
And we have one final question left.

40

00:02:44.970  -->  00:02:48.230
The question is why is it cold lean years still.

41

00:02:48.240  -->  00:02:48.480
Right.

42

00:02:48.480  -->  00:02:53.130
So we saw those different powers squared cubes of power and and so on.

43

00:02:53.130  -->  00:02:55.860
Why is this so called new year and I'll show you what I mean.

44

00:02:55.860  -->  00:02:59.880
If you look on the left here it says polynomial linear regression.

45

00:02:59.910  -->  00:03:04.400
So why is it still called a linear regression if it's a polynomial regression.

46

00:03:04.590  -->  00:03:09.600
Well the trick here is that when we're talking about linear and nonlinear we're not actually talking

47

00:03:09.600  -->  00:03:11.910
about the X variables.

48

00:03:11.910  -->  00:03:16.690
Right so even though they're nonlinear here the relationship between Y and X is non-linear.

49

00:03:16.890  -->  00:03:20.670
When you're talking about the class of a regression you're talking.

50

00:03:20.670  -->  00:03:22.490
So whether it is linear or non-linear.

51

00:03:22.620  -->  00:03:25.200
You're talking about the coefficients here.

52

00:03:25.200  -->  00:03:31.410
So that's the interesting part so whether or not this function which we have here so why is a function

53

00:03:31.410  -->  00:03:32.400
of x Right.

54

00:03:32.580  -->  00:03:39.890
And so the question is can this function be expressed as a linear combination of these coefficients

55

00:03:39.900  -->  00:03:42.710
that because ultimately they are the unknowns right.

56

00:03:42.720  -->  00:03:48.630
So your goal when you're building is to find these coefficients find out their actual values so that

57

00:03:48.630  -->  00:03:54.660
then further down the track you can use those coefficients to then plug in X and predict y whether it's

58

00:03:54.660  -->  00:04:00.510
a linear wasing a simple linear multiple linear regression or pull nominal integration that's a goal

59

00:04:00.720  -->  00:04:02.130
to find these beco efficient.

60

00:04:02.340  -->  00:04:06.770
And that's why linear non linear refers to the coefficients.

61

00:04:06.780  -->  00:04:15.300
So an example of a non linear regression would be if the equation was y equals zero plus the 1 X1 divided

62

00:04:15.300  -->  00:04:24.090
by B 2 plus x 2 or something or a B 0 divided by B one plus X Y and so a situation where you really

63

00:04:24.090  -->  00:04:29.740
cannot replace the coefficients with other coefficients to turn the equation into a linear one.

64

00:04:29.850  -->  00:04:33.960
In regards to the coefficients not that x values.

65

00:04:33.960  -->  00:04:38.840
So there you go that's why I pull normal regression is still called a linear regression.

66

00:04:38.850  -->  00:04:44.380
That's a fun fact for the day maybe you can show off to your colleagues and also because of that the

67

00:04:44.390  -->  00:04:51.190
polynomial linear regression is actually a special case of the multiple linear regression.

68

00:04:51.240  -->  00:04:57.990
So that just something to also kind of note that this is a version of the multiple Denia regression

69

00:04:58.380  -->  00:05:01.940
rather than a standalone absolutely new type of regression.

70

00:05:02.010  -->  00:05:06.450
So I hope you enjoyed today's tutorial and I look forward to seeing you next time.

71

00:05:06.450  -->  00:05:08.310
Until then in Germany in learning
