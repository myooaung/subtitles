WEBVTT
1
00:00:00.290 --> 00:00:01.260
Are my friends.

2
00:00:01.270 --> 00:00:04.740
Let's see if Hugh managed to build and train on your own.

3
00:00:04.740 --> 00:00:11.610
This logistic regression model by of course having a look at the cyclone documentation and more specifically

4
00:00:11.920 --> 00:00:16.170
the cyclone API and by implementing the solution together.

5
00:00:16.170 --> 00:00:17.830
This is exactly what we will do.

6
00:00:17.850 --> 00:00:24.210
You know I will go right now to the documentation the cyclone api in order to show you how to indeed

7
00:00:24.270 --> 00:00:29.850
find information on your own which is here how to build that logistic regression model.

8
00:00:29.870 --> 00:00:31.020
All right let's do this.

9
00:00:31.170 --> 00:00:39.480
Let's open a new tab here and in the search bar let's just type psych it learn perfect let's press enter

10
00:00:39.600 --> 00:00:45.240
and let's go to the first link which is the main page of cyclone learn.

11
00:00:45.450 --> 00:00:48.660
Then remember it's good to go to API here.

12
00:00:48.660 --> 00:00:54.320
The other option was to directly type here in the search bar so I could learn logistic regression class.

13
00:00:54.420 --> 00:00:59.670
Okay but I really want to show you again the API because indeed it contains everything you know all

14
00:00:59.670 --> 00:01:02.300
the things you can do with cyclone.

15
00:01:02.310 --> 00:01:12.060
So now we're going to scroll down to find classification which is in a module below called linear models.

16
00:01:12.060 --> 00:01:12.900
Why is that.

17
00:01:12.900 --> 00:01:18.270
That's because of course the logistic regression model is a linear model and we will clearly see that

18
00:01:18.500 --> 00:01:23.580
at the end with the visualization you will clearly see you know how to make the difference between a

19
00:01:23.850 --> 00:01:25.870
linear model and a non-linear moral.

20
00:01:25.890 --> 00:01:27.930
So we'll come to that later but there you go.

21
00:01:27.960 --> 00:01:34.950
This is where you find you know in that linear model module of the circular library all the Linear classifiers

22
00:01:35.190 --> 00:01:38.970
and one of them is of course the logistic regression.

23
00:01:39.000 --> 00:01:44.700
So we're going to click this and there you go here you have the whole documentation of the logistic

24
00:01:44.880 --> 00:01:50.610
regression class you know this is the name of the class that allows to build the logistic regression

25
00:01:50.610 --> 00:01:51.240
model.

26
00:01:51.390 --> 00:01:56.760
And so that's all you needed to get and you could get exactly the same thing by just Tybee here in the

27
00:01:56.760 --> 00:01:59.700
search bar psychically and logistic regression class.

28
00:01:59.700 --> 00:02:01.550
You know you will end up in the same page.

29
00:02:01.560 --> 00:02:08.430
So now what we will only take is you know the name of the class plus the module and if you want cycle

30
00:02:08.430 --> 00:02:15.120
turn and then we will rewrite it the right way to import our class and then create the object.

31
00:02:15.120 --> 00:02:20.660
All right so let's just copy this and then remember the center access to start with from.

32
00:02:20.850 --> 00:02:29.280
So from cycled learn and then from the linear model module of psychic learn and from this linear model

33
00:02:29.280 --> 00:02:34.270
module you import that logistic regression class.

34
00:02:34.320 --> 00:02:40.580
All right so that's the usual syntax we take from the linear model module of the cycle learn library

35
00:02:40.800 --> 00:02:44.940
we import the logistic regression class and now.

36
00:02:44.940 --> 00:02:51.060
Now the next natural step is to create an object of this logistic regression class which will be exactly

37
00:02:51.300 --> 00:02:53.480
the logistic regression model itself.

38
00:02:53.550 --> 00:02:57.540
And since now we're in classification and no longer in regression.

39
00:02:57.540 --> 00:03:00.570
Well we're gonna call our model classifier.

40
00:03:00.570 --> 00:03:06.270
All right so let's do this classifier and that's how we'll call all our other classification models

41
00:03:06.330 --> 00:03:07.470
of this part 3.

42
00:03:07.550 --> 00:03:11.000
So classifier and then you know the next step we have to call the class.

43
00:03:11.010 --> 00:03:14.700
That's how we create an instance of a class.

44
00:03:14.720 --> 00:03:15.510
There we go.

45
00:03:15.510 --> 00:03:18.030
And then we add some parenthesis.

46
00:03:18.030 --> 00:03:21.480
And now the question is do we have to input any parameters.

47
00:03:21.480 --> 00:03:27.370
Well so far we would just like to build the logistic regression model but then don't worry in part 10.

48
00:03:27.510 --> 00:03:33.390
I will teach you how to tune your models which consists of you know choosing the optimal values of your

49
00:03:33.390 --> 00:03:40.350
parameters in order to take the best version of a model but this will come later in part in so far.

50
00:03:40.410 --> 00:03:46.380
Let's just focus on how to build and train the simple logistic regression model which will yet provide

51
00:03:46.440 --> 00:03:47.510
amazing results.

52
00:03:47.510 --> 00:03:47.900
All right.

53
00:03:48.180 --> 00:03:56.370
So no parameters here however we'll just you know enter this random state parameter which will allow

54
00:03:56.370 --> 00:04:02.280
us to get the same results displayed on our notebooks so this is just for teaching purposes you don't

55
00:04:02.280 --> 00:04:05.970
have to do it on your own data sets for your own problems.

56
00:04:05.970 --> 00:04:10.240
All right so random state and we'll set that equal to zero.

57
00:04:10.350 --> 00:04:11.180
Perfect.

58
00:04:11.190 --> 00:04:12.600
And now final step.

59
00:04:12.600 --> 00:04:14.660
You know what you have to do right.

60
00:04:14.670 --> 00:04:17.810
We have to take first are a classifier and then.

61
00:04:17.820 --> 00:04:22.220
Well now what we want to do is to train our classifier on the training set.

62
00:04:22.350 --> 00:04:28.560
Because remember that this line of code only builds the logistic regression model but doesn't train

63
00:04:28.560 --> 00:04:29.200
it yet.

64
00:04:29.310 --> 00:04:35.640
And this next line of code is indeed the final step where we train our classifier on the training set

65
00:04:36.060 --> 00:04:43.740
and remember to do this we have to call the fit method which takes as input to entities you know two

66
00:04:43.740 --> 00:04:49.950
sets of data the first one is the matrix of features of the training set and the second one is the dependent

67
00:04:49.950 --> 00:04:54.870
variable vector of the training set where of course all the purchase decisions of the dependent variable

68
00:04:54.870 --> 00:05:00.420
vector correspond to the same customers of the matrix of features all right.

69
00:05:00.840 --> 00:05:07.890
So what we had to input here was simply X train for the matrix of features of the training set and then

70
00:05:08.070 --> 00:05:13.930
why train for the dependent viable vector of the same training set.

71
00:05:13.930 --> 00:05:15.180
And there you go my friends.

72
00:05:15.180 --> 00:05:16.340
Congratulations.

73
00:05:16.380 --> 00:05:23.490
If you obtained this and also congratulations if you tried because indeed that's how you build the logistic

74
00:05:23.490 --> 00:05:24.310
regression model.

75
00:05:24.390 --> 00:05:25.050
So there you go.

76
00:05:25.050 --> 00:05:30.460
That's one extra machinery moral in your tool kit and you're gonna have many more.

77
00:05:30.480 --> 00:05:37.140
And don't worry I will train you on how to select the best one for any data set.

78
00:05:37.170 --> 00:05:37.550
Okay.

79
00:05:37.580 --> 00:05:38.040
Great.

80
00:05:38.070 --> 00:05:39.610
So let's run this cell.

81
00:05:39.630 --> 00:05:45.870
This will indeed build and train the logistic regression model on your training set composed of extreme

82
00:05:45.930 --> 00:05:51.030
NY train and here by the way you see all the parameters of the logistic regression all which you can

83
00:05:51.030 --> 00:05:56.910
tune the most famous one to see which is the inverse of the regularization strength meaning that the

84
00:05:56.910 --> 00:06:02.940
smaller you see the stronger will be the regularization and therefore the more it will protect you from

85
00:06:03.090 --> 00:06:04.280
over fitting.

86
00:06:04.380 --> 00:06:06.850
Right here will just keep the default value of one.

87
00:06:06.960 --> 00:06:07.830
And there you go.

88
00:06:07.860 --> 00:06:09.920
We're ready to move onto the next step.

89
00:06:09.960 --> 00:06:11.690
Predicting a new result.

90
00:06:11.760 --> 00:06:16.690
And so now new exercise for you because we already did it with regression.

91
00:06:16.740 --> 00:06:22.290
I taught you before how to you know take your regrets her and then go to predict method to predict the

92
00:06:22.290 --> 00:06:24.600
result of a single observation.

93
00:06:24.630 --> 00:06:31.560
And so here the exercise that I would like you to do is to predict the poor chaste decision of a single

94
00:06:31.560 --> 00:06:34.960
result you know the purchase decision of a single customer.

95
00:06:35.130 --> 00:06:41.580
And I will tell you which one I would like you to predict the chaste decision of the first customer

96
00:06:41.820 --> 00:06:50.220
in the test set who you will see is 30 years old and earns an estimated salary of eighty seven thousand

97
00:06:50.220 --> 00:06:50.970
dollars.

98
00:06:50.970 --> 00:06:56.190
So I would like you to take these two inputs you know these two features with these values 30 years

99
00:06:56.190 --> 00:06:59.720
old and eighty seven thousand dollars at the estimated salary.

100
00:06:59.820 --> 00:07:05.270
And now I would like you to predict whether this customer has but yes or no.

101
00:07:05.310 --> 00:07:11.880
The SUV you have the answer in white sense you know you take the first result why test and thus you'll

102
00:07:11.880 --> 00:07:18.570
be able to compare your prediction to the real result to figure out whether your prediction was correct.

103
00:07:18.570 --> 00:07:24.450
And so there you go please do the exercise please try to do this on your own first before we do it together

104
00:07:24.450 --> 00:07:31.560
in the next story or please predict the purchase decision of that first customer of the test and we

105
00:07:31.560 --> 00:07:37.560
will of course implement the solution in the next tutorial.

106
00:07:37.560 --> 00:07:39.720
Until then enjoy machine learning.
