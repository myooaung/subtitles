1
00:00:00,210 --> 00:00:07,740
Hello, my friends, and welcome to this very exciting new practical activity on convolutional neural

2
00:00:07,860 --> 00:00:08,430
networks.

3
00:00:08,730 --> 00:00:12,660
If you're not too overwhelmed by the previous section, you know, on our visual news networks.

4
00:00:13,110 --> 00:00:19,020
Well, then you will smash with me this new section, because basically a convolutional neural network,

5
00:00:19,080 --> 00:00:25,470
as you saw in the intuition lectures, simply consists of adding an extra layer, which is the convolutional

6
00:00:25,470 --> 00:00:31,620
layer that, as you understood, gives eyes to the A.I., you know, to the deep learning model, because

7
00:00:31,620 --> 00:00:37,980
indeed, with the convolutional neural network, we can now take an image or, you know, a 3D frame

8
00:00:38,040 --> 00:00:44,640
as an input as opposed to our previous artificial neural network, which could only take an input vector

9
00:00:44,670 --> 00:00:47,220
containing some features as information.

10
00:00:47,350 --> 00:00:47,540
Right.

11
00:00:47,550 --> 00:00:49,650
Remember the features of the customers in the bank.

12
00:00:50,010 --> 00:00:57,180
But here we're going to add at the front a convolutional layer which will be able to visualize or see

13
00:00:57,570 --> 00:00:59,450
images just like humans do.

14
00:00:59,700 --> 00:01:00,760
So that's pretty exciting.

15
00:01:00,780 --> 00:01:06,720
You know, we're making a step further towards human intelligence because, you know, the fascination

16
00:01:06,750 --> 00:01:11,310
that scientists have about deep learning is that, you know, it's a branch of machine learning that

17
00:01:11,460 --> 00:01:15,600
gets artificial intelligence closer and closer to human intelligence.

18
00:01:15,900 --> 00:01:21,390
And you will even see in some more advanced courses on deep learning that not only we can add eyes to

19
00:01:21,390 --> 00:01:26,940
the A.I., but also some memory with the alicja themselves, but also some critics sense.

20
00:01:27,180 --> 00:01:32,130
Well, there are a lot of innovations in the deploying science, which is absolutely fascinating.

21
00:01:32,160 --> 00:01:34,950
But here we're going to focus on C and ends.

22
00:01:35,190 --> 00:01:36,410
And so there you go, my friends.

23
00:01:36,450 --> 00:01:39,360
Let's start this new practical activity.

24
00:01:39,710 --> 00:01:44,520
And as usual, before we go into this further, let's make sure everyone here is on this same page.

25
00:01:44,700 --> 00:01:48,340
I give you the link to this for the right before this tutorial in the article.

26
00:01:48,480 --> 00:01:52,380
And so now please follow me into part eight, deep learning.

27
00:01:52,920 --> 00:01:53,820
We're inside.

28
00:01:53,910 --> 00:01:58,230
We're now going to go to convolutional neural networks.

29
00:01:58,770 --> 00:01:59,010
All right.

30
00:01:59,040 --> 00:02:04,140
So for this section, exceptionally, we only have an implementation in Python.

31
00:02:04,380 --> 00:02:10,590
And that's for the simple reason that or is more used for data mining kind of machine learning or,

32
00:02:10,590 --> 00:02:13,380
you know, advanced statistics, high dimensional statistics.

33
00:02:13,740 --> 00:02:18,880
But I have not met any scientists in my life who does computer vision with ah.

34
00:02:19,110 --> 00:02:24,840
There are some libraries like Deep Water that can build a CNN for computer vision.

35
00:02:25,080 --> 00:02:31,620
But really the best and most advanced programming language for deep learning is definitely Python.

36
00:02:31,650 --> 00:02:36,690
Thanks to the amazing libraries that have been developed by Google and Facebook, you know, Google

37
00:02:36,690 --> 00:02:40,560
developed Tensor Flow, which is an amazing library for deep learning.

38
00:02:40,830 --> 00:02:45,420
And Facebook developed by Torch, which is another amazing deep learning library.

39
00:02:45,450 --> 00:02:49,230
But these two, Tenzer, fluent by Torch, are only used with Python.

40
00:02:49,320 --> 00:02:54,720
And that's why, exceptionally for this section, there will not be an R implementation of the CNN.

41
00:02:54,870 --> 00:02:55,130
Right.

42
00:02:55,170 --> 00:03:00,180
The Eynon was fine because we were still doing some advanced data mining with neural networks.

43
00:03:00,420 --> 00:03:04,590
But for computer vision, really your best option is Python.

44
00:03:05,160 --> 00:03:05,520
All right.

45
00:03:05,760 --> 00:03:07,170
So let's go into Python.

46
00:03:07,530 --> 00:03:10,800
And now second different thing compared to before.

47
00:03:11,040 --> 00:03:16,310
As you notice, you will only find the implementation here in this folder and not the dataset.

48
00:03:16,770 --> 00:03:18,480
That's for a very good reason.

49
00:03:18,660 --> 00:03:22,590
That's because the dataset is actually super huge and or in terms of size.

50
00:03:22,740 --> 00:03:29,310
It's a couple hundreds of megabytes because the dataset contains lots and lots of images of cats and

51
00:03:29,310 --> 00:03:29,670
dogs.

52
00:03:29,700 --> 00:03:31,290
We're gonna see them in a second.

53
00:03:31,320 --> 00:03:33,760
But since it contains a lot of images.

54
00:03:34,050 --> 00:03:37,380
Well, I did not include the dataset here otherwise.

55
00:03:37,380 --> 00:03:42,330
You know, for those of you who want to download the whole machinery, it is it codes and data sets

56
00:03:42,330 --> 00:03:42,780
folder.

57
00:03:43,050 --> 00:03:48,600
Well, it will take a lot more time if I include this dataset here than if I left it separately, which

58
00:03:48,600 --> 00:03:49,260
is what I did.

59
00:03:49,380 --> 00:03:54,240
I left it separately and I gave it to you actually right before this tutorial in the same article.

60
00:03:54,450 --> 00:04:00,030
So I hope you downloaded it, because right now we're gonna have a look right at the bottom of the Oracle

61
00:04:00,030 --> 00:04:01,350
right before this tutorial.

62
00:04:01,530 --> 00:04:04,710
You had to download this exact folder.

63
00:04:04,770 --> 00:04:07,440
Well, actually, the zip folder better already and zipped it.

64
00:04:07,890 --> 00:04:13,770
But you had to download this for those Section 40 convolutional neural networks, which indeed contains

65
00:04:13,800 --> 00:04:21,990
not only the codes and IPY and B format and P y format, but mostly the dataset, the dataset, which

66
00:04:22,050 --> 00:04:24,060
contains three sub folders.

67
00:04:24,330 --> 00:04:28,710
The first one containing all the images of cats and dogs.

68
00:04:28,740 --> 00:04:34,950
But for the training set, which means that we're gonna train our CNN Morrel on all these images of

69
00:04:34,950 --> 00:04:36,810
cats and dogs in the train set.

70
00:04:37,320 --> 00:04:43,170
And then we have this other folder, which is the test set on which we will actually evaluate our moral

71
00:04:43,200 --> 00:04:47,640
with new images of cats and dogs on which the model wasn't trained.

72
00:04:48,180 --> 00:04:52,590
And finally, we have this little folder here, which only contains two images.

73
00:04:52,950 --> 00:04:55,890
And this will be just to test the model in production.

74
00:04:56,100 --> 00:04:57,450
You know, the single image.

75
00:04:57,660 --> 00:04:59,690
So we will first take this image of.

76
00:04:59,860 --> 00:05:06,820
This beautiful dug to test that our CNN can detect the dog, you know, can predict that indeed we have

77
00:05:06,820 --> 00:05:13,240
a dug in this image and we will do the same with that image of a cat so that we can check that.

78
00:05:13,330 --> 00:05:17,080
And these are CNN predicts that there is a cat in this image.

79
00:05:17,470 --> 00:05:19,810
So, as you understood, I just explained the problem.

80
00:05:19,810 --> 00:05:26,500
Actually, we're going to build and train a convolutional neural network to recognize if there is a

81
00:05:26,500 --> 00:05:29,090
dog or a cat in an image.

82
00:05:29,400 --> 00:05:29,600
OK.

83
00:05:29,680 --> 00:05:31,460
So I hope you like the Casey.

84
00:05:31,480 --> 00:05:35,860
Of course, this time it's not a business case study, but we're gonna have a lot of fun doing this.

85
00:05:35,890 --> 00:05:39,520
And it's a great way to be introduced to convolutional neural networks.

86
00:05:39,790 --> 00:05:44,050
And even if it's just an introduction, you will see that to see an end we're going to build will be

87
00:05:44,110 --> 00:05:44,950
quite advanced.

88
00:05:44,950 --> 00:05:50,290
And actually the implementation is quite advanced with lots of technical tools, which will, of course,

89
00:05:50,290 --> 00:05:52,180
perfectly do the job at d'Eon.

90
00:05:52,870 --> 00:05:53,210
OK.

91
00:05:53,320 --> 00:05:58,000
So that was the second specific thing the dataset was given to you separately.

92
00:05:58,300 --> 00:05:58,610
All right.

93
00:05:58,630 --> 00:06:01,680
And just to show you quickly, the training set and a test set.

94
00:06:01,720 --> 00:06:05,880
So in a training set, you have lots and lots of images of cats and dogs.

95
00:06:05,890 --> 00:06:12,340
Actually, you have 4000 images of cats and four thousand images of dogs.

96
00:06:12,640 --> 00:06:12,940
Right.

97
00:06:12,970 --> 00:06:14,130
I can take anyone.

98
00:06:14,680 --> 00:06:15,550
This is a dog.

99
00:06:17,040 --> 00:06:17,850
Another dog.

100
00:06:18,060 --> 00:06:20,340
You know, many different breeds of dogs.

101
00:06:20,700 --> 00:06:25,200
So if you love dogs, you're gonna have a great time looking at the images here.

102
00:06:25,740 --> 00:06:26,160
Right.

103
00:06:27,540 --> 00:06:28,320
And there he goes.

104
00:06:28,470 --> 00:06:30,090
This is a very cute dog, by the way.

105
00:06:30,600 --> 00:06:30,860
OK.

106
00:06:30,930 --> 00:06:34,140
And simply catch you have many images of cats.

107
00:06:34,350 --> 00:06:34,770
Right.

108
00:06:35,080 --> 00:06:37,010
A different style, different colors, you know.

109
00:06:37,770 --> 00:06:43,440
So whether you're a cat lover or dog lover, you will have a great time looking at any of these images.

110
00:06:43,890 --> 00:06:45,100
And send for the test set.

111
00:06:45,330 --> 00:06:51,000
Well, you have 1000 images of cats here and same 1000 images of dogs.

112
00:06:51,360 --> 00:06:58,260
So just to recap, in the training set, you have until 8000 images with 4000 images of cats and 4000

113
00:06:58,260 --> 00:06:59,040
images of dogs.

114
00:06:59,430 --> 00:07:06,300
And in a test set, you have in total 2000 images with 1000 images of cats and 1000 images of dogs.

115
00:07:06,450 --> 00:07:06,750
Right.

116
00:07:06,810 --> 00:07:11,250
It's important to keep numbers in mind because we're going to use them in the implementation.

117
00:07:12,000 --> 00:07:12,570
OK, good.

118
00:07:12,620 --> 00:07:18,240
So make sure to have this on your machine, because, of course, we will use it to run our coat.

119
00:07:18,660 --> 00:07:25,710
And now, third specific thing that I wanted to highlight in this first introductory tutorial here is

120
00:07:25,710 --> 00:07:33,120
the fact that for the very first time, we won't be able to run our implementation, which is this one

121
00:07:33,450 --> 00:07:35,840
convolutional neural network that i.p Wendy.

122
00:07:36,270 --> 00:07:40,230
We won't be able to run this implementation on Google CoLab.

123
00:07:40,650 --> 00:07:41,400
Why is that?

124
00:07:41,730 --> 00:07:46,770
That's for the simple reason that the dataset is too big for a Google killer notebook.

125
00:07:47,250 --> 00:07:53,670
And therefore, for the very first time in this course, I will show you how to run this implementation

126
00:07:53,970 --> 00:08:00,150
on Jubera notebook, because with Jubera notebook, we will be able to access directly from your machine

127
00:08:00,210 --> 00:08:01,020
the data set.

128
00:08:01,410 --> 00:08:03,540
And we will run the code from our machine.

129
00:08:03,600 --> 00:08:05,400
But within a Juber notebook.

130
00:08:05,640 --> 00:08:06,360
Well, notebook.

131
00:08:06,500 --> 00:08:06,760
Okay.

132
00:08:07,230 --> 00:08:13,380
So what we'll do, in fact, in this new section is we will still, you know, reimplement this whole

133
00:08:13,440 --> 00:08:16,040
code from scratch on Google Kulab.

134
00:08:16,380 --> 00:08:22,650
But at the end, once all this is implemented, we will simply go to FAO here and then click here,

135
00:08:22,800 --> 00:08:29,970
download DOT, IPY, NDB, and this will download the IPY and be FAO, which will be able to run on

136
00:08:30,090 --> 00:08:30,990
Jubran Notebook.

137
00:08:31,470 --> 00:08:31,800
All right.

138
00:08:31,920 --> 00:08:32,880
So that's what will happen.

139
00:08:32,910 --> 00:08:35,670
But we will stay on Google Cloud to implement this together.

140
00:08:35,940 --> 00:08:37,110
And speaking of which.

141
00:08:37,200 --> 00:08:43,950
Well right now we have to save a copy and drive because this is an read only mode and therefore we need

142
00:08:43,950 --> 00:08:48,540
to create a copy to be able to modify and reimplement the whole code.

143
00:08:49,140 --> 00:08:49,400
All right.

144
00:08:49,410 --> 00:08:50,820
So let's do this as usual.

145
00:08:50,880 --> 00:08:52,810
Let's delete all the code cells.

146
00:08:53,130 --> 00:08:53,430
Right.

147
00:08:53,550 --> 00:08:54,480
Only the code cells.

148
00:08:54,510 --> 00:09:00,570
Make sure to keep the text cells to keep that well highlighted structure, because indeed, now we have

149
00:09:00,870 --> 00:09:02,250
a pretty long implementation.

150
00:09:02,250 --> 00:09:07,860
So it's important to keep the structure so that we can, you know, take a step back any time and know

151
00:09:07,950 --> 00:09:08,850
where we're going.

152
00:09:09,210 --> 00:09:09,690
All right.

153
00:09:09,810 --> 00:09:14,400
So let's remove only the code cells and.

154
00:09:15,440 --> 00:09:21,080
Now, reaching part three, you know, you're going to recognize some of the same steps as before with

155
00:09:21,140 --> 00:09:21,680
CNN.

156
00:09:22,180 --> 00:09:22,410
Right.

157
00:09:22,460 --> 00:09:23,390
This is part four.

158
00:09:23,450 --> 00:09:24,470
And there we go.

159
00:09:25,040 --> 00:09:25,190
All right.

160
00:09:25,220 --> 00:09:26,220
So that's the whole structure.

161
00:09:26,240 --> 00:09:28,580
Let's have a look at it, you know, from here.

162
00:09:28,760 --> 00:09:30,950
So at first, we will import the libraries.

163
00:09:31,220 --> 00:09:37,270
Then we have a structure in four parts, parts one day pricing, part two, building the CNN, Part

164
00:09:37,290 --> 00:09:41,720
three, training the CNN and port for making a single prediction.

165
00:09:42,050 --> 00:09:44,840
So it's exactly the same as before, you know, with the CNN.

166
00:09:45,080 --> 00:09:50,360
Only this time, in part one, we will do a different work because for the very first time actually

167
00:09:50,360 --> 00:09:54,300
in the course, we won't be preprocessing a classic dataset.

168
00:09:54,530 --> 00:09:57,740
But this time we will be preprocessing some images.

169
00:09:58,070 --> 00:10:00,800
And therefore, the data pricing phase will be different.

170
00:10:01,040 --> 00:10:02,660
It will consist of doing two steps.

171
00:10:02,930 --> 00:10:07,730
First, we will pre-process the training set and then we will pre-process the test set.

172
00:10:08,300 --> 00:10:13,130
All right, then in part two, we'll build a CNN Nual, the whole architecture of the convolutional

173
00:10:13,130 --> 00:10:13,850
neural network.

174
00:10:14,090 --> 00:10:16,850
We will initializes CNN as a sequence of layers.

175
00:10:17,120 --> 00:10:21,500
Then we will proceed to step one convolution to add to convolutional layers.

176
00:10:21,830 --> 00:10:25,670
Then we will proceed to step two, pooling, more specifically, max pooling.

177
00:10:26,030 --> 00:10:31,280
Then we will add a second convolutional layer to make it, you know, a deep neural network as opposed

178
00:10:31,280 --> 00:10:32,990
to a shallow neural network.

179
00:10:33,350 --> 00:10:39,230
Then we'll proceed to step three flattening to flatten the result of all the convolutions and pullings

180
00:10:39,590 --> 00:10:45,350
into a one dimensional vector, which will become the input of a fully connected neural network.

181
00:10:45,590 --> 00:10:47,420
And finally, we will connect to all this.

182
00:10:47,690 --> 00:10:51,800
The final output layer then in part three when training CNN.

183
00:10:51,800 --> 00:10:53,320
Well, same as a CNN.

184
00:10:53,330 --> 00:10:58,010
We will first compile the CNN and then we'll train the CNN on the training set.

185
00:10:58,040 --> 00:11:01,210
Well, you know, evaluating it on the test set.

186
00:11:01,330 --> 00:11:03,110
We will clearly see that in the output.

187
00:11:03,500 --> 00:11:08,390
And finally, we will make a single prediction, you know, to test our model and prediction.

188
00:11:08,750 --> 00:11:12,410
And so we will deploy our CNN on to different images.

189
00:11:12,740 --> 00:11:15,740
One that will have Doug and the other that will have a cat.

190
00:11:15,830 --> 00:11:21,080
And we will hope that our CNN can recognize, respectively, the dog and cat.

191
00:11:21,860 --> 00:11:22,250
All right.

192
00:11:22,340 --> 00:11:22,940
So that.

193
00:11:23,060 --> 00:11:24,290
Ah, structure.

194
00:11:24,410 --> 00:11:25,610
I hope you're ready for it.

195
00:11:25,790 --> 00:11:27,440
And actually, I'm sure you are.

196
00:11:27,560 --> 00:11:32,660
So if that's the case, well, join me in the next tutorial to smash this implementation.

197
00:11:32,840 --> 00:11:34,780
And until then, enjoy machine learning.
