WEBVTT
1

00:00:00.390  -->  00:00:02.540
Hello and welcome to this art tutorial.

2

00:00:02.580  -->  00:00:08.430
So in the British Statoil we did a pre-processing phase we imported the data set and selected only the

3

00:00:08.430  -->  00:00:13.550
level him and the salary column then we didn't have to spend the day to send into the training set and

4

00:00:13.570  -->  00:00:18.900
attested because as you can see the data set is a very small dataset with only 10 observations.

5

00:00:18.900  -->  00:00:22.310
And finally we didn't have to apply scaling.

6

00:00:22.470  -->  00:00:25.210
So that made this first preprocessing step pretty easy.

7

00:00:25.260  -->  00:00:30.420
And now we are ready to move on to the next step which is to fit our polynomial model to the data sets

8

00:00:30.420  -->  00:00:30.750
.

9

00:00:30.760  -->  00:00:37.200
However I would like to show you how the polynomial regression model is a much more powerful model for

10

00:00:37.200  -->  00:00:43.320
our situation and the best way to show you this is to actually compare it to a baseline model like a

11

00:00:43.310  -->  00:00:46.940
reference base model which will be our linear regression model.

12

00:00:46.980  -->  00:00:51.720
That's why in this Statoil we will build two models the linear regression model and the pulling of your

13

00:00:51.720  -->  00:00:52.600
regression model.

14

00:00:52.860  -->  00:00:58.220
And then we will compare the results we will compare the graphic results and also the predictions.

15

00:00:58.260  -->  00:01:03.450
So you'll be convinced that the polling and the regression model is a much more appropriate model for

16

00:01:03.450  -->  00:01:04.290
this problem.

17

00:01:04.350  -->  00:01:08.780
And the main reason for that is that our problem is a nonlinear problem.

18

00:01:09.270  -->  00:01:14.900
OK so let's start by building this linear model it's going to be very quick because we actually really

19

00:01:14.910  -->  00:01:15.670
did this.

20

00:01:15.810  -->  00:01:20.820
So you know we start by creating or regressors that this time we're not going to call regressors because

21

00:01:20.820  -->  00:01:24.920
we will build two regressors the linear one and the polynomial one.

22

00:01:24.990  -->  00:01:27.750
So we will call it Lin rock.

23

00:01:27.780  -->  00:01:28.560
Here we go.

24

00:01:28.770  -->  00:01:32.630
And then you know later we will call our polynomial regrets are probably wrong.

25

00:01:32.970  -->  00:01:38.120
So Liberec equals and then remember we have to use the L.N. formula.

26

00:01:38.190  -->  00:01:44.850
And so we need to add some parenthesis here and then let's remind ourselves what we need to input by

27

00:01:44.850  -->  00:01:47.850
pressing F on here to have a look at the arguments.

28

00:01:47.850  -->  00:01:50.870
OK so remember the first argument is formula.

29

00:01:50.910  -->  00:01:59.780
So the formula is very simply the salary that is already been invariable Tilda.

30

00:01:59.910  -->  00:02:05.010
So I just spread it out and and then a dot here to take all the independent variables.

31

00:02:05.010  -->  00:02:12.120
But actually there is only one independent variable so the dot here is strictly equivalent as just writing

32

00:02:12.210  -->  00:02:12.860
level.

33

00:02:13.050  -->  00:02:16.520
OK so perfect for the first arguments and then what is the second argument.

34

00:02:16.680  -->  00:02:18.580
It's data so data.

35

00:02:18.600  -->  00:02:20.400
OK so let's add this argument.

36

00:02:20.400  -->  00:02:22.590
Data equals.

37

00:02:22.650  -->  00:02:23.430
And now let's see.

38

00:02:23.430  -->  00:02:23.690
OK.

39

00:02:23.700  -->  00:02:30.870
So in the linear regression section we actually used the training set here as the data argument to train

40

00:02:30.930  -->  00:02:32.630
our linear regression model.

41

00:02:32.700  -->  00:02:37.580
But as we explained before here we did not speed the dataset into the training center the test set.

42

00:02:37.590  -->  00:02:43.530
So we were simply going to train our model on the whole data set itself because it's a small data set

43

00:02:43.530  -->  00:02:46.970
anyway and we want to have the most accurate prediction.

44

00:02:46.980  -->  00:02:50.640
So here simply we will just input data set.

45

00:02:51.210  -->  00:02:54.430
All right and our linear regression model is ready.

46

00:02:54.500  -->  00:03:00.740
We are actually ready to build it so let's just do it let's build our linear regression model and press

47

00:03:00.760  -->  00:03:03.070
and commander control plus and do execute.

48

00:03:03.120  -->  00:03:05.450
All right then our aggression made.

49

00:03:05.460  -->  00:03:09.420
We can have a quick look at the summary here summary.

50

00:03:09.550  -->  00:03:15.170
Let reg so some typing this in the console and pressing enter.

51

00:03:15.450  -->  00:03:18.470
And here are the statistical results of the model.

52

00:03:18.490  -->  00:03:22.500
We're doing this on our Because as you can see it's really easy on bytes and we would have needed to

53

00:03:22.500  -->  00:03:24.420
import a class create an object.

54

00:03:24.480  -->  00:03:29.900
Here it's really easy so we're going to have a look and we can see that the level has to store us here

55

00:03:29.910  -->  00:03:35.080
for the level of significance and is actually not a bad predictor of the salary.

56

00:03:35.220  -->  00:03:40.650
Let's wait for the polynomial model to see how it can be much better than linear regression.

57

00:03:41.030  -->  00:03:43.320
OK so now let's move on to the next level.

58

00:03:43.320  -->  00:03:46.400
That is the better model polynomial regression.

59

00:03:46.500  -->  00:03:47.880
And let's build it.

60

00:03:48.010  -->  00:03:53.670
OK so as I mentioned we're going to call this regress or Poley underscore Greg.

61

00:03:53.770  -->  00:03:54.770
Right this way.

62

00:03:54.960  -->  00:04:00.600
And you know since the polynomial regression model is actually a multiple in our aggression model in

63

00:04:00.600  -->  00:04:06.300
which the independent variables are actually the polynomial features of one independent variables.

64

00:04:06.300  -->  00:04:12.240
As Carroll explained in the intuition tutorial Well we're going to use again the L.M. function as we

65

00:04:12.240  -->  00:04:13.770
did for linear regression.

66

00:04:13.770  -->  00:04:19.530
So here I'm just going to start by taking my L-N function at the parenthesis and we're going to input

67

00:04:19.530  -->  00:04:20.750
our two arguments.

68

00:04:20.770  -->  00:04:26.950
Formula equals salary till the out.

69

00:04:27.170  -->  00:04:31.860
And then this dot here dory will actually represent something else.

70

00:04:31.880  -->  00:04:37.110
So so far I'm just putting the dots and you understand what's going to happen next which will make our

71

00:04:37.110  -->  00:04:39.810
polynomial regression builds correctly.

72

00:04:40.200  -->  00:04:45.450
So then come up and then we add our second argument which is still going to be the data equals data

73

00:04:45.450  -->  00:04:50.720
set because we're going to train our polynomial regression model on the whole dataset.

74

00:04:50.900  -->  00:04:56.130
OK so now you must be telling yourself Wait but this is exactly the same as linear regression.

75

00:04:56.280  -->  00:05:02.610
Well that's true and that's why we need to add a little something here to make this model a polynomial

76

00:05:02.610  -->  00:05:07.980
regression model and this little something that we're going to add is actually the pulling of your features

77

00:05:07.990  -->  00:05:08.030
.

78

00:05:08.560  -->  00:05:13.400
The polynomial features are actually some additional independent variables that are going to be the

79

00:05:13.400  -->  00:05:19.800
level squared level cubed level to the fourth level to the fifth up to any degree you want.

80

00:05:19.820  -->  00:05:22.430
These are these additional independent variables.

81

00:05:22.430  -->  00:05:27.920
There are going to compose are new metrics or features in some way which will actually be the matrix

82

00:05:28.130  -->  00:05:34.550
on which will apply multiple linear regression model which will make the whole model a polynomial regression

83

00:05:34.550  -->  00:05:35.270
model.

84

00:05:35.270  -->  00:05:42.110
So in short a polynomial regression model is a multiple regression model that is composed of one independent

85

00:05:42.110  -->  00:05:48.170
variable and additional independent variables that are pulling in terms of this first independent variable

86

00:05:48.180  -->  00:05:48.460
.

87

00:05:48.770  -->  00:05:54.000
Ok so now that we get this idea you'll perfectly understand what we're about to do right now.

88

00:05:54.050  -->  00:06:00.680
When building our polynomial regression model because what we are going to do is to build this polynomial

89

00:06:00.680  -->  00:06:07.010
terms and to that extent what we're simply going to do is to add specifically and you call them here

90

00:06:07.010  -->  00:06:10.010
in this dataset which will be the level squared.

91

00:06:10.010  -->  00:06:15.650
So we're going to call this new independent variable level 2 and let's add this new column right now

92

00:06:15.670  -->  00:06:15.990
.

93

00:06:16.310  -->  00:06:21.840
So to add a column in a data frame we need to take our data frame so it's data set.

94

00:06:21.860  -->  00:06:28.130
Here it is and then we need to add a dollar sign here and then we can add any name here which will create

95

00:06:28.280  -->  00:06:31.740
a new column of this name and add it into our dataset.

96

00:06:31.790  -->  00:06:37.760
So we're going to call this call him level 2 because we're taking the level squared of our 10 levels

97

00:06:37.760  -->  00:06:38.450
.

98

00:06:38.450  -->  00:06:44.660
Then we add equals and then we actually need to give the formula of the values in this level to go in

99

00:06:44.660  -->  00:06:51.060
of our data sets and this formula is there for the levels in our data set and the power of two.

100

00:06:51.200  -->  00:06:58.040
So very simply we're going to take all the levels of our data sets by taking our data set and same adding

101

00:06:58.040  -->  00:07:02.800
this dollar here to take the level column which is here I just have to press enter.

102

00:07:03.020  -->  00:07:08.210
So by doing this I'm taking the level call him that is all the values of the level column in our dataset

103

00:07:08.290  -->  00:07:08.670
.

104

00:07:08.870  -->  00:07:15.350
And now I'm going to take the square of all these levels in our data sets and so to do this very simply

105

00:07:15.350  -->  00:07:22.520
I just add hats and to that said that we'll just create a new column which will contain the squares

106

00:07:22.520  -->  00:07:24.490
of our 10 levels in our dataset.

107

00:07:24.500  -->  00:07:29.890
So let's see right now my data set contains only two columns level and salary.

108

00:07:30.170  -->  00:07:32.940
And if I execute this.

109

00:07:33.530  -->  00:07:34.400
Here we go.

110

00:07:34.400  -->  00:07:37.370
Now let's have a look at the data set as you can see.

111

00:07:37.400  -->  00:07:41.250
I now have three columns level salary and level two.

112

00:07:41.450  -->  00:07:47.000
And as you can notice the value and the level to call them are the squares of the values and the level

113

00:07:47.000  -->  00:07:47.720
column.

114

00:07:48.080  -->  00:07:49.040
OK.

115

00:07:49.430  -->  00:07:55.520
And now we can build our polynomial regression model because now it is done here not only contains the

116

00:07:55.520  -->  00:07:58.760
level column but also the level to call him.

117

00:07:58.760  -->  00:08:05.540
So this will build a multiple in our regression model where the independent variables are the original

118

00:08:05.540  -->  00:08:10.440
independent variable and the polynomial term of this first independent viable.

119

00:08:10.610  -->  00:08:15.740
And if you want to build a bullet in a regression model with a higher degree Well you will need to do

120

00:08:15.740  -->  00:08:23.240
the same here you know we can copy this line and paste it here and just add a level 3 column that will

121

00:08:23.240  -->  00:08:30.070
contain the cubes of the levels in the original independent variable level of our dataset.

122

00:08:30.080  -->  00:08:31.800
And as you can see it'll be very easy.

123

00:08:31.940  -->  00:08:38.230
I just need to execute this line and this will add a level 3 column in our dataset.

124

00:08:38.240  -->  00:08:45.020
And so now this little dot here will be the original in the pen variable level the square values of

125

00:08:45.020  -->  00:08:50.770
our levels and level 2 and the cube values of our levels and the call them level 3.

126

00:08:50.990  -->  00:08:55.280
You can add as many powers of levels as you want but maybe we will stop here.

127

00:08:55.310  -->  00:08:58.610
We will see what is the best polynomial regression for our model.

128

00:08:58.700  -->  00:09:00.670
And so we will see what we'll get with this one.

129

00:09:00.800  -->  00:09:04.330
And now let's actually build the polynomial regression model.

130

00:09:04.370  -->  00:09:10.430
If we select this and execute press command and control pass and to execute and done our polynomial

131

00:09:10.430  -->  00:09:13.250
regression model is created also.

132

00:09:13.250  -->  00:09:20.590
So we're going to have a look that's type summary in the console poly reg and let's press enter and

133

00:09:20.590  -->  00:09:21.700
let's see where we get.

134

00:09:21.990  -->  00:09:27.860
OK so now where we can see is that these are level 2 and level 3 polynomial terms that we created are

135

00:09:27.860  -->  00:09:33.800
actually statistical significant variables but it's actually this table here does not show the real

136

00:09:33.800  -->  00:09:37.120
deal of the polynomial regression model for our problem.

137

00:09:37.160  -->  00:09:42.230
You will be much more convinced in the next tutorial where we'll be visualizing the graphic results

138

00:09:42.530  -->  00:09:47.660
and you will perfectly understand why are pulling a regression which is a non-linear model will make

139

00:09:47.660  -->  00:09:53.180
a much better job at predicting what we want compared to this linear regression model because it's a

140

00:09:53.180  -->  00:09:54.610
linear model.

141

00:09:54.770  -->  00:09:56.820
So we'll check that in the next tutorial.

142

00:09:56.870  -->  00:09:58.610
And until then enjoy machine learning
