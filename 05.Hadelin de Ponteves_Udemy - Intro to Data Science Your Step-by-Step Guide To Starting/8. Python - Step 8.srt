1
00:00:04,340 --> 00:00:10,490
Hello and welcome to the second challenge of the section The second challenge will be about classification

2
00:00:10,850 --> 00:00:16,970
which I don't mind is another data science branch in which you have to predict a category or also called

3
00:00:17,080 --> 00:00:17,880
a class.

4
00:00:18,140 --> 00:00:23,470
And our starting point for this new challenge will be exactly the same one as progression.

5
00:00:23,660 --> 00:00:30,320
We're going to start with this UCI machinery repository which again I recommend to use when you're starting

6
00:00:30,590 --> 00:00:32,290
to practice as much as possible.

7
00:00:32,450 --> 00:00:35,060
And then when you're ready start with Kaggle.

8
00:00:35,210 --> 00:00:42,230
But this contains again a great collection of data science problems grouped into classification regression

9
00:00:42,310 --> 00:00:45,620
and clustering and even other types of data science problem.

10
00:00:45,800 --> 00:00:50,720
And so the one we're going to tackle now is a classification problem and that's why I'm clicking on

11
00:00:50,720 --> 00:00:53,260
this to get all the data set.

12
00:00:53,260 --> 00:00:58,230
There are three hundred and fourteen days said about classification.

13
00:00:58,490 --> 00:01:03,710
And as I told you this time it's not going to be an energy related challenge.

14
00:01:03,890 --> 00:01:05,380
It's going to be about health.

15
00:01:05,480 --> 00:01:12,220
Another industry in which machine learning and artificial intelligence could have a great impact.

16
00:01:12,230 --> 00:01:14,240
We're going to start with a simple problem.

17
00:01:14,320 --> 00:01:21,710
It's to predict whether or not a tumor in the breast is cancerous and this is indeed a classification

18
00:01:21,710 --> 00:01:28,550
problem because we have to predict two classes the first class is the tumor in the breast is cancerous

19
00:01:28,910 --> 00:01:32,720
and the second class is the tumor in the breast is benign.

20
00:01:32,890 --> 00:01:39,480
And so the data will be dealing with to solve this challenge is a classic one.

21
00:01:39,500 --> 00:01:46,160
It's got the breast cancer as you can see there are four versions of this breast cancer data.

22
00:01:46,310 --> 00:01:52,430
We're going to take the original one breast cancer Wisconsin and again we have all the description of

23
00:01:52,430 --> 00:01:56,110
today's set just below the days that information here.

24
00:01:56,210 --> 00:02:03,080
But what we're interested in are mostly attribute information because remember the next step now is

25
00:02:03,080 --> 00:02:05,290
to figure out what you want to predict.

26
00:02:05,450 --> 00:02:12,350
So I already told you we have to predict the outcome whether or not a tumor in the breast is benign

27
00:02:12,560 --> 00:02:13,670
or malignant.

28
00:02:13,670 --> 00:02:15,220
So we have a code for this.

29
00:02:15,320 --> 00:02:21,140
Our class voidable will take two values to four benign and four for malignant.

30
00:02:21,170 --> 00:02:23,090
So we have to depend and viable.

31
00:02:23,140 --> 00:02:24,350
That's first step done.

32
00:02:24,560 --> 00:02:30,860
And then remember the next step after that is to understand with which independent variables you're

33
00:02:30,860 --> 00:02:36,880
going to predict is dependent variable and well all the independent variables are just above.

34
00:02:36,890 --> 00:02:38,720
These are all these ones.

35
00:02:38,720 --> 00:02:45,440
And so basically we're going to predict if a tumor is benign or malignant thanks to 10 independent variables

36
00:02:45,800 --> 00:02:51,620
the one selected here and more precisely we can already see that we want to use probably the simple

37
00:02:51,620 --> 00:02:54,550
code number because this is just an identifier.

38
00:02:54,710 --> 00:02:59,450
And of course this has no impact on whether or not a tumor is malignant.

39
00:02:59,460 --> 00:03:04,140
So more precisely we'll use these nine independent variables.

40
00:03:04,190 --> 00:03:05,180
And so what are they.

41
00:03:05,300 --> 00:03:10,850
Well we have the clum thickness uniformity of cell size uniformity of cell shape.

42
00:03:11,110 --> 00:03:15,050
The marginal adhesion single epithelial cell size.

43
00:03:15,050 --> 00:03:20,570
Forgive me I'm not a doctor but feel free to check on the Internet what this means exactly if you're

44
00:03:20,570 --> 00:03:24,660
interested in knowing more nuclear plants.

45
00:03:24,710 --> 00:03:28,190
Chromatin normal nuclear only and mitosis.

46
00:03:28,190 --> 00:03:35,210
All right so basically these are our nine independent variables which we'll use to understand some correlations

47
00:03:35,630 --> 00:03:41,330
between these and the fact whether or not a tumor in the breast is benign or malignant.

48
00:03:41,330 --> 00:03:47,030
We can see that these variables were already normalized because their range is from 1 to 10 for all

49
00:03:47,030 --> 00:03:47,540
of them.

50
00:03:47,690 --> 00:03:50,650
So that's just a normalization that was done.

51
00:03:50,810 --> 00:03:51,610
That's great.

52
00:03:51,610 --> 00:03:57,200
The data set is some way already partly pre-processed but you'll see that we'll have to do some other

53
00:03:57,200 --> 00:04:01,670
kind of pre-processing which will be related to the following.

54
00:04:01,670 --> 00:04:05,840
We can see and I actually recommend to check that as well.

55
00:04:05,840 --> 00:04:09,110
We can see that there are some missing values.

56
00:04:09,140 --> 00:04:10,060
Yes.

57
00:04:10,130 --> 00:04:17,630
And so I will explain this to toile how we can handle these missing values very efficiently without

58
00:04:17,630 --> 00:04:20,040
losing any significance.

59
00:04:20,420 --> 00:04:20,720
All right.

60
00:04:20,720 --> 00:04:25,320
So to finish just before we get the data sets I'd like to give the full credit.

61
00:04:25,340 --> 00:04:33,560
And thank you to the author the creator Dr. William Walberg from the University of Wisconsin and also

62
00:04:33,560 --> 00:04:36,190
the daughter of the man Ghazarian.

63
00:04:36,440 --> 00:04:37,560
Thank you very much.

64
00:04:37,560 --> 00:04:39,790
And now let's get the data set.

65
00:04:39,890 --> 00:04:45,280
Data sets and data folder and we can see that this time we have many files.

66
00:04:45,500 --> 00:04:51,080
But the one we were interested in is this one breast cancer Wisconsin that data and if we click on it

67
00:04:51,170 --> 00:04:52,630
here is the data set.

68
00:04:52,720 --> 00:04:58,670
So as you can see when I clicked on the link it didn't download a zip file it with a data set in the

69
00:04:58,670 --> 00:05:01,500
Excel file like what we had for regression.

70
00:05:01,520 --> 00:05:09,210
So here what I recommend to do is just to press them in a to select everything then copy and then you

71
00:05:09,210 --> 00:05:16,500
can just open a text editor like for Windows users notepad plus plus or for Mac users Sublime Text or

72
00:05:16,500 --> 00:05:17,540
text in it.

73
00:05:17,590 --> 00:05:24,630
I did that on subcontext open Sublime Text I pasted all this inside it and then what I did is I also

74
00:05:25,160 --> 00:05:26,340
if you come back.

75
00:05:26,460 --> 00:05:31,150
I also got the names here which are at the bottom here.

76
00:05:31,290 --> 00:05:37,050
I added all these names separated by a comma because as you can see the values were separated by a comma

77
00:05:37,470 --> 00:05:44,160
in the data and I added all the attributes in the first line of my text file so that in our final dataset

78
00:05:44,250 --> 00:05:46,640
we can have the names of the attributes.

79
00:05:46,920 --> 00:05:51,960
But then there is another thing that I did which is quite important in the data.

80
00:05:51,960 --> 00:05:57,390
You can notice that we have some missing values and actually it is precise in the days a description

81
00:05:57,960 --> 00:06:05,250
and those missing values are not specified by an empty space or even nothing there are specified by

82
00:06:05,340 --> 00:06:06,690
a question mark.

83
00:06:06,690 --> 00:06:10,140
We can actually find one here.

84
00:06:10,140 --> 00:06:11,170
Here is a question mark.

85
00:06:11,170 --> 00:06:12,960
That's a missing value.

86
00:06:12,990 --> 00:06:17,000
The thing is that in this data set there are very few missing values there.

87
00:06:17,010 --> 00:06:22,470
Only I think 11 of them and there are different ways to handle missing values.

88
00:06:22,470 --> 00:06:28,560
One of them which can actually be very relevant is to ignore the missing values and to do this you simply

89
00:06:28,560 --> 00:06:33,000
need to delete the observations that contain missing values.

90
00:06:33,000 --> 00:06:39,210
And so since there were only 11 missing values here that is 11 observations containing missing values.

91
00:06:39,210 --> 00:06:42,960
Well what I did is I simply removed these observations.

92
00:06:42,960 --> 00:06:49,380
Besides we are dealing with sensitive data about cancer and therefore it could be dangerous to replace

93
00:06:49,590 --> 00:06:54,540
the missing values by something which is another way of handling missing values.

94
00:06:54,540 --> 00:07:01,800
You know you can't replace them by the mean of the values of the future or by the median or by the max

95
00:07:01,800 --> 00:07:02,850
or by the men.

96
00:07:02,850 --> 00:07:09,020
There are several ways of replacing missing values but here for two reasons I chose to ignore them.

97
00:07:09,030 --> 00:07:14,800
First of all because there were very few of them and second reason we are dealing with sensitive data.

98
00:07:15,120 --> 00:07:21,890
So I just did a control f or a comment F on my text editor to find all the question marks and each time

99
00:07:21,890 --> 00:07:27,510
I found a question mark I removed the observations containing the question marks and therefore contained

100
00:07:27,510 --> 00:07:28,660
the missing values.

101
00:07:28,890 --> 00:07:30,580
And then I got the final dataset.

102
00:07:30,750 --> 00:07:33,080
I saved it as a C as well.

103
00:07:33,180 --> 00:07:38,850
And that's how I got the final data set on which we're going to train our classification model which

104
00:07:38,850 --> 00:07:42,360
is great and boosting to solve the challenge.

105
00:07:42,360 --> 00:07:47,410
So I didn't want to do all this in front of you in this tutorial because that could take a while.

106
00:07:47,430 --> 00:07:52,420
You can either do it yourself or just wait for what's going to happen after the end of the Statoil.

107
00:07:52,520 --> 00:07:59,640
You will find an article in which I'm sharing this data set all pre-processed without missing values

108
00:07:59,910 --> 00:08:02,310
and with the names of the variable.

109
00:08:02,490 --> 00:08:08,800
So make sure it either do the same thing or download this preprocess dataset in the tutorial.

110
00:08:08,820 --> 00:08:11,280
After the article to solve the challenge.

111
00:08:11,340 --> 00:08:13,190
Until then enjoy data science.
