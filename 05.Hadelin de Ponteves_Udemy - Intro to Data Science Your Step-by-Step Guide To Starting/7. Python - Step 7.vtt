WEBVTT
1
00:00:04.390 --> 00:00:09.560
Hello and welcome to the final Tauriel of our regression challenge.

2
00:00:09.580 --> 00:00:15.310
So this is the final editorial because basically we have our model ready and trained were trained on

3
00:00:15.310 --> 00:00:21.430
a train set in the previous toil and now in is new to toil we are going to test it on the test set to

4
00:00:21.430 --> 00:00:28.270
see how it reacts to new observations that weren't used for the training that will be very interesting

5
00:00:28.270 --> 00:00:28.890
to see.

6
00:00:29.080 --> 00:00:35.980
And you're going to see how it is so easy to apply a model to predict some new observations because

7
00:00:35.980 --> 00:00:40.060
basically again our model is an object of a class.

8
00:00:40.060 --> 00:00:45.570
The class has several tools remember which are several functions or several methods.

9
00:00:45.640 --> 00:00:51.130
And I told you about the fit method that we saw in the previous Statoil but there is another method

10
00:00:51.370 --> 00:00:56.500
that is used all the time and that is called of course the Predict method.

11
00:00:56.620 --> 00:01:03.700
And as you might guess this is the method we use to predict the outcome of an input so the input doesn't

12
00:01:03.700 --> 00:01:09.550
have to be to test that observations it can be any observation even a new observation which you would

13
00:01:09.550 --> 00:01:10.870
like to know the outcome.

14
00:01:11.080 --> 00:01:16.960
But in our case here in the Statoil the input will be of course the test set observations.

15
00:01:17.320 --> 00:01:23.080
And so what we have to do the only thing that we have to do is basically take our regressors and then

16
00:01:23.080 --> 00:01:28.070
remember to use a method and it adhered to that and then we add the method.

17
00:01:28.150 --> 00:01:31.450
And as we said the method is to predict method.

18
00:01:31.450 --> 00:01:33.010
Then we add some parenthesis.

19
00:01:33.130 --> 00:01:36.050
And here it's important to understand what we have to input.

20
00:01:36.160 --> 00:01:42.570
So for the fit method which was used to train our aggressive to the training set of course we had to

21
00:01:42.650 --> 00:01:48.580
put extra in NY train because they compose the train set and without which when we couldn't figure out

22
00:01:48.580 --> 00:01:53.220
the correlations between the independent variables and the dependent variable.

23
00:01:53.380 --> 00:02:00.410
But here we want to predict the outcome of the test that observations and therefore the only argument

24
00:02:00.430 --> 00:02:07.780
we need to input here is X test because basically the machinery model only needs the independent variables

25
00:02:07.780 --> 00:02:08.840
to predict something.

26
00:02:08.980 --> 00:02:15.970
But then why test will be useful because we will of course compare the predictions to the real results.

27
00:02:15.970 --> 00:02:20.880
That is what we call the ground truth that are contained in Y test.

28
00:02:20.890 --> 00:02:28.240
So here in the method we just need to put our independent variables of the test set which are all included

29
00:02:28.330 --> 00:02:36.310
in X test and since the Predict method applied to X test returns something which you might guess are

30
00:02:36.490 --> 00:02:37.580
the predictions.

31
00:02:37.780 --> 00:02:45.760
Well we are going to introduce here a new variable which we're going to call y pred and that will be

32
00:02:45.760 --> 00:02:50.260
equal to this result returned by the Predict method.

33
00:02:50.260 --> 00:02:51.160
And there we go.

34
00:02:51.160 --> 00:02:54.230
We're already ready to get our predictions.

35
00:02:54.370 --> 00:02:56.470
Again that's the beauty of sikat learn.

36
00:02:56.650 --> 00:03:00.910
We can totally build a model and get some predictions in just a few lines of code.

37
00:03:00.910 --> 00:03:03.160
Can you see only 21 lines of code.

38
00:03:03.160 --> 00:03:04.480
That's amazing.

39
00:03:04.480 --> 00:03:07.650
So let's do this let's get our predictions.

40
00:03:07.660 --> 00:03:10.400
I'm selecting this line of code and here we go.

41
00:03:10.420 --> 00:03:17.940
Let's press command control plus enter to execute and we now have our predictions in white pride.

42
00:03:18.220 --> 00:03:18.900
Perfect.

43
00:03:18.970 --> 00:03:22.760
So congratulations for reaching this we can already see here.

44
00:03:22.900 --> 00:03:28.750
As you can see that our predictions are close to the real results but we're going to see that closer

45
00:03:29.010 --> 00:03:32.460
and to do this I'm first going to open wide test.

46
00:03:32.470 --> 00:03:38.020
I'm going to put that here and then why Pret here is why produce so let's compare them.

47
00:03:38.020 --> 00:03:41.360
I'm just going to put that right here.

48
00:03:41.370 --> 00:03:42.110
There we go.

49
00:03:42.110 --> 00:03:46.120
So this is why test and this is why Pritt So let's see.

50
00:03:46.120 --> 00:03:50.970
First of all of course each line corresponds to the same observation.

51
00:03:50.980 --> 00:03:56.220
So this is a real result and this is the prediction predicted by our model.

52
00:03:56.310 --> 00:04:02.170
And so for the first observation which corresponds to a certain combination of you know temperature

53
00:04:02.260 --> 00:04:06.010
and pressure exerts vacuum and humidity.

54
00:04:06.190 --> 00:04:12.340
Well when we are in the situation with these specific temperature pressure vacuum and humidity we have

55
00:04:12.430 --> 00:04:18.990
the real value of the output energy and the predicted value of the same output energy.

56
00:04:19.060 --> 00:04:25.220
And so for this observation we can see that our prediction is very close to the real value.

57
00:04:25.360 --> 00:04:31.840
And that's amazing because now we are having three figures so just a difference of three here is amazing.

58
00:04:31.840 --> 00:04:34.920
That's a very close prediction compared to the real result.

59
00:04:35.170 --> 00:04:43.800
And then same for the second observation 460 for the real result and 457 for the prediction.

60
00:04:43.900 --> 00:04:51.720
Then again for 161 for the real result and 463 for the prediction.

61
00:04:51.820 --> 00:04:53.410
Then again here that's even better.

62
00:04:53.420 --> 00:04:57.900
Four hundred forty six point nine and 447.

63
00:04:58.090 --> 00:05:03.400
So the predictions are really amazing here that's a little less good but still very good you know if

64
00:05:03.400 --> 00:05:09.900
you compute the difference between the prediction and the real result and divided by the real result

65
00:05:10.260 --> 00:05:14.900
you will see that the error percentage because that's what you'll get is very small.

66
00:05:15.180 --> 00:05:15.470
All right.

67
00:05:15.480 --> 00:05:18.330
And then I don't know we can check some other observations.

68
00:05:18.330 --> 00:05:21.000
Let's take for example the one hundredth one.

69
00:05:21.000 --> 00:05:27.690
So the real result for the one hundred one is 400 and 70 and then check out the prediction

70
00:05:29.880 --> 00:05:32.110
471.

71
00:05:32.160 --> 00:05:33.890
Wow that's really amazing.

72
00:05:33.890 --> 00:05:40.170
So that's what I told you the gradient boosting the aggressor or grading boosting in general and even

73
00:05:40.380 --> 00:05:45.190
the extra boost are one of the best options in machine learning.

74
00:05:45.330 --> 00:05:48.170
If you don't know which machine or any model to choose.

75
00:05:48.330 --> 00:05:54.730
Definitely go for grain boosting or actually boost because they have an amazing predictive power.

76
00:05:54.990 --> 00:05:55.760
So there we go.

77
00:05:55.830 --> 00:05:59.130
Empirically we can see that we have amazing results.

78
00:05:59.220 --> 00:06:00.120
We could check that.

79
00:06:00.150 --> 00:06:02.470
Even better things to some metrics.

80
00:06:02.550 --> 00:06:04.470
But this is quite obvious here.

81
00:06:04.530 --> 00:06:07.270
The predictions are amazing we will need this.

82
00:06:07.290 --> 00:06:13.020
This was just an introduction to bison which at the same time gave you the know how on how to implement

83
00:06:13.100 --> 00:06:15.000
a powerful machinery.

84
00:06:15.270 --> 00:06:21.000
And now we're going to jump to the other challenge which is about classification and therefore we're

85
00:06:21.000 --> 00:06:23.460
going to jump into another industry.

86
00:06:23.640 --> 00:06:25.230
The health industry.

87
00:06:25.420 --> 00:06:30.380
I will not say now what the challenge is about but I can already tell you that this is something you

88
00:06:30.380 --> 00:06:35.760
will be very happy to solve or you will find it meaningful to solve.

89
00:06:35.760 --> 00:06:39.900
So congratulations again for taking the first regression challenge.

90
00:06:39.930 --> 00:06:41.830
And now let's move on to classification.

91
00:06:41.970 --> 00:06:43.910
Until then enjoy the science.
