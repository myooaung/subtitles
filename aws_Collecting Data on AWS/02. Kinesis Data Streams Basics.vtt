WEBVTT
1
00:00:01.240 --> 00:00:04.640
Let's look at a few Kinesis Data Streams basics.

2
00:00:04.640 --> 00:00:06.880
We'll start by looking at producers.

3
00:00:06.880 --> 00:00:08.590
When working with Kinesis Data Streams,

4
00:00:08.590 --> 00:00:10.530
we need to first understand some of the core

5
00:00:10.530 --> 00:00:12.620
concepts around working with streams.

6
00:00:12.620 --> 00:00:16.840
So let's look at them in the order data flows through a Kinesis data stream.

7
00:00:16.840 --> 00:00:19.100
First, we have the concept of a producer.

8
00:00:19.100 --> 00:00:21.700
Similar to other Kinesis family services,

9
00:00:21.700 --> 00:00:23.590
producers, as you might expect,

10
00:00:23.590 --> 00:00:27.410
produce the data we want to stream into a Kinesis data stream.

11
00:00:27.410 --> 00:00:29.950
There are a variety of different producers we can use,

12
00:00:29.950 --> 00:00:33.590
depending on the situation, including the Kinesis Agent,

13
00:00:33.590 --> 00:00:37.440
the Kinesis Producer Library, and the AWS SDKs.

14
00:00:37.440 --> 00:00:41.270
Every time we use the Kinesis Data Streams, we'll need one or more producers.

15
00:00:41.270 --> 00:00:44.160
The producer sends the data into the data stream itself.

16
00:00:44.160 --> 00:00:47.940
So let's look at how a stream itself works.

17
00:00:47.940 --> 00:00:50.450
Streams are the overarching concept that contain the

18
00:00:50.450 --> 00:00:52.510
data being sent in by producers.

19
00:00:52.510 --> 00:00:55.910
But with every Kinesis data stream, it's not quite that simple.

20
00:00:55.910 --> 00:00:59.580
Inside every Kinesis data stream, there are one or more shards.

21
00:00:59.580 --> 00:01:02.140
These shards determine the capacity of the stream to

22
00:01:02.140 --> 00:01:04.880
receive data and the capacity of the stream for that data

23
00:01:04.880 --> 00:01:07.620
to be read by consumers of the data.

24
00:01:07.620 --> 00:01:10.720
AWS replicates and manages those shards across multiple

25
00:01:10.720 --> 00:01:12.650
availability zones in the same region,

26
00:01:12.650 --> 00:01:15.840
so we don't have to manage that process ourselves.

27
00:01:15.840 --> 00:01:18.710
These shards of a stream will each contain records,

28
00:01:18.710 --> 00:01:20.580
which are the underlying unit that data is

29
00:01:20.580 --> 00:01:23.490
transmitted into and read from the streams.

30
00:01:23.490 --> 00:01:27.490
There can be many different formats of data from a variety of different sources,

31
00:01:27.490 --> 00:01:30.600
but all data read from a Kinesis data stream will be sent in

32
00:01:30.600 --> 00:01:34.640
one or more records inside the stream.

33
00:01:34.640 --> 00:01:36.590
After the records are put into a stream,

34
00:01:36.590 --> 00:01:39.550
the stream can be interacted with using a consumer.

35
00:01:39.550 --> 00:01:42.560
Consumers might be one of the Kinesis Client Libraries,

36
00:01:42.560 --> 00:01:45.520
which pairs directly with the Kinesis Producer Library in some

37
00:01:45.520 --> 00:01:49.780
ways or the AWS SDKs, which allow for more customizations in

38
00:01:49.780 --> 00:01:51.430
how you interact with a stream.

39
00:01:51.430 --> 00:01:56.200
However, you might also have other AWS services act as a consumer from a stream.

40
00:01:56.200 --> 00:01:57.060
For example,

41
00:01:57.060 --> 00:01:59.910
Kinesis Data Analytics can be configured to consume and

42
00:01:59.910 --> 00:02:02.440
process data from Kinesis Data Streams.

43
00:02:02.440 --> 00:02:04.300
Now you should have an understanding of some of the

44
00:02:04.300 --> 00:02:11.000
different parts of Kinesis Data Streams. In the next videos, we'll look more at how these parts come back together.

