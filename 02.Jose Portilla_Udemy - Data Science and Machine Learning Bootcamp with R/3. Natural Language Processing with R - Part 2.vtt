WEBVTT
1

00:00:01.350  -->  00:00:05.720
Hello everyone and welcome to natural language processing with our heart too.

2

00:00:05.870  -->  00:00:10.890
In the first part of this video lecture series we went ahead and installed all the packages we needed

3

00:00:10.890  -->  00:00:11.300
.

4

00:00:11.310  -->  00:00:16.780
Then we set up our Twitter account and we also set up our application developer Twitter account.

5

00:00:16.980  -->  00:00:23.160
Also we got our consumer key or consumer secret key in our access token and our secret access token

6

00:00:23.160  -->  00:00:28.860
codes you'll need this code for all four of these codes to continue on part two in order to connect

7

00:00:28.860  -->  00:00:33.350
to Twitter through our let's go ahead and jump to our studio and get started.

8

00:00:33.630  -->  00:00:40.410
OK here we are our studio our first step in creating the word cloud or data mining Twitter first some

9

00:00:40.830  -->  00:00:44.870
text data is to actually import all the libraries we're going to be using.

10

00:00:45.000  -->  00:00:53.280
We're going to first off use the Twitter library then we'll need to call library again on T.M. which

11

00:00:53.280  -->  00:00:56.800
will allow us to actually work with the text data and manipulate it.

12

00:00:57.350  -->  00:01:02.240
Then the next library are going to need is the word cloud library.

13

00:01:03.270  -->  00:01:08.400
And then finally we'll also need the our color library which will allow us to easily color that word

14

00:01:08.400  -->  00:01:09.940
cloud.

15

00:01:10.020  -->  00:01:16.800
Next we want to actually connect to Twitter in order to do this.

16

00:01:16.920  -->  00:01:22.620
You're going to call the following function set up underscore Twitter underscore.

17

00:01:22.980  -->  00:01:29.490
And this basically allows you to set up your authorization to Twitter to do this you'll need a pass in

18

00:01:29.610  -->  00:01:31.370
your consumer key.

19

00:01:31.590  -->  00:01:40.320
I already saved this as the key your consumer secret key aready say as Eski then you'll need your access

20

00:01:40.380  -->  00:01:47.220
token already say this as token and then you'll need your secret token again just to clarify these are

21

00:01:47.220  -->  00:01:48.110
variables.

22

00:01:48.240  -->  00:01:53.850
But before actually started recording this video I said each of these variables as a string containing

23

00:01:54.090  -->  00:01:59.160
the long series of characters and numbers from part 1 of this lecture series.

24

00:01:59.280  -->  00:02:07.410
So go ahead and put in your secret key or consumer key and then your token and your secret token once

25

00:02:07.410  -->  00:02:11.280
you've connected to Twitter what you should be able to do is search Twitter.

26

00:02:11.280  -->  00:02:19.110
Let's go ahead and search for the term Soccer and grab a bunch of tweets that have the word soccer in

27

00:02:19.110  -->  00:02:19.970
them.

28

00:02:20.250  -->  00:02:25.710
I can use the search Twitter function from the Twitter library.

29

00:02:26.790  -->  00:02:28.890
I put in the term that I want to search for.

30

00:02:28.890  -->  00:02:31.140
I'm going to go ahead and search for soccer.

31

00:02:31.140  -->  00:02:38.490
I'm going to go ahead and grab one thousand tweets and I want to grab them in the English language which

32

00:02:38.490  -->  00:02:44.160
I can say by the end and there's a bunch of other really cool stuff you can do of search Twitter.

33

00:02:44.160  -->  00:02:48.670
Go ahead and say Help search Twitter in case you want to pass and more parameters.

34

00:02:48.690  -->  00:02:53.010
You can do things like geographical location latitude and longitude.

35

00:02:53.190  -->  00:02:56.970
Set a radius from allotted and longitude to only see geographical regions.

36

00:02:57.060  -->  00:03:00.070
So other languages are set dates if you want to.

37

00:03:00.120  -->  00:03:01.300
There's a lot of options there.

38

00:03:01.350  -->  00:03:02.810
So go ahead and play around them.

39

00:03:03.060  -->  00:03:07.700
Right now we're basically just asking for the most recent 1000 tweets that had soccer in them.

40

00:03:07.710  -->  00:03:14.460
There were also in English then we we're going to do is go ahead and get the text out of those tweets

41

00:03:14.460  -->  00:03:14.790
.

42

00:03:14.790  -->  00:03:24.240
This is going to return some tweet data and we want the text from that data and want to make a new variable

43

00:03:24.240  -->  00:03:34.620
called Soccer text and I'm going to call as supply person my soccer tweets which is essentially a list

44

00:03:35.370  -->  00:03:44.100
of this tweet or object and I can do something a little special of this object which is just grab the

45

00:03:44.850  -->  00:03:50.360
get text method off of it.

46

00:03:50.430  -->  00:04:04.590
So this is returning tweets and this is grabbing text data from tweets and we're using basically a quick

47

00:04:04.590  -->  00:04:08.790
anonymous function to do this easily.

48

00:04:08.790  -->  00:04:12.060
Once we have the text data we want to do is clean the text data

49

00:04:17.550  -->  00:04:24.750
in this step we're going to remove emoticons and then create a corpus and going to go ahead and call

50

00:04:24.750  -->  00:04:25.920
soccor text again

51

00:04:28.790  -->  00:04:36.310
and and then don't call the I see on a V function which is basically an encoding function.

52

00:04:36.480  -->  00:04:43.140
If you're not super familiar with text encodings such as UTF 8 basically or are going to be doing is

53

00:04:43.140  -->  00:04:48.490
making sure to remove emoticons and characters that are not in UTF 8.

54

00:04:48.540  -->  00:04:55.940
That way we don't have errors if there's weird symbols or accent marks over the ears etc..

55

00:04:56.280  -->  00:05:09.710
I'm going to go ahead and pass in soccer text pasan UTF dash 8 as one in including calls and then S

56

00:05:09.830  -->  00:05:16.470
C I and this will essentially just remove the emoticons and any other data that we can't really work

57

00:05:16.470  -->  00:05:17.760
with as far as text data

58

00:05:21.370  -->  00:05:23.490
then I'm going to create a soccer corpus

59

00:05:26.070  -->  00:05:29.170
and this is all using the T.M. library.

60

00:05:29.740  -->  00:05:35.460
We're going to call corpus and then vector source which just creates a vector source from the text data

61

00:05:35.460  -->  00:05:40.490
.

62

00:05:40.500  -->  00:05:43.770
All right we have our sacred text and we have our soccor corpus.

63

00:05:43.770  -->  00:05:46.810
Next we're going to do is create a document term matrix

64

00:05:52.680  -->  00:05:56.930
and you can go ahead and reference the notes in case you want more details about these functions.

65

00:05:57.090  -->  00:06:00.800
Or just call help on these functions themselves.

66

00:06:00.810  -->  00:06:06.330
Let's go ahead and apply some transformations using the term document matrix function.

67

00:06:06.390  -->  00:06:09.480
I'm going to create an object called term dot matrix

68

00:06:12.060  -->  00:06:15.990
and the function I'm going to call is a term document matrix.

69

00:06:16.060  -->  00:06:17.590
I pass in my corpus

70

00:06:20.400  -->  00:06:29.320
and then I'm going to pass in an argument control and control is going to take a list and it is essentially

71

00:06:29.310  -->  00:06:35.340
going to be a list of actions to do on every document in that corpus.

72

00:06:35.400  -->  00:06:37.590
First thing to do is remove punctuation

73

00:06:41.230  -->  00:06:43.370
and I'm going to set that equal to true.

74

00:06:43.370  -->  00:06:45.880
It's basically saying yes remove punctuation.

75

00:06:46.380  -->  00:06:52.320
And then I'm going to put in stop words stop words are just really common words that you're going to

76

00:06:52.320  -->  00:06:54.970
have to remove words such as the.

77

00:06:54.960  -->  00:06:56.640
Or he or she.

78

00:06:56.680  -->  00:06:58.990
Those are words that don't add too much information.

79

00:06:59.040  -->  00:07:01.120
We're going to go ahead and remove them.

80

00:07:01.480  -->  00:07:06.350
That means we're going to pass in a vector of words we want to remove one of the words I want our move

81

00:07:06.370  -->  00:07:13.590
is soccer because if I just ask for soccer my word cloud is going to have a huge soccer word in it.

82

00:07:13.830  -->  00:07:16.270
I want the words that are associated with soccer.

83

00:07:16.530  -->  00:07:19.080
We can go ahead and remove that.

84

00:07:20.440  -->  00:07:26.650
And then I can also use the Stoppard's function itself and pass an English to remove common English

85

00:07:26.700  -->  00:07:29.040
Stop words.

86

00:07:32.010  -->  00:07:38.850
And then I want to also remove numbers so that equal to true.

87

00:07:39.630  -->  00:07:42.370
And then I also want to lower everything.

88

00:07:42.390  -->  00:07:44.910
So say two lower equals.

89

00:07:44.910  -->  00:07:47.170
True.

90

00:07:47.310  -->  00:07:47.700
All right.

91

00:07:47.910  -->  00:07:51.940
Let me break this down over time as to what actually is happening here.

92

00:07:52.080  -->  00:07:59.170
We're taking advantage of this library that T.M. library which is made for a text manipulation or creating

93

00:07:59.190  -->  00:08:05.040
a term Dockett matrix or a document matrix with the term document matrix function.

94

00:08:05.040  -->  00:08:10.150
We pass in the corpus we made it which we're able to do if corpus and vector source off of that Texada

95

00:08:10.620  -->  00:08:15.940
and then we pass in this control parameter which is just a list of operations we want to do.

96

00:08:16.000  -->  00:08:20.020
We're going to remove the punctuation remove any stop words.

97

00:08:20.100  -->  00:08:23.870
In this case soccer is included along with the normal English Stoppard's.

98

00:08:24.000  -->  00:08:29.800
We're going to remove numbers and then we're going to say two lower equals true and all of these calls

99

00:08:29.860  -->  00:08:35.260
are just functions that are included in the T.M. library.

100

00:08:35.250  -->  00:08:41.590
Let's go ahead and move along.

101

00:08:41.880  -->  00:08:48.540
We're going to convert the object into a matrix.

102

00:08:48.540  -->  00:08:56.410
And what I mean by that is this term dot dot matrix doesn't actually come back as a matrix in R.

103

00:08:56.470  -->  00:09:05.350
So we're going to go ahead and do is say as Matrix and pass it in.

104

00:09:06.780  -->  00:09:09.520
Then what we want to do is get the word counts

105

00:09:12.150  -->  00:09:17.000
in order to get information into our word cloud function.

106

00:09:17.130  -->  00:09:30.100
I'm going to set up a variable called word frequency or word freak and I'm going to sorts row sums of

107

00:09:30.100  -->  00:09:42.510
the term doc matrix and we'll go ahead and say decreasing equals true or capital-T which as we know

108

00:09:42.500  -->  00:09:43.910
is the same thing.

109

00:09:44.110  -->  00:09:54.370
And then I'm going to call it data frame and say the column word is equal to the names of word frequency

110

00:09:56.160  -->  00:10:05.770
and the frequency or the freq column of r e q is just equal to word frequency.

111

00:10:06.180  -->  00:10:12.260
And basically what is doing is creating a data frame with all the words and their counts.

112

00:10:12.660  -->  00:10:19.710
And then after that they can finally create the word cloud and hopefully it turns up well.

113

00:10:19.770  -->  00:10:23.740
So it is a little hard to tell if you're going to get a good result here because this is just getting

114

00:10:23.740  -->  00:10:28.710
Twitter live but hopefully it works out for us.

115

00:10:28.810  -->  00:10:38.970
We'll go ahead and pasand the word column in the frequency column that we just created and we'll specify

116

00:10:38.970  -->  00:10:41.810
that random order is equal to false

117

00:10:44.630  -->  00:10:50.460
it let's go ahead and say colors equals better pal.

118

00:10:50.560  -->  00:10:52.590
And this is from the color of our library.

119

00:10:52.880  -->  00:10:59.200
I'm going to go ahead and just choose one of these dark too and you can go ahead and check out the documentation

120

00:10:59.200  -->  00:11:00.300
for word cloud.

121

00:11:00.460  -->  00:11:06.770
In order to explore different color schemes Let's go ahead and see if this all worked out.

122

00:11:06.800  -->  00:11:09.010
I'm going to go ahead and run the source.

123

00:11:09.100  -->  00:11:14.770
But before I do I'm just going to expand the actual plot window we're going to be seeing this from.

124

00:11:14.830  -->  00:11:15.310
Hopefully

125

00:11:19.210  -->  00:11:25.630
you may get a prompt here asking you whether or not you want to use direct authentication that's going

126

00:11:25.630  -->  00:11:27.780
to say 1 for yes 2 for no.

127

00:11:27.910  -->  00:11:30.240
Go ahead and say one.

128

00:11:30.810  -->  00:11:35.740
This may take a little bit of time depending on your interconnect internet connection and in your ability

129

00:11:35.740  -->  00:11:39.710
to grab data from Twitter.

130

00:11:39.760  -->  00:11:40.080
OK.

131

00:11:40.090  -->  00:11:42.900
So here is our word cloud.

132

00:11:42.970  -->  00:11:49.350
Unfortunately if we just look at this we can kind of tell that there's some words that it just show

133

00:11:49.350  -->  00:11:50.510
up too often.

134

00:11:50.620  -->  00:11:55.270
And there's word sources just played and it's probably because people are tons of people are tweeting

135

00:11:55.270  -->  00:12:00.340
out just played soccer and there that's going to heavily weigh out these words.

136

00:12:00.550  -->  00:12:05.470
And you also notice that there's a lot of h t t p s and that's because a lot of people are putting links

137

00:12:05.830  -->  00:12:08.610
into their tweets which you'll probably have to remove.

138

00:12:08.830  -->  00:12:13.510
Let's go ahead and try searching for another word and then we'll review everything and break it down

139

00:12:13.510  -->  00:12:14.040
.

140

00:12:14.080  -->  00:12:20.440
I'm going to go ahead and remove this color scheme because it wasn't too helpful in our case.

141

00:12:20.440  -->  00:12:30.040
Let's go ahead and in the Stop words put in t p s that way that goes in that vector.

142

00:12:30.130  -->  00:12:37.450
We'll just put h t t p and then we'll also search for another term instead of soccer.

143

00:12:37.450  -->  00:12:43.720
Let's go with something like Python

144

00:12:46.990  -->  00:12:49.150
which is another programming language.

145

00:12:49.150  -->  00:12:54.250
Let's go ahead and see if we get more results about snakes or more results about the programming language

146

00:12:54.250  -->  00:12:54.590
.

147

00:12:54.640  -->  00:12:58.350
I want to go ahead and run source again.

148

00:12:59.870  -->  00:13:02.740
And there we have our word cloud.

149

00:13:02.740  -->  00:13:09.100
Now something we forgot to do is actually change the stop where it's remove python instead of soccer

150

00:13:09.120  -->  00:13:09.750
.

151

00:13:10.240  -->  00:13:15.680
You can go ahead and add that in and try calling this one more time.

152

00:13:17.080  -->  00:13:19.980
And then we get a result which is actually a little surprising.

153

00:13:19.990  -->  00:13:27.100
We get Monty Python as one of the top results and then we get programming the animal game Java other

154

00:13:27.100  -->  00:13:30.050
languages javascript's eggs etc..

155

00:13:30.580  -->  00:13:35.980
I encourage you to go ahead and play around with this maybe search for new terms or add in your arguments

156

00:13:35.980  -->  00:13:37.130
and search Twitter.

157

00:13:37.150  -->  00:13:39.210
Check out the free languages etc..

158

00:13:39.250  -->  00:13:43.990
Right now we're going to take a step back and look at everything we just did because we used a lot of

159

00:13:43.990  -->  00:13:49.540
really specialized functions in this and I want to go have a brief overview of what they were each actually

160

00:13:49.540  -->  00:13:50.590
doing.

161

00:13:50.590  -->  00:13:56.080
You don't need to understand all these functions completely but you should be able to understand them

162

00:13:56.080  -->  00:14:00.060
enough that you can reference the documentation for all of them.

163

00:14:00.070  -->  00:14:02.960
Let's start off at the very top and work our way back down.

164

00:14:02.960  -->  00:14:09.020
We're going to shrink the council that the very first thing we did was call all the libraries.

165

00:14:09.460  -->  00:14:16.810
Then we connected to Twitter using our He's in our tokens and our secret keys are secret tokens then

166

00:14:16.810  -->  00:14:21.750
we use the search Twitter function to search for soccer or Python later on.

167

00:14:21.760  -->  00:14:24.610
You can see that the number of tweets you want to return back to languages.

168

00:14:24.730  -->  00:14:29.320
Now I encourage you to actually search the documentation or search Twitter and play around with the

169

00:14:29.320  -->  00:14:31.780
different parameters you can pasan.

170

00:14:31.780  -->  00:14:34.700
Then we grabbed the text data from the tweets.

171

00:14:34.750  -->  00:14:40.350
Basically these Socred tweets have an object in them that you can grab called Get text that returns

172

00:14:40.350  -->  00:14:43.120
a text from that tweet data.

173

00:14:43.120  -->  00:14:51.380
Then we went ahead and cleaned the data to only grab UTF 8 encoded characters.

174

00:14:51.430  -->  00:14:57.070
Then we went ahead and used corpus and vector source from the T.M. library to create a corpus of all

175

00:14:57.070  -->  00:14:58.550
those text documents.

176

00:14:58.690  -->  00:15:03.430
And then in this kind of really important step we did the document turned matrix and this basically

177

00:15:03.430  -->  00:15:09.760
took advantage of T.M. library in order to perform a bunch of transformations on the text.

178

00:15:09.760  -->  00:15:15.760
We removed the punctuation we removed the stop words we removed the numbers from them and then we lowercase

179

00:15:15.940  -->  00:15:17.680
all the words.

180

00:15:17.680  -->  00:15:24.610
Then we just converted that object to a matrix then we got the word counts by adding up the counts in

181

00:15:24.620  -->  00:15:29.410
that term document matrix and then we created a data frame which basically has the word in how many

182

00:15:29.410  -->  00:15:31.600
times it showed up the frequency.

183

00:15:31.610  -->  00:15:35.150
And with that information you can quickly and easily create a word cloud.

184

00:15:35.170  -->  00:15:40.020
We try to color it but sometimes it doesn't look too nice so you can just go ahead and skip the coloring

185

00:15:40.030  -->  00:15:41.530
scheme.

186

00:15:41.530  -->  00:15:45.020
All right I hope you found that fun and interesting.

187

00:15:45.070  -->  00:15:49.920
Obviously this is something you can go ahead and put in a bunch of search terms play around this sort

188

00:15:49.930  -->  00:15:54.100
of search Twitter function a lot and see what else you can come up with.

189

00:15:54.110  -->  00:15:56.020
Thanks everyone and I'll see you at the next lecture
