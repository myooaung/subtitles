WEBVTT
1

00:00:00.840  -->  00:00:05.810
Hello everyone and welcome to the Kinnear's Neighbors Project solution's lecture this lecture.

2

00:00:05.820  -->  00:00:09.480
We're going to be going through the solutions for the Kinnear's Neighbors Project.

3

00:00:09.480  -->  00:00:11.750
Let's go ahead and jump to our studio and get started.

4

00:00:11.910  -->  00:00:12.380
OK.

5

00:00:12.420  -->  00:00:14.130
Here we are in our studio.

6

00:00:14.130  -->  00:00:22.830
I'm going to go ahead and start off by calling library SLR and then checking out the head of the iris

7

00:00:22.830  -->  00:00:30.890
dataset and let me shrink this a little bit and run this again.

8

00:00:31.240  -->  00:00:31.800
OK.

9

00:00:31.980  -->  00:00:33.550
Hopefully you're able to get that far.

10

00:00:33.570  -->  00:00:35.130
It's just checking out their data set.

11

00:00:35.160  -->  00:00:40.920
Like I mentioned in the previous lecture this is a data set that tries to basically predict the species

12

00:00:41.240  -->  00:00:42.630
of the iris flower.

13

00:00:42.810  -->  00:00:51.700
There's the Tosa virginica and versicolor next case or next step after this was to actually standardize

14

00:00:51.700  -->  00:00:53.060
the data.

15

00:00:53.370  -->  00:01:01.820
We'll go ahead and just put a newline script and we'll say scale the data.

16

00:01:01.840  -->  00:01:04.410
This is a really important step with Kinnear's neighbors.

17

00:01:04.770  -->  00:01:11.430
Everything in the state of frame or this data set is actually pretty OK as far as the same scale maybe

18

00:01:11.460  -->  00:01:16.210
pedal with is a little smaller but a magnet order Magas is smaller than everything else.

19

00:01:16.350  -->  00:01:21.750
But this is a data framework will it make a huge difference and not scale the data but just we're in

20

00:01:21.750  -->  00:01:25.650
the mode of scaling data whenever you're going to use Kinnear's neighbors.

21

00:01:25.650  -->  00:01:30.930
Let's go ahead and use scale to standardize the feature columns.

22

00:01:30.930  -->  00:01:39.270
I'm going to make a new variable called Stand features and then it is going to cost scale and scale

23

00:01:39.270  -->  00:01:39.810
function.

24

00:01:39.840  -->  00:01:48.000
I'm going just going to pasan Iris columns 1 through 4 and then I'm going to go ahead and print the

25

00:01:48.000  -->  00:01:58.770
variance lips of standard features make sure it all worked out and let me actually describe the variance

26

00:01:58.800  -->  00:02:03.460
of one of these guys should be one that all makes sense.

27

00:02:03.510  -->  00:02:06.750
Looks like the variance is one along the diagonal and that's perfect.

28

00:02:06.750  -->  00:02:08.410
That's exactly what we want.

29

00:02:09.000  -->  00:02:13.890
Let's go ahead and join the standardized data with the response target or label column whatever you

30

00:02:13.890  -->  00:02:15.550
want to call it.

31

00:02:15.720  -->  00:02:23.960
It's basically the column with the species name on it to make a variable called final data.

32

00:02:24.450  -->  00:02:29.160
And then you see bind or column bind to say Stand-Up features

33

00:02:31.920  -->  00:02:35.710
and then join the fifth column of the iris dataset.

34

00:02:35.850  -->  00:02:42.000
That means I'm taking the scaled version of my data and joining it back with the original label which

35

00:02:42.000  -->  00:02:44.260
makes sense because we don't want to scale or label.

36

00:02:44.280  -->  00:02:48.000
In fact we can't scale or label it's just a words Tosa.

37

00:02:48.420  -->  00:02:54.780
Then we're going to go ahead and do the train test splits.

38

00:02:54.780  -->  00:03:01.800
Hopefully these various assignments we had to do were pretty easy for you and we put some new lines

39

00:03:01.800  -->  00:03:02.440
here.

40

00:03:02.760  -->  00:03:06.260
The train splits I went ahead and set C to 101.

41

00:03:06.270  -->  00:03:10.290
That way if you're following along you get the same splits I do.

42

00:03:10.290  -->  00:03:17.230
We're going to go ahead and call CAA tools and then we have our three lines that we always do.

43

00:03:17.250  -->  00:03:18.570
We say sample that split

44

00:03:21.180  -->  00:03:24.480
pass in a column from our data set.

45

00:03:24.480  -->  00:03:27.300
In this case our data set is final data.

46

00:03:27.390  -->  00:03:34.230
I always like to pass in the column that we're trying to predict this case it should be called species

47

00:03:34.230  -->  00:03:34.280
.

48

00:03:34.300  -->  00:03:35.040
Let's make sure

49

00:03:38.880  -->  00:03:46.710
and then I'm going to say split ratio of 0.7 that way 70 percent of my data is going to be sample it

50

00:03:46.740  -->  00:03:49.710
was true and I will set that as my training data

51

00:03:57.950  -->  00:03:59.320
goinge tippity there.

52

00:03:59.340  -->  00:04:01.720
And let's do the same for a test.

53

00:04:02.100  -->  00:04:08.450
A subset final data take a sample.

54

00:04:08.660  -->  00:04:10.190
That's where it's equal to false.

55

00:04:10.230  -->  00:04:15.140
And then we're going to do is actually build the model and go in a little fast here.

56

00:04:15.150  -->  00:04:20.760
But hopefully this was all pretty straightforward for you because it's basically exactly what we just

57

00:04:20.760  -->  00:04:24.780
did in the previous lecture.

58

00:04:24.900  -->  00:04:31.440
We're going to go ahead and call library class and then we're going to use the k and a function to predict

59

00:04:31.440  -->  00:04:35.510
the species of the test set with equal to 1.

60

00:04:35.610  -->  00:04:40.250
And this is the main step that I really want you to basically have down.

61

00:04:40.260  -->  00:04:46.140
You're going to go ahead and make some variable in this case we'll call it predict that species you

62

00:04:46.140  -->  00:04:52.830
call the K and end function and then you pass in for things you pass in your training data.

63

00:04:52.830  -->  00:05:00.240
Your test data the label of your training data and then the value ones and you can actually see here

64

00:05:00.720  -->  00:05:04.570
that our studio helps you out by reminding you the order train test.

65

00:05:04.570  -->  00:05:09.140
C L K equals 1 etc..

66

00:05:09.390  -->  00:05:13.590
I'm going to say train columns 1 through four.

67

00:05:13.590  -->  00:05:23.000
The actual training data that I want my test data columns 1 through four that I want the labels of my

68

00:05:23.000  -->  00:05:27.290
train data in this case that is species.

69

00:05:28.040  -->  00:05:29.860
And then I specify what value I want.

70

00:05:29.870  -->  00:05:35.210
We'll go ahead and start off of Keiko's one and then let's go ahead and Prince predicted species just

71

00:05:35.210  -->  00:05:36.350
to make sure the salt worked out

72

00:05:39.330  -->  00:05:40.090
okay perfect.

73

00:05:40.100  -->  00:05:47.420
We have to predict the species for that test set where we're going to do now is just see what our misclassification

74

00:05:47.420  -->  00:05:48.340
rate was.

75

00:05:48.380  -->  00:05:55.400
We can do that by following the example I showed in the previous lecture where it's just the mean of

76

00:05:57.560  -->  00:06:02.970
test species not equal to the predicted species value.

77

00:06:03.170  -->  00:06:04.130
Let's go ahead and run that.

78

00:06:04.120  -->  00:06:10.000
Check it out at our misclassification rate is about 4.4 4 4 percent not so bad.

79

00:06:10.000  -->  00:06:12.820
But again remember this is a really small data set.

80

00:06:12.970  -->  00:06:16.490
We're going to go ahead and do now is choose a k value.

81

00:06:16.790  -->  00:06:21.230
And this is essentially the other half that I really want to understand and have down

82

00:06:24.290  -->  00:06:28.590
and we're going to do this by plotting out the values.

83

00:06:29.360  -->  00:06:35.880
I'm going to go ahead and say predicted that species is no.

84

00:06:36.920  -->  00:06:41.370
And then the error rates is no.

85

00:06:42.560  -->  00:06:49.950
Then I'll say for I in 1 through 10.

86

00:06:50.220  -->  00:06:56.300
So the seed to 101 just to make sure if there's any rain the variations will be the same for you and

87

00:06:56.300  -->  00:07:06.690
me if you're following along and I will grab the predicted species and set it equal to my Canon function

88

00:07:06.690  -->  00:07:07.840
.

89

00:07:08.620  -->  00:07:13.000
I will call a train on the features columns 1 through 4.

90

00:07:13.090  -->  00:07:16.700
I will pass in my test data columns one for the features

91

00:07:21.110  -->  00:07:30.650
then I will go ahead and grab train species and set K equal to I

92

00:07:35.150  -->  00:07:38.080
and then I'll say error rate.

93

00:07:39.490  -->  00:07:46.080
I is mean of the test species

94

00:07:48.740  -->  00:07:55.260
not equal to predicted species.

95

00:07:56.470  -->  00:08:07.500
Then we're going to go ahead and plot this out for the elbow method.

96

00:08:07.940  -->  00:08:12.220
We'll go ahead and call library G-G plots 2.

97

00:08:12.800  -->  00:08:18.950
And just like we did in the previous lecture to quickly make a data frame our values these are 1 through

98

00:08:18.950  -->  00:08:19.860
10 member.

99

00:08:19.880  -->  00:08:33.920
This should match the values used here then we'll say error that T.F. data frame passen error rates

100

00:08:34.700  -->  00:08:39.950
and then pass in the K values.

101

00:08:41.240  -->  00:08:44.160
And once that's done we're actually plot the data.

102

00:08:44.320  -->  00:08:52.100
You can go ahead and say people Ju-Ju plot in this case my data frame is error that the F and I want

103

00:08:52.100  -->  00:08:59.590
to pass x as equal to k values and Y is equal to error rate.

104

00:08:59.650  -->  00:09:02.360
And you don't have to indicate sequel's or white girls.

105

00:09:02.360  -->  00:09:05.480
I understand that to be a little more clear.

106

00:09:05.500  -->  00:09:13.460
Well go ahead make a scatterplot and then I'm going to go ahead and also add a dotted line to that just

107

00:09:13.460  -->  00:09:24.020
like we did in the previous lecture will say L T Y which is the line style is equal to dotted and then

108

00:09:24.010  -->  00:09:27.690
we'll say color is equal to red.

109

00:09:28.340  -->  00:09:30.720
Then we'll go ahead and finally print out that plot.

110

00:09:30.800  -->  00:09:35.340
Let's see if this all worked out for us.

111

00:09:35.550  -->  00:09:40.590
What's scootch this overside and zoom in.

112

00:09:41.510  -->  00:09:42.080
OK.

113

00:09:42.260  -->  00:09:48.550
If you can't see this let me go ahead and make the line just a little thicker and we'll go ahead and

114

00:09:48.880  -->  00:09:56.180
add a size argument to this going to go ahead and say size equal to.

115

00:09:56.170  -->  00:10:00.180
Let's try to that maybe a little too thick but we'll see.

116

00:10:00.200  -->  00:10:03.490
Look at this isover zoom in on it.

117

00:10:03.590  -->  00:10:03.950
All right.

118

00:10:04.020  -->  00:10:12.950
But do we notice here your error rate drops down when youre increasing to from 1 K to cake to and essentially

119

00:10:12.950  -->  00:10:16.000
stays the same all the way up to around 6.

120

00:10:16.040  -->  00:10:20.240
It shoots back up again for a higher K and then shoots back down.

121

00:10:20.300  -->  00:10:26.240
However he should know that the actual range of your error rate is quite small overall will either drop

122

00:10:26.240  -->  00:10:32.420
down to about zero point or excuse me about 1 percent misclassification rate all the way up to around

123

00:10:32.410  -->  00:10:34.430
6 percent misclassification rate.

124

00:10:34.550  -->  00:10:40.070
Looks like our optimal k value should be somewhere around 2 to 6 ish.

125

00:10:40.070  -->  00:10:44.570
Let's go ahead and just call it 3 as the optimal k we should choose.

126

00:10:44.840  -->  00:10:49.440
Again the reason we get kind of this funky behavior is that the data is just too small.

127

00:10:49.460  -->  00:10:54.780
It doesn't have that many observations in it for us to really use the elbow method effectively.

128

00:10:55.370  -->  00:10:56.390
OK.

129

00:10:56.380  -->  00:10:57.700
I hope that was helpful to you.

130

00:10:57.710  -->  00:11:02.770
Go ahead and review the notebook if you want to look through any of this code.

131

00:11:02.780  -->  00:11:08.270
But again the main idea is just scale the data do the train test splits.

132

00:11:08.510  -->  00:11:14.770
Remember how to use the KNM function from the class library choose the K value by running this for loop

133

00:11:15.160  -->  00:11:19.220
and then plot out the data for the method to figure out what's the best Katis.

134

00:11:19.220  -->  00:11:21.970
All right thanks everyone and I'll see you at the next lecture
