WEBVTT
1
00:00:00.840 --> 00:00:01.280
[Autogenerated] all right.

2
00:00:01.280 --> 00:00:03.580
And this brings us to data firehose.

3
00:00:03.580 --> 00:00:04.740
So we just got done.

4
00:00:04.740 --> 00:00:08.320
Looking at Cannes is is data streams and how we can use those.

5
00:00:08.320 --> 00:00:10.760
So let's move on to data fire host now,

6
00:00:10.760 --> 00:00:15.070
Data firehose is another fully managed service that allows

7
00:00:15.070 --> 00:00:19.240
for real time data delivery within a W S.

8
00:00:19.240 --> 00:00:23.410
It provides output to data sources like S3,

9
00:00:23.410 --> 00:00:28.040
red shift, elastic search and even Splunk.

10
00:00:28.040 --> 00:00:31.680
So if you're needing to output all of your records and stream

11
00:00:31.680 --> 00:00:35.310
data to some type of storage destination data,

12
00:00:35.310 --> 00:00:37.940
firehose is probably your best bet.

13
00:00:37.940 --> 00:00:38.290
Now,

14
00:00:38.290 --> 00:00:43.360
the cool thing about data firehose minus the massive amounts of data that it

15
00:00:43.360 --> 00:00:47.880
can stream in real time is that it can also output raw data.

16
00:00:47.880 --> 00:00:52.040
Or it can transform data before delivering.

17
00:00:52.040 --> 00:00:55.430
So we can perform data transformation on a record

18
00:00:55.430 --> 00:00:58.940
before its output to are S3 buckets, for example.

19
00:00:58.940 --> 00:01:00.270
That's a pretty cool feature.

20
00:01:00.270 --> 00:01:03.680
Now the last thing I want to talk about here is that it stores

21
00:01:03.680 --> 00:01:07.840
data up to 24 hours in case of delivery failures.

22
00:01:07.840 --> 00:01:11.290
So this is similar to data streams where we have a retention

23
00:01:11.290 --> 00:01:15.060
period that allows for replay of failed processing.

24
00:01:15.060 --> 00:01:17.500
So let's go ahead and take a look at an example.

25
00:01:17.500 --> 00:01:20.640
Architecture of data Firehose.

26
00:01:20.640 --> 00:01:24.810
Now here we have a python application running on Niecy to instance,

27
00:01:24.810 --> 00:01:27.040
and this is similar to our previous one,

28
00:01:27.040 --> 00:01:30.240
where we use a Java application in the diagram,

29
00:01:30.240 --> 00:01:33.490
and it's putting records into our data firehose.

30
00:01:33.490 --> 00:01:35.700
Now this would be a massive amount of data that's

31
00:01:35.700 --> 00:01:37.520
getting put in more than likely.

32
00:01:37.520 --> 00:01:39.550
And on the back end here,

33
00:01:39.550 --> 00:01:43.830
you can see that we don't have a traditional consumer like we do with data.

34
00:01:43.830 --> 00:01:48.140
Streams were actually putting records that are transformed

35
00:01:48.140 --> 00:01:52.440
within data firehose into elastic search service,

36
00:01:52.440 --> 00:01:55.840
which allows us to do some processing and analytics.

37
00:01:55.840 --> 00:02:01.020
But what's nice is we can store the raw source records in an S3 bucket,

38
00:02:01.020 --> 00:02:05.540
as well as any failed records that failed to process.

39
00:02:05.540 --> 00:02:09.250
So it allows us to have a backup of our data that comes

40
00:02:09.250 --> 00:02:12.240
in so we can see what's going on.

41
00:02:12.240 --> 00:02:15.710
So this is one of the key benefits to data fire hoses,

42
00:02:15.710 --> 00:02:20.510
the multiple outputs and the data transformation that comes along with it.

43
00:02:20.510 --> 00:02:21.350
So with that,

44
00:02:21.350 --> 00:02:30.000
let's go ahead and we'll wrap this clip up here and we'll pick up in the console in the next clip and we'll start looking at data firehose

