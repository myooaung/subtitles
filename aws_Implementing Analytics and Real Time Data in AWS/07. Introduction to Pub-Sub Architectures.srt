1
00:00:00,940 --> 00:00:05,390
[Autogenerated] All right, So now that were experts and sqs and s and s.

2
00:00:05,390 --> 00:00:09,240
This allows us to talk about pubs, apps, architectures.

3
00:00:09,240 --> 00:00:13,340
Now pub sub, which is short for publish and subscribe,

4
00:00:13,340 --> 00:00:17,700
is an asynchronous service to service communication that's used

5
00:00:17,700 --> 00:00:21,540
within services in microsurgery is architectures.

6
00:00:21,540 --> 00:00:26,290
So any message published to an SNS topic is received by

7
00:00:26,290 --> 00:00:29,740
multiple subscriptions to that topic.

8
00:00:29,740 --> 00:00:31,690
And then each of those back ends,

9
00:00:31,690 --> 00:00:34,930
those subscribers are able to perform whatever needs

10
00:00:34,930 --> 00:00:37,840
to be done with the same message.

11
00:00:37,840 --> 00:00:41,720
So it allows for parallel processing of the same data.

12
00:00:41,720 --> 00:00:45,140
So in this example, here we have our producer,

13
00:00:45,140 --> 00:00:50,640
and it's pushing a message to our SNS topic here on the left side.

14
00:00:50,640 --> 00:00:53,220
Now message A, which is what's being pushed,

15
00:00:53,220 --> 00:00:57,390
gets published out to all three of our subscriptions.

16
00:00:57,390 --> 00:01:04,040
So these three sqs cues are considered subscriptions to the topic on the left.

17
00:01:04,040 --> 00:01:08,090
And what's cool about this is you can put IFilter policies

18
00:01:08,090 --> 00:01:11,970
into place so you can only pick up certain messages

19
00:01:11,970 --> 00:01:14,300
depending on the back end subscription.

20
00:01:14,300 --> 00:01:19,230
So this is handy if you're sharing an SNS topic with other cues

21
00:01:19,230 --> 00:01:22,140
that might not be related to the same work,

22
00:01:22,140 --> 00:01:27,340
or if you want to filter out unnecessary messages and only act

23
00:01:27,340 --> 00:01:31,040
uncertain ones that contain a specific JSON field.

24
00:01:31,040 --> 00:01:31,310
Now,

25
00:01:31,310 --> 00:01:35,940
once this message a hits all three of our subscription cues

26
00:01:35,940 --> 00:01:40,050
we can configure different types of compute on the back end of

27
00:01:40,050 --> 00:01:44,650
those cues and those back in resource is our what performed the

28
00:01:44,650 --> 00:01:47,540
actions on the same message.

29
00:01:47,540 --> 00:01:50,840
But you'll see each level is doing its own thing,

30
00:01:50,840 --> 00:01:56,540
so we hav e c two out, putting some type of message result to S3.

31
00:01:56,540 --> 00:02:00,630
We have a container service running that pulls the message from Sqs and

32
00:02:00,630 --> 00:02:04,740
then places some data and dynamodb and then at the bottom.

33
00:02:04,740 --> 00:02:08,640
We have a lambda that pulls the message off the queue

34
00:02:08,640 --> 00:02:13,340
and then pops it into elasticsearch, which we looked at in the last module.

35
00:02:13,340 --> 00:02:14,310
So let's go ahead.

36
00:02:14,310 --> 00:02:22,000
I want to dive into the AWS console, so we can see how you can set this up in an efficient manner.

