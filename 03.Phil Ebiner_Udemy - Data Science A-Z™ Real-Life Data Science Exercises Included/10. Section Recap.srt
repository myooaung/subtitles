1

00:00:00,750  -->  00:00:05,220
Already end of the section we're just getting started into the fun stuff.

2

00:00:05,400  -->  00:00:10,260
But don't worry in the next section we will talk about some very powerful insights you can read for

3

00:00:10,260  -->  00:00:13,280
models and for this section.

4

00:00:13,380  -->  00:00:14,670
This is what we learned.

5

00:00:14,700  -->  00:00:19,770
Number one we talked about the accuracy paradox and that helped us understand why we cannot just use

6

00:00:19,770  -->  00:00:27,380
the accuracy rate which comes from the confusion matrix as the driving factor for defining whether our

7

00:00:27,420  -->  00:00:29,970
models are good or not.

8

00:00:29,970  -->  00:00:35,220
Next we talked about the cumulative accuracy profile and when we got so used to it that now we just

9

00:00:35,220  -->  00:00:37,650
call it the cap or the cap curve.

10

00:00:38,070  -->  00:00:43,020
And basically what it is is a measure for how William is performing.

11

00:00:43,020  -->  00:00:49,170
There is a mathematical way to assess the cap curve which is calculate the area under the ideal scenario

12

00:00:49,200  -->  00:00:54,840
calculate the area under your model scenario and then divide one by the other and get the actual accuracy

13

00:00:54,840  -->  00:00:56,040
ratio.

14

00:00:56,040  -->  00:01:01,080
However we also talked about a rule of thumb which is very visual which is very quick.

15

00:01:01,080  -->  00:01:04,220
Just look at the 50 percent line see where William all sitting there.

16

00:01:04,380  -->  00:01:10,780
And then you have some certain thresholds which I told you about the ones that I personally use.

17

00:01:11,130  -->  00:01:15,070
And then what we talked about is how to build a cap curve in Excel.

18

00:01:15,120  -->  00:01:20,550
Plus you got the template so hopefully you now know how to build one but also hopefully that template

19

00:01:20,550  -->  00:01:24,780
will save you lots of time and you can just use it again and again again.

20

00:01:24,780  -->  00:01:26,780
Took me a while to come up with that template.

21

00:01:26,850  -->  00:01:35,220
Usually for me it was always very messy when I was building these cap curves but now I know how to structure

22

00:01:35,640  -->  00:01:41,630
it in a great way so that it's very efficient and I don't get cluttered with all these extra columns

23

00:01:41,630  -->  00:01:43,110
and I don't need.

24

00:01:43,110  -->  00:01:47,440
Number four is how to assess your model using the cap curve.

25

00:01:47,730  -->  00:01:50,440
So that's we talked about that already.

26

00:01:50,490  -->  00:01:51,950
That's the 50 percent line.

27

00:01:51,990  -->  00:02:00,030
And just visually see how it is how the curves are structured how close it is to that ideal curve that

28

00:02:00,380  -->  00:02:05,050
you know you can never achieve but you're always you always want to get as close to it as possible.

29

00:02:05,370  -->  00:02:08,160
We'll talked about overfitting models and how you can avoid it.

30

00:02:08,160  -->  00:02:15,000
So we're using a train data and test data so separating a test group from your daughter said early on

31

00:02:15,000  -->  00:02:15,270
.

32

00:02:15,270  -->  00:02:22,250
So that further down the track when you're ready you can actually apply the model to your test data

33

00:02:22,290  -->  00:02:27,180
and then see how well you went on in that scenario.

34

00:02:27,180  -->  00:02:32,700
So then compare the accuracy ratio in your train scenario and your test scenario and make sure that

35

00:02:32,700  -->  00:02:35,760
there was no overfitting in your trained data.

36

00:02:36,150  -->  00:02:39,210
We also practiced how to verify models by test.

37

00:02:39,240  -->  00:02:45,420
So we didn't just talk about the theory we actually did it in practice and this time we had our test

38

00:02:45,420  -->  00:02:49,650
data prepared for us or separated for us in a separate file.

39

00:02:49,920  -->  00:02:55,620
Further down the course we will talk about the correct way of separating your test data from your training

40

00:02:55,620  -->  00:02:56,960
data yourselves.

41

00:02:57,270  -->  00:03:02,790
But this time we already had it and we did actually practice and visually compare the two.

42

00:03:03,060  -->  00:03:09,480
And I really think that's that's a good exercise because you'll be doing quite a lot of that if you

43

00:03:09,480  -->  00:03:10,940
want to build robust models.

44

00:03:11,170  -->  00:03:14,720
And number seven there was a preview as to what's coming next.

45

00:03:14,760  -->  00:03:21,180
So we talked a bit about how models can deteriorate over time and how you compare model we can compare

46

00:03:21,180  -->  00:03:24,590
models side by side even if there are different models using the cap curve.

47

00:03:24,900  -->  00:03:27,420
So that's coming further down the track in this course.

48

00:03:27,420  -->  00:03:31,800
Hope you're enjoying the material so far and I look forward to seeing you in the next section of the

49

00:03:31,800  -->  00:03:33,230
course.
