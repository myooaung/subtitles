WEBVTT
1

00:00:00.710  -->  00:00:01.400
All right.

2

00:00:01.400  -->  00:00:07.530
So this is the summary for the handling errors during each phases one and two.

3

00:00:07.620  -->  00:00:10.310
I cannot believe we got here.

4

00:00:10.680  -->  00:00:16.570
It has been a huge ride and we're finally at the end of this section.

5

00:00:16.800  -->  00:00:19.170
Congratulations for getting this far.

6

00:00:19.170  -->  00:00:27.000
So let's quickly recap on what we've learned in this massive section in this section we learned how

7

00:00:27.000  -->  00:00:28.990
Excel can mess up your data.

8

00:00:29.040  -->  00:00:31.640
Be careful if Excel it has a life of its own.

9

00:00:31.890  -->  00:00:40.140
And even if you just open and close a file it can change the format of the file and your data can be

10

00:00:40.140  -->  00:00:48.690
messed up as we saw how to correctly open files in Excel via the text import wizard that is a very great

11

00:00:49.530  -->  00:00:55.730
way to open files so that Excel doesn't us the formats of your columns.

12

00:00:55.800  -->  00:01:03.570
You can actually specify them yourself and it saves you from lots of issues the ones we saw were when

13

00:01:03.570  -->  00:01:11.100
dates were picked up incorrectly and also when credit card numbers were lost because of the way Excel

14

00:01:11.190  -->  00:01:12.280
looked at them.

15

00:01:12.450  -->  00:01:15.680
How to handle daughter truncation in SOSIAS.

16

00:01:15.990  -->  00:01:25.380
So that was when you allocated only a thousand characters for a column which had a comment which in

17

00:01:25.380  -->  00:01:29.720
one of the rows which was over 1000 characters.

18

00:01:29.720  -->  00:01:31.040
A very simple solution.

19

00:01:31.050  -->  00:01:34.500
Just allocate more space for that specific column.

20

00:01:34.920  -->  00:01:36.850
Everything about text qualifiers.

21

00:01:36.990  -->  00:01:42.240
I'm expecting that you are totally sick of text qualifiers by now.

22

00:01:42.240  -->  00:01:49.380
If that's not the case then re watch this section again I want you to be sick of text qualifiers and

23

00:01:49.620  -->  00:01:53.280
that means that you know them really really well.

24

00:01:53.370  -->  00:01:58.800
You need to know them because you will be dealing as a data scientist you'll be dealing a lot with ECAC

25

00:01:58.800  -->  00:02:02.680
files and other files that use text qualifiers.

26

00:02:03.270  -->  00:02:11.460
So you need to know them really well and exactly what they're there for and how they operate and what

27

00:02:11.460  -->  00:02:13.240
they qualify on and qualify.

28

00:02:13.320  -->  00:02:19.490
So we talked a lot about text qualifies in this section and you will have to qualify as in your homework

29

00:02:19.540  -->  00:02:19.590
.

30

00:02:19.620  -->  00:02:25.920
So make sure you're quite comfortable very comfortable with text qualifiers and that topic never ever

31

00:02:25.920  -->  00:02:29.610
bothers you again in your career ever.

32

00:02:29.610  -->  00:02:33.400
How to use notepad plus plus with two files side by side.

33

00:02:33.420  -->  00:02:41.070
I hope that now you can appreciate the power of Notepad plus plus and was better than just notepad and

34

00:02:41.610  -->  00:02:49.290
exactly what you can do with notepad plus plus we saw how we can put two files side by side and actually

35

00:02:49.290  -->  00:02:52.320
synchronize them in vertical and horizontal scrolling.

36

00:02:52.320  -->  00:03:01.200
It was very very easy for us to analyze huge volumes of data as remember we had 50000 rows and that

37

00:03:01.230  -->  00:03:07.500
allowed us to quickly pick up any errors that we were looking for what to do when your source file is

38

00:03:07.500  -->  00:03:08.460
corrupt.

39

00:03:08.550  -->  00:03:13.320
So we looked at some of the basic very basic ways.

40

00:03:13.320  -->  00:03:15.400
A source file can be corrupt.

41

00:03:15.570  -->  00:03:22.950
And trust me the bigger your file gets the more issues you can have if you are potentially going to

42

00:03:22.950  -->  00:03:30.010
have Woolford because larger files you know they're stored on sometimes are stored on the flash drive

43

00:03:30.010  -->  00:03:38.400
sometimes are stored on hard drives and there are clusters there and you know them magnets can be can

44

00:03:38.490  -->  00:03:44.800
fail at some point and there can be lots of different issues while a wire file can be corrupt.

45

00:03:44.820  -->  00:03:52.350
Will looked at some of the basic examples when simple text qualifiers were missing and how that affects

46

00:03:52.650  -->  00:04:00.510
your rows and the rest of your data so that is there was a good way to get introduced to corruption

47

00:04:00.510  -->  00:04:01.490
of data.

48

00:04:01.500  -->  00:04:07.380
It's not guaranteed that in your career what you'll be experiencing is that specific type of corruption

49

00:04:07.380  -->  00:04:10.730
but at least you will know that things can go wrong.

50

00:04:10.760  -->  00:04:18.240
And I gave you some ideas of how to address these issues and situations when you can potentially fix

51

00:04:18.240  -->  00:04:19.590
things yourself.

52

00:04:19.770  -->  00:04:21.430
But once again I advise.

53

00:04:21.450  -->  00:04:28.440
If you find corruption your main goal is to isolate it isolate it make sure only 1 to 10 a thousand

54

00:04:28.440  -->  00:04:34.110
rows are affected by that corruption and but everything before and everything after is OK and then you

55

00:04:34.110  -->  00:04:35.460
can separate your files.

56

00:04:35.460  -->  00:04:38.270
That was the road we were focusing on in SSA es.

57

00:04:38.280  -->  00:04:45.660
In all manual assessments using Excel as a text import wizard to save guard from further corruption

58

00:04:45.660  -->  00:04:46.150
.

59

00:04:47.350  -->  00:04:53.060
We were focusing on isolation of the corruption corrupted rows putting them into a separate file and

60

00:04:53.060  -->  00:04:58.080
sending them off to the person that is responsible the custodian of the daughter who can analyze them

61

00:04:58.350  -->  00:05:00.310
and give you the correct rows.

62

00:05:00.420  -->  00:05:07.140
Your goal is to make sure that the corruption doesn't spread across a whole file and that you are confident

63

00:05:07.230  -->  00:05:12.470
that the fraud that you are analyzing that the rules that you are letting through into a database that

64

00:05:12.600  -->  00:05:17.330
they are not corrupt or they are not including that corruption that you noticed.

65

00:05:17.330  -->  00:05:23.960
And if there is some issues with the rows with the rows of data that do into your data set as we discussed

66

00:05:24.000  -->  00:05:29.140
maybe in this blueprint up to now there's something that you won't be able to pick up.

67

00:05:29.150  -->  00:05:34.890
We've picked up we're picking up the majority of the you know huge volumes of corrupted data.

68

00:05:34.920  -->  00:05:38.870
Maybe there's one or two or three or you know depending on the size of the database maybe is another

69

00:05:38.880  -->  00:05:40.660
thousand issues that you haven't picked up.

70

00:05:40.800  -->  00:05:44.270
But we will look at that in the further sections of the course.

71

00:05:44.260  -->  00:05:51.660
We'll look at how to surgically pick out few other roles that might have anomalies in this section you

72

00:05:51.680  -->  00:05:55.140
also learn a handy trick to find anomalies in as well.

73

00:05:55.130  -->  00:05:59.180
So that was the trick when we looked at the last column whether it's shifted left or right.

74

00:05:59.250  -->  00:06:00.640
It picks up quite a lot.

75

00:06:00.720  -->  00:06:06.050
So if you do have say in one row you have two anomalies so you have a corruption in one column and then

76

00:06:06.050  -->  00:06:11.430
in corruption five columns down the track and what the cloud of corruption on the left or the first

77

00:06:11.430  -->  00:06:14.970
corruption makes everything shift to the left the second corruption makes everything shift to the right

78

00:06:14.980  -->  00:06:15.000
.

79

00:06:15.000  -->  00:06:19.980
Then they kind of cancel each other out and you won't pick that up because your last columns will be

80

00:06:19.980  -->  00:06:20.650
in place.

81

00:06:20.780  -->  00:06:22.090
But that happens rarely.

82

00:06:22.110  -->  00:06:28.010
More likely you will have only one corruption and something will shift and this handy trick will help

83

00:06:28.010  -->  00:06:29.360
you pick stuff up in a scale.

84

00:06:29.370  -->  00:06:35.870
But once again we don't really need to use a chicken scale because we then integrated that trick into

85

00:06:35.880  -->  00:06:42.740
our Sosias using conditional splits and automating the whole process so stick to that.

86

00:06:42.750  -->  00:06:50.740
That is the way to go how to use conditional splits to create powerful projects and SS nominee Commons

87

00:06:50.750  -->  00:06:51.430
here.

88

00:06:51.620  -->  00:06:58.020
Conditional splits are powerful and they make your Sosias projects look awesome and work awesome and

89

00:06:58.010  -->  00:06:59.920
they automate a lot of stuff for you.

90

00:07:00.000  -->  00:07:03.160
So use conditional splits in your work.

91

00:07:03.160  -->  00:07:07.450
They're great how to automate error handling in SSI.

92

00:07:07.710  -->  00:07:14.730
So once again that is using conditional splits and different logical operators and looking at different

93

00:07:14.730  -->  00:07:15.300
columns.

94

00:07:15.320  -->  00:07:20.240
And don't forget here we not only looking at corrupt rows we're also looking at rows with missing data

95

00:07:20.250  -->  00:07:20.750
.

96

00:07:20.780  -->  00:07:26.240
So if you already know what data you will definitely need for analysis or if there is a critical column

97

00:07:26.250  -->  00:07:33.330
for instance name surname or customer ID or email that your office or of your customers or if it's transactions

98

00:07:33.320  -->  00:07:37.820
and you know it could be credit card numbers and so on if that information is missing for some rows

99

00:07:38.250  -->  00:07:44.880
then SSA as is your friend to help you you and use conditional splits to get those rolls out before

100

00:07:44.880  -->  00:07:52.520
you upload the data so you can efficiently send them back and get the full version from the person or

101

00:07:52.520  -->  00:07:56.210
from the department that sent you down in the first place.

102

00:07:56.340  -->  00:08:04.010
The important due diligence check for quality assurance what was the due diligence check that one little

103

00:08:04.010  -->  00:08:04.910
one.

104

00:08:04.910  -->  00:08:06.000
That's right.

105

00:08:06.120  -->  00:08:11.780
It was counting the rows of your table when you upload data.

106

00:08:11.780  -->  00:08:19.010
If you forget to truncate the table before you rerun your Sosias package it will not truncated automatically

107

00:08:19.010  -->  00:08:19.640
for you.

108

00:08:19.860  -->  00:08:24.650
It'll just add it will append the new rows to the ones that already exist in your table.

109

00:08:24.840  -->  00:08:26.720
And in that way what will happen.

110

00:08:26.730  -->  00:08:33.720
Well you will get duplicate results and it can be very very painful when you report something that is

111

00:08:33.720  -->  00:08:34.040
wrong.

112

00:08:34.050  -->  00:08:41.870
When you complete a report an inflated sales or an inflated losses or your reports are completely out

113

00:08:41.880  -->  00:08:43.950
of whack because you've counted everything twice.

114

00:08:43.940  -->  00:08:50.300
So get into the habit of doing that due diligence check and just running a simple count query in Escal

115

00:08:50.370  -->  00:08:52.270
after the import has finished.

116

00:08:52.350  -->  00:08:59.630
And also don't forget after you've finished working with ISIS to disable your package because if you

117

00:08:59.630  -->  00:09:09.240
add more packages into that project in Sosias for other data sets that relate to your data science project

118

00:09:09.240  -->  00:09:09.550
.

119

00:09:09.840  -->  00:09:15.960
Then every time you run your SSL project all the packages that are not disabled will run.

120

00:09:16.050  -->  00:09:22.050
And once again you can get duplicate rows so very important to disable your package.

121

00:09:22.460  -->  00:09:31.700
Once you've finished playing that specific table into your database and finally we talked about types

122

00:09:31.700  -->  00:09:37.810
of errors in essays so we looked at the errors that we had the errors that we can potentially have.

123

00:09:37.910  -->  00:09:44.150
And the other errors in Sosias that could happen but won't happen in this blueprint because it's so

124

00:09:44.150  -->  00:09:44.870
simple.

125

00:09:44.900  -->  00:09:52.940
So that was a good overview and a good backing to this blueprint why you should use it and why it's

126

00:09:52.940  -->  00:09:58.630
been designed in this way to help you avoid errors in as as this blueprint.

127

00:09:58.730  -->  00:10:06.230
Speaking of we'll help you with at least 90 percent of situations so it's not a guarantee that it works

128

00:10:06.230  -->  00:10:08.440
in all situations.

129

00:10:08.480  -->  00:10:14.660
And I'm also maybe situations like when your daughter is not in a text file.

130

00:10:14.690  -->  00:10:20.090
Is it a different type of file or is in a database maybe you can use bits and pieces out of this blueprint

131

00:10:20.100  -->  00:10:26.810
so for instance you could use the conditional splits and you know look for some ideas on how to look

132

00:10:26.810  -->  00:10:34.370
for anomalies and so on so maybe you can use all of the blueprint right away in your specific project

133

00:10:34.850  -->  00:10:37.960
or maybe you can use this blueprint at all sometimes.

134

00:10:38.180  -->  00:10:44.840
But what this is saying is that in most cases you should be able to use this blueprint you should put

135

00:10:44.840  -->  00:10:50.660
yourself in a position that you can use as a blueprint and more as much of it as you can because it

136

00:10:50.660  -->  00:10:51.810
will help you.

137

00:10:51.950  -->  00:10:52.820
It will guide you.

138

00:10:52.820  -->  00:10:54.120
It will help you avoid errors.

139

00:10:54.140  -->  00:11:01.820
It will give you exact steps that you need to perform to get your data into a prepared format to further

140

00:11:01.820  -->  00:11:03.700
analyze it.

141

00:11:03.890  -->  00:11:08.960
This blueprint is simple and methodic hopefully you've noticed that by now that there's nothing complicated

142

00:11:08.960  -->  00:11:15.050
about it after you've done it you know a couple couple times maybe a dozen times you will you'll be

143

00:11:15.050  -->  00:11:16.130
able to do it move.

144

00:11:16.430  -->  00:11:21.890
Metaphorically speaking of your eyes closed it is methodic meaning you don't have to invent anything

145

00:11:21.890  -->  00:11:25.640
you just have to follow the steps and you should be fine.

146

00:11:25.640  -->  00:11:32.780
It includes numerous Q8 checks which is always a great thing to have because once again we're spending

147

00:11:32.840  -->  00:11:40.820
a lot of time on uploading all data uploading data is one of the most important steps in a data science

148

00:11:40.820  -->  00:11:46.310
project or preparing data I should say. You've got to spend at least 70 percent of your time.

149

00:11:46.310  -->  00:11:49.520
That's the reality of things and that's what you see from the scores.

150

00:11:49.610  -->  00:11:52.720
At least 70 percent of the time you're going to be spending preparing data.

151

00:11:52.730  -->  00:11:59.450
So you want to make sure that what you've done is correct that there are no errors along the way because

152

00:11:59.900  -->  00:12:06.950
if there is one major error then the rest of your work that you do with visualization programming modeling

153

00:12:06.950  -->  00:12:07.610
and so on.

154

00:12:07.760  -->  00:12:09.420
It doesn't matter at all.

155

00:12:09.920  -->  00:12:10.780
OK.

156

00:12:10.790  -->  00:12:17.090
This blueprint leaves an auditable trace meaning that you can always come back and see exactly what

157

00:12:17.090  -->  00:12:23.390
happened where some rows went where the other rows went how it was structured what the logic was behind

158

00:12:23.810  -->  00:12:26.580
isolating certain anomalies and so on.

159

00:12:26.810  -->  00:12:31.730
It is reliable because there are Q8 checks because it's methodic It's simple it has an orderable trace

160

00:12:31.960  -->  00:12:38.330
it is a reliable blueprint and it is repeatable meaning that if you ever need to re-upload the data

161

00:12:38.360  -->  00:12:44.240
or as you saw redevelop the package you saw that in this section that we were constantly redeveloping

162

00:12:44.240  -->  00:12:45.290
our SSX package.

163

00:12:45.360  -->  00:12:51.350
It's very simple to come back there and add something to add or remove something just don't forget to

164

00:12:51.920  -->  00:12:55.330
truncate the table that you are uploading into.

165

00:12:55.370  -->  00:13:00.320
So you don't have duplicate rows and don't forget to do the check afterwards every single time.

166

00:13:00.320  -->  00:13:07.060
And finally why are we uploading the data as text so if your experience Professor Assayas already or

167

00:13:07.620  -->  00:13:10.660
you know you have some I've done some tutorials on that.

168

00:13:10.790  -->  00:13:19.430
You would probably know that you can in essence yes you can convert your data there and upload it as

169

00:13:19.490  -->  00:13:25.940
the correct format so say you take customer numbers and you convert them into numbers.

170

00:13:26.000  -->  00:13:30.410
You wouldn't really comment that it takes a dollars and you convert them dollar amounts you convert

171

00:13:30.410  -->  00:13:32.940
them into actual float variables.

172

00:13:33.020  -->  00:13:33.280
Right.

173

00:13:33.290  -->  00:13:40.100
Or you take dates and you convert them instead of imploding or less text you convert them into dates

174

00:13:40.100  -->  00:13:40.690
in essence.

175

00:13:40.730  -->  00:13:46.700
And then you upload them as dates already into as well so it makes it more prettier the table as you

176

00:13:46.700  -->  00:13:50.100
get skills a bit prettier and more ready.

177

00:13:50.110  -->  00:13:53.290
Well why are we applauding daughter as text.

178

00:13:53.430  -->  00:13:55.650
Going to answer that question for you.

179

00:13:55.790  -->  00:13:57.700
We're doing that to avoid errors.

180

00:13:57.770  -->  00:14:02.860
It is a complex procedure to find the right types for your daughter.

181

00:14:02.870  -->  00:14:08.780
And plus if you have anomalies in your daughter in those columns that you converting If in your date

182

00:14:08.780  -->  00:14:13.430
field there's a dollar amount or something you're going to get heaps and heaps of errors along the way

183

00:14:13.430  -->  00:14:13.700
.

184

00:14:13.700  -->  00:14:20.380
Yes you can exclude them yes you can find ways in SSA as to direct those arrows to other places that

185

00:14:20.380  -->  00:14:27.760
you really want to do all of that in essays and built this huge package we are not doing a creating

186

00:14:27.750  -->  00:14:31.940
a business analysis process here we're not creating.

187

00:14:32.050  -->  00:14:38.730
No we're not here to create SOSIAS projects we're using as assets to help us get the data into the database

188

00:14:38.740  -->  00:14:38.760
.

189

00:14:38.760  -->  00:14:45.330
And along the way we're executing some anomalies but we want to do most of the work in school.

190

00:14:45.510  -->  00:14:51.230
So exactly that we want to move all the heavy lifting to school and see e-tail face 3.

191

00:14:51.330  -->  00:14:54.310
If you thought that this was the end of the tail process.

192

00:14:54.490  -->  00:14:55.580
No it's not.

193

00:14:55.690  -->  00:15:00.610
That was it's a mistake to think that this is the end of retail.

194

00:15:00.610  -->  00:15:04.910
We still have Phase 3 when we are going to work with the data in as well.

195

00:15:04.910  -->  00:15:11.130
So for now we've learned how to upload a raw file where everything is in text inter-school and as you

196

00:15:11.130  -->  00:15:19.860
will see working with that and converting that file into something pretty something that you can actually

197

00:15:19.920  -->  00:15:23.500
analyze something and work with is very simple.

198

00:15:23.620  -->  00:15:29.260
It's also going to be a very methodical very simple blueprint is going to be fast hopefully faster than

199

00:15:29.250  -->  00:15:36.310
this one and very repeatable very honorable and we want to move all of that into as well because we're

200

00:15:36.300  -->  00:15:41.850
going to have a great blueprint for that and having the raw files in Eskdale reduces the chance that

201

00:15:41.860  -->  00:15:44.100
you will have to re-upload or in the future.

202

00:15:44.190  -->  00:15:48.960
So in addition to all of those other benefits of askew all that you know it's phos that you are able

203

00:15:48.970  -->  00:15:51.740
to follow a specific blueprint that we're going to have for us.

204

00:15:51.830  -->  00:15:59.040
Q Well it's repeatable that it's orderable that it's very simple and methodic and you not going to have

205

00:15:59.040  -->  00:16:02.430
as many errors or at least you will know how to deal with those errors.

206

00:16:02.430  -->  00:16:08.010
The fact that you're happy that you're going to have the rule files in as you well and let's face it

207

00:16:08.010  -->  00:16:13.810
here we're not actually modifying the raw files that much we're all we're doing is extracting some rows

208

00:16:13.820  -->  00:16:14.240
.

209

00:16:14.500  -->  00:16:18.620
The rows that are anomalies and maybe corruption's we're extracting them but the remaining rows that

210

00:16:18.630  -->  00:16:22.240
were actually uploaded were applauding them in pretty much their row format.

211

00:16:22.260  -->  00:16:28.310
We're not modifying the contents of the table the cells of these rows.

212

00:16:28.410  -->  00:16:34.410
And what that means is that you have that rule file as is in skill and if you ever need to revert back

213

00:16:34.410  -->  00:16:35.600
to it it's there.

214

00:16:35.760  -->  00:16:43.920
Whereas on the other hand if you do something with the profile in SSA as for instance you modify the

215

00:16:43.950  -->  00:16:51.990
types you guess or do some type conversions in SSA es or you join tables or whatever you do in SSA us

216

00:16:52.000  -->  00:16:56.060
and then you upload the file to tables to a.

217

00:16:56.280  -->  00:17:02.550
And then at some point you realize while you're working in a SQL server that oh actually I know I don't

218

00:17:02.560  -->  00:17:04.950
like what I did in essence I I need to change that.

219

00:17:05.010  -->  00:17:09.600
Then you will have to go back to say yes you'll have to change it and then you'll have to re upload

220

00:17:09.610  -->  00:17:10.500
the files again.

221

00:17:10.510  -->  00:17:17.760
So we want to avoid that we want to upload a version the files as close as possible to the original

222

00:17:17.990  -->  00:17:23.830
a scale so that we minimize the chance that we will ever have to re upload or in the future.

223

00:17:24.010  -->  00:17:27.670
So that's my answer to that question why we're uploading daughter as text.

224

00:17:27.660  -->  00:17:32.290
I really really hope you enjoy this section or even if you didn't enjoy it.

225

00:17:32.290  -->  00:17:37.340
I know it was tedious and it was a lot of hard core work the data wasn't clean.

226

00:17:37.440  -->  00:17:38.590
That's the reality of things.

227

00:17:38.590  -->  00:17:45.430
You know like I don't I don't really enjoy courses where everything is nice and fluffy and smooth and

228

00:17:45.420  -->  00:17:49.630
you just follow certain instructions and you get get the result that you should.

229

00:17:49.620  -->  00:17:57.460
I believe that this is like war you should be faced with the reality of the real world what's going

230

00:17:57.450  -->  00:17:58.610
to happen to you.

231

00:17:58.740  -->  00:18:05.880
And the more you practice the more you see these things these anomalies these you know horrible things

232

00:18:05.880  -->  00:18:09.750
that can happen to your daughter along the way and horrible types of data.

233

00:18:09.820  -->  00:18:12.100
The more prepared you are for the real world.

234

00:18:12.100  -->  00:18:13.080
And that's what counts.

235

00:18:13.090  -->  00:18:17.130
Because when you get out there and you're fresh and green and you don't know anything about the real

236

00:18:17.130  -->  00:18:18.290
world of data science.

237

00:18:18.590  -->  00:18:27.160
Well it's going to take ages to make all these mistakes and good good good good at working with the

238

00:18:27.150  -->  00:18:34.050
data that's out there whereas hopefully now from this course you've already had a taste for it and it's

239

00:18:34.060  -->  00:18:41.520
like a fast track into hard core data so that you will be able to you know face these challenges when

240

00:18:41.530  -->  00:18:42.030
they come.

241

00:18:42.030  -->  00:18:45.320
And speaking of challenges check out the next lecture.

242

00:18:45.380  -->  00:18:47.750
It is your homework from this section.

243

00:18:47.760  -->  00:18:54.210
Of course it's not compulsory you don't have to do it but I highly recommend you check it out.

244

00:18:54.210  -->  00:19:00.720
I've prepared some really cool challenges for you and not going to be as simple as you think.

245

00:19:00.720  -->  00:19:02.190
So check that out.

246

00:19:02.190  -->  00:19:06.030
And I look forward to seeing you in the next section of the course
