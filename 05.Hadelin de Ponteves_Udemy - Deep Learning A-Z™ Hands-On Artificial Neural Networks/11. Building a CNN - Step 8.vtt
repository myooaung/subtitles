WEBVTT
1
1

00:00:00.350  -->  00:00:02.900
<v Instructor>Hello and welcome to this Python tutorial.</v>
2

2

00:00:02.900  -->  00:00:04.760
All right, so now we added all the layers
3

3

00:00:04.760  -->  00:00:06.670
in our convolutional neural network,
4

4

00:00:06.670  -->  00:00:08.930
and so now we just need to compile the whole thing
5

5

00:00:08.930  -->  00:00:11.920
by choosing a stochastic gradient descent algorithm,
6

6

00:00:11.920  -->  00:00:15.040
a loss function and, eventually, a performance metric.
7

7

00:00:15.040  -->  00:00:15.960
So let's do this.
8

8

00:00:15.960  -->  00:00:18.940
We already know how to do it, since it was the last step
9

9

00:00:18.940  -->  00:00:22.220
of the building process of our ANN in the previous section.
10

10

00:00:22.220  -->  00:00:24.440
We need to take our classifier.
11

11

00:00:24.440  -->  00:00:28.070
I'm copying that, pasting it here, and then dot,
12

12

00:00:28.070  -->  00:00:31.800
because we are gonna introduce the compile method.
13

13

00:00:31.800  -->  00:00:33.260
This time we are not adding anything,
14

14

00:00:33.260  -->  00:00:36.740
we are compling our CNN, so it's the compile method,
15

15

00:00:36.740  -->  00:00:39.870
and then parenthesis, and then inside these parenthesis,
16

16

00:00:39.870  -->  00:00:42.790
we add the parameters, that is, the optimizer parameter
17

17

00:00:42.790  -->  00:00:45.380
to choose the stochastic gradient descent algorithm.
18

18

00:00:45.380  -->  00:00:47.850
Then the last parameter to choose the loss function.
19

19

00:00:47.850  -->  00:00:49.780
And then finally, the metrics parameter
20

20

00:00:49.780  -->  00:00:51.540
to choose the performance metric.
21

21

00:00:51.540  -->  00:00:53.260
So let's start with the first parameter.
22

22

00:00:53.260  -->  00:00:55.403
The first parameter is optimizer.
23

23

00:00:56.250  -->  00:00:57.200
Here we go.
24

24

00:00:57.200  -->  00:00:59.010
Equals, and we are gonna choose
25

25

00:00:59.010  -->  00:01:01.650
the same stochastic gradient descent algorithm
26

26

00:01:01.650  -->  00:01:04.340
as we chose in the previous section for our ANN.
27

27

00:01:04.340  -->  00:01:08.320
Remember it is the Adam algorithm.
28

28

00:01:08.320  -->  00:01:09.500
All right.
29

29

00:01:09.500  -->  00:01:11.070
Then, next argument.
30

30

00:01:11.070  -->  00:01:13.690
The next argument is the loss function.
31

31

00:01:13.690  -->  00:01:17.880
So loss equals, quotes, and inside these quotes,
32

32

00:01:17.880  -->  00:01:20.160
we're gonna input the name of our loss function,
33

33

00:01:20.160  -->  00:01:23.820
which, remember, is the binary cross entropy.
34

34

00:01:23.820  -->  00:01:25.280
And that is for two reasons.
35

35

00:01:25.280  -->  00:01:27.020
First of all, because this function corresponds
36

36

00:01:27.020  -->  00:01:29.410
to the logarithmic loss, that is the loss function
37

37

00:01:29.410  -->  00:01:32.080
that we use in general for classification problems
38

38

00:01:32.080  -->  00:01:35.080
using a classification model like logistic regression.
39

39

00:01:35.080  -->  00:01:37.830
And the second reason is that we have a binary outcome
40

40

00:01:37.830  -->  00:01:39.160
and therefore, we need to choose
41

41

00:01:39.160  -->  00:01:41.640
the binary cross entropy loss function.
42

42

00:01:41.640  -->  00:01:44.520
And if we had more than two outcomes,
43

43

00:01:44.520  -->  00:01:47.970
like cats, dogs, and birds, well,
44

44

00:01:47.970  -->  00:01:50.810
we would need to choose categorical cross entropy.
45

45

00:01:50.810  -->  00:01:53.530
But here we have a binary outcome, cat or dog,
46

46

00:01:53.530  -->  00:01:58.530
so it's binary cross entropy.
47

47

00:01:58.860  -->  00:02:00.080
Here we go.
48

48

00:02:00.080  -->  00:02:03.030
And now comma and last argument.
49

49

00:02:03.030  -->  00:02:05.480
So the last argument is the performance metric.
50

50

00:02:05.480  -->  00:02:06.840
And we are gonna choose, as usual,
51

51

00:02:06.840  -->  00:02:09.600
the most common one, the accuracy metric.
52

52

00:02:09.600  -->  00:02:10.780
So let's input it.
53

53

00:02:10.780  -->  00:02:15.780
Metrics equals, then in brackets and quotes, accuracy.
54

54

00:02:19.270  -->  00:02:20.103
Here we go.
55

55

00:02:20.103  -->  00:02:20.936
And that's all.
56

56

00:02:20.936  -->  00:02:22.770
Our model is ready to compile.
57

57

00:02:22.770  -->  00:02:26.770
So I'm going to select this line and execute.
58

58

00:02:26.770  -->  00:02:28.210
All right, perfect.
59

59

00:02:28.210  -->  00:02:30.440
Our classifier was just compiled correctly.
60

60

00:02:30.440  -->  00:02:32.710
And so now we are ready to move on to the next step
61

61

00:02:32.710  -->  00:02:35.400
and final step before we get our results.
62

62

00:02:35.400  -->  00:02:38.160
That is the image preprocessing step
63

63

00:02:38.160  -->  00:02:41.100
where we will fit our CNN that we just built
64

64

00:02:41.100  -->  00:02:42.780
to all our images.
65

65

00:02:42.780  -->  00:02:44.700
So it's gonna be a very exciting step
66

66

00:02:44.700  -->  00:02:47.730
and I look forward to doing it in the next tutorial.
67

67

00:02:47.730  -->  00:02:49.803
Until then, enjoy deep learning.
