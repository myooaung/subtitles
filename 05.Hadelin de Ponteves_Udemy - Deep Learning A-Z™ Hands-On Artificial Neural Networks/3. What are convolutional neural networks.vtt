WEBVTT
1
1

00:00:00.360  -->  00:00:01.300
<v Instructor>Hello and welcome back</v>
2

2

00:00:01.300  -->  00:00:02.850
to the course on Deep Learning.
3

3

00:00:02.850  -->  00:00:05.403
Today we're kicking off Convolutional Neural Networks.
4

4

00:00:05.403  -->  00:00:08.500
This is gonna be exciting, let's dive straight into it.
5

5

00:00:08.500  -->  00:00:10.810
We're going to start off with an image.
6

6

00:00:10.810  -->  00:00:13.500
What do you see when you look at this image?
7

7

00:00:13.500  -->  00:00:15.560
Do you see a person looking at you
8

8

00:00:15.560  -->  00:00:18.090
or do you see a person looking to the right?
9

9

00:00:18.090  -->  00:00:21.570
You can see that your brain is struggling,
10

10

00:00:21.570  -->  00:00:23.970
it's struggling to adjust.
11

11

00:00:23.970  -->  00:00:25.790
If you look to the right side of the image,
12

12

00:00:25.790  -->  00:00:27.340
just look at the right border of the image,
13

13

00:00:27.340  -->  00:00:29.150
you'll see a person looking to the right.
14

14

00:00:29.150  -->  00:00:31.420
If you look at the left border of the image,
15

15

00:00:31.420  -->  00:00:33.170
you'll see a person looking at you.
16

16

00:00:34.670  -->  00:00:39.670
This just proves that what our brain is looking for
17

17

00:00:39.670  -->  00:00:42.100
when we see things is features.
18

18

00:00:42.100  -->  00:00:44.150
Depending on the features that it sees,
19

19

00:00:44.150  -->  00:00:46.060
depending on the features that you process,
20

20

00:00:46.060  -->  00:00:48.620
you categorize things in certain ways.
21

21

00:00:48.620  -->  00:00:51.700
So when you look on the right side of the image,
22

22

00:00:51.700  -->  00:00:53.940
you see certain features of a person looking to the right
23

23

00:00:53.940  -->  00:00:57.150
because they're closer to your center of focus
24

24

00:00:57.150  -->  00:00:59.300
and, therefore, your brain classifies it
25

25

00:00:59.300  -->  00:01:00.900
as a person looking to the right.
26

26

00:01:00.900  -->  00:01:03.190
When you look to the left side of the image,
27

27

00:01:03.190  -->  00:01:06.040
you see more features of a person looking at you
28

28

00:01:06.040  -->  00:01:09.460
and, therefore, your brain classifies it as such.
29

29

00:01:09.460  -->  00:01:11.130
So let's have a look at another one.
30

30

00:01:11.130  -->  00:01:12.810
This is a very famous image,
31

31

00:01:12.810  -->  00:01:14.600
you probably have already seen it,
32

32

00:01:14.600  -->  00:01:15.950
but what do you see here?
33

33

00:01:16.970  -->  00:01:18.860
Some people will say that they see
34

34

00:01:18.860  -->  00:01:23.730
a young lady wearing a dress looking away,
35

35

00:01:23.730  -->  00:01:25.360
some people will say they see
36

36

00:01:25.360  -->  00:01:30.170
an old lady wearing a scarf on her head looking down.
37

37

00:01:30.170  -->  00:01:32.330
So, I'm gonna point these features out
38

38

00:01:32.330  -->  00:01:34.780
and you'll see that'll become very obvious.
39

39

00:01:34.780  -->  00:01:37.380
This is the face of the young lady looking away,
40

40

00:01:37.380  -->  00:01:40.340
she's looking into the distance, that's her coat,
41

41

00:01:40.340  -->  00:01:43.570
that's her hair, that's her little feather in her hair.
42

42

00:01:43.570  -->  00:01:44.880
And, on the other hand,
43

43

00:01:44.880  -->  00:01:48.890
this is the head of the old lady looking down,
44

44

00:01:48.890  -->  00:01:52.210
that's her nose, that's her mouth, that's her chin,
45

45

00:01:52.210  -->  00:01:55.680
that's the scarf on her head, and she's looking down.
46

46

00:01:55.680  -->  00:01:57.830
So, as you can see, two in one
47

47

00:01:57.830  -->  00:02:00.460
and, depending on which features your brain picks up,
48

48

00:02:00.460  -->  00:02:04.880
it will switch between classifying the image
49

49

00:02:04.880  -->  00:02:06.790
as one or the other.
50

50

00:02:06.790  -->  00:02:09.720
The oldest one of these illusions
51

51

00:02:09.720  -->  00:02:13.810
recorded in the printed work is this one,
52

52

00:02:13.810  -->  00:02:15.110
it's the duck with the rabbit.
53

53

00:02:15.110  -->  00:02:16.890
So is this a duck or is this a rabbit?
54

54

00:02:16.890  -->  00:02:18.300
Another example.
55

55

00:02:18.300  -->  00:02:20.880
And now I'm gonna show you an image which will,
56

56

00:02:20.880  -->  00:02:22.430
just for a second,
57

57

00:02:22.430  -->  00:02:25.560
just look at it and see what emotions
58

58

00:02:25.560  -->  00:02:27.670
or what kind of experience, visual experience,
59

59

00:02:27.670  -->  00:02:29.020
you go through.
60

60

00:02:29.020  -->  00:02:31.050
So, what do you see?
61

61

00:02:31.050  -->  00:02:35.630
Do you feel like a bit, not dizzy, but a bit dazzled?
62

62

00:02:35.630  -->  00:02:38.020
Like your brain is trying to understand what it is,
63

63

00:02:38.020  -->  00:02:40.220
what it is, it's trying to,
64

64

00:02:40.220  -->  00:02:43.733
it's jumping between her eyes, up and down, eyes.
65

65

00:02:45.160  -->  00:02:49.850
It's a classic example of when there are certain features
66

66

00:02:49.850  -->  00:02:52.050
where it could be this, it could be that,
67

67

00:02:52.050  -->  00:02:57.037
but your brain cannot decide because both seem plausible.
68

68

00:02:58.670  -->  00:03:00.900
So, basically, all these examples
69

69

00:03:00.900  -->  00:03:02.890
illustrate to us how the brain works,
70

70

00:03:02.890  -->  00:03:05.470
that it processes certain features on an image
71

71

00:03:05.470  -->  00:03:08.650
or on whatever you see in real life
72

72

00:03:08.650  -->  00:03:10.113
and it classifies that as such.
73

73

00:03:10.113  -->  00:03:12.230
And you've probably been in situations
74

74

00:03:12.230  -->  00:03:15.210
when you look over your shoulder quickly
75

75

00:03:15.210  -->  00:03:16.950
and you see something you think it's,
76

76

00:03:16.950  -->  00:03:20.700
I don't know, it's like a ball,
77

77

00:03:20.700  -->  00:03:22.190
but it turns out to be a cat,
78

78

00:03:22.190  -->  00:03:25.010
or you think it's a car but it turns out to be a shadow,
79

79

00:03:25.010  -->  00:03:25.843
things like that.
80

80

00:03:25.843  -->  00:03:27.300
That's because you don't have enough time
81

81

00:03:27.300  -->  00:03:29.570
to process those features or you don't have enough features
82

82

00:03:29.570  -->  00:03:31.120
to classify things as such.
83

83

00:03:31.120  -->  00:03:35.330
And this is, for me, this is very interesting
84

84

00:03:35.330  -->  00:03:37.122
because what we're going to be doing
85

85

00:03:37.122  -->  00:03:40.710
with convolutional neural networks is very similar
86

86

00:03:40.710  -->  00:03:42.200
and you'll find that the way
87

87

00:03:42.200  -->  00:03:44.900
that computers are going to be processing images
88

88

00:03:44.900  -->  00:03:46.320
is going to be extremely similar
89

89

00:03:46.320  -->  00:03:48.130
to the way we are processing images.
90

90

00:03:48.130  -->  00:03:50.400
So it's very valuable to understand
91

91

00:03:50.400  -->  00:03:52.250
and just kind of remember these things
92

92

00:03:52.250  -->  00:03:53.500
that this is how we do it.
93

93

00:03:53.500  -->  00:03:55.840
And I'm going to take this lady off your screens
94

94

00:03:55.840  -->  00:03:58.530
because she's probably already freaking you out by now.
95

95

00:03:58.530  -->  00:04:02.040
So here's something different, here's an experiment.
96

96

00:04:02.040  -->  00:04:05.360
An experiment done on computers,
97

97

00:04:05.360  -->  00:04:06.880
on convolutional neural networks,
98

98

00:04:06.880  -->  00:04:11.260
so we're slowly moving now from humans to computers.
99

99

00:04:11.260  -->  00:04:14.253
This slide is from a talk by Geoffrey Hinton.
100

100

00:04:15.250  -->  00:04:17.560
And here you have, basically,
101

101

00:04:17.560  -->  00:04:19.930
it describes an experiment that he had done
102

102

00:04:19.930  -->  00:04:22.220
on some convolutional neural networks
103

103

00:04:22.220  -->  00:04:24.370
that he had trained up.
104

104

00:04:24.370  -->  00:04:26.460
So, here you see three images
105

105

00:04:26.460  -->  00:04:28.130
and we're gonna go through them left to right
106

106

00:04:28.130  -->  00:04:30.040
and see how you would classify them
107

107

00:04:30.040  -->  00:04:31.750
and then see them how the computer classified them.
108

108

00:04:31.750  -->  00:04:34.223
So, on the left, what do you think this is?
109

109

00:04:35.320  -->  00:04:37.600
You probably said cheetah and you would be right,
110

110

00:04:37.600  -->  00:04:39.950
and this is what the computer said.
111

111

00:04:39.950  -->  00:04:41.120
Right away, right off the bat,
112

112

00:04:41.120  -->  00:04:42.610
we're going to learn how to read these images
113

113

00:04:42.610  -->  00:04:45.440
because, if you're going to go deep
114

114

00:04:45.440  -->  00:04:49.540
into convolutional neural networks, no pun intended,
115

115

00:04:49.540  -->  00:04:51.533
if you're going to start learning more and more
116

116

00:04:51.533  -->  00:04:54.400
about them and using them, you'll see a lot of these,
117

117

00:04:54.400  -->  00:04:56.980
and I've actually seen people read them incorrectly.
118

118

00:04:56.980  -->  00:05:01.340
So, here at the top, cheetah is what it actually is,
119

119

00:05:01.340  -->  00:05:04.770
so that's the actual correct label of the image,
120

120

00:05:04.770  -->  00:05:07.270
that's what the label of the image is,
121

121

00:05:07.270  -->  00:05:10.783
regardless of any processing and computer vision.
122

122

00:05:11.660  -->  00:05:13.830
And then here are the guesses,
123

123

00:05:13.830  -->  00:05:18.190
the top four or five sometimes guesses of the algorithm
124

124

00:05:18.190  -->  00:05:20.540
and they're given the probability.
125

125

00:05:20.540  -->  00:05:24.500
So the computer said, or the neural network said cheetah,
126

126

00:05:24.500  -->  00:05:26.190
leopard, snow leopard or Egyptian cat,
127

127

00:05:26.190  -->  00:05:27.410
it could be one of the four,
128

128

00:05:27.410  -->  00:05:29.030
and cheetah has the highest vote.
129

129

00:05:29.030  -->  00:05:30.847
And throughout this part of the course
130

130

00:05:30.847  -->  00:05:32.780
you'll understand what these votes mean
131

131

00:05:32.780  -->  00:05:34.760
and how they are derived.
132

132

00:05:34.760  -->  00:05:36.910
But for now it's pretty intuitive, right?
133

133

00:05:36.910  -->  00:05:38.240
It's a cheetah in reality
134

134

00:05:38.240  -->  00:05:40.600
and the neural network guessed right,
135

135

00:05:40.600  -->  00:05:43.410
it said with a high probability, about 95-99%,
136

136

00:05:43.410  -->  00:05:44.243
it's a cheetah.
137

137

00:05:45.810  -->  00:05:49.080
Then, the second one, what do you think that is?
138

138

00:05:49.080  -->  00:05:51.180
That is a bullet train.
139

139

00:05:51.180  -->  00:05:54.410
And the neural network was able to distinguish
140

140

00:05:54.410  -->  00:05:56.520
between bullet train, passenger car,
141

141

00:05:56.520  -->  00:05:57.980
subway train, electric locomotive.
142

142

00:05:57.980  -->  00:05:58.920
Those are the top choices,
143

143

00:05:58.920  -->  00:06:00.380
of course it had many more options.
144

144

00:06:00.380  -->  00:06:03.250
These neural networks learn to distinguish
145

145

00:06:03.250  -->  00:06:05.390
from not just four categories,
146

146

00:06:05.390  -->  00:06:08.640
from dozens, thousands of categories at the same time.
147

147

00:06:08.640  -->  00:06:11.230
So those are the four options that it picked.
148

148

00:06:11.230  -->  00:06:12.720
So that's a bullet train and it's a bullet train.
149

149

00:06:12.720  -->  00:06:14.620
So, what do you think the last one is?
150

150

00:06:17.220  -->  00:06:18.510
There are a couple of options,
151

151

00:06:18.510  -->  00:06:20.040
it's not very clear what it is.
152

152

00:06:20.040  -->  00:06:22.730
It could be a frying pan, could be a magnifying glass,
153

153

00:06:22.730  -->  00:06:27.730
it could be even maybe a pair of scissors, some might say.
154

154

00:06:27.980  -->  00:06:30.640
Well, the neural network said it was a pair of scissors.
155

155

00:06:30.640  -->  00:06:32.500
But you can see how you can go wrong here.
156

156

00:06:32.500  -->  00:06:35.420
First of all, it's not a very clear image,
157

157

00:06:35.420  -->  00:06:37.370
and also you can see that
158

158

00:06:37.370  -->  00:06:41.700
the probabilities are not as clear here,
159

159

00:06:41.700  -->  00:06:43.850
so the neural network was a bit confused,
160

160

00:06:43.850  -->  00:06:46.910
a bit indecisive, just as we are.
161

161

00:06:46.910  -->  00:06:48.450
It said scissors with the highest probability
162

162

00:06:48.450  -->  00:06:51.263
but then it had hand glass, which it actually was,
163

163

00:06:51.263  -->  00:06:53.690
not so far away on the second place,
164

164

00:06:53.690  -->  00:06:55.810
and frying pan, stethoscope.
165

165

00:06:55.810  -->  00:06:58.360
So, basically, here you can see
166

166

00:06:58.360  -->  00:06:59.820
that scissors was its first guess
167

167

00:06:59.820  -->  00:07:01.520
but the correct option was number two
168

168

00:07:01.520  -->  00:07:03.190
and that's why it's highlighted in red.
169

169

00:07:03.190  -->  00:07:04.114
So there we go,
170

170

00:07:04.114  -->  00:07:06.950
that's what neural networks are already capable of.
171

171

00:07:06.950  -->  00:07:08.840
And this is actually quite an old slide,
172

172

00:07:08.840  -->  00:07:10.550
this was several years ago.
173

173

00:07:10.550  -->  00:07:12.650
Now they're even better and you will see that
174

174

00:07:12.650  -->  00:07:15.020
from the practical application
175

175

00:07:15.020  -->  00:07:16.840
that you'll be coding together with Hadelin.
176

176

00:07:16.840  -->  00:07:18.330
But now let's try and discern a bit better
177

177

00:07:18.330  -->  00:07:20.790
what ConvNets, or convolutional neural networks,
178

178

00:07:20.790  -->  00:07:23.840
actually are and why are they gaining so much popularity.
179

179

00:07:23.840  -->  00:07:25.860
And they actually are gaining popularity.
180

180

00:07:25.860  -->  00:07:29.470
You can see here a Google Trends comparison
181

181

00:07:29.470  -->  00:07:31.640
I did just yesterday.
182

182

00:07:31.640  -->  00:07:35.580
Here you can see that convolutional neural networks
183

183

00:07:35.580  -->  00:07:39.390
are even taking over artificial neural networks,
184

184

00:07:39.390  -->  00:07:43.160
so a massive increase
185

185

00:07:43.160  -->  00:07:44.810
and this is just gonna keep going that way
186

186

00:07:44.810  -->  00:07:48.380
because it is a very important field,
187

187

00:07:48.380  -->  00:07:50.760
that is where all the things happen.
188

188

00:07:50.760  -->  00:07:52.440
Such as self-driving cars,
189

189

00:07:52.440  -->  00:07:55.860
how do they recognize people on the road,
190

190

00:07:55.860  -->  00:07:57.820
how they recognize stops signs and things like that.
191

191

00:07:57.820  -->  00:08:02.820
How is Facebook able to tag images or people in images,
192

192

00:08:04.840  -->  00:08:06.400
and no only just,
193

193

00:08:06.400  -->  00:08:08.720
remember, previously, years ago,
194

194

00:08:08.720  -->  00:08:10.510
you had to tag people yourself,
195

195

00:08:10.510  -->  00:08:12.590
then, it would recognize faces,
196

196

00:08:12.590  -->  00:08:14.160
you'd had to add the names,
197

197

00:08:14.160  -->  00:08:16.380
and now it just recognizes the faces
198

198

00:08:16.380  -->  00:08:18.500
and adds the names at the same time,
199

199

00:08:18.500  -->  00:08:22.490
well, that is what convolutional neural networks
200

200

00:08:22.490  -->  00:08:23.700
are capable of.
201

201

00:08:23.700  -->  00:08:25.053
And speaking of Facebook,
202

202

00:08:26.030  -->  00:08:28.717
if Geoffrey Hinton is the godfather
203

203

00:08:28.717  -->  00:08:32.890
of artificial neural networks and deep learning,
204

204

00:08:32.890  -->  00:08:35.801
then Yann LeCun is the grandfather
205

205

00:08:35.801  -->  00:08:39.040
of convolutional neural networks.
206

206

00:08:39.040  -->  00:08:42.253
Yann LeCun is a student of Geoffrey Hinton's,
207

207

00:08:43.290  -->  00:08:45.433
in fact, here you can see them together.
208

208

00:08:46.310  -->  00:08:51.310
Geoffrey Hinton now is pioneering deep learning at Google,
209

209

00:08:51.320  -->  00:08:52.650
Yann LeCun is the director
210

210

00:08:52.650  -->  00:08:54.810
of Facebook Artificial Intelligence Research
211

211

00:08:54.810  -->  00:08:56.900
and also a professor at NYU.
212

212

00:08:56.900  -->  00:09:00.040
So, slowly we're, I love this party of the course,
213

213

00:09:00.040  -->  00:09:03.280
slowly we're building up these names
214

214

00:09:03.280  -->  00:09:07.410
or this picture of the profiles of the people
215

215

00:09:07.410  -->  00:09:09.300
who are driving this field,
216

216

00:09:09.300  -->  00:09:12.490
and in the next couple of parts
217

217

00:09:12.490  -->  00:09:14.330
we'll get to know about a few more
218

218

00:09:14.330  -->  00:09:17.350
and we'll have this whole Mafia, as they call themselves,
219

219

00:09:17.350  -->  00:09:18.720
or Yann LeCun calls them,
220

220

00:09:18.720  -->  00:09:20.990
Mafia or Conspiracy of Deep Learning
221

221

00:09:20.990  -->  00:09:22.240
and you'll learn a bit more
222

222

00:09:22.240  -->  00:09:24.430
about how this whole field developed.
223

223

00:09:24.430  -->  00:09:27.640
Yeah, these are just some great, great people.
224

224

00:09:27.640  -->  00:09:31.310
So, Yann LeCun, back in the '80s and the '90s,
225

225

00:09:31.310  -->  00:09:33.500
made significant contributions
226

226

00:09:33.500  -->  00:09:36.200
to the field of convolutional neural networks
227

227

00:09:36.200  -->  00:09:39.620
and, as we will see throughout this course,
228

228

00:09:39.620  -->  00:09:43.790
has been able to develop, or help the world develop,
229

229

00:09:43.790  -->  00:09:46.540
something so extremely powerful.
230

230

00:09:46.540  -->  00:09:51.043
So, moving on to how convolutional neural networks work.
231

231

00:09:52.680  -->  00:09:54.190
It's very simple, it's very straightforward.
232

232

00:09:54.190  -->  00:09:56.080
You have an input image,
233

233

00:09:56.080  -->  00:09:58.280
it goes through the convolutional neural network,
234

234

00:09:58.280  -->  00:09:59.710
and you have an output label
235

235

00:09:59.710  -->  00:10:02.763
so it classifies that image as something,
236

236

00:10:03.870  -->  00:10:06.670
like, as a cheetah or a bullet train or something else.
237

237

00:10:06.670  -->  00:10:10.780
Now, kind of like going into a bit more detail.
238

238

00:10:10.780  -->  00:10:14.880
For instance, after a neural network has been trained up
239

239

00:10:14.880  -->  00:10:19.690
on certain images, on certain classified images,
240

240

00:10:19.690  -->  00:10:23.600
or categorized the images that have been categorized prior,
241

241

00:10:23.600  -->  00:10:25.060
after that you can give it,
242

242

00:10:25.060  -->  00:10:26.740
let's say a neural network has been trained up
243

243

00:10:26.740  -->  00:10:30.410
to recognize facial expressions, emotions,
244

244

00:10:30.410  -->  00:10:33.400
you can give it a face of a smiling person,
245

245

00:10:33.400  -->  00:10:37.270
not just a drawing of a face like this
246

246

00:10:37.270  -->  00:10:39.340
but an actual face of a person smiling,
247

247

00:10:39.340  -->  00:10:41.520
and it'll tell you that that person is happy.
248

248

00:10:41.520  -->  00:10:44.770
And you can give it a face of a person that's frowning,
249

249

00:10:44.770  -->  00:10:46.670
it'll tell you that the person is sad.
250

250

00:10:47.532  -->  00:10:48.500
It can recognize these emotions.
251

251

00:10:48.500  -->  00:10:50.950
And, as you can see, that's already very powerful
252

252

00:10:50.950  -->  00:10:53.210
in terms of so many different applications
253

253

00:10:53.210  -->  00:10:57.633
just off this one example you can think of right away.
254

254

00:10:58.483  -->  00:11:00.600
And in both cases it will give you a probability,
255

255

00:11:00.600  -->  00:11:04.870
it won't say with 100% that person's happy or sad,
256

256

00:11:04.870  -->  00:11:07.660
it will be 99 or 98,
257

257

00:11:07.660  -->  00:11:11.770
or maybe 80% when it's unclear of what's going on.
258

258

00:11:11.770  -->  00:11:12.910
Just like we are, right?
259

259

00:11:12.910  -->  00:11:16.550
Sometimes we can mistake things for what they're not,
260

260

00:11:16.550  -->  00:11:20.500
or sometimes we can, sometimes it's just not clear
261

261

00:11:20.500  -->  00:11:22.180
if the person is smiling or frowning
262

262

00:11:22.180  -->  00:11:24.650
or if it's a dog or a cat
263

263

00:11:24.650  -->  00:11:28.410
or if it's a train or a bullet train,
264

264

00:11:28.410  -->  00:11:30.940
sometimes we haven't seen enough features.
265

265

00:11:30.940  -->  00:11:32.280
It all goes down to features
266

266

00:11:32.280  -->  00:11:35.780
because that's how we process visual information,
267

267

00:11:35.780  -->  00:11:38.293
as we saw from the start of this tutorial.
268

268

00:11:39.160  -->  00:11:41.150
But how does a neural network,
269

269

00:11:41.150  -->  00:11:44.030
how is a neural network able to recognize these features?
270

270

00:11:44.030  -->  00:11:47.733
Well, it all starts at the very basic level.
271

271

00:11:48.668  -->  00:11:50.680
Let's say you have an image, you have two images,
272

272

00:11:50.680  -->  00:11:53.920
one is a black and white image of two by two pixels,
273

273

00:11:53.920  -->  00:11:56.420
and one is a colored image of two by two pixels.
274

274

00:11:56.420  -->  00:11:59.160
Well, neural networks leverage the fact
275

275

00:11:59.160  -->  00:12:04.160
that the black and white image is a two-dimensional array.
276

276

00:12:04.600  -->  00:12:07.130
So the way we see it right now on the left
277

277

00:12:07.130  -->  00:12:09.770
is just the visual representation,
278

278

00:12:09.770  -->  00:12:11.170
just some kind of picture,
279

279

00:12:11.170  -->  00:12:14.000
and for simplicity's sake it's just a two by two picture.
280

280

00:12:14.000  -->  00:12:15.270
But in computer terms,
281

281

00:12:15.270  -->  00:12:16.840
it's actually a two-dimensional array
282

282

00:12:16.840  -->  00:12:19.430
with every single one of those pixels
283

283

00:12:19.430  -->  00:12:22.260
having a value between zero and 255.
284

284

00:12:22.260  -->  00:12:24.971
So that's eight bits of information,
285

285

00:12:24.971  -->  00:12:27.560
two to the power of eight is 256,
286

286

00:12:27.560  -->  00:12:30.260
so, therefore, the values are from zero to 255,
287

287

00:12:30.260  -->  00:12:32.140
and that's the intensity of the color,
288

288

00:12:32.140  -->  00:12:33.410
and, in this case, the color white.
289

289

00:12:33.410  -->  00:12:36.190
So zero will be a completely black pixel,
290

290

00:12:36.190  -->  00:12:38.560
255 will be a completely white pixel,
291

291

00:12:38.560  -->  00:12:42.030
and between them you have the grayscale range
292

292

00:12:42.030  -->  00:12:44.530
of possible options for this pixel.
293

293

00:12:44.530  -->  00:12:46.430
And based on that information,
294

294

00:12:46.430  -->  00:12:49.920
computers are able to then work with the image.
295

295

00:12:49.920  -->  00:12:51.340
And that's kind of like the starting point,
296

296

00:12:51.340  -->  00:12:55.080
that any image has a digital representation,
297

297

00:12:55.080  -->  00:12:56.480
has a digital form
298

298

00:12:56.480  -->  00:12:59.370
and those are just basically ones and zeros
299

299

00:12:59.370  -->  00:13:03.180
that form a number of zero to 255 for every single pixel.
300

300

00:13:03.180  -->  00:13:04.270
That's what the computer works with.
301

301

00:13:04.270  -->  00:13:06.910
It doesn't actually work with colors or anything,
302

302

00:13:06.910  -->  00:13:08.700
it works with the ones and zeros at the end of the day.
303

303

00:13:08.700  -->  00:13:12.373
That's kind of like the foundation of it all.
304

304

00:13:13.250  -->  00:13:15.093
And in a colored image
305

305

00:13:15.093  -->  00:13:17.110
it's actually a three-dimensional array.
306

306

00:13:17.110  -->  00:13:22.069
You've got a blue layer, a green layer and a red layer,
307

307

00:13:22.069  -->  00:13:25.330
and that stands for RGB, red, green, blue,
308

308

00:13:25.330  -->  00:13:29.680
and each one of those colors has its own intensity.
309

309

00:13:29.680  -->  00:13:34.680
So, basically, a pixel has three values assigned to it,
310

310

00:13:36.910  -->  00:13:41.280
each one of them is between zero and 255,
311

311

00:13:41.280  -->  00:13:46.060
and, therefore, you can find out what this image,
312

312

00:13:46.060  -->  00:13:48.260
what color exactly this pixel is
313

313

00:13:48.260  -->  00:13:50.220
by combining those three values.
314

314

00:13:50.220  -->  00:13:53.430
And, again, computers are going to be working with that.
315

315

00:13:53.430  -->  00:13:55.700
So that's the foundation of it all,
316

316

00:13:55.700  -->  00:13:59.440
that's the red channel, the green channel, the blue channel.
317

317

00:13:59.440  -->  00:14:03.480
And finally let's have a look at, for instance,
318

318

00:14:03.480  -->  00:14:05.440
an example, a very trivial example
319

319

00:14:05.440  -->  00:14:09.510
of a smiling face in computer terms.
320

320

00:14:09.510  -->  00:14:12.150
If we just really simplify things,
321

321

00:14:12.150  -->  00:14:15.800
instead of having from zero to 255,
322

322

00:14:15.800  -->  00:14:17.060
instead of having those values,
323

323

00:14:17.060  -->  00:14:18.960
just so that we can understand things better
324

324

00:14:18.960  -->  00:14:20.950
and really grasp the concepts,
325

325

00:14:20.950  -->  00:14:25.950
we're going to say zero is white, one is black, right?
326

326

00:14:26.720  -->  00:14:30.810
So we're just going to simplify things to the extreme
327

327

00:14:30.810  -->  00:14:32.570
and you will see that that image
328

328

00:14:32.570  -->  00:14:33.910
can be represented like that.
329

329

00:14:33.910  -->  00:14:35.930
So the reason why we brought this up is
330

330

00:14:35.930  -->  00:14:37.530
because we're going to,
331

331

00:14:37.530  -->  00:14:38.830
all over in our intuition tutorials
332

332

00:14:38.830  -->  00:14:40.750
we're going to structure on images like this,
333

333

00:14:40.750  -->  00:14:43.200
which are very simple but at the same time
334

334

00:14:43.200  -->  00:14:45.277
then have all of those concepts can transcend back to
335

335

00:14:45.277  -->  00:14:48.860
the the zero to 256 range of values
336

336

00:14:48.860  -->  00:14:50.620
and everything applies the same way there.
337

337

00:14:50.620  -->  00:14:52.150
And the steps that we're going to be going through
338

338

00:14:52.150  -->  00:14:53.310
with these images are:
339

339

00:14:53.310  -->  00:14:54.840
step number one, convolution;
340

340

00:14:54.840  -->  00:14:56.730
step number two, max pooling;
341

341

00:14:56.730  -->  00:14:58.420
step number three, flattening;
342

342

00:14:58.420  -->  00:15:00.350
and step number four, full connection.
343

343

00:15:00.350  -->  00:15:03.380
And I can imagine that probably none of these words
344

344

00:15:03.380  -->  00:15:05.710
mean much to you at the moment,
345

345

00:15:05.710  -->  00:15:08.310
but by the end of this section of the course
346

346

00:15:08.310  -->  00:15:11.630
you will understand them in great detail
347

347

00:15:11.630  -->  00:15:13.860
and exactly what they're doing.
348

348

00:15:13.860  -->  00:15:15.930
So, we'll get started on the next tutorial.
349

349

00:15:15.930  -->  00:15:17.980
For now, the additional reading
350

350

00:15:17.980  -->  00:15:20.290
that you might want to look into
351

351

00:15:20.290  -->  00:15:23.790
is Yann LeCun's original paper
352

352

00:15:23.790  -->  00:15:28.120
that gave the rise to convolutional neural networks,
353

353

00:15:28.120  -->  00:15:28.953
it's called
354

354

00:15:28.953  -->  00:15:31.550
Gradient-Based Learning Applied to Document Recognition.
355

355

00:15:31.550  -->  00:15:33.300
You may have seen this image before
356

356

00:15:33.300  -->  00:15:35.690
floating around the Internet, it is from that paper.
357

357

00:15:35.690  -->  00:15:38.680
So if you wanna go back to the very beginnings
358

358

00:15:39.590  -->  00:15:41.840
of how it all happened, where it all came from,
359

359

00:15:41.840  -->  00:15:44.420
this is the paper to look into.
360

360

00:15:44.420  -->  00:15:46.310
And I look forward to seeing you on the next tutorial.
361

361

00:15:46.310  -->  00:15:48.373
Until then, enjoy deep learning.
