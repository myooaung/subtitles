WEBVTT

00:00.500 --> 00:02.880
Arrive exciting tutorial ahead.

00:02.880 --> 00:04.780
Welcome back to the course on deep learning.

00:04.800 --> 00:08.050
Today we're talking about how neural networks work.

00:08.070 --> 00:13.800
Now we've led a lot of ground work we've talked about how neural networks are structured what elements

00:13.800 --> 00:16.380
they consist of and even their functionality.

00:16.590 --> 00:21.960
And today we're going to look at a real example of how unusual neural network can be applied and we're

00:21.960 --> 00:28.320
actually going to work step by step through the process of its application so we know what's going on.

00:28.320 --> 00:30.720
So let's have a look what example we're going to be talking about.

00:30.750 --> 00:37.110
We're going to be looking at a property evaluation so we're going to look at a neural network that takes

00:37.110 --> 00:39.520
in some parameters of our property and value values.

00:39.570 --> 00:40.890
And the thing here.

00:40.920 --> 00:45.780
There's a small caveat for today's tutorial and that is we're not actually going to train the network.

00:45.780 --> 00:50.820
So a very important part in neural networks is training them up and we are going to look at that in

00:50.820 --> 00:53.390
the next tutorials in this section.

00:53.400 --> 00:57.480
For now we're going to focus on the actual applications that we're going to work with a neural network

00:57.480 --> 01:04.510
that we're going to pretend is already trained up and that will allow us to focus on the application

01:04.510 --> 01:09.330
side of things and not get bogged down in the training aspect and then will cower off the training when

01:09.330 --> 01:11.700
we already know the end goal we're working towards.

01:11.730 --> 01:12.430
Sounds good.

01:12.570 --> 01:14.860
All right let's jump straight into it.

01:15.210 --> 01:19.040
So let's say we have some input parameters.

01:19.050 --> 01:24.140
Right so let's say we have four parameters about the property we have area in square feet.

01:24.150 --> 01:29.430
We have the number of bedrooms that distance the city and Miles the New York City and the age of the

01:29.430 --> 01:33.460
property and all of those four are going to comprise our input layer.

01:33.600 --> 01:40.770
Now of course they're probably way more parameters that define the price of a property but for simplicity's

01:40.770 --> 01:47.460
sake we're going to look at just these for now in its very basic form a neural network only has an input

01:47.460 --> 01:52.230
learn an output there so no hidden layers and our output layer is the price that we're predicting.

01:52.230 --> 02:00.930
So in this form what these inputs variables would do is they would just be weighted up by the syllabuses

02:00.960 --> 02:06.150
and then the output there would be calculated basically the price of recalculate and we get a price.

02:06.150 --> 02:14.220
And for instance the price can be calculated as simple as the weighted sum of all of the inputs.

02:14.220 --> 02:17.620
And again here you could use pretty much any function you could use.

02:17.750 --> 02:19.040
What we're using now.

02:19.090 --> 02:26.160
We could use any of the activation functions we had previously you could use logistic regression you

02:26.160 --> 02:30.950
could use a squared function you could approach anything here.

02:31.140 --> 02:33.460
But the point is that you get a certain output.

02:33.490 --> 02:40.940
And moreover most of the machine learning algorithms that exist can be represented in this form.

02:40.950 --> 02:46.500
This is basically diagrammatic representation of how you deal with the variables by changing the way

02:46.500 --> 02:47.180
it's a formalised.

02:47.310 --> 02:54.030
You can accomplish quite a lot of the machine learning algorithms that we've talked about before and

02:54.030 --> 02:58.820
put them into this form and that just tends to show how powerful new neural networks are.

02:58.890 --> 03:04.200
Even without the hidden layers we are already where we have a representation that works for most other

03:04.200 --> 03:05.340
machine learning algorithms.

03:05.430 --> 03:12.450
But in neural networks what we do have is an extra advantage that gives us lots of flexibility and power

03:12.780 --> 03:16.950
which is where that increase in accuracy comes from.

03:17.010 --> 03:24.360
And that power is the hidden layers and there we go that's our here and there were added in and now

03:24.360 --> 03:30.020
we're going to understand how that hit in Lair gives us that extra power.

03:30.240 --> 03:35.770
And in fact to do that we're going to walk through an example so as we agreed this neural network has

03:35.770 --> 03:40.110
already been trained up and now we're just going to plug in we're going to imagine that we're plugging

03:40.110 --> 03:48.280
in a property and we're going to walk step by step through how the neural network will deal with the

03:48.300 --> 03:51.840
input variables and calculate the Himalaya and then calculate the output layer.

03:51.840 --> 03:54.360
So let's go through this is going to be exciting.

03:54.360 --> 03:59.940
All right we've got all four variables on the left and we're going to first start with the top Nurin

03:59.940 --> 04:01.300
on the hidden lair.

04:01.380 --> 04:08.250
Now as we previously saw in the press and morals all of the neurons from the input layer they have Cynapsus

04:08.250 --> 04:13.040
connecting it to each one of them to the top neuron in a hidden lair.

04:13.440 --> 04:15.160
And those sytems have weights.

04:15.180 --> 04:20.430
Now let's agree that some weights will have a non-zero value some ways will have zero value because

04:20.670 --> 04:28.320
basically not all inputs will be valid or not all inputs will be important for every single neuron sometimes

04:28.320 --> 04:29.370
inputs will not be important.

04:29.370 --> 04:34.140
Here we can see two examples that X-1 makes three the area and the distance to the city and Miles are

04:34.140 --> 04:35.430
important for that.

04:35.640 --> 04:40.170
Whereas bedrooms and age are not like let's think about this for a second why how would that be the

04:40.170 --> 04:40.500
case.

04:40.500 --> 04:47.310
Like why would a neuron be linked to the area in the distance what does that what could that mean.

04:47.310 --> 04:53.370
Well that could mean that normally the further we get from the city the cheaper real estate becomes

04:53.370 --> 04:58.360
and therefore the space in square feet of properties becomes larger.

04:58.360 --> 05:02.660
So for the same price you can get a lot of the further away you go from the city that's normal right.

05:02.660 --> 05:09.200
That makes sense and probably what this neuron is doing is it is looking specifically it's like like

05:09.210 --> 05:17.280
a sniper it's looking for area properties which have which are not so far from the city but have a large

05:17.280 --> 05:17.540
area.

05:17.550 --> 05:24.780
So for their distance from the city they have an unfair square foot area.

05:24.810 --> 05:25.050
Right.

05:25.050 --> 05:28.770
So something that's abnormal height is higher than average so they're quite close to the city but they're

05:28.770 --> 05:32.850
still large as opposed to the other ones at the same distance.

05:33.040 --> 05:38.790
And so that neuron again we're speculating here but that neuron might be picking out laser picking out

05:38.850 --> 05:44.110
those specific properties and it will activate and hence the activation function it will activate will

05:44.130 --> 05:49.550
fire up only when the certain criteria is met that you know the distance and the area of the proper

05:49.560 --> 05:54.720
distance the city and the air of the area of the property and it performs on calculations inside itself

05:55.380 --> 06:00.600
and it combines those two and as soon as certain areas when it fires up and that contributes to the

06:00.600 --> 06:05.580
price in the output list and therefore this neuron doesn't really care about bedrooms and age of the

06:05.580 --> 06:07.660
property because it's focused on that specific thing.

06:07.680 --> 06:12.570
That's where the power of the neural network comes from because you have many of these years and all

06:12.570 --> 06:14.160
see just now how the other ones work.

06:14.170 --> 06:20.880
So but what I wanted to agree here is that let's not even draw these lines for the syllabuses that are

06:20.880 --> 06:25.770
not in play so that we don't clutter up our image as the only reason we're not going to draw them so

06:25.980 --> 06:27.330
let's just get rid of those too.

06:27.420 --> 06:33.900
And that way we will know exactly OK so this neuron is focused on area and distance to the city.

06:33.900 --> 06:34.860
All right.

06:34.860 --> 06:36.790
So as long as we agree on that let's move on to next.

06:36.810 --> 06:42.330
Let's take them one in the middle here we've got three parameters feeding into this neuron so we've

06:42.330 --> 06:45.700
got the area the bedrooms and the age of the property.

06:45.960 --> 06:48.680
So what could be the reason here.

06:48.720 --> 06:54.630
Again let's try to understand the intuition and the thinking of this neuron.

06:54.630 --> 06:58.690
How is this neuron thinking why is it picking these three programs what could it be.

06:58.800 --> 07:02.080
What could have a head like found in the data.

07:02.080 --> 07:06.510
Right so we've already established this trained up data set the training has happened a long time ago

07:06.510 --> 07:11.520
maybe like a day ago or somebody is written up as it is now we're just applying and we know that this

07:11.520 --> 07:17.550
neuron through all of the thousands of examples of properties has found out that the area plus the bedrooms

07:17.580 --> 07:20.530
plus the age combination of those parameters is important.

07:20.550 --> 07:21.560
Why could that be the case.

07:21.570 --> 07:29.340
Well for instance maybe in that specific city in those suburbs that this neural network has been trained

07:29.340 --> 07:38.790
up in perhaps there's a lot of families with kids who have two or more children who are looking for

07:39.930 --> 07:43.550
large properties with lots of bedrooms which are new.

07:43.590 --> 07:52.170
Which are not old properties because maybe that's in that area almost all are kind of like big properties

07:52.170 --> 07:52.860
are usually old.

07:52.880 --> 07:58.740
But there's lots of modern families and you know maybe there has been a social demographic shift and

07:59.370 --> 08:06.720
or maybe there's been like a lot of like some growth in terms of employment and jobs for the younger

08:06.720 --> 08:13.800
self population maybe just you know the like the population demographics have changed and now younger

08:14.490 --> 08:21.450
couples or younger families are looking for properties but they prefer new property so they want the

08:21.450 --> 08:27.480
age of the property to be lower and hence from the training that this neural network has undergone it

08:27.540 --> 08:32.850
knows that when there's a property with a large area and with lots of better with at least three at

08:32.850 --> 08:36.510
least three bedrooms for the parents for the first child the second child for at least three bedrooms

08:36.510 --> 08:44.730
maybe a guest room when you property with high area and lots of bedrooms that is valued that in that

08:44.730 --> 08:48.210
market that is valuable so that neuron has picked that up.

08:48.210 --> 08:49.340
It knows that.

08:49.350 --> 08:51.420
OK so this is what I'm going to be looking for.

08:51.420 --> 08:54.140
I don't care about the distance to the city and Miles wherever it is.

08:54.420 --> 08:57.030
As long as it has high area lots of bedrooms.

08:57.060 --> 08:59.750
As soon as that criteria is met then you're on fire is up.

08:59.760 --> 09:03.870
And the combination of these two parameters and this is again this is where the power of the neural

09:03.870 --> 09:10.340
network is coming from because it combines these three parameters into a brand new parameter into brand

09:10.340 --> 09:15.900
new attributes that helps with the evaluation.

09:15.930 --> 09:17.820
The helps with the valuation of the property.

09:17.820 --> 09:21.530
It combines them into an attribute and therefore it's more precise.

09:21.870 --> 09:24.120
So there we go that's how that works.

09:24.210 --> 09:29.970
And let's look at another one let's look at the very bottom one for us is this neuron could be could

09:29.970 --> 09:35.490
even have picked up just one parameter it could have just picked up H and not in any of the other ones.

09:35.490 --> 09:37.830
And how could that be the case.

09:37.830 --> 09:45.720
Well this is a classic example of when age could mean like as we all know the older properties usually

09:45.720 --> 09:47.630
it's less valuable because it's worn out.

09:47.640 --> 09:49.690
Probably the building is old probably.

09:49.700 --> 09:54.720
Now if things are falling apart more maintenance is required so the price drops in terms of the price

09:54.720 --> 09:55.410
of the real estate.

09:55.410 --> 10:00.520
Whereas a brand new building it would be more expensive because it's brand new but perhaps if a property

10:00.520 --> 10:03.940
is over a certain age that could indicate that it's a historic property.

10:03.980 --> 10:11.200
For instance if a property is under 100 years old then the older it is the less valuable it is.

10:11.330 --> 10:17.000
But as soon as it jumps over 100 years old all of a sudden it becomes a historic property because this

10:17.000 --> 10:20.800
is a property where people used to live hundreds of years ago.

10:20.810 --> 10:26.170
It tells a story it's got all this history behind it and some people like that some people value that.

10:26.210 --> 10:32.060
In fact quite a lot of people would like that and would be proud to live in a property and especially

10:32.060 --> 10:37.970
in the higher socioeconomic classes they would show off to their friends or things like that and therefore

10:38.060 --> 10:42.260
properties that are over 100 years old could be deemed as historic.

10:42.260 --> 10:46.320
And therefore this neuron as soon as it sees a property over 100 years old.

10:46.320 --> 10:49.300
It'll fire up and contribute to the overall price.

10:49.310 --> 10:53.030
And otherwise if it's under 100 years old then it won't do and where it can.

10:53.090 --> 10:55.040
This is a good example of that.

10:55.130 --> 10:57.530
The rectifier function being applied.

10:57.530 --> 11:04.490
So here you've got like a very like a zero until a certain point and then let's say 100 years old.

11:04.490 --> 11:09.260
And then after 100 years old the older it gets the higher the value the higher the contribution of this

11:09.260 --> 11:11.390
neuron to the overall price.

11:11.420 --> 11:18.860
And there's just a wonderful example of a very simple example of this rectifier Fange function in action.

11:18.860 --> 11:19.700
So there we go.

11:19.700 --> 11:20.880
That could be this year.

11:21.050 --> 11:27.790
And moreover the neural network could have picked up things that we wouldn't have thought of ourselves

11:27.800 --> 11:28.480
right.

11:28.520 --> 11:34.280
For instance bedrooms plus distance the city maybe that's in combination somehow contributes to the

11:34.290 --> 11:38.660
price maybe it's not as strong as the other neurons and it contributes but it still contributes or maybe

11:38.840 --> 11:43.460
it detracts from the price that could also be the case or other things like that and maybe add your

11:43.460 --> 11:47.330
own picked up all for a combination of all four of these parameters.

11:47.330 --> 11:56.360
And as you can see that these neurons this whole hidden layer situation allows you to increase the flexibility

11:56.420 --> 12:03.680
of your neural network and allows you to really allows the neural network to look for very specific

12:03.680 --> 12:09.610
things and then in combination that's where the power comes from it's like that example the answer I'd

12:09.610 --> 12:12.500
like an ad by itself cannot build an anthill.

12:12.500 --> 12:17.860
But when you have like a thousand or 100000 ads they can build an anthill together and that's that's

12:17.870 --> 12:18.550
the situation you know.

12:18.560 --> 12:20.980
Each one of these years by itself cannot predict the price.

12:21.050 --> 12:27.860
But together they have super powers and they predict the price and they can do quite an accurate job

12:27.890 --> 12:30.250
if trained properly set up properly.

12:30.680 --> 12:35.300
And that's what this whole Course is about in understanding how to utilize them.

12:35.300 --> 12:42.390
There we go so that is a step by step example and walk through of how neural networks actually work.

12:42.410 --> 12:45.560
I hope you enjoyed today's tutorial and I can't wait to see you next time.

12:45.560 --> 12:47.300
Until then enjoy deep learning.
