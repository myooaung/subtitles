WEBVTT

00:00.520 --> 00:04.870
Hello and welcome back to the course on deep learning I hope you're tracking along with these intuition

00:04.870 --> 00:10.930
tutorials just fine and that you had a chance to play around with everything we've learned so far and

00:10.930 --> 00:15.850
today we're talking about flattening and the good news is that this is a very simple step and this story

00:15.850 --> 00:21.850
is going to be very quick and then we'll be able to move on to the next interesting things.

00:21.850 --> 00:28.780
All right so we so far we've got the pulled Lehre pulled feature map and that is after we apply the

00:28.780 --> 00:33.970
convolution operation to our image and then we apply pooling to the result of the collision or to the

00:33.970 --> 00:34.930
involved image.

00:35.080 --> 00:37.490
And so what are we going to do if this pull feature up.

00:37.540 --> 00:41.340
Well we're going to take it and we get to flatten it into a column.

00:41.590 --> 00:47.080
So basically just take the numbers row by row and put them into this one long column.

00:47.140 --> 00:53.620
And the reason for that is because we want to later in put this into an artificial neural network for

00:53.620 --> 00:55.270
further processing.

00:55.270 --> 01:00.070
So this is what it looks like when you have many pooling layers or you have the pooling there with many

01:00.940 --> 01:07.840
puled feature maps and then you flatten them so you put them into this one long column sequentially

01:07.840 --> 01:15.160
one after the other and you get one huge vector of inputs for an artificial neural network.

01:15.370 --> 01:19.360
And so to sum all of this up we've got an input image.

01:19.360 --> 01:27.270
We apply a convolutional there and let's not forget the reals or rectified rectified linear units function

01:27.280 --> 01:28.090
that we apply.

01:28.360 --> 01:37.270
After the revolution there as well and then we apply pooling and then we flatten everything into a long

01:37.270 --> 01:44.530
vector which will be our input layer for an artificial neural network and exactly how that works we'll

01:44.530 --> 01:47.160
find out in the next tutorial.

01:47.170 --> 01:49.960
Hope you enjoyed today's session and looks forward to you next time.

01:49.960 --> 01:51.990
Until then enjoy deep learning.
