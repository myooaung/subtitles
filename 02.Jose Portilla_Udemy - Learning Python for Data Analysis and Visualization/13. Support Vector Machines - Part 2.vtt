WEBVTT
1
00:00:01.830 --> 00:00:06.570
Hai semuanya, selamat datang di kuliah kedua di bagian mesin vektor dukungan bagian pembelajaran mesin

2
00:00:06.740 --> 00:00:07.900
dari kursus ini.

3
00:00:08.280 --> 00:00:13.470
Jadi yang akan kami lakukan adalah Anda ingin mempelajari lima situs web SVM.

4
00:00:13.470 --> 00:00:19.360
Jadi kita akan beralih ke beberapa kode Python dan belajar dan kita akan melihat bagaimana menerapkan mesin

5
00:00:19.690 --> 00:00:24.300
vektor dukungan pada status iris dataset yang sudah kita kenal dari kuliah sebelumnya.

6
00:00:24.300 --> 00:00:27.730
Ayo maju dan lompat sekarang ke kode kehidupan.

7
00:00:27.730 --> 00:00:30.050
Jadi mari kita mulai dengan beberapa impor di sini.

8
00:00:30.050 --> 00:00:43.430
Saya penting karena mereka akan mengimpor petak peta, pikiran hidup, mengetikkan petak sebagai halal dan kemudian saya memiliki

9
00:00:43.430 --> 00:00:48.110
petak peta perintah saya secara langsung.

10
00:00:48.110 --> 00:00:53.030
Tidak akan mengimpor seaborne karena kami sudah melakukan analisis data visual pada set data

11
00:00:53.030 --> 00:00:54.070
bunga iris.

12
00:00:54.960 --> 00:01:01.570
Jadi kita hanya akan menggunakan Lib nanti untuk menunjukkan kepada Anda perbedaan antara metode SBM linear

13
00:01:01.600 --> 00:01:05.240
dan non-linear seperti yang Anda pelajari dengan baik.

14
00:01:05.460 --> 00:01:09.070
Hal-hal dari psikologi yang Anda pelajari saat kita jalan dan membutuhkannya.

15
00:01:09.070 --> 00:01:18.290
Hal pertama yang akan kita lakukan adalah mengatakan dari Eskay mempelajari set data impor.

16
00:01:18.290 --> 00:01:24.550
Dan setelah kami melakukannya, kami akan melanjutkan dan mengimpor set data iris dan saya bisa melakukannya.

17
00:01:24.550 --> 00:01:29.460
Saya akan membuat objek yang disebut Iris sama dengan set data.

18
00:01:29.460 --> 00:01:32.210
Saya pikir memuat garis bawah.

19
00:01:32.210 --> 00:01:35.400
Iris.

20
00:01:35.400 --> 00:01:40.140
Dan kemudian apa yang akan saya lakukan adalah mengambil fitur yang akan saya beri label X dan

21
00:01:40.140 --> 00:01:42.590
mudah-mudahan ini akrab bagi Anda dari kuliah sebelumnya.

22
00:01:43.560 --> 00:01:47.410
Dan kemudian saya akan mendapatkan target saya.

23
00:01:47.410 --> 00:01:48.980
Kelas bunga miliknya.

24
00:01:50.420 --> 00:01:52.350
Dan atur itu sebagai x dan y.

25
00:01:52.940 --> 00:01:58.330
Dan kalau-kalau Anda tidak akrab dengan iris mereka sedikit kabur.

26
00:01:58.330 --> 00:02:02.130
Semoga Anda sudah terbiasa dengan apa yang kami lakukan di kuliah sebelumnya tetapi Anda

27
00:02:02.130 --> 00:02:03.880
selalu bisa mengatakan pemikiran Iris.

28
00:02:03.880 --> 00:02:10.330
D E S C R dalam semua topi dan cetak deskripsi dari database tanaman iris.

29
00:02:10.330 --> 00:02:15.180
Jadi hanya pengingat cepat mengingat mereka memiliki kehidupan yang sederhana dan melihat orang dengan dan kemudian mengayuh dan

30
00:02:15.180 --> 00:02:15.540
mengayuh.

31
00:02:15.540 --> 00:02:18.360
Dan itu milik salah satu dari tiga kelas ini.

32
00:02:18.980 --> 00:02:21.580
Warna virginica.

33
00:02:21.580 --> 00:02:24.810
Jadi bergerak turun dan melanjutkan.

34
00:02:25.050 --> 00:02:33.530
Yang akan kita lakukan sekarang adalah mengimpor klasifikasi vektor dukungan dari perpustakaan SVM of psych learn.

35
00:02:33.530 --> 00:02:41.090
Jadi jika Anda melompat kembali ke sini ke buku catatan AI Python yang dapat Anda lakukan adalah memeriksa dua tautan bawaan ini.

36
00:02:41.090 --> 00:02:44.770
Ini mendukung klasifikasi vektor dari perpustakaan SVM of psych.

37
00:02:44.770 --> 00:02:45.440
Belajar.

38
00:02:45.830 --> 00:02:51.760
Dan tautan pertama SABC klasifikasi vektor dukungan hanya akan membawa Anda ke API dan Anda dapat melihat semua

39
00:02:51.760 --> 00:02:55.530
atribut dan hal-hal yang dapat Anda lewati serta contoh sederhana.

40
00:02:57.300 --> 00:03:02.670
Dan kemudian apa yang dapat Anda lakukan untuk mesin-mesin vektor pendukung adalah memeriksa

41
00:03:02.670 --> 00:03:07.290
situs ini yang mempelajari dokumentasi yang akan benar-benar melalui contoh klasifikasi ini

42
00:03:07.290 --> 00:03:08.870
sendiri dan sedikit.

43
00:03:08.870 --> 00:03:16.210
Tetapi memiliki contoh klasifikasi kelas dan banyak hal yang lebih mendalam dan masalah keseimbangan analisis regresi

44
00:03:16.240 --> 00:03:19.030
dari perkiraan kota dll dll.

45
00:03:19.030 --> 00:03:20.610
Jadi saya bisa memeriksanya.

46
00:03:20.610 --> 00:03:25.510
Seperti yang telah saya katakan sebelumnya bahwa Anda mempelajari dokumentasi ditulis dengan sangat baik

47
00:03:25.510 --> 00:03:29.180
sehingga selalu merupakan sumber yang bagus untuk Anda periksa.

48
00:03:29.180 --> 00:03:38.310
Kode kehidupan yang akan kita lakukan adalah mengatakan dari yang dipelajari sebagai impor GM di semua batas.

49
00:03:38.310 --> 00:03:40.030
SBC.

50
00:03:40.320 --> 00:03:43.060
Dan itu akan menjadi klasifikasi vektor dukungan.

51
00:03:43.410 --> 00:03:49.510
Jadi mudah-mudahan ini akan menjadi sedikit akrab bagi Anda berdasarkan kuliah pembelajaran mesin kami sebelumnya.

52
00:03:49.510 --> 00:03:56.790
Tapi langkah pertama adalah kita membuat model dan kita akan lakukan sekarang adalah membagi data menjadi satu set pelatihan dan

53
00:03:56.790 --> 00:03:59.380
set pengujian dan kemudian melatih model kita.

54
00:03:59.380 --> 00:04:05.760
Jadi katakanlah dari saat belajar pemikiran lintas

55
00:04:08.030 --> 00:04:13.570
validasi impor uji kereta split.

56
00:04:17.760 --> 00:04:25.410
Dan sekarang impor itu saya akan membagi data menjadi set pelatihan dan pengujian melihat

57
00:04:28.020 --> 00:04:41.410
katakanlah X train x tes dan kemudian y garis bawah kereta dan Y dan skor tes fisik mereka untuk melatih split tes dan semua

58
00:04:41.410 --> 00:04:43.920
lulus x dan y.

59
00:04:43.920 --> 00:04:47.980
Semoga ini terlihat akrab bagi Anda dari kuliah sebelumnya tetapi sekali lagi hanya gambaran singkat.

60
00:04:47.980 --> 00:04:56.270
Kami sedang melakukan kami mengambil fitur dan target kami dan membaginya menjadi set pelatihan jadi x train and y train dan kemudian

61
00:04:56.270 --> 00:05:03.100
set pengujian X test dan uji Y sehingga kami memiliki empat objek yang siap untuk kami tuju.

62
00:05:03.770 --> 00:05:08.100
Dan yang akan kita lakukan adalah maju dan muat model menggunakan data pelatihan kita.

63
00:05:08.420 --> 00:05:15.890
Jadi saya katakan model ketika saya lulus metode fit dan saya melewati data pelatihan kami sehingga kami

64
00:05:15.890 --> 00:05:24.070
ingin melatihnya menggunakan fitur X train dan kemudian memberikannya kepada target y train dan itu akan cocok dengan model kami.

65
00:05:25.550 --> 00:05:34.700
Hebat dan belajar melewati argumen lain ini semua argumen untuk klasifikasi faktor pendukung.

66
00:05:34.700 --> 00:05:42.450
Jadi sekarang kita bisa masuk dan melihat seberapa baik model kita lakukan dan apa yang bisa kita katakan dari saat mereka mempelajari metrik impor

67
00:05:44.240 --> 00:05:50.960
sehingga kita mengimpor metrik itu dan apa yang ingin kita lakukan adalah menguji model kita sesuai dengan menggunakan data pelatihan

68
00:05:51.070 --> 00:05:53.540
dan melihat seberapa baik memprediksi data pengujian.

69
00:05:53.900 --> 00:06:04.230
Jadi buatlah sebuah objek yang disebut terprediksi dan saya akan menetapkan itu sama dengan model yang memprediksi X dalam tes skor.

70
00:06:04.890 --> 00:06:06.580
Jadi itu prediksi saya.

71
00:06:06.580 --> 00:06:13.810
Menggunakan data uji X, hasil yang diharapkan hanya akan menjadi data uji Y saya.

72
00:06:13.810 --> 00:06:16.960
Ingat itu adalah perpecahan yang kami lakukan sebelumnya.

73
00:06:17.310 --> 00:06:24.710
Dan kemudian untuk membandingkan hasil yang saya dapat cetak dan kita dapat memanggil dari pustaka metrik garis

74
00:06:25.220 --> 00:06:26.580
psikis skor akurasi.

75
00:06:26.580 --> 00:06:37.550
Jadi saya akan melewati metrik dan kemudian memberikan akurasi di bawah skor skor dan kemudian membandingkan hasil yang saya harapkan dengan hasil prediksi saya

76
00:06:37.630 --> 00:06:41.420
dan kemudian melihat seberapa baik saya melakukannya.

77
00:06:46.120 --> 00:06:51.700
Dan Anda mungkin telah memperhatikan lompatan cepat dalam video di sana tetapi secara tidak sengaja hanya menjalankan kembali tes.

78
00:06:51.700 --> 00:06:56.780
Anda perhatikan di sini kita mendapatkan akurasi sembilan puluh empat koma tujuh persen.

79
00:06:56.780 --> 00:07:03.140
Itu hanya melompat dari satu titik yang saya miliki sebelumnya dan itu karena pending pada tes

80
00:07:03.140 --> 00:07:10.470
pelatihan ini Anda mungkin menghadapi beberapa keacakan yang akan dengan sempurna membagi data Anda dengan cara yang sangat bagus

81
00:07:10.470 --> 00:07:12.150
untuk mesin vektor dukungan.

82
00:07:12.380 --> 00:07:18.020
Jadi jika Anda bisa lakukan adalah terus menjalankan sel-sel ini X train x tes yang melatih

83
00:07:18.020 --> 00:07:26.230
splitsville test dan jika Anda menjalankannya dan saya menjalankan semua sel ini lagi maka Anda akan mendapatkan hasil yang berbeda untuk skor akurasi

84
00:07:26.230 --> 00:07:31.580
Anda dan apa yang dapat Anda lakukan adalah jika Anda menyadari Anda terlalu akurat.

85
00:07:31.840 --> 00:07:38.840
Anda dapat mengatur ukuran tes menjadi lebih besar sehingga secara default adalah 30 persen.

86
00:07:38.840 --> 00:07:44.870
Tetapi jika Anda ingin menjadi 40 persen, kami dapat menetapkannya sebagai nol koma empat dan Anda juga dapat

87
00:07:45.800 --> 00:07:52.860
menetapkan status acak menjadi sama dengan nilai tertentu yang Anda inginkan tergantung bagaimana Anda ingin mengacak cara kereta untuk membagi mengambil nilai

88
00:07:52.860 --> 00:07:53.430
Anda.

89
00:07:53.430 --> 00:07:57.840
Jadi jika saya menetapkan ini mungkin ke 3 saya harus mendapatkan beberapa hasil berbeda di sini.

90
00:07:57.840 --> 00:08:03.840
Memiliki tes menjadi 40 persen, bukan standar 30 persen dan saya menjalankan semua sel lagi.

91
00:08:03.840 --> 00:08:07.290
Dan sekarang keakuratan saya adalah sembilan puluh enam koma tujuh persen.

92
00:08:08.020 --> 00:08:13.090
Jadi saya mendorong Anda untuk selalu mengacau jika Anda mencoba untuk berpisah.

93
00:08:13.770 --> 00:08:18.550
Lihat apa yang terjadi jika Anda menambah ukuran pengujian atau mengurangi ukuran pengujian Anda, jadi berikan

94
00:08:18.550 --> 00:08:22.950
contoh jika kami benar-benar mengurangi ukuran pengujian hanya menjadi 10 persen dari data.

95
00:08:23.750 --> 00:08:28.370
Sekarang kami memiliki akurasi 100 persen tetapi Anda dapat melihatnya meskipun agak masuk akal mengingat

96
00:08:28.370 --> 00:08:29.800
ukuran pengujian sangat kecil.

97
00:08:30.100 --> 00:08:37.710
Tetapi jika kita kembali meningkatkannya menjadi sesuatu yang lebih besar seperti 40 persen dan kita terus berputar maka skor

98
00:08:37.710 --> 00:08:39.660
akurasi kita akan berkurang.

99
00:08:39.660 --> 00:08:40.540
BAIK.

100
00:08:40.880 --> 00:08:47.190
Jadi mudah-mudahan sekarang Anda telah melihat implementasi dasar dari mesin vektor dukungan dan yang akan kita

101
00:08:47.190 --> 00:08:56.230
lakukan sekarang adalah jika saya melompat kembali ke sini dan gulir ke notebook Python di bagian yang saya terima akurasi sembilan puluh

102
00:08:56.230 --> 00:08:58.160
tujuh koma empat persen.

103
00:08:58.160 --> 00:09:03.140
Sekali lagi hasil Anda akan berbeda tergantung pada keacakan pemilihan Anda.

104
00:09:03.480 --> 00:09:08.440
Untuk split tes terlatih Anda, tetapi karena kami telah melalui implementasi dasar mesin vektor

105
00:09:08.440 --> 00:09:13.440
dukungan. Mari kita lanjutkan dan cepat mengeksplorasi berbagai jenis kernel yang dapat kita gunakan untuk klasifikasi.

106
00:09:13.440 --> 00:09:16.890
Itu adalah metode klasifikasi nonlinier yang telah kita bahas sebelumnya.

107
00:09:19.500 --> 00:09:24.500
Cara kita dapat melakukan ini adalah dengan merencanakan batas-batas yang dibuat oleh masing-masing jenis kernel.

108
00:09:24.500 --> 00:09:29.200
Jadi kita akan melakukan permulaan dari beberapa impor dan mengatur data dan kita akan mengeksplorasi

109
00:09:29.200 --> 00:09:36.770
untuk metode yang akan kita eksplorasi ke model linier fungsi basis radial Gaussian dan menempatkan tautan di sini jika Anda ingin untuk mempelajari

110
00:09:36.770 --> 00:09:38.330
lebih lanjut tentang itu.

111
00:09:38.330 --> 00:09:41.290
Ada halaman Wikipedia di sini.

112
00:09:41.290 --> 00:09:46.710
NSPCC merupakan klasifikasi vektor dukungan dengan polinomial, bukan linear fit.

113
00:09:46.710 --> 00:09:52.320
Kita akan menggunakan kernel tingkat ketiga ke dalam model linier. Kedua model linier ini akan menjadi

114
00:09:52.320 --> 00:09:58.330
SPC linier dan yang lainnya akan menjadi SPC yang baru saja kita lakukan dengan pengaturan kernel default

115
00:09:58.330 --> 00:09:58.980
linear.

116
00:09:59.460 --> 00:10:04.750
Dan Anda akan melihat batas keputusan yang sedikit berbeda untuk klasifikasi Anda dan itu bisa

117
00:10:04.750 --> 00:10:06.980
menjadi konsekuensi dari perbedaan berikut.

118
00:10:06.980 --> 00:10:14.520
SPC Linear meminimalkan kerugian engsel kuadrat dan SPC meminimalkan kehilangan engsel biasa.

119
00:10:14.520 --> 00:10:19.260
Dan jika Anda ingin mempelajari lebih lanjut tentang apa artinya itu, Anda bisa masuk

120
00:10:19.300 --> 00:10:24.490
dan memeriksa dokumentasi karena apa yang sebenarnya kami lakukan sesuai dengan contoh ini dan menjelaskannya untuk Anda.

121
00:10:25.580 --> 00:10:32.140
Dan SBC linear menggunakan yang diinginkan versus semua untuk satu vs beristirahat seperti pengurangan kelas yang kita

122
00:10:32.140 --> 00:10:32.910
kenal.

123
00:10:32.910 --> 00:10:39.690
Dan SBC menggunakan metode satu lawan satu demikian juga setiap kelas versus penggunaan individu lainnya dari satu versus

124
00:10:39.690 --> 00:10:42.150
satu metode, bukan satu vs semua.

125
00:10:42.730 --> 00:10:49.210
Melanjutkan kita sekarang akan melompat ke kode kehidupan dan kita akan dapat mereproduksi sesuatu yang

126
00:10:49.210 --> 00:10:52.280
mirip dengan plot ini dalam dokumentasi.

127
00:10:52.280 --> 00:11:01.660
Jadi itu akan melompat kembali ke Life Code dan yang akan kita lakukan adalah mengimpor dari skala belajar.

128
00:11:01.660 --> 00:11:09.450
Saya akan mengimpor SVM sehingga saya dapat mengimpor seluruh pustaka mesin dukungan di sana dan yang akan kami lakukan bukanlah saya menggunakan

129
00:11:09.450 --> 00:11:14.600
semua data dan kami tidak akan repot jika ada pemisahan antara pelatihan dan pengujian yang

130
00:11:14.600 --> 00:11:19.070
ditetapkan sejak kami Saya hanya tertarik pada metode kernel yang berbeda sekarang.

131
00:11:19.590 --> 00:11:25.460
Jadi saya akan mengatur X sama dengan data Iris dot.

132
00:11:27.740 --> 00:11:37.460
Dan saya akan memilih dua fitur pertama dan kemudian y saya akan tetap sama akan tetap

133
00:11:37.690 --> 00:11:40.480
menjadi target Iris dots.

134
00:11:40.480 --> 00:11:41.880
BAIK.

135
00:11:41.880 --> 00:11:42.440
Luar biasa.

136
00:11:42.970 --> 00:11:46.900
Dan kita akan melewati parameter regularisasi SVM.

137
00:11:46.900 --> 00:11:50.080
Saya akan meminta B C sama dengan satu poin.

138
00:11:50.520 --> 00:11:56.330
Dan alasannya adalah agar kita dapat memiliki rutinisasi antara semua metode kernel yang berbeda yang akan digunakan

139
00:11:56.330 --> 00:11:59.040
sehingga kita dapat melakukan perbandingan yang akurat.

140
00:11:59.490 --> 00:12:08.030
Begitu juga seperti yang kita lihat sebagai objek vektor dukungan klasifikasi akan memiliki yang sebagai model ABC

141
00:12:08.720 --> 00:12:11.920
sehingga titik-titik SVM sebagai VC.

142
00:12:11.920 --> 00:12:15.650
Dan ini akan menjadi linear sehingga kita akan memiliki kernel.

143
00:12:15.650 --> 00:12:23.670
Baik secara khusus atau eksplisit mengaturnya ke linear dan kemudian kita akan memiliki parameter regularisasi

144
00:12:23.670 --> 00:12:31.940
b c akan c dan kemudian saya akan cocok dengan model itu menggunakan x dan y menggabungkan.

145
00:12:31.940 --> 00:12:33.640
Kami gulir ke sini.

146
00:12:33.640 --> 00:12:37.770
Kami mengkombinasikan set penciptaan ini dalam model dan menyesuaikan model.

147
00:12:39.890 --> 00:12:44.660
Tapi ingat kita tidak membagi menjadi set pelatihan dan pengujian karena

148
00:12:44.690 --> 00:12:49.910
kami hanya tertarik pada bagaimana perbedaan SVM akan membagi data menjadi kelas yang berbeda.

149
00:12:50.180 --> 00:12:51.800
Jadi itu SBC kita.

150
00:12:51.800 --> 00:13:00.280
Dan sekarang yang akan kita lakukan adalah fungsi basis radial Gaussian untuk r bf dan semua panggilan itu

151
00:13:00.280 --> 00:13:06.430
rb menggarisbawahi SPC dan sekali lagi saya akan melewati SVM sebagai VC.

152
00:13:06.870 --> 00:13:12.510
Dan saya akan menetapkan kernel saya menjadi sama dengan r bf dan maju dan periksa tautan Wikipedia jika Anda

153
00:13:12.510 --> 00:13:16.420
ingin mempelajari lebih lanjut tentang matematika di balik fungsi basis radial Gaussian.

154
00:13:17.000 --> 00:13:24.120
Dalam hal ini saya akan memberikan beberapa parameter tambahan yang harus dilakukan dengan fungsi basis radial

155
00:13:24.120 --> 00:13:25.020
dasar Gaussian.

156
00:13:25.020 --> 00:13:33.170
Jadi gamma 0. 7 dan lagi Anda selalu dapat melihat tautan itu dan mempelajari lebih lanjut

157
00:13:33.200 --> 00:13:35.500
tentang mengapa kami melakukan parameter itu.

158
00:13:35.500 --> 00:13:45.280
Tapi kita melompat kembali ke kode kehidupan lagi kita hanya cocok ini dengan x dan y dan kemudian kita juga akan membuat polinomial derajat

159
00:13:45.280 --> 00:13:51.350
ketiga cocok untuk semua panggilan yang mendukung klasifikasi vektor garis bawah atau seperti yang kita

160
00:13:51.350 --> 00:13:55.370
lihat semuanya memiliki yang sama dengan SVM SABC .

161
00:13:58.030 --> 00:14:01.930
Dan saya memiliki kolonel di sini sama dengan Polly.

162
00:14:01.930 --> 00:14:07.580
Dan ingat sebelumnya kita menyatakan bahwa harus polinomial tingkat ketiga jadi saya akan melewati tingkat

163
00:14:07.580 --> 00:14:09.380
argumen sama dengan tiga.

164
00:14:10.080 --> 00:14:20.510
Dan terhadap C yang sama dan kami cocok dengan model itu dengan X dan Y dan akhirnya akan memiliki model linier

165
00:14:20.550 --> 00:14:31.350
kami yang lain kami akan menyebutnya LIN menggarisbawahi SB adalah C dan akan memiliki sama dengan SVM Dot linear seperti abc

166
00:14:31.350 --> 00:14:37.910
dengan C sama dengan c dan lagi kita cocok dengan model itu.

167
00:14:37.910 --> 00:14:42.080
OK jadi sekarang kami memiliki empat model berbeda yang kami pasang.

168
00:14:42.080 --> 00:14:46.470
Sekarang yang akan kita lakukan adalah melanjutkan dan memulai proses menyiapkan plot visual yang kita

169
00:14:46.470 --> 00:14:48.500
lihat dalam dokumentasi psikis yang dipelajari.

170
00:14:48.990 --> 00:14:54.150
Hal pertama yang ingin kita lakukan adalah mendefinisikan mesh untuk plot dan kita mendefinisikan Maximina.

171
00:14:54.170 --> 00:15:00.340
Plot untuk sumbu-X anggur berdasarkan fitur terkecil dan terbesar dalam kumpulan data dan sebenarnya memiliki metode grid mesh

172
00:15:00.340 --> 00:15:05.410
yang dibangun dengan baik di sana yang akan kita gunakan untuk membangun plot kita.

173
00:15:05.410 --> 00:15:09.380
Jadi hanya untuk menunjukkan kepada Anda kami akan lakukan.

174
00:15:09.380 --> 00:15:13.910
Kami baru saja melakukan impor dan belajar Eskay dalam empat model ini.

175
00:15:14.350 --> 00:15:20.750
Dan untuk menunjukkan kepada Anda gambaran umum sebelum kami benar-benar melakukannya, kami

176
00:15:20.750 --> 00:15:29.860
akan menyiapkan kisi jala kami sehingga beberapa judul plot dan kemudian menyiapkan loop for untuk memetakan keempat plot ini.

177
00:15:29.860 --> 00:15:34.910
Oke bagus.

178
00:15:34.910 --> 00:15:39.260
Jadi mari kita mulai dan mulai dengan mengatur ukuran langkah.

179
00:15:39.260 --> 00:15:47.530
Jadi ini akan menentukan ukuran langkah untuk grid jala itu dan kemudian memilih ukuran langkah Will 0. 02

180
00:15:47.530 --> 00:15:52.680
Saya hanya bermain-main dan mengikuti dari dokumentasi psikis

181
00:15:53.210 --> 00:16:05.080
yang tampaknya cocok dan saya ingin mengatur x axis minimum maksimum maksimum kami juga x garis bawah min sama dengan minimum.

182
00:16:07.580 --> 00:16:18.280
Fitur dalam kolom fitur pertama minus satu dan kemudian sama untuk campuran.

183
00:16:18.580 --> 00:16:28.550
Saya akan mengaturnya ke ukuran fitur maksimal di kolom fitur plus satu.

184
00:16:28.650 --> 00:16:35.800
Jadi yang kami lakukan adalah kami melihat data fitur kolom pertama yang mendapatkan min minus

185
00:16:35.800 --> 00:16:38.380
1 mendapatkan maks plus satu.

186
00:16:38.380 --> 00:16:47.150
OK dan itu X M. kami X Max dan kita pada dasarnya akan melakukan proses yang sama untuk Wyman kita.

187
00:16:47.150 --> 00:16:49.560
Kecuali sekarang ini akan menjadi kolom selanjutnya.

188
00:16:53.050 --> 00:17:04.560
Dan pria itu akan menjadi minus satu dan WiMAX akan menjadi plus plus satu.

189
00:17:04.560 --> 00:17:07.240
OK jadi sekarang kita punya mengapa Mina WiMax kami.

190
00:17:07.240 --> 00:17:11.070
Dan akhirnya nomor saya dapat membuat grid mesh untuk itu.

191
00:17:11.900 --> 00:17:17.090
Jadi saya akan membuat dua objek yang disebut x x dan yy.

192
00:17:17.320 --> 00:17:28.190
Dan kemudian saya berkata bahwa saya sama dengan tidak memanggil Paez dan P dot mesh grid dan sebuah grid.

193
00:17:29.190 --> 00:17:40.270
Dan hal-hal yang kita akan melewati grid adalah kita akan menggunakan NPC mengatur untuk poin X dan kemudian NPD mengatur untuk

194
00:17:40.300 --> 00:17:52.560
poin y dan kita ingin lakukan adalah mengatur hal-hal dari X minimum ke X terlihat ke X maksimum x menit maks dan kemudian kami

195
00:17:53.150 --> 00:18:00.360
ingin menunjukkan bahwa langkah sains untuk pengaturan dan kemudian kami juga ingin mengatur titik

196
00:18:00.360 --> 00:18:06.350
y untuk grid mesh dan akan melakukannya dengan y min.

197
00:18:09.120 --> 00:18:14.000
Dan WiMax dalam ukuran ukuran H.

198
00:18:14.910 --> 00:18:15.700
Itu dia.

199
00:18:15.700 --> 00:18:23.730
Dan sekarang yang akan kita lakukan adalah judul plot pada judul say untuk setiap plot dan apa yang sebenarnya akan saya

200
00:18:23.730 --> 00:18:24.130
lakukan.

201
00:18:24.130 --> 00:18:28.060
Hanya saja itu bukan buang-buang waktu.

202
00:18:28.060 --> 00:18:31.490
Saya akan menyalin daftar judul plot dari sini.

203
00:18:31.490 --> 00:18:37.850
Jadi judul plot sama seperti yang kita lihat dari metode SABC linear kernel linear yang juga merupakan kernel linear.

204
00:18:37.850 --> 00:18:43.850
SPCA dari kernel RPF dan kemudian SABC dari kernel polinomial tingkat ketiga itu.

205
00:18:44.300 --> 00:18:46.770
Jadi saya akan pergi ke depan dan mengatur daftar judul itu.

206
00:18:47.140 --> 00:18:51.850
Dan ketika kita melakukan loop FOR kita kita akan terus menggambar dari judul-judul itu.

207
00:18:51.850 --> 00:18:56.880
Jadi akhirnya kita akan memiliki ini untuk loop melalui setiap model mengatur posisinya

208
00:18:57.360 --> 00:19:02.680
sebagai sub plot dan kemudian menyebarkan poin data dan menggambar kontur dari batas-batas keputusan tersebut.

209
00:19:02.680 --> 00:19:09.060
Cara kita melacak menggunakan loop for hanya menggunakan penghitungan untuk mengatur hampir

210
00:19:09.060 --> 00:19:10.470
seperti akun.

211
00:19:10.470 --> 00:19:19.840
Jadi Anda bisa mengatakan untuk saya dan objek lainnya adalah bahwa kontur dalam penghitungan.

212
00:19:22.800 --> 00:19:29.730
Dan saya ingin meneruskannya untuk masing-masing model yang kami buat beberapa akan dilakukan sebagai VC dan lulus sebagai pasangan.

213
00:19:29.730 --> 00:19:30.940
Perhatikan disini.

214
00:19:31.490 --> 00:19:32.710
Ketika

215
00:19:34.950 --> 00:19:44.510
SPC RBA menggarisbawahi sebagai VC dan kemudian Polly menggarisbawahi seperti yang Anda lihat.

216
00:19:44.510 --> 00:19:46.620
Jadi apa yang ingin kita lakukan ini untuk loop.

217
00:19:46.620 --> 00:19:50.400
Jadi hal pertama yang ingin saya lakukan adalah merencanakan batas keputusan.

218
00:19:50.400 --> 00:19:56.360
Dan untuk itu yang akan kita lakukan adalah menetapkan warna untuk setiap titik di mesh X Min dan

219
00:19:56.360 --> 00:20:00.780
Max Max di y menit dan titik WiMax jadi saya akan mengatakan bahwa

220
00:20:05.290 --> 00:20:09.180
angka 1 yang akan saya lakukan adalah pertama-tama atur ukuran ara.

221
00:20:13.450 --> 00:20:15.630
Juga 15 dengan 15.

222
00:20:15.630 --> 00:20:17.840
Anda dapat mengaturnya hingga ukuran gambar apa pun yang Anda inginkan.

223
00:20:17.840 --> 00:20:22.370
Saat ini saya menggunakan mereka untuk browser saya sehingga Anda mungkin ingin memilih yang berbeda sesuai ukuran Anda,

224
00:20:22.370 --> 00:20:24.810
tetapi sekarang hanya menyiapkan ukuran gambar untuk setiap gambar.

225
00:20:24.810 --> 00:20:34.360
Dan kemudian kita akan mengatur posisi subplot sehingga untuk membuat subplot yang menggunakan Call feel ke subplot.

226
00:20:34.360 --> 00:20:40.360
Karena kita sedang melakukan empat angka saya ingin menjadi dua dengan dua subplot.

227
00:20:40.360 --> 00:20:47.560
Jadi, jika Anda melihat kembali contoh di sini dalam dokumentasi kami memiliki dua oleh dua.

228
00:20:47.560 --> 00:20:53.140
Sesuatu yang perlu dipertahankan adalah menyematkan ilmu angka ini I Python tidak ada buku tidak mungkin tidak bisa

229
00:20:53.140 --> 00:20:55.430
cocok dengan angka 2 dengan 2.

230
00:20:55.430 --> 00:21:03.140
Jadi itu sebabnya jika Anda melihat notebook di sini mereka semua hanya sebenarnya empat per satu.

231
00:21:03.140 --> 00:21:09.070
Tetapi jika Anda mengatakan angka yang lebih kecil, maka ia akan dapat masuk ke dua plot dua dimensi.

232
00:21:09.070 --> 00:21:15.130
Jadi kita akan berkeliling dan kemudian untuk masing-masing model ini kami katakan itu untuk ukuran Anda.

233
00:21:15.130 --> 00:21:22.170
Dan kami mengatur subplot menjadi dua demi dua dan kemudian argumen terakhir yang Anda lewati adalah lokasinya dan

234
00:21:22.170 --> 00:21:25.780
itu akan menjadi dasarnya penghitungan jumlah plus satu.

235
00:21:29.040 --> 00:21:31.820
Dan alasannya adalah karena kita tidak ingin memulai dari nol.

236
00:21:32.660 --> 00:21:38.110
Dan kemudian jarak subplot.

237
00:21:38.110 --> 00:21:45.100
Saya tidak akan membutuhkannya untuk output saya tetapi jika Anda membutuhkannya untuk Anda, Anda dapat melanjutkan dan

238
00:21:45.130 --> 00:21:51.010
mengatakan subplot menggarisbawahi saja dan Anda dapat mengatur parameter w spacer dengan spasi.

239
00:21:51.010 --> 00:21:54.590
Dan 0. 4 adalah apa yang mereka miliki dalam contoh dokumentasi.

240
00:21:54.590 --> 00:22:00.570
Dan kemudian jarak Anda ruang h juga diatur ke nol koma empat dan

241
00:22:01.480 --> 00:22:05.340
itu hanya jarak antara empat plot yang spasi.

242
00:22:06.430 --> 00:22:08.910
OK terus saja.

243
00:22:09.230 --> 00:22:13.720
Selanjutnya yang harus kita lakukan adalah mendefinisikan Z sebagai prediksi.

244
00:22:13.720 --> 00:22:15.250
Jadi saya mengatur objek saya yang disebut Z.

245
00:22:18.080 --> 00:22:22.710
Dan kemudian saya akan mengatakan untuk

246
00:22:26.070 --> 00:22:38.440
masing-masing model memprediksi sesuatu yang harus saya lakukan di sini adalah lulus metode transfer form dari array.

247
00:22:38.440 --> 00:22:45.870
Jadi yang saya maksud adalah saya akan menyebut numb PI dan P dot C garis bawah.

248
00:22:46.590 --> 00:22:56.340
Dan kemudian saya akan mengambil objek-objek yang XX dan menggunakan Ravel yang telah Anda lakukan di masa lalu untuk memformat ulang

249
00:22:56.390 --> 00:23:04.990
array dan kemudian melewati daftar itu dan apa C garis bawah adalah jika kita melihat dokumentasi di sini

250
00:23:04.990 --> 00:23:12.610
tidak ada Piscean menggarisbawahi apa yang dilakukannya apakah pada dasarnya diterjemahkan menjadi irisan benda menjadi gabungan

251
00:23:12.610 --> 00:23:14.170
sepanjang sumbu kedua.

252
00:23:14.730 --> 00:23:21.460
Bentuk singkat untuk ungkapan ini di sini Anda dapat masuk dan cukup memeriksa contoh cepat.

253
00:23:21.460 --> 00:23:27.550
Tetapi pada dasarnya apa yang dilakukan ini hanyalah memformat prediksi sedemikian rupa sehingga kita dapat

254
00:23:27.550 --> 00:23:30.460
menggunakannya secara efektif untuk plot garis kontur.

255
00:23:31.360 --> 00:23:41.210
Dan kemudian bergerak bersama kita akan memasukkan hasilnya ke dalam plot warna jadi saya akan mengatakan Z.

256
00:23:43.710 --> 00:23:45.000
Dan

257
00:23:47.370 --> 00:23:53.780
saya akan membentuk kembali ditentukan bahwa X-Men ish.

258
00:23:53.780 --> 00:24:02.040
Lain Kami memiliki prediksi kami, kami benar-benar dapat kontur plot dan untuk plot kontur dan plot langsung

259
00:24:02.040 --> 00:24:10.510
Anda dapat memanggil kontur kontur dan jika Anda ingin mengisi plot kontur dan Anda memanggil kontur F dan

260
00:24:10.510 --> 00:24:17.750
hal-hal yang akan berlalu adalah titik-titik jala yang poin x dan y mesh Z.

261
00:24:17.750 --> 00:24:24.870
Garis kontur yang baru saja kita buat dan kemudian kita dapat memanggil peta warna membantu peta Lihat

262
00:24:25.140 --> 00:24:28.780
Dalam hal ini Anda hanya dapat memilih peta warna apa pun yang Anda inginkan.

263
00:24:28.780 --> 00:24:31.580
Tapi saya hanya memilih hujan.

264
00:24:33.500 --> 00:24:39.700
Ingat karena kita mengisi dengan warna saya akan mengatakan Alpha nol koma lima karena yang akan kita

265
00:24:39.700 --> 00:24:43.440
lakukan sebenarnya adalah plot poin di atas plot kontur ini.

266
00:24:44.580 --> 00:24:49.160
Dan saya akan mengaturnya dengan parameter tersebut.

267
00:24:49.160 --> 00:24:59.480
Dan kemudian saya juga akan mengatur garis dengan itu sama dengan nol dan itu mungkin tidak diperlukan untuk plot Anda dalam

268
00:24:59.480 --> 00:25:00.500
kasus Anda.

269
00:25:00.500 --> 00:25:05.380
Tapi mengingat ukuran figur saya, saya akan mengatur garis dengan beberapa plot kontur jadi kami hanya fokus pada

270
00:25:05.380 --> 00:25:06.270
isian itu sendiri.

271
00:25:07.360 --> 00:25:08.730
Dan sekarang kami memiliki plot kontra.

272
00:25:08.730 --> 00:25:16.590
Saya juga ingin membuat plot sebar poin pelatihan sendiri sehingga akan terjadi.

273
00:25:17.880 --> 00:25:21.140
Kolom pertama di set pelatihan.

274
00:25:23.510 --> 00:25:34.970
Atau jalan tergantung pada bagaimana format sebenarnya dan dalam fitur data kedua saya akan menetapkan C saya sama dengan

275
00:25:34.970 --> 00:25:38.420
y jadi itu hanya warna.

276
00:25:38.420 --> 00:25:40.920
Jadi setiap warna akan menjadi kelas yang berbeda.

277
00:25:41.110 --> 00:25:49.200
Dan dalam hal ini saya akan mengatur peta c saya lagi sama dengan medan itu atau sebenarnya sama

278
00:25:50.290 --> 00:25:52.560
dengan gelap sehingga sedikit jelas.

279
00:25:52.560 --> 00:25:57.800
Dan lagi bagus juga daripada di kuliah sebelumnya saya akan memilih peta warna

280
00:25:57.800 --> 00:26:04.260
apa pun yang Anda inginkan dan akhirnya kita bisa memasukkan label dan judul sehingga orang t label X

281
00:26:04.260 --> 00:26:06.640
Jadi itu sebenarnya panjang menara

282
00:26:10.590 --> 00:26:13.140
dan itu harus menjadi titik di sana.

283
00:26:13.140 --> 00:26:15.470
Hal berikutnya yang ingin saya

284
00:26:19.110 --> 00:26:22.130
lakukan adalah plot label y dan itulah kelompok

285
00:26:26.030 --> 00:26:29.500
C dengan dan kemudian saya akan plot batas saya juga.

286
00:26:29.500 --> 00:26:31.520
T y batas.

287
00:26:31.520 --> 00:26:39.420
Jadi pengaturan batas-batas itu hanya akan menjadi nilai minimum mesh dan nilai maksimumnya.

288
00:26:44.510 --> 00:26:47.980
Kenapa itu maks.

289
00:26:47.980 --> 00:26:49.120
Itu dia.

290
00:26:49.330 --> 00:26:56.100
Dan kemudian saya bisa memanggil orang-orang dengan tanda centang X.

291
00:26:56.100 --> 00:27:05.250
Dan aku tidak akan memberikan argumen tambahan apa pun tentang daya tarik mereka. Aku akan melewati kuil kosong itu.

292
00:27:06.060 --> 00:27:12.720
Dan akhirnya judul dari masing-masing subplot tersebut akan sama dengan posisi

293
00:27:12.720 --> 00:27:17.690
itu di dalam daftar saat for loop berjalan.

294
00:27:17.690 --> 00:27:18.930
Jadi semoga itu berhasil.

295
00:27:18.930 --> 00:27:24.680
Ini sesuatu yang perlu dicatat dengan cepat di sini yang sebenarnya disebut judul daftar saya.

296
00:27:28.940 --> 00:27:30.620
Di sana kita memilikinya.

297
00:27:30.620 --> 00:27:35.430
Jadi sekarang kita dapat melihat plot untuk masing-masing metode yang berbeda.

298
00:27:35.430 --> 00:27:36.750
Jadi jika kita lihat di sini.

299
00:27:37.310 --> 00:27:42.790
Ini adalah dua metode linear dari klasifikasi mesin vektor dukungan.

300
00:27:42.790 --> 00:27:50.340
Jadi, Anda dapat melihat bagaimana garis-garis bidang hyper pesawat terlihat di ruang fitur.

301
00:27:50.340 --> 00:27:54.340
Dan inilah metode linier yang berbeda dengan SPC linier.

302
00:27:54.340 --> 00:27:56.920
Sekali lagi Anda dapat dengan jelas melihat bahwa garis-garisnya linear di sana.

303
00:27:57.890 --> 00:28:04.050
Dan menggunakan itu adalah B. F. kernel Anda dapat melihat Anda

304
00:28:04.050 --> 00:28:10.030
bisa mendapatkan klasifikasi yang berbeda untuk batas keputusan Anda dan ini adalah kernel tahap ketiga polinomial.

305
00:28:10.030 --> 00:28:11.200
Keren.

306
00:28:11.200 --> 00:28:17.160
Jadi sekali lagi ini hanya sebuah contoh dari dokumentasi belajar yang dapat Anda ikuti bersama dengan contoh mereka

307
00:28:17.160 --> 00:28:19.220
sendiri di situs web mereka.

308
00:28:19.220 --> 00:28:25.970
Tetapi kembali ke notebook setelah kita melihat bagian 6 sumber daya tambahan ini ada banyak sumber daya tambahan

309
00:28:25.970 --> 00:28:28.350
online untuk dukungan seperti mesin.

310
00:28:28.350 --> 00:28:33.040
Yang pertama di sini adalah makalah Penelitian Microsoft dan sedikit tutorial SVM di dalamnya.

311
00:28:33.040 --> 00:28:39.190
Yang kedua bahwa bab buku teks online lunak pada mesin dukungan vektor juga sangat baik.

312
00:28:39.190 --> 00:28:42.200
Jadi saya bisa belajar dokumentasi sangat bagus untuk mesin vektor dukungan.

313
00:28:42.200 --> 00:28:44.310
Wikipedia juga sangat bagus.

314
00:28:44.310 --> 00:28:50.570
Dan kemudian saya memiliki slide kuliah dua jam terakhir ini dan catatan kelas dari Universitas Columbia dan

315
00:28:50.570 --> 00:28:51.720
catatan kelas.

316
00:28:51.720 --> 00:28:57.530
Jadi terima kasih saya tahu ini adalah video yang panjang tapi terima kasih telah bersabar untuk semua itu.

317
00:28:57.530 --> 00:29:01.820
Semoga sekarang Anda memiliki pemahaman yang lebih baik tentang mesin vektor dukungan dan tahu bagaimana

318
00:29:01.820 --> 00:29:03.600
menerapkannya dalam Python pembelajaran psikis.

319
00:29:03.600 --> 00:29:04.910
Baiklah, terima kasih kawan.
