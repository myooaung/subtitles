1
00:00:01,620 --> 00:00:06,750
Halo semuanya dan selamat datang di Bagian 3 dari bagian pemrosesan bahasa alami dan bagian ini

2
00:00:06,750 --> 00:00:09,670
kita akan ke langit bagaimana memproses data teks.

3
00:00:09,670 --> 00:00:14,140
Jadi masalah utama kami saat ini adalah bahwa data semua dalam string format teks.

4
00:00:14,140 --> 00:00:19,440
Jadi jika kita lanjutkan dan gulir kembali ke sini untuk memeriksa seperti apa pesan-pesan ini

5
00:00:19,440 --> 00:00:24,550
seperti mereka hanya sekelompok string dan algoritma klasifikasi yang telah kita pelajari sejauh ini

6
00:00:24,550 --> 00:00:28,220
memerlukan semacam vektor fitur numerik untuk melakukan klasifikasi tugas.

7
00:00:28,220 --> 00:00:34,480
Ada banyak cara dan banyak metode untuk mengubah corpus menjadi corpus format vektor hanya menjadi kata

8
00:00:34,480 --> 00:00:36,040
untuk sekelompok teks.

9
00:00:36,040 --> 00:00:41,710
Cara paling sederhana adalah pendekatan kantong kata-kata dan jika Anda terus maju dan melompat ke chip

10
00:00:41,740 --> 00:00:48,080
atau notebook yang dibuat untuk Anda, Anda dapat melanjutkan dan memeriksa tautan di sini untuk membuat cadangan kata-kata.

11
00:00:48,080 --> 00:00:53,500
Tidak ada tiket yang akan menarik tetapi pada dasarnya apa yang dilakukan oleh kantong kata adalah memakai

12
00:00:53,500 --> 00:00:57,010
pendekatan ini setiap kata unik dalam teks diwakili oleh satu nomor.

13
00:00:57,010 --> 00:00:59,420
Jadi kita akan mulai di sini.

14
00:00:59,420 --> 00:01:03,550
Dan satu hal yang akan kita lakukan hanyalah mengatakan string impor.

15
00:01:07,520 --> 00:01:11,470
Dan tujuan utama kami adalah membuat fungsi yang akan memproses string

16
00:01:11,470 --> 00:01:16,560
di kolom pesan yang bisa kita gunakan apply dan panders untuk melakukan semua proses pada

17
00:01:16,560 --> 00:01:21,800
teks dalam bingkai data, tetapi akan mencoba membuat pesan mentah ini dan mengubah mereka menjadi vektor.

18
00:01:21,800 --> 00:01:26,070
Ambil urutan karakter dan ubah menjadi urutan angka.

19
00:01:26,070 --> 00:01:38,270
Hal pertama mari kita lanjutkan dan hanya membuat variabel yang disebut pesan dan katakan pesan sampel.

20
00:01:38,270 --> 00:01:44,140
Perhatikan bahwa titik dua memiliki tanda baca.

21
00:01:44,140 --> 00:01:49,510
Jadi jika kita lanjut dan melihat ini dan melanjutkannya sedikit Anda akan melihat kami memiliki string ini.

22
00:01:49,510 --> 00:01:52,260
Pertama yang ingin kita lakukan hanya menyingkirkan tanda baca.

23
00:01:52,260 --> 00:01:57,430
Jadi alih-alih harus menerapkan segala sesuatu pada seluruh kerangka data yang akan kita lakukan

24
00:01:57,660 --> 00:02:00,640
adalah mengacaukan hanya dengan kekacauan variabel tunggal.

25
00:02:00,640 --> 00:02:06,840
Dan dengan cara itu saya pada dasarnya dapat mengumpulkan semua transformasi berbeda yang akan dilakukan untuk itu dan

26
00:02:06,840 --> 00:02:08,590
mengaturnya sebagai fungsi nanti.

27
00:02:08,590 --> 00:02:13,080
Alih-alih harus menjalankan semuanya pada frame data sekaligus.

28
00:02:13,080 --> 00:02:17,440
Jadi yang saya lakukan adalah memeriksa karakter untuk melihat apakah mereka ada atau tidak.

29
00:02:17,440 --> 00:02:26,790
Jadi, tunjukkan sedikit alasan kami mengimpor strain adalah untuk mendapatkan string tanda baca.

30
00:02:26,790 --> 00:02:29,110
Itulah yang akan saya buat.

31
00:02:30,660 --> 00:02:36,980
Tidak ada punk yang sama dengan karakter untuk karakter dalam kekacauan.

32
00:02:36,980 --> 00:02:46,700
Jika karakter C H A R itu tidak dalam tanda baca string.

33
00:02:46,700 --> 00:02:55,580
Jadi sekarang jika saya tidak melihat punk, saya mendapatkan daftar semua yang bukan tanda baca dari string.

34
00:02:55,580 --> 00:03:03,670
Jadi saya akan pergi ke depan dan mengatur yang sama untuk bergabung dengan Anda tahu punk.

35
00:03:03,670 --> 00:03:12,700
Dan jika kita melanjutkan dan memeriksa seperti apa kelihatannya sekarang saya dapat mencetak tidak ada punk atau tanpa tanda baca dan saya telah

36
00:03:12,700 --> 00:03:15,460
menghapus semua tanda baca dari string sampel.

37
00:03:15,460 --> 00:03:16,920
Jadi itu sangat berguna.

38
00:03:16,920 --> 00:03:20,420
Itulah langkah pertama cara menghapus tanda baca.

39
00:03:20,420 --> 00:03:27,530
Sekarang kami ingin tahu cara menghapus kata berhenti jadi berhenti atau hanya kata-kata bahasa Inggris yang sangat umum atau kata apa

40
00:03:27,530 --> 00:03:29,910
pun dalam bahasa tertentu yang Anda gunakan.

41
00:03:29,910 --> 00:03:34,920
Dan saya akan mengambil yang memiliki dukungan paling besar untuk bahasa Inggris hanya perlu diingat.

42
00:03:34,920 --> 00:03:43,070
Jadi saya akan mengatakan dari dan saya akan mengambil corpus impor berhenti kata SHIFT ENTER.

43
00:03:43,070 --> 00:03:49,230
Dan itulah alasan utama kami mengunduh NL ke KS menghentikan kata-kata di awal kuliah

44
00:03:49,230 --> 00:03:50,220
yang pertama.

45
00:03:50,220 --> 00:03:55,400
Jadi, jika Anda terus maju dan melihat apa kata berhenti itu objek ini.

46
00:03:55,400 --> 00:03:58,670
Saya bisa mengatakan kata-kata berhenti kata-kata itu.

47
00:04:00,680 --> 00:04:02,620
Dalam hal ini dalam bahasa

48
00:04:05,330 --> 00:04:09,080
Inggris kami katakan Ayo maju dan raih 10 lap pertama.

49
00:04:09,080 --> 00:04:12,080
Ada 10 dan ini hanya menunjukkan beberapa kata Stop.

50
00:04:13,800 --> 00:04:19,180
Jadi, jika Anda perhatikan ini semua adalah kata-kata berhenti yang sangat umum atau hanya kata-kata ini adalah kata-kata yang tidak berhenti jadi ini

51
00:04:19,180 --> 00:04:22,750
adalah hal-hal yang ingin Anda hapus karena mereka sangat umum sehingga mereka tidak akan benar-benar

52
00:04:22,750 --> 00:04:24,030
memberi kami informasi sebanyak itu.

53
00:04:24,030 --> 00:04:27,380
Ketika kami mencoba untuk mengklasifikasikan hal-hal spam ham.

54
00:04:27,380 --> 00:04:36,520
Jadi saya akan pergi ke depan dan lakukan adalah mengambil bahwa tidak ada tanda baca dan mari kita lanjutkan dan membaginya sehingga kita

55
00:04:36,520 --> 00:04:39,020
dapat melihat seperti apa itu daftar.

56
00:04:39,020 --> 00:04:40,110
Baiklah.

57
00:04:40,110 --> 00:04:43,270
Jadi sekarang yang ingin saya lakukan hanyalah menghapus kata berhenti.

58
00:04:43,270 --> 00:04:47,330
Jadi dalam hal ini akan mengatakan kekacauan garis bawah bersih.

59
00:04:47,330 --> 00:04:58,310
Jadi untuk pesan bersih saya ingin kata demi kata tanpa perbedaan kata yang pada dasarnya daftar

60
00:04:58,310 --> 00:05:00,720
ini di sini.

61
00:05:00,720 --> 00:05:13,990
Dan kemudian apa yang akan saya lakukan adalah mengatakan jika kata-kata lebih rendah sehingga huruf kecil bukan dalam Stop kalau bukan kata-kata.

62
00:05:13,990 --> 00:05:17,520
Dalam hal ini kami akan menentukan bahasa Inggris.

63
00:05:17,520 --> 00:05:20,170
Mari kita pastikan itu benar-benar berfungsi.

64
00:05:20,170 --> 00:05:21,820
Dan Alice melihat nona bersih.

65
00:05:24,230 --> 00:05:31,270
OK jadi kami menyingkirkan kata Stop yang umum, jadi dalam kasus ini, kata itu dan sudah terlalu umum

66
00:05:31,270 --> 00:05:33,180
untuk digunakan di sini.

67
00:05:33,180 --> 00:05:34,430
Kanan.

68
00:05:34,430 --> 00:05:41,100
Jadi saya akan pergi ke depan dan meletakkan semua ini ke dalam fungsi yang disebut Text underscore proses

69
00:05:41,100 --> 00:05:48,100
Anda akan pergi ke depan dan menyalin ini dari notebook Jupiter jadi jika Anda pergi ke notebook Jupiter Ini

70
00:05:48,100 --> 00:05:50,080
adalah fungsi yang saya salin.

71
00:05:50,080 --> 00:05:55,090
Sekarang mari kita lihat sekilas apa yang dibutuhkan dalam string teks dalam hal ini

72
00:05:55,090 --> 00:06:00,570
disebut mess kemudian melakukan yang berikut ini menghapus semua tanda baca menghapus semua kata berhenti dan

73
00:06:00,570 --> 00:06:07,630
kemudian mengembalikan daftar teks yang telah dibersihkan sehingga kami melanjutkan dan menjalankan bahwa itu akan memeriksa kerangka data yang kami buat.

74
00:06:07,630 --> 00:06:09,400
Ini disebut pesan.

75
00:06:09,400 --> 00:06:10,580
Lihatlah kepalanya.

76
00:06:11,920 --> 00:06:17,900
Jadi seperti apa tampilan pesan itu dan apa yang ingin Anda lakukan adalah tokenize pesan-pesan ini mengambil

77
00:06:17,900 --> 00:06:23,530
zasiasi hanyalah istilah yang digunakan untuk menggambarkan proses mengubah string teks normal menjadi daftar token

78
00:06:23,560 --> 00:06:26,430
yang merupakan kata-kata yang kita inginkan sebenarnya.

79
00:06:26,430 --> 00:06:30,910
Ada banyak lagi yang dibutuhkan untuk mengambil loncatan jika Anda ingin lebih mendalam tentang itu.

80
00:06:30,910 --> 00:06:33,890
Ada sumber daya untuk notebook Jupiter untuk memeriksanya.

81
00:06:33,890 --> 00:06:35,670
Tetapi untuk saat ini kita akan melihat.

82
00:06:35,670 --> 00:06:38,960
Lihatlah ke dasar-dasarnya.

83
00:06:38,960 --> 00:06:51,180
Jadi, kecuali jika sebuah pesan adalah kepala pesan, pergilah ke sini dan lakukan lima yang pertama saja dan saya akan menerapkan proses

84
00:06:51,180 --> 00:06:53,380
garis bawah teks.

85
00:06:53,380 --> 00:06:57,910
Jadi jika Anda perhatikan ini adalah pusat dari logika yang akan kita lihat

86
00:06:57,910 --> 00:07:04,680
nanti di seluruh kuliah adalah mengambil seluruh string ini dan menerapkan proses teks untuk itu dan mendapatkan sesuatu yang terlihat

87
00:07:04,680 --> 00:07:05,580
seperti ini.

88
00:07:05,580 --> 00:07:06,820
Hanya catatan singkat.

89
00:07:06,820 --> 00:07:11,450
Saya tidak benar-benar melakukan ini di tempat dan kita akan melihat mengapa nanti.

90
00:07:11,450 --> 00:07:19,430
Jadi jika Anda masih melihat pesan bingkai data asli di depan.

91
00:07:19,430 --> 00:07:21,000
Kami belum benar-benar melakukan apa pun.

92
00:07:21,000 --> 00:07:24,630
Tapi ini hanya contoh untuk menunjukkan kepada Anda apa yang akan kami dapatkan sebagai output.

93
00:07:26,270 --> 00:07:32,800
OK sejauh melanjutkan normalisasi biarkan saya pergi untuk melompat di sini ada bagian kecil di sini membahas melanjutkan normalisasi

94
00:07:32,800 --> 00:07:37,990
Jadi ada banyak cara untuk melanjutkan menormalkan itu billeting seks yang telah kami lakukan sejauh

95
00:07:38,780 --> 00:07:43,150
ini adalah membagi kata menghapus tanda baca atau menghapus SEMUA kata STOP.

96
00:07:43,150 --> 00:07:48,070
Sebenarnya ada sedikit lebih banyak yang dapat Anda lakukan jika Anda mau dan itu termasuk hal-hal seperti

97
00:07:48,070 --> 00:07:53,350
membendung atau membedakan mana bagian dari pidato dan saya akan mengambil memiliki banyak alat built-in dan dokumentasi yang

98
00:07:53,350 --> 00:07:54,700
bagus semua metode ini.

99
00:07:54,700 --> 00:07:59,380
Namun terkadang mereka tidak berfungsi dengan baik untuk teks informal seperti pesan teks.

100
00:07:59,380 --> 00:08:07,210
Jadi, tunjukkan pada kami contoh singkat mengapa bisa ada di sini. Saya baru saja memperbesar pesan teks.

101
00:08:07,210 --> 00:08:10,890
Benar-benar informal menulis pesan teks saja mengatakan non-anjing.

102
00:08:10,890 --> 00:08:17,520
Saya dk jam berapa Anda menuju klub versus teks string standar mungkin ini akan dari artikel berita atau

103
00:08:17,520 --> 00:08:23,630
novel dan mengatakan Tidak ada anjing saya tidak tahu jam berapa Anda menuju ke klub jadi

104
00:08:23,630 --> 00:08:28,820
sesuatu seperti ini jauh lebih mudah untuk melanjutkan normalisasi daripada sesuatu seperti ini.

105
00:08:28,820 --> 00:08:30,770
Jadi ingatlah itu.

106
00:08:30,770 --> 00:08:33,860
Ada hal-hal seperti membendung Saya mendorong Anda untuk memeriksa itu.

107
00:08:33,860 --> 00:08:37,070
Dan juga bagian dari pidato saya juga mendorong Anda untuk memeriksa itu.

108
00:08:37,070 --> 00:08:43,500
Dan ada semua metode normalisasi ini sebenarnya tercakup dalam NL, ambil buku online, jadi jika Anda teruskan

109
00:08:43,500 --> 00:08:46,660
dan klik itu akhirnya mereka akan membawa Anda.

110
00:08:46,710 --> 00:08:52,810
Pemrosesan bahasa alami dari Python Jadi ini sebenarnya sebuah buku yang sejalan dengan perpustakaan

111
00:08:52,810 --> 00:08:58,090
L to K dan jenis mengajarkan Anda lebih mendalam bagaimana menggunakan perpustakaan.

112
00:08:58,090 --> 00:09:00,180
Jadi Anda pergi untuk memeriksanya.

113
00:09:00,180 --> 00:09:06,600
Dia memeriksa tautan untuk kategori-kategori dalam menandai kata-kata yang dapat Anda beri tag berdasarkan bagian-bagian kelas kata

114
00:09:06,630 --> 00:09:07,780
ucapan, dll.

115
00:09:07,780 --> 00:09:10,650
Ada banyak hal yang harus dilalui di sini.

116
00:09:10,650 --> 00:09:12,760
Jadi mari kita jelajahi sendiri.

117
00:09:12,760 --> 00:09:17,290
Anda tahu seperti yang saya sebutkan untuk pemrosesan bahasa alami dan pada dasarnya memiliki

118
00:09:17,320 --> 00:09:19,040
kursus sendiri atau beberapa saja.

119
00:09:19,040 --> 00:09:25,820
Ini adalah topik yang sangat mendalam, jadi di sini kita hanya melihat dasar-dasar menghilangkan tanda

120
00:09:26,150 --> 00:09:28,490
baca dan mengubahnya menjadi daftar.

121
00:09:28,490 --> 00:09:33,030
Setelah kami menghapus kata-kata penghentian itu saja yang kami lakukan untuk contoh khusus ini.

122
00:09:33,030 --> 00:09:37,650
Tetapi saya mendorong Anda untuk memeriksa tautan di sini untuk normalisasi yang dapat Anda lakukan.

123
00:09:37,650 --> 00:09:38,990
Baiklah dan kemudian.

124
00:09:39,050 --> 00:09:40,840
Penutupnya menusuk sangat cepat.

125
00:09:40,840 --> 00:09:45,400
Ini cara lain untuk membawa kata ke kata STEM atau bentuk root.

126
00:09:45,400 --> 00:09:56,080
Jadi misalnya Anda dapat membayangkan jika Anda memiliki kata seperti katakanlah bepergian dan Anda memiliki perjalanan kata lain Anda benar-benar ingin mengatakan dua

127
00:09:56,270 --> 00:10:03,060
perang ini sangat mirip dan mereka harus direpresentasikan seperti itu sehingga yang menakjubkan adalah

128
00:10:03,060 --> 00:10:07,040
tertunda pada jenis apa batang yang Anda lakukan.

129
00:10:07,040 --> 00:10:14,280
Mungkin perlu bepergian untuk mempersingkat perjalanan jika dokumen memiliki perjalanan di dalamnya dan dokumen

130
00:10:14,280 --> 00:10:15,870
lain bepergian.

131
00:10:15,870 --> 00:10:19,290
Algoritme Anda akan menyadari bahwa mereka sebenarnya terkait satu sama lain.

132
00:10:19,290 --> 00:10:24,910
Baiklah mari kita telusuri sendiri dengan tautan asalkan Anda lebih tahu papan dan

133
00:10:24,910 --> 00:10:28,220
sekarang kita akan melakukan bagiannya untuk vektorisasi.

134
00:10:28,220 --> 00:10:35,260
Jadi sekarang kita memiliki pesan sebagai daftar token yang juga dikenal sebagai lemmas atau limas dan bahwa kita dapat

135
00:10:35,260 --> 00:10:37,620
menutupi masing-masing pesan tersebut menjadi vektor.

136
00:10:37,620 --> 00:10:40,520
Itu seperti belajar model algoritma dapat bekerja dengan.

137
00:10:40,520 --> 00:10:42,530
Jadi kita akan mengonversi setiap pesan.

138
00:10:42,550 --> 00:10:48,610
Diwakili sebagai daftar token ke dalam vektor yang dapat dipahami oleh model pembelajaran mesin.

139
00:10:48,610 --> 00:10:56,360
Mari kita pergi ke depan sekarang dan melompat ke notebook Jupiter ke langit dan sedikit lebih detail.

140
00:10:56,360 --> 00:11:02,400
Jadi seperti yang saya sebutkan kita akan mengubah setiap pesan yang direpresentasikan sebagai daftar token menjadi vektor

141
00:11:02,400 --> 00:11:05,350
yang dapat dipahami oleh model pembelajaran mesin.

142
00:11:05,350 --> 00:11:08,540
Sekarang kita akan melakukan itu pada dasarnya dalam tiga langkah.

143
00:11:08,540 --> 00:11:12,270
Kita akan menghitung berapa kali sebuah kata muncul di setiap pesan.

144
00:11:12,270 --> 00:11:18,460
Ini adalah frekuensi istilah jujur maka kita akan menimbang jumlah sehingga token sering mendapatkan bobot lebih

145
00:11:18,460 --> 00:11:18,940
rendah.

146
00:11:18,940 --> 00:11:21,720
Itu disebut frekuensi dokumen terbalik.

147
00:11:21,720 --> 00:11:26,900
Kemudian kita akan menormalkan vektor ke satuan panjang untuk abstrak dari teks asli.

148
00:11:26,900 --> 00:11:29,860
Ini dikenal sebagai norma L2.

149
00:11:29,860 --> 00:11:34,800
Kita akan memulai langkah pertama sehingga setiap vektor akan memiliki dimensi sebanyak

150
00:11:34,800 --> 00:11:37,360
ada kata-kata unik dalam teks itu.

151
00:11:37,360 --> 00:11:43,610
Jadi kita akan terlebih dahulu menggunakan akun sekuler yang dibangun menjadi vektor atau dalam model ini mengonversi kumpulan

152
00:11:43,610 --> 00:11:50,020
dokumen teks menjadi matriks jumlah token sehingga kita dapat membayangkan ini sebagai matriks dua dimensi di mana kita bertemu

153
00:11:50,020 --> 00:11:50,750
satu.

154
00:11:51,070 --> 00:11:52,810
Itu adalah seluruh kosakata.

155
00:11:52,810 --> 00:11:57,520
Jadi, satu kata, Perot. Jadi, inilah satu kata untuk menggairahkan era sampai ke tempat kerja.

156
00:11:57,520 --> 00:12:03,280
Ini semua kata-kata yang tersedia dalam kumpulan teks dan dimensi lainnya adalah

157
00:12:03,280 --> 00:12:04,940
dokumen yang sebenarnya.

158
00:12:04,940 --> 00:12:11,100
Jadi Pesan 1 pesan teks nomor 2 dan seterusnya sampai ke pesan dan kemudian Anda memiliki

159
00:12:11,100 --> 00:12:14,600
hitungan berapa kali kata itu terjadi dalam pesan itu.

160
00:12:14,600 --> 00:12:19,510
Jadi karena ada begitu banyak pesan, kita dapat mengharapkan 0 hitungan untuk keberadaan kata

161
00:12:19,510 --> 00:12:20,940
tertentu dalam dokumen itu.

162
00:12:20,940 --> 00:12:25,140
Dan karena ini akan menampilkan apa yang dikenal sebagai matriks jarang yang jika Anda

163
00:12:25,140 --> 00:12:27,650
ingin mengetahui lebih lanjut klik tautan itu.

164
00:12:27,650 --> 00:12:35,900
Tapi mari kita lanjutkan dan melompat ke bagaimana kita benar-benar dapat melakukan ini dan mengatakan saya akan mengatakan dari melarikan diri.

165
00:12:38,020 --> 00:12:51,200
Pelajari fitur dalam hal ini ekstraksi dot text mengimpor akun bahwa ada banyak argumen dan parameter yang dapat diteruskan ke penghitungan vektor atau

166
00:12:51,200 --> 00:12:56,600
dalam hal ini saya hanya akan menentukan argumen penganalisa

167
00:12:56,600 --> 00:13:01,430
untuk meneruskan fungsi yang telah ditentukan sebelumnya .

168
00:13:01,430 --> 00:13:11,940
Jadi itu akan mengatakan bag over B O W garis bawah transformator sama dengan menghitung vektor isor dan satu-satunya

169
00:13:11,940 --> 00:13:16,430
argumen yang akan lulus di sini adalah analisa

170
00:13:16,430 --> 00:13:22,840
Dan saya akan mengatakan bahwa itu sama dengan fungsi proses langkah bawah Tex yang kita lakukan sebelumnya.

171
00:13:22,840 --> 00:13:31,960
Jadi ada tentang transformator yang lebih buruk dan hal selanjutnya yang harus dilakukan adalah menyesuaikan model itu dengan

172
00:13:32,080 --> 00:13:35,520
pesan yang akan disampaikan di sini.

173
00:13:35,520 --> 00:13:36,600
Itu kolomnya.

174
00:13:36,600 --> 00:13:43,580
Ini mungkin memakan waktu cukup lama tergantung pada komputer Anda sehingga akan menunggu sedikit dan saya akan melanjutkan dan positif

175
00:13:43,660 --> 00:13:46,810
Anda sekarang dan melompat kembali ke sana setelah selesai.

176
00:13:46,810 --> 00:13:51,470
Sekali lagi ini mungkin perlu waktu di komputer Anda jadi bersabarlah.

177
00:13:51,470 --> 00:13:53,240
OK, baru saja selesai.

178
00:13:53,240 --> 00:13:55,390
Sehingga butuh sekitar 10 hingga 15 detik.

179
00:13:55,660 --> 00:14:02,310
Yang perlu diketahui Peter adalah Anda mungkin mendapatkan semacam argumen kesalahan atau peringatan.

180
00:14:02,310 --> 00:14:07,360
Kasus ini biasanya akan mendapatkan peringatan atau kegagalan Unicode untuk perbandingan yang sama gagal.

181
00:14:07,360 --> 00:14:09,300
Jangan khawatir, Anda bisa mengabaikannya untuk saat ini.

182
00:14:09,300 --> 00:14:16,750
Tapi itu pada dasarnya karena beberapa Unicode aneh yang ada di pesan teks seperti seperti simbol

183
00:14:17,040 --> 00:14:20,040
pound untuk adegan Inggris saat ini.

184
00:14:20,040 --> 00:14:26,580
Baiklah, mari kita lanjutkan dan pastikan bagian bekerja pada pesan yang sama untuk

185
00:14:26,610 --> 00:14:29,630
variabel yang sama dengan pesan.

186
00:14:29,630 --> 00:14:35,530
Kasing ini akan mengatakan pesan untuk 1 0 1 2 3.

187
00:14:35,530 --> 00:14:39,990
Silakan cetak pesan untuk.

188
00:14:39,990 --> 00:14:44,330
Baiklah jadi inilah pesan teks acak ini yang keempat.

189
00:14:44,330 --> 00:14:55,150
OK jadi yang akan kita lakukan sekarang adalah katakanlah 4 mundur 4 sama dengan kantong

190
00:14:55,150 --> 00:15:04,840
kata-kata kita dan kemudian kita hanya akan memanggil transformasi ke daftar pesan empat.

191
00:15:04,840 --> 00:15:06,610
Itu bagus di cetak seperti apa itu.

192
00:15:11,770 --> 00:15:22,160
OK jadi apa yang sebenarnya dilakukan masing-masing mengacu pada kata itu di sofa tertentu gulir kembali ke

193
00:15:22,470 --> 00:15:24,160
notebook Jupiter.

194
00:15:24,160 --> 00:15:31,200
Masing-masing angka itu adalah kata tertentu dari kata 1 ke N dan kemudian angka-angka di sini mengacu pada

195
00:15:31,200 --> 00:15:33,250
berapa kali itu terjadi.

196
00:15:33,250 --> 00:15:38,390
Jadi ini artinya ada tujuh kata unik dalam pesan nomor empat.

197
00:15:38,390 --> 00:15:43,720
Setelah kami menghapus kata-kata berhenti umum dan dua dari mereka muncul dua kali sisanya hanya sekali.

198
00:15:43,720 --> 00:15:49,690
Jadi cara saya dapat memeriksa bahwa saya benar-benar dapat mencetak ini langsung dari belakang

199
00:15:49,690 --> 00:15:51,980
kata mengubah atau objek

200
00:15:51,980 --> 00:15:55,810
Saya bisa memanggil get name feature.

201
00:15:55,810 --> 00:15:58,890
Dan mari kita panggil salah satu dari ini untuk 0 7

202
00:16:01,610 --> 00:16:03,340
3 x dan Anda mendapatkannya.

203
00:16:03,340 --> 00:16:09,520
Jadi jika kami melihat Anda di sini mengatakan Anda mendengar dua kali.

204
00:16:09,520 --> 00:16:11,430
Baiklah, jadi kita tahu itu berhasil.

205
00:16:11,430 --> 00:16:14,360
Dan mari kita periksa yang lain yang terjadi dua kali 9 5 7 0.

206
00:16:18,440 --> 00:16:23,750
Kami menjalankan kata dan mengatakan itu juga terjadi dua kali.

207
00:16:23,750 --> 00:16:24,740
Baiklah.

208
00:16:24,740 --> 00:16:28,620
Jadi sekarang kita bisa menggunakan transformasi titik di belakang kata-kata kita.

209
00:16:28,620 --> 00:16:33,050
Anda tahu, mentransformasi objek dan mengubah seluruh frame data pesan.

210
00:16:33,050 --> 00:16:40,360
Mari kita pergi ke depan dan memeriksa bagaimana jumlah mundur pesan keseluruhan

211
00:16:40,920 --> 00:16:49,810
tampak seperti mengatakan pesan menggarisbawahi kembali dan ke depan sama dengan belakang kata mengubah atau mengubah.

212
00:16:49,810 --> 00:16:56,110
Sekarang akan mengatakan pesan karena ingat bahwa seluruh bingkai data dan

213
00:16:56,140 --> 00:16:58,950
memanggil seluruh pesan memanggilnya.

214
00:16:58,950 --> 00:17:04,260
Perlu diingat ini mungkin perlu waktu tergantung pada komputer Anda.

215
00:17:04,260 --> 00:17:05,610
OK jadi sudah selesai.

216
00:17:05,610 --> 00:17:13,160
Saya benar-benar menempatkan rekaman di sana jadi ingatlah bahwa ini memakan waktu sekitar 15 hingga 30 detik di komputer saya.

217
00:17:13,160 --> 00:17:13,900
Baiklah.

218
00:17:13,900 --> 00:17:16,770
Jadi sekarang kita memiliki pesan kita bolak-balik.

219
00:17:16,770 --> 00:17:22,880
Dan apa yang akan saya lakukan adalah langsung saja menyalin dan menempelkan beberapa kode dari notebook Jupiter

220
00:17:22,880 --> 00:17:30,270
jadi jika Anda teruskan dan salin dan tempel kode ini di sini Anda dapat mencetak beberapa fitur atau hanya fakta-fakta

221
00:17:30,270 --> 00:17:31,000
halus.

222
00:17:34,080 --> 00:17:36,430
Jadi, Anda memiliki matriks jarang.

223
00:17:36,430 --> 00:17:41,900
Kami memiliki jumlah kejadian non-nol dan persentase makna sparsity.

224
00:17:41,900 --> 00:17:49,650
Jadi sebenarnya kita harus 0 dan sekali lagi saya mendorong Anda untuk memeriksa tautan ke matriks jarang yang tersedia di

225
00:17:49,650 --> 00:17:50,810
notebook Jupiter.

226
00:17:50,810 --> 00:17:53,590
Kemudian bacalah tentang itu.

227
00:17:53,590 --> 00:18:01,690
Baiklah jadi mari kita bahas secara singkat apa istilah frekuensi dokumen invers frekuensi yang akan maju dan

228
00:18:01,690 --> 00:18:08,690
melompat ke notebook Jupiter di kuliah berikutnya setelah kita selesai membahas ini secara singkat.

229
00:18:08,690 --> 00:18:15,820
Yang akan kita lakukan adalah beralih ke benar-benar melakukan istilah frekuensi dokumen invers frekuensi dan

230
00:18:15,820 --> 00:18:18,810
kemudian kita akan mendapatkan pelatihan model.

231
00:18:18,810 --> 00:18:25,730
Tetapi hanya gambaran singkat istilah frekuensi frekuensi dokumen semesta itu pada dasarnya adalah cara menimbang ukuran

232
00:18:25,730 --> 00:18:30,890
statistik dan itu digunakan untuk mengevaluasi seberapa penting sebuah kata untuk

233
00:18:30,890 --> 00:18:38,880
sebuah dokumen dalam kumpulan atau kumpulan sehingga frekuensi istilah yang mengukur seberapa sering melihat seberapa sering sebuah istilah

234
00:18:38,880 --> 00:18:40,600
muncul dalam dokumen.

235
00:18:40,600 --> 00:18:44,600
Dan karena setiap dokumen memiliki panjang yang berbeda, ada kemungkinan bahwa sebuah istilah akan muncul lebih

236
00:18:44,600 --> 00:18:47,250
banyak dalam dokumen yang panjang daripada yang lebih pendek.

237
00:18:47,250 --> 00:18:48,180
Demikian istilahnya sering.

238
00:18:48,200 --> 00:18:56,590
Dia sering dibagi dengan panjang dokumen T beberapa kali istilah saat dia muncul di dokumen dibagi dengan jumlah

239
00:18:56,590 --> 00:18:58,940
total istilah dalam dokumen.

240
00:18:58,940 --> 00:19:01,950
Jadi pertama mengapa Anda melakukan itu.

241
00:19:01,950 --> 00:19:07,610
Misalnya, jika Anda mencoba membandingkan pesan teks, katakanlah 100 karakter dan

242
00:19:07,610 --> 00:19:12,960
Anda memiliki pasangan yang memiliki pesan teks sekitar 900 karakter.

243
00:19:12,960 --> 00:19:18,330
Anda benar-benar ingin membagi berapa kali istilah tertentu muncul dalam dokumen dengan jumlah total

244
00:19:18,330 --> 00:19:20,260
istilah dalam dokumen itu.

245
00:19:20,260 --> 00:19:26,200
Kalau tidak, Anda akan mulai condongkan bobot Anda untuk istilah umum.

246
00:19:26,200 --> 00:19:32,420
Kemudian untuk memperluas gagasan itu, kita memiliki frekuensi frekuensi dokumen terbalik yang mengukur seberapa penting

247
00:19:32,420 --> 00:19:33,540
istilah tersebut.

248
00:19:33,540 --> 00:19:38,050
Jadi saat menghitung frekuensi istilah semua istilah dianggap sama pentingnya.

249
00:19:38,050 --> 00:19:41,670
Namun diketahui bahwa istilah tertentu dan jenis Sestak bisa.

250
00:19:41,680 --> 00:19:47,440
Telah berhenti kata-kata tetapi jika Anda tidak menangkap saya menghentikan kata-kata seperti adalah bahwa mereka dapat mendengar

251
00:19:47,440 --> 00:19:49,630
banyak kali yang memiliki sedikit kepentingan.

252
00:19:49,630 --> 00:19:55,800
Mari kita tunggu istilah yang sering sementara meningkatkan yang langka dan hanya itu dengan

253
00:19:55,800 --> 00:19:57,460
menghitung berikut ini.

254
00:19:57,460 --> 00:20:03,170
Jadi hanya untuk memberi Anda contoh singkat pertimbangkan sebuah dokumen yang berisi 100 Kata dimana kata kucing

255
00:20:03,170 --> 00:20:04,500
muncul tiga kali.

256
00:20:04,500 --> 00:20:12,550
Frekuensi istilah untuk kucing akan menjadi 3 dibagi 100 jadi 0. 03 sekarang anggap kita memiliki 10 juta dokumen dan

257
00:20:13,060 --> 00:20:15,960
kata cat muncul dalam 1000.

258
00:20:16,510 --> 00:20:22,390
Kemudian frekuensi dokumen terbalik dihitung sebagai log 10 juta dibagi dengan seribu yang sama

259
00:20:22,390 --> 00:20:23,460
dengan empat.

260
00:20:23,460 --> 00:20:30,900
Dengan demikian TFI IDF berat produk jumlah ini 0. 03 kali empat sama dengan nol koma dua belas.

261
00:20:30,900 --> 00:20:35,410
Sekali lagi saya mendorong Anda sebelum Anda memeriksa kuliah berikutnya untuk memeriksa tautan

262
00:20:35,410 --> 00:20:40,770
ini di sini yang menjelaskan untuk bertarung lebih detail dan membaca seluruh penjelasan buku catatan Jupiter.

263
00:20:40,770 --> 00:20:45,680
OK di kuliah selanjutnya sebenarnya dan mengeksplorasi bagaimana melakukan ini saya bisa belajar.

264
00:20:45,680 --> 00:20:46,950
Terima kasih dan sampai jumpa di sana.
