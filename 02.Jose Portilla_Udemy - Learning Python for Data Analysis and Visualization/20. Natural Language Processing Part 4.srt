1
00:00:01,220 --> 00:00:07,570
Halo semua, selamat datang di empat flusher dalam seri pemrosesan bahasa alami di The Last Lecture yang kami

2
00:00:07,570 --> 00:00:11,960
selesaikan, kita sedang berbicara tentang frekuensi istilah dalam frekuensi dokumen verst.

3
00:00:11,960 --> 00:00:17,420
Sekarang mari kita lanjutkan dan lihat bagaimana kita sebenarnya bisa belajar mengimplementasikan ini.

4
00:00:17,420 --> 00:00:21,380
Saya ingin mengatakan dari skala belajar

5
00:00:24,360 --> 00:00:38,790
ekstraksi fitur impor teks jika IDEA IF transformer maka label TFI underscore transformer sama dengan T if ide transformer dan kemudian saya akan

6
00:00:38,790 --> 00:00:47,430
memasangnya sehingga kembali ke objek yang kita buat sebelumnya yang sebelumnya pesan garis

7
00:00:47,460 --> 00:00:50,380
bawah atau bawah w.

8
00:00:52,920 --> 00:00:53,780
Jadi begitu.

9
00:00:53,780 --> 00:01:02,270
Dan mereka akan mengatakan T Jika IDF sama dengan ide JIKA jika garis bawah trafo bahasa Inggris akan

10
00:01:02,270 --> 00:01:07,530
mengubah satu baris kembali kata jadi jika Anda gulir ke atas.

11
00:01:07,530 --> 00:01:12,590
Ingat kami sedang melihat satu baris dalam hal ini satu kantong kata.

12
00:01:12,590 --> 00:01:16,530
Mari kita masuk dan memeriksanya.

13
00:01:16,530 --> 00:01:19,220
Dan mari kita beri label untuk ini.

14
00:01:19,220 --> 00:01:28,600
Jadi itu cocok dengan miliknya yang lain, saya akan mengatakan Jika ide untuk hanya melanjutkan dan mencetaknya.

15
00:01:28,600 --> 00:01:37,330
OK jadi mari kita lanjutkan dan periksa berapa frekuensi dokumen terbalik dari kata Anda di dokumen ini jadi saya

16
00:01:37,330 --> 00:01:41,330
akan mengatakan itu akan menyalin dan menempel ini.

17
00:01:42,800 --> 00:01:49,120
Dari buku catatan Jupiter saya katakan melihat apakah ide dari disk atau transformer memanggil

18
00:01:49,150 --> 00:01:58,130
frekuensi bicara terbalik menggarisbawahi dan kemudian saya mengatakan bahwa skor kosakata transformator terburuk memanggil Anda dan ini benar-benar akan memberi

19
00:01:58,130 --> 00:02:01,990
tahu kami nomor frekuensi stockinette terbalik ini.

20
00:02:01,990 --> 00:02:03,940
Pikirkan hanya itu yang bisa kita lihat.

21
00:02:03,940 --> 00:02:09,540
Jika Anda tertarik untuk mencari tahu secara spesifik kami sering tidak Anda mungkin tidak

22
00:02:09,540 --> 00:02:12,370
akan melihat setiap kata seperti itu.

23
00:02:12,370 --> 00:02:18,080
Anda akan melihat mengubah seluruh kembali menuju Corpus menjadi ide ATF corpus sekaligus.

24
00:02:18,080 --> 00:02:22,950
Tentu Anda mendapatkan sesuatu seperti ini, Anda dapat melihat pesan yang menggarisbawahi istilah frekuensi semesta berbicara

25
00:02:22,950 --> 00:02:23,700
dalam frekuensi.

26
00:02:23,700 --> 00:02:35,760
Jika IDF sama dengan t gagasan jika garis bawah bertransformasi atau mengubah dalam kasus ini akan melakukan itu

27
00:02:35,760 --> 00:02:39,180
seluruh pesan menggarisbawahi sekumpulan kata.

28
00:02:39,180 --> 00:02:44,290
Jadi, lanjutkan dan periksa bentuk pesan.

29
00:02:44,290 --> 00:02:45,200
Jika IDF.

30
00:02:48,180 --> 00:02:49,790
Dan ini dia.

31
00:02:49,790 --> 00:02:51,220
Baiklah.

32
00:02:51,220 --> 00:02:56,970
Ada banyak cara data terutama data teks dapat diproses dan di-vektorisasi.

33
00:02:56,970 --> 00:03:01,550
Langkah-langkah ini melibatkan rekayasa fitur dan membangun apa yang dikenal sebagai saluran pipa.

34
00:03:01,550 --> 00:03:06,150
Dan saya mendorong Anda untuk memeriksa seperti mempelajari dokumentasi tentang penanganan

35
00:03:06,150 --> 00:03:11,260
data teks serta koleksi makalah dan buku akademik yang tersedia tentang topik umum

36
00:03:11,260 --> 00:03:12,990
pemrosesan bahasa alami.

37
00:03:13,590 --> 00:03:19,360
Selanjutnya yang akan kita lakukan adalah mulai melatih model kita sehingga dengan pesan yang ditampilkan

38
00:03:19,360 --> 00:03:24,240
sebagai vektor, kita akhirnya dapat mulai melatih spam versus penggolong ham.

39
00:03:24,240 --> 00:03:30,430
Sekarang kita benar-benar dapat menggunakan hampir semua jenis biaya dari algoritma kation karena berbagai alasan.

40
00:03:30,430 --> 00:03:35,340
Dan sebenarnya ada tautan di sini di notebook Jupiter dengan apa yang saya bicarakan.

41
00:03:35,340 --> 00:03:40,500
Jadi jika Anda ingin memeriksa tautan ini di sini karena berbagai alasan, kelas dasar yang

42
00:03:40,530 --> 00:03:45,780
naif untuk algoritme adalah pilihan yang bagus ketika mencoba untuk mengklasifikasikan teks dasar sebagai spam atau ham.

43
00:03:45,780 --> 00:03:48,000
Anda dapat membaca mengapa di tautan ini di sini.

44
00:03:50,110 --> 00:03:55,480
Sekarang kita akan menggunakan pembelajaran psikis sehingga kita akan memilih classifier berbasis naif lagi tautan

45
00:03:55,480 --> 00:03:56,220
ke Wikipedia.

46
00:03:56,220 --> 00:04:02,890
Jika Anda tidak ingat apa pangkalan Angkatan Laut Baiklah, mari kita periksa.

47
00:04:02,890 --> 00:04:16,540
Jadi saya akan mengatakan belajar itu naif menggarisbawahi impor Bayes multinomial dan B.

48
00:04:16,540 --> 00:04:25,720
Dan kemudian saya ingin mengatakan spam menggarisbawahi teks menggarisbawahi model sebagai nama variabel saya.

49
00:04:25,720 --> 00:04:34,410
Jadikan itu sebagai contoh dari model multi-multinomial naive multi mereka dan saya akan menyesuaikan model

50
00:04:34,750 --> 00:04:39,650
itu dengan istilah frekuensi matriks frekuensi dokumen terbalik.

51
00:04:39,650 --> 00:04:49,460
Dan kemudian saya mengirimkan label pesan sebagai label untuk itu dan mari kita pastikan kita melakukannya dengan benar.

52
00:04:49,460 --> 00:04:50,600
Itu harus label.

53
00:04:50,600 --> 00:04:52,400
Permintaan maaf saya.

54
00:04:52,400 --> 00:04:57,210
Sekarang berfungsi dan mari kita coba mengklasifikasikan single kita yang menjalankan pesan dan memeriksa bagaimana kita melakukannya.

55
00:04:57,210 --> 00:05:03,090
Baiklah jadi yang akan kita lakukan adalah mengatakan cetakan mengatakan diprediksi.

56
00:05:06,700 --> 00:05:17,650
Dan saya tahu ini adalah model teks spam yang memprediksi dari single T. F. ide jika untuk begitu pesan

57
00:05:18,630 --> 00:05:24,950
tunggal hanya memberi saya indeks pertama di sana dari output

58
00:05:28,020 --> 00:05:34,310
dan kemudian diharapkan untuk mengatakan pesan label panggilan bingkai data.

59
00:05:34,310 --> 00:05:37,490
Dalam kasusnya Anda ingin yang keempat.

60
00:05:37,490 --> 00:05:40,050
Jadi kami memperkirakannya dan kami mengharapkannya.

61
00:05:40,050 --> 00:05:45,500
Sangat luar biasa kami telah mengembangkan model yang dapat memprediksi klasifikasi spammer.

62
00:05:45,500 --> 00:05:47,640
Sekarang kami ingin menentukan seberapa baik model kami.

63
00:05:47,640 --> 00:05:50,070
Secara keseluruhan seluruh kumpulan data.

64
00:05:50,070 --> 00:05:57,390
Jadi satu hal yang bisa Anda lakukan hanyalah memulai dengan mendapatkan semua prediksi jadi misalnya di copy n paste

65
00:05:57,390 --> 00:05:57,870
ini.

66
00:05:59,330 --> 00:06:05,220
Dan notebook Jupiter saya dapat mengatakan bahwa prediksi kami memiliki rentang yang sama dengan model teknologi yang

67
00:06:05,220 --> 00:06:08,960
memprediksi seluruh pesan untuk melihat apakah IDF mencetak semua prediksi.

68
00:06:08,960 --> 00:06:12,390
Jadi di sini Anda mendapatkan ham ham spam dll.

69
00:06:12,390 --> 00:06:17,780
Kita dapat menggunakan laporan klasifikasi built-in psikis Lawrence yang akan mengembalikan skor F1

70
00:06:18,040 --> 00:06:20,620
recall presisi dan kolom untuk dukungan.

71
00:06:20,620 --> 00:06:24,100
Yang berarti berapa banyak kasus yang mendukung klasifikasi itu.

72
00:06:24,100 --> 00:06:30,380
Jika kita lompat evaluasi Ammal notebook Jupiter ada beberapa tautan di sini untuk memeriksa ketepatan dan

73
00:06:30,380 --> 00:06:31,930
mengingat skor F-1.

74
00:06:31,930 --> 00:06:33,750
Apa yang sebenarnya mereka maksudkan.

75
00:06:33,750 --> 00:06:39,590
Jika Anda tertarik untuk mempelajari lebih lanjut tentang mereka pada dasarnya hanya diskusi tentang positif yang sebenarnya vs. negatif palsu dan

76
00:06:39,590 --> 00:06:42,690
ada gambar di sini.

77
00:06:43,160 --> 00:06:48,100
Cukup besar tapi gambar yang sama sebenarnya jika Anda pergi ke tautan Wikipedia itu gambar

78
00:06:48,100 --> 00:06:49,200
ini di sini.

79
00:06:49,200 --> 00:06:53,630
Tetapi pada dasarnya yang terjadi adalah Anda bertanya berapa banyak item yang dipilih relevan.

80
00:06:53,630 --> 00:06:59,800
Jika Anda mencari positif sebenarnya daripada positif sejati ditambah positif palsu dan ingat Anda bertanya berapa banyak item

81
00:06:59,800 --> 00:07:01,900
yang tidak relevan yang dipilih.

82
00:07:01,900 --> 00:07:06,880
Jadi, Anda mencari yang benar-benar positif daripada positif yang sebenarnya plus negatif yang salah.

83
00:07:06,880 --> 00:07:11,640
Jadi itu adalah metrik penting dan saya benar-benar mendorong Anda

84
00:07:11,640 --> 00:07:17,300
untuk meluangkan waktu dan membaca artikel ini di Wikipedia untuk benar-benar memahami konsep ini.

85
00:07:17,300 --> 00:07:22,060
OK jadi mari kita lanjutkan dan melanjutkan laporan klasifikasi.

86
00:07:22,060 --> 00:07:28,550
Mari kita lakukan semua prediksi yang akan saya salin dan tempel ini dan ini sebenarnya harus label.

87
00:07:31,050 --> 00:07:31,750
Baiklah.

88
00:07:31,750 --> 00:07:34,210
Jadi di sini kita memiliki prediksi kita.

89
00:07:34,210 --> 00:07:38,210
Jadi ada beberapa kemungkinan metrik lagi untuk mengevaluasi kinerja model ini.

90
00:07:38,210 --> 00:07:42,020
Mana yang paling penting tergantung pada tugas dalam bisnis yang mempengaruhi keputusan itu.

91
00:07:42,020 --> 00:07:48,140
Jadi misalnya biasanya biaya kesalahan prediksi spammer sebagai ham mungkin jauh lebih rendah daripada

92
00:07:48,140 --> 00:07:49,870
kesalahan prediksi spamma.

93
00:07:49,870 --> 00:07:57,030
Anda dapat memikirkan hal ini mungkin hampir seperti memprediksi tuduhan penipuan pada kartu kredit versus tagihan

94
00:07:57,030 --> 00:07:59,230
sebenarnya pada kartu kredit.

95
00:07:59,230 --> 00:08:00,530
Baiklah.

96
00:08:00,530 --> 00:08:06,120
Satu hal penting untuk dicatat di sini dan bahwa dalam evaluasi di atas ini kami mengevaluasi sebenarnya pada data yang

97
00:08:06,120 --> 00:08:07,960
sama yang kami gunakan untuk pelatihan.

98
00:08:07,960 --> 00:08:09,630
Anda seharusnya tidak benar-benar melakukan itu.

99
00:08:09,630 --> 00:08:12,600
Dia tidak pernah benar-benar mengevaluasi data yang sama yang Anda latih.

100
00:08:12,600 --> 00:08:14,170
Kami sudah membicarakan ini sebelumnya.

101
00:08:14,170 --> 00:08:19,880
Kita perlu melatih pemisahan uji untuk membagi data kita menjadi satu set pelatihan dan pengujian.

102
00:08:19,880 --> 00:08:25,180
Jadi yang akan kita lakukan adalah menggunakan alat bawaan untuk ini.

103
00:08:25,180 --> 00:08:33,850
Saya akan mengatakan dari skala belajar kereta impor validasi silang untuk dibagi.

104
00:08:36,420 --> 00:08:40,860
Kecuali jika pesan kereta

105
00:08:43,810 --> 00:08:52,400
pesan mengatakan label kereta dan uji label sama dengan.

106
00:08:52,400 --> 00:08:54,770
Di sini saya akan memulai baris baru.

107
00:08:54,770 --> 00:09:02,580
Katakanlah train test membagi pesan passin.

108
00:09:02,580 --> 00:09:12,790
Dalam hal ini kolom pesan juga melewati label pesan.

109
00:09:12,790 --> 00:09:14,800
Hanya catatan singkat di notebook Jupiter.

110
00:09:14,800 --> 00:09:18,570
Ini satu label.

111
00:09:18,570 --> 00:09:24,370
Dan akhirnya saya ingin menentukan ukuran tes menjadi nol koma dua.

112
00:09:24,370 --> 00:09:26,220
Default adalah pembagian 70 30.

113
00:09:26,220 --> 00:09:32,170
Seperti yang telah kita bahas sebelumnya dalam kuliah sebelumnya, ini akan menjalankan ini, pastikan kita tidak mendapatkan kesalahan.

114
00:09:32,170 --> 00:09:33,730
Baiklah, kita baik-baik saja di sana.

115
00:09:33,730 --> 00:09:39,750
Jadi saat ini ukuran tes adalah 20 persen dari seluruh set data dalam pelatihan sebagai sisanya.

116
00:09:39,750 --> 00:09:47,160
Jadi sebenarnya hanya menyalin dan menempel ini dari notebook Jupiter yang bisa kita lihat di sini.

117
00:09:47,160 --> 00:09:50,680
Mari kita lanjutkan dan hapus ini.

118
00:09:50,680 --> 00:09:51,290
Hapus ini.

119
00:09:54,580 --> 00:10:04,120
Di sini kita memiliki 4 4 5 7 sebagai tautan untuk set pelatihan untuk pesan 1 1 1 5 1915 sebagai tautan

120
00:10:04,120 --> 00:10:11,690
untuk pesan untuk pengujian dan kemudian seluruh kumpulan data adalah lima ribu lima ratus tujuh puluh dua.

121
00:10:11,690 --> 00:10:16,290
Sekarang kita akan membuat pipa data sehingga kita akan menjalankan model kita lagi

122
00:10:16,290 --> 00:10:22,490
dan memprediksi dari set tes agar tidak harus menulis semua baris yang berbeda ini untuk mengubah exciter di belakang

123
00:10:22,490 --> 00:10:23,040
kata-kata.

124
00:10:23,040 --> 00:10:26,900
Semua yang bisa kita gunakan seperti itu belajar pipa.

125
00:10:26,900 --> 00:10:30,530
Jadi sekali lagi saya mendorong Anda untuk melihat dokumentasi.

126
00:10:30,530 --> 00:10:32,360
Berikut tautannya di buku catatan Jupiter.

127
00:10:32,360 --> 00:10:36,640
Jika Anda cukup mengklik tautan pipa ini tetapi pada dasarnya yang akan kami

128
00:10:36,640 --> 00:10:40,270
lakukan adalah menyiapkan semua model dan pra-pemrosesan menjadi satu pipa tunggal.

129
00:10:40,270 --> 00:10:54,150
Saya akan mengatakan dari skala belajar pipa impor pipa dan kemudian saya akan mengatakan pipa sama dengan pipa.

130
00:10:54,150 --> 00:10:59,620
Dan kemudian akan lulus dalam daftar tupel.

131
00:10:59,620 --> 00:11:01,630
Jadi itu akan menunjukkan seperti apa ini.

132
00:11:01,630 --> 00:11:09,380
Pertama akan diberi label B O W untuk bagian belakang kata-kata dan kemudian jumlah passon vektorize atau

133
00:11:10,220 --> 00:11:14,680
dengan analisis saya yang kami buat disebut proses Teks.

134
00:11:14,680 --> 00:11:15,620
Itu adalah langkah pertama kami.

135
00:11:18,310 --> 00:11:19,530
Baiklah.

136
00:11:19,530 --> 00:11:24,880
Itulah yang pertama kali menarik dan string ke bilangan bulat diperhitungkan.

137
00:11:24,880 --> 00:11:33,410
Selanjutnya yang akan kita lakukan disebut IDF dan ini hanya nama yang saya pilih untuk setiap langkah ini.

138
00:11:33,410 --> 00:11:38,630
Dan kemudian ini akan menjadi TFI transformator F tidak akan memberikan

139
00:11:39,380 --> 00:11:46,640
argumen tambahan di sana tetapi hanya mengambil jumlah bilangan bulat yang ditimbang ke TFI skor kemudian

140
00:11:46,640 --> 00:11:50,090
akhirnya kita menggunakan label classifier itu classifier.

141
00:11:50,090 --> 00:11:56,520
Dan dalam hal ini kami menggunakan teluk multinomial Anda tahu argumen tambahan.

142
00:11:56,520 --> 00:12:01,310
Dan ini adalah pelatihan tentang ide para dokter.

143
00:12:01,310 --> 00:12:10,240
Mari kita lanjutkan dan tutup ini dan jalankan ini saya pastikan Anda tidak memiliki kesalahan dalam pipa kami.

144
00:12:10,240 --> 00:12:15,170
Baiklah jadi pipeline kita baik untuk dilalui sehingga kita bisa benar-benar melewati pesan yang tidak mereka

145
00:12:15,170 --> 00:12:20,380
periksa sekarang dan pipeline kita akan melakukan semua preprocessing yang kita lakukan sebelumnya sehingga kamu hampir

146
00:12:20,380 --> 00:12:24,980
bisa memperlakukan ini adalah model besar yang telah memproses sebagai bagian dari itu.

147
00:12:24,980 --> 00:12:35,650
Jadi bisa saya katakan pipeline yang pas di kereta Emmas G dan label train.

148
00:12:41,960 --> 00:12:45,310
Ini mungkin memakan waktu cukup lama jadi ingatlah itu.

149
00:12:45,310 --> 00:12:49,190
Sekali lagi setelah selesai menjalankan Anda mungkin mendapatkan peringatan Unicode.

150
00:12:49,190 --> 00:12:55,160
Itu karena pesan teks memiliki beberapa mungkin beberapa karakter khusus seperti tanda dolar atau sesuatu seperti itu

151
00:12:55,160 --> 00:12:57,950
dan mereka akan gagal mengubahnya menjadi Unicode.

152
00:12:57,950 --> 00:12:59,220
Tetap ingatlah selalu.

153
00:12:59,220 --> 00:13:01,670
Anda mungkin mendapat peringatan di sana.

154
00:13:01,670 --> 00:13:07,010
Lalu mari kita buat prediksi objek sama dengan Pipeline.

155
00:13:07,010 --> 00:13:11,260
Dan seperti model yang bisa saya prediksi darinya.

156
00:13:11,260 --> 00:13:13,070
Garis bawah pengujian

157
00:13:16,680 --> 00:13:20,580
yang seharusnya menjadi DST untuk kasus kami.

158
00:13:20,580 --> 00:13:22,500
Perlu diingat bahwa notebook Jupiter.

159
00:13:22,500 --> 00:13:26,730
Saya memilikinya karena dia tidak menulis ke T.

160
00:13:26,730 --> 00:13:29,250
OK lagi Anda mungkin mendapat peringatan tetapi.

161
00:13:29,530 --> 00:13:34,590
Sekarang kita benar-benar dapat menggunakan prediksi untuk mencetak laporan klasifikasi lengkap.

162
00:13:34,590 --> 00:13:37,900
Jadi, ambil laporan klasifikasi.

163
00:13:37,900 --> 00:13:46,570
Saya akan menyajikan prediksi saya dan saya akan lulus dalam tes label saya untuk

164
00:13:46,700 --> 00:13:54,810
memastikan mereka benar-benar kata yang tepat dalam tes label kasus ini harus memilikinya.

165
00:13:54,810 --> 00:14:02,120
OK jadi sekarang saya memiliki laporan klasifikasi yang benar dan laporan klasifikasi ini adalah seberapa baik pesan

166
00:14:02,320 --> 00:14:04,490
saya diprediksi pada set pengujian.

167
00:14:04,490 --> 00:14:06,350
Jadi begitu.

168
00:14:06,350 --> 00:14:11,100
Kami benar-benar membangun seluruh model dan kami mengujinya di kereta untuk dibelah.

169
00:14:11,100 --> 00:14:19,280
Sekarang Anda dapat melihat kami benar-benar melakukan cukup baik di sini kami melakukan sekitar 98 persen pada pengingatan presisi dan di sini

170
00:14:19,280 --> 00:14:24,610
pada pengujian mengatakan bahwa sekitar 97 96 untuk skor EF 1 dari 96.

171
00:14:24,610 --> 00:14:31,450
OK jadi kami benar-benar membuat laporan klasifikasi benar berdasarkan data teks untuk memprediksi nilai ham

172
00:14:31,450 --> 00:14:32,910
dan spam.

173
00:14:32,910 --> 00:14:37,950
Jadi sekali lagi sebenarnya ada lebih banyak hal dalam pemrosesan bahasa alami daripada yang telah kita bahas di sini.

174
00:14:37,950 --> 00:14:38,720
Sungguh luas.

175
00:14:38,740 --> 00:14:44,000
Topik luas yang dapat mengisi beberapa kursus perguruan tinggi dan saya mendorong Anda untuk memeriksa sumber daya yang terpasang

176
00:14:44,260 --> 00:14:47,050
pada notebook Jupiter untuk mempelajari lebih lanjut tentang hal itu.

177
00:14:47,050 --> 00:14:53,110
Jadi jika Anda pergi ke sini ada beberapa sumber daya yang tersedia untuk Anda sehingga Anda dapat mengklik tab

178
00:14:53,110 --> 00:14:54,720
Buka Anda pada masing-masing.

179
00:14:54,720 --> 00:14:57,190
Ada NL mengambil buku online.

180
00:14:57,190 --> 00:14:58,640
Ini buku yang fantastis.

181
00:14:58,640 --> 00:15:03,790
Gratis online dan mengajarkan Anda cara menggunakan perpustakaan LTA.

182
00:15:03,790 --> 00:15:07,010
Jadi saya sangat menyarankan Anda untuk memeriksanya.

183
00:15:07,010 --> 00:15:13,310
Berikutnya yang sangat bagus adalah tutorial Kaggle sendiri dan membahas beberapa dasar-dasar

184
00:15:13,310 --> 00:15:20,850
pemrosesan bahasa alami dari kata-kata dll. jadi itu akan mirip dengan kompetisi Titanic dengan Tauriel.

185
00:15:20,850 --> 00:15:26,310
Dalam hal ini Anda harus memeriksa proyek tannic terlebih dahulu sebelum memeriksa bangsal

186
00:15:26,340 --> 00:15:28,050
belakang Tauriel di sini.

187
00:15:28,050 --> 00:15:33,640
Kemudian, paranormal Lauren memiliki Tauriel yang sangat baik tentang bagaimana menangani data teks

188
00:15:33,640 --> 00:15:36,750
dan ini ketika Anda mengklasifikasikan artikel.

189
00:15:36,750 --> 00:15:38,470
Jadi saya mendorong Anda untuk memeriksanya.

190
00:15:38,470 --> 00:15:43,580
Ini adalah tulisan yang sangat bagus dan pada dasarnya mencakup semua yang baru saja kami lakukan di sini hanya dalam

191
00:15:45,270 --> 00:15:46,190
dataset yang berbeda.

192
00:15:46,190 --> 00:15:50,710
Jadi apa yang saya benar-benar mendorong Anda lakukan adalah setelah melewati ini dalam

193
00:15:50,710 --> 00:15:56,400
perjalanan teritorial melalui kerja teks itu Tauriel dan Anda harus memiliki perasaan yang benar-benar nyaman untuk ide

194
00:15:56,400 --> 00:15:59,310
F Count vectorize ors sekuler pipeline pipeline dll.

195
00:15:59,310 --> 00:16:00,270
Baiklah.

196
00:16:00,270 --> 00:16:04,010
Nah itu saja untuk pemrosesan bahasa alami.

197
00:16:04,010 --> 00:16:09,150
Ada banyak hal yang harus dilalui, jadi pasti melalui pemrosesan bahasa alami notebook Jupiter.

198
00:16:09,150 --> 00:16:12,870
Periksa semua tautan yang disediakan dan kemudian periksa sumber daya tambahan.

199
00:16:12,870 --> 00:16:15,920
OK terima kasih semuanya dan saya akan lihat di kuliah berikutnya.
