1
1

00:00:02,070  -->  00:00:06,700
Hello everyone and welcome to
the first lecture in machine learning.
2

2

00:00:06,700  -->  00:00:11,770
In this lecture we're going to be learning
about supervised learning methods and
3

3

00:00:11,770  -->  00:00:14,250
specifically we'll be learning
about linear regression.
4

4

00:00:15,460  -->  00:00:21,190
So I have my iPython notebook open as
well as the LiveCoding notebook open.
5

5

00:00:21,190  -->  00:00:23,360
So we'll be hopping back and
forth between both of them.
6

6

00:00:24,900  -->  00:00:26,690
So just to give you a quick introduction,
7

7

00:00:27,840  -->  00:00:31,100
we're going to go over how to use
the scikit-learn regression model.
8

8

00:00:31,100  -->  00:00:34,420
As well as how to train the regresser
using the fit method and
9

9

00:00:34,420  -->  00:00:35,200
we'll see that later.
10

10

00:00:35,200  -->  00:00:39,180
And we'll also learn how to predict
new labels using the predict method.
11

11

00:00:40,410  -->  00:00:45,160
So we're gonna be analyzing a data set
consisting of house prices in Boston and
12

12

00:00:45,160  -->  00:00:47,220
that data sets actually
built into scikit-learn.
13

13

00:00:47,220  -->  00:00:48,470
And we'll learn how to access it.
14

14

00:00:48,470  -->  00:00:52,470
And then we're gonna start off with
a single variable linear regression.
15

15

00:00:52,470  -->  00:00:53,440
So just an x and y.
16

16

00:00:53,440  -->  00:00:55,070
And we'll use numb pie to do that.
17

17

00:00:55,070  -->  00:00:59,290
Then we'll move on to a multi-variable
regression, using scikit-learn.
18

18

00:01:00,320  -->  00:01:03,360
As we're going through this, we'll do
a quick overview of the mathematics behind
19

19

00:01:03,360  -->  00:01:04,910
the methods we're using.
20

20

00:01:04,910  -->  00:01:09,470
But mostly we're gonna dive deeper into
practical hands-on coding lessons.
21

21

00:01:09,470  -->  00:01:12,660
So if you're interested in deeper
mathematics of linear regression methods,
22

22

00:01:12,660  -->  00:01:15,520
you can go ahead and
check out this Wikipedia page link.
23

23

00:01:15,520  -->  00:01:19,290
And like I mentioned before in
the introduction you can also check out
24

24

00:01:19,290  -->  00:01:22,670
these really nice lectures for
free on YouTube.
25

25

00:01:22,670  -->  00:01:23,490
Check out this link here.
26

26

00:01:23,490  -->  00:01:27,050
And then the linear regression link
on Wikipedia is also very good.
27

27

00:01:28,930  -->  00:01:33,570
So jumping back here, we're gonna go and
do this through nine steps.
28

28

00:01:33,570  -->  00:01:35,435
So you can almost think
of this as micro-project.
29

29

00:01:37,200  -->  00:01:39,970
The first step is gonna be getting and
setting up the data.
30

30

00:01:39,970  -->  00:01:42,550
Then we're gonna visualize
that current data.
31

31

00:01:42,550  -->  00:01:46,450
After that, step three, the mathematics
behind the Least Square Methods.
32

32

00:01:46,450  -->  00:01:49,715
That's the method we're gonna be using,
in order to do this linear regression so
33

33

00:01:49,715  -->  00:01:52,575
we'll go over some of
the mathematics behind the method.
34

34

00:01:52,575  -->  00:01:57,133
Then in step 4 we'll use numpy for
a univariate linear regression.
35

35

00:01:57,133  -->  00:01:59,770
And what univariate
linear regression means.
36

36

00:01:59,770  -->  00:02:03,877
It's just using a single variable to
do that that linear regression and
37

37

00:02:03,877  -->  00:02:05,197
we'll dive deeper into that later.
38

38

00:02:06,467  -->  00:02:11,257
Step five, we'll see how we can
get the error of our analysis.
39

39

00:02:11,257  -->  00:02:12,217
And then step six.
40

40

00:02:12,217  -->  00:02:17,040
We'll switch from using Numpy to
using scikit-learn to implement
41

41

00:02:17,040  -->  00:02:21,520
multivariate regression using multiple
data variables from our data set.
42

42

00:02:21,520  -->  00:02:26,220
And then after that, we'll set up
the training invalidation data sets.
43

43

00:02:26,220  -->  00:02:27,740
And then the next two steps,
44

44

00:02:27,740  -->  00:02:32,970
the final steps after that are predicting
prices and then making a residual plot.
45

45

00:02:32,970  -->  00:02:36,430
Now we'll dive deeper into all
those topics as we get to them.
46

46

00:02:36,430  -->  00:02:39,380
So, step one, getting up and
setting up the data.
47

47

00:02:40,610  -->  00:02:44,370
We'll start by looking at an example
data set from scikit-learn.
48

48

00:02:44,370  -->  00:02:47,390
So first we're gonna import our
usual data analysis import.
49

49

00:02:47,390  -->  00:02:52,020
So let's go ahead and hop over to the
LiveCoding and start going through that.
50

50

00:02:52,020  -->  00:02:55,650
So I'm going to import numpy as np.
51

51

00:02:57,210  -->  00:02:59,800
Going to import pandas as pd.
52

52

00:02:59,800  -->  00:03:07,850
And then from pandas import series and
data frame.
53

53

00:03:10,200  -->  00:03:12,200
After that I'm going to get my imports for
plotting.
54

54

00:03:12,200  -->  00:03:17,840
So I'm going to import
matplotlib.pyplot as plt.
55

55

00:03:17,840  -->  00:03:22,140
Then I'm going to import Seaborn as SNS.
56

56

00:03:22,140  -->  00:03:26,890
And then like we did in previous videos,
I'm gonna set the style for
57

57

00:03:26,890  -->  00:03:31,330
Seaborn as a white grid style.
58

58

00:03:31,330  -->  00:03:33,590
So we can see a white grid background.
59

59

00:03:33,590  -->  00:03:36,210
Again you can set style
however you please.
60

60

00:03:36,210  -->  00:03:39,402
And then just to make sure
we always see our plots,
61

61

00:03:39,402  -->  00:03:41,920
I'm going to call matplotlib inline.
62

62

00:03:43,697  -->  00:03:48,185
So now what we're gonna do is we're gonna
import a data set from scikit-learn,
63

63

00:03:48,185  -->  00:03:50,780
as well as the linear model module.
64

64

00:03:50,780  -->  00:03:54,535
So just a quick note you
may have to run a download,
65

65

00:03:54,535  -->  00:03:57,650
scikit-learn may read
an error when you do this.
66

66

00:03:57,650  -->  00:03:58,610
And if you read an error and
67

67

00:03:58,610  -->  00:04:04,600
it prompts you something around the lines
of you need to run download models.
68

68

00:04:04,600  -->  00:04:06,820
Go ahead and just follow the directions.
69

69

00:04:06,820  -->  00:04:07,949
And you can go ahead and
70

70

00:04:07,949  -->  00:04:12,008
always make a discussion in case you're
confused by the directions that pop up.
71

71

00:04:14,446  -->  00:04:21,540
But once you have them you can just
say from sklearn.datasets import.
72

72

00:04:22,940  -->  00:04:28,850
And in this case,
I'm gonna import load_boston.
73

73

00:04:28,850  -->  00:04:32,050
And that's importing a Boston data set.
74

74

00:04:32,050  -->  00:04:35,019
So in order to load the data set, I'm
just gonna make an object called Boston.
75

75

00:04:38,422  -->  00:04:41,730
And have it be equal to
that imported data set.
76

76

00:04:42,740  -->  00:04:45,560
So let's see what the data set contains.
77

77

00:04:45,560  -->  00:04:49,040
If you went into the documentation
of scikit-learn.
78

78

00:04:49,040  -->  00:04:54,470
And looked up the Boston data sets, you'll
be able to read there that they've built
79

79

00:04:54,470  -->  00:05:01,490
in a special describe method into
that data set capital DESCR.
80

80

00:05:01,490  -->  00:05:04,800
So if you call that method
on the Boston data set,
81

81

00:05:04,800  -->  00:05:07,560
it'll actually print out
a really nice description of it.
82

82

00:05:07,560  -->  00:05:08,570
So let's go ahead and check that out.
83

83

00:05:09,870  -->  00:05:14,210
Looks like we have 506
instances in this data set.
84

84

00:05:14,210  -->  00:05:18,540
We have 13 different attributes, and
85

85

00:05:18,540  -->  00:05:23,700
the median value of the attributes
14 is usually the target.
86

86

00:05:23,700  -->  00:05:27,620
So if we look at what kind of
information is in this data set.
87

87

00:05:27,620  -->  00:05:31,910
We have a per capita crime rate by town,
and
88

88

00:05:31,910  -->  00:05:35,490
notice it's giving you the labels
here of each of these attributes.
89

89

00:05:36,800  -->  00:05:40,800
So we also have the proportion
of residential lands owned for
90

90

00:05:40,800  -->  00:05:42,930
lots over 25,000 square feet.
91

91

00:05:42,930  -->  00:05:45,510
We have a bunch of
different attributes here.
92

92

00:05:45,510  -->  00:05:50,440
We also have the index of
accessibility to radial highways,
93

93

00:05:50,440  -->  00:05:55,360
the pupil-teacher ratio in town,
average number of rooms per dwelling.
94

94

00:05:55,360  -->  00:05:58,660
So a bunch of different attributes for
these houses.
95

95

00:05:58,660  -->  00:06:03,370
And if you notice the last one here is
the median value of ower-occupied homes
96

96

00:06:03,370  -->  00:06:05,500
in thousands of dollars.
97

97

00:06:05,500  -->  00:06:09,290
We're gonna treat this guy,
this median value,
98

98

00:06:09,290  -->  00:06:13,150
as the target and sometimes you
also call the target the label.
99

99

00:06:14,710  -->  00:06:17,730
We have all these different
features of a house.
100

100

00:06:17,730  -->  00:06:23,106
So a house can have different number
of rooms, different proportions
101

101

00:06:23,106  -->  00:06:28,800
of non-retail business acres per
town where that particular house is.
102

102

00:06:28,800  -->  00:06:32,320
So your house can have a bunch
of different features, and
103

103

00:06:32,320  -->  00:06:35,140
it has one label, or one target.
104

104

00:06:36,170  -->  00:06:40,040
The median value of the owner-occupied
home in terms of thousands of dollars.
105

105

00:06:40,040  -->  00:06:44,130
So this is actually a copy of a UC Irvine
Machine Learning housing data set.
106

106

00:06:44,130  -->  00:06:46,770
So you can click this link and
find out more about it there.
107

107

00:06:48,660  -->  00:06:49,580
But, moving on,
108

108

00:06:49,580  -->  00:06:53,950
there's also references here in case
you're interested more into the data set.
109

109

00:06:53,950  -->  00:06:57,190
What we're gonna is just a quick
visualization of the data.
110

110

00:06:58,210  -->  00:07:01,380
So, you should always do a quick
visualization of the data you have
111

111

00:07:01,380  -->  00:07:05,090
just to make sure everything looks
okay and nothing strange pops up.
112

112

00:07:06,140  -->  00:07:09,722
Let's go ahead and
do a histogram of the prices.
113

113

00:07:09,722  -->  00:07:13,890
So remember the prices is the current
target or label of our data set.
114

114

00:07:13,890  -->  00:07:17,743
I'm gonna do that by calling plt.hist.
115

115

00:07:22,316  -->  00:07:23,380
And I can call that target value
just by calling the target method.
116

116

00:07:23,380  -->  00:07:27,231
So this is actually pretty
particular to this,
117

117

00:07:27,231  -->  00:07:31,676
what they're called toy
data sets in scikit-learn.
118

118

00:07:31,676  -->  00:07:34,698
Since this data set was actually built
119

119

00:07:34,698  -->  00:07:38,860
into scikit-learn it's
a nice training data set.
120

120

00:07:40,090  -->  00:07:42,510
As far as training yourself
to learn machine learning.
121

121

00:07:44,270  -->  00:07:46,890
Not to be confused with training and
testing and validation data sets,
122

122

00:07:46,890  -->  00:07:47,770
we'll get into that later.
123

123

00:07:50,110  -->  00:07:53,160
But, as you can imagine not every
data sets gonna be very nice and
124

124

00:07:53,160  -->  00:07:57,030
very clean and you're not going to be
able to call this target method on it.
125

125

00:07:57,030  -->  00:08:00,170
But you will be able
to make histograms for
126

126

00:08:00,170  -->  00:08:03,630
you own data given the skill sets
you learned so far in this course.
127

127

00:08:05,630  -->  00:08:12,978
And I'm gonna make my X label equal
to prices in thousands of dollars.
128

128

00:08:12,978  -->  00:08:18,618
And then I'm going to plot my Y label
129

129

00:08:22,160  -->  00:08:24,678
to be equal to the number of houses.
130

130

00:08:27,838  -->  00:08:29,140
Since we're doing histogram.
131

131

00:08:30,220  -->  00:08:33,700
So we're just making a simple
histogram of all the houses.
132

132

00:08:33,700  -->  00:08:40,730
I have created 50 bins because there were
up to 506 different housing instances.
133

133

00:08:41,890  -->  00:08:43,177
So let's go ahead and run that,
see what it looks like.
134

134

00:08:45,395  -->  00:08:46,500
Great.
135

135

00:08:46,500  -->  00:08:50,730
So now we basically see the histogram,
or the distribution if you will,
136

136

00:08:50,730  -->  00:08:54,450
of the average median price
in thousands of dollars.
137

137

00:08:55,530  -->  00:08:59,960
And the number of houses that
are in that price bin, if you will.
138

138

00:09:01,690  -->  00:09:05,080
Okay, so you can see there's
an average price between,
139

139

00:09:05,080  -->  00:09:09,220
looks like, somewhere around
the $20,000-$25,000 range.
140

140

00:09:09,220  -->  00:09:10,900
As far as this particular data set.
141

141

00:09:13,090  -->  00:09:16,590
So, what might be interesting
to do is just see a scatter plot
142

142

00:09:16,590  -->  00:09:20,570
of a single feature versus the target or
that label.
143

143

00:09:20,570  -->  00:09:24,570
So we want to scatter plot
one feature versus a target.
144

144

00:09:24,570  -->  00:09:28,030
So how about we scatter
plot the housing price
145

145

00:09:28,030  -->  00:09:29,840
versus the number of
rooms in the dwelling.
146

146

00:09:31,010  -->  00:09:34,740
So, in order to get the number
of rooms in the dwelling
147

147

00:09:34,740  -->  00:09:36,840
I'm gonna scroll back up
here to the description.
148

148

00:09:38,200  -->  00:09:45,000
And note here that RM is that label for
the average number of rooms per dwelling.
149

149

00:09:45,000  -->  00:09:48,760
And it looks like it's one,
two, three, four, five,
150

150

00:09:48,760  -->  00:09:52,680
six, down in the attribute information.
151

151

00:09:52,680  -->  00:09:55,920
Notice that this information
was given to you in order.
152

152

00:09:55,920  -->  00:09:57,332
So it's the sixth one down.
153

153

00:09:57,332  -->  00:10:02,180
Which means if you're index starts
at zero, then it's gonna be zero,
154

154

00:10:02,180  -->  00:10:04,450
one, two, three, four, five.
155

155

00:10:04,450  -->  00:10:08,080
So, we're gonna wanna call
the column at the number five index
156

156

00:10:09,120  -->  00:10:11,120
of our Boston data set.
157

157

00:10:11,120  -->  00:10:15,889
So, to show you what I mean by that,
I'm gonna call a scatter plot method,
158

158

00:10:15,889  -->  00:10:16,970
plt.scatter.
159

159

00:10:20,185  -->  00:10:22,732
And then I'm gonna say boston.data, so
160

160

00:10:22,732  -->  00:10:28,050
these were all those attributes we
were looking at, those 13 attributes.
161

161

00:10:28,050  -->  00:10:34,130
And now I want every attribute
in that fifth column.
162

162

00:10:35,990  -->  00:10:42,060
And that's what I want my X to be,
the average number of rooms.
163

163

00:10:42,060  -->  00:10:44,880
And what I want my Y to be is the price.
164

164

00:10:44,880  -->  00:10:47,350
So, I already know the price,
165

165

00:10:47,350  -->  00:10:52,460
as we did last time was the target
method on that data set.
166

166

00:10:52,460  -->  00:10:56,190
And always keep in mind,
we're working with this built in data set.
167

167

00:10:56,190  -->  00:10:59,948
You're not gonna have nice methods
to call on your own data sets,
168

168

00:10:59,948  -->  00:11:04,625
these lectures are really just to teach
you how to deal and manipulate with data.
169

169

00:11:05,925  -->  00:11:08,075
And you may have to do some
cleaning on your own data.
170

170

00:11:09,455  -->  00:11:11,175
So let's go ahead and
put in the labels real quick.
171

171

00:11:12,645  -->  00:11:14,954
We'll call it price in thousands.
172

172

00:11:19,192  -->  00:11:25,437
And we'll have our X label be
equal to the number of rooms.
173

173

00:11:25,437  -->  00:11:30,150
So right here
174

174

00:11:35,770  -->  00:11:36,826
And now let's go ahead and run that.
175

175

00:11:40,227  -->  00:11:41,550
And there you go.
176

176

00:11:41,550  -->  00:11:44,810
So you can make out
a bit of a slight trend
177

177

00:11:44,810  -->  00:11:49,050
that the price increases along with
the number of rooms in that house.
178

178

00:11:49,050  -->  00:11:51,490
Which intuitively that kinda makes sense.
179

179

00:11:51,490  -->  00:11:55,930
You would expect as you get a higher
number of rooms in that house,
180

180

00:11:55,930  -->  00:11:59,620
most likely that house is larger so
the price increases.
181

181

00:11:59,620  -->  00:12:03,829
So you should see some sort of positive
correlation between the number of rooms
182

182

00:12:03,829  -->  00:12:05,690
And the price of the house itself.
183

183

00:12:06,919  -->  00:12:09,550
So how about we try to
do the following now.
184

184

00:12:09,550  -->  00:12:14,960
Let's try to use Pandas to transform
this Boston data set into a data frame.
185

185

00:12:14,960  -->  00:12:19,930
And then we'll use Seaborn to perform
an LM plot on that data frame.
186

186

00:12:19,930  -->  00:12:24,140
To try to reproduce the scatter plot
we just did with a linear fit line.
187

187

00:12:25,790  -->  00:12:27,355
So let's go ahead and
start off by resetting the data.
188

188

00:12:31,199  -->  00:12:39,800
So I'll make an object called boston_df,
and I'll call the data frame method
189

189

00:12:44,561  -->  00:12:48,770
just on the data of that Boston data
set not the actual target itself.
190

190

00:12:51,280  -->  00:12:53,264
So I'm resetting all the data
as a Pandas data frame.
191

191

00:12:56,247  -->  00:12:57,222
And then
192

192

00:13:05,825  -->  00:13:09,645
I'm going to set the columns
of my data frame
193

193

00:13:13,963  -->  00:13:17,470
equal to the feature names method.
194

194

00:13:17,470  -->  00:13:22,410
So, like I said before, these are kind of
particular and specific things to this
195

195

00:13:22,410  -->  00:13:27,130
data set, as far as calling the .data and
.feature names methods.
196

196

00:13:27,130  -->  00:13:30,485
They're just here for convenience
because this it build into scikit-learn.
197

197

00:13:33,460  -->  00:13:40,220
So let's go ahead and move on and just see
what that Boston data frame looks like.
198

198

00:13:40,220  -->  00:13:41,508
Just going to call the first five rows.
199

199

00:13:44,630  -->  00:13:45,431
And there you go.
200

200

00:13:45,431  -->  00:13:51,364
Now we have a data frame consisting
of all those attributes or features.
201

201

00:13:54,788  -->  00:14:01,670
Moving on now, let's go ahead and add the
target of the Boston data set, the price.
202

202

00:14:01,670  -->  00:14:04,189
So we'll do that by creating
a new column in our data frame.
203

203

00:14:05,340  -->  00:14:09,124
And we do that just by doing this.
204

204

00:14:14,161  -->  00:14:17,677
And now I'm gonna set that equal to
the target of the data frame which was
205

205

00:14:17,677  -->  00:14:18,270
the price.
206

206

00:14:19,490  -->  00:14:21,260
And I can do that by
passing that target method.
207

207

00:14:23,550  -->  00:14:25,023
And now let's go ahead see
the resulting data frame.
208

208

00:14:28,994  -->  00:14:32,870
And there you have it.
209

209

00:14:32,870  -->  00:14:37,830
So now we have a nice complete data frame
with all those different features and
210

210

00:14:37,830  -->  00:14:40,720
finally our target price.
211

211

00:14:40,720  -->  00:14:46,190
So If you remember your Seaborn lectures.
212

212

00:14:46,190  -->  00:14:50,350
You might be reminded of the Seaborn LM
plot functions we used during
213

213

00:14:50,350  -->  00:14:53,950
the visualization lectures when
you looked at the scatter plot.
214

214

00:14:53,950  -->  00:14:57,320
So you can actually use it
here to do a linear fit or
215

215

00:14:57,320  -->  00:14:59,060
a linear regression automatically.
216

216

00:14:59,060  -->  00:15:02,310
So that's actually a nice
feature build into Seaborn.
217

217

00:15:02,310  -->  00:15:07,137
So let's go ahead and try to do that So
we'll do that by sns.lmplot.
218

218

00:15:10,214  -->  00:15:13,137
And remember you can review
the visualization lectures in case you're
219

219

00:15:13,137  -->  00:15:14,116
a little fuzzy on this.
220

220

00:15:22,137  -->  00:15:26,430
So what I did here is I'm using
Seaborn calling that linear plot.
221

221

00:15:26,430  -->  00:15:30,100
It's gonna plot basically a linear
regression over that scatter plot,
222

222

00:15:30,100  -->  00:15:31,800
just the first order line.
223

223

00:15:31,800  -->  00:15:35,790
And I'm plotting that room
feature versus the price, and
224

224

00:15:35,790  -->  00:15:38,010
setting my data as that data frame.
225

225

00:15:38,010  -->  00:15:41,530
So, it's gonna be trying to reproduce
this exact same scatter plot here.
226

226

00:15:41,530  -->  00:15:45,370
Except in Seaborn it gives
you a linear fit to it.
227

227

00:15:47,260  -->  00:15:50,700
Run that, and there you go.
228

228

00:15:50,700  -->  00:15:55,270
So now you have, just within Seaborn,
you've already done a very
229

229

00:15:55,270  -->  00:16:00,070
simple linear fit model to your data.
230

230

00:16:01,100  -->  00:16:02,460
Great.
231

231

00:16:02,460  -->  00:16:06,250
So your not going to be able to do this
however when we get to more complicated
232

232

00:16:06,250  -->  00:16:07,230
regression models.
233

233

00:16:07,230  -->  00:16:11,720
So we're gonna stay focused on using
Numpy and the scikit-learn library
234

234

00:16:11,720  -->  00:16:14,740
in order to really dive deeper
into actual machine learning.
235

235

00:16:15,860  -->  00:16:18,480
So, I'll stop the video here
236

236

00:16:18,480  -->  00:16:22,260
before we jump into the mathematics
behind the machine learning.
237

237

00:16:22,260  -->  00:16:23,880
So, let's just do a quick
overview of what we done.
238

238

00:16:26,340  -->  00:16:29,680
We've set up everything we
needed as far as the imports.
239

239

00:16:29,680  -->  00:16:33,640
We've imported a particular data set,
the Boston data set fromscikit-learn.
240

240

00:16:33,640  -->  00:16:37,460
And I encourage you to go
check out the documentation
241

241

00:16:37,460  -->  00:16:41,800
on that particular data set from
the scikit-learn documentation.
242

242

00:16:41,800  -->  00:16:45,480
We've gone ahead and
printed a description of that data set.
243

243

00:16:45,480  -->  00:16:48,370
Looked around, looked at the different
attributes and variables.
244

244

00:16:48,370  -->  00:16:50,840
Also looked at the target,
which was the median value.
245

245

00:16:50,840  -->  00:16:56,560
So what we're gonna wanna do during
this data set analysis is try to predict
246

246

00:16:56,560  -->  00:17:01,310
the price of a house based
on the input attributes.
247

247

00:17:01,310  -->  00:17:02,810
Remember, this was supervised learning.
248

248

00:17:04,070  -->  00:17:05,250
Then we did a quick histogram.
249

249

00:17:06,750  -->  00:17:10,170
We did a scatter plot of the number
of rooms versus the price.
250

250

00:17:11,310  -->  00:17:13,150
Then we set up a Pandas data frame.
251

251

00:17:13,150  -->  00:17:16,910
And did the exact same thing in
Seaborn with an automatic regression
252

252

00:17:16,910  -->  00:17:18,960
fitted to our data.
253

253

00:17:18,960  -->  00:17:25,270
So in the next lecture,
we're gonna go and move on to learning
254

254

00:17:25,270  -->  00:17:29,720
about the mathematics, just a quick
overview behind the Least Squares Method.
255

255

00:17:29,720  -->  00:17:34,690
Which is what we're gonna be using
with Numpy and scikit-learn.
256

256

00:17:34,690  -->  00:17:37,240
Alright, so
I'll see you at the next video.
257

257

00:17:37,240  -->  00:17:37,760
Thanks guys.
