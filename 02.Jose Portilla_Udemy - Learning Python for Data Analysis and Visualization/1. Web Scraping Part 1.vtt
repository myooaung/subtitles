WEBVTT
1
1

00:00:02.620  -->  00:00:07.870
Hi everyone and welcome to this appendix
lecture on Web Scraping in Python.
2

2

00:00:07.870  -->  00:00:09.287
So in this appendix lecture,
3

3

00:00:09.287  -->  00:00:12.695
I'm gonna go over how to scrape
information from the web using Python.
4

4

00:00:12.695  -->  00:00:16.663
So, we'll go to a website, decide what
information we want, see where and
5

5

00:00:16.663  -->  00:00:20.265
how it's stored, then scrape it and
set it as a pandas.DataFrame.
6

6

00:00:20.265  -->  00:00:24.586
So, as always,
you can just go to nbviewer.ipython.org,
7

7

00:00:24.586  -->  00:00:29.323
search for my get hub user name,
J-M-P-O-R-T-I-L-L-A,
8

8

00:00:29.323  -->  00:00:33.311
jmportilla, and
then if you click here on web scraping,
9

9

00:00:33.311  -->  00:00:37.238
after searching,
you'll have a link to the nb viewer.
10

10

00:00:37.238  -->  00:00:41.190
This iPython notebook is
just called web scraping.
11

11

00:00:41.190  -->  00:00:44.000
So you click it here and you will be
able to see the IPython notebook for
12

12

00:00:44.000  -->  00:00:44.560
this lecture.
13

13

00:00:46.710  -->  00:00:51.490
So I'll be switching back between the
IPython notebook and also the live coding.
14

14

00:00:53.160  -->  00:00:55.350
So let's go over a little bit
of web scraping in general.
15

15

00:00:56.970  -->  00:01:00.440
So, there's some things you should
consider before web scraping a website.
16

16

00:01:00.440  -->  00:01:02.840
You should definitely check
out a site's terms and
17

17

00:01:02.840  -->  00:01:06.620
conditions before you scrape
the information off that website.
18

18

00:01:06.620  -->  00:01:11.840
For instance, if you want to make an app
that shows different sporting outcomes,
19

19

00:01:11.840  -->  00:01:13.370
it would most likely be illegal for
20

20

00:01:13.370  -->  00:01:18.770
you to scrape information off ESPN since
that's the same business that they're in.
21

21

00:01:18.770  -->  00:01:23.270
In our case, we're gonna be scraping off
information from a government website.
22

22

00:01:23.270  -->  00:01:25.960
So that's public information so
that's okay to scrape.
23

23

00:01:25.960  -->  00:01:29.210
So you should be personally responsible
and check a site's terms and
24

24

00:01:29.210  -->  00:01:30.560
conditions before you scrape them.
25

25

00:01:32.140  -->  00:01:35.600
Another thing to consider is you should
definitely space out your requests so
26

26

00:01:35.600  -->  00:01:37.870
you don't overload the site's server.
27

27

00:01:37.870  -->  00:01:41.980
If you make too many requests
at too close of a time interval,
28

28

00:01:41.980  -->  00:01:43.760
your IP could get blocked.
29

29

00:01:45.230  -->  00:01:49.156
Another thing to keep in consideration
is that your web-scraping code will most
30

30

00:01:49.156  -->  00:01:51.360
likely break after
a certain amount of time.
31

31

00:01:51.360  -->  00:01:54.664
Web pages change their layout all
the time, and more than likely,
32

32

00:01:54.664  -->  00:01:58.325
maybe like a year down the line,
you're gonna have to rewrite your code.
33

33

00:01:58.325  -->  00:02:02.824
It could even be just a few days down
the line, depending on the website and
34

34

00:02:02.824  -->  00:02:04.432
how often it's changed.
35

35

00:02:04.432  -->  00:02:07.881
Another thing to know is that web
pages are usually inconsistent,
36

36

00:02:07.881  -->  00:02:11.822
so more than likely you'll have to clean
up the data after you scrape it, and
37

37

00:02:11.822  -->  00:02:15.639
you'll see an example of us cleaning
the data in this lecture as well, and
38

38

00:02:15.639  -->  00:02:19.243
then last but not least,
every web page and situation is different.
39

39

00:02:19.243  -->  00:02:22.176
You'll more than likely have to spend
quite a bit of time configuring
40

40

00:02:22.176  -->  00:02:22.842
your scraper.
41

41

00:02:25.001  -->  00:02:29.018
Another thing we want to know is HTML,
so you're going to need some
42

42

00:02:29.018  -->  00:02:32.988
very basic knowledge of HTML in
order to web scrape effectively.
43

43

00:02:32.988  -->  00:02:36.340
So I suggest you go to
one of these two links.
44

44

00:02:36.340  -->  00:02:38.310
One is the w3school.
45

45

00:02:38.310  -->  00:02:41.340
It just has a nice HTML tutorial here.
46

46

00:02:41.340  -->  00:02:44.140
And if you wanna get
really deep into HTML and
47

47

00:02:44.140  -->  00:02:48.560
CSS style sheets, you can go ahead and
check out Code Academies.
48

48

00:02:49.800  -->  00:02:50.920
HTML and CSS.
49

49

00:02:52.450  -->  00:02:54.720
For this lecture,
you don't have to worry about that.
50

50

00:02:54.720  -->  00:02:59.801
I'll explain the few HTML tags we deal
with, but in case you want to get
51

51

00:02:59.801  -->  00:03:05.150
deeper into web scraping in the future
definitely learn more about HTML and CSS.
52

52

00:03:06.760  -->  00:03:07.520
So moving along.
53

53

00:03:07.520  -->  00:03:10.460
There's going to be three modules
we'll need in addition to just Python.
54

54

00:03:10.460  -->  00:03:15.380
The first one is beautiful soup and
you can download that by typing either
55

55

00:03:15.380  -->  00:03:19.810
pip install Beautiful Soup 4 or conda
install Beautiful Soup 4 depending on what
56

56

00:03:19.810  -->  00:03:22.430
distribution of Python you
installed on your computer.
57

57

00:03:22.430  -->  00:03:24.750
And you can just put that
into your command prompt.
58

58

00:03:24.750  -->  00:03:27.970
Next LMXL,
we'll need to download that as well.
59

59

00:03:27.970  -->  00:03:30.380
Again pip install our conda install.
60

60

00:03:30.380  -->  00:03:33.740
Then finally requests, and
you can pip or conda install that.
61

61

00:03:35.010  -->  00:03:39.280
So if we look at requests what
we're going to be using that for
62

62

00:03:39.280  -->  00:03:43.820
is just basically a standard module for
63

63

00:03:43.820  -->  00:03:49.610
communicating with websites using HTTP and
it's really user friendly.
64

64

00:03:49.610  -->  00:03:55.380
And then the Beautiful Soup module is one
of the main modules used in Python for
65

65

00:03:55.380  -->  00:03:59.950
web scraping and it's got a lot
of documentation to read up on.
66

66

00:03:59.950  -->  00:04:03.026
So you can check that
out on your own time.
67

67

00:04:03.026  -->  00:04:09.412
So now we'll hop over to the live
coding and do those imports.
68

68

00:04:09.412  -->  00:04:14.927
So lets go ahead and
69

69

00:04:14.927  -->  00:04:22.185
import Beautiful Soup.
70

70

00:04:22.185  -->  00:04:28.952
But, something to keep in mind is you're
actually going to import this from BS4.
71

71

00:04:28.952  -->  00:04:32.620
So that's just the convention, so
72

72

00:04:32.620  -->  00:04:37.700
you're importing Beautiful Soup from BS4,
which stands for Beautiful Soup 4.
73

73

00:04:37.700  -->  00:04:38.990
Great.
74

74

00:04:40.320  -->  00:04:43.792
So, let's keep going.
75

75

00:04:43.792  -->  00:04:45.209
I'm going to also import requests.
76

76

00:04:49.806  -->  00:04:52.860
And then since I want to later set
my information that I web scraped as
77

77

00:04:52.860  -->  00:04:55.286
a pandas.DataFrame I'm
gonna import pandas as PD.
78

78

00:04:58.931  -->  00:05:01.392
And then import, or from pandas,
79

79

00:05:04.156  -->  00:05:10.169
import series and data frame.
80

80

00:05:10.169  -->  00:05:12.633
Okay, so for
our quick web scraping tutorial,
81

81

00:05:12.633  -->  00:05:16.825
we're gonna look at some legislative
reports from the University of California
82

82

00:05:16.825  -->  00:05:19.905
webpage, so feel free to
experiment with other webpages,
83

83

00:05:19.905  -->  00:05:23.479
but just remember to be cautious and
respectful on what you scrape and
84

84

00:05:23.479  -->  00:05:27.270
how often you do it, and always check
the legality of a web scraping job.
85

85

00:05:28.830  -->  00:05:29.870
So, if we just go ahead and
86

86

00:05:29.870  -->  00:05:33.100
check out the URL,
I have it here in my IPython notebook.
87

87

00:05:34.490  -->  00:05:37.940
It's quite a long URL so
I'm just going to copy and paste it.
88

88

00:05:40.340  -->  00:05:46.120
Copy, paste it here, and
I'm setting it as an object called URL.
89

89

00:05:47.460  -->  00:05:50.050
So I'm just going to run this cell
real quick, and let's go ahead and
90

90

00:05:50.050  -->  00:05:51.290
check out the web page itself.
91

91

00:05:53.770  -->  00:05:57.178
So if you notice here,
we're at the University of California,
92

92

00:05:57.178  -->  00:05:58.890
office of the President.EDU.
93

93

00:05:58.890  -->  00:06:02.895
And I've come to a page where the budget
and the analysis and planning,
94

94

00:06:02.895  -->  00:06:05.043
and you can see there's a table here.
95

95

00:06:05.043  -->  00:06:07.876
So what I want to do is, if you notice,
96

96

00:06:07.876  -->  00:06:13.378
some of the report titles are available
as a PDF, and they all have a date.
97

97

00:06:13.378  -->  00:06:20.205
So what I want to do is Get this table and
basically set it as a pandas.DataFrame.
98

98

00:06:20.205  -->  00:06:26.179
So the next step is setting up a request
to grab content from the URL and
99

99

00:06:26.179  -->  00:06:29.376
set it up as a Beautiful Soup object.
100

100

00:06:29.376  -->  00:06:31.884
So I'm going to head over,
back to my life coding.
101

101

00:06:35.158  -->  00:06:39.361
Set an object called result, and
102

102

00:06:39.361  -->  00:06:46.883
then I'm gonna use
requests.getmethod on my URL object.
103

103

00:06:46.883  -->  00:06:51.173
That will be my result, and then I'll set
104

104

00:06:51.173  -->  00:06:56.210
an object called C as
the content of that result.
105

105

00:06:57.380  -->  00:07:01.890
So we're using requests to get the
information off that URL, that webpage,
106

106

00:07:01.890  -->  00:07:06.110
and then we're setting the content method
on that result and setting that as C.
107

107

00:07:07.610  -->  00:07:10.470
And then once you have that content
what you're going to be able to do using
108

108

00:07:10.470  -->  00:07:15.100
Beautiful Soup is make a soup object and
this is just the convention.
109

109

00:07:16.480  -->  00:07:21.200
And then call Beautiful Soup as
110

110

00:07:21.200  -->  00:07:26.230
a function on that content and
now you have a Beautiful Soup object.
111

111

00:07:26.230  -->  00:07:29.100
So we're going to be able to use
Beautiful Soup to search for
112

112

00:07:29.100  -->  00:07:34.070
what we want in that requests
result object, that content.
113

113

00:07:35.460  -->  00:07:39.690
So let's head back over
to the web page here.
114

114

00:07:40.940  -->  00:07:44.102
So how do I know what to look for
and where to find it?
115

115

00:07:44.102  -->  00:07:47.754
So what you're gonna do here is if you
go on Chrome, you can right-click and
116

116

00:07:47.754  -->  00:07:48.676
inspect element.
117

117

00:07:53.553  -->  00:07:57.610
And then this is where your HTML
knowledge will come into hand,
118

118

00:07:57.610  -->  00:07:59.381
will come handy actually.
119

119

00:07:59.381  -->  00:08:05.420
So what we wanna do is look for where
in the HTML code is this table written.
120

120

00:08:07.520  -->  00:08:11.092
So you can kind of scroll and look and
what you're generally gonna be doing is
121

121

00:08:11.092  -->  00:08:15.560
checking where your
table gets highlighted.
122

122

00:08:19.220  -->  00:08:24.900
So if you notice here and I'm sorry if
it's hard to read, but basically I am
123

123

00:08:24.900  -->  00:08:29.070
going through the HTML code,
it's inspecting the element, and
124

124

00:08:29.070  -->  00:08:32.860
waiting until I see what
I want is highlighted.
125

125

00:08:34.150  -->  00:08:40.440
So if you notice here, I clicked on
divclass=listland and did=content.
126

126

00:08:40.440  -->  00:08:43.910
And I see that what I wanted
is highlighted there.
127

127

00:08:43.910  -->  00:08:46.310
So now I know what class and
id to search for.
128

128

00:08:47.400  -->  00:08:52.390
So I'm gonna get that information, and
again if you don't quite understand that
129

129

00:08:52.390  -->  00:08:56.750
go ahead and look those things
up on the HTML tutorials, but
130

130

00:08:56.750  -->  00:08:58.530
now I know what class and ID I want.
131

131

00:08:58.530  -->  00:09:04.100
So I'm gonna go back to my live coding and
go to that section of interest.
132

132

00:09:04.100  -->  00:09:13.042
So, I'm gonna make an object
called summary and
133

133

00:09:13.042  -->  00:09:17.403
I'm gonna call the find
134

134

00:09:17.403  -->  00:09:22.647
method on that soup object.
135

135

00:09:22.647  -->  00:09:27.059
And then what I'm gonna do is pass
a dictionary for the class and the ID.
136

136

00:09:32.980  -->  00:09:37.438
And again, I'm not diving too
much into the HTML itself.
137

137

00:09:37.438  -->  00:09:39.830
I'll go ahead and
let you look that stuff up on your own.
138

138

00:09:39.830  -->  00:09:42.860
So this is really just about web scraping.
139

139

00:09:42.860  -->  00:09:45.822
Hopefully you already have a little
bit of HTML knowledge but again,
140

140

00:09:45.822  -->  00:09:47.057
if you don't don't worry.
141

141

00:09:47.057  -->  00:09:50.076
You can go ahead and
always look up those tutorials online.
142

142

00:09:53.744  -->  00:09:54.436
Okay, so
143

143

00:09:54.436  -->  00:09:59.968
we're gonna find in our soup object where
the class was equal to list land and
144

144

00:09:59.968  -->  00:10:05.516
where the ID was content and we can do
that by passing that dictionary there.
145

145

00:10:05.516  -->  00:10:08.551
And go ahead and look up
the beautiful soup documentation for
146

146

00:10:08.551  -->  00:10:11.720
other methods of doing this,
there's tons of ways to do this.
147

147

00:10:13.910  -->  00:10:18.100
So now I'm at the correct section and
I want to find a table in the HTML.
148

148

00:10:18.100  -->  00:10:24.180
So the way to do that is I'll
make an object called tables and
149

149

00:10:24.180  -->  00:10:32.869
I'll have that be equal to my summary and
then I'll pass the find all method.
150

150

00:10:32.869  -->  00:10:35.540
And I'm gonna tell it
to find all the tables.
151

151

00:10:37.070  -->  00:10:37.570
Great.
152

152

00:10:39.520  -->  00:10:44.570
So now we need to use Beautiful Soup
to find the actual table entries.
153

153

00:10:44.570  -->  00:10:47.770
So I'm gonna hop back over to
the IPython notebook here.
154

154

00:10:47.770  -->  00:10:50.910
A little quick dive into HTML.
155

155

00:10:50.910  -->  00:10:55.230
A td tag defines a standard
cell in an HTML table and
156

156

00:10:55.230  -->  00:10:58.270
the tr tag defines a row in an HTML table.
157

157

00:10:58.270  -->  00:11:01.090
So you can think of tr as table row.
158

158

00:11:01.090  -->  00:11:05.878
So what we're going to do is we're
gonna parse through our tables object,
159

159

00:11:05.878  -->  00:11:10.529
the one we just made and try to find
each cell using the find all TD method.
160

160

00:11:10.529  -->  00:11:14.523
So there's tons of options to use with
the find all method in Beautiful Soup.
161

161

00:11:14.523  -->  00:11:18.359
You can go ahead and click this
link here in the IPython notebook,
162

162

00:11:18.359  -->  00:11:23.175
that'll take you to the documentation,
specifically the find all section, and
163

163

00:11:23.175  -->  00:11:27.921
you can see that there's lots of different
ways to basically search through your
164

164

00:11:27.921  -->  00:11:32.564
Beautiful Soup objects, and I encourage
you to check out the documentation.
165

165

00:11:32.564  -->  00:11:37.190
If you're already familiar with HTML, it
will be very readable, but if you're not
166

166

00:11:37.190  -->  00:11:42.660
go ahead and do the HTML tutorials first,
and then look up the find all information.
167

167

00:11:42.660  -->  00:11:45.970
Again, this whole web scraper
tutorial is pretty dependent on
168

168

00:11:45.970  -->  00:11:48.460
a little bit of HTML knowledge.
169

169

00:11:48.460  -->  00:11:50.040
So, that's a good starting place for it.
170

170

00:11:51.230  -->  00:11:55.500
Okay, so what we're gonna do next
is we're gonna use Beautiful Soup
171

171

00:11:55.500  -->  00:12:00.610
to find the table entries and
we're going to do this using a four loop.
172

172

00:12:00.610  -->  00:12:04.000
So I'll go ahead and stop the video here,
and in the next section,
173

173

00:12:04.000  -->  00:12:07.610
we'll look at how to parse through our
information, that data from that webpage,
174

174

00:12:07.610  -->  00:12:10.130
and then set it as a pandas.DataFrame.
175

175

00:12:10.130  -->  00:12:11.880
Okay, thanks, and
I'll see you in the next video.
