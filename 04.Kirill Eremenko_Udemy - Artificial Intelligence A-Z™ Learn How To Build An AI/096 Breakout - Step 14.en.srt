1
00:00:00,540 --> 00:00:05,090
Hello and welcome to this story almost the final title of this module.

2
00:00:05,100 --> 00:00:10,260
I'm just going to explain the main code that will execute the whole thing before we get the exciting

3
00:00:10,290 --> 00:00:11,930
results and watch the videos.

4
00:00:12,090 --> 00:00:15,920
So this is the main code and as you can see this is pretty short.

5
00:00:15,930 --> 00:00:21,120
We start by importing the libraries and the modules and also the different classes and functions we

6
00:00:21,120 --> 00:00:24,270
made like Altikriti from our model file.

7
00:00:24,390 --> 00:00:30,210
The train function from the train file and the test function from the test file and of course we import

8
00:00:30,270 --> 00:00:31,930
our optimizer.

9
00:00:31,950 --> 00:00:37,350
Then we start with the first section where we get into a class all the parameters.

10
00:00:37,500 --> 00:00:39,660
And this is this perhaps.

11
00:00:39,720 --> 00:00:44,040
Remember this is BRAMs object that we created from this harams class.

12
00:00:44,040 --> 00:00:48,900
Each time we got a parameter like the learning rate we are not without.

13
00:00:49,200 --> 00:00:50,870
So let's go through them quickly.

14
00:00:50,880 --> 00:00:54,380
This first one or here is the learning rates.

15
00:00:54,480 --> 00:00:59,140
So as you can see we choose a small and you rate the second one is the parameter.

16
00:00:59,160 --> 00:01:09,810
Again we take it as 0.39 we take a OneTel parameter a set of 1 16 processes 20 steps and max length

17
00:01:09,900 --> 00:01:10,850
of 10000.

18
00:01:10,850 --> 00:01:17,580
And we spoke about that this is the parameter we set to make sure the agent doesn't get stuck indefinitely

19
00:01:17,730 --> 00:01:20,910
into a state of the environment so this will stop the game.

20
00:01:21,060 --> 00:01:28,800
If the episode length goes over this maximum length and eventually of course we get the name of our

21
00:01:28,800 --> 00:01:29,690
environment.

22
00:01:29,790 --> 00:01:30,890
Break up is zero.

23
00:01:30,990 --> 00:01:37,770
And by the way you can also play on some other environments just by changing the name of the environment

24
00:01:37,770 --> 00:01:38,410
here.

25
00:01:38,430 --> 00:01:44,760
So if you want to play to some other breakout versions or even some other Atari games well you can simply

26
00:01:45,030 --> 00:01:48,580
replace this breaking of zero here by some other games.

27
00:01:48,750 --> 00:01:53,730
But I can tell you that breakout video is already very challenging.

28
00:01:53,730 --> 00:01:56,030
All right so all the parameters here.

29
00:01:56,160 --> 00:01:59,330
And then there is the main code for the main run.

30
00:01:59,550 --> 00:02:02,850
And so here lets see what we do in this first line.

31
00:02:02,850 --> 00:02:05,270
We set one thread per core.

32
00:02:05,430 --> 00:02:11,880
Then in the second line we get all up renderers by you know creating a new object of the Paramjit class

33
00:02:12,150 --> 00:02:18,810
which will get initialize all these parameters here because there are variables attached to this BRAMs

34
00:02:18,810 --> 00:02:19,490
object.

35
00:02:19,560 --> 00:02:20,840
Then we set the seed.

36
00:02:20,970 --> 00:02:28,830
Then we get our environment using the Create tree and function with the name of our environment which

37
00:02:28,830 --> 00:02:30,040
is break out of zero.

38
00:02:30,040 --> 00:02:35,410
You see cells that name and therefore parameter and name is pretty of zero.

39
00:02:35,430 --> 00:02:37,660
So that will get us the environment of break out.

40
00:02:37,890 --> 00:02:42,870
And by the way this is not the usual way of creating an environment but you know to improve the whole

41
00:02:42,870 --> 00:02:45,540
process and to improve the performance.

42
00:02:45,690 --> 00:02:52,470
Well we use this to actually create an optimized environment and this we do this things the universe

43
00:02:52,630 --> 00:02:57,730
universe is a package that comes with all the packages you installed on open engine.

44
00:02:57,870 --> 00:03:01,490
Well thanks to universe we get an optimized environment.

45
00:03:01,590 --> 00:03:03,320
This is what its all about here.

46
00:03:04,050 --> 00:03:09,240
Then we get our shared model by creating an object of the active critic class.

47
00:03:09,240 --> 00:03:14,430
And so here it's important to understand that this shared model is the model shared by the different

48
00:03:14,430 --> 00:03:15,030
agents.

49
00:03:15,180 --> 00:03:17,880
So we have different threads in different course.

50
00:03:18,210 --> 00:03:25,410
And speaking of threats at the next line here shirred model that share memory what we do is we store

51
00:03:25,500 --> 00:03:31,260
the model in the shared memory of the computer so that all the threads can get access to it even if

52
00:03:31,260 --> 00:03:32,960
they are in different course.

53
00:03:33,000 --> 00:03:34,510
So that's what we do here.

54
00:03:34,530 --> 00:03:42,410
This is to enable this then we get our optimizer linked to the parameters of our shared model and with

55
00:03:42,410 --> 00:03:45,780
a learning rate of one point or one.

56
00:03:45,930 --> 00:03:51,030
And again it's important to understand that the optimizer is also shared because it's going to act on

57
00:03:51,030 --> 00:03:57,720
the shared model and saying that the next line optimized that share memory we store the optimizer into

58
00:03:57,780 --> 00:04:02,530
shared memory so that all the agents can get access to it to optimize the model.

59
00:04:02,910 --> 00:04:10,260
Then we initialize our processes so the test process doesn't update the shared model but it just uses

60
00:04:10,260 --> 00:04:14,710
it to try it in one part and print the score and record the videos.

61
00:04:14,820 --> 00:04:17,920
So that's exactly what is done here with Target equals test.

62
00:04:17,940 --> 00:04:24,330
That's the test process and this process here is cut from torture that multi pre-processing.

63
00:04:24,450 --> 00:04:31,600
So here and what it does is that it basically runs a function on an independent thread.

64
00:04:31,860 --> 00:04:38,050
So then when we do restart we start a new process which was the initial Last year at this time.

65
00:04:38,370 --> 00:04:45,030
And then with this process to append P we add the process in the list of the processes.

66
00:04:45,270 --> 00:04:52,170
And finally in this loop here we just do a loop to run all the other processes that will be trained

67
00:04:52,380 --> 00:04:54,320
by updating the shared model.

68
00:04:54,780 --> 00:04:58,030
And that's basically what happens in the last lines of code here.

69
00:04:58,380 --> 00:05:03,870
So if you don't want to get into the details of it the important thing to understand is that this will

70
00:05:03,870 --> 00:05:09,420
run the processes in an optimal way and therefore we should all be good to execute this code and to

71
00:05:09,420 --> 00:05:12,670
have a trained model and eventually watch the results.

72
00:05:12,840 --> 00:05:14,150
So I can't wait to do that.

73
00:05:14,160 --> 00:05:16,110
This is going to be pretty exciting.

74
00:05:16,110 --> 00:05:19,240
I will try to find people now so that we can all watch it together.

75
00:05:19,350 --> 00:05:21,440
And so until next time I.
