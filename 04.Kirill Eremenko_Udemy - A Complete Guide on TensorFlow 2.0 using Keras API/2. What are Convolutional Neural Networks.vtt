WEBVTT
1
00:00:00.450 --> 00:00:02.880
Hello and welcome back to the course on deep learning.

2
00:00:02.880 --> 00:00:06.840
Today we're kicking off convolution evolution all neural networks is gonna be exciting.

3
00:00:06.840 --> 00:00:08.550
Let's dive straight into it.

4
00:00:08.550 --> 00:00:10.860
We're going to start off with an image.

5
00:00:10.860 --> 00:00:13.530
What do you see when you look at this image.

6
00:00:13.530 --> 00:00:17.980
Do you see a person looking at you or do you see a person looking to the right.

7
00:00:18.120 --> 00:00:24.000
You can see that your brain is is struggling is struggling to adjust.

8
00:00:24.000 --> 00:00:27.810
If you look to the right side of the image just look at the right border of there which you'll see a

9
00:00:27.810 --> 00:00:29.180
person looking to the right.

10
00:00:29.220 --> 00:00:32.810
If you look at the left border of the image you'll see a person looking at you.

11
00:00:33.660 --> 00:00:42.720
And this just proves that what our brain is looking for when we see things is features depending on

12
00:00:42.720 --> 00:00:47.970
the features that it sees depending on the features that you process you categorize things in certain

13
00:00:47.970 --> 00:00:48.650
ways.

14
00:00:48.660 --> 00:00:53.760
So when you look on the right side of the image you see certain features of a person looking to the

15
00:00:53.760 --> 00:00:59.490
right because they're closer to your center of focus and therefore your brain classifies as that as

16
00:00:59.490 --> 00:01:00.820
a person looking to the right.

17
00:01:00.930 --> 00:01:06.750
When you look to the left side of the image you see more features of a person looking at you and therefore

18
00:01:06.750 --> 00:01:09.540
your brain classifies it as such.

19
00:01:09.540 --> 00:01:11.070
So let's have a look at another one.

20
00:01:11.160 --> 00:01:14.540
This is a very famous image you probably have already seen it.

21
00:01:14.610 --> 00:01:16.760
But what do you see here.

22
00:01:16.800 --> 00:01:23.770
So some people will say that they see a young lady wearing a dress looking away.

23
00:01:23.790 --> 00:01:30.070
Some people say they see an old lady wearing a scarf on her head looking down.

24
00:01:30.210 --> 00:01:34.230
So I'm going to point these features out and you'll see that will become very obvious.

25
00:01:34.230 --> 00:01:37.440
So this is the face of the young lady looking away.

26
00:01:37.440 --> 00:01:43.170
She's looking into the distance that's her coat that's her hair that's her little feather in her hair

27
00:01:43.620 --> 00:01:50.790
and on the other hand this is the head of the old lady looking down that's her nose that's her mouth

28
00:01:51.090 --> 00:01:55.650
that's her chin that's the scarf on her head and she's looking down.

29
00:01:55.740 --> 00:02:01.890
So as you can see two in one and depending on which features your brain picks up it will switch between

30
00:02:02.550 --> 00:02:06.810
classifying each the image as one or the other.

31
00:02:06.820 --> 00:02:15.180
Now all this one of these illusions recorded in the printed work is this one it's the duck or the rabbit.

32
00:02:15.180 --> 00:02:16.940
So is this a duck or is this a rabbit.

33
00:02:16.950 --> 00:02:17.850
Another example.

34
00:02:18.360 --> 00:02:24.570
And now I'm going to show an image which will just for a second just look at it and see what what's

35
00:02:24.720 --> 00:02:29.060
what emotions or what kind of experience visual experience you go through.

36
00:02:29.070 --> 00:02:36.360
So what do you see does you feel like a bit not dizzy but a bill a of a bedazzled like your brain is

37
00:02:36.360 --> 00:02:38.950
trying to try and understand what it is what it is like.

38
00:02:39.100 --> 00:02:48.550
It's trying to is jumping between her eyes up and down eyes and this is a classic example of when there

39
00:02:48.730 --> 00:02:53.920
are certain features where it could be this it could be that but your brain cannot decide.

40
00:02:54.090 --> 00:03:02.520
And because both seem plausible and yes so basically all these examples illustrate to us how the brain

41
00:03:02.520 --> 00:03:08.570
works that it processes certain features on an image or on whatever you see in in real life.

42
00:03:08.730 --> 00:03:14.820
And it classifies that as such and you probably have been in situations when you look over your shoulder

43
00:03:14.820 --> 00:03:21.630
quickly and you see something you think it's I don't know if it's like a a a ball but it turns out to

44
00:03:21.630 --> 00:03:26.310
be a cat or you think it's a it's a car but turns out to be a shadow and things like that because you

45
00:03:26.310 --> 00:03:30.360
don't have enough time to process those features or you don't have enough features to classify things

46
00:03:30.360 --> 00:03:31.120
as such.

47
00:03:31.200 --> 00:03:38.520
And this is for me is this is very interesting because what we're going to be doing with neural networks

48
00:03:38.520 --> 00:03:43.680
with convolution or neural networks is very similar and you'll find that the way that computers are

49
00:03:43.680 --> 00:03:48.150
going to be processing images is going to be extremely similar to the way we are processing images.

50
00:03:48.150 --> 00:03:53.540
So it is very valuable to understand and just kind of remember these things that this is how we do it.

51
00:03:53.550 --> 00:03:58.230
And I'm going to take this lady off your screens because she's probably already freaking out by now.

52
00:03:58.560 --> 00:04:06.510
So here's something different here's an experiment an experiment done on computers on conventional neural

53
00:04:06.510 --> 00:04:13.680
networks so we're slowly moving now from humans to computers and this slide is a is from a told by Jeffrey

54
00:04:13.680 --> 00:04:15.120
Hinton.

55
00:04:15.300 --> 00:04:22.230
And here you have basically describes an experiment that he had done on some conventional neural networks

56
00:04:22.230 --> 00:04:24.330
that he had trained up.

57
00:04:24.390 --> 00:04:29.520
So here you see three images and we're going to go through them we'll have to wait and see how you would

58
00:04:29.520 --> 00:04:31.500
classify them and then see how the computer classify them.

59
00:04:31.800 --> 00:04:35.010
So on the left to what do you think this is.

60
00:04:35.400 --> 00:04:37.650
You probably said cheetah and you will be right.

61
00:04:37.650 --> 00:04:39.960
And this is what the computer said so and the right.

62
00:04:39.990 --> 00:04:44.520
Right away right off the bat we're going to learn how to read these images because if you're going to

63
00:04:44.550 --> 00:04:52.140
go deep into call or neural networks no pun intended if you're going to start learning more and more

64
00:04:52.140 --> 00:04:53.940
about them and using them you'll see a lot of these.

65
00:04:54.000 --> 00:05:01.000
So and I've actually seen people read them incorrectly so here at the top Qaeda is what it actually

66
00:05:01.000 --> 00:05:01.420
is.

67
00:05:01.420 --> 00:05:04.810
So that's the actual correct label of the image.

68
00:05:04.810 --> 00:05:07.270
That's what the label of the images.

69
00:05:07.300 --> 00:05:11.310
Regardless of any processing and view computer vision.

70
00:05:11.710 --> 00:05:18.130
And then here are the guesses the top four or five sometimes guesses of the algorithm.

71
00:05:18.250 --> 00:05:25.000
And they're given the probability so the computer is said or the neural network said cheetah leopard.

72
00:05:25.000 --> 00:05:29.110
Snow Leopard or Egyptian cat can be one of the four and cheetah has the highest vote.

73
00:05:29.110 --> 00:05:34.780
And throughout this part of the course you will understand what these votes mean and how they are derived.

74
00:05:34.780 --> 00:05:40.090
But for now it's pretty intuitive right so it's a cheetah in reality and the neural network guessed

75
00:05:40.210 --> 00:05:40.630
right.

76
00:05:40.630 --> 00:05:45.730
It said for hyperbole about like ninety five million eight percent it's a chimp.

77
00:05:45.880 --> 00:05:46.780
Then the second one.

78
00:05:46.810 --> 00:05:54.430
What do you think does it that is that it is a bullet train and the neural network was able to distinguish

79
00:05:54.430 --> 00:05:57.970
between bullet train passenger car subway train electric locomotive.

80
00:05:57.970 --> 00:05:59.330
Those are the top choices of course.

81
00:05:59.350 --> 00:06:05.800
It had many more options these neural networks learned to distinguish from not just for categories from

82
00:06:05.950 --> 00:06:08.680
dozens thousands of categories at the same time.

83
00:06:08.680 --> 00:06:10.830
So those are the four options that it picked.

84
00:06:10.870 --> 00:06:12.760
And so that's a bullet train and it's a train.

85
00:06:12.760 --> 00:06:17.270
So what do you think the last one is very very.

86
00:06:17.320 --> 00:06:18.480
There are a couple of options.

87
00:06:18.490 --> 00:06:25.000
It's not very clear what is it could be a frying pan could be a magnifying glass it could be even maybe

88
00:06:25.240 --> 00:06:31.030
a pair of scissors some might say well the neural network said it was a pair of scissors but you can

89
00:06:31.030 --> 00:06:32.500
see how you can go wrong here.

90
00:06:32.530 --> 00:06:41.530
First of all it's not a very clear image and also you can see that the probabilities are not as clear

91
00:06:41.530 --> 00:06:46.210
here as the neural network was a bit confused a bit indecisive just as we are.

92
00:06:46.210 --> 00:06:51.330
So it said scissors with the highest probability but then it had hand glass which had actually was with

93
00:06:51.400 --> 00:06:55.840
not not so far away on second place and frying pan stethoscope.

94
00:06:55.840 --> 00:07:01.570
So basically here you can see that scissors was its first guess but the correct option was number two

95
00:07:01.570 --> 00:07:03.160
and that's why it's highlighted in red.

96
00:07:03.250 --> 00:07:03.950
So there we go.

97
00:07:03.950 --> 00:07:08.820
Those that's what neural networks are already capable of and this is actually quite an old slide.

98
00:07:08.830 --> 00:07:10.590
This was several years ago.

99
00:07:10.600 --> 00:07:16.020
Now they're even better and you will see that from the practical application that you'll be coding together

100
00:07:16.070 --> 00:07:16.730
Hudlin.

101
00:07:16.860 --> 00:07:21.160
But now let's try trying to set a bit better what converts or evolution or neural networks actually

102
00:07:21.160 --> 00:07:26.140
are and why are they gaining so much popularity and they actually are gaining popularity so you can

103
00:07:26.140 --> 00:07:31.720
see here a Google Trends comparison I did just yesterday.

104
00:07:31.720 --> 00:07:38.530
Here you can see that convenient can relational neural networks are even taking over artificial neural

105
00:07:38.740 --> 00:07:39.400
networks.

106
00:07:39.400 --> 00:07:47.740
So a massive increase and this is going to keep going that way because it is a very important field

107
00:07:48.040 --> 00:07:52.480
that that is where all the things happen such as like self-driving cars.

108
00:07:52.480 --> 00:07:59.290
How do they recognize people on the road how to recognize stop signs and things like that how do how

109
00:07:59.290 --> 00:08:07.600
does Facebook host Facebook able to tag images or people in images and not only just like remember previously

110
00:08:07.930 --> 00:08:13.570
years ago you had to take people yourself then it would recognize faces you had to add many.

111
00:08:13.570 --> 00:08:18.100
Add the names and now it just recognizes the faces and add the names at the same time.

112
00:08:18.550 --> 00:08:23.670
Well that is what kind of delusional neural networks are capable of.

113
00:08:23.710 --> 00:08:32.290
And speaking of Facebook if Geoffrey Hinton is the godfather of artificial neural networks and deep

114
00:08:32.290 --> 00:08:39.610
learning then a young Lachlan is the grandfather of convert delusional neural networks young lagoon

115
00:08:39.670 --> 00:08:47.320
is a student of Geoffrey Hinton's and in fact here you can see them together and Geoffrey Hinton now

116
00:08:47.500 --> 00:08:54.400
is pioneering Deep Learning in at Google Yang kun is the director of Facebook artificial intelligence

117
00:08:54.400 --> 00:08:56.560
research and also a professor at NYU.

118
00:08:56.950 --> 00:09:02.610
So we're slowly aware I love this part of the course slowly we're building up this name.

119
00:09:02.620 --> 00:09:10.750
These names are this kind of picture of the profiles of the people who are driving this field and next

120
00:09:10.930 --> 00:09:16.600
in the next couple of parts will get to know about a few more and we'll have this whole Mafia as they

121
00:09:16.600 --> 00:09:22.240
call themselves or you could call them mafia or conspiracy of deep learning and you'll learn a bit more

122
00:09:22.240 --> 00:09:27.230
about how this whole field developed and yeah it's just these are just some great great people.

123
00:09:27.370 --> 00:09:35.230
And so young looking back in the 80s and the 90s made significant contributions to their field of evolution

124
00:09:35.230 --> 00:09:36.250
or neural networks.

125
00:09:36.280 --> 00:09:44.260
And as we'll see throughout this course has been able to develop or help the world develop something

126
00:09:44.290 --> 00:09:46.480
so extremely powerful.

127
00:09:46.570 --> 00:09:51.210
So moving onto how can delusional neural networks work.

128
00:09:51.400 --> 00:09:54.220
You have an input it's very simple it's very straightforward.

129
00:09:54.250 --> 00:09:59.740
So you have an input image it goes through the conditional neural network and you have an the label

130
00:09:59.740 --> 00:10:06.610
so it classifies that image as something like as a Cheeto or a bullet train or something else.

131
00:10:06.710 --> 00:10:10.650
Now kind of like going into a bit more detail.

132
00:10:10.810 --> 00:10:18.850
For instance you can after a neural network has been trained up on uncertain images on certain classified

133
00:10:18.850 --> 00:10:21.360
images or categorized images prior.

134
00:10:21.400 --> 00:10:23.650
There have been Cairo's prior.

135
00:10:23.650 --> 00:10:29.470
After that you can give it let's say and unilaterally has been trained up to recognize facial expressions

136
00:10:29.470 --> 00:10:36.970
emotions you can give in a face of a smiling person is not just a face like a drawing of a face like

137
00:10:36.970 --> 00:10:39.150
this but actual face or a person smiling.

138
00:10:39.400 --> 00:10:44.830
And I'll tell you that that person is happy and you can give her a face of a person that's frowning.

139
00:10:44.830 --> 00:10:47.200
It will tell you that the person is sad.

140
00:10:47.230 --> 00:10:52.510
You can recognize these emotions and as you can see that's already very powerful in terms of so many

141
00:10:52.510 --> 00:10:57.590
different applications just this one example you can think of right away.

142
00:10:58.130 --> 00:11:03.730
And in both cases it'll give you a probability so it won't say you know if we're 100 percent the person's

143
00:11:03.940 --> 00:11:11.560
happy or sad it'll be ninety nine or many eight or maybe 80 percent when it's unclear of what's going

144
00:11:11.560 --> 00:11:16.590
on and just like we are right sometimes we can mistake things for what they're not.

145
00:11:16.630 --> 00:11:23.560
Or sometimes we can sometimes it's just not clear if the person is smiling or frowning or if it's if

146
00:11:23.560 --> 00:11:29.540
it's a dog or a cat or if it's a train or a bullet train all right sometimes we don't have.

147
00:11:29.710 --> 00:11:35.830
We haven't seen enough features and all goes down to features because that's how we process visual information

148
00:11:35.830 --> 00:11:38.490
as we saw from the start of this tutorial.

149
00:11:38.560 --> 00:11:40.980
So but how does a neural network.

150
00:11:41.020 --> 00:11:44.080
How does a neural network able to recognize these features.

151
00:11:44.080 --> 00:11:50.730
Well it all starts at the very basic level you have let's say you have an image you have two images.

152
00:11:50.770 --> 00:11:56.240
One is a black and white image of two by two pixels and one is a colored image of two by two pixels.

153
00:11:56.470 --> 00:12:04.630
While neural networks leverage the fact that the black and white image is a two dimensional array.

154
00:12:04.630 --> 00:12:09.560
So the way we see it right now on the left is just the visual representation.

155
00:12:09.630 --> 00:12:11.100
So it's some kind of picture.

156
00:12:11.190 --> 00:12:16.540
And for simplicity's sake is just a two way two picture but in computer terms it's actually a two dimensional

157
00:12:16.540 --> 00:12:22.250
array with every single one of those pixels having a value between zero and China and 55.

158
00:12:22.300 --> 00:12:27.600
So that's 8 8 bits of information to the two to the power of eight is 256.

159
00:12:27.610 --> 00:12:30.390
So therefore the values are from 0 to 255.

160
00:12:30.400 --> 00:12:32.150
And that's the intensity of the color.

161
00:12:32.200 --> 00:12:38.200
And in this case the color white so 0 will be a completely black pixel 255 will be a completely white

162
00:12:38.200 --> 00:12:44.440
pixel and between them you have the grayscale range of possible options for this pixel.

163
00:12:44.590 --> 00:12:50.640
And based on that information computers are able to then work off the image and that's kind of like

164
00:12:50.680 --> 00:12:56.560
the starting point that any image is actually has a digital representation has a digital form.

165
00:12:56.560 --> 00:13:03.220
And those are just basically ones and zeros that form a number of 0 to 255 for every single pixel.

166
00:13:03.220 --> 00:13:07.120
That's what the computer looks for if it doesn't actually work with you know colors or anything works

167
00:13:07.120 --> 00:13:08.730
with the ones and zeros at the end of the day.

168
00:13:08.740 --> 00:13:13.000
That's as kind of like the foundation of it all.

169
00:13:13.300 --> 00:13:17.120
And in a colored image it's actually a three dimensional array.

170
00:13:17.170 --> 00:13:24.130
You've got blue pixel you've got a blue Larry Green layer and a red layer and and that says for RG Big

171
00:13:24.130 --> 00:13:24.840
Red Green Blue.

172
00:13:25.390 --> 00:13:29.710
And each one of those colors has its own intensity.

173
00:13:29.710 --> 00:13:40.910
So basically a pixel has 3 3 values assigned to it each one of them is between 0 and 256 255.

174
00:13:41.350 --> 00:13:45.970
And therefore you can find out what's this image.

175
00:13:46.240 --> 00:13:51.730
What color exactly this pixel is by combining those three values and again computers are going to be

176
00:13:51.940 --> 00:13:53.470
working with that.

177
00:13:53.470 --> 00:13:59.420
So that's the foundation of it all that's the red channel the green channel the blue channel.

178
00:13:59.470 --> 00:14:08.020
And finally let's have a look at for instance an example a very trivial example of a smiling face in

179
00:14:08.370 --> 00:14:16.480
in computer terms if we just really simplify things instead of having from 0 to 255 instead of having

180
00:14:16.480 --> 00:14:21.280
those values just so that we can understand things better and really grasp the concepts we're going

181
00:14:21.280 --> 00:14:26.490
to say zero is is white one is black.

182
00:14:26.530 --> 00:14:26.770
Right.

183
00:14:26.770 --> 00:14:33.400
So we're just going to simplify things to the extreme and you will see that that image can be represented

184
00:14:33.400 --> 00:14:33.940
like that.

185
00:14:33.940 --> 00:14:38.920
So the reason why we've brought this up is because we're going to all of our interest in story as we

186
00:14:38.920 --> 00:14:44.500
get a structure on images like this which are very simple but at the same time then all of those concepts

187
00:14:44.500 --> 00:14:50.400
can translate back to the 0 2 256 range of values and everything applies the same way.

188
00:14:50.680 --> 00:14:54.850
And the steps that we're going to be going through with these images are September 1 convolution.

189
00:14:54.880 --> 00:14:56.770
Step number two max pulling.

190
00:14:56.770 --> 00:15:02.420
Step number three flattening and step number for full connection and I can imagine that probably none

191
00:15:02.420 --> 00:15:05.690
of these words mean much to you at the moment.

192
00:15:05.690 --> 00:15:13.400
But by the end of this section of the course you will understand them in great detail and exactly what

193
00:15:13.400 --> 00:15:15.950
they're doing so we'll get started the next material.

194
00:15:15.950 --> 00:15:24.350
For now the additional reading that you might want to look into is a young Lukens original paper that

195
00:15:24.560 --> 00:15:28.160
gave the rise to coalition of neural networks.

196
00:15:28.160 --> 00:15:31.600
It's called gradient based learning applied to documentary cognition.

197
00:15:31.640 --> 00:15:34.530
You may have seen this image before floating around the Internet.

198
00:15:34.550 --> 00:15:40.940
It is from that paper so if you want to go back to the very beginnings of how it all happened where

199
00:15:40.940 --> 00:15:41.800
it all came from.

200
00:15:41.870 --> 00:15:46.100
This is the paper to look into and I look forward to seeing on the next story.

201
00:15:46.370 --> 00:15:48.230
Until then enjoy deep learning.
