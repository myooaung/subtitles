1
00:00:00,860 --> 00:00:06,680
Hello everyone and welcome to the low serving section throughout this section we are going to talk about

2
00:00:06,700 --> 00:00:13,130
tens of flow serving which is one of the most powerful libraries out there to put a deep learning model

3
00:00:13,190 --> 00:00:15,210
into production.

4
00:00:15,270 --> 00:00:20,850
It is going to handle a lot of stuff in the background for us and we are going to leverage that power

5
00:00:20,850 --> 00:00:26,660
to create image classification API and put it in production using this library.

6
00:00:26,790 --> 00:00:33,900
It is extension of the terms of flow library itself which makes a lot stop easier.

7
00:00:33,910 --> 00:00:37,340
Let's take a few minutes to talk about the library.

8
00:00:37,350 --> 00:00:43,490
The first question we need to answer is what these tens of low serving as I mentioned the tens of flow's

9
00:00:43,490 --> 00:00:47,160
serving is an extension of the terms of flow library.

10
00:00:47,160 --> 00:00:51,570
It is there to provide a multiple services around the model itself.

11
00:00:51,570 --> 00:00:59,970
For example comparing all models version control of the models A B testing and many more putting model

12
00:00:59,970 --> 00:01:05,980
in production can be really complicated but to overcome this problem we are going to use terms of flow

13
00:01:05,980 --> 00:01:13,150
serving library after we train our model that has a flow serving is there to provide all around the

14
00:01:13,150 --> 00:01:19,870
model which is much bigger than the model itself how it all comes together and how it works will be

15
00:01:19,870 --> 00:01:27,150
much better explained in the code where you will see all the magic happening but the highest level overview

16
00:01:27,300 --> 00:01:33,480
is like this on the one side we have a train model it could be any model that we train so far in the

17
00:01:33,480 --> 00:01:40,620
course then we have a tensor flow serving the library that takes that model and creates a whole infrastructure

18
00:01:40,620 --> 00:01:44,920
around it and then we have an application on the other side.

19
00:01:45,170 --> 00:01:51,840
Some other developer came and has written a Web application or a mobile application and the middleman

20
00:01:51,840 --> 00:01:58,170
here between you and that developer is the tens of low serving it creates a very simple connection between

21
00:01:58,170 --> 00:02:04,850
a user facing application and a model that we trained let's explain what these tens of low serving in

22
00:02:04,850 --> 00:02:12,800
more detail is all of the client server architectures we have the client side which could be a web application

23
00:02:12,840 --> 00:02:17,010
mobile application or even an I.T. device.

24
00:02:17,250 --> 00:02:23,880
On the other side we have a server which is here to handle a hard core stuff that couldn't be handled

25
00:02:24,000 --> 00:02:25,780
on the client side.

26
00:02:25,890 --> 00:02:31,080
What you see right here is an overview of the task that we are trying to solve in this module of course

27
00:02:31,950 --> 00:02:38,640
we have a certain picture of a dog and we want to put that image of a dog for a model which is located

28
00:02:38,670 --> 00:02:46,190
on a server and only thing that we expect from a server is a prediction is that a cat or a dog what

29
00:02:46,190 --> 00:02:52,880
we need to do on the client side is we need to take a picture create a request of it a boss request

30
00:02:52,940 --> 00:03:00,020
since we are sending some data to the server and that's all what we have to do on the client side on

31
00:03:00,020 --> 00:03:00,920
the server side.

32
00:03:00,920 --> 00:03:07,340
However it is going to take that picture from the request and put it through the model and spill out

33
00:03:07,340 --> 00:03:10,020
some prediction after that's done.

34
00:03:10,040 --> 00:03:16,510
It is going to send those prediction in the form of a response to the application and that's all what

35
00:03:16,510 --> 00:03:23,260
we have to do as you can see it is not that complicated because the developers from the tens of low

36
00:03:23,260 --> 00:03:26,430
serving handled a lot of stuff for us.

37
00:03:26,560 --> 00:03:33,220
Therefore you will see that at the end of the day it is very straightforward to make a very cool scalable

38
00:03:33,220 --> 00:03:38,340
service of your model in the previous section of the course.

39
00:03:38,350 --> 00:03:42,670
We put the model in production using flask framework or the python.

40
00:03:42,670 --> 00:03:45,610
It worked and it worked really well.

41
00:03:45,610 --> 00:03:48,510
Why do we need a tender flow serving instead of a flask.

42
00:03:48,520 --> 00:03:56,700
For example since it is a much simpler to be honest than the tens of low serving well scalability is

43
00:03:56,700 --> 00:03:59,680
a very big issue when it comes to the flask.

44
00:03:59,820 --> 00:04:05,810
It is made to handle some things but when it comes to millions of users it is not good.

45
00:04:05,880 --> 00:04:10,380
It could be good but we would need to write a lot of stuff from scratch.

46
00:04:10,380 --> 00:04:17,390
It is a bare minimum to put something on the web scalability is not an issue in the terms of flow serving

47
00:04:17,810 --> 00:04:22,400
it is made for us to handle millions or even billions of requests.

48
00:04:22,400 --> 00:04:29,150
Google is using it daily for multiple of their products such as Google Translate Google Maps and so

49
00:04:29,150 --> 00:04:35,510
on due to its scalability and its use for millions or even billions of requests.

50
00:04:35,580 --> 00:04:39,270
It is a must to have a low latency in parallel.

51
00:04:39,300 --> 00:04:44,270
It can serve multiple clients and that is not what flask is able to do.

52
00:04:45,410 --> 00:04:51,650
These are two major issues flask cannot handle natively and that's why to flow serving.

53
00:04:51,650 --> 00:04:54,160
Is there on the other side.

54
00:04:54,170 --> 00:05:00,010
We have the issue of handling multiple models flask is capable of doing that.

55
00:05:00,020 --> 00:05:01,910
It is not that difficult to make it work.

56
00:05:02,720 --> 00:05:07,630
But scenes that tend to flow serving is made for that use case as well.

57
00:05:07,730 --> 00:05:12,530
That is one more advantage of the terms of flow serving over the flask.

58
00:05:12,530 --> 00:05:18,950
Apart from everything we mentioned so far that tells a flow serving also handles multiple versions of

59
00:05:18,950 --> 00:05:20,470
the same model.

60
00:05:20,600 --> 00:05:22,430
It could be pretty messy to handle.

61
00:05:22,430 --> 00:05:28,970
Free models for free different tasks that has 10 different versions of each model.

62
00:05:29,120 --> 00:05:35,450
As I mentioned before flask is capable of doing that but not on the same level as it has a flow serving

63
00:05:36,520 --> 00:05:42,870
I would say that these four are the main advantages of the tens of close serving in the next three days

64
00:05:42,870 --> 00:05:50,900
or we will focus on the explanation of the tender plus serving architecture if you have more if you

65
00:05:50,900 --> 00:05:53,300
have any questions or comments so far.

66
00:05:53,360 --> 00:05:55,410
Please post them in the comments section.

67
00:05:55,550 --> 00:05:57,410
Otherwise I've seen a nice tutorial.
