1
00:00:00,420 --> 00:00:02,870
Hello everyone and welcome to this python tutorial.

2
00:00:03,990 --> 00:00:11,160
In the previous video we define our custom model by combining a Bayes network which is a pre train model

3
00:00:11,190 --> 00:00:19,320
called Mobile that to be two in our custom head for the specific task of classifying cats and dogs.

4
00:00:19,320 --> 00:00:26,770
The next step for us is to compile the model if you remember how we compile all models in previous sections.

5
00:00:26,770 --> 00:00:32,830
It is going to be the same even though we are using the pre train as well which are more complicated

6
00:00:32,830 --> 00:00:35,530
and loading in different ways.

7
00:00:35,530 --> 00:00:44,620
The combining step is totally the same so in the first free cell right model does compile and now we

8
00:00:44,620 --> 00:00:52,240
have to provide free arguments as always an optimizer a lost function and metrics.

9
00:00:52,300 --> 00:00:59,530
So in this case we want specified the optimizer with the string as before we are going to use a specific

10
00:00:59,530 --> 00:01:02,130
tensor flow function for it.

11
00:01:02,170 --> 00:01:04,300
I'll explain why in just a second.

12
00:01:04,390 --> 00:01:13,570
So just write they don't care us but optimizes and now we have to choose what optimizer to use since

13
00:01:13,570 --> 00:01:15,310
we are using that mobile Net.

14
00:01:15,310 --> 00:01:17,480
Architecture is our base network.

15
00:01:17,740 --> 00:01:20,430
It is proven to be the best optimized for it.

16
00:01:20,470 --> 00:01:23,280
Air mass prop so we are going to choose it.

17
00:01:24,610 --> 00:01:31,900
And because we are using a pre train network we have to specify smaller learning rate than default 1

18
00:01:33,090 --> 00:01:35,970
if we want to specify an optimizer with a string.

19
00:01:35,970 --> 00:01:41,240
It will take all default arguments but we have to change the learning rate parameter.

20
00:01:41,280 --> 00:01:47,990
In this case and that's why we have used that tends to flow function to set our optimizer instead of

21
00:01:47,990 --> 00:01:57,450
simple string so inside Aramis prop provide L are shorter for learning rate and said that to be zero

22
00:01:57,450 --> 00:02:01,990
point three zeros and one at this point.

23
00:02:02,080 --> 00:02:07,810
You may wonder how do they knew what learning rate to choose when I prepared this section for you.

24
00:02:07,810 --> 00:02:14,830
I use mumble net architecture for the first time as well so I had to google a lot of stuff and they

25
00:02:14,830 --> 00:02:22,090
found on Stack Overflow what learning array to choose for this architecture now said the loss to binary

26
00:02:22,210 --> 00:02:26,910
cross entropy since we are only have two classes in our set.

27
00:02:27,400 --> 00:02:33,750
And lastly let us provide metrics that we are going to monitor throughout the training process in this

28
00:02:33,750 --> 00:02:34,200
case.

29
00:02:34,260 --> 00:02:41,730
We are going to simply use an accuracy execute the cell and we have successfully compiled the model

30
00:02:42,790 --> 00:02:43,650
in the next video.

31
00:02:43,660 --> 00:02:48,590
We are going to create our data generators for the data set for now.

32
00:02:48,610 --> 00:02:52,960
If you have any questions or comments please bother them in the comments section.

33
00:02:52,960 --> 00:02:54,880
Otherwise I see in the next tutorial.
