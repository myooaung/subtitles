1
00:00:00,390 --> 00:00:02,220
And welcome back guys.

2
00:00:02,220 --> 00:00:07,030
So far we cover the high level overview of the tens of flow serving.

3
00:00:07,320 --> 00:00:12,120
And in this video we'll talk about its architecture obviously.

4
00:00:12,150 --> 00:00:17,070
You don't have to know these things or to know them in great detail.

5
00:00:17,070 --> 00:00:22,760
If you want only to put the modelling production you can do that in just a few lines of code.

6
00:00:23,040 --> 00:00:29,910
But if you want to create more complex infrastructures around your models or to handle some errors this

7
00:00:29,910 --> 00:00:31,320
knowledge will come in handy.

8
00:00:32,670 --> 00:00:36,370
In the previous video we started the client side architecture.

9
00:00:36,420 --> 00:00:40,230
Since then the client side did not change at all.

10
00:00:40,230 --> 00:00:46,170
Still we have an application from whom a user uploads an image for the post to request to our server

11
00:00:47,150 --> 00:00:51,800
by the server side was much simpler on the server side.

12
00:00:51,800 --> 00:00:58,010
We had a model that takes an image from the request and sends a prediction back to the client.

13
00:00:58,010 --> 00:01:04,820
Now let's take a few minutes to explain what is the role of tens of serving on the server our server

14
00:01:04,820 --> 00:01:12,000
is now split up into two different parts the file system and the tens of low serving on the file system

15
00:01:12,000 --> 00:01:18,480
we have free models saved it could be the same model but three different versions of it or we could

16
00:01:18,480 --> 00:01:24,500
have a totally different models and let's say that we have an app where we want to serve a different

17
00:01:24,500 --> 00:01:31,970
model based on geo location to our user or we want to test the model one on one set of users and the

18
00:01:31,970 --> 00:01:39,760
rest should be served by a model to that's where the tensor flow comes into play the tensor flow has

19
00:01:39,850 --> 00:01:47,170
many moving parts and we won't cover them all in this tutorial just three of them let's start from the

20
00:01:47,170 --> 00:01:54,880
left in the desert floor serving because we are serving the model a model is called a server all because

21
00:01:54,880 --> 00:02:02,230
of that we have a path called solvable handler it is a module of the tens of flows serving infrastructure

22
00:02:02,470 --> 00:02:10,760
that handles a model for us the middle path here is called version MANAGER We can either have multiple

23
00:02:10,760 --> 00:02:18,590
models for different tasks or various versions of the same model we as a deep learning engineers our

24
00:02:18,590 --> 00:02:25,580
job is to improve the current model constantly or to come up with newer and newer architectures and

25
00:02:25,580 --> 00:02:32,030
that's how we end up having multiple versions of the same model or even multiple models to make sure

26
00:02:32,030 --> 00:02:37,850
that our newest version of the model works better than the current one in production we need to test

27
00:02:37,850 --> 00:02:45,130
it well testing the latest version of the model we don't want to expose it to all the users but one

28
00:02:45,130 --> 00:02:52,120
subset that is that subset for us let's say on the users from Serbia are going to experience latest

29
00:02:52,120 --> 00:02:59,770
version and we can specify that to a version manager and the manager will handle that for us and then

30
00:02:59,770 --> 00:03:07,630
we have a model loader it is the closest part of the tells a flow serving stack to the filesystem it

31
00:03:07,630 --> 00:03:14,110
takes a message from the version manager what model to load based on that message the model loader will

32
00:03:14,110 --> 00:03:20,650
reach for the file system load the model and provide it back to a version manager the version manager

33
00:03:20,710 --> 00:03:25,890
will inform the cerebral handler that the model is a loaded and ready to be served.

34
00:03:26,320 --> 00:03:33,430
And finally the prediction based on the uploaded image is sent to the user and that's pretty much it.

35
00:03:33,600 --> 00:03:36,050
We won't go into more detail than this.

36
00:03:36,330 --> 00:03:41,970
If you have any questions or comments so far please post them in the comments section otherwise I'll

37
00:03:41,970 --> 00:03:43,050
see you in the next tutorial.
