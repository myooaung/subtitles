1

00:00:00,560  -->  00:00:07,200
Last and we had a very long tutorial on corrupted CSU files and text qualifiers and I hope that by now

2

00:00:07,200  -->  00:00:14,070
you are a pro with text qualifiers and you know exactly what they're for and how they work and how CACP

3

00:00:14,070  -->  00:00:16,710
files operate as well.

4

00:00:16,710  -->  00:00:20,940
So today what we're going to do is we're going to start our upload Hulver before we do that.

5

00:00:20,940  -->  00:00:25,610
I wanted to show you something in this preview over here.

6

00:00:25,770  -->  00:00:33,210
So as you remember we excluded row 1 from our analysis because it was totally corrupted and fro '96

7

00:00:33,210  -->  00:00:34,630
we decided to fix it.

8

00:00:34,650  -->  00:00:43,230
And we added that quotation mark so that the feedback column is in one cell rather than skewing this

9

00:00:43,230  -->  00:00:44,060
whole row.

10

00:00:44,310  -->  00:00:51,150
But if you scroll a bit to the Right now what you will notice is that the date the birth date is not

11

00:00:51,180  -->  00:00:54,600
in the right format it's not in the format that we wanted to put it in.

12

00:00:54,690  -->  00:01:00,660
And the reason for that is because the rows were actually skewed to the right in excel when we originally

13

00:01:00,660  -->  00:01:05,190
put the file in Excel the rows automatically go skewed to the right.

14

00:01:05,190  -->  00:01:10,280
So this birthday was actually in the tropical zodiac or colon.

15

00:01:10,290  -->  00:01:16,590
And then when we performed our daughter wrangling before the load in Excel and we corrected the birth

16

00:01:16,600  -->  00:01:23,100
the column as you remember we didn't affect this specific cell because it wasn't in this column at the

17

00:01:23,100  -->  00:01:23,760
time.

18

00:01:23,760  -->  00:01:25,600
So all the other cells got affected.

19

00:01:25,800  -->  00:01:33,000
And then this cell only came back into this column so this data only came back into this column after

20

00:01:33,180  -->  00:01:38,640
we corrected the CACP file just in the previous tutorial.

21

00:01:38,790  -->  00:01:45,900
So that is some of those discrepancies that you have to keep in mind that the adjustments that you make

22

00:01:45,900  -->  00:01:50,670
to the file are affected by the discrete anomalies that are present in the file.

23

00:01:50,670  -->  00:01:53,550
So in this case this data was not in the right.

24

00:01:53,550  -->  00:01:56,250
Call them when we were making the changes.

25

00:01:56,410  -->  00:02:02,730
On the other hand the dollar sign is OK because it is to the left of the column that had an error.

26

00:02:02,730  -->  00:02:07,710
So it is to the left of this column and it wasn't affected by that by this anomaly so it wasn't skewed

27

00:02:07,740  -->  00:02:11,000
and it got fixed up OK in Excel.

28

00:02:11,280  -->  00:02:12,290
The date wasn't.

29

00:02:12,300  -->  00:02:18,120
So if you're fixing up columns to the right of the problem area then you might have you might experience

30

00:02:18,120  -->  00:02:24,300
issues in this case what you would need to do is you need to go back and correct this column as well

31

00:02:24,300  -->  00:02:24,550
.

32

00:02:24,570  -->  00:02:26,840
That's option number one.

33

00:02:26,910  -->  00:02:30,590
Number two is you can upload the file like this and then deal with this error.

34

00:02:30,600  -->  00:02:33,480
This is an error in as well.

35

00:02:33,540  -->  00:02:34,730
Or option number three.

36

00:02:34,770  -->  00:02:39,480
You can go into your file and exclude this row and that's exactly what we're going to do.

37

00:02:39,870  -->  00:02:43,800
Because I find it just safer if you find any kind of anomaly.

38

00:02:43,950  -->  00:02:49,830
You can try to correct it like we did in the Preuss tutorial and you know I hope that's a good illustration

39

00:02:49,830  -->  00:02:53,590
of how you would go about correcting issues manually.

40

00:02:53,730  -->  00:02:59,310
On the other hand I find it's a bit safer to exclude anomalies and then deal with all of them separately

41

00:02:59,310  -->  00:02:59,330
.

42

00:02:59,330  -->  00:03:00,940
So that's what we're going to do now.

43

00:03:01,290  -->  00:03:04,820
We're going to go to our folder fake names.

44

00:03:04,860  -->  00:03:09,480
That file is in the uploaded data that's the one we're dealing with now what we're not going to touch

45

00:03:09,480  -->  00:03:10,020
it right now.

46

00:03:10,020  -->  00:03:15,290
We're going to always go to the prepared folder and here we've got osseous Veep.

47

00:03:15,480  -->  00:03:20,080
So as you recall we want to excluded from this file from this file.

48

00:03:20,160  -->  00:03:27,830
And we will find the column and row its row number 96 the low record number 96.

49

00:03:27,900  -->  00:03:29,130
So here it is.

50

00:03:29,130  -->  00:03:30,660
Thank you for a great experience.

51

00:03:30,660  -->  00:03:36,610
So all we can do is we're going to delete it make sure that you didn't delete anything else.

52

00:03:36,610  -->  00:03:37,680
That's great.

53

00:03:37,840  -->  00:03:43,790
And we're just going to save it now we're going to take this file first.

54

00:03:43,830  -->  00:03:46,190
We're going to close our manager here.

55

00:03:46,500  -->  00:03:53,570
Now we're going to take the file and we're going to replace the one that's over here.

56

00:03:54,960  -->  00:04:00,900
And also we need to remember that we need to make a copy of that role so we're going to take the original

57

00:04:00,900  -->  00:04:06,570
data file copy it put it in the prepared data for now or actually which is good to put in the analysis

58

00:04:06,570  -->  00:04:08,350
right away data errors.

59

00:04:08,400  -->  00:04:12,220
So we're going to go to manually exclude results.

60

00:04:12,450  -->  00:04:18,800
Fake name then we're going to just say original row.

61

00:04:18,810  -->  00:04:23,160
Ninety six.

62

00:04:23,160  -->  00:04:29,040
So now we just want to go here and delete everything except for Rule Number 96

63

00:04:31,860  -->  00:04:39,690
that will allow us to come back and deal with all of these error rows when the time comes.

64

00:04:39,690  -->  00:04:41,520
So we'll save that.

65

00:04:41,550  -->  00:04:45,490
Now we have to delete rows in the correct result which is going to get rid of this whole folder.

66

00:04:45,840  -->  00:04:46,130
All right.

67

00:04:46,140  -->  00:04:47,880
Now let's proceed with our upload.

68

00:04:47,910  -->  00:04:49,960
We're going to go back to the source.

69

00:04:49,970  -->  00:04:54,780
We're going to create a new connection manager find a file see us we file.

70

00:04:54,770  -->  00:04:55,580
There it is.

71

00:04:55,770  -->  00:05:01,610
So it's going to be quotation marks columns.

72

00:05:01,620  -->  00:05:03,610
Let's have a look here.

73

00:05:04,200  -->  00:05:05,620
96 is not here.

74

00:05:05,730  -->  00:05:07,490
And so is 81.

75

00:05:07,480  -->  00:05:09,880
That because we took them out.

76

00:05:10,020  -->  00:05:11,790
Now we're going to go to advanced.

77

00:05:11,790  -->  00:05:19,180
We're going to select everything and say which is a thousand press Enter preview.

78

00:05:19,260  -->  00:05:28,710
Check again click OK columns are output could only be destination here.

79

00:05:28,740  -->  00:05:35,730
What I wanted to say is that for every single project Ideally you will have a separate database or at

80

00:05:35,730  -->  00:05:38,220
least a separate schema within your database.

81

00:05:38,220  -->  00:05:45,480
That way you can separate the files or the tables that relate to that project from the tables that relate

82

00:05:45,480  -->  00:05:46,470
to other projects.

83

00:05:46,470  -->  00:05:50,240
In our case we're going to use the same database just because this is training.

84

00:05:50,240  -->  00:05:56,730
So as I recall we've already used year straining for tables not related to this project in the previous

85

00:05:56,730  -->  00:05:58,150
sections of discourse.

86

00:05:58,380  -->  00:06:03,810
However today we're still going to use this training just because we're practicing and we don't really

87

00:06:03,810  -->  00:06:07,230
need a separate database for every single project we're doing.

88

00:06:07,800  -->  00:06:12,990
OK so India-Australia we're going to create a new table we're going to give our table name as you recall

89

00:06:13,200  -->  00:06:18,210
the name is going to have a role and there will be something familiar.

90

00:06:18,210  -->  00:06:19,110
Fake names.

91

00:06:19,110  -->  00:06:21,620
And then the date.

92

00:06:23,100  -->  00:06:30,030
And now we're going to add an identity row just because we do that every single time.

93

00:06:30,030  -->  00:06:33,570
All right so that is our table.

94

00:06:33,580  -->  00:06:40,140
Those are all our columns including the last column over here which we will deal with in Eski already

95

00:06:40,440  -->  00:06:43,690
and click OK mappings.

96

00:06:43,690  -->  00:06:45,750
There is our mappings heire output.

97

00:06:45,750  -->  00:06:46,280
Good.

98

00:06:46,530  -->  00:06:54,810
So everything is ready just need to fix this up because of the code page and off we go to the races

99

00:06:54,810  -->  00:06:56,570
.

100

00:06:56,670  -->  00:07:00,680
So there they go as uploading and we get an error.

101

00:07:00,870  -->  00:07:01,870
What happened here.

102

00:07:01,890  -->  00:07:03,190
Let's have a look.

103

00:07:03,240  -->  00:07:08,130
This is how it looks like when you get an error in your society process.

104

00:07:08,250  -->  00:07:10,640
So a certain number of rows has been uploaded.

105

00:07:10,650  -->  00:07:15,510
This number of rows has very little to do with where the error occurred.

106

00:07:15,510  -->  00:07:21,910
You can't really tell the error didn't occur on a row thirty thousand two hundred seventy eight which

107

00:07:21,960  -->  00:07:27,960
you can find out is more information on the error and you need to go down here where it says package

108

00:07:27,960  -->  00:07:30,180
executed execution complete with error.

109

00:07:30,270  -->  00:07:35,820
So basically you want to click this button or as we discussed this button at the top stop debugging

110

00:07:36,360  -->  00:07:38,700
and that will stop this process.

111

00:07:38,760  -->  00:07:45,510
And now to find out more about where you go to execution results over here and here you will have information

112

00:07:45,540  -->  00:07:47,280
on what happened during the upload.

113

00:07:47,290  -->  00:07:49,780
So this is exactly what is going on.

114

00:07:49,800  -->  00:07:53,700
We started the upload over here and some information some information.

115

00:07:53,760  -->  00:07:58,950
And then finally here these red crosses over here it tells you about the error right away.

116

00:07:58,950  -->  00:08:04,980
Here you can see daughter conversion failed the daughter conversion for calm feedback returned status

117

00:08:04,980  -->  00:08:12,780
value for and status text text was truncated or one or more characters had no match in the target code

118

00:08:12,780  -->  00:08:13,410
page.

119

00:08:13,410  -->  00:08:14,850
So that's our era.

120

00:08:14,850  -->  00:08:20,100
And then there's some more information so then it's like regraded here by the way if it doesn't fit

121

00:08:20,130  -->  00:08:28,700
in the in this line you just have to take make a copy so you copy that era and let's say we take notepad

122

00:08:28,710  -->  00:08:36,410
plus plus now and we just copy the error in here and we want to view Wardrop.

123

00:08:36,600  -->  00:08:38,300
And here you can read the whole area.

124

00:08:38,430  -->  00:08:44,370
So basically there was a truncation of the text in the feedback column and we will need to go have a

125

00:08:44,370  -->  00:08:45,240
look at that.

126

00:08:45,330  -->  00:08:48,310
If you keep reading here you can see it actually tells you the row.

127

00:08:48,390  -->  00:08:51,720
Thirty one thousand three hundred and fifty one.

128

00:08:51,720  -->  00:08:54,090
So let's go ahead and check that row out.

129

00:08:54,090  -->  00:08:57,050
So we're going to go back to notepad plus plus close this.

130

00:08:57,390  -->  00:09:06,720
And now we will go to our daughter errors Nelson's fake names so prepare data this one that we're working

131

00:09:06,720  -->  00:09:07,750
with.

132

00:09:08,640  -->  00:09:13,910
We're going to open it up and see it's in Notepad plus plus now we go into view.

133

00:09:13,920  -->  00:09:15,490
Word wrap unwrap it.

134

00:09:15,570  -->  00:09:22,320
You just press control on your keyboard and say where you want to go through 1351 OK.

135

00:09:22,680  -->  00:09:26,220
And there you go that's your old 1351.

136

00:09:26,460  -->  00:09:30,970
And if you scroll to the right what can we see here.

137

00:09:31,030  -->  00:09:37,360
We have we see the column feedback and you can see that it is quite long.

138

00:09:37,710  -->  00:09:46,480
So this person left a lot of feedback like a lot a lot of feedback really had something to say.

139

00:09:47,040  -->  00:09:53,160
So this is one of those anomalies people like in your daughter said people don't usually write more

140

00:09:53,160  -->  00:09:59,370
than a thousand characters of feedback but this person really had a massive complaint to make and they

141

00:09:59,370  -->  00:09:59,800
made it.

142

00:09:59,970  -->  00:10:02,480
So obviously we want to preserve this information.

143

00:10:02,580  -->  00:10:04,920
How can we get it into the database.

144

00:10:04,920  -->  00:10:10,380
Very simple we just need to specify more than 1000 characters for this specific field for the whole

145

00:10:10,380  -->  00:10:11,840
field of feedback.

146

00:10:12,120  -->  00:10:13,580
So that's what we're going to do.

147

00:10:13,590  -->  00:10:20,700
We're not going to change anything in fake names and therefore we don't need to change the file in the

148

00:10:21,030  -->  00:10:23,040
uploaded data folder.

149

00:10:23,070  -->  00:10:28,030
All we need to do is correct our connection manager and our database.

150

00:10:28,110  -->  00:10:35,640
So we're going to go to the connection manager wrote two columns advanced and here we'll leave everything

151

00:10:35,650  -->  00:10:37,930
at a thousand with output.

152

00:10:38,160  -->  00:10:41,810
The one we want to correct is feedback.

153

00:10:41,900  -->  00:10:43,100
There is feedback.

154

00:10:43,200  -->  00:10:45,620
So we're going to change it to 5000.

155

00:10:45,960  -->  00:10:52,510
I like to specify 5000 that is usually enough in these cases the maximum you can specify here is 8000

156

00:10:52,980  -->  00:10:59,570
because that is the maximum length of a VAR char variable in your database.

157

00:10:59,580  -->  00:11:04,040
So you don't want to go over 8000 If you have a field that's over 8000.

158

00:11:04,230  -->  00:11:09,630
You will have to deal with that separately you might need to exclude that record as an anomaly or you

159

00:11:09,630  -->  00:11:15,200
might need to break that up and try to break it up into two pieces of text.

160

00:11:15,300  -->  00:11:20,870
So we're just going to say five thousand go to preview look at it here just in case.

161

00:11:21,220  -->  00:11:22,150
OK.

162

00:11:22,680  -->  00:11:25,320
Then you see this exclamation mark up here.

163

00:11:25,320  -->  00:11:27,660
That's because we corrected the flat file connection.

164

00:11:27,710  -->  00:11:32,730
We haven't corrected the flat file source so DoubleClick that it will say do you want to replace the

165

00:11:32,730  -->  00:11:36,080
metadata of the output columns with the method out of certain columns.

166

00:11:36,120  -->  00:11:41,730
Yes exactly you want to do that and it's already done it for us so we don't need to do anything in here

167

00:11:41,730  -->  00:11:41,790
.

168

00:11:41,790  -->  00:11:44,490
It's correct to everything click OK.

169

00:11:44,650  -->  00:11:46,830
Now this needs to go.

170

00:11:46,870  -->  00:11:53,400
We need to delete this connection because here the table that we created is not going to be good enough

171

00:11:53,550  -->  00:11:56,570
for the flat file sources you'll see that in a second.

172

00:11:56,620  -->  00:12:01,560
So what are we going to do is we're going to go to you all and and ask Well we're going to drop the

173

00:12:01,560  -->  00:12:04,990
table that we just populate because we don't need it anymore.

174

00:12:05,010  -->  00:12:08,070
So this is this skill if you can see your table.

175

00:12:08,160  -->  00:12:10,740
So just right click tables and click refresh.

176

00:12:10,890  -->  00:12:18,600
Should be there so if you take your table and select top thousand rows you will see here that some rows

177

00:12:18,610  -->  00:12:19,970
have been uploaded.

178

00:12:19,980  -->  00:12:22,110
Of course this is the top thousand.

179

00:12:22,120  -->  00:12:27,450
So if we just get rid of that and click the execute button over here you will see.

180

00:12:27,450  -->  00:12:29,740
Now this is the full table.

181

00:12:29,760  -->  00:12:34,290
What there is you'll see that a certain number of rows have been applied but not everything obviously

182

00:12:34,300  -->  00:12:34,530
.

183

00:12:34,740  -->  00:12:37,560
So we want to get rid of this table we don't need any more.

184

00:12:37,560  -->  00:12:42,470
You can right click here and click delete or I'll show you the proper way of doing it.

185

00:12:42,480  -->  00:12:46,380
So get rid of everything from from from select to from.

186

00:12:46,380  -->  00:12:53,760
So just leave the table name and click drop type and drop table and then click execute.

187

00:12:54,090  -->  00:13:00,600
What you'll see happen is Tables drop successfully and so if you click refresh tables no longer there

188

00:13:00,610  -->  00:13:01,010
.

189

00:13:01,080  -->  00:13:01,520
Great.

190

00:13:01,530  -->  00:13:04,710
So we got rid of that is good to clean up after yourself.

191

00:13:05,010  -->  00:13:11,970
And now we're going to go into Assayas and we're going to create a new table all the D-B destination

192

00:13:11,990  -->  00:13:13,260
.

193

00:13:13,260  -->  00:13:14,980
We're going to create new.

194

00:13:15,060  -->  00:13:16,080
Same thing.

195

00:13:16,230  -->  00:13:19,670
And now we're going to add a roll number.

196

00:13:19,740  -->  00:13:23,600
All right so that's how table why the previous still wasn't good enough.

197

00:13:23,620  -->  00:13:26,400
Well have a look here in feedback.

198

00:13:26,400  -->  00:13:28,940
Now this table is going to be created as a click OK.

199

00:13:28,950  -->  00:13:35,410
This table is going to be created with varchar of 5000 not 1000 so everything else is still thousand

200

00:13:35,860  -->  00:13:42,390
but this one's going to be 5000 why it will because of that blue arrow that connects the to the flat

201

00:13:42,390  -->  00:13:45,860
file source and the destination.

202

00:13:45,960  -->  00:13:52,390
This manager knows that we want to create a table that is 5000 with this column.

203

00:13:52,500  -->  00:13:55,790
The previous table was 1000 with and now it was fixed.

204

00:13:55,800  -->  00:13:59,660
You would have to modify the table itself to to fix it to correct that.

205

00:13:59,760  -->  00:14:02,200
We don't want to waste time on that so why follow.

206

00:14:02,310  -->  00:14:03,850
It is it's already done for us.

207

00:14:03,840  -->  00:14:05,310
We're just going to click OK.

208

00:14:05,310  -->  00:14:08,910
Tables being created will go to mappings error output.

209

00:14:08,910  -->  00:14:09,550
Good.

210

00:14:09,880  -->  00:14:14,780
And we could just launch this and off it goes.

211

00:14:15,530  -->  00:14:17,190
So everything has been uploaded.

212

00:14:17,190  -->  00:14:18,100
Great.

213

00:14:18,660  -->  00:14:19,660
Let's have a look.

214

00:14:19,710  -->  00:14:22,800
Let's obviously stop this process.

215

00:14:22,800  -->  00:14:24,720
Click here.

216

00:14:24,720  -->  00:14:27,690
Don't forget to save your package.

217

00:14:27,690  -->  00:14:28,140
All right.

218

00:14:28,140  -->  00:14:31,390
Now let's go to Eskew all again and here.

219

00:14:31,380  -->  00:14:35,150
We don't want to drop the table so we're just going to close this refresh.

220

00:14:35,210  -->  00:14:41,040
There is our table and we're going to select the top 1000 rows.

221

00:14:41,040  -->  00:14:45,640
All right we're going to actually select everything.

222

00:14:46,140  -->  00:14:50,700
So you can just get rid of that the top thousand and you'll select everything.

223

00:14:50,700  -->  00:14:59,250
And here as you can see they're not uploaded in in order so basically they're uploaded kind of randomly

224

00:14:59,250  -->  00:15:02,040
and that's just you know that's how the skill works.

225

00:15:02,040  -->  00:15:05,310
They don't have to be uploaded in order.

226

00:15:05,310  -->  00:15:08,400
So here we go to the bottom.

227

00:15:08,430  -->  00:15:13,130
We can look around and basically this is our table.

228

00:15:13,140  -->  00:15:19,700
But as we discussed this is not the heredoc format yet it's not ready for us to do our analysis.

229

00:15:19,710  -->  00:15:20,140
Why.

230

00:15:20,130  -->  00:15:25,530
Well because we know that there are still errors in here or we suspect that there are still errors in

231

00:15:25,530  -->  00:15:29,780
this data and we would love to get rid of them somehow.

232

00:15:30,120  -->  00:15:34,640
Obviously we can go through everything manually and like right now it doesn't look like there's anything

233

00:15:35,040  -->  00:15:39,630
and your problems in this column but that's just because we're scrolling so fast and we can see if there's

234

00:15:39,630  -->  00:15:42,900
like one record somewhere here in this column that's anomalous.

235

00:15:42,900  -->  00:15:45,020
You won't be able to visually pick it up.

236

00:15:45,150  -->  00:15:46,560
You just scroll through it quickly.

237

00:15:46,560  -->  00:15:54,900
So in the next tutorial I will show you how to pick up errors in skill and then we'll learn how to deal

238

00:15:54,900  -->  00:15:55,120
with them
