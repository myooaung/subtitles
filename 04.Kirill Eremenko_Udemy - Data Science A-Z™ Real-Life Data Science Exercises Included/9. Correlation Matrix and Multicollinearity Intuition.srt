1

00:00:00,510  -->  00:00:07,200
Last time we checked for killing effects using Varians inflation factors and today we will look at using

2

00:00:07,200  -->  00:00:09,380
the correlation metric metrics by the way.

3

00:00:09,390  -->  00:00:16,440
I just wanted to say that we're not going into detail into the formulas into the whys and hows of these

4

00:00:16,920  -->  00:00:22,470
methods simply because I just can't fit everything into this course.

5

00:00:22,470  -->  00:00:28,320
I just want to show you the methods that exist and how you can apply them in practice because I think

6

00:00:28,320  -->  00:00:30,110
that's that's the most important part.

7

00:00:30,120  -->  00:00:39,150
And whenever you do need to learn the nuts and bolts of why what geefs are or how the correlation match

8

00:00:39,150  -->  00:00:41,320
matrix is constructs and so on.

9

00:00:41,610  -->  00:00:45,290
I believe there's lots and lots of ways you can learn that.

10

00:00:45,300  -->  00:00:49,760
But right now we're focusing on the practical application of these things.

11

00:00:50,070  -->  00:00:57,600
So we want to look at the correlation matrix that's another way to investigate any kind of possible

12

00:00:58,140  -->  00:01:07,290
culinarily between your variables to create a correlation matrix in gril you need to go to dadda and

13

00:01:07,290  -->  00:01:13,050
we'll talk about it just now once we've created a view correlation matrix and then select the variables

14

00:01:13,080  -->  00:01:21,180
we want to check log w a wealth accumulation log bounds and what else age.

15

00:01:21,420  -->  00:01:23,190
Let's look at those.

16

00:01:23,220  -->  00:01:27,840
So I just put in for you can put in more Brize just put in for because this window once once you burn

17

00:01:27,840  -->  00:01:32,100
more and it goes to the next line and it doesn't look pretty.

18

00:01:32,100  -->  00:01:38,530
So what can we see here a correlation matrix is basically a table which is half filled.

19

00:01:38,900  -->  00:01:43,530
It's how I feel because this other part here that's not there would have been a mirror image of that

20

00:01:43,530  -->  00:01:44,250
one.

21

00:01:44,250  -->  00:01:51,900
And in each cell you have a number which tells you about the creation of the two variables the one that's

22

00:01:51,990  -->  00:01:54,360
at the head of the column and the ones at the head of the row.

23

00:01:54,360  -->  00:02:02,610
So if you cross these rows and columns and say the correlation for followed bounce log that is 0.19

24

00:02:02,610  -->  00:02:08,290
it for the Croatian for wealth accumulation and ages minus 0.2 463.

25

00:02:08,640  -->  00:02:18,650
And correlation can be between minus 1 and 1 and is basically a parameter that tells you about how how

26

00:02:18,660  -->  00:02:25,410
in line these variables are so when one variable changes how much how how similar does the other variable

27

00:02:25,410  -->  00:02:26,580
change as well.

28

00:02:26,580  -->  00:02:30,480
And the more correlated they are the higher the number will be.

29

00:02:30,480  -->  00:02:37,620
So basically a correlation of one is ideal correlation and that's why you can see here that age of age

30

00:02:37,620  -->  00:02:41,800
is ideally correlated and your variable of itself is always going to be idylic related.

31

00:02:42,090  -->  00:02:46,920
And then zero is no correlation at all whatsoever.

32

00:02:46,920  -->  00:02:48,850
So for example here you can see age and low.

33

00:02:48,980  -->  00:02:56,610
They are very they have very very low correlation and minus one is ideal anti-coalition or negative

34

00:02:56,610  -->  00:03:01,930
correlation which means that there they're still correlated but they change in opposite ways.

35

00:03:02,130  -->  00:03:07,650
And so basically when you look at the correlation matrix you should forget about the minus a plus.

36

00:03:07,770  -->  00:03:15,150
Just look at the absolute value here you can see that right away log bounds and log w a have a very

37

00:03:15,150  -->  00:03:20,440
high correlation it pretty much x behaving as the same variable.

38

00:03:20,450  -->  00:03:24,520
So that is very bad for our model.

39

00:03:24,780  -->  00:03:27,300
Then we have low balance and wealth accumulation.

40

00:03:27,300  -->  00:03:33,600
This is why previously we saw that there was there were some issues because they are also very well

41

00:03:33,630  -->  00:03:34,680
correlated.

42

00:03:34,680  -->  00:03:35,910
Age is an interesting one.

43

00:03:35,910  -->  00:03:41,550
Age is not very well correlated with Flugge W.A. even though it's part of that calculation but it is

44

00:03:43,290  -->  00:03:46,890
quite a bit correlated with wealth accumulation.

45

00:03:46,890  -->  00:03:53,100
So as you can see the logarithm changes the variable and makes it less correlated with that variable

46

00:03:53,100  -->  00:03:55,000
which is part of the calculation.

47

00:03:55,380  -->  00:04:01,860
Basically here which is looking for a rule of thumb is anything above zero point nine is very high correlation

48

00:04:01,890  -->  00:04:07,780
and you have to do something about anything above zero point seven.

49

00:04:07,890  -->  00:04:09,530
Also very high correlation.

50

00:04:09,540  -->  00:04:16,530
So not very high but I'd say just high correlation also suggests that to do something about 0.5 to 0.7

51

00:04:16,530  -->  00:04:18,840
is moderate can cause a correlation.

52

00:04:18,990  -->  00:04:24,140
Perhaps we're looking into 0.3 to and higher.

53

00:04:24,360  -->  00:04:31,200
That's just like low correlation and perhaps you could leave that in the model but try to avoid those

54

00:04:31,200  -->  00:04:32,040
kind of things.

55

00:04:32,040  -->  00:04:37,890
And finally Anything below 0 0.3 is low correlation and as you get closer to zero there's pretty much

56

00:04:38,250  -->  00:04:39,450
no correlation left.

57

00:04:39,450  -->  00:04:43,160
So those are your That's your rule of thumb.

58

00:04:43,170  -->  00:04:48,870
But it also ultimately depends on what variables you're looking into what your ultimate goal is and

59

00:04:49,320  -->  00:04:51,070
things like that.

60

00:04:51,150  -->  00:04:59,410
So that's how you read a correlation matrix and you're probably wondering by now why is it bad for a

61

00:04:59,560  -->  00:05:03,420
model when you have what multi-colored Nardi in your marbles.

62

00:05:03,510  -->  00:05:08,340
It's kind of intuitive when you think about it that you're pretty much double counting like here you

63

00:05:08,340  -->  00:05:11,970
can see even though there are different variables you're double counting a variable in the model.

64

00:05:12,060  -->  00:05:16,520
But why is exactly is it bad on like on an intuitive level.

65

00:05:16,530  -->  00:05:22,860
I think it's worth covering this question so I'll bring up them for mail for logistic regression.

66

00:05:23,010  -->  00:05:24,650
So we're looking at this bottom one here.

67

00:05:24,720  -->  00:05:27,860
You can see that you've got lots of variables here.

68

00:05:27,960  -->  00:05:35,850
So let's say that x1 and x2 just like Lague balance and log W-K are highly very highly correlated then

69

00:05:35,850  -->  00:05:42,750
what happens is when the regression is trying to build this model it's slow it's tweaking X-1 a little

70

00:05:42,750  -->  00:05:50,310
bit and trying to hold everything else constant to see how X-1 affects the probability and the left

71

00:05:50,310  -->  00:05:56,280
side and based on like lots and lots of those iterations it will find the ultimate BE1 coefficient for

72

00:05:56,280  -->  00:06:02,130
x 1 then it does the same thing for X it tries to hold everything else constant and tweaks this a little

73

00:06:02,130  -->  00:06:09,570
bit a bit more a bit less and tries to find the ultimate coefficient for B2 that will explain how X-2

74

00:06:09,570  -->  00:06:15,510
is affecting what we are observing the changes on the left and so on and then gets to X and the same

75

00:06:15,510  -->  00:06:21,420
thing and hold everything else constant as much as it can as possibly can and tweaks this one a little

76

00:06:21,420  -->  00:06:27,120
bit to left a little bit to the right looks at how the verbal is changing for those observations and

77

00:06:27,120  -->  00:06:32,090
then tries to find the Beco coefficient that best explains this.

78

00:06:32,580  -->  00:06:39,540
This association between the two what happens when you have two variables that are correlated to say

79

00:06:39,540  -->  00:06:47,490
x1 and x2 are correlated well the correlation simply cannot find the correct coefficients for these

80

00:06:47,490  -->  00:06:57,090
variables because whenever it tries to assess X-1 it's trying to investigate how X-1 is associated with

81

00:06:57,090  -->  00:06:58,920
the dependent variable.

82

00:06:58,920  -->  00:07:03,490
So what is doing is trying to hold everything else constant and just tweak X-1 a little bit to level

83

00:07:03,610  -->  00:07:05,840
limit to the right to see how this will change.

84

00:07:05,880  -->  00:07:07,230
Well what ever tries to do that.

85

00:07:07,230  -->  00:07:08,580
This one also changes.

86

00:07:08,700  -->  00:07:12,140
So as long as you change this one and this one will change.

87

00:07:12,140  -->  00:07:12,670
Whatever.

88

00:07:12,690  -->  00:07:18,810
Whatever tries to read always see that so it cannot assess the individual effects of the variables on

89

00:07:18,810  -->  00:07:20,190
your dependent variable.

90

00:07:20,190  -->  00:07:25,560
Same thing when when you get to X 2 it's tries to hold everything else constant and tweak X-2 a little

91

00:07:25,560  -->  00:07:33,430
bit to left a little bit to the right and still it fails because X-1 will always change in its change

92

00:07:33,460  -->  00:07:38,060
will be aligned with the change of X-2 and it just doesn't have those.

93

00:07:38,060  -->  00:07:42,170
It just doesn't have the opportunity to assess the individual effects.

94

00:07:42,300  -->  00:07:43,200
And that's what happens.

95

00:07:43,200  -->  00:07:49,890
That's what I mean when I say that multicollinearity breaks in models it doesn't allow them to be constructed

96

00:07:49,890  -->  00:07:58,500
properly and that's why you want to get rid of multicollinearity effects in your independent variables

97

00:07:58,500  -->  00:07:58,950
.

98

00:07:58,980  -->  00:08:05,800
So that's a very intuitive way of looking at multicollinearity and why it's bad.

99

00:08:05,820  -->  00:08:07,400
Hope that's that's helpful.

100

00:08:07,500  -->  00:08:16,200
It's quite a complex thing and I guess it's important to get your head around that so I hope this my

101

00:08:16,200  -->  00:08:20,320
intuitive way of understanding it helps you understand it a little bit better as well.
