WEBVTT
1
00:00:00.840 --> 00:00:05.440
[Autogenerated] Let's switch our attention to sage Maker built in algorithms.

2
00:00:05.440 --> 00:00:10.000
If you have used an unsupervised algorithm like work to wake for sentiment,

3
00:00:10.000 --> 00:00:16.140
analysis our text classifications for tasks like Web searches,

4
00:00:16.140 --> 00:00:19.790
then you will have a good handle off blazing text algorithm.

5
00:00:19.790 --> 00:00:23.780
Because there's interest algorithm is a highly optimized

6
00:00:23.780 --> 00:00:27.840
implementation off these to algorithms.

7
00:00:27.840 --> 00:00:30.890
Both were to wake on text classifications.

8
00:00:30.890 --> 00:00:35.010
Works only on words and sentences are not an entire

9
00:00:35.010 --> 00:00:38.580
document for text classifications.

10
00:00:38.580 --> 00:00:42.940
URL Gardens The input needs to be one sentence per line,

11
00:00:42.940 --> 00:00:48.540
separated by spaces, with the first word being a string underscore.

12
00:00:48.540 --> 00:00:54.140
Underscore label Underscore Underscore on for a word to wake.

13
00:00:54.140 --> 00:01:00.540
It just wants a plain text file with one sentence per line.

14
00:01:00.540 --> 00:01:05.640
What to wake Supports three modes off operations.

15
00:01:05.640 --> 00:01:12.300
Continuous bag of words also on a see ball Skip gram on batch

16
00:01:12.300 --> 00:01:17.030
Skip ____ search maker recommends using single Petri Instance for

17
00:01:17.030 --> 00:01:24.740
skip gram on sable on multiple CPU instances for batch skip crab

18
00:01:24.740 --> 00:01:26.740
for text classification,

19
00:01:26.740 --> 00:01:30.130
search maker recommends using PSI Phi for training

20
00:01:30.130 --> 00:01:33.800
data less than to get and API to R P.

21
00:01:33.800 --> 00:01:37.540
Three instances for a larger dataset.

22
00:01:37.540 --> 00:01:42.770
What to wake Reports mean underscore arch OAuth on text

23
00:01:42.770 --> 00:01:46.730
classifications reports accuracy as the metric during the training

24
00:01:46.730 --> 00:01:51.940
process mode is the require hyper parameter,

25
00:01:51.940 --> 00:01:57.340
both forward to wake on takes classifications.

26
00:01:57.340 --> 00:02:01.200
Let's jump into a Jupyter notebook and see how to implement a

27
00:02:01.200 --> 00:02:06.640
blazing text using a text classifications algorithm.

28
00:02:06.640 --> 00:02:13.140
This demo uses w get to download the data from the data source.

29
00:02:13.140 --> 00:02:16.220
Since the class labels needs to be prefixed with

30
00:02:16.220 --> 00:02:20.680
underscore underscore label Underscore, Underscore said,

31
00:02:20.680 --> 00:02:23.030
an amount of pre processing is required,

32
00:02:23.030 --> 00:02:25.320
which is done in transform.

33
00:02:25.320 --> 00:02:26.940
Instance.

34
00:02:26.940 --> 00:02:33.440
On this applied to every single roll off the input data source.

35
00:02:33.440 --> 00:02:35.740
Once the pre process is done,

36
00:02:35.740 --> 00:02:41.240
the training on validation data are uploaded to S3 buckets.

37
00:02:41.240 --> 00:02:44.710
Docker image off blazing text is obtained from the

38
00:02:44.710 --> 00:02:49.900
container Registry for super was more blazing.

39
00:02:49.900 --> 00:02:54.890
Text supports single CPU instance and can see CSV Mater

40
00:02:54.890 --> 00:02:58.940
object is created with a single see, for instance,

41
00:02:58.940 --> 00:03:00.020
on file mode.

42
00:03:00.020 --> 00:03:06.410
For data, read operation under hyper parameters supervised.

43
00:03:06.410 --> 00:03:11.440
More dissect on the number of epochs is said to 10,

44
00:03:11.440 --> 00:03:17.560
and word Ingram's is set to to input channels are set

45
00:03:17.560 --> 00:03:20.350
with both training on validation.

46
00:03:20.350 --> 00:03:26.540
Data on the training process is started.

47
00:03:26.540 --> 00:03:29.240
Once the training is completed,

48
00:03:29.240 --> 00:03:34.140
the model can then be deployed and is ready for influencing

49
00:03:34.140 --> 00:03:39.140
blazing text except JSON type during inference face.

50
00:03:39.140 --> 00:03:46.540
And it expects the key to be instances before being passed to the endpoint.

51
00:03:46.540 --> 00:03:51.740
Next to algorithm that we're going to look is sequence to sequence.

52
00:03:51.740 --> 00:03:57.540
This is a record neural network that has three main layers.

53
00:03:57.540 --> 00:04:01.640
First one is embedding layer in this layer.

54
00:04:01.640 --> 00:04:07.840
The metrics off input tokens are mapped to a dense feature layer.

55
00:04:07.840 --> 00:04:11.220
This is because a high dimensional feature vector is more

56
00:04:11.220 --> 00:04:15.580
effective in encoding the information compared to a simple one

57
00:04:15.580 --> 00:04:20.040
________ and victor In n quarter layer,

58
00:04:20.040 --> 00:04:24.940
this high dimension input token is passed through an end quarter layer

59
00:04:24.940 --> 00:04:29.310
that compresses the information on produces a feature vector that is a

60
00:04:29.310 --> 00:04:33.680
fixed length usually are on the networks,

61
00:04:33.680 --> 00:04:34.670
like ___.

62
00:04:34.670 --> 00:04:40.440
Enum are gr do are present in this in quarter layer,

63
00:04:40.440 --> 00:04:44.260
the decoder layer takes the feature victor that was encoded

64
00:04:44.260 --> 00:04:49.140
and produces the sequence off output tokens.

65
00:04:49.140 --> 00:04:53.420
It is a supervised learning algorithm where the input is a sequence

66
00:04:53.420 --> 00:04:58.740
off tokens on output is another sequence of tokens.

67
00:04:58.740 --> 00:05:02.320
Machine translation speech to text are some of the

68
00:05:02.320 --> 00:05:05.040
classic example off this algorithm,

69
00:05:05.040 --> 00:05:09.920
and it uses both recommend neural Network and Convolution Neural Network

70
00:05:09.920 --> 00:05:16.840
models with attention as in color decoder architectures.

71
00:05:16.840 --> 00:05:20.470
This algorithm expects all the three channels during the training

72
00:05:20.470 --> 00:05:24.620
process on the supporter Input format is record.

73
00:05:24.620 --> 00:05:32.320
I will during influence, both recordable on JSON formats are supported.

74
00:05:32.320 --> 00:05:36.840
This algorithm can be trained on GPU instances only

75
00:05:36.840 --> 00:05:42.590
sequence to sequence reports accuracy blue on perplexity

76
00:05:42.590 --> 00:05:46.340
metrics during the training process.

77
00:05:46.340 --> 00:05:49.140
It does not have any require hyper parameter,

78
00:05:49.140 --> 00:05:52.410
but it does have a plenty off optional hyper parameters that

79
00:05:52.410 --> 00:05:56.040
can be set during the training process.

80
00:05:56.040 --> 00:05:59.200
Let's switch your attention to a Jupyter notebook on see

81
00:05:59.200 --> 00:06:03.040
how sequence to sequence is implemented.

82
00:06:03.040 --> 00:06:07.120
This demo uses the English to German translation dataset from

83
00:06:07.120 --> 00:06:11.840
the Conference on Machine Translation 2017.

84
00:06:11.840 --> 00:06:15.390
This DevOps uses a python code that transforms the

85
00:06:15.390 --> 00:06:19.340
input dataset to four output files,

86
00:06:19.340 --> 00:06:25.380
with the source on target sentences being converted to pro top of farm app on,

87
00:06:25.380 --> 00:06:29.440
then uploaded to S3 buckets.

88
00:06:29.440 --> 00:06:31.940
Under resource conflict,

89
00:06:31.940 --> 00:06:38.440
you can see that we're going to use API to instantiate for the training process.

90
00:06:38.440 --> 00:06:42.340
Maximum source on target sequence length is set to

91
00:06:42.340 --> 00:06:49.010
60 and optimized metric is blue.

92
00:06:49.010 --> 00:06:50.480
Under input conflict.

93
00:06:50.480 --> 00:06:54.740
Three separate channels are set up one for train.

94
00:06:54.740 --> 00:06:55.470
Another for what?

95
00:06:55.470 --> 00:06:57.140
Cap on another.

96
00:06:57.140 --> 00:07:02.420
For validation on the training job is created using create training

97
00:07:02.420 --> 00:07:07.960
job API one is the training process is completed,

98
00:07:07.960 --> 00:07:10.540
which may take some time.

99
00:07:10.540 --> 00:07:15.440
Endpoint configuration is created.

100
00:07:15.440 --> 00:07:20.140
You can see we're using em, for instance,

101
00:07:20.140 --> 00:07:25.240
and past this configuration in creating an endpoint.

102
00:07:25.240 --> 00:07:31.440
Once this endpoint has deployed, you are now ready for the inference process.

103
00:07:31.440 --> 00:07:37.140
Next, we will talk about object to back on, see how it works.

104
00:07:37.140 --> 00:07:39.080
It has three important steps.

105
00:07:39.080 --> 00:07:43.120
The first one is processed data in the step.

106
00:07:43.120 --> 00:07:47.580
The date I shuffle properly under it is converted to the JSON lines.

107
00:07:47.580 --> 00:07:50.340
Text file format.

108
00:07:50.340 --> 00:07:53.640
Next step is training the Marty.

109
00:07:53.640 --> 00:08:01.340
This algorithm takes two input channels two in quarters on the Comparator.

110
00:08:01.340 --> 00:08:05.540
Each input channel has its sworn in quarter path.

111
00:08:05.540 --> 00:08:08.140
Both of them feed into a competitive er.

112
00:08:08.140 --> 00:08:11.940
We generates the labeled output.

113
00:08:11.940 --> 00:08:14.740
Some of the possible choices for in quarters are

114
00:08:14.740 --> 00:08:19.590
bidirectional L s Team CNN's on average.

115
00:08:19.590 --> 00:08:22.340
Pull em beddings.

116
00:08:22.340 --> 00:08:24.000
You need to choose the right one.

117
00:08:24.000 --> 00:08:27.740
Based on the data that you're going to process,

118
00:08:27.740 --> 00:08:33.130
the Comparator itself is followed by a feed forward network on the

119
00:08:33.130 --> 00:08:36.640
label can be trained using means squired error,

120
00:08:36.640 --> 00:08:40.340
our cross entropy loss.

121
00:08:40.340 --> 00:08:44.840
The third step is producing influence.

122
00:08:44.840 --> 00:08:47.940
You can perform two types off inferences.

123
00:08:47.940 --> 00:08:54.040
First one is to convert Singleton input objects into a fixed length M beddings.

124
00:08:54.040 --> 00:08:59.940
Or you can predict the relationship label between a pair off input objects.

125
00:08:59.940 --> 00:09:04.040
This is an unsupervised learning algorithm.

126
00:09:04.040 --> 00:09:05.660
In blazing text algorithm,

127
00:09:05.660 --> 00:09:08.950
you saw word to back that was focused on finding the

128
00:09:08.950 --> 00:09:12.540
relationship between words in a sentence.

129
00:09:12.540 --> 00:09:16.350
But object to back is not just limited to words,

130
00:09:16.350 --> 00:09:20.940
but it can operate at a more generic object level.

131
00:09:20.940 --> 00:09:23.670
It usually operates in embedding layer,

132
00:09:23.670 --> 00:09:26.630
converting a high dimensional object to a lower,

133
00:09:26.630 --> 00:09:30.140
dimensional, dense and beddings.

134
00:09:30.140 --> 00:09:32.900
This algorithm is primarily used in Johndroe.

135
00:09:32.900 --> 00:09:34.140
Prediction.

136
00:09:34.140 --> 00:09:35.860
Our recommendation system,

137
00:09:35.860 --> 00:09:42.140
similar to what Netflix does based on your previous viewing history,

138
00:09:42.140 --> 00:09:45.540
object to back trains data uniquely.

139
00:09:45.540 --> 00:09:51.040
It uses spares off tokens like sentence sentence pairs label sequence.

140
00:09:51.040 --> 00:09:54.640
Pairs are customer customer pairs.

141
00:09:54.640 --> 00:09:58.470
All this input data needs to be preproduction est on object

142
00:09:58.470 --> 00:10:02.140
to wake supports two types off input.

143
00:10:02.140 --> 00:10:04.340
First one is a discreet token.

144
00:10:04.340 --> 00:10:09.440
On the second one is a sequence of discrete tokens.

145
00:10:09.440 --> 00:10:14.840
Sage maker recommends using em Fight If you're using a CPU and API,

146
00:10:14.840 --> 00:10:19.640
too, if you're using GPU during the training face,

147
00:10:19.640 --> 00:10:22.970
and it recommends using P three during inference.

148
00:10:22.970 --> 00:10:25.140
Face.

149
00:10:25.140 --> 00:10:30.270
This algorithm reports root mean square error for regression tasks on

150
00:10:30.270 --> 00:10:34.540
accuracy and cross entropy for classification tasks.

151
00:10:34.540 --> 00:10:36.550
Maximum sequence land for the N.

152
00:10:36.550 --> 00:10:36.750
C.

153
00:10:36.750 --> 00:10:41.130
Zero in quarter on the vocabulary size off VPNs zero

154
00:10:41.130 --> 00:10:44.840
tokens are required Hyper parameters.

155
00:10:44.840 --> 00:10:48.990
There's jumping to a quick demo and see how object to can be implemented in

156
00:10:48.990 --> 00:10:56.120
Sage Maker On this demo uses movieland 100 k dataset.

157
00:10:56.120 --> 00:11:00.040
This demo uses use error IDE on movie I repair.

158
00:11:00.040 --> 00:11:01.840
And for each such bear,

159
00:11:01.840 --> 00:11:05.210
a label is provided that tells the Al Garden if the

160
00:11:05.210 --> 00:11:09.140
user on movie are similar or not,

161
00:11:09.140 --> 00:11:14.860
the data is downloaded using Curl Command and is requires

162
00:11:14.860 --> 00:11:19.440
considerable amount off pre processing on data exploration.

163
00:11:19.440 --> 00:11:22.890
And I suggest you look at this specific notebook if you

164
00:11:22.890 --> 00:11:25.940
are interested in knowing these details,

165
00:11:25.940 --> 00:11:31.540
pre process data is then uploaded to S3 buckets.

166
00:11:31.540 --> 00:11:35.480
Get image you are A method is used to fetch the Docker

167
00:11:35.480 --> 00:11:39.740
image from the container registry.

168
00:11:39.740 --> 00:11:42.450
Under hyper parameters were sitting pulled,

169
00:11:42.450 --> 00:11:49.380
embedding network with maximum sequence length said to one on vocabulary

170
00:11:49.380 --> 00:11:57.740
size to 9 44 Anton Ege is used for activation function.

171
00:11:57.740 --> 00:12:04.360
Then the estimator object is created and these hyper parameters are set on.

172
00:12:04.360 --> 00:12:07.840
The training process is started.

173
00:12:07.840 --> 00:12:13.740
Once the training process completes, this model can then be deployed.

174
00:12:13.740 --> 00:12:22.000
You can see it is being deployed on em, for instance and it is now ready for prediction.

