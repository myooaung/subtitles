WEBVTT
0
1
00:00:04.260 --> 00:00:09.450
Hey guys, welcome back to the course. So, in this lecture, we're going to talk about how do we take our assumption
1

2
00:00:09.450 --> 00:00:16.740
list and identify which of them are the really risky ones
and which ones are not as risky.
2

3
00:00:16.740 --> 00:00:23.220
Now, the reason why we do this is because it's a function of
being lean and it's a function of running an MVP experiment.
3

4
00:00:23.220 --> 00:00:25.050
Now, the reason why we do this is because it's a function of
being lean and it's a function of running an MVP experiment.
4

5
00:00:25.050 --> 00:00:30.690
Now, remember, it's all about mitigating risk and saving resources.
5

6
00:00:30.690 --> 00:00:37.860
So, if we have a lot of factors that have to be true in order
for our product or feature to be successful,
6

7
00:00:38.160 --> 00:00:45.450
it makes sense to focus first on the ones that could
potentially sink the ship and make the entire thing
7

8
00:00:45.790 --> 00:00:53.410
unviable, versus some of the less risky things
that are not really a big deal.
8

9
00:00:53.460 --> 00:00:58.950
You don't want to get into a situation where you spent
a lot of time validating assumptions that were
9

10
00:00:58.950 --> 00:01:06.450
very, very small and unrisky, only to come up to, let's say,
your sixth experiment, where you test a risky one, and you fail
10

11
00:01:06.450 --> 00:01:10.020
miserably and you completely scrap the project.
11

12
00:01:10.020 --> 00:01:11.540
That's going to happen all the time, but you wasted
so many resources that you didn't have to waste
12

13
00:01:11.550 --> 00:01:15.470
That's going to happen all the time, but you wasted
so many resources that you didn't have to waste
13

14
00:01:15.540 --> 00:01:20.940
had you just started the opposite direction with the riskiest one first.
In this section, we're going
14

15
00:01:20.940 --> 00:01:27.690
to come up with an MVP experiment structure that's going to
target as many of the riskiest ones as we can,
15

16
00:01:27.690 --> 00:01:28.080
to come up with an MVP experiment structure that's going to
target as many of the riskiest ones as we can,
16

17
00:01:28.080 --> 00:01:30.470
but we first have got to figure out which ones are risky.
17

18
00:01:30.470 --> 00:01:34.400
So, let's look at the template of examples that we used before.
18

19
00:01:34.410 --> 00:01:41.520
Number one was the assumption that our customer has X, Y, Z problem, number two is that we assume our customer
19

20
00:01:41.520 --> 00:01:44.460
cares about whatever we think they care about,
20

21
00:01:44.460 --> 00:01:50.370
number three, we're assuming that the solution we're
about to create is valuable enough to the user or
21

22
00:01:50.370 --> 00:01:57.240
potential user for them to either pay you or give you
their email address, or some form of information.
22

23
00:01:57.260 --> 00:01:57.400
potential user for them to either pay you or give you
their email address, or some form of information.
23

24
00:01:57.480 --> 00:02:03.480
And the last one on the template was that we assume
that there are no satisfactory substitutes, meaning
24

25
00:02:03.480 --> 00:02:08.050
that there's no other way of doing this that people find to be okay.
25

26
00:02:08.160 --> 00:02:10.460
So now, just out of these examples,
26

27
00:02:10.470 --> 00:02:17.700
let's say you just had a theoretical product idea. Which
of these four do you think is probably the biggest
27

28
00:02:17.760 --> 00:02:22.310
deal, as in if one of these things turned out
to be false, we assume this and it's not true,
28

29
00:02:22.320 --> 00:02:26.640
deal, as in if one of these things turned out
to be false, we assume this and it's not true,
29

30
00:02:26.640 --> 00:02:33.630
which of them is probably going to be the biggest deal,
which one could potentially just blow up and
30

31
00:02:33.630 --> 00:02:35.390
make all the other ones not matter?
31

32
00:02:35.490 --> 00:02:40.490
So let's just start from the bottom - no satisfactory substitutions.
32

33
00:02:40.500 --> 00:02:47.690
Well, there are plenty of products and plenty of services
out there that competed with satisfactory substitutions,
33

34
00:02:47.700 --> 00:02:51.990
people didn't even realize they had a problem with it until someone popped up and said, "Hey, here's a better way of doing it."
34

35
00:02:51.990 --> 00:02:54.030
people didn't even realize they had a problem with it until someone popped up and said, "Hey, here's a better way of doing it."
35

36
00:02:54.060 --> 00:02:56.670
People were pretty satisfied with their feature phones.
36

37
00:02:56.670 --> 00:03:02.190
I mean, they had a lot of issues, but for the most part
if you asked someone who had a feature phone, you
37

38
00:03:02.190 --> 00:03:06.740
know, before 2006, they'd probably say,
"Yeah, I'm pretty satisfied with it."
38

39
00:03:06.750 --> 00:03:09.860
And that was before they came out with the iPhone.
39

40
00:03:10.020 --> 00:03:15.900
So people can typically get dislodged from substitutions
if you show them there's a better way on some dimension.
40

41
00:03:15.900 --> 00:03:16.580
So people can typically get dislodged from substitutions
if you show them there's a better way on some dimension.
41

42
00:03:16.650 --> 00:03:19.790
Number three - they will pay for it or sign up for it.
42

43
00:03:19.830 --> 00:03:21.950
Well, that's a problem if they won't, because it's an issue for your business model, but is it absolutely a game changer, something
43

44
00:03:21.960 --> 00:03:29.190
Well, that's a problem if they won't, because it's an issue for your business model, but is it absolutely a game changer, something
44

45
00:03:29.190 --> 00:03:32.710
that, you know, just drops the curtain and you can't possibly go forward?
45

46
00:03:32.790 --> 00:03:38.290
Well, no, not really, because there's plenty of other ways
of monetizing or growing a successful product
46

47
00:03:38.370 --> 00:03:38.500
Well, no, not really, because there's plenty of other ways
of monetizing or growing a successful product
47

48
00:03:38.590 --> 00:03:44.980
that don't rely on the customer paying you directly.
For instance, you can work with ads.
48

49
00:03:45.030 --> 00:03:49.420
Ads don't require any sign up and they
don't require anyone paying you any money.
49

50
00:03:49.440 --> 00:03:52.710
It might not be ideal, but it's still a viable avenue.
50

51
00:03:52.800 --> 00:03:55.430
Number two - [...] matters to my customers.
51

52
00:03:55.430 --> 00:03:59.840
You know, if you're trying to build something, let's say,
that is super fast, and you find out that people
52

53
00:03:59.910 --> 00:04:02.280
don't really care how fast it is,
53

54
00:04:02.280 --> 00:04:09.290
let's say we were, you know, Domino's Pizza, and we came out
with the 30 minutes or less delivery strategy
54

55
00:04:09.300 --> 00:04:11.160
and we found out that no one cares,
55

56
00:04:11.160 --> 00:04:15.180
it doesn't matter if they get it in 30 minutes,
or two hours, or three hours,
56

57
00:04:15.180 --> 00:04:16.640
now, would it be a game-ender?
57

58
00:04:16.680 --> 00:04:20.970
Well, no, but it would be a pretty significant setback.
58

59
00:04:20.970 --> 00:04:26.310
The thing is that we have a thing called marketing
and the job of marketing is to convince people that
59

60
00:04:26.310 --> 00:04:29.370
they care about things they didn't previously care about.
60

61
00:04:29.370 --> 00:04:35.760
So it's very plausible that Domino's could just run an ad
convincing people that you want pizza and that
61

62
00:04:35.760 --> 00:04:37.720
pizza is better if you eat it sooner.
62

63
00:04:37.740 --> 00:04:44.280
Before I bought a 1080p HD TV, if you would have asked me,
"Do you care about the resolution of your TV?" I'd say,
63

64
00:04:44.820 --> 00:04:46.050
"What are you talking about? What is resolution?"
64

65
00:04:46.050 --> 00:04:47.400
"What are you talking about? What is resolution?"
65

66
00:04:47.400 --> 00:04:50.740
But after I bought one and I saw what they could do,
66

67
00:04:50.830 --> 00:04:54.640
yeah, all of a sudden I started caring, because that was really crisp.
67

68
00:04:54.660 --> 00:04:55.950
This was actually shot in 1080p, not 4K, and you can
thank us for that, because if it was shot in 4K,
68

69
00:04:55.980 --> 00:04:56.920
This was actually shot in 1080p, not 4K, and you can
thank us for that, because if it was shot in 4K,
69

70
00:04:56.940 --> 00:04:59.870
This was actually shot in 1080p, not 4K, and you can
thank us for that, because if it was shot in 4K,
70

71
00:05:00.030 --> 00:05:01.200
you wouldn't be paying attention, you'd be
lost in every contour and bump on my face.
71

72
00:05:01.200 --> 00:05:05.840
you wouldn't be paying attention, you'd be
lost in every contour and bump on my face.
72

73
00:05:05.880 --> 00:05:08.750
The last one is "My customer has X, Y, Z problem."
73

74
00:05:08.760 --> 00:05:15.630
That actually is a big, big deal. If we're trying to build something
that solves a problem, and that problem doesn't exist,
74

75
00:05:15.630 --> 00:05:16.520
That actually is a big, big deal. If we're trying to build something
that solves a problem, and that problem doesn't exist,
75

76
00:05:16.530 --> 00:05:21.380
we are building a solution in search of a problem,
and that never goes well.
76

77
00:05:21.420 --> 00:05:28.020
So I would actually say the lack of a problem in this scenario
is by far the riskiest, and, as a product
77

78
00:05:28.020 --> 00:05:35.190
manager, what I would do then is try to design my MVP experiment to target that one. After I proved that one to be true,
78

79
00:05:35.220 --> 00:05:36.290
manager, what I would do then is try to design my MVP experiment to target that one. After I proved that one to be true,
79

80
00:05:36.300 --> 00:05:41.700
I would then move on to the next riskiest, which is
probably number two, and then the next one, which is
80

81
00:05:41.820 --> 00:05:45.450
probably number four, and then the next one, which is
probably number three. In the next lecture, we're going
81

82
00:05:45.450 --> 00:05:48.180
to find the riskiest assumption of our example, Zirx.
You guys can skip this one if you want.
82

83
00:05:48.220 --> 00:05:50.700
to find the riskiest assumption of our example, Zirx.
You guys can skip this one if you want.
83

84
00:05:50.700 --> 00:05:54.540
Totally not mandatory, but if you do care, watch it,
84

85
00:05:54.540 --> 00:05:56.900
otherwise I'll see you in the next, next lecture.
