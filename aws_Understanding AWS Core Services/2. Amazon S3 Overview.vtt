WEBVTT
1
00:00:01.040 --> 00:00:03.980
So next, we're going to be talking about Amazon S3,

2
00:00:03.980 --> 00:00:07.280
and Amazon S3 is a core AWS service.

3
00:00:07.280 --> 00:00:09.850
It is the first service that I ever leveraged on AWS,

4
00:00:09.850 --> 00:00:12.740
and chances are if you've leveraged the platform at all,

5
00:00:12.740 --> 00:00:15.840
you have used Amazon S3 at some point.

6
00:00:15.840 --> 00:00:21.580
Now, Amazon S3 at a high level lets you store files as objects inside of buckets.

7
00:00:21.580 --> 00:00:24.500
Now buckets are the unit of organization within S3.

8
00:00:24.500 --> 00:00:27.140
You will create a bucket, it will have a set of settings,

9
00:00:27.140 --> 00:00:31.240
and then any file that you drop in can have those settings applied to it.

10
00:00:31.240 --> 00:00:35.330
Now it provides different storage classes for different use cases,

11
00:00:35.330 --> 00:00:38.540
and we'll dive through those storage classes in just a bit.

12
00:00:38.540 --> 00:00:42.990
It allows you to store data automatically across multiple availability zones,

13
00:00:42.990 --> 00:00:46.520
which gives you durability and resiliency for your data.

14
00:00:46.520 --> 00:00:49.360
Now another great feature of S3 is that it enables you

15
00:00:49.360 --> 00:00:52.540
to have URL access for your files.

16
00:00:52.540 --> 00:00:54.960
So if you want to be able to send a link to someone

17
00:00:54.960 --> 00:00:58.720
else to access a file within S3, assuming the permissions are correct,

18
00:00:58.720 --> 00:01:00.270
you can actually do that.

19
00:01:00.270 --> 00:01:04.330
And it also offers configurable rules for data lifecycle,

20
00:01:04.330 --> 00:01:07.390
so if you want something to expire after a period of time

21
00:01:07.390 --> 00:01:09.310
or go to a different storage class.

22
00:01:09.310 --> 00:01:12.280
Now, it also can serve as a static web host,

23
00:01:12.280 --> 00:01:16.040
and we'll actually be implementing that later within this module.

24
00:01:16.040 --> 00:01:20.520
So next, let's talk about the non‑archival storage classes for S3.

25
00:01:20.520 --> 00:01:21.650
Now as a note here,

26
00:01:21.650 --> 00:01:25.840
we will cover the archival storage classes later within this module.

27
00:01:25.840 --> 00:01:29.210
So first of all, we have S3 Standard, and by default,

28
00:01:29.210 --> 00:01:34.140
if you upload a file to S3, it will have the S3 Standard storage class.

29
00:01:34.140 --> 00:01:36.560
Then, we also have S3 Intelligent‑Tiering,

30
00:01:36.560 --> 00:01:40.930
and this is a special storage class that will allow you to move your

31
00:01:40.930 --> 00:01:44.100
data to a correct storage class based on usage.

32
00:01:44.100 --> 00:01:47.290
And we'll talk more about Intelligent‑Tiering in just a minute.

33
00:01:47.290 --> 00:01:51.110
Then, we have S3 Standard‑Infrequent Access.

34
00:01:51.110 --> 00:01:54.070
So, if you have data that is not frequently accessed,

35
00:01:54.070 --> 00:01:58.520
you can get a lower cost by utilizing this particular storage class.

36
00:01:58.520 --> 00:02:01.440
Now it still has the standard resiliency because it

37
00:02:01.440 --> 00:02:03.600
leverages multiple availability zones,

38
00:02:03.600 --> 00:02:07.930
but we also have S3 One Zone‑Infrequent Access,

39
00:02:07.930 --> 00:02:10.410
and this is for data that is not frequently accessed,

40
00:02:10.410 --> 00:02:13.510
but it is only stored within one availability zone.

41
00:02:13.510 --> 00:02:17.440
So you get a much lower cost point than you do with the other options; however,

42
00:02:17.440 --> 00:02:19.440
you do have less resiliency.

43
00:02:19.440 --> 00:02:22.270
So let's talk about Intelligent‑Tiering.

44
00:02:22.270 --> 00:02:25.600
Now, Intelligent‑Tiering is the only way that you can automatically move

45
00:02:25.600 --> 00:02:29.280
data between different storage classes based on access.

46
00:02:29.280 --> 00:02:31.230
And within this overall storage class,

47
00:02:31.230 --> 00:02:33.800
it has two different classes associated with it.

48
00:02:33.800 --> 00:02:36.730
The first is frequent and the second is infrequent,

49
00:02:36.730 --> 00:02:40.380
so it will move your data back and forth between those two different classes.

50
00:02:40.380 --> 00:02:44.480
It gives you pretty much the same performance as what you get with S3 Standard,

51
00:02:44.480 --> 00:02:47.920
but it can provide a cost savings if you have some data that needs to

52
00:02:47.920 --> 00:02:50.540
be moved between those different storage classes.

53
00:02:50.540 --> 00:02:54.640
Now next, let's talk about the S3 lifecycle policies.

54
00:02:54.640 --> 00:02:57.910
Now this is an approach that allows you to transition, based on

55
00:02:57.910 --> 00:03:01.780
your own custom criteria, the objects in your bucket. Now

56
00:03:01.780 --> 00:03:04.330
transitions in this case can enable objects to move to another

57
00:03:04.330 --> 00:03:07.170
storage class based on time.

58
00:03:07.170 --> 00:03:10.340
Now it's important to note here, you can't move something back and

59
00:03:10.340 --> 00:03:13.190
forth based on usage, that's only available with

60
00:03:13.190 --> 00:03:17.360
Intelligent‑Tiering, but you can do it based on time. And you also

61
00:03:17.360 --> 00:03:21.130
can delete objects with expiration based on age.

62
00:03:21.130 --> 00:03:23.900
So if you want a certain file to only last for 30 days,

63
00:03:23.900 --> 00:03:28.220
for example, you could configure that also using lifecycle policies.

64
00:03:28.220 --> 00:03:30.530
Now policies can also factor in the concept of

65
00:03:30.530 --> 00:03:33.240
versions for an object within the bucket.

66
00:03:33.240 --> 00:03:37.090
So S3 does support versioning of data, and you could say something like,

67
00:03:37.090 --> 00:03:37.620
for example,

68
00:03:37.620 --> 00:03:42.480
delete a version of a file that's not the current version after seven days.

69
00:03:42.480 --> 00:03:44.780
So those are different things that you can configure

70
00:03:44.780 --> 00:03:47.710
utilizing S3 lifecycle policies.

71
00:03:47.710 --> 00:03:50.380
Now one additional concept here for S3, and that is the

72
00:03:50.380 --> 00:03:53.840
concept of S3 Transfer Acceleration.

73
00:03:53.840 --> 00:03:56.530
So this is a feature that enables you to upload

74
00:03:56.530 --> 00:03:58.830
data into your bucket much faster,

75
00:03:58.830 --> 00:04:02.430
and it does it by utilizing the AWS edge locations

76
00:04:02.430 --> 00:04:04.400
as a part of Amazon CloudFront.

77
00:04:04.400 --> 00:04:07.130
So if you need to upload your data in a fast and

78
00:04:07.130 --> 00:04:14.000
efficient way into your S3 buckets, you can consider utilizing S3 Transfer Acceleration.

