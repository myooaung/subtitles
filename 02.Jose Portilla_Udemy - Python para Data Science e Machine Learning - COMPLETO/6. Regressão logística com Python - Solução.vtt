WEBVTT

00:09.370 --> 00:15.850
Eu sou bom de bola de soluções do projeto de regressão logística completou.

00:15.950 --> 00:20.720
Como expliquei na última aula esse projeto a gente está tentando criar um modelo que vai basicamente

00:20.720 --> 00:23.810
predizer se as pessoas clicaram ou não em um almoço.

00:24.030 --> 00:31.370
Isso é o site algumas informações da visita da pessoa do site como o portal que os dados vamos começar

00:31.400 --> 00:32.250
a trabalhar com isso.

00:32.620 --> 00:39.440
Então vou copiar aqui o pessoal de um artigo os nossos impostos padrões da banda do pai do povo líbio

00:39.440 --> 00:45.160
Cyborg e definir o médico aquele que vai rodar essa linha de código.

00:45.580 --> 00:55.750
Vamos começar aqui lendo o arquivo pais em ponto CSV gravar uma chamada data a data.

00:56.420 --> 01:00.240
OP Outro ainda CSV.

01:00.810 --> 01:05.180
Eu vou ler o arquivo que pode.

01:07.890 --> 01:13.160
Como você se vê eu estava dando tempo para esse pessoal mas não estava importando porque a biblioteca

01:13.160 --> 01:14.840
não tinha sido importada ainda.

01:15.050 --> 01:21.140
Então para conseguir fazer a leitura das funções é algo complicado completo Júpiter sabe que tem que

01:21.140 --> 01:29.260
ter importado as duas bibliotecas ou daqui por tabela ou verificar o cabeçalho desse meu filme.

01:31.160 --> 01:36.250
Pelo formato que havia visto anteriormente houve também que o wi fi e o desktop.

01:36.440 --> 01:39.660
Isso aqui é o meu livro.

01:40.530 --> 01:44.310
Aliás neutros como o e o meu com isso.

01:44.370 --> 01:46.820
Isso aqui meu Deus claro.

01:48.740 --> 01:49.520
Lembrando o iPhone.

01:49.530 --> 01:55.190
Basicamente ele mostra pra gente quantidades como nazi produzidas com músico com o nome de cada uma

01:55.190 --> 01:56.080
delas.

01:56.360 --> 02:00.450
E informações sobre o consumo de memórias os chips encontrados na série.

02:01.250 --> 02:06.920
Enquanto que o descalabro é basicamente cálculo algumas informações de variáveis numéricas tais que

02:06.950 --> 02:13.370
você deve ter visto aqui algumas informações por exemplo é dito que não tenho informações aqui pois

02:13.370 --> 02:16.950
é impossível calcular média desvio padrão mínimo.

02:17.130 --> 02:23.680
Aqui eu pensei que fiz no máximo 100 metros para dar uma primeira visualizar os dados.

02:23.720 --> 02:27.150
Vou começar agora com a parte que a gente quer sempre a parte.

02:27.230 --> 02:32.180
Assim na prática o ser a parte mais importante que é a parte de explorar os dados e entender as coisas

02:32.180 --> 02:33.190
dele.

02:33.410 --> 02:36.840
Começar aqui criando coisas ou queremos algumas visualizações.

02:36.850 --> 02:42.920
Primeiro a primeira coisa que nos é solicitada é criar um histograma da idade que a gente tem que poupar

02:42.920 --> 02:43.280
os dados.

02:43.280 --> 02:51.800
Dessa forma vamos começar colocando Big Data copiar e colocar o Egito deve ter visto que a gente tem

02:51.800 --> 02:58.550
uma coisa chamada idade da pessoa que estava visitando aquele site como estão dispostas sobre essas

02:58.550 --> 02:59.290
pessoas.

03:00.500 --> 03:06.070
Colocar aqui histograma é mais que isso.

03:06.470 --> 03:11.280
Como colocar um pouco mais de bits que a eles têm poucos conseguem muito bem como é que essa distribuição

03:11.360 --> 03:16.340
colocar 50 toca 30 watts.

03:16.340 --> 03:23.780
Basicamente está focado com pessoas que entram entre a faixa dos 25 aos 45 anos onde está a grande maioria

03:23.780 --> 03:25.740
das pessoas.

03:25.910 --> 03:30.990
Isso vai colocar também como a gente tinha anteriormente só pra gente exercitar o método é que se lembra

03:32.730 --> 03:38.580
só pra gente também está conseguindo visualizar aqui sua informação aqui embaixo nos perfis de organização

03:38.620 --> 03:43.010
a próxima solicitação que nos é feita é criar um relatório mostrando

03:46.600 --> 03:53.860
isso a gente tem duas colunas aqui a gente tem o elenco e o IBGE para quem não lembra o elenco qualquer

03:53.940 --> 03:59.770
especificação os frames podem ter acesso a Maxima e médio da renda do consumidor da região.

04:00.930 --> 04:11.180
Abaixo duas informações que o SNS de Pelotas possui uma distribuição conjunta apenas de duas variáveis.

04:11.180 --> 04:15.130
Se a gente quiser fazer e desfazer de toda essa gente estaria utilizando o método.

04:15.750 --> 04:25.570
Boto meu X aqui idade não é meu iPod seu rs.

04:26.760 --> 04:33.980
Eu vou extrair esses cálculos aqui do data da rodada.

04:34.710 --> 04:40.340
Tá lá a principio a gente tem uma distribuição tem um modelo muito linear muito forte aqui.

04:41.140 --> 04:48.320
A gente tem mais pontos aqui porque a partir do gráfico obviamente que a gente tem mais pessoas pra

04:48.320 --> 04:54.790
cá as pessoas com essa distribuição aqui mas eu percebi que tem uma distribuição aqui.

04:55.160 --> 05:05.260
Só quando os soldados dos EUA ainda não estão linearmente dependente da idade quando estou aqui António

05:05.400 --> 05:07.070
boto que mostra as só.

05:07.090 --> 05:09.580
Cadê o coronel deste mês.

05:10.330 --> 05:14.730
Ele está me esperando brechas ou seja vou ver só pra gente lembrar dele.

05:14.870 --> 05:18.830
Dispenso basicamente o tempo de sete minutos.

05:19.040 --> 05:25.920
Então como é que estão distribuídos o tempo que a pessoa gasta no site em função da idade dela mesma

05:25.930 --> 05:28.660
forma como já havia feito anteriormente aqui vou copiar.

05:28.860 --> 05:35.420
Se você toca aqui o olha aqui embaixo é a desculpa.

05:36.390 --> 05:42.370
O coelho aqui e agora está substituindo a gente quer quero ir no eixo X se a gente quer aqui ele está

05:42.370 --> 05:43.460
suspenso.

05:46.260 --> 05:55.780
Esse cara que eu tava até o data só que eu posso modificar ou de ficar sozinha sou eu que sai do formato

05:55.780 --> 06:02.140
de cadeia é para manter a mesma cor eu vou utilizar o coito.

06:03.150 --> 06:03.540
Agora

06:07.150 --> 06:18.110
que eu sabia era que o pessoal acredito que este é exatamente o S maiúsculo.

06:18.270 --> 06:18.700
Aqui está o

06:23.530 --> 06:27.220
copiar as informações que ele fez pelo site

06:30.880 --> 06:31.630
agora.

06:32.980 --> 06:38.760
Embora o segundo cocô nesse nosso caderno taí o Top Blog exatamente igual ao que a gente tinha visto

06:38.760 --> 06:39.170
anteriormente.

06:39.180 --> 06:41.230
Estou com vocês podem estar vendo.

06:41.220 --> 06:47.820
A gente tem uma certa distribuição e essa quantidade de tempo que gastam o site as pessoas de idade

06:47.820 --> 06:50.020
mais os que ficam mais concentrados aqui.

06:50.630 --> 06:55.180
A próxima formação a pedido que a gente criou já pode dele.

06:55.180 --> 06:57.150
Ele está esperando pela internet.

06:57.280 --> 07:05.950
Usei essa informação aqui como a média de minutos porque o consumidor está na internet.

07:05.970 --> 07:10.050
Isso tem alguma correlação entre o tempo que a pessoa gasta nesse site específico o tempo que ela fica

07:10.050 --> 07:11.990
na internet.

07:12.180 --> 07:25.090
Da mesma forma que utilizou copiar esse blog que está visto e agora isso aqui é o meu X o meu y se chama

07:25.620 --> 07:25.950
ele

07:30.010 --> 07:31.740
sei lá.

07:32.220 --> 07:38.740
Eu não tenho mais um caderno Bôscoli esse cara daqui é para manter igual aqui como teu guri

07:43.440 --> 07:53.610
logo que eu li aqui faltou outra coisa faltou uma vírgula para o nosso caderno.

07:54.460 --> 07:57.410
Então existem basicamente duas concentrações aqui.

07:57.460 --> 08:01.280
Pessoas mais velhas em geral que só vai usar mais tempo.

08:01.280 --> 08:08.810
Pessoas que na verdade usam mais tempo e com mais tempo nesses sites também costumam ficar mais tempo

08:08.810 --> 08:11.100
em qualquer outro site.

08:11.150 --> 08:18.440
Pessoas que costumam ficar menos tempo e com muito menos tempo no site também têm uma certa dois clusters

08:18.440 --> 08:19.400
aqui.

08:20.540 --> 08:29.270
Para finalizar crie um pacote com X sem definição de corpo definido do recurso que você quer ver se

08:29.270 --> 08:32.730
a gente pode de alguma forma extrair alguma informação.

08:32.860 --> 08:40.560
Todo ano todos os nossos gráficos se agregando sul do Rio a coleção dele pelo que a gente quer realmente

08:40.610 --> 08:44.630
classificada é que essa pessoa clicou ou não o anúncio do site.

08:44.640 --> 08:48.540
O modo como a gente faz isso utilizando o Metro do Porto.

08:49.130 --> 09:00.560
O pessoal meio que adota o Rio quero fazer uma separação que eu posso fazer isso porque o carioca ele

09:00.680 --> 09:04.370
é categórico o rio segue variáveis categóricas.

09:04.730 --> 09:11.050
Ele vai quebrar duas cores diferentes e colocar essa mesma paleta de cor aqui mas não se atentem a isso.

09:11.070 --> 09:21.980
A pessoa que não é tão relevante então tocar Let's Go e rodar isso aqui ele devolve o figurino para

09:22.010 --> 09:22.900
cá para todo

09:26.390 --> 09:33.400
e pra cima do peito então que isso aqui nos visitar deve estar percebendo que essas variáveis que estão

09:33.400 --> 09:40.690
aqui para elas de certa forma elas têm um certo poder explicativo sobre as pessoas que clicam no site.

09:40.810 --> 09:45.770
Você deve ter percebido que a gente consegue de certa forma até uma certa separação entre dados.

09:46.520 --> 09:54.130
Se as variáveis não tivessem poder explicativo tão bom que a gente veria seria todos os pontos vermelhos

09:54.130 --> 09:59.360
e azuis aqui misturados àquela aquela variável por si só não teria um poder explicativo tão bom para

09:59.380 --> 10:01.700
poder separar os dados dessa forma.

10:02.090 --> 10:07.330
Então isso é importante para conseguir criar um modelo de regressão logística de classificação.

10:07.450 --> 10:09.760
Consegui ver que os nossos dados.

10:09.970 --> 10:17.050
A gente utiliza um parâmetro como o Rio aqui existe um certo poder de segregação e vou dar um exemplo

10:17.050 --> 10:22.490
aqui pessoal imaginem que todas essas colunas aqui a gente tivesse os pontos muito bem mesclados muito

10:22.570 --> 10:28.770
bem misturados e não a princípio não fosse possível fazer um tipo de segregação só que a gente vê que

10:28.870 --> 10:31.980
uma das variáveis por si só ela mantém o mesmo padrão.

10:32.050 --> 10:38.000
Porque o dele tendo ele ser da mesma forma como ele está aqui ele consegue a segregação das variáveis

10:38.900 --> 10:41.030
enquanto que as demais variáveis todas mescladas.

10:41.050 --> 10:45.590
A gente poderia fazer um modelo de regressão logística usando apenas a variável que houve essa separação.

10:46.890 --> 10:53.120
Eu só lembro esses dados aqui eles são eles são forjados a prática de separar se bolso.

10:53.130 --> 10:54.080
Tão simples assim.

10:54.200 --> 10:57.850
Que tratam mais pensar um pouco mais o modelo de vocês.

10:57.850 --> 11:00.950
Mas nesse caso aqui essas variáveis por si só já são suficientes.

11:00.960 --> 11:09.500
Modelo ou pessoal para só questão pede que a gente cria um gráfico de distribuição conjunta de todo

11:09.560 --> 11:12.130
tipo de país pelo site.

11:12.220 --> 11:17.270
A cultura dele que usei seja o que a pessoa fica nesse site específico.

11:17.360 --> 11:23.540
Outra tempo que a pessoa fica na internet que no geral está copiando aqui esse jogo bota aqui de cima.

11:23.730 --> 11:30.970
Eu vou colocar algumas coisas aqui porque só eu vou colocar o nosso X aqui e o tempo médio gasto diariamente

11:31.040 --> 11:33.580
não mais da idade ou do que meu Y.

11:34.060 --> 11:35.810
Ele é o dele Mac OS X.

11:35.950 --> 11:41.180
Substitua por esse valor ao meu data.

11:41.300 --> 11:50.150
Aqui ele é basicamente igual e o nosso Caio não é mais um caderno ele é simplesmente um gráfico de dispersão

11:50.150 --> 11:50.620
normal.

11:51.370 --> 11:58.940
Eu vou colocar aqui cor verde para o rodapé que a gente pode ver que a gente tem uma concentração relativamente

11:58.940 --> 12:05.060
grande em pessoas que passam mais tempo na internet do geral também só as pessoas que ficam mais tempo

12:05.060 --> 12:09.790
nesse site e o contrário também é válido.

12:10.070 --> 12:15.590
Isso é a última questão que eu acredito que seja mais relevante que é a primeira questão que a gente

12:15.590 --> 12:18.070
efetivamente está vendo.

12:19.170 --> 12:25.120
Nossa característica e predizer o período que a gente que o PT pode ou a definição de cura que o matiz

12:26.090 --> 12:29.380
sendo definido pelo recurso da coluna clicando ao lado.

12:29.390 --> 12:33.600
Ou seja vamos fazer uma separação de cores da mesma forma como a gente está vendo aqui.

12:33.630 --> 12:37.680
Se a pessoa clicou ou o molusco então para isso vou estar utilizando métodos.

12:38.300 --> 12:50.270
Vou passar aquela data está Meu Rio eu vou passar essa coluna clicando ao lado de maiúsculo o olho azul

12:50.270 --> 12:53.240
a maiúsculo e vou colocar essa paleta de cores aqui.

12:53.240 --> 13:02.530
Pessoal não se preocupe com isso não é tão importante quanto mostrá mostrar do mesmo jeito que

13:06.140 --> 13:12.740
ele demora um pouquinho e ressaltou que o que isso aqui significa vocês estão vendo a gente tem de certa

13:12.740 --> 13:20.300
forma uma segregação entre os parâmetros que a gente está botando aqui no nosso blog só palavra de interesse

13:20.300 --> 13:22.040
que essa pessoa clicou do molusco.

13:22.520 --> 13:29.000
Ou seja a princípio esses parâmetros comuns como um todo eles podem ir são relevantes para a gente conseguir

13:29.000 --> 13:34.730
definir se a pessoa que colocou esse anúncio a gente pode criar um modelo de segregação sugeriu regressão

13:34.730 --> 13:39.770
logística ou outro modelo de classificação que consiga utilizar esses caras para produzir alguma coisa.

13:40.410 --> 13:47.720
Um caso diferente seria por exemplo a gente começar a poupar o nosso tal informações ao não conseguisse

13:47.750 --> 13:51.750
utilizar essa informação da coluna para segregar os dados de nenhuma forma.

13:51.760 --> 13:57.560
Se por exemplo outros vermelhos e azuis ficassem todos misturados nesse ano esse gráfico de distribuição

13:57.560 --> 14:03.650
aqui a gente não poderia usar o modelo de segregação porque essa informação aqui esse parâmetro ele

14:03.650 --> 14:08.770
não contém nenhum conteria no caso nenhum poder explicativo para poder justificar se a pessoa clicou

14:08.770 --> 14:10.550
do balanço de branco.

14:10.580 --> 14:12.110
Esses dados aqui são falsos.

14:13.310 --> 14:17.900
Essa é a principal conclusão que a gente pode tirar desse gráfico dados que a gente tem os parâmetros

14:17.900 --> 14:22.760
eles são sim determinantes para determinar se a pessoa clicou romanos.

14:22.860 --> 14:27.560
é isso que eles tem em mente quando está isolada dos dados.

14:27.740 --> 14:32.850
Esse processo chamado estrutura de dados e você encontra algum amplo na qual a gente possa olhar os

14:32.870 --> 14:40.550
nossos dados que nos orgulha prever alguma coisa para variável de saída ou pessoal continuando aqui

14:40.730 --> 14:45.050
agora que a gente já concluiu que as nossas variáveis são suficientes para que a gente possa criar um

14:45.050 --> 14:52.090
modelo bem sucedido de regressão logística para classificar se as pessoas vão ou não clicar na pesquisa.

14:52.490 --> 14:57.060
Vamos criar esse modelo novamente da mesma forma como já havia feito anteriormente.

14:57.060 --> 15:00.530
O primeiro passo é interpretar os dados e entrei de teste.

15:00.830 --> 15:02.640
Então vou reportar aqui no TeK.

15:02.750 --> 15:15.610
Sempre importa para esse método escrever modos Selection importe teste escritos vou rodar e vamos lá

15:15.620 --> 15:18.220
vão definir que vai ser o nosso X.

15:18.470 --> 15:24.860
E o que que vai ser o nosso IP o nosso X vai ser tudo o que nós vamos querer utilizar para predizer

15:24.860 --> 15:26.450
se a pessoa clicou ou não.

15:26.780 --> 15:34.410
Ou seja tudo menos a coluna clica onde começa a colocar as suas informações aqui.

15:35.950 --> 15:42.140
Eu vou colocar o x vai ser igual data base dos 2 dois colchetes eu quero fazer uma seleção em múltiplas

15:42.140 --> 15:43.160
colunas.

15:43.170 --> 15:47.780
Como colocar que ele vai escrevendo um site.

15:49.100 --> 15:50.060
A idade da pessoa

15:54.480 --> 15:56.220
o uso médio.

15:56.270 --> 16:00.710
Estou vendo aqui que as informações está pessoal dele.

16:02.400 --> 16:05.080
Sei Se a pessoa é ou não é.

16:06.250 --> 16:11.920
Automaticamente ele consegue classificar se a mulher também pela forma como a gente apequenou seção

16:11.960 --> 16:18.190
anterior pesquisou os dados do Titanic e meu iPod vai ser basicamente se a pessoa clicou ou não clicou

16:18.190 --> 16:18.760
o molusco.

16:18.780 --> 16:20.410
Isso que a gente quer conseguir classificar.

16:22.190 --> 16:27.280
Então rodar ali de código que defini agora meu x ou y.

16:27.490 --> 16:32.900
E vou passar esse X Y aqui como parâmetros para esse método aqui para a gente conseguir hospitais grande

16:32.900 --> 16:33.570
teste.

16:33.910 --> 16:41.560
O ato de copiar os dados aqui copia esse método da Apple que está basicamente quase sempre igual.

16:41.990 --> 16:48.740
Suponha que se feche o teste para interesse político x e y o tamanho do teste pode fica a critério de

16:48.740 --> 16:52.250
você está com 33 a 40.

16:52.250 --> 17:00.020
Ola boa colocar entre quase 40 por cento e vinte quarenta por cento mais ou menos e coloquei o ano inteiro

17:00.050 --> 17:01.950
para conseguir manter os meus resultados.

17:02.000 --> 17:03.290
Vocês aí quanto eu.

17:03.290 --> 17:09.640
Ele vai respeitar esses dados aleatoriamente porem seguindo esse o analista obtém a mesma resposta.

17:10.510 --> 17:18.410
Lá o efeito da suposta quebra de dados agora ele pede que a gente treine e ajuste um modelo de regressão

17:18.410 --> 17:20.470
logística no conjunto de treinamentos.

17:20.570 --> 17:30.250
Da mesma forma como tinha feito anteriormente por parte do esquema linear model modelo linear importar

17:30.950 --> 17:41.270
logística para o disco Black rodei essa linha de código e como a já havia feito inteiramente de modo

17:41.630 --> 17:48.050
definitivo essa logística vai ser construtor dessa classe aqui e após isso eu vou usar o UOL de modo

17:49.320 --> 18:01.070
Fit para evitar complexo falei com meu pai ao rodar isso aqui eu espero que ele já consiga tal modelo

18:01.070 --> 18:06.490
encontrar um valor esse para baixo da mesma forma como está aqui embaixo.

18:06.790 --> 18:13.840
Feito o modelo próximo o próximo passo para o passo final seria a gente tirar predições do modelo para

18:13.860 --> 18:21.460
o jogo pegar os dados de testes ou tirar lições aprendidas de igual modo de modo.

18:21.960 --> 18:28.840
Eu vou passar o X teste então está feito.

18:28.900 --> 18:30.130
Tenho previsões aqui dentro.

18:30.700 --> 18:35.530
Vou comparar o que ele predisse o que é correto que seria o meu blogue pessoal e pessoal de treino ou

18:35.530 --> 18:42.700
de teste agora esse cara daqui é pra isso ou vou utilizar métricas de classificação de resultado como

18:43.360 --> 18:46.780
uma escala de métricas.

18:47.430 --> 19:00.460
Pode se assim porque a ou b Eu vou utilizar que eu classifiquei por portos.

19:01.030 --> 19:11.820
Desculpa eu fiquei porque pode passar aqui o meu valor de teste o que ele aí vamos brincar espero ver

19:11.820 --> 19:19.120
respostas semelhantes às obtemos as mesmas respostas para teve um modelo aqui que obteve precisão de

19:19.390 --> 19:27.310
91 por cento com certeza sobre suas classificações e modelo muito bom.

19:27.870 --> 19:33.760
Esse modelo aqui baseado nas informações que foram passados aqui se a gente tiver acesso às informações

19:33.760 --> 19:39.980
do momento em que a pessoa entrar no site já sabe dizer com 91 por cento de certeza certeza produtos

19:40.030 --> 19:46.240
para esse conjunto de dados que a pessoa ela vai clicar no anúncio que é muito relevante então se seus

19:46.240 --> 19:50.580
dados fossem tão fáceis assim esses dados só são forjados.

19:52.450 --> 19:56.720
Isso aqui é uma boa forma como se pode fazer para estar criando um modelo de regressão logística colocando

19:56.770 --> 19:58.290
em prática.

19:58.360 --> 19:59.130
Simples assim.

19:59.150 --> 20:03.910
Pessoal o modelo já está apitava aqui dentro pode dar condições predições ele pode refutar com outros

20:03.910 --> 20:04.490
dados.

20:05.590 --> 20:12.820
Basicamente isso é o q esse pessoal de regressão logística é um método relativamente simplista um conceito

20:12.820 --> 20:13.870
relativamente simples.

20:13.880 --> 20:19.970
Eu particulamente considera a matemática pode ser um pouquinho pouquinho complicada mas se você entende

20:19.990 --> 20:23.060
operacionalizar isso também faz fácil colocar em prática.

20:23.680 --> 20:29.470
Então pessoal qualquer dúvida que tenho tido sobre a sala ou qualquer outra aula da Seção de Logística

20:29.470 --> 20:31.330
eu perguntei no fórum de perguntas e respostas.

20:32.140 --> 20:34.370
A próxima sessão vai ser sobre Katniss.

20:34.670 --> 20:36.850
Então espero vocês lá mais.
