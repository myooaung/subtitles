1
00:00:00,380 --> 00:00:02,890
Hello and welcome back to the course on deep learning.

2
00:00:02,910 --> 00:00:09,700
Today we're kicking off this section for recurrent neural networks and I'm very excited about this section.

3
00:00:09,750 --> 00:00:12,720
There's going to be quite some interesting tutorials.

4
00:00:12,720 --> 00:00:19,410
This is a one of the most advanced algorithms that exists in the world of supervised learning.

5
00:00:19,410 --> 00:00:21,700
So let's get started.

6
00:00:21,750 --> 00:00:27,970
We have our little breakdown of supervised versus unsupervised learning branches.

7
00:00:27,990 --> 00:00:32,200
And here we've got artificial neural networks which we've already talked about.

8
00:00:32,220 --> 00:00:35,910
We were talking about convolutional neural networks as well.

9
00:00:36,060 --> 00:00:38,830
And today we're talking about recurrent neural networks.

10
00:00:38,850 --> 00:00:45,060
So there's just so that we see where we are in the big picture of things slowly getting to the unsupervised

11
00:00:45,360 --> 00:00:46,240
part of the course.

12
00:00:46,410 --> 00:00:49,800
But nevertheless that's focused on our own ends today.

13
00:00:49,800 --> 00:00:54,630
All right so now that we know where we are on the map in terms of a list let's have a look where we

14
00:00:54,630 --> 00:00:57,150
are on the map in terms of the human brain.

15
00:00:57,360 --> 00:01:02,250
And so why are we doing this why are we looking at the human brain as if it's a map of the world.

16
00:01:02,370 --> 00:01:09,780
Well the reason for that is the whole concept behind deep learning is to try mimic the human brain and

17
00:01:09,810 --> 00:01:17,970
get kind of similar functions as the human brain has and leveraged the things that evolution has already

18
00:01:17,970 --> 00:01:18,950
developed for us.

19
00:01:18,960 --> 00:01:26,460
And I thought it would be pretty cool if we can somehow link the different branches of deep learning

20
00:01:26,460 --> 00:01:29,880
and we've discussed so we've talked about or the outcomes of risks we're talking about.

21
00:01:29,900 --> 00:01:35,010
And then CNN and now we're talking about RNA and if we could link those to certain parts of the human

22
00:01:35,010 --> 00:01:35,770
brain.

23
00:01:36,330 --> 00:01:39,970
And if it don't make sense so let's have a look here.

24
00:01:39,990 --> 00:01:45,720
We've got the brain the human brain has got three parts so get the cerebrum which is all of this colored

25
00:01:45,720 --> 00:01:46,310
part.

26
00:01:46,350 --> 00:01:49,990
Then we get the cerebellum which is underneath there and that's the little brain.

27
00:01:49,990 --> 00:01:53,760
I actually looked it up in Latin and that does mean little brain.

28
00:01:54,120 --> 00:02:00,960
And we've already looked at a dissection of the cerebellum in the Partow took about and ends that orange

29
00:02:00,960 --> 00:02:07,380
that beat that big orange picture where we saw all of those little neurons that we were trying to kind

30
00:02:07,380 --> 00:02:13,530
of gauge how many there are there are these millions of neurons in the brain and then we've got the

31
00:02:13,530 --> 00:02:21,410
brain stem over here which connects the brain to the organs and her arms and legs and so on.

32
00:02:22,380 --> 00:02:25,200
And so that's how the brain.

33
00:02:25,200 --> 00:02:26,750
Those are the main three parts of the brain.

34
00:02:26,950 --> 00:02:31,130
Now the cerebrum has for Lopez and they're colored in here.

35
00:02:31,140 --> 00:02:33,430
So it's got the frontal lobe.

36
00:02:33,720 --> 00:02:35,220
It's got that temporal lobe.

37
00:02:35,280 --> 00:02:38,550
Got the parietal lobe and it's got the occipital lobe.

38
00:02:38,910 --> 00:02:41,550
And now how do we link these.

39
00:02:41,550 --> 00:02:41,780
Right.

40
00:02:41,780 --> 00:02:42,860
So we've got.

41
00:02:42,890 --> 00:02:45,900
And then we've already discussed CNN and Arnon.

42
00:02:46,260 --> 00:02:50,400
And the interesting way the is on probably was to start off with.

43
00:02:50,450 --> 00:02:54,320
And then because what is the main advantage of an ant.

44
00:02:54,330 --> 00:02:59,790
Well the main advantage the main breakthrough in and ends is apart from the back propagation algorithm

45
00:02:59,790 --> 00:03:01,530
which kind of applies to all of them.

46
00:03:01,560 --> 00:03:05,780
And in fact whatever applies to and applies to everything here.

47
00:03:05,790 --> 00:03:14,880
But for me I think the main thing about an ends and it wouldn't even exist without saying this whole

48
00:03:14,970 --> 00:03:18,270
concept of depression when you don't exist are the weights.

49
00:03:18,300 --> 00:03:27,030
The fact that a man's can learn through prior experience or through private airports and prior observations

50
00:03:27,060 --> 00:03:29,460
that's extremely valuable.

51
00:03:29,490 --> 00:03:35,250
And so what do those those weights represent and moreover the weights of course are present across all

52
00:03:35,250 --> 00:03:36,030
neurons in the brain.

53
00:03:36,030 --> 00:03:42,210
But we're going to try to take away the main philosophical underlying notion there and that is that

54
00:03:42,330 --> 00:03:47,880
weights represent long term memory that once you run your own and then you've trained it you can switch

55
00:03:47,880 --> 00:03:53,280
it off you can come back later it's trained up you know the weights and so whatever input you put into

56
00:03:53,280 --> 00:03:59,180
it it will process it the same way as it would yesterday as it will tomorrow as it will the day after.

57
00:03:59,370 --> 00:04:05,940
So the weights are long term memory over neural network and that's why weights or the A-n go into a

58
00:04:05,940 --> 00:04:06,560
temporal lobe.

59
00:04:06,570 --> 00:04:13,230
Again the weights exists across the whole brain but philosophically and ends are a start to deploring

60
00:04:13,260 --> 00:04:17,340
and they represent long term memory so we're going to put them in the temporal lobe because the temporal

61
00:04:17,340 --> 00:04:25,380
lobe lobe is responsible for long term memory hence called the temporal lobe meaning that lost things

62
00:04:25,380 --> 00:04:30,570
lost through time and their brain is very complex and of course other parts also responsible for memory

63
00:04:30,570 --> 00:04:31,110
as well.

64
00:04:31,260 --> 00:04:37,440
But we're going to simplify things and say N-N is like that temporal lobe then CNN is much easier.

65
00:04:37,470 --> 00:04:43,100
It's vision recognition of images and objects and so on and so that's the occipital lobe.

66
00:04:43,440 --> 00:04:45,590
And today we're talking about our own ends.

67
00:04:45,600 --> 00:04:49,630
And as you'll find out our own ends are like short term memory.

68
00:04:49,680 --> 00:04:55,380
They can remember things that just happened in the previous couple of observations and apply that knowledge

69
00:04:55,380 --> 00:04:56,390
in that going forward.

70
00:04:56,670 --> 00:04:58,940
I'm giving away so much already.

71
00:04:58,980 --> 00:05:03,640
You like your pretty much no there as this tutorial but nevertheless.

72
00:05:03,810 --> 00:05:07,100
So that's the frontal lobe that's where we have a lot of the short term memory.

73
00:05:07,110 --> 00:05:13,880
And of course the frontal lobe also like a quick breakdown of the frontal lobe also responds is responsible

74
00:05:13,880 --> 00:05:17,610
for personality behavior or motor cortex working memory.

75
00:05:17,940 --> 00:05:23,190
And like lots of other things but in our purposes the main thing that we're looking out for is the short

76
00:05:23,190 --> 00:05:24,050
term memory.

77
00:05:24,540 --> 00:05:25,780
By the way if you're interested.

78
00:05:25,890 --> 00:05:31,440
Temporal Lobe is the temporal lobe is concerned with for cognition memory.

79
00:05:31,830 --> 00:05:36,870
That's our long term memory parietal lobe is and these are from Wikipedia.

80
00:05:36,870 --> 00:05:43,350
The parietal lobe is responsible for sensation and perception and constructing a spatial coordination

81
00:05:43,350 --> 00:05:50,220
system to represent the world around us and we are yet to create a neural network which would fit into

82
00:05:50,220 --> 00:05:53,040
that category and occipital is vision.

83
00:05:53,040 --> 00:06:00,120
All right so there you go a bit of neuroscience so let's move on to our favorite neural networks.

84
00:06:00,120 --> 00:06:04,900
So here we've got a simple artificial neural network three inputs to outputs one hand larrup.

85
00:06:05,610 --> 00:06:11,540
What does a r n and how do we represent this as how do we represent or turn this into an RNA.

86
00:06:11,760 --> 00:06:14,910
Well we squash it we squash it all together.

87
00:06:14,910 --> 00:06:22,230
So they're still there but we think of it as if we're looking from underneath or from underneath this

88
00:06:23,550 --> 00:06:24,270
neural network.

89
00:06:24,270 --> 00:06:26,000
So we're looking for a new dimension.

90
00:06:26,000 --> 00:06:27,740
Right so we're looking.

91
00:06:27,750 --> 00:06:29,690
It's still there it's just flattened out.

92
00:06:29,700 --> 00:06:34,800
We're looking at a we're adding a new dimension to all of this but remember that those neurons the whole

93
00:06:34,800 --> 00:06:35,700
network is still there.

94
00:06:35,700 --> 00:06:41,040
Nothing change we just question it for our purposes then to simplify things which is going to change

95
00:06:41,040 --> 00:06:42,460
these multiple hours into two.

96
00:06:42,470 --> 00:06:46,950
And we're going to twist this whole thing make it vertical because that's the standard representation

97
00:06:47,340 --> 00:06:50,040
then in terms of neural networks we're going to call them instead of green.

98
00:06:50,070 --> 00:06:52,170
We're going to color the hindlegs and blue.

99
00:06:52,470 --> 00:06:54,780
And there we go and we're going to add this line.

100
00:06:54,870 --> 00:06:56,550
And what does that line do.

101
00:06:56,550 --> 00:07:04,590
Well that line is the temporal loop and this is an old school representation of our own ends and basically

102
00:07:04,590 --> 00:07:11,090
means that this hidden layer not only gives an output but also feeds back into itself.

103
00:07:11,100 --> 00:07:19,500
So again this is an optical representation so the common kind of approach is now to unwind this or unroll

104
00:07:19,500 --> 00:07:27,410
this temporal loop and represent and ends in the following manner like that so you can see that again.

105
00:07:27,440 --> 00:07:32,630
Don't forget that we've got we've had lots of these things happening right so you're looking in a new

106
00:07:32,630 --> 00:07:38,890
dimension that the layers are actually still there are still there but we're just not focusing on them.

107
00:07:38,900 --> 00:07:42,490
We just remember that each one of these circles is not one you are on.

108
00:07:42,490 --> 00:07:44,510
It's a whole layer of neurons.

109
00:07:44,630 --> 00:07:50,300
And so what is happening is you've got inputs coming into the neurons then you've got outputs but also

110
00:07:50,510 --> 00:07:54,140
the neurons connecting to themselves through time.

111
00:07:54,140 --> 00:07:59,630
So that's the whole concept that they have some sort of memory short term memory that they remember

112
00:07:59,630 --> 00:08:02,620
what was in that neuron just previously or.

113
00:08:02,990 --> 00:08:04,410
And then the one before that.

114
00:08:04,520 --> 00:08:09,540
Or before that it used to remember what it was previous and that allows them to pass information onto

115
00:08:09,580 --> 00:08:13,920
themselves in the future and analyze things.

116
00:08:14,480 --> 00:08:17,960
Kind of like when you're you know when you're watching this course right.

117
00:08:17,960 --> 00:08:24,180
So it would be very sad if you could not remember what was happening in the previous tutorial.

118
00:08:24,190 --> 00:08:30,890
I mean even if we break time down discreetly through not by seconds but like continuous seconds by discreetly

119
00:08:30,890 --> 00:08:37,250
through tutorials and we say like every moment in time is you tutorial it would be very sad if you did

120
00:08:37,250 --> 00:08:41,840
not remember what we had in the previous tutorial or in the previous section or in the previous part

121
00:08:41,840 --> 00:08:42,510
of the course.

122
00:08:42,560 --> 00:08:46,410
Right because then this whole recurrent neural networks part wouldn't makes any sense.

123
00:08:46,420 --> 00:08:51,860
You wouldn't have memory of what a neuron is what an activation function is but because you do remember

124
00:08:51,860 --> 00:08:54,290
those things you can understand this and same thing here.

125
00:08:54,290 --> 00:09:03,320
So how why would we deprive a artificial construct which is supposed to be a synthetic human brain or

126
00:09:03,320 --> 00:09:04,730
like a mimicking the human brain.

127
00:09:04,730 --> 00:09:10,910
Why would we deprived of something so powerful as short term memory long term memory is great but short

128
00:09:10,910 --> 00:09:15,740
term memory is so powerful why would we not give it that opportunity and that's where recurrent neural

129
00:09:15,740 --> 00:09:16,460
networks come in.

130
00:09:16,460 --> 00:09:18,990
That's the gap that they feel it.

131
00:09:19,190 --> 00:09:21,790
And so let's have a look at a couple of examples.

132
00:09:22,520 --> 00:09:28,580
A huge shout out to the Karpovsky blog Capozzi don't get how do I owe some of these examples from here.

133
00:09:28,640 --> 00:09:33,770
So one to many relationship this is when you have one input and have multiple outputs.

134
00:09:33,800 --> 00:09:41,300
Example of this is an image where a computer describes the image you have one input the image and that

135
00:09:41,300 --> 00:09:47,180
would go through a CNN and then would be fed into an R and it and then the computer would come up with

136
00:09:47,180 --> 00:09:48,350
words to describe the image.

137
00:09:48,350 --> 00:09:51,860
And this is an actual computer describing image.

138
00:09:51,860 --> 00:09:54,830
How accurate is that black and white dog jumps over bar.

139
00:09:54,830 --> 00:09:57,290
This is the computer looked at this image and it like up.

140
00:09:57,380 --> 00:10:00,380
It's a black and white dot based on what it's previously learned.

141
00:10:00,380 --> 00:10:09,550
You know the long term memory allowed it to come up with weights and come up with certain feature feature

142
00:10:09,560 --> 00:10:15,030
feature recognition system and come up with the filters come up with everything that is required to

143
00:10:15,040 --> 00:10:20,390
CNN and then the Arnon allows it to make sense out of the sentence right so you can see that the sentence

144
00:10:20,390 --> 00:10:21,530
actually flows.

145
00:10:21,530 --> 00:10:28,790
You know there's a there's an and there's a lake over the bar and then there's like a verb there's a

146
00:10:29,330 --> 00:10:30,220
noun and so on.

147
00:10:30,220 --> 00:10:37,100
So basically it allows the Arnon is what allows it to put a sentence together in this case then many

148
00:10:37,100 --> 00:10:40,670
to one would and example would be sentiment analysis.

149
00:10:40,670 --> 00:10:48,320
So when you have a lot of text and from that text you kind of need to gauge is it other people.

150
00:10:48,320 --> 00:10:53,600
Is this like a positive comment or a negative comment what's the chance that it's a positive or positive

151
00:10:53,600 --> 00:10:55,200
or negative is that comment.

152
00:10:55,340 --> 00:10:57,420
And you've got an example here as well.

153
00:10:57,890 --> 00:11:01,530
And again there's lots of other different examples these are just some.

154
00:11:01,530 --> 00:11:04,000
Then we've got many too many for instance.

155
00:11:04,080 --> 00:11:10,770
I wanted to show you this one so here we've got an example of Google translator and I don't know if

156
00:11:10,860 --> 00:11:13,110
a Google translator uses Arnalds or not.

157
00:11:13,110 --> 00:11:18,870
I know that they have very sophisticated deep learning in Google mind and I've heard that they've used

158
00:11:18,870 --> 00:11:21,480
that in their Android systems and so on.

159
00:11:21,540 --> 00:11:25,040
I'm not sure if they use Arnaz here or not but the concept remains.

160
00:11:25,050 --> 00:11:30,930
So if I say here from English to check I say I am a boy who likes to learn.

161
00:11:31,140 --> 00:11:33,200
You cloak carrier out to it.

162
00:11:33,290 --> 00:11:33,600
Right.

163
00:11:33,630 --> 00:11:39,350
And basically in other languages in some other languages it is important.

164
00:11:39,420 --> 00:11:42,560
What's gender you're a person is right.

165
00:11:42,570 --> 00:11:43,940
So here boy is male.

166
00:11:43,950 --> 00:11:46,620
So that's why he's got Teri arat.

167
00:11:46,740 --> 00:11:54,450
And if you see if I change this to girl in English the other words don't change but in check the other

168
00:11:54,450 --> 00:11:58,530
words change you said Holker caetera Aranda said.

169
00:11:58,740 --> 00:12:00,460
It so you can see right away.

170
00:12:00,480 --> 00:12:03,450
Now it's not really a rat.

171
00:12:03,480 --> 00:12:10,740
It's caetera meaning that these words they depend on the gender of this word Holker and Holker is a

172
00:12:10,740 --> 00:12:17,240
girl and therefore this becomes caetera rather and again I don't know for google translate these are

173
00:12:17,270 --> 00:12:19,610
an enemy who are going to comment on that.

174
00:12:19,630 --> 00:12:27,390
But basically the concept is the same that you need short term information about the previous word in

175
00:12:27,390 --> 00:12:29,300
order to translate the next word right.

176
00:12:29,300 --> 00:12:34,440
You can just translate word by word and it's just a simple example and of course it's like it makes

177
00:12:34,800 --> 00:12:36,790
to make a sentence make sense.

178
00:12:36,810 --> 00:12:38,970
You didn't do need information about the.

179
00:12:39,000 --> 00:12:46,170
But like a very visual example we have here is that the at the least you need to know the gender of

180
00:12:46,170 --> 00:12:51,390
this word too in order to translate the following words for the sentence to make sense.

181
00:12:51,480 --> 00:12:58,200
And that's where our own ends have power because they have short term memory and they can do these things.

182
00:12:58,230 --> 00:12:59,690
So there we go that's a many to many.

183
00:12:59,690 --> 00:13:02,600
You put in lots of words and then you get lots of words out that translation.

184
00:13:02,610 --> 00:13:08,430
And of course not every example has to be related to text or images there can be lots and lots of different

185
00:13:08,430 --> 00:13:09,400
implications of ordnance.

186
00:13:09,420 --> 00:13:17,820
For instance many too many you can use are an ends to subtitle movies meaning that you can have running

187
00:13:17,820 --> 00:13:23,460
spells so basically or describe every single frame in a movie and that is something you can simply do

188
00:13:23,460 --> 00:13:29,130
with a CNN or other neural network because if you're watching a movie you need context about what happened

189
00:13:29,130 --> 00:13:31,880
previously to describe what's happening now.

190
00:13:32,010 --> 00:13:36,390
And so you need that short term memory you can't just run around through a million movies and kind of

191
00:13:36,630 --> 00:13:42,720
understand the whole plot that is going to happen you need short term memory of the plot to be able

192
00:13:42,720 --> 00:13:44,530
to comment on every single frame.

193
00:13:44,790 --> 00:13:50,280
And speaking of movies today we don't have additional reading today we have additional watching.

194
00:13:50,430 --> 00:13:58,380
So a movie called some spring in 2016 directed by Oscar Sharpe and it's got you know this actor almost

195
00:13:58,380 --> 00:14:07,020
middle age from TV shows Silicon Valley and this movie was entirely written by Benjamin who is a Arnon

196
00:14:07,270 --> 00:14:12,170
and LACMA to be specific so I'm going to show you this movie now.

197
00:14:12,810 --> 00:14:13,790
Well I'm not going to play it.

198
00:14:13,800 --> 00:14:15,480
I'm just she will find it so she goes.

199
00:14:15,480 --> 00:14:17,670
Ars Technica it's only nine minutes long.

200
00:14:17,670 --> 00:14:18,720
I highly recommend it.

201
00:14:18,720 --> 00:14:20,000
I've seen it twice.

202
00:14:20,040 --> 00:14:24,100
It's so it's so fun like you will find that.

203
00:14:24,240 --> 00:14:28,570
So a couple of things this is a great description here as well so it's worth reading through this action

204
00:14:28,590 --> 00:14:31,650
interview Benjamin and he actually gave himself the name of Benjamin.

205
00:14:31,650 --> 00:14:33,240
That's why they call him Benjamin.

206
00:14:33,360 --> 00:14:40,470
Is this really cool to see these things and what you'll find about movie is the acting is amazing just

207
00:14:40,500 --> 00:14:41,120
amazing.

208
00:14:41,120 --> 00:14:50,160
Like I had shivers down my spine towards and it got in the top 10 in London in the London Sify in the

209
00:14:50,160 --> 00:14:51,440
Sipher London Festival.

210
00:14:51,690 --> 00:14:57,930
And then what you'll find is that Benjamin is able to construct sentences which kind of makes sense

211
00:14:58,020 --> 00:15:03,490
for the most part which is good but what he lacks is kind of the bigger picture.

212
00:15:03,510 --> 00:15:09,930
He cannot come up with like a plot that constantly makes sense even that even though the actors do a

213
00:15:09,930 --> 00:15:14,370
great job about putting it together and it does look amazing in the end.

214
00:15:14,460 --> 00:15:19,620
But you will notice and kind of look out for this separate when you're watching separate the sentences

215
00:15:19,680 --> 00:15:24,290
and you'll see that each sentence on its own more or less 90 percent of the time makes sense.

216
00:15:24,330 --> 00:15:27,470
But overall he cannot properly link sentences together.

217
00:15:27,480 --> 00:15:32,040
And that's that's the next step for our own ends where you know we're this is still quite a new technology

218
00:15:32,040 --> 00:15:35,730
or it's only picking up recently so it will be developed very soon.

219
00:15:35,850 --> 00:15:40,920
And maybe when you're watching this tutorial you're laughing in the future to five years from now you're

220
00:15:40,920 --> 00:15:45,000
laughing to herself and you're saying oh we've already passed that milestone and probably we will very

221
00:15:45,000 --> 00:15:45,240
soon.

222
00:15:45,240 --> 00:15:47,240
But this is where things are now.

223
00:15:47,250 --> 00:15:49,210
And I highly recommend checking this out.

224
00:15:49,260 --> 00:15:51,450
Only nine minutes long.

225
00:15:51,570 --> 00:15:52,110
So there we go.

226
00:15:52,110 --> 00:15:53,430
That's what our Arnold's are.

227
00:15:53,430 --> 00:15:59,760
In a nutshell and in the next tutorial we will continue digging deeper look for the next time.

228
00:15:59,760 --> 00:16:01,280
Until then enjoy learning.
