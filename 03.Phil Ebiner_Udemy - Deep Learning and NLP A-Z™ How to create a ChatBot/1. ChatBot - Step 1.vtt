WEBVTT
1
00:00:00.210 --> 00:00:06.060
Hi Guys welcome to the implementation part of this course that is the part where we'll build the chat

2
00:00:06.090 --> 00:00:07.620
but from scratch.

3
00:00:07.620 --> 00:00:10.730
And of course following a step by step approach.

4
00:00:10.860 --> 00:00:11.790
This is a law here.

5
00:00:11.790 --> 00:00:15.980
The second instructor of this course and I'm super excited to be back in the game.

6
00:00:16.110 --> 00:00:23.310
We will build a super powerful Chad but by implementing a state of the art deep and LP model which will

7
00:00:23.310 --> 00:00:29.680
be the SEC 2 sec and we will implement that with one of the best API is to build deep ideations or art

8
00:00:29.680 --> 00:00:32.220
of her own talents which will be tense afloat.

9
00:00:32.430 --> 00:00:39.360
I hesitated to implement the chad but in terms of flow or pi torch I actually experimented with both

10
00:00:39.690 --> 00:00:46.000
but I actually got better results with tenso flow and besides I know a lot of you asked for some tests

11
00:00:46.000 --> 00:00:50.330
of your implementation so I'm very happy to give that to you in this course.

12
00:00:50.430 --> 00:00:56.520
We will get into the details and the high level techniques of tense of flow to build our childhood.

13
00:00:56.730 --> 00:01:03.630
So this implementation will be done in five parts which are the common five parts when implementing

14
00:01:03.690 --> 00:01:05.750
a deeper application or an AI.

15
00:01:06.000 --> 00:01:06.770
So here we go.

16
00:01:06.840 --> 00:01:08.520
First part part zero.

17
00:01:08.530 --> 00:01:11.490
Installing Anaconda and getting the data set.

18
00:01:11.600 --> 00:01:18.570
Anaconda is the idea we will use to build our chat but we will actually use more precisely spider inside

19
00:01:18.600 --> 00:01:23.850
and I can it because its like a studio and I want you to feel comfortable with all these great tools

20
00:01:23.850 --> 00:01:26.420
that spider has when implementing our chat.

21
00:01:26.420 --> 00:01:32.060
But and then we will get the data set which is the Cornell movie corpus.

22
00:01:32.100 --> 00:01:39.000
They said basically it's a data set of more than 600 movies containing thousands of conversations between

23
00:01:39.000 --> 00:01:40.240
lots of characters.

24
00:01:40.410 --> 00:01:42.110
And I wanted to train our Chad.

25
00:01:42.120 --> 00:01:47.610
But on this day he said because I wanted to build a general chat but that can have general conversation

26
00:01:47.610 --> 00:01:55.000
with us like a friend instead of you know specified chat but there is use for some specific purpose.

27
00:01:55.260 --> 00:02:01.950
That being said the model we will use can be trained on other datasets for some other purposes you know

28
00:02:02.160 --> 00:02:08.310
for example you will be able to train the same chat but on a more specific dataset like a calendar assistant

29
00:02:08.370 --> 00:02:10.480
or a navigation assistant.

30
00:02:10.500 --> 00:02:15.170
These are some more specific applications but this is not what we do in this course.

31
00:02:15.330 --> 00:02:21.450
We will try in a general chat but to talk about everyday conversations and thats why movies are perfect

32
00:02:21.720 --> 00:02:27.050
because in movies you have a lot of random conversations general conversations between friends.

33
00:02:27.240 --> 00:02:29.510
And so this will actually be pretty fun.

34
00:02:29.670 --> 00:02:30.780
Then part one.

35
00:02:30.840 --> 00:02:37.500
So that was part zero and part one will be data processing data processing is inevitable whenever you

36
00:02:37.500 --> 00:02:45.090
build an AI or whenever you build a machinery model you have to make the data set compatible with the

37
00:02:45.090 --> 00:02:46.520
model you're going to build.

38
00:02:46.530 --> 00:02:52.890
We're going to build a neural network based model and therefore the data will have to have a special

39
00:02:52.890 --> 00:02:55.290
format especially for the inputs.

40
00:02:55.320 --> 00:03:01.380
Besides we'll have to clean the text because the less we clean it and simplify it the more difficult

41
00:03:01.440 --> 00:03:05.260
it will be for a model to train itself to talk like a human.

42
00:03:05.280 --> 00:03:11.940
So we will have to do a lot of data processing this will not be the funniest part but I will try to

43
00:03:11.940 --> 00:03:18.620
do it the most efficiently so that we can get to the exciting parts which are actually part 2.3 and

44
00:03:18.630 --> 00:03:22.050
part four when we get into the heart of the model.

45
00:03:22.050 --> 00:03:28.950
And speaking of these parts part two will be building the SEC to sec morrow the sequence to sequence

46
00:03:28.950 --> 00:03:32.530
model which is a state of the art deep an LP model.

47
00:03:32.610 --> 00:03:33.800
So we will build it.

48
00:03:33.930 --> 00:03:40.920
We will actually build a brain composed of an encoder and then a decoder and we will assemble all of

49
00:03:40.920 --> 00:03:46.830
them to build the final brain which Be careful will not be trained yet.

50
00:03:46.830 --> 00:03:53.120
And speaking of training that leads us to part three part three will be about training this set to segmental

51
00:03:53.220 --> 00:03:56.890
that is training this brain that we would have just made in part two.

52
00:03:57.030 --> 00:03:58.200
So we will train it.

53
00:03:58.260 --> 00:04:04.650
We will set up a last function get the optimizer and then apply some to get a grade in the center to

54
00:04:04.830 --> 00:04:10.090
update the weight of the neurons of the brain so that it improves its ability to talk with us.

55
00:04:10.110 --> 00:04:15.770
And finally part for the last part of this implementation we will test our Chad.

56
00:04:15.780 --> 00:04:18.390
But that is we will test the SEC to Sec.

57
00:04:18.480 --> 00:04:25.500
All that is will make some kind of a code to you know once we executed have an interface where we can

58
00:04:25.560 --> 00:04:30.580
ask some questions and then the jabat will answer and we will just test the chad.

59
00:04:30.600 --> 00:04:36.930
But by observing its answers and see how its capable of conversing with us.

60
00:04:36.930 --> 00:04:38.520
So this will be pretty exciting.

61
00:04:38.670 --> 00:04:39.750
And here we go.

62
00:04:39.750 --> 00:04:42.730
Thats the plan of attack of this implementation.

63
00:04:42.840 --> 00:04:47.400
And without waiting we are going to start with part zero directly in the next tutorial.

64
00:04:47.520 --> 00:04:49.590
We will install efficiently and.

65
00:04:49.830 --> 00:04:54.340
And then in the next tutorial after that we'll get the data set and then it will be good to go.

66
00:04:54.450 --> 00:04:58.770
We will start part 1 day of pre-processing and the next parts after that.

67
00:04:58.800 --> 00:04:59.780
So I'm super excited.

68
00:05:00.050 --> 00:05:05.140
It let's install quickly Anaconda in the next Tauriel and I'll see you there.

69
00:05:05.180 --> 00:05:07.310
Until then enjoy deep and.
