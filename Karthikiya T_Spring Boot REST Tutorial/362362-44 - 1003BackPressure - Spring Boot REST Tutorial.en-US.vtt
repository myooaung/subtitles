WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:02.750
Let's try to understand the concept of back pressure.

00:00:02.750 --> 00:00:04.880
But before that,

00:00:04.880 --> 00:00:09.350
let us try to understand the difference between pull and push model.

00:00:09.350 --> 00:00:13.450
An example off pull model could be Javits streams.

00:00:13.450 --> 00:00:15.260
If you're a bit off java,

00:00:15.260 --> 00:00:16.080
it streams.

00:00:16.080 --> 00:00:20.860
What we're trying to do here is we're trying to create a stream off even numbers without

00:00:20.860 --> 00:00:26.690
first instruction in here and with our second instruction were trying to pull the data from

00:00:26.690 --> 00:00:27.350
the stream.

00:00:27.350 --> 00:00:30.970
That means the producer is not pushing the data,

00:00:30.970 --> 00:00:34.580
rather the consumers pulling the data from the stream.

00:00:34.580 --> 00:00:35.610
In this case,

00:00:35.610 --> 00:00:37.950
we're trying to pull five elements from the stream.

00:00:37.950 --> 00:00:40.370
So this is an example off pulled model.

00:00:40.370 --> 00:00:43.890
Whereas when it comes to reactor programming,

00:00:43.890 --> 00:00:47.260
it's more off a push model than a pull model.

00:00:47.260 --> 00:00:50.050
Some people call it as pull push hybrid model.

00:00:50.050 --> 00:00:56.850
But whichever way you think the way it works is the subscriber will request what the data

00:00:56.850 --> 00:01:02.640
just the amount of data that it is capable of processing and the data source are the

00:01:02.640 --> 00:01:06.150
producer will have a huge chunk of greater Toby streamed.

00:01:06.150 --> 00:01:09.050
But depending on how much data is being requested,

00:01:09.050 --> 00:01:14.350
the producer will push only that much off data that the subscriber is capable of handling

00:01:14.350 --> 00:01:15.250
The data,

00:01:15.250 --> 00:01:19.200
which is available to be streamed but is not yet requested by the subscriber,

00:01:19.200 --> 00:01:21.350
would be stored inside this buffer.

00:01:21.350 --> 00:01:22.830
And maybe that studies.

00:01:22.830 --> 00:01:28.610
And it's called back pressure mechanism because all this data yet to be requested by the

00:01:28.610 --> 00:01:31.880
subscriber might actually build up some pressure.

00:01:31.880 --> 00:01:33.330
And hence that name.

00:01:33.330 --> 00:01:35.350
I'm not sure that's my best guess.

00:01:35.350 --> 00:01:39.170
The concept of back pressure is very crucial,

00:01:39.170 --> 00:01:41.650
especially in case off micro services,

00:01:41.650 --> 00:01:46.390
because all these micro services would actually coming to get each other with rest.

00:01:46.390 --> 00:01:51.590
API I called etcetera and each notice both consumer as well as a producer,

00:01:51.590 --> 00:01:52.550
toe another node.

00:01:52.550 --> 00:01:58.750
If there is no concept of back pressure than all the data would be streamed in one go,

00:01:58.750 --> 00:02:02.450
which the Microsoft's may not be able to handle it,

00:02:02.450 --> 00:02:05.250
and that might cause lack off resources,

00:02:05.250 --> 00:02:08.200
and hence the service may go down.

00:02:08.200 --> 00:02:10.250
And as a side effect,

00:02:10.250 --> 00:02:16.200
all the other micro services which are reliant on the affected micro service can also be

00:02:16.200 --> 00:02:16.970
impacted.

00:02:16.970 --> 00:02:21.000
And hence the back pressure mechanism is very crucial.

00:02:21.000 --> 00:02:27.470
Where all the downstream note would notify the upstream notes as toe how much data they're

00:02:27.470 --> 00:02:28.700
capable off handling.

00:02:28.700 --> 00:02:34.740
What we're going to do next is to take a look at a simple example off back pressure when

00:02:34.740 --> 00:02:38.700
will try to pull a limited set of data depending on our needs.

00:02:38.700 --> 00:02:40.410
Let's go wreck clips.

00:02:40.410 --> 00:02:47.410
So here is our previous example and currently we're trying to request for all the data that

00:02:47.410 --> 00:02:48.760
is available in the stream.

00:02:48.760 --> 00:02:54.950
But now we're going to enhance it to request only two elements from the stream.

00:02:54.950 --> 00:03:01.990
So I can make this to know what this is going to do is the subscriber is just requesting

00:03:01.990 --> 00:03:04.670
for two elements from the stream.

00:03:04.670 --> 00:03:10.250
But what we won't accomplish now is not just request to elements,

00:03:10.250 --> 00:03:13.400
but we want to request to elements at a time.

00:03:13.400 --> 00:03:17.550
So the unsubscribe matter would be called only ones.

00:03:17.550 --> 00:03:21.050
When the subscriber subscribes to the producer.

00:03:21.050 --> 00:03:22.850
However,

00:03:22.850 --> 00:03:26.950
the our next event would be triggered a rich in every element.

00:03:26.950 --> 00:03:32.460
So we can have a logic in here that will check to see if we had all the reprocessed the

00:03:32.460 --> 00:03:33.590
requested data.

00:03:33.590 --> 00:03:35.010
If so,

00:03:35.010 --> 00:03:40.090
then total request new set of data and in order to request noose around data,

00:03:40.090 --> 00:03:46.050
we need tohave the subscription object because that's what who used to request for new data

00:03:46.050 --> 00:03:46.050
.

00:03:46.050 --> 00:03:51.040
So we're going to make this available globally in this class.

00:03:51.040 --> 00:03:59.150
So let me just create a variable private subscription.

00:03:59.150 --> 00:04:11.070
Let me just populated and inside the on next,

00:04:11.070 --> 00:04:17.700
even we're going to request the next set of data from the stream,

00:04:17.700 --> 00:04:20.350
which in this case is too now,

00:04:20.350 --> 00:04:20.970
obviously,

00:04:20.970 --> 00:04:22.290
this doesn't make sense.

00:04:22.290 --> 00:04:35.640
Have to have a check to see if and for this We need to have a account and would incriminate

00:04:35.640 --> 00:04:38.270
the count for each and every our next event.

00:04:38.270 --> 00:04:43.250
And then we'll check the safe count equals two.

00:04:43.250 --> 00:04:48.360
That means we had all the re process,

00:04:48.360 --> 00:04:52.650
the data which we had received,

00:04:52.650 --> 00:05:08.050
and let me also reset the counter back 20 And there you have it.

00:05:08.050 --> 00:05:13.210
In order to understand this behavior in better fashion,

00:05:13.210 --> 00:05:17.050
let me also log what's happening.

00:05:17.050 --> 00:05:29.650
I'm not support the log message in here.

00:05:29.650 --> 00:05:42.700
Annan for log to see populated products.

00:05:42.700 --> 00:05:47.350
I'm just simply going to print whatever is available.

00:05:47.350 --> 00:05:48.650
A spot on the list.

00:05:48.650 --> 00:05:54.450
Let's run out application and see what's happening.

00:05:54.450 --> 00:05:59.670
I mean,

00:05:59.670 --> 00:06:02.050
go to postmen and send the request real quick.

00:06:02.050 --> 00:06:10.900
And if you take a look at the console the first time subscribers subscribed to the producer

00:06:10.900 --> 00:06:13.100
producer called the On Subscribe.

00:06:13.100 --> 00:06:16.930
Even with the subscription object his language,

00:06:16.930 --> 00:06:22.250
we requested for a couple of elements and hence their corresponding on next events off

00:06:22.250 --> 00:06:25.340
those two elements for each and every our next call,

00:06:25.340 --> 00:06:26.920
we're implementing the counter,

00:06:26.920 --> 00:06:28.960
and since there are two elements in here,

00:06:28.960 --> 00:06:31.030
the condition is met.

00:06:31.030 --> 00:06:32.170
The count will become,

00:06:32.170 --> 00:06:32.600
too.

00:06:32.600 --> 00:06:41.100
And so we requested for additional set off data and something is repeated once again,

00:06:41.100 --> 00:06:46.390
and the third time were trying to reckless for new data.

00:06:46.390 --> 00:06:49.720
We don't have any data to be streamed by the producer,

00:06:49.720 --> 00:06:54.750
and so the producer will call the incomplete method off subscriber.

00:06:54.750 --> 00:06:56.390
And finally,

00:06:56.390 --> 00:06:59.200
we're just trying to print what's there in the end,

00:06:59.200 --> 00:07:03.350
our list with this log message right here.

00:07:03.350 --> 00:07:10.510
So that's are you limit the amount of data that you want to consume.

00:07:10.510 --> 00:07:17.950
I'm pretty sure that this is not the most realistic example off back pressure.

00:07:17.950 --> 00:07:21.760
We have many more exacting an interesting examples coming.

00:07:21.760 --> 00:07:22.950
Stay tuned

