1
00:00:05,370 --> 00:00:10,660
Welcome back for the solution for machine learning Question Number 10 says questions asking what metrics

2
00:00:10,660 --> 00:00:13,100
can be used to evaluate a regression task.

3
00:00:14,290 --> 00:00:15,520
So there's lots of different metrics.

4
00:00:15,520 --> 00:00:17,280
Let's go through some of them.

5
00:00:17,290 --> 00:00:18,810
There's mean absolute error.

6
00:00:18,820 --> 00:00:23,290
So this is the mean of the absolute values of the error so we have why and why.

7
00:00:23,500 --> 00:00:28,030
Basically taking the difference between the true value versus the value predicted.

8
00:00:28,030 --> 00:00:32,530
You take the absolute value of that and then you sum them all up and divide by how many points to where

9
00:00:32,650 --> 00:00:34,270
essentially taking the average.

10
00:00:34,270 --> 00:00:39,010
So this is not the most common metric but it is the most basic metric.

11
00:00:39,070 --> 00:00:43,370
Basically on average how often you.

12
00:00:43,480 --> 00:00:45,900
So there's then the mean square error.

13
00:00:45,970 --> 00:00:49,110
And the reason this one is popular because it's the mean of squared errors.

14
00:00:49,150 --> 00:00:54,250
It basically punishes you for having larger errors because you're going to be squaring the difference

15
00:00:54,250 --> 00:00:56,890
between your predicted values and those true values.

16
00:00:56,890 --> 00:01:02,050
So that means if you have a larger error when it gets squared then you're going to have a really larger.

17
00:01:02,080 --> 00:01:03,790
So that's means squared error.

18
00:01:03,910 --> 00:01:07,880
And again you're taking some of these dividing it by the number of points that were available.

19
00:01:07,900 --> 00:01:12,520
There is a problem with this one though and it's the fact that even though you have the advantage that

20
00:01:12,520 --> 00:01:18,760
you're punishing larger errors you are no longer in the same units as whatever the continuous value

21
00:01:18,760 --> 00:01:20,220
you are trying to predict was.

22
00:01:20,380 --> 00:01:25,180
So then we finally come up with root mean squared error and it's the same as the mean square there.

23
00:01:25,240 --> 00:01:27,690
Except now we're taking the root the square root of it.

24
00:01:27,790 --> 00:01:32,470
That way we still have the same units at the end of the day in the same category of whatever the label

25
00:01:32,470 --> 00:01:34,000
happens to be.

26
00:01:34,000 --> 00:01:38,470
So these are definitely three are some of the most common metrics root mean square error probably being

27
00:01:38,470 --> 00:01:43,360
the most common out of three of these because it takes advantage of the fact that you are punishing

28
00:01:43,360 --> 00:01:44,380
for larger errors.

29
00:01:44,440 --> 00:01:48,730
And at the end of the day you still have the same units as whatever your label was in.

30
00:01:48,820 --> 00:01:53,170
There's other metrics to consider things like R-squared value and adjust that R-squared value.

31
00:01:53,180 --> 00:01:57,820
You can check out the resource links in the guide book if you want more information on the various metrics

32
00:01:57,820 --> 00:01:59,130
for regression tasks.

33
00:01:59,230 --> 00:02:03,520
But definitely you want to be able to know these three and also be able to explain the differences between

34
00:02:03,520 --> 00:02:07,680
them and the advantages and how we kind of build up to root mean squared air.

35
00:02:07,990 --> 00:02:10,200
All right thanks everyone and I'll see you at the next lecture.

