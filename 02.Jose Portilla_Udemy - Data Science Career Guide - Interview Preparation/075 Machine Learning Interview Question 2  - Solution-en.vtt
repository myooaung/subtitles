WEBVTT
1

00:00:05.960 --> 00:00:07.610

Welcome to the solution for machine learning.



2

00:00:07.610 --> 00:00:09.510

Question number two.



3

00:00:09.660 --> 00:00:14.040

So this question just wanted to describe the formula for logistic regression and how the algorithm is



4

00:00:14.040 --> 00:00:15.950

used for binary classification.



5

00:00:17.250 --> 00:00:21.900

So the formula for logistic regression typically shouldn't have to memorize a lot of formulas for an



6

00:00:21.900 --> 00:00:25.800

interview setting but this one is definitely common enough that you should just note off the top your



7

00:00:25.800 --> 00:00:28.460

head and the formula for religious progression.



8

00:00:28.470 --> 00:00:34.380

The logistic function is going to be one over one plus it's a negative t or it could be to negative



9

00:00:34.380 --> 00:00:38.050

Z negative x whatever that variable happens to be.



10

00:00:38.070 --> 00:00:44.210

Now as far as actually performing logistic regression what we do is we take the linear regression which



11

00:00:44.210 --> 00:00:50.760

is the T is equal to some beta term plus beta times x plus another beta term times X..



12

00:00:50.790 --> 00:00:52.260

So then cetera.



13

00:00:52.310 --> 00:00:55.800

So you take that and then you plug that into the logistic function.



14

00:00:56.000 --> 00:01:00.940

So the very first top function that's the logistic function then to actually perform the logistic regression.



15

00:01:00.950 --> 00:01:06.520

We take our typical linear regression formula and plug that in to the logistic regression.



16

00:01:06.800 --> 00:01:08.890

So what actually happens when we do that.



17

00:01:09.260 --> 00:01:14.810

Well we can then use the result of f of x there as the probability of the data points being in the positive



18

00:01:14.810 --> 00:01:15.740

a class.



19

00:01:15.740 --> 00:01:17.030

So here we can actually compare.



20

00:01:17.030 --> 00:01:22.100

Right on top of each other what the linear model is doing versus what the logistic model is doing.



21

00:01:22.100 --> 00:01:27.380

So don't hear the Linear Model S that straight blue line where y is equal to some Bayda term plus some



22

00:01:27.380 --> 00:01:32.030

beta turn times X and that can continue all the way for however many variables you have.



23

00:01:32.060 --> 00:01:37.280

You take that and you plug it into the logistic function giving you the logistic model and know the



24

00:01:37.280 --> 00:01:39.950

sigmoid shape of that logistic model.



25

00:01:40.220 --> 00:01:45.830

Here we can see that no matter what you plug in to the logistic function the values are always going



26

00:01:45.830 --> 00:01:48.070

to be between 0 and 1.



27

00:01:48.110 --> 00:01:54.290

So that allows us to actually calculate a probability of either be in class 0 or class 1 because we'll



28

00:01:54.290 --> 00:01:58.890

set the cutoff right in the middle there and that middle point is going to be 0.5.



29

00:01:58.910 --> 00:02:06.020

So we decide that whatever we plug into the logistic model if it's output value is less than 0.5 we'll



30

00:02:06.020 --> 00:02:08.140

go ahead and classify that as zero.



31

00:02:08.330 --> 00:02:13.720

And if its value is greater than or equal to 0.5 we classify that as Class 1.



32

00:02:13.730 --> 00:02:19.070

So that's the main idea behind the logistic model basically using the logistic function Passey in the



33

00:02:19.070 --> 00:02:20.390

linear regression model into it.



34

00:02:20.540 --> 00:02:23.890

And now everything you get as an output has to be between 0 and 1.



35

00:02:23.900 --> 00:02:28.670

Mathematically you can check out the guidebook for a lot of more great resources and understanding the



36

00:02:28.670 --> 00:02:30.850

logistic regression in general.



37

00:02:31.130 --> 00:02:32.610

Thanks and I'll see at the next lecture.



