1
00:00:05,350 --> 00:00:06,260
Welcome back everyone.

2
00:00:06,280 --> 00:00:09,480
This lecture on the confusion matrix.

3
00:00:09,540 --> 00:00:14,560
We mentioned the way to view various metrics of classification is called the confusion matrix.

4
00:00:14,730 --> 00:00:21,280
Let's explore the basics of the confusion matrix to help us understand precision and recall better in

5
00:00:21,280 --> 00:00:23,980
the classification problem during testing phase.

6
00:00:24,040 --> 00:00:26,020
You're going to have two main categories.

7
00:00:26,110 --> 00:00:32,980
The true condition and the predictive condition for example the true condition of a text message could

8
00:00:32,980 --> 00:00:34,570
be that it is spam.

9
00:00:34,690 --> 00:00:39,160
The predicted condition is what you're machine learning model predicted such as predicting that that

10
00:00:39,160 --> 00:00:41,170
test message was spam.

11
00:00:41,170 --> 00:00:46,310
Keep in mind it could have also pricked it that it incorrectly as him.

12
00:00:46,340 --> 00:00:51,800
This means if you have two possible classes you should have four separate groups at the end of testing.

13
00:00:51,890 --> 00:00:54,690
You have correctly classified the class 1.

14
00:00:54,740 --> 00:01:00,740
So that means you had a message that was him and you positively identified it as him.

15
00:01:00,740 --> 00:01:03,080
There's also correctly classified the class too.

16
00:01:03,380 --> 00:01:08,580
So something was truly spam and then you correctly identified it as spam.

17
00:01:08,600 --> 00:01:15,710
Then there's the other two options incorrectly classifying something to class 1 or incorrectly classifying

18
00:01:15,710 --> 00:01:20,820
something into class to a false ham or false spam.

19
00:01:20,850 --> 00:01:25,240
So if we were to map these out in a little grid we'd have something that looks like this.

20
00:01:25,260 --> 00:01:28,470
And this is the confusion matrix and is the confusion matrix.

21
00:01:28,470 --> 00:01:32,970
If you look it up on Wikipedia which is actually a really helpful article on this it would map out something

22
00:01:32,970 --> 00:01:33,980
that looks like this.

23
00:01:35,150 --> 00:01:40,100
So if we were to actually look at it a little more simplified for our particular example going back

24
00:01:40,100 --> 00:01:41,550
to those text messages.

25
00:01:41,690 --> 00:01:46,630
Again we have the real condition and the predicted condition so we can see over on the left hand side

26
00:01:46,630 --> 00:01:48,680
if we're going to have two real conditions.

27
00:01:48,680 --> 00:01:52,310
The real condition is either him or real condition spam.

28
00:01:52,520 --> 00:01:58,690
And then along the columns we have our predicted condition predicting him or predicting spam.

29
00:01:58,720 --> 00:02:04,820
You'll notice that if the real condition is him and we predicted him then we have a true positive.

30
00:02:04,840 --> 00:02:11,010
We correctly predicted that this was positively him along the predicted condition as well.

31
00:02:11,010 --> 00:02:12,940
We have a false negative.

32
00:02:12,990 --> 00:02:17,370
That means that the real condition was him but our machine learning model incorrectly predicted it to

33
00:02:17,370 --> 00:02:18,260
be spam.

34
00:02:18,270 --> 00:02:20,760
That's a false negative here.

35
00:02:20,800 --> 00:02:25,060
Relabeling him as positive and spam as negative.

36
00:02:25,110 --> 00:02:28,470
We also see that we have real conditions spam and then predicted him.

37
00:02:28,470 --> 00:02:33,420
That's known as a false positive falsely identifying something to the positive class which in this case

38
00:02:33,420 --> 00:02:34,450
is him.

39
00:02:34,470 --> 00:02:36,960
We also finally true negative correctly.

40
00:02:36,970 --> 00:02:42,260
And the feeling something to the negative class predicting spam free spam text message.

41
00:02:42,270 --> 00:02:47,280
Now if we come back to that other confusion matrix that we saw earlier we can expand on this to have

42
00:02:47,280 --> 00:02:53,430
quite a wide variety of different metrics we can calculate things like true positive rate false positive

43
00:02:53,430 --> 00:02:57,400
rate positive likelihood ratio false emission rate etc..

44
00:02:57,660 --> 00:02:59,790
But really we're just concerned for a few of these.

45
00:02:59,880 --> 00:03:03,450
We're concerned with recall accuracy and precision.

46
00:03:03,750 --> 00:03:09,280
And here I can see a bunch of formulas for actually calculating those now the main point to remember

47
00:03:09,280 --> 00:03:14,170
is the confusion matrix and the various calculated metrics is that they are all fundamentally ways of

48
00:03:14,170 --> 00:03:19,660
comparing the predicted values versus the true values and what constitutes good metrics will really

49
00:03:19,660 --> 00:03:21,970
depend on the specific situation.

50
00:03:22,210 --> 00:03:25,610
In some situations 99 percent accuracy is fantastic.

51
00:03:25,690 --> 00:03:26,620
In other situations.

52
00:03:26,640 --> 00:03:31,420
Ninety nine percent accuracy may actually not be good enough for whatever you're are trying to predict

53
00:03:31,750 --> 00:03:35,900
because maybe it comes at the cost of a really poor precision and poor recall.

54
00:03:36,040 --> 00:03:41,400
So we can't just say that there's certain good values for particular metrics.

55
00:03:41,410 --> 00:03:46,990
Obviously if you get 100 percent across precision accuracy and recall if you get across a hundred percent

56
00:03:47,050 --> 00:03:49,410
on all three of those then you have a really good model.

57
00:03:49,420 --> 00:03:55,070
But in the real world you're probably not going to get 100 percent of all those.

58
00:03:55,090 --> 00:03:58,840
So let's go ahead and use confusion matrix to evaluate our model.

59
00:03:58,840 --> 00:04:01,600
Let's imagine now we're testing for a disease.

60
00:04:01,630 --> 00:04:07,270
So in this example we're going to test for the presence of a disease and we have the actual patients

61
00:04:07,270 --> 00:04:07,850
come in.

62
00:04:07,870 --> 00:04:09,810
Remember this is supervised learning.

63
00:04:09,820 --> 00:04:15,250
So before we actually run them through the testing program we actually already know the true conditions

64
00:04:15,280 --> 00:04:19,980
of these patients whether or not they had disease or don't have these.

65
00:04:20,020 --> 00:04:23,640
So you can imagine that we're testing a new diagnostic tool.

66
00:04:23,660 --> 00:04:30,050
So in this case for example test for presence of disease we'll say no is equal to a negative test or

67
00:04:30,050 --> 00:04:30,770
false.

68
00:04:30,770 --> 00:04:35,000
Often you just say that zero or yes is a positive test which is true.

69
00:04:35,030 --> 00:04:36,580
And again you say that's one.

70
00:04:36,650 --> 00:04:43,180
So in this particular example the total number of patients we have for this new diagnostic test is 165.

71
00:04:43,190 --> 00:04:49,820
So we say end is equal to 165 and then we have the results as follows of the condition that people did

72
00:04:49,820 --> 00:04:51,400
not have the condition.

73
00:04:51,410 --> 00:04:55,390
Maybe we're testing for something like a cancer in this particular example.

74
00:04:55,430 --> 00:05:00,240
There's 50 people that didn't have cancer that we correctly predicted they don't have cancer.

75
00:05:00,230 --> 00:05:07,400
So we say predicted no actual no 50 then we can also see that we actually predicted 10 people to have

76
00:05:07,430 --> 00:05:08,210
disease.

77
00:05:08,450 --> 00:05:11,050
And these people actually did not have disease.

78
00:05:11,060 --> 00:05:17,810
So those 10 were incorrect that we also see that we have actually yes and predicted no as 5 and then

79
00:05:17,900 --> 00:05:20,360
actually yes or predicted Yes as 100

80
00:05:23,290 --> 00:05:29,280
so some basic terminology here are true positives true negatives false positives and false negatives.

81
00:05:29,340 --> 00:05:34,470
So you can see here on the great how that actually lines up and keep in mind you can kind of flip this

82
00:05:34,470 --> 00:05:41,130
the order no versus Yes on either the columns or the rows in order to flip the quadrants of negatives

83
00:05:41,130 --> 00:05:46,290
versus positives in the original confusion matrix we showed it in this lecture that was actually flipped.

84
00:05:46,290 --> 00:05:49,400
So keep in mind you may see the confusion matrix both ways.

85
00:05:49,500 --> 00:05:52,740
But other than that the information presented is still the same.

86
00:05:52,800 --> 00:05:55,190
It's just the quadrants are slightly rotated.

87
00:05:57,480 --> 00:06:01,880
So if we're trying to answer a question like What is the accuracy of this test.

88
00:06:01,920 --> 00:06:07,290
We ask ourselves how often is it correct and for accuracy it's just equal to true positives.

89
00:06:07,290 --> 00:06:13,290
Plus true negatives divided by the total essentially asking the question How many did I classify correctly

90
00:06:13,560 --> 00:06:15,060
over all my examples.

91
00:06:15,120 --> 00:06:21,270
And in this case we get 150 divided by the total number which was 165 and that means that our test was

92
00:06:21,270 --> 00:06:22,960
91 percent accurate.

93
00:06:23,190 --> 00:06:25,020
Now is 91 percent accurate.

94
00:06:25,200 --> 00:06:26,130
Good enough.

95
00:06:26,130 --> 00:06:28,000
That really depends on the situation.

96
00:06:28,200 --> 00:06:33,090
If you're dealing with something that's as high stakes as something like cancer 91 percent accuracy

97
00:06:33,540 --> 00:06:34,650
may not be good enough.

98
00:06:34,830 --> 00:06:41,010
And you also have to take into the context of precision and recall notice that a really important statistic

99
00:06:41,010 --> 00:06:48,120
here is the false negative the false negative means that you knew this person when you're going through

100
00:06:48,120 --> 00:06:49,960
the test actually had the disease.

101
00:06:50,100 --> 00:06:53,530
But the machine learning model predicted them as not having the disease.

102
00:06:53,760 --> 00:06:59,940
That's an extremely dangerous situation to be in when the stakes are very high like a cancer diagnostic

103
00:07:00,240 --> 00:07:05,150
because that means someone that actually has a disease you're telling them they do not have it.

104
00:07:05,460 --> 00:07:11,800
So you have to keep in context the entire idea of what you're machine learning model is trying to achieve.

105
00:07:12,000 --> 00:07:18,990
So there's always going to be a bit of a tradeoff between false negatives and false positives and ideally

106
00:07:19,080 --> 00:07:23,790
for something like this where we're dealing with a really high stakes situation and we want to make

107
00:07:23,790 --> 00:07:26,340
sure we minimize the false negatives.

108
00:07:26,340 --> 00:07:29,800
It doesn't matter too much in kind of a diagnostic sense.

109
00:07:29,910 --> 00:07:35,010
If we have a larger amount of false positives in order to lower our false negatives because we would

110
00:07:35,010 --> 00:07:40,110
rather set up a situation where we tell a patient that they have a disease when they actually don't

111
00:07:40,110 --> 00:07:44,650
have it and then conclude that they are in line now for further diagnostic tests.

112
00:07:44,820 --> 00:07:47,720
Again it depends on the context of what the next steps are.

113
00:07:47,760 --> 00:07:52,080
What we'd really like to avoid in this situation when it comes to disease is telling someone they're

114
00:07:52,100 --> 00:07:54,750
clear of the disease when they actually have it.

115
00:07:54,750 --> 00:08:00,090
So again there's no right or wrong answer as far as what your false positive rate or false negative

116
00:08:00,090 --> 00:08:01,230
rate should be.

117
00:08:01,230 --> 00:08:06,750
It really depends on the context of the situation and how important each of these are in the overall

118
00:08:06,750 --> 00:08:07,350
study.

119
00:08:09,530 --> 00:08:14,150
Now there's other things you can calculate such as the misclassification Ree or Airey.

120
00:08:14,300 --> 00:08:17,650
That's another one that's essentially the reverse of accuracy.

121
00:08:17,660 --> 00:08:20,660
It's just asking overall how often am I wrong.

122
00:08:20,660 --> 00:08:25,370
So that's false positives plus false negatives divided by a total or 100 minus accuracy.

123
00:08:25,370 --> 00:08:33,810
So in this case where 9 percent error rate in other common thing to keep in mind is that in statistics

124
00:08:34,170 --> 00:08:39,060
false positives and false negatives are often referred to as type 1 errors and type 2 errors.

125
00:08:39,120 --> 00:08:44,100
And here you can see kind of a funny example in order to keep in mind the differences between the two.

126
00:08:44,400 --> 00:08:45,440
A false positive.

127
00:08:45,660 --> 00:08:47,370
Here we're telling the man that they're pregnant.

128
00:08:47,400 --> 00:08:52,910
Clearly this person cannot be pregnant or the false negative in which case this woman is clearly pregnant.

129
00:08:52,910 --> 00:08:54,740
What we're telling them they're not pregnant.

130
00:08:54,870 --> 00:08:56,230
So keep mine in statistics.

131
00:08:56,250 --> 00:09:01,320
You may see type 1 error and type 2 error instead of the terms false positives and false negatives.

132
00:09:03,380 --> 00:09:06,550
If you're still confused the confusion matrix don't worry too much about it.

133
00:09:06,590 --> 00:09:09,080
I would encourage you to check out the Wikipedia page for it.

134
00:09:09,080 --> 00:09:13,310
It has a really good diagram that we saw during this lecture with all the formulas for all the metrics

135
00:09:13,790 --> 00:09:14,610
throughout the training.

136
00:09:14,690 --> 00:09:19,460
What we're going to be doing is just printing out metrics for example just print the accuracy or print

137
00:09:19,460 --> 00:09:24,350
out a confusion matrix or print out what's known as a classification report which reports back precision

138
00:09:24,470 --> 00:09:26,500
recall an F1 score.

139
00:09:26,500 --> 00:09:29,800
Again it takes time to really get an understanding of these metrics.

140
00:09:29,990 --> 00:09:32,080
And more importantly an intuition behind them.

141
00:09:32,360 --> 00:09:38,810
Check out the resource links for this lecture in order to help your understanding of things like precision

142
00:09:38,990 --> 00:09:40,970
recall and accuracy.

143
00:09:40,970 --> 00:09:41,660
All right.

144
00:09:41,660 --> 00:09:47,330
Coming up next we're going to discuss a primer into using Python's sikat learn machine learning library

145
00:09:47,640 --> 00:09:48,770
will see at the next lecture.

