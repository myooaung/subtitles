WEBVTT
ï»¿1
00:00:05.830 --> 00:00:06.840
Welcome back everyone.

2
00:00:06.880 --> 00:00:12.610
This lecture on text classification and this particular lecture we're going to go from start to finish

3
00:00:12.880 --> 00:00:18.730
for the full text classification code along project will be working for a movie review dataset and then

4
00:00:18.730 --> 00:00:23.520
being able to tell whether a movie review is positive or negative based off the texts.

5
00:00:23.530 --> 00:00:26.080
Let's get started.

6
00:00:26.150 --> 00:00:29.500
Let's begin by checking out our data set for this project.

7
00:00:29.510 --> 00:00:34.220
We're going to be using a movie review a data set and we're going to try to develop a classification

8
00:00:34.220 --> 00:00:37.520
model just what we did with the spam collection dataset.

9
00:00:37.520 --> 00:00:42.920
However we're going to be trying to predict simply based off the text of a movie review if that movie

10
00:00:42.920 --> 00:00:46.250
review is positive or negative on the movie.

11
00:00:46.250 --> 00:00:53.960
So we're wanted to import some pie and as and import pandas as PD and we've actually already downloaded

12
00:00:53.960 --> 00:00:55.590
this movie review that it for you.

13
00:00:55.850 --> 00:01:03.380
So you simply need to read it in using the read C S V and you can read it in from the text files folder.

14
00:01:03.380 --> 00:01:11.510
It's called Movie reviews and it's the first one without the two Ts V and it's separated by tabs because

15
00:01:11.520 --> 00:01:12.870
the TSB file.

16
00:01:12.870 --> 00:01:19.270
So you just indicate the separator is backslash T and then we can check the head of the document with

17
00:01:19.270 --> 00:01:21.050
the head.

18
00:01:21.100 --> 00:01:23.020
And here we can see the label.

19
00:01:23.020 --> 00:01:27.750
So if it's negative or positive review and then the actual review itself.

20
00:01:28.320 --> 00:01:33.420
If you check out the length of this data frame here we have 2000 reviews.

21
00:01:33.440 --> 00:01:35.980
Let's go ahead and take a look at one of the reviews.

22
00:01:36.110 --> 00:01:45.460
I can do this simply by saying F and then as a string passen review and then off of this index one of

23
00:01:45.460 --> 00:01:47.390
the reviews so he can index the first one.

24
00:01:47.710 --> 00:01:49.580
And here we have the entire review.

25
00:01:49.630 --> 00:01:50.140
And if you want.

26
00:01:50.140 --> 00:01:54.880
You can even attempt to print this out and you can see here.

27
00:01:54.950 --> 00:01:59.920
This is a negative review of the movie and we can check out a positive view of the movie.

28
00:01:59.960 --> 00:02:02.580
Let's go ahead and do index to.

29
00:02:02.810 --> 00:02:08.110
So here you can see a positive review of the movie and we're going to do is using the raw text attempts

30
00:02:08.120 --> 00:02:12.260
to predict whether a movie review is positive or negative.

31
00:02:12.290 --> 00:02:16.160
You can imagine if we're running a site like rotten tomatoes we would then be able to automatically

32
00:02:16.160 --> 00:02:20.310
scrape the Internet and decide if a review is positive or negative.

33
00:02:20.390 --> 00:02:24.400
We're going to do is first check for missing values just as we did before.

34
00:02:24.770 --> 00:02:28.610
It's important that we check for missing values because a lot of real world data will be missing values

35
00:02:29.300 --> 00:02:32.950
so we can do this by simply saying T.F. is null and in taking the some.

36
00:02:33.260 --> 00:02:37.680
And here we can see while we aren't missing any labels we are missing a few reviews.

37
00:02:37.790 --> 00:02:40.730
So some of the reviews seem to be just completely empty.

38
00:02:40.730 --> 00:02:45.500
We can remove these and am not a number or none.

39
00:02:45.500 --> 00:02:53.620
Reviews by saying the F drop and a and then we're going to also say in place is equal to true.

40
00:02:53.620 --> 00:02:55.620
That way it's a permanent drop.

41
00:02:55.900 --> 00:03:03.580
And then if we say F is null and take the sum of that you'll notice now we are not having any missing

42
00:03:03.580 --> 00:03:04.930
values.

43
00:03:04.990 --> 00:03:09.850
However whenever you're dealing with text data formatted like this it's important to understand that

44
00:03:09.910 --> 00:03:16.020
often databases will actually instead of putting in a a number or a null value.

45
00:03:16.020 --> 00:03:21.670
When I review or piece of text is missing they actually put an empty string or a blank string.

46
00:03:21.670 --> 00:03:28.750
What we want to do is understand and detect and remove empty strings and we can do this through a variety

47
00:03:28.750 --> 00:03:29.790
of methods.

48
00:03:29.790 --> 00:03:34.750
What we're going to show you is probably the simplest method which is to start off with an empty list.

49
00:03:34.750 --> 00:03:40.720
Iterate over that data frame and then just check the review for whitespace or check the reviews length

50
00:03:41.140 --> 00:03:44.590
and then double check to make sure that there's actually a review there.

51
00:03:44.590 --> 00:03:50.510
So again lots of different ways to do this but here's kind of a simple way we're going to set up a list

52
00:03:50.540 --> 00:03:55.600
of blanks and then we're going to iterate through our data frame.

53
00:03:55.630 --> 00:04:06.750
So we're going to say for I comma Elby comma Arvie in deep thought itor tuples.

54
00:04:06.850 --> 00:04:08.190
So this is going to return.

55
00:04:08.290 --> 00:04:15.620
It's going to return a tuple of the index location the label value and then the review text itself.

56
00:04:15.850 --> 00:04:20.390
And we're going to do as we iterate through every row in the data frame.

57
00:04:20.620 --> 00:04:25.860
We'll check if the review is just simply whitespace.

58
00:04:25.870 --> 00:04:30.430
So we're checking if that review is whitespace and what we can do is we can actually do the is space

59
00:04:30.430 --> 00:04:31.800
method off a string.

60
00:04:31.870 --> 00:04:35.840
So I want to show you what I mean by that when I quickly create a string here.

61
00:04:35.860 --> 00:04:42.730
We're going to say my string is equal to hello and let's create an empty string.

62
00:04:42.730 --> 00:04:45.870
So just empty whitespace string will say empty is equal to.

63
00:04:46.180 --> 00:04:48.680
And here and is going to have an empty string.

64
00:04:48.970 --> 00:04:51.380
So a method I can call off the string.

65
00:04:51.640 --> 00:04:56.330
I can say my string and there's an is space method.

66
00:04:56.740 --> 00:05:01.330
So I can check is space in all turnback a boolean true or false.

67
00:05:01.330 --> 00:05:07.300
Notice that if I run this same method off that empty variable which is an empty string it's going to

68
00:05:07.300 --> 00:05:13.090
say true and if it's multiple spaces it's still going to return true.

69
00:05:13.390 --> 00:05:18.840
So again this is a way we can use to detect whether or not something is empty just full of whitespace.

70
00:05:19.030 --> 00:05:26.100
So I'll say if that particular review Arvi thought is space check your spelling on this.

71
00:05:26.140 --> 00:05:30.350
So there's two s's and then we're going to say blanks in the pen.

72
00:05:30.400 --> 00:05:31.420
The exposition.

73
00:05:31.420 --> 00:05:37.150
So now I'm basically collecting the index position of these blank statements.

74
00:05:37.330 --> 00:05:42.550
And now if I take a look at blinks here are all the index positions of reviews that are actually just

75
00:05:42.610 --> 00:05:43.960
empty whitespace.

76
00:05:43.960 --> 00:05:49.170
So we're going to want to drop these index positions as well and we can do that simply by saying DSF

77
00:05:50.140 --> 00:05:55.510
drop and then we're going to pass in that list of index positions those blanks and again we'll say in

78
00:05:55.510 --> 00:05:57.710
place as equal to true.

79
00:05:57.710 --> 00:06:02.810
And if I finally check the length of McLean that data frame it's 1938.

80
00:06:02.870 --> 00:06:09.700
So remember the original data frame if we take a look at it was 2000 but we ended up dropping missing

81
00:06:09.700 --> 00:06:12.830
data as well as dropping empty string data.

82
00:06:12.950 --> 00:06:15.960
And now we finally have our cleaned data frame.

83
00:06:16.060 --> 00:06:21.420
So we're going to do now is go ahead and split the data into a training set and a test set.

84
00:06:22.510 --> 00:06:32.240
We can do this simply by saying from S-K learned model selection import train test split and then we'll

85
00:06:32.240 --> 00:06:44.590
set X equal to the if review and y equal to DSF label and then we call train to split.

86
00:06:44.710 --> 00:06:52.600
And I was just going to do shift type here to scroll down and then copy and paste this X train x test

87
00:06:52.810 --> 00:06:58.710
Y train Y test line and then set that equal to that following.

88
00:06:58.920 --> 00:07:05.430
And then we're going to do person X Y and then if you want it can pass in a test size.

89
00:07:05.540 --> 00:07:13.300
So we'll just use 0.3 or default and then we'll see a random state as an arbitrary number 42.

90
00:07:13.650 --> 00:07:17.240
OK so we just perform our train to split.

91
00:07:17.240 --> 00:07:23.030
Now it's time to actually build a pipeline to vectorize that data then train and fit the model so it

92
00:07:23.030 --> 00:07:35.560
will say as we learn that pipeline import pipeline and then we'll say from S-K learned that feature

93
00:07:35.560 --> 00:07:45.090
extraction text import and here we're just going to use that to effect razor and then we'll save from

94
00:07:45.090 --> 00:07:48.360
S-K learn thought SVM

95
00:07:51.150 --> 00:07:55.330
implore and we'll use a linear support vector classifier.

96
00:07:55.560 --> 00:07:56.770
Then we set up our pipeline.

97
00:07:56.790 --> 00:08:03.030
Just as we saw in previous lectures by creating a pipeline object as a list of tuples of the steps it's

98
00:08:03.040 --> 00:08:08.710
up to you whatever string you want to provide here for naming this particular step will say T.F. idea.

99
00:08:09.070 --> 00:08:12.280
And then we passen an instance of the T.F. idea.

100
00:08:12.280 --> 00:08:14.090
Vectorize or.

101
00:08:14.280 --> 00:08:21.140
And then the next tuple we're going to passen is simply going to be the classifier itself.

102
00:08:21.320 --> 00:08:28.750
We can call it CNF and then we pass an instance of the linear support vector classifier we run that

103
00:08:29.170 --> 00:08:31.900
and then it's time to actually fit the pipeline.

104
00:08:32.760 --> 00:08:39.110
So we say text CNF now we fit this to our training data

105
00:08:42.230 --> 00:08:42.940
we run that.

106
00:08:43.010 --> 00:08:46.020
And again you may get a warning pending on what version of sikat learn you're using.

107
00:08:46.040 --> 00:08:48.610
That's OK for the future warning.

108
00:08:48.800 --> 00:08:56.150
And now it's time to perform predictions so it can say predictions is equal to tech sealife and let's

109
00:08:56.150 --> 00:09:05.300
predict on our test data so we can then compare it to our y data we'll say from S-K learn that metrics

110
00:09:05.990 --> 00:09:14.450
import and we'll import a confusion matrix the classification report and the accuracy score and let's

111
00:09:14.450 --> 00:09:15.740
run all those.

112
00:09:15.760 --> 00:09:21.780
So a confusion matrix pasan our true test values and test them against our predictions.

113
00:09:21.950 --> 00:09:23.630
So you can see we're doing all right here.

114
00:09:23.750 --> 00:09:25.610
Let's go in and check out the classification report.

115
00:09:26.540 --> 00:09:32.430
We'll say print classification report Y test along with the predictions.

116
00:09:32.800 --> 00:09:37.450
And then here we can explore our precision recall an EF 1 score looks like for both classes we're doing

117
00:09:37.570 --> 00:09:44.950
almost the exact same or on 85 percent F 1 score or 0.5 EF 1 score is not really a percentage.

118
00:09:45.340 --> 00:09:48.770
And then all we want to do here is finally point out the accuracy.

119
00:09:48.770 --> 00:09:55.540
So you can print out the accuracy score on why test against the predictions.

120
00:09:55.540 --> 00:09:59.180
And here it looks like we're getting around again 85 percent accuracy.

121
00:09:59.410 --> 00:10:05.620
So we're getting 0.5 for precision recall and accuracy which is pretty amazing given the fact that we're

122
00:10:05.620 --> 00:10:07.650
doing this with just a few lines of code.

123
00:10:07.840 --> 00:10:14.150
And more importantly we're able to do this based off the raw text of the actual review.

124
00:10:14.380 --> 00:10:19.960
So just by reading the raw text we're now able to understand the for review is positive or negative.

125
00:10:20.170 --> 00:10:25.020
So now it could set up our own movie review site that goes through the Internet scrapes text reviews.

126
00:10:25.090 --> 00:10:29.410
We run it through our classifier and then we could tally up and make some sort of percentage across

127
00:10:29.410 --> 00:10:29.900
the Internet.

128
00:10:29.950 --> 00:10:33.080
If this movie was rated positively or negatively.

129
00:10:33.420 --> 00:10:36.860
OK so that's it for this next classification project.

130
00:10:37.000 --> 00:10:41.530
Coming up next we're going to make sure that you fully understand what's going on by giving you a very

131
00:10:41.530 --> 00:10:43.560
similar task for your assessment.

132
00:10:43.600 --> 00:10:49.420
Basically you're going to repeat these similar steps on the movie review to that text file just to make

133
00:10:49.420 --> 00:10:52.760
sure you understand we're going to walk you through it and then we'll go over the solutions.

134
00:10:52.780 --> 00:10:55.930
So we'll see in the next lecture where we have an overview of the assessment.

