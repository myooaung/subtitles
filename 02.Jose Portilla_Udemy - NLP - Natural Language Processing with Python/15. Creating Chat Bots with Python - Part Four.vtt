WEBVTT
ï»¿1
00:00:05.310 --> 00:00:10.770
Welcome back everyone to part four of our Q and A bot with Python 4 Part 4.

2
00:00:10.770 --> 00:00:15.030
We're going to fit and train the network or at least show you how to fit and train the network.

3
00:00:15.030 --> 00:00:16.980
It takes quite a long time to train this network.

4
00:00:17.220 --> 00:00:21.150
So we're going to show you how to train it but then we'll cancel the training and then just show you

5
00:00:21.150 --> 00:00:25.620
how to load the pre train model that we provide for you optionally it's up to you if you want to train

6
00:00:25.620 --> 00:00:28.250
your own model on more epochs and what we did.

7
00:00:28.350 --> 00:00:33.210
We have a model that was trained on one hundred epochs took a bit of time and we have that for you as

8
00:00:33.210 --> 00:00:37.830
an H5 file they can easily load up so we'll show how to train the network will kind of cancel the training

9
00:00:37.860 --> 00:00:42.390
then load up the pre train network if you want you can wait for the training and then we will plot out

10
00:00:42.390 --> 00:00:47.250
the training history and then evaluate on our own test set and then what's really cool is we'll be able

11
00:00:47.250 --> 00:00:52.470
to create our own stories and our own questions and then see if our network is able to answer some simple

12
00:00:52.470 --> 00:00:53.310
questions.

13
00:00:53.370 --> 00:00:57.630
Let's get started by jumping back to the notebook OK.

14
00:00:57.640 --> 00:01:03.110
Recall last time we finished up our model by compiling it and then we have our summary of our model.

15
00:01:03.130 --> 00:01:06.150
Now it's time to fit the model to do this.

16
00:01:06.220 --> 00:01:13.890
We're going to assign a history variable and then we'll say model dot fit and then as a list will pass

17
00:01:13.890 --> 00:01:22.170
in inputs train that we created earlier and then we will say queries train source and see training on

18
00:01:22.170 --> 00:01:27.960
the input stories as well as the input questions the training set ones at least.

19
00:01:27.960 --> 00:01:37.730
And then finally those were our exes and then we'll say answers train is the correct label you pass

20
00:01:37.740 --> 00:01:40.910
in a batch size so let's use a batch size of 32.

21
00:01:40.960 --> 00:01:46.300
This is something you can experiment with smaller batch sizes with longer training epochs should lead

22
00:01:46.630 --> 00:01:47.790
to slightly better results.

23
00:01:47.800 --> 00:01:52.370
But the one we train for was epochs one hundred.

24
00:01:52.400 --> 00:01:55.840
So we train four hundred epochs in the model that we provide for you.

25
00:01:55.880 --> 00:01:57.230
Doesn't take that long to train.

26
00:01:57.230 --> 00:02:02.330
It's about five to 10 seconds per step on a pretty fast graphics card.

27
00:02:02.330 --> 00:02:07.640
But if you're just running this on you it could be a quite a more maybe 30 to 60 seconds per step so

28
00:02:07.640 --> 00:02:11.840
you can imagine for 100 epochs you're looking at six thousand seconds so that's quite a bit of time

29
00:02:13.090 --> 00:02:17.420
we'll go ahead and just show you what this looks like what we'll train for just three epochs.

30
00:02:17.420 --> 00:02:22.340
But again we provide a model for you in fact if you go to the departing folder there is a file called

31
00:02:22.420 --> 00:02:24.490
Chapel underscore 10 that H5.

32
00:02:24.620 --> 00:02:28.670
This is the one hundred epoch model that will load up in just a little bit.

33
00:02:28.720 --> 00:02:33.020
The first illustrate how to train your own model in case you want to train it then we'll say validation

34
00:02:33.170 --> 00:02:35.540
underscored data is equal to.

35
00:02:35.570 --> 00:02:43.440
And here we're going to pass in a tuple with the same format as training data which is input test queries

36
00:02:43.440 --> 00:02:49.230
test and then into this tuple will say answers test.

37
00:02:49.230 --> 00:02:53.220
So let me zoom out here just so you can make sure you get the entire format.

38
00:02:53.300 --> 00:03:00.320
Notice my validation data itself is a tuple here where the first item in the tuple is a list of two

39
00:03:00.320 --> 00:03:02.560
elements the inputs test and the queries test.

40
00:03:02.660 --> 00:03:04.910
And the second item is just answers test.

41
00:03:04.910 --> 00:03:06.980
So go ahead and run this.

42
00:03:06.980 --> 00:03:12.470
Make sure we don't commit any typos and then you should see training on 10000 samples validate on a

43
00:03:12.470 --> 00:03:13.670
thousand samples.

44
00:03:13.670 --> 00:03:17.600
Again this may take a while depending on how fast your computer is.

45
00:03:17.600 --> 00:03:21.410
So right now I'm looking at about eight seconds but I have a really fast GPO.

46
00:03:21.800 --> 00:03:27.350
So if you have a slower CPA or GP you depending on what you're running this on it could take quite a

47
00:03:27.350 --> 00:03:32.390
bit of time and notice accuracy still isn't that good 50 percent which is essentially it's random guessing

48
00:03:32.420 --> 00:03:33.590
yes or no.

49
00:03:33.590 --> 00:03:37.760
And what we're gonna do now is show you how you could evaluate and plot out the training history of

50
00:03:37.760 --> 00:03:41.180
your model and then we'll show you had actually load up the model that we created.

51
00:03:42.080 --> 00:03:48.230
So if you wanted to plot out your training history I'm going to copy and paste the code that we provided

52
00:03:48.230 --> 00:03:51.440
for you inside of our provided notebook.

53
00:03:51.500 --> 00:03:57.920
So as a quick note if you open up our provided notebook right after this training step there's a saving

54
00:03:57.920 --> 00:03:58.920
the model step.

55
00:03:59.090 --> 00:04:02.780
I would not recommend overwriting the model that we created for you.

56
00:04:02.780 --> 00:04:05.160
And then there's a plotting out training history.

57
00:04:05.210 --> 00:04:09.680
This is essentially just a bunch of map plot lib code which gives you a nice little plot like this.

58
00:04:09.680 --> 00:04:14.420
It's actually pretty straightforward we just plot out the history of the accuracy for the training set

59
00:04:14.540 --> 00:04:17.250
as well as our validation accuracy for the test set.

60
00:04:17.270 --> 00:04:21.730
So I'm just going to copy and paste this code.

61
00:04:21.780 --> 00:04:25.000
So it's essentially just a bunch of title calls and plot calls.

62
00:04:25.000 --> 00:04:27.320
So going to copy that.

63
00:04:27.400 --> 00:04:33.110
So again copying it and then pasting it right here and let's go ahead and run that.

64
00:04:33.130 --> 00:04:38.560
Remember we only trained for three epochs so it's gonna be kind of not a very impressive chart.

65
00:04:38.770 --> 00:04:44.560
So this is on the first epoch or essentially where it started the first epoch and then the second epoch.

66
00:04:44.560 --> 00:04:49.360
So not a whole lot of information here but as you train for more and more epochs for example I'll go

67
00:04:49.360 --> 00:04:56.320
ahead and retrain for a ten epochs and then plot this out again while we wait for these tiny epochs

68
00:04:56.320 --> 00:05:01.750
let me explain what's going on here in this plotting line we're importing my public SPL BLT we saying

69
00:05:01.780 --> 00:05:06.790
map published lib in line in order to see the chart in line in this notebook the most recent version

70
00:05:06.790 --> 00:05:10.600
of Jupiter no longer requires this but just the case you're using an older version I put it in there

71
00:05:11.110 --> 00:05:16.390
and then I printed out the history that history donkey's history the history keys there's essentially

72
00:05:16.870 --> 00:05:22.270
four items returned back and it's your validation loss validation accuracy and then your training loss

73
00:05:22.330 --> 00:05:27.580
and trainee accuracy so sometimes you'll see people plot out the loss sometimes you'll see people plot

74
00:05:27.580 --> 00:05:32.650
out the accuracy they're essentially in versus of each other right you're trying to either increase

75
00:05:32.650 --> 00:05:37.880
your accuracy or reduce your loss depending on how you're thinking about the training.

76
00:05:37.960 --> 00:05:45.150
So here we can see kind of a more realistic beginning of the curve that are more epochs or certainly

77
00:05:45.160 --> 00:05:46.630
get better accuracy.

78
00:05:46.630 --> 00:05:51.930
So after ten epochs we can see our accuracy is slowly improving again it makes sense that our default

79
00:05:51.940 --> 00:05:57.280
accuracy starts off at 50 percent because the correct answers are either only yes or no.

80
00:05:57.280 --> 00:06:02.020
So even in totally untrained neural network you get about 50 percent accuracy if you just randomly guessing

81
00:06:02.050 --> 00:06:07.900
yes or no depending on some random initialization of those weights you'll be correct about 50 percent

82
00:06:07.900 --> 00:06:13.030
of the time and then off of this we're just plotting history accuracy history validation accuracy for

83
00:06:13.030 --> 00:06:18.310
those keys and if you wanted to you don't have to plot train and test but it should apply to kind of

84
00:06:18.310 --> 00:06:23.870
see the point at where you're no longer getting any improvement on your test data.

85
00:06:23.870 --> 00:06:28.810
And for my particular program that happened around 40 epochs so maybe training for a hundred epochs

86
00:06:29.110 --> 00:06:34.660
isn't even that useful since you should get results that are pretty darn good around maybe 80 percent

87
00:06:34.660 --> 00:06:37.680
accuracy area test set around the 50 epoch Mark.

88
00:06:37.750 --> 00:06:37.990
All right.

89
00:06:38.470 --> 00:06:45.760
So if you wanted to save this model all you need to do is say model that save and choose some sort of

90
00:06:45.760 --> 00:06:46.300
file path.

91
00:06:46.300 --> 00:06:50.830
So my brand new model dot H5.

92
00:06:50.920 --> 00:06:56.540
So that would say this H5 waits under whatever you just trained up here.

93
00:06:56.620 --> 00:07:01.080
Now in our case we're going to use the model that we've already trained for you.

94
00:07:01.240 --> 00:07:02.560
And again that is the chapel.

95
00:07:02.590 --> 00:07:04.160
Underscore ten dot H five.

96
00:07:04.240 --> 00:07:16.520
So I'm going to load up that model so I will say model that load weights and against called Chaput underscore

97
00:07:16.570 --> 00:07:17.330
that H5.

98
00:07:17.520 --> 00:07:23.230
You have to be in the correct notebook if you want you could just pass an entire file path to this H5

99
00:07:23.230 --> 00:07:23.590
folder.

100
00:07:23.620 --> 00:07:27.790
But I recommend running this inside the deep learning folder so you don't get any errors.

101
00:07:27.790 --> 00:07:29.260
So go ahead and load those weights.

102
00:07:29.260 --> 00:07:33.730
Now you have our hundred epoch trained model and then we're going to use this to evaluate on the given

103
00:07:33.730 --> 00:07:34.780
test set.

104
00:07:34.780 --> 00:07:40.790
So we want to do is want to predict results for the input test and the queries test so we'll say predicted.

105
00:07:40.810 --> 00:07:43.810
Let me zoom in here so we can see the code a little better.

106
00:07:43.810 --> 00:07:52.240
We'll say predicted results or pred results is equal to model that predict and as a tuple that has two

107
00:07:52.240 --> 00:07:57.940
inputs the first input is inputs test and then the second item.

108
00:07:57.940 --> 00:08:01.570
It's actually in this list is queries underscore a test.

109
00:08:01.570 --> 00:08:09.190
So here I have a tuple of a single item where the single item is a list of two items inputs test and

110
00:08:09.190 --> 00:08:10.270
queries test.

111
00:08:10.270 --> 00:08:16.210
It makes sense that I no longer pass in answers because I'm trying to predict based off my test set.

112
00:08:16.210 --> 00:08:20.890
I don't want to pass on answers nor do I have a need to because I'm not predicting answers based off

113
00:08:20.890 --> 00:08:21.430
the test set.

114
00:08:21.850 --> 00:08:26.950
So again if you want to predict based off new stories new questions you simply call the predict method

115
00:08:26.950 --> 00:08:32.640
off your model and then using this formatting you pass in a new story and a new set of questions and

116
00:08:32.640 --> 00:08:36.190
we'll show you how to write your own stories on questions in just a little bit.

117
00:08:36.460 --> 00:08:37.580
So go ahead and run that.

118
00:08:37.690 --> 00:08:40.480
It should predict some results for you.

119
00:08:40.540 --> 00:08:41.950
Remember our test data.

120
00:08:42.100 --> 00:08:45.310
If we take a look at it it's essentially I run this whole thing.

121
00:08:45.400 --> 00:08:47.820
It's tuples right where we have the story.

122
00:08:48.040 --> 00:08:53.980
The question and then the answer so I can take a look at the first story here and says Mary got the

123
00:08:53.980 --> 00:08:55.140
milk there.

124
00:08:55.300 --> 00:08:58.590
John moved to the bedroom and is going to ask something like where's John.

125
00:08:58.930 --> 00:09:03.510
So we're going to do now is generate the prediction from the actual model.

126
00:09:03.520 --> 00:09:08.320
So if I take a look at the pred results is essentially just a bunch of probabilities.

127
00:09:08.320 --> 00:09:12.400
Notice that it actually has probabilities for every single word.

128
00:09:12.460 --> 00:09:16.790
So I check the shape of this it's 1000 by 38.

129
00:09:16.810 --> 00:09:23.110
So we have thirty seven vocab words plus one extra for padding and then we had 1000 Test stories test

130
00:09:23.110 --> 00:09:24.750
questions and test answers.

131
00:09:24.790 --> 00:09:32.110
So if I take a look at the very first one here ups make sure we grab zero off predict the results.

132
00:09:32.130 --> 00:09:35.380
These are the probabilities for every single vocab words.

133
00:09:35.460 --> 00:09:41.130
It makes sense that the probabilities for random words like John and moved based off the token a or

134
00:09:41.130 --> 00:09:45.960
word index should be extremely low because we wouldn't expect the correct answer to be something like

135
00:09:46.050 --> 00:09:51.450
milk to a question of is John in the kitchen which is the question that goes along with this first test

136
00:09:51.450 --> 00:09:52.490
dataset.

137
00:09:52.500 --> 00:09:58.380
So we're gonna do is we're then going to perform ARG Max in order to figure out which of these words

138
00:09:58.380 --> 00:10:01.020
has the max probability and it should be either yes or no.

139
00:10:01.650 --> 00:10:07.910
So the way we can generate a prediction directly of yes or no we're just going to say my max value essentially

140
00:10:07.950 --> 00:10:14.600
the max probability is equal to FP ARG Max of predicted results.

141
00:10:14.630 --> 00:10:19.750
Let's go ahead and just do the first one so I'm actually gonna print out everything for the first test

142
00:10:19.750 --> 00:10:20.050
data.

143
00:10:20.620 --> 00:10:21.580
So say test data.

144
00:10:21.580 --> 00:10:22.650
Mary got the milk there.

145
00:10:22.660 --> 00:10:24.900
John moved to the bedroom.

146
00:10:24.960 --> 00:10:30.850
The question was Is John in the kitchen and then the correct answer was No.

147
00:10:30.850 --> 00:10:31.400
He is not.

148
00:10:31.400 --> 00:10:32.290
He moves to the bedroom.

149
00:10:32.310 --> 00:10:33.110
Right.

150
00:10:33.170 --> 00:10:39.050
So let's go ahead and see what the prediction was based off this first prediction results.

151
00:10:39.050 --> 00:10:41.220
So I have my VAX maximum value.

152
00:10:41.360 --> 00:10:51.510
And then what I can do here is simply say for key val and took a nicer word index items.

153
00:10:51.640 --> 00:10:59.260
No word index items essentially just the the word index and the word itself will say if vow is equal

154
00:10:59.260 --> 00:11:05.510
to Val Max K's equal the key essentially just searching for the word.

155
00:11:05.630 --> 00:11:09.870
And then once you run that if you go ahead and just print out k it should tell you know as long as you

156
00:11:09.870 --> 00:11:13.690
trained it enough epochs because it's asking us is John in the kitchen.

157
00:11:13.730 --> 00:11:14.560
It's no.

158
00:11:14.570 --> 00:11:22.010
We can also check how sure it is of this by simply grabbing the predicted results at that in the exposition

159
00:11:22.100 --> 00:11:28.970
of zero and then calling Val underscore Max is essentially going to return back to direct probability

160
00:11:28.970 --> 00:11:31.330
that we saw up here.

161
00:11:31.640 --> 00:11:36.530
So we're gonna run this and now we can see the model is ninety nine point nine percent sure that John

162
00:11:36.590 --> 00:11:38.300
isn't in the kitchen.

163
00:11:38.300 --> 00:11:38.650
All right.

164
00:11:39.020 --> 00:11:43.340
So now comes the really cool part where we're going to write our own stories and questions and then

165
00:11:43.430 --> 00:11:45.350
run them through the actual model

166
00:11:48.100 --> 00:11:53.050
something you're going to need to be aware of as you're doing this is recall we have a set vocabulary

167
00:11:54.490 --> 00:11:59.090
so if I say vocab these are the only words that my model is aware of.

168
00:11:59.170 --> 00:12:03.580
Which means these are the only words I can use for testing the model.

169
00:12:03.580 --> 00:12:07.630
I can't write in proper names or other verbs that it won't understand.

170
00:12:07.660 --> 00:12:10.370
So keep that in mind as you're writing your own stories.

171
00:12:10.420 --> 00:12:15.310
You're going to have to not only format it in the correct way but be limited to the vocabulary that

172
00:12:15.310 --> 00:12:16.720
our network was trained on.

173
00:12:16.780 --> 00:12:21.340
You can't do things like was hose a in the Super Bowl or something like that because it doesn't know

174
00:12:21.340 --> 00:12:24.690
what Hosey is this note the Super Bowl is et cetera.

175
00:12:24.700 --> 00:12:27.250
So let's go ahead and create a story first.

176
00:12:27.340 --> 00:12:34.530
So I will say the following I will say my story and I was going to type this out as a string and something

177
00:12:34.540 --> 00:12:40.090
we're also going to have to do is keep a space in between punctuation as I'm not sure what I mean by

178
00:12:40.090 --> 00:12:40.750
that.

179
00:12:40.840 --> 00:12:47.110
We're going to say Jon left the kitchen space period.

180
00:12:47.260 --> 00:12:53.630
Space Sandra dropped and then you can look for any object here.

181
00:12:53.640 --> 00:12:54.710
I see we have football.

182
00:12:54.720 --> 00:12:58.150
So we'll go ahead and drop the football and we'll drop it in the garden.

183
00:12:58.710 --> 00:13:07.800
So say Sandra dropped the football in the garden space period.

184
00:13:07.980 --> 00:13:13.410
And the reason we have these spaces after the period is because right after this.

185
00:13:13.410 --> 00:13:16.980
I want to make sure my story is in the same format as what it was trained on.

186
00:13:17.120 --> 00:13:22.380
And recall our test data is a list here where the punctuation is separated.

187
00:13:22.380 --> 00:13:28.560
So all I need to do is say the following we will say my story and then we just need to split it.

188
00:13:29.250 --> 00:13:31.380
So let's go ahead and do that.

189
00:13:31.470 --> 00:13:37.400
We will say my underscore story and then call that split.

190
00:13:37.640 --> 00:13:42.860
And here we can see my story is now basically in the same sort of formatting that the test data was

191
00:13:42.860 --> 00:13:52.670
in or the training data then we'll create one more for my question and we'll say my underscore question

192
00:13:53.360 --> 00:14:02.730
is equal to and let's ask about that football will say is the football in the garden space question

193
00:14:02.730 --> 00:14:07.380
mark and recall that the question should also be split for the formatting.

194
00:14:07.380 --> 00:14:13.290
So if we come back here and look at our original training data remember these questions for the test

195
00:14:13.290 --> 00:14:16.310
data and the training data are also a list of all the words.

196
00:14:16.440 --> 00:14:17.870
So we'll do the same thing here.

197
00:14:17.960 --> 00:14:24.110
We'll say my question that split and we'll see that this is the format we need the question is.

198
00:14:24.280 --> 00:14:27.450
So let's create a brand new dataset of just one single story.

199
00:14:27.490 --> 00:14:32.880
One single question and then also a single answer and we'll pass it into our vector rise data function.

200
00:14:33.010 --> 00:14:38.500
So we'll say my data is equal to and this is exactly what you would need to do if you wanted to expand

201
00:14:38.500 --> 00:14:40.400
your training set or your test set.

202
00:14:40.450 --> 00:14:46.240
You could hire somebody or you yourself could create new stories new questions and then correct answers.

203
00:14:46.240 --> 00:14:51.610
So the way it's going to work is we're simply going to make a list because remember our training data

204
00:14:51.610 --> 00:14:54.230
was just a list of three item tuples.

205
00:14:54.400 --> 00:15:02.830
So here is just going to be one tuple where it's my story that split it's my question thought split

206
00:15:03.870 --> 00:15:07.220
and then the correct answer in this case is the football in the garden.

207
00:15:07.230 --> 00:15:11.070
Well it is because Sandra dropped the football in the garden so we'll say the answer is yes.

208
00:15:12.090 --> 00:15:18.210
OK so now we have a data set which is in the exact same format of my original training data and my original

209
00:15:18.210 --> 00:15:23.610
test data except this time is just one single set of question or story question and answer.

210
00:15:23.610 --> 00:15:27.060
It's not a bunch of them as the training data was or the test data was.

211
00:15:27.270 --> 00:15:32.840
So I have my data in the exact same format as expected by the victories story function.

212
00:15:32.840 --> 00:15:33.230
No.

213
00:15:33.690 --> 00:15:36.060
We create a function earlier that vector I stories.

214
00:15:36.150 --> 00:15:43.340
So all I'm going to do is pass in my data here and I'm going to impact this to be my story my quests

215
00:15:44.180 --> 00:15:51.710
and my aunts for my answer run that and I have a vector res version of my story so if you check out

216
00:15:51.710 --> 00:15:55.710
my story here it's now been victimized with some padding here.

217
00:15:55.880 --> 00:16:02.370
It's the same thing for my question and the same thing for my answer.

218
00:16:02.390 --> 00:16:03.930
So this is all ready to go.

219
00:16:03.950 --> 00:16:09.700
Now what I want to do is call the model and predict only off my story and my question.

220
00:16:09.740 --> 00:16:13.310
So just as before we're just going to copy and paste what we did earlier.

221
00:16:13.310 --> 00:16:18.470
So you can always predict on a new set of data just as you predicted on the test set will come back

222
00:16:18.470 --> 00:16:22.950
here and call pred results is modeled up predict.

223
00:16:23.030 --> 00:16:28.040
So I'm going to copy this and in machine learning again the way you predict on your data is the same

224
00:16:28.040 --> 00:16:29.870
we predicted on the test data.

225
00:16:29.870 --> 00:16:35.300
So here we are calling to call a model that predict except this time instead of inputs test and queries

226
00:16:35.300 --> 00:16:36.500
test all Pessin

227
00:16:39.680 --> 00:16:47.970
my story and my question and now I have the predicted results just for that single story and just for

228
00:16:47.970 --> 00:16:55.290
that single question let's go ahead and copy and paste what we also said here which was just that Max

229
00:16:55.410 --> 00:16:57.600
is NPR predicted results.

230
00:16:59.590 --> 00:17:04.210
Remember predictive results has not been changed to only my story my question and right now we're just

231
00:17:04.210 --> 00:17:11.420
looking to predict the results of the first item will come back down here and run this.

232
00:17:11.830 --> 00:17:13.290
Check out what case.

233
00:17:13.420 --> 00:17:15.130
And we say K is yes.

234
00:17:15.160 --> 00:17:20.490
So we have a model that predicted correctly amazingly on our own story on our own question.

235
00:17:20.500 --> 00:17:23.940
I hope you realize just how basically freaking awesome this is.

236
00:17:24.010 --> 00:17:29.080
You can write your own stories your own questions within the limitations the vocabulary and the model

237
00:17:29.320 --> 00:17:35.170
with pretty good accuracy is going to respond correctly to a lot of these questions that you create

238
00:17:35.290 --> 00:17:36.340
for yourself.

239
00:17:36.400 --> 00:17:41.090
So if you want to figure out how sure it was you simply need to say predict the results.

240
00:17:41.140 --> 00:17:50.460
0 at the maximum value and what's predicted results plural and you can see that it was around ninety

241
00:17:50.460 --> 00:17:56.030
nine point two percent sure that it was the correct answer yes.

242
00:17:56.160 --> 00:18:01.320
All right I hope you enjoyed this exercise for creating our own chat bots and I would love to see how

243
00:18:01.320 --> 00:18:06.210
you can expand this to your own stories and your own datasets for your own problems either for your

244
00:18:06.210 --> 00:18:07.910
own projects or work.

245
00:18:07.980 --> 00:18:09.420
Thanks and we'll see you there.

