WEBVTT
1
00:00:05.570 --> 00:00:12.320
Welcome to lecture discussing machine learning of Sparke Sparke has its own M-L live for machine learning

2
00:00:12.320 --> 00:00:15.370
and Emma live just stands for a machine learning library.

3
00:00:15.380 --> 00:00:21.410
The future of M-L lib utilizes the spark 2.0 data framed syntax which we just learned about in this

4
00:00:21.410 --> 00:00:22.340
course.

5
00:00:22.340 --> 00:00:27.250
Now it used to focus on the ARDE decent tax cuts that older Spark's syntax.

6
00:00:27.350 --> 00:00:30.910
But the main focus is using SPARC 2.0.

7
00:00:30.990 --> 00:00:36.200
French syntax and if you visit the documentation page it will actually tell you that the RTT syntax

8
00:00:36.200 --> 00:00:39.850
is outdated and eventually it's no longer going to be supported or updated.

9
00:00:41.330 --> 00:00:46.700
So one of the main quirks when dealing with the M-L lib machine learning library is that you need a

10
00:00:46.700 --> 00:00:52.610
form at your data so eventually it just has one or two columns and if using a supervised learning algorithm

11
00:00:52.970 --> 00:00:56.690
the two columns are going to be features and labels unsupervised.

12
00:00:56.700 --> 00:00:58.370
It's just the features column.

13
00:00:58.370 --> 00:01:02.870
Basically what that means is if you have a data set with a ton of feature columns you eventually need

14
00:01:02.870 --> 00:01:09.080
to condense those all down to just a singular column where each entry in that single column so the rows

15
00:01:09.380 --> 00:01:14.270
is actually just an array consisting of all those old entries and that will make a lot more sense when

16
00:01:14.270 --> 00:01:15.750
we actually show you how to do that.

17
00:01:15.890 --> 00:01:21.440
But I think personally speaking at this point in time one of the documentation's weak points is showing

18
00:01:21.440 --> 00:01:27.340
you how to go through that process of turning realistic data into a just same features column.

19
00:01:27.380 --> 00:01:30.600
But we definitely focus on that process in the beginning of this course.

20
00:01:30.620 --> 00:01:33.150
As far as the machine learning section.

21
00:01:33.340 --> 00:01:38.530
So overall this requires a little more data processing work than some other machine learning libraries.

22
00:01:38.620 --> 00:01:43.600
But the big upside and the whole reason for all this data processing work is that that exact same since

23
00:01:43.600 --> 00:01:45.710
tax will work with the treated data.

24
00:01:45.760 --> 00:01:50.800
So if you have a huge dataset you don't need to learn a new syntax for it so that's no small feat for

25
00:01:50.800 --> 00:01:53.630
what's actually going on under the hood with Peifer and SPARC.

26
00:01:53.650 --> 00:01:57.640
It just requires you to put in a little more work with data processing and we're going to show you how

27
00:01:57.640 --> 00:02:02.920
to make that kind of an easy task with different vector indexers throughout the rest of the machine

28
00:02:02.920 --> 00:02:05.570
learning half of the course but I'm getting ahead of myself.

29
00:02:05.570 --> 00:02:12.350
We'll see they're all when we talk about the code when working with Python and Sparc and the Lib documentation

30
00:02:12.350 --> 00:02:14.930
examples are always with nicely formatted data.

31
00:02:15.110 --> 00:02:20.060
However after we show a documentation example of how to work with the machine learning algorithm we're

32
00:02:20.060 --> 00:02:23.950
going to have our own custom examples to have mesir more realistic data to work with.

33
00:02:24.920 --> 00:02:30.320
And will also have the consulting projects which set you loose on a real world data project with a data

34
00:02:30.320 --> 00:02:34.340
set and a problem to solve a explicitly telling you what to do is step by step.

35
00:02:34.340 --> 00:02:39.420
So I think you'll have a lot of enjoyment and fun getting to work on a more realistic scenario.

36
00:02:40.860 --> 00:02:41.220
All right.

37
00:02:41.250 --> 00:02:46.470
A huge part of learning M-L lib is getting comfortable with the documentation being able to master the

38
00:02:46.470 --> 00:02:52.020
skill of finding information not just memorizing it is really the key to becoming a great spark in Python

39
00:02:52.020 --> 00:02:52.850
developer.

40
00:02:53.070 --> 00:02:58.620
Fortunately the spark M-L lib documentation is actually quite good and will constantly teach you how

41
00:02:58.620 --> 00:02:59.640
to refer to it.

42
00:02:59.670 --> 00:03:01.720
Each machine learning algorithm section.

43
00:03:01.890 --> 00:03:05.970
I think just one of the weak points is if you're totally new to it it may be a little hard to discover

44
00:03:06.150 --> 00:03:10.080
what you're looking for but overall the documentation is quite clear.

45
00:03:10.080 --> 00:03:14.360
It has lots of examples and all those examples come when you download Sparke.

46
00:03:14.430 --> 00:03:17.700
So let's jump to the documentation now and kind of teach you how to navigate it.

47
00:03:17.850 --> 00:03:21.300
So the link you want to visit is that sparked that Apache that org.

48
00:03:21.360 --> 00:03:23.330
I'll show you the lay of the land for the navigation.

49
00:03:23.340 --> 00:03:25.690
I'm going to hop over there right now in my own browser.

50
00:03:26.860 --> 00:03:30.320
So this is what the home page for Sparc for Apache that org looks like.

51
00:03:30.320 --> 00:03:36.750
Now we're going to select the documentation and go to latest release sparked 2.1 and then there is a

52
00:03:36.750 --> 00:03:38.180
basic spark overview.

53
00:03:38.370 --> 00:03:43.250
But we really want the M-L lib so we come down here and go to MLA for machine learning.

54
00:03:43.260 --> 00:03:47.000
You basically know everything that you need to know about the frame's datasets and sequel.

55
00:03:47.160 --> 00:03:48.760
So hop straight to machine learning.

56
00:03:49.050 --> 00:03:53.530
And here we have the machine learning M-L lib guide and it says an announcement that the data frame

57
00:03:53.550 --> 00:03:55.630
based the API is the primary API.

58
00:03:55.710 --> 00:03:58.520
Zoom in C see this a little better.

59
00:03:58.560 --> 00:04:03.930
So again the RTD based API is now in maintenance mode but that's no problem for us because we just focused

60
00:04:03.930 --> 00:04:06.630
a lot of our energy into learning data frame's really well.

61
00:04:06.630 --> 00:04:09.060
So we have no problem with the data from API.

62
00:04:09.240 --> 00:04:10.400
And this is it right here.

63
00:04:10.410 --> 00:04:12.320
The main guide for M-L lib.

64
00:04:12.540 --> 00:04:18.450
So there's a lot to focus on here and we'll touch on this often we're actually learning how to work

65
00:04:18.450 --> 00:04:22.470
with different algorithms but I just want to guide you through everything that's here.

66
00:04:22.470 --> 00:04:26.460
So we'll start actually with classification and regression which is going to be one of the first things

67
00:04:26.460 --> 00:04:27.660
we actually visit here.

68
00:04:27.870 --> 00:04:32.670
So classification and regression has a table of contents and basically it shows you all the algorithms

69
00:04:32.670 --> 00:04:37.550
available for classification tasks as well as all the algorithms available for regression tests.

70
00:04:37.650 --> 00:04:41.640
And then it talks a little more about decision trees and tree ensembles and we will discuss things like

71
00:04:41.680 --> 00:04:43.850
in the forest gradient boosting trees et cetera.

72
00:04:44.010 --> 00:04:47.430
But when you click on these let's say you want to deal with basically the regression when the first

73
00:04:47.430 --> 00:04:52.860
things we'll learn about in this course come down here and it shows you a basic idea of linear regression

74
00:04:52.950 --> 00:04:54.300
and then an example.

75
00:04:54.600 --> 00:04:59.370
And if you click here on Python This has the Python code and will actually walk through this for every

76
00:04:59.370 --> 00:05:03.720
algorithm we teach in this course will walk through the basic documentation example.

77
00:05:03.720 --> 00:05:06.590
So essentially you just import the model.

78
00:05:06.690 --> 00:05:10.680
You have your training data and the training data for these documentation examples is always nicely

79
00:05:10.680 --> 00:05:11.480
formatted.

80
00:05:11.550 --> 00:05:15.180
We'll show you some other examples where you have to deal with messier or illusory data.

81
00:05:15.330 --> 00:05:20.640
You create an instance in the model you train the model and then you call various things on your model

82
00:05:20.700 --> 00:05:24.810
against some sort of testing or here they're actually doing the training set but we'll discuss that

83
00:05:24.810 --> 00:05:26.880
later and you evaluate your model.

84
00:05:26.880 --> 00:05:31.170
So these are pretty simple examples but it's nice to go through them because it gives you an idea of

85
00:05:31.170 --> 00:05:35.450
the basic workflow when dealing with PI sparks M-L libraries.

86
00:05:35.550 --> 00:05:41.200
So scrolling back up you can see all the various examples here and also show you a little bit of background.

87
00:05:41.280 --> 00:05:43.890
It also has some useful links for more information.

88
00:05:43.890 --> 00:05:46.890
So that's the basic idea behind classification and regression.

89
00:05:46.920 --> 00:05:48.460
There's also the clustering section.

90
00:05:48.630 --> 00:05:53.160
Now if you're looking for an algorithm for classification and it's not listed here then most likely

91
00:05:53.190 --> 00:05:54.410
it's just not supported yet.

92
00:05:54.450 --> 00:05:56.700
And Python and Sparke So keep that in mind.

93
00:05:56.970 --> 00:06:00.960
And then we're going to come over here click on clustering and we can see the various clustering algorithms

94
00:06:00.960 --> 00:06:02.110
that are available to us.

95
00:06:02.310 --> 00:06:03.980
Not a whole lot of selection here.

96
00:06:03.980 --> 00:06:06.830
Basically k means LPA bisecting k means.

97
00:06:06.840 --> 00:06:11.490
And then this Gaussian mixture model will really focus on K means because that's the most common one

98
00:06:11.490 --> 00:06:11.970
used.

99
00:06:12.030 --> 00:06:17.070
And it's also once you know one of them you basically know all of them collaborative filtering.

100
00:06:17.100 --> 00:06:19.680
We're going to be using that for a recommender system.

101
00:06:19.680 --> 00:06:24.210
So keep that in mind as we continue on towards the end of the course we discuss recommender system will

102
00:06:24.210 --> 00:06:26.060
use collaborative filtering for that.

103
00:06:26.160 --> 00:06:29.670
Then there's extracting transforming and selecting features.

104
00:06:29.670 --> 00:06:34.110
This is actually a really important page here and it's something we're going to visit often but basically

105
00:06:34.170 --> 00:06:40.350
this is going to allow you to convert your data sets into a format that's easily readable by the machine

106
00:06:40.350 --> 00:06:43.020
learning libraries that Matlab has.

107
00:06:43.020 --> 00:06:47.220
So a lot of the things we're going to be working with are things like vector indexers indexes string

108
00:06:47.460 --> 00:06:52.770
the string lexer etc. and there are a lot of things here for dealing with natural language processing

109
00:06:53.160 --> 00:06:54.930
like tokenizer stopwatches remover.

110
00:06:54.930 --> 00:06:57.360
And we're going to talk about all of that later on in the course.

111
00:06:57.360 --> 00:07:02.690
But keep this page in mind whenever we're dealing with things like transforming features.

112
00:07:02.840 --> 00:07:06.460
And if you click on one of these just to show you quickly for instance vector indexer.

113
00:07:06.620 --> 00:07:10.760
You go down it gives you a description of what it was click on the Python tab and it shows you a quick

114
00:07:10.760 --> 00:07:12.020
example of how to use it.

115
00:07:12.280 --> 00:07:13.730
So scrolling all the way back up.

116
00:07:13.730 --> 00:07:15.970
Lots of examples there which is really nice.

117
00:07:15.980 --> 00:07:16.850
Then there's pipeline's.

118
00:07:16.850 --> 00:07:17.990
We'll discuss that later on.

119
00:07:17.990 --> 00:07:20.980
The pipelines are basically a way to kind of set a bunch of stuff.

120
00:07:20.990 --> 00:07:25.970
So once you have the steps you put it all in a pipeline and you don't have to manually write out all

121
00:07:25.970 --> 00:07:29.240
those singular steps anymore and we'll discuss that later on the course.

122
00:07:29.470 --> 00:07:29.830
OK.

123
00:07:29.840 --> 00:07:35.210
There's also some things about model selection and tuning which we'll briefly mention we'll do the train

124
00:07:35.210 --> 00:07:39.930
test splits herself and there's also things like advanced topics we won't really touch in on these.

125
00:07:40.070 --> 00:07:44.930
And in fact for most use cases you really shouldn't be messing around with these sort of things.

126
00:07:44.930 --> 00:07:48.340
This is kind of way beyond the scope of this course.

127
00:07:48.350 --> 00:07:53.840
So again it's really for hardcore developers as far as itemization of these linear method so don't worry

128
00:07:53.840 --> 00:07:55.690
too much about these advanced topics.

129
00:07:55.700 --> 00:07:59.780
The last thing I want to mention is how you actually get the API docs if you really want to dive deep

130
00:07:59.780 --> 00:08:06.710
into something you click here on a paradox hit Python and it will take you to the API page.

131
00:08:06.770 --> 00:08:11.360
So if you ever want to dive into what's really available for a certain price spark call you come over

132
00:08:11.360 --> 00:08:11.890
here.

133
00:08:12.050 --> 00:08:14.870
So for instance we see PI Sparke Amlet package.

134
00:08:14.870 --> 00:08:16.280
Let's click on regression.

135
00:08:16.340 --> 00:08:17.970
I'll zoom in a little more here.

136
00:08:18.050 --> 00:08:23.960
So we hit on regression really any of these and I'll show you the regression model of the API and then

137
00:08:23.960 --> 00:08:30.080
it shows you everything that's available for these models as well as some more in-depth tutorials or

138
00:08:30.300 --> 00:08:34.660
not really tutorials but just code examples here as well as the methods or attributes available.

139
00:08:34.700 --> 00:08:38.030
So this is the API for everything that's available to you.

140
00:08:38.030 --> 00:08:42.890
And I definitely recommend kind of diving into these things when you feel more comfortable with the

141
00:08:42.890 --> 00:08:44.690
basics of paice Mark.

142
00:08:44.690 --> 00:08:45.180
All right.

143
00:08:45.290 --> 00:08:47.660
That's really all we need to know right now for the documentation.

144
00:08:47.660 --> 00:08:51.320
It's definitely a great skill to have to feel comfortable clicking around documentation.

145
00:08:51.320 --> 00:08:55.400
Navigating it and finding information on your own and will definitely guide you through that process

146
00:08:55.400 --> 00:08:56.930
throughout the rest of the course.

147
00:08:56.930 --> 00:08:57.320
All right.

148
00:08:57.530 --> 00:09:00.910
I hope you're really excited to begin learning machine learning with Python and SPARC.

149
00:09:00.920 --> 00:09:04.340
It's a really powerful tool to have and I can't wait to teach it to you.
