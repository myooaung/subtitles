1
00:00:05,880 --> 00:00:12,050
Hello everyone and welcome to the documentation example lecture for the logistic regression section.

2
00:00:12,220 --> 00:00:16,680
We're going to do is quickly walk through the documentation logistic regression example.

3
00:00:16,670 --> 00:00:21,620
In reviewing this lecture as well as the previous lectures you should begin to pick up on Spark's general

4
00:00:21,620 --> 00:00:27,250
pattern and workflow for using machine learning with sparks and Python's M-L lib library.

5
00:00:27,410 --> 00:00:32,270
Regardless if you're doing a classification task or a regression task the general workflow for this

6
00:00:32,270 --> 00:00:34,310
lecture should become clear to you.

7
00:00:35,410 --> 00:00:41,110
But we're also going to do is introduce the concept of evaluators evaluators behaves similar to machine

8
00:00:41,110 --> 00:00:46,300
learning algorithm objects that are designed to take any evaluation data frames that is data frames

9
00:00:46,300 --> 00:00:51,820
that are produced when we run things like model thought evaluate on some test data set that produces

10
00:00:51,820 --> 00:00:56,890
an evaluation data frame that has that prediction column and this evaluator object is going to be able

11
00:00:56,890 --> 00:01:01,630
to take in that object and that what we can call metrics off of it and we'll explain that when we actually

12
00:01:01,630 --> 00:01:04,860
see the coded example as a quick note.

13
00:01:04,990 --> 00:01:09,880
If you read the documentation evaluators are still technically labeled as experimental.

14
00:01:10,090 --> 00:01:13,180
So you should use caution when using them for production code.

15
00:01:13,180 --> 00:01:18,580
However they have been around and part of SPARC since version 1.4 and at this time in filming the latest

16
00:01:18,580 --> 00:01:20,250
version of Sparke is 2.1.

17
00:01:20,410 --> 00:01:22,860
So you can assume they have some stability to them.

18
00:01:22,930 --> 00:01:26,250
However you definitely use caution there label experimental for a reason.

19
00:01:26,290 --> 00:01:28,410
So keep that in mind.

20
00:01:28,520 --> 00:01:32,780
The files we're going to be using for this lecture are a logistic regression example the IPY and be

21
00:01:32,780 --> 00:01:38,960
for the notebook and sample it SVM underscored data that text or the actual data look under the logistic

22
00:01:38,960 --> 00:01:44,330
regression folder under the machine learning folder her access to these files and all inks we show can

23
00:01:44,330 --> 00:01:47,580
be found inside that notebook OK.

24
00:01:47,750 --> 00:01:51,680
Let's get started in a brand new notebook and also have some links open and new types.

25
00:01:51,690 --> 00:01:54,050
We're going to visit throughout this lecture.

26
00:01:54,050 --> 00:01:58,820
All right here we have the logistic regression folder open under sparker machine learning and you can

27
00:01:58,820 --> 00:02:02,520
see here we have the logistic regression code along that's going to be the next lecture.

28
00:02:02,600 --> 00:02:07,190
The consulting project the consulting project solutions and the example which is exactly the notebook

29
00:02:07,190 --> 00:02:08,340
we're using right now.

30
00:02:08,340 --> 00:02:11,350
So if you click on that you should see an output that looks like this.

31
00:02:11,360 --> 00:02:15,680
This is all the codes and all the links as well as some explanatory text for everything that we're going

32
00:02:15,680 --> 00:02:17,390
to be doing in this lecture.

33
00:02:17,390 --> 00:02:22,010
And then we have also as well the sample SVM data text that you're going to need for this lecture as

34
00:02:22,010 --> 00:02:22,440
well.

35
00:02:22,640 --> 00:02:26,780
I've created an you know book it's called Untitled right now it's a blank notebook so we can do is just

36
00:02:26,780 --> 00:02:33,600
get started in what you need to do is say from Paice park sequel and begin a spark session in order

37
00:02:33,600 --> 00:02:36,920
to create a data frame Hopefully by now this is second nature to you.

38
00:02:36,930 --> 00:02:42,240
But we can just say spark session builder give or app a name we'll call it.

39
00:02:42,720 --> 00:02:50,220
I don't know my log Reg firm I looked just regression and I'm going to get or creates and the next thing

40
00:02:50,220 --> 00:02:57,090
I want to do is say from Paice spark thought and well and since logistic regression is a classification

41
00:02:57,090 --> 00:02:57,700
task.

42
00:02:57,780 --> 00:03:03,500
The family it falls under is classification and then it can say import and if a hit tab here.

43
00:03:03,540 --> 00:03:05,840
I can see the various things that are available to me.

44
00:03:06,020 --> 00:03:10,740
A lot of these aren't models or just general things but I'm looking for logistic regression.

45
00:03:10,740 --> 00:03:20,200
So let's run that and then let's grab our training data so I'll say my data and I will say Sparke read

46
00:03:21,010 --> 00:03:27,340
formats and this is a live SVM format remember because it's the documentation example and I'm going

47
00:03:27,340 --> 00:03:32,020
to load sample SVM they get that text.

48
00:03:32,030 --> 00:03:34,080
So let's see what that data looks like.

49
00:03:34,790 --> 00:03:40,250
By saying that show and I can see here it's already nicely formatted for me we have labels which are

50
00:03:40,250 --> 00:03:44,900
either 0 or 1 is binary classification and they have features as well.

51
00:03:44,930 --> 00:03:46,760
So that vector of features.

52
00:03:46,760 --> 00:03:49,040
So we'll scroll down here and continue on.

53
00:03:49,100 --> 00:03:54,440
Next I'm going to just go straight ahead and actually create my logistic regression model so I'll say

54
00:03:54,440 --> 00:04:02,450
it my log read model maybe call it something shorter and then we'll say it's an instance of a logistic

55
00:04:02,450 --> 00:04:03,530
regression model.

56
00:04:03,830 --> 00:04:08,150
And as always in this logistic regression model you can specify the features the label column in the

57
00:04:08,150 --> 00:04:12,410
prediction column will keep everything with the default right now that should be enough for us.

58
00:04:12,530 --> 00:04:22,700
And what we're going to do next is call log Regg model lips is equal to.

59
00:04:23,040 --> 00:04:25,640
And we'll just say something like my log.

60
00:04:25,650 --> 00:04:26,990
Well let's call this fitted.

61
00:04:27,060 --> 00:04:37,380
So fitted Greg Zucco to my luck Rick model fit and I'm going to fit it on that training data which I

62
00:04:37,380 --> 00:04:42,450
called my data so will say my data and run that.

63
00:04:42,710 --> 00:04:47,020
So now what I've done is I went ahead and fitted this logistic regression to this data.

64
00:04:47,060 --> 00:04:49,750
I didn't bother to train test Blitt will see that later on.

65
00:04:49,940 --> 00:04:52,550
Oftentimes the documentation doesn't do that.

66
00:04:52,600 --> 00:04:59,570
Now that model has been fitted to the data what it can do is get a summary off of it so I can say results

67
00:04:59,990 --> 00:05:00,980
is equal to.

68
00:05:01,220 --> 00:05:09,580
Well it's called this something like log summary is equal to that fitted log model.

69
00:05:09,710 --> 00:05:12,670
And I'm going to call the summary off of it.

70
00:05:12,780 --> 00:05:19,950
So I've called that summary which means I can grab my log summary and graphs something the predictions

71
00:05:19,950 --> 00:05:21,060
date of frame.

72
00:05:21,060 --> 00:05:26,480
So if I just shift enter here it says that data frame and we can check out the columns Ahaz I could

73
00:05:26,690 --> 00:05:33,000
just print scheme and check out what has it has the label the features the raw prediction the probability

74
00:05:33,030 --> 00:05:34,110
and then the prediction.

75
00:05:34,290 --> 00:05:39,090
So in order to do this we're going to need data which we already knew the labels for in this case we

76
00:05:39,090 --> 00:05:40,470
already knew the labels for data.

77
00:05:40,530 --> 00:05:43,910
So basically what this is saying is here's the actual correct label.

78
00:05:43,980 --> 00:05:45,400
Here were the features.

79
00:05:45,450 --> 00:05:48,670
Here's the raw prediction value which do a logistic regression.

80
00:05:48,840 --> 00:05:51,300
Here's the probability for that prediction value.

81
00:05:51,300 --> 00:05:53,510
And then here is what the model predicted.

82
00:05:53,520 --> 00:06:00,090
So we really want to compare at least the most straightforward way is does this label match our actual

83
00:06:00,090 --> 00:06:01,590
prediction for it.

84
00:06:01,590 --> 00:06:06,060
So let's show this results hopefully we're not too zoomed in here.

85
00:06:06,060 --> 00:06:06,570
OK.

86
00:06:06,840 --> 00:06:11,060
Let me zoom out one more time and then show this again so we can see this nicely formatted.

87
00:06:11,330 --> 00:06:15,690
Well basically this is actually even nice reformat it because I can see label.

88
00:06:15,840 --> 00:06:17,140
And then I can see prediction.

89
00:06:17,160 --> 00:06:20,400
They're kind of stacked right on top of each other which is actually pretty convenient.

90
00:06:20,610 --> 00:06:24,540
So you can see here my labels are Point Zero and my prediction was are appointer as well.

91
00:06:24,540 --> 00:06:29,700
And then 1 1 etc. If you keep going down it looks like we're doing a pretty darn good job of predicting

92
00:06:30,060 --> 00:06:31,290
the labels correctly.

93
00:06:31,320 --> 00:06:37,090
So we can end up doing is checking how we can evaluate this now that we've seen the basic way to perform

94
00:06:37,090 --> 00:06:38,370
a logistic regression.

95
00:06:38,520 --> 00:06:44,130
Let's expand on this documentation example a little bit and introduce the concept of evaluators in order

96
00:06:44,130 --> 00:06:49,140
to really show that we're going to end up doing is grabbing my data and splitting it into a training

97
00:06:49,140 --> 00:06:54,840
set and a test set and then running evaluate on that and then passing in that evaluate data frame into

98
00:06:54,840 --> 00:06:56,580
the evaluator itself.

99
00:06:56,580 --> 00:07:00,980
So we're going to scroll down here and we're actually on a run and you sell.

100
00:07:01,230 --> 00:07:05,870
And in this new cell what I'm going to do is use random split on that all data.

101
00:07:06,060 --> 00:07:12,010
So I'll say all data Let's double check that it was called my data.

102
00:07:12,120 --> 00:07:12,740
OK.

103
00:07:12,930 --> 00:07:25,040
So say my data ran them split and I'll do a 70 30 split and then we'll say well our train religious

104
00:07:25,180 --> 00:07:25,730
aggression.

105
00:07:25,750 --> 00:07:32,380
And then our test set that equal to that and then we're going to do is retrain just on the training

106
00:07:32,380 --> 00:07:35,250
data and then evaluate our test.

107
00:07:35,260 --> 00:07:39,940
So if we come back up here we're basically going to follow these exact same things except we're only

108
00:07:39,940 --> 00:07:44,320
going to fit on the training data instead of all the data.

109
00:07:44,590 --> 00:07:45,680
So we'll come back up here.

110
00:07:45,710 --> 00:07:52,420
Couldn't you model for this so I'll say final model is equal to a logistic regression object.

111
00:07:53,850 --> 00:08:03,240
And then we'll say final model fits on L.R. train and then we'll call this fit final.

112
00:08:03,270 --> 00:08:07,700
So now I have that final model it's fitted to that logistic regression training data.

113
00:08:07,740 --> 00:08:09,900
So I want the actual prediction and results.

114
00:08:09,900 --> 00:08:22,710
So what I'm going to do is say prediction and labels is equal to fit final and then I evaluates on that

115
00:08:22,710 --> 00:08:24,160
test set.

116
00:08:24,180 --> 00:08:28,830
So you've seen a really similar process back in the regression lectures but hopefully these four cells

117
00:08:28,860 --> 00:08:30,590
basically show everything you need to know.

118
00:08:30,760 --> 00:08:31,660
You take all your data.

119
00:08:31,680 --> 00:08:36,590
Once it's formatted Well then you randomly split it into whatever ratio you want.

120
00:08:36,750 --> 00:08:41,820
Pre-training data and you test data you create a logistic regression model if any parameters you want

121
00:08:42,270 --> 00:08:47,190
then you fit that model onto your training data and set that as your fitted model and then using that

122
00:08:47,190 --> 00:08:50,410
fit in model you can evaluate on the test set.

123
00:08:50,610 --> 00:08:52,590
And this is everything shown in separate steps.

124
00:08:52,590 --> 00:08:57,560
But sometimes people like to combine these steps so they'll call a method on a method.

125
00:08:57,780 --> 00:09:00,730
So I have this prediction labels data frame that I'm about to create.

126
00:09:00,990 --> 00:09:07,080
And if we take a look at it I have a prediction it labels and then I can call various things off of

127
00:09:07,080 --> 00:09:07,700
this.

128
00:09:07,920 --> 00:09:11,540
But what I wanted to call is predictions and then show the results here.

129
00:09:12,360 --> 00:09:18,360
So I can see here I have my label the features the raw prediction value probability and then prediction

130
00:09:18,360 --> 00:09:18,850
again.

131
00:09:19,020 --> 00:09:21,140
So essentially this is the exact same thing.

132
00:09:21,210 --> 00:09:23,830
I had a peer with the log summary.

133
00:09:24,090 --> 00:09:28,090
But what I did is I called evaluate on this test data.

134
00:09:28,140 --> 00:09:33,780
So that means is I'm on the test data so I may not get perfect label and prediction matching up.

135
00:09:33,840 --> 00:09:37,770
Right now it looks like it's doing pretty well especially because it's kind of just the documentation's

136
00:09:37,770 --> 00:09:38,480
own data.

137
00:09:38,550 --> 00:09:41,280
It may be a perfect fit but we're about to explore that.

138
00:09:41,280 --> 00:09:47,640
So what I want to do is actually explore the valuation of this prediction and labels data frame is do

139
00:09:47,640 --> 00:09:50,520
an evaluator object or an evaluation object.

140
00:09:50,520 --> 00:09:59,120
So we'll scroll down here and we're going to do say from Paice spark thought M-L the evaluation import

141
00:09:59,610 --> 00:10:04,550
and then we're going to be discussing both multiclass cation and binary classification.

142
00:10:04,620 --> 00:10:09,360
So the ones that may interest you I'm just sitting tab's autocomplete there is binary classification

143
00:10:09,360 --> 00:10:10,520
evaluator.

144
00:10:10,530 --> 00:10:13,680
And let me put on a new line so you can see it.

145
00:10:14,070 --> 00:10:20,280
Multiclass classification evaluator sort of have these multiple lines what we can do is just wrap them

146
00:10:20,280 --> 00:10:21,750
in parentheses.

147
00:10:21,780 --> 00:10:26,820
Now that we've imported both of these evaluator objects I want to quickly hop over to the documentation

148
00:10:27,090 --> 00:10:33,000
so we can dive a little more into the details about binary classification evaluator and multiclass classification

149
00:10:33,000 --> 00:10:33,950
evaluator.

150
00:10:33,960 --> 00:10:37,070
Let's start with binary classification.

151
00:10:37,150 --> 00:10:41,440
So if you come over here and you see M-L that evaluation we have this binary classification evaluator

152
00:10:41,800 --> 00:10:47,740
that takes in the raw prediction column and by default it expects it to be called prediction a label

153
00:10:47,740 --> 00:10:51,430
column that expects to be called label and then some sort of metric name.

154
00:10:51,430 --> 00:10:55,330
In this case it expects area under our O.S. by default.

155
00:10:55,330 --> 00:10:57,870
So that's that receiver operator characteristic curve.

156
00:10:58,150 --> 00:11:02,890
And you can see here that actually has an example where it creates a frame for you to kind of play around

157
00:11:02,890 --> 00:11:03,670
with.

158
00:11:03,670 --> 00:11:07,270
So this is essentially just the basic evaluator for binary classification.

159
00:11:07,510 --> 00:11:13,780
And the raw prediction column can actually be of type 0 or 1 for prediction or probability of label

160
00:11:13,780 --> 00:11:19,510
1 or some sort of type of vectors so that length to vector prediction scores are able probabilities

161
00:11:19,510 --> 00:11:23,810
and we actually had all of those we hopped back to our notebook and scroll up.

162
00:11:23,920 --> 00:11:28,290
We had some of those we had both for our prediction and we had the label and prediction.

163
00:11:28,480 --> 00:11:32,610
So we have this prediction column which is just a zero or once who could use that as well.

164
00:11:33,560 --> 00:11:39,980
And coming down here we want to explore the metric name so the actual metric name if we scroll down

165
00:11:39,980 --> 00:11:45,200
here we basically have two options and that's going to be all the way under metric name right here.

166
00:11:45,230 --> 00:11:51,410
So the metric name it expects is either the area under the receiver operator characteristic curve or

167
00:11:51,440 --> 00:11:53,890
the area under the precision recall curve.

168
00:11:54,080 --> 00:11:59,690
So those are the only two metrics it can return to you since it's the binary classification evaluator.

169
00:11:59,750 --> 00:12:05,240
It's a little more difficult to actually grab things like precision or recall directly from this specific

170
00:12:05,270 --> 00:12:06,650
evaluator.

171
00:12:06,650 --> 00:12:12,140
Now speaking of grabbing things like accuracy precision or recall directly we could use the multiclass

172
00:12:12,140 --> 00:12:14,260
classification evaluator for that.

173
00:12:14,270 --> 00:12:19,210
So what I am going to do is hop over to the next tab I have open which is multiclass classification

174
00:12:19,220 --> 00:12:19,900
evaluator.

175
00:12:19,990 --> 00:12:22,810
You know this multiclass classification evaluator.

176
00:12:22,910 --> 00:12:27,440
I have the prediction column expected which can no longer just take raw prediction and it needs the

177
00:12:27,440 --> 00:12:32,930
actual prediction column which is going to be those zeros those ones and since this is multiclass also

178
00:12:32,970 --> 00:12:37,340
toos and you can see it's basically building one for you with just the strict prediction and the actual

179
00:12:37,340 --> 00:12:41,950
label and the label call them which is the true label as well as the metric name.

180
00:12:41,960 --> 00:12:47,690
So multiclass classification evaluator if you begin to scroll down here you'll eventually get to the

181
00:12:47,690 --> 00:12:54,560
metric name and it can return back the F-1 a weighted precision score a weighted recall score or even

182
00:12:54,620 --> 00:12:56,350
an accuracy score.

183
00:12:56,360 --> 00:13:01,510
So those are all your options for dealing with multiclass classification evaluators.

184
00:13:01,520 --> 00:13:05,380
Now they're a little complicated so don't worry if you totally don't get the idea right now.

185
00:13:05,480 --> 00:13:10,550
We're really going to focus in on these evaluator objects a lot more when we discuss pipeline objects

186
00:13:10,550 --> 00:13:12,390
because that's where they're really going to come into play.

187
00:13:12,620 --> 00:13:17,870
But right now what we can do is go ahead and just show you a very basic example of using one.

188
00:13:17,870 --> 00:13:19,590
So we'll come back to Untitled.

189
00:13:19,590 --> 00:13:22,570
We have prediction and labels predictions that show.

190
00:13:22,670 --> 00:13:31,460
So I'll come down here and use this binary classification evaluator so I'll create my evaluator object

191
00:13:31,460 --> 00:13:40,130
so I'll say my evil is equal to a binary classification evaluator and we'll just keep the actual defaults

192
00:13:40,130 --> 00:13:43,450
since I have a label column and I have a prediction column.

193
00:13:43,670 --> 00:13:48,950
So we'll keep those the faults here and then when I'm going to do is run this and then the next thing

194
00:13:48,950 --> 00:13:57,420
I want to do is actually say my evil and I want to evaluate and I want to go away on this predictions

195
00:13:57,480 --> 00:13:58,110
data frame.

196
00:13:58,110 --> 00:14:08,450
So that was predictions and labels that predictions will pass that N and we'll call this my final Aros

197
00:14:08,450 --> 00:14:11,200
see results or whatever you want to call it.

198
00:14:11,440 --> 00:14:12,430
We'll run that.

199
00:14:12,430 --> 00:14:13,600
And that may take a little bit of time.

200
00:14:13,600 --> 00:14:16,400
The pinning on your actual computer.

201
00:14:16,720 --> 00:14:20,100
And then what we can do is check this out.

202
00:14:20,180 --> 00:14:23,470
So we say my final Orosi Well that happens to be one.

203
00:14:23,480 --> 00:14:24,710
So what does that actually mean.

204
00:14:24,740 --> 00:14:28,680
Well it means the area under the curve of the Orosi was 1.0.

205
00:14:28,880 --> 00:14:33,270
Meaning this essentially was a perfect fit and it predicted everything accurately.

206
00:14:33,290 --> 00:14:35,090
So is that realistic.

207
00:14:35,090 --> 00:14:40,330
Probably not unless you have a lot of faith that everything was highly separable in this case.

208
00:14:40,370 --> 00:14:45,410
This data was highly separable and you can even see a hint of that we were getting predictions that

209
00:14:45,410 --> 00:14:48,790
match the labels perfectly even with the train test blip.

210
00:14:48,920 --> 00:14:55,040
So this wasn't a super good example for what the my final Orosi would look like but this is an indication

211
00:14:55,040 --> 00:15:00,080
that we filled up the Aros seeker and we basically matched our prediction to every single level perfectly.

212
00:15:00,100 --> 00:15:04,910
But what I really want you to get out of this is how to generally use evaluation or evaluate or objects

213
00:15:05,180 --> 00:15:10,910
you'll say from Paice sparked the M-L that evaluation called binary classification evaluator or multiclass

214
00:15:10,910 --> 00:15:12,330
classification evaluator.

215
00:15:12,440 --> 00:15:17,810
And then you can get back for binary class know the area under the Orosi curve or the area under the

216
00:15:17,810 --> 00:15:19,060
precision recall curve.

217
00:15:19,310 --> 00:15:25,720
Her multiclass classification you can get back accuracy the precision and recall etc..

218
00:15:25,770 --> 00:15:27,860
All right I hope you found that useful.

219
00:15:27,890 --> 00:15:31,340
This was not a super realistic example since we got everything perfect.

220
00:15:31,340 --> 00:15:35,980
So let's head up next and see a realistic example using a custom coatl on.

221
00:15:36,190 --> 00:15:37,820
Thanks and I'll see at the next lecture.
