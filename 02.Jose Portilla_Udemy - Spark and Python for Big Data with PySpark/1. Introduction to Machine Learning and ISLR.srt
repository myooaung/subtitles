1
00:00:06,280 --> 00:00:09,210
Welcome to the machine learning half of the course.

2
00:00:09,440 --> 00:00:14,690
It is now time to begin with the machine learning sections of the course this introduction section will

3
00:00:14,690 --> 00:00:20,570
discuss a general introduction to machine learning theory in general and how sparks M-L lib library

4
00:00:20,570 --> 00:00:22,020
works for machine learning.

5
00:00:23,020 --> 00:00:27,090
In the machine learning half of this course most machine learning sections will have these following

6
00:00:27,090 --> 00:00:27,990
points.

7
00:00:27,990 --> 00:00:33,050
We'll have the suggested reading assignment based off a book called Introduction to statistical learning.

8
00:00:33,240 --> 00:00:37,980
Then we'll have the basic theory lecture will all explain the basic theory for whatever machine learning

9
00:00:38,010 --> 00:00:40,140
algorithm we happen to be working with.

10
00:00:40,350 --> 00:00:42,270
Then we'll have a documentation walk through.

11
00:00:42,370 --> 00:00:47,790
So I'll walk you through the actual documentation example for the code that aligns of whatever algorithm

12
00:00:47,790 --> 00:00:48,630
we're learning.

13
00:00:48,790 --> 00:00:51,720
Then I'll show you a more realistic custom code example.

14
00:00:51,720 --> 00:00:57,910
So again I'll walk you through a more realistic version of custom code which works on another data set.

15
00:00:58,020 --> 00:01:01,160
Then we'll have a consulting project and we'll discuss this later on.

16
00:01:01,290 --> 00:01:06,210
But the consulting projects are going to be more open and looser where you're basically given some sort

17
00:01:06,210 --> 00:01:12,360
of tasks to solve and you have the actual freedom to solve it in any way you want and then you have

18
00:01:12,360 --> 00:01:17,430
the consulting project solutions where I will walk through a possible method to solve that particular

19
00:01:17,430 --> 00:01:18,660
consulting project.

20
00:01:19,990 --> 00:01:24,730
So again the consulting projects are looser there are more realistic projects to attempt with the skills

21
00:01:24,730 --> 00:01:25,770
you just learned.

22
00:01:25,780 --> 00:01:30,070
So what data set some background that a problem is described and you're free to solve it however you

23
00:01:30,070 --> 00:01:31,490
want.

24
00:01:31,570 --> 00:01:35,720
If you prefer a more guided approach to problems that's totally OK.

25
00:01:35,770 --> 00:01:40,270
We have the custom code examples before each consulting project which walks you through an example.

26
00:01:40,270 --> 00:01:45,640
Plus you could treat the consulting project solutions as an additional quote code along lecture.

27
00:01:45,700 --> 00:01:50,590
So if you don't really have the learning style where you're faced with this kind of a loose open ended

28
00:01:50,590 --> 00:01:55,390
problem and you want to just tackle it on your own you prefer for someone to guide you and code along.

29
00:01:55,390 --> 00:01:59,830
Feel free to just skip the consulting project and go straight to the consulting project solutions as

30
00:01:59,830 --> 00:02:01,440
an additional code along lecturer.

31
00:02:01,560 --> 00:02:05,680
So really you have the flexibility there to learn in the way that works best for you.

32
00:02:06,280 --> 00:02:10,190
And one more note because different students have different backgrounds in math.

33
00:02:10,210 --> 00:02:14,470
We're going to try to keep the mathematics behind the machine learning algorithms light as far as what

34
00:02:14,470 --> 00:02:17,030
we present in this course instead.

35
00:02:17,050 --> 00:02:21,010
If you're actually interested in reading more about the actual math behind the algorithms we discuss

36
00:02:21,310 --> 00:02:26,060
We're going to be using introduction to mystical learning by Gareth James as a companion book.

37
00:02:26,170 --> 00:02:30,070
It's freely available online and will show you the links in the resources for it.

38
00:02:31,300 --> 00:02:35,610
So students who want the mathematical theory should do the suggested reading assignment that will appear

39
00:02:35,610 --> 00:02:37,470
for each machine learning section.

40
00:02:37,560 --> 00:02:41,970
Otherwise if you're more interested in the actual practical implementation of these algorithms using

41
00:02:41,970 --> 00:02:46,890
Python and Sparke you can just watch the introduction theory lecture for the fundamentals of the algorithm.

42
00:02:47,160 --> 00:02:50,780
If you want to dive in more of the math feel free to do the suggested reading assignment.

43
00:02:51,910 --> 00:02:56,350
So the first suggested reading assignment for this actual introduction to machine learning is to read

44
00:02:56,350 --> 00:03:00,850
chapters 1 and 2 to gain a background understanding before continuing on to the rest of the machine

45
00:03:00,850 --> 00:03:01,870
learning lectures.

46
00:03:01,870 --> 00:03:06,820
So again check the resources for this lecture for an actual link to grab the introduction to mystical

47
00:03:06,850 --> 00:03:08,730
learning book.

48
00:03:08,730 --> 00:03:09,040
All right.

49
00:03:09,040 --> 00:03:11,850
Now that we discussed how we approach machine learning in this course.

50
00:03:12,020 --> 00:03:17,620
Let's take some time to actually discuss what machine learning is machine learning at its core is a

51
00:03:17,620 --> 00:03:23,880
method of data analysis that automates analytical model building using algorithms that iterative we

52
00:03:23,890 --> 00:03:25,030
learn from the data.

53
00:03:25,030 --> 00:03:30,040
Machine learning allows computers to find hidden insights without being explicitly program where to

54
00:03:30,040 --> 00:03:30,530
look.

55
00:03:30,580 --> 00:03:32,040
And that's kind of the key idea.

56
00:03:32,080 --> 00:03:35,580
You don't have to explicitly tell the actual algorithm what to do.

57
00:03:35,590 --> 00:03:39,500
The algorithm it really learns from the data.

58
00:03:39,570 --> 00:03:41,090
So what is machine learning is for.

59
00:03:41,100 --> 00:03:42,960
It's used for a ton of applications.

60
00:03:42,960 --> 00:03:48,480
Anything from fraud detection to predict the equipment failures e-mail spam filtering financial modeling

61
00:03:48,780 --> 00:03:52,860
tech sentiment analysis recommendation engines so many applications.

62
00:03:54,350 --> 00:03:56,450
So what does the actual machine learning process looks like.

63
00:03:56,450 --> 00:03:59,260
Well this is actually a key to understanding machine learning.

64
00:03:59,260 --> 00:04:02,840
So let's go through this sort of diagram of the machine learning process.

65
00:04:02,870 --> 00:04:05,010
First you need to get your data from somewhere.

66
00:04:05,030 --> 00:04:08,060
You can't do a machine learning algorithm if you don't have data.

67
00:04:08,060 --> 00:04:10,040
So somehow you have to acquire data.

68
00:04:10,100 --> 00:04:13,940
A lot of times if you're already working at a company where you just got a job at a new company they'll

69
00:04:13,940 --> 00:04:18,520
actually have a ton of data will be stored in a sequel database a cxxviii file etc..

70
00:04:18,590 --> 00:04:22,640
And luckily we already learned that Python and SPARC can read data from a wide variety of sources.

71
00:04:22,640 --> 00:04:27,560
So once you've acquired that data sometimes usually you actually need to clean that data.

72
00:04:27,680 --> 00:04:31,250
So if you have missing values you either need to fill them in or drop them.

73
00:04:31,250 --> 00:04:36,790
Maybe you want to make some new features maybe have a date time column that we saw during the dates

74
00:04:36,800 --> 00:04:41,450
and time stamps lecture and you actually just need the year etc. So that's kind of cleaning and managing

75
00:04:41,450 --> 00:04:41,830
your data.

76
00:04:41,840 --> 00:04:42,850
That's the next step.

77
00:04:42,950 --> 00:04:47,780
Then once you've done that you're going to split your data and you get to split your data into a training

78
00:04:47,780 --> 00:04:49,370
set and a test set.

79
00:04:49,370 --> 00:04:54,180
There's also sometimes a three way split between training test and what's known as hold out.

80
00:04:54,290 --> 00:04:55,640
But we'll explain that later on.

81
00:04:55,640 --> 00:05:00,050
Right now we'll take the simpler approach of a training set and a testing set.

82
00:05:00,080 --> 00:05:05,000
So we end up doing is you take your training set and you actually train your machine learning model

83
00:05:05,060 --> 00:05:10,140
on that training set and then to actually evaluate how well your model performed.

84
00:05:10,160 --> 00:05:13,630
You compare that train the model onto your test data.

85
00:05:13,640 --> 00:05:17,840
The reason for this split is because your model was trained on the training data.

86
00:05:17,870 --> 00:05:23,060
It's not really a fair evaluation to then say okay how well did it work with the training data.

87
00:05:23,060 --> 00:05:28,250
Maybe you're trying to predict housing prices well you should work on some data that your algorithm

88
00:05:28,280 --> 00:05:33,590
or your machine learning model has never actually seen before which is why we split it into test data.

89
00:05:33,590 --> 00:05:34,790
Then you just do this process.

90
00:05:34,810 --> 00:05:39,770
It's really until you figured out the best parameters for your machine learning model.

91
00:05:39,770 --> 00:05:43,900
Once you have it ready to go you can then deploy that model onto brand new data.

92
00:05:44,190 --> 00:05:50,750
Ok so now let's dive in a little more into different types of machine learning Spark's M-L lib library

93
00:05:50,990 --> 00:05:56,660
is mainly designed for supervised and unsupervised learning tasks with most of the algorithms falling

94
00:05:56,660 --> 00:05:58,370
under those two categories.

95
00:05:58,370 --> 00:06:01,570
Let's discuss them in more detail and describe how they're different.

96
00:06:02,980 --> 00:06:08,990
So we'll start of supervised learning supervised learning algorithms are trained using labeled examples

97
00:06:09,140 --> 00:06:12,280
such as an input or the desired output is known.

98
00:06:12,290 --> 00:06:17,670
For example a piece of equipment could have data points labeled either failed or are for runs.

99
00:06:17,690 --> 00:06:19,310
So you have some sort of label.

100
00:06:19,310 --> 00:06:22,340
Another example would be the housing price data.

101
00:06:22,400 --> 00:06:27,740
You have various features of houses like how many rooms they have their location the amount of square

102
00:06:27,740 --> 00:06:32,360
footage cetera and you have the actual label the price of the house.

103
00:06:32,480 --> 00:06:35,310
So that's where supervised learning comes into play.

104
00:06:35,450 --> 00:06:40,550
So that supervised learning algorithm receives a set of inputs along with the corresponding correct

105
00:06:40,610 --> 00:06:46,670
outputs those labels and then the algorithm learns by comparing its actual output with correct outputs

106
00:06:46,670 --> 00:06:50,200
to find errors that then modifies the model accordingly.

107
00:06:51,530 --> 00:06:56,560
Through methods like classification regression prediction and gradient boosting supervised learning

108
00:06:56,560 --> 00:07:01,470
uses patterns to predict the values of the label on additional unlabeled data.

109
00:07:01,540 --> 00:07:06,520
So supervised learning is commonly used in applications where historical data predicts likely future

110
00:07:06,520 --> 00:07:07,420
events.

111
00:07:07,420 --> 00:07:13,390
So the main idea to go back to the housing example is you have a bunch of housing data you have all

112
00:07:13,390 --> 00:07:17,370
these various features of houses and then you have the corresponding price they sold at.

113
00:07:17,380 --> 00:07:18,920
So that's historical data.

114
00:07:19,060 --> 00:07:23,800
And then once you've trained your model if you visit a new house that hasn't been sold it and you're

115
00:07:23,800 --> 00:07:25,570
looking for the price to sell it.

116
00:07:25,720 --> 00:07:34,190
You can use your model on this new unlabeled data but it was trained on label data that historical information.

117
00:07:34,320 --> 00:07:39,420
So again for example it can anticipate when credit card transactions are likely to be fraudulent or

118
00:07:39,420 --> 00:07:42,000
which insurance customer is likely to file a claim.

119
00:07:42,210 --> 00:07:47,130
Or like I mentioned it can attempt to predict the price of a house based on different features for houses

120
00:07:47,130 --> 00:07:48,800
for which we have historical price data.

121
00:07:48,920 --> 00:07:50,460
So supervised learning a lot.

122
00:07:50,460 --> 00:07:52,430
It's just historical data that's labeled.

123
00:07:52,590 --> 00:07:56,670
And then you train your model on it and you're trying to predict for new unlabeled data that's going

124
00:07:56,670 --> 00:07:58,020
to eventually come in.

125
00:07:59,290 --> 00:08:02,040
So now let's discuss unsupervised learning.

126
00:08:02,080 --> 00:08:04,250
So imagine they have all this historical data.

127
00:08:04,270 --> 00:08:06,270
But it has no labels to begin with.

128
00:08:06,340 --> 00:08:10,660
So you have these unsupervised learning against data that has no historical labels.

129
00:08:10,690 --> 00:08:15,890
And the system isn't really told the quote unquote right answer such as the price of the house.

130
00:08:16,090 --> 00:08:18,420
The algorithm must figure out what is being shown.

131
00:08:18,490 --> 00:08:25,110
And the goal is to really explore the data and find some sort of structure within the data.

132
00:08:25,140 --> 00:08:30,360
So as an example if you're dealing with customer data I can find the main attributes a separate customer

133
00:08:30,360 --> 00:08:31,950
segments from each other.

134
00:08:31,950 --> 00:08:37,410
Popular techniques include self-organizing maps nearest neighbor mapping Kamins clustering and singular

135
00:08:37,410 --> 00:08:39,020
value decomposition.

136
00:08:39,030 --> 00:08:43,650
One major issue with unsupervised learning is that it can be really difficult to evaluate the results

137
00:08:43,650 --> 00:08:45,440
of an unsupervised learning model.

138
00:08:45,570 --> 00:08:49,300
And the reason for that is because this data never had any labels to begin with.

139
00:08:49,440 --> 00:08:53,760
She can't really compare to see how well you did because you're essentially trying to discover these

140
00:08:53,760 --> 00:08:58,590
labels or try to cluster them in some way to find some sort of structure within the data.

141
00:08:58,590 --> 00:09:03,510
Now this is a little confusing don't worry unsupervised learning can be a little hard to grasp at first

142
00:09:03,510 --> 00:09:06,670
especially in just a theoretical conceptual argument.

143
00:09:06,810 --> 00:09:09,630
When you actually see it in action and in this course will kind of deal with it.

144
00:09:09,630 --> 00:09:12,520
With Kamins clustering it's going to make a lot more sense.

145
00:09:13,760 --> 00:09:16,580
Ok some final thoughts on machine learning in general.

146
00:09:16,580 --> 00:09:19,010
Machine Learning takes time to learn.

147
00:09:19,010 --> 00:09:24,410
Be patient yourself and feel free to post to any forums and as a quick reference no one course can be

148
00:09:24,410 --> 00:09:26,440
a reference for all machine learning topics.

149
00:09:26,510 --> 00:09:31,910
So if you were looking for a particular algorithm it may or may not be in this course and also a particular

150
00:09:31,940 --> 00:09:35,320
algorithm may or may not be even implemented in Python and Sparke.

151
00:09:35,450 --> 00:09:39,860
So if you were looking for a particular algorithm and it's not in this course there is also the possibility

152
00:09:39,870 --> 00:09:44,390
it's not even implemented in Python with SPARC So it was never available for you to begin with.

153
00:09:44,390 --> 00:09:45,460
So keep that in mind.

154
00:09:45,470 --> 00:09:50,030
However in this course we really are going to go over the major topics in major learning algorithms

155
00:09:50,360 --> 00:09:52,310
that are available to you in Python and SPARC.

156
00:09:52,310 --> 00:09:58,040
So you're pretty much going to get the wide view of what you can do with Python and Sparc and it's M-L

157
00:09:58,040 --> 00:09:59,460
lib library.

158
00:09:59,470 --> 00:10:03,620
Again I'm always happy to point you in the right direction for machine learning topics and that book

159
00:10:03,650 --> 00:10:04,310
that we mentioned.

160
00:10:04,310 --> 00:10:09,710
Introduction to learning is a really great base for you to begin your journey on discovering machine

161
00:10:09,710 --> 00:10:10,400
learning.

162
00:10:10,550 --> 00:10:11,240
All right.

163
00:10:11,240 --> 00:10:16,310
Coming up next we're going to discuss the specifics of using Spark's M-L lib library and how it's a

164
00:10:16,310 --> 00:10:19,180
little different than other Python machine learning libraries.

165
00:10:19,190 --> 00:10:20,870
Thanks and I'll see you at the next lecture.
