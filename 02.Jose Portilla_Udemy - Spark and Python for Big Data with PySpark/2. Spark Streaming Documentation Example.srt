1
00:00:05,550 --> 00:00:11,420
Hello everyone and welcome to the sparks streaming example code along lecture because we're really using

2
00:00:11,420 --> 00:00:17,920
spark streaming and the structures streaming that's still experimental in an Alpha at SPARC 2.1 0.1.

3
00:00:18,020 --> 00:00:23,420
What we need to do is use some older ardy the syntax because we're going to be using a spark context

4
00:00:23,510 --> 00:00:24,940
instead of a spark session.

5
00:00:26,130 --> 00:00:30,350
So we're going to be building a very simple application that connects to a local stream of data just

6
00:00:30,380 --> 00:00:33,330
to open terminal through a socket connection.

7
00:00:33,330 --> 00:00:37,950
It will then count the words for each line that we type in the terminal.

8
00:00:37,950 --> 00:00:41,440
Now the steps for creating the actual streaming connection is going to be the following.

9
00:00:41,460 --> 00:00:43,250
Well first create a smart contex.

10
00:00:43,260 --> 00:00:45,960
It's very similar to the way we've been treating SPARC sessions.

11
00:00:45,960 --> 00:00:51,750
Then using that SPARC context we create a streaming context and then using that streaming context we

12
00:00:51,750 --> 00:00:55,700
create a socket text stream essentially connecting via a socket.

13
00:00:55,800 --> 00:01:00,300
Our Jupiter notebook or your PI file to the actual terminal.

14
00:01:00,300 --> 00:01:04,860
Then we're going to read in the lines as a stream worried data stream.

15
00:01:04,900 --> 00:01:09,190
Then once you actually have that data stream the steps were working the data are the following.

16
00:01:09,190 --> 00:01:13,990
First we'll take that input line Remember we're just reading this in batches so we'll have these inputs

17
00:01:13,990 --> 00:01:16,720
of lines which are essentially just a long string.

18
00:01:16,750 --> 00:01:21,030
We want to split that into a list of words just using a normal not split method.

19
00:01:21,250 --> 00:01:27,520
Then we're going to map each of those words to a tuple that looks like this a word comma one where it's

20
00:01:27,520 --> 00:01:31,310
always going to be one as the second parameter in that tuple.

21
00:01:31,480 --> 00:01:36,820
Then we're going to group or reduce the tuples by the word which is the key.

22
00:01:36,970 --> 00:01:42,700
And this is just a way of saying a reduced by key then we're going to sum up the second argument which

23
00:01:42,700 --> 00:01:44,160
is always the number one.

24
00:01:44,230 --> 00:01:50,020
And that allows us to essentially reduce all those tuples which is going to the words comma 1 and actually

25
00:01:50,020 --> 00:01:50,890
get a word count.

26
00:01:50,950 --> 00:01:57,640
So you can imagine if I had type then hello hello we would end up splitting hello hello into a list

27
00:01:57,880 --> 00:01:59,000
of those two strings.

28
00:01:59,020 --> 00:02:00,270
Hello comma Hello.

29
00:02:00,430 --> 00:02:05,770
Then would a map each word to a tuple hello come a one in one tuple and again hello come a one in another

30
00:02:05,770 --> 00:02:09,810
tuple and then we group or reduce the tuples by the word which is the key.

31
00:02:09,880 --> 00:02:14,700
In this case it's the hello and we actually sum up the second argument which is the number one.

32
00:02:14,710 --> 00:02:21,250
So at the end we will get something that looks like a tuple except they would say hello comma two and

33
00:02:21,250 --> 00:02:25,510
that will then provide us with a word count in the form like I just said hello comma three or comma

34
00:02:25,510 --> 00:02:27,820
to cetera for each line.

35
00:02:27,820 --> 00:02:33,460
Then as a quick note the ardy the syntax relies heavily on lambda expressions which are just quick anonymous

36
00:02:33,460 --> 00:02:34,060
functions.

37
00:02:34,100 --> 00:02:39,070
And luckily the land expressions we use here are really quite simple and basic so I don't think you

38
00:02:39,070 --> 00:02:41,130
have any problem understanding them.

39
00:02:41,310 --> 00:02:46,550
OK let's get started with a simple example I'm going to open up my virtual box and we'll open up two

40
00:02:46,550 --> 00:02:48,400
terminals and the in a notebook.

41
00:02:48,400 --> 00:02:53,190
Let's get started OK here I am at my Ubuntu desktop inside my virtual box.

42
00:02:53,230 --> 00:02:58,820
Going to come over here and I will open a terminal and then I'm actually going to open a terminal twice.

43
00:02:58,840 --> 00:03:04,930
So we'll have two terminals and in the first terminal that will be used for Jupiter notebook in the

44
00:03:04,930 --> 00:03:05,620
second terminal.

45
00:03:05,620 --> 00:03:08,760
I will actually use for the streaming socket connection.

46
00:03:08,830 --> 00:03:11,040
So let's start a Jupiter notebook.

47
00:03:11,200 --> 00:03:15,200
Enter and then eventually my Mozilla Firefox.

48
00:03:15,240 --> 00:03:22,030
Or google chrome whatever you're using should pop up and we'll create a new notebook and then I'm going

49
00:03:22,030 --> 00:03:26,440
to save you toggle header you toggle toolbar.

50
00:03:26,920 --> 00:03:33,340
And since I'm running this on a virtual box also I'm going to say import fine spark and then the next

51
00:03:33,340 --> 00:03:39,070
step after import find spark is just find spark in it and then the file location for our spark.

52
00:03:39,070 --> 00:03:44,440
So I'm going to copy and paste this sentence I just say find spark in it and then wherever spark happens

53
00:03:44,440 --> 00:03:48,480
to be installed in my virtual box machine then I'm going to run that.

54
00:03:48,550 --> 00:03:50,050
And now we should be ready to go.

55
00:03:50,340 --> 00:03:50,880
OK.

56
00:03:51,010 --> 00:03:53,970
So the first thing you have to do is begin the streaming.

57
00:03:54,070 --> 00:04:02,140
So I'll say from Paice spark import a spark context so you can run that and then I will also say from

58
00:04:02,140 --> 00:04:11,800
Paice spark not streaming import a streaming context then we can also use tab autocomplete that as well.

59
00:04:12,030 --> 00:04:15,270
Then we will say actually create these.

60
00:04:15,400 --> 00:04:21,770
So I'll say S-C is equal to a smart context and we're going to be working with two working threads.

61
00:04:21,810 --> 00:04:29,070
So the actual syntax for that is local and in square brackets and the number two are two local threads

62
00:04:29,640 --> 00:04:31,830
and then whatever you want the application to be called.

63
00:04:31,830 --> 00:04:36,790
So we'll call this network word count.

64
00:04:36,960 --> 00:04:41,850
And you can actually check out all the details in the instructions both in the notes provided but as

65
00:04:41,850 --> 00:04:43,600
well as the documentation.

66
00:04:43,740 --> 00:04:46,800
This is the example from the documentation.

67
00:04:46,860 --> 00:04:53,340
And then once you've created that smart contex I'm going to say s s c for streaming context is equal

68
00:04:53,340 --> 00:04:59,540
to a streaming context and then I'm going to pass in the Smart context.

69
00:04:59,540 --> 00:05:04,840
And then one so the number one just means the interval is 1 second.

70
00:05:05,090 --> 00:05:10,610
So whatever type of streaming context I end up using it's always going to be taking it in batches of

71
00:05:10,610 --> 00:05:12,070
one second at a time.

72
00:05:12,440 --> 00:05:20,380
So we can run that and then I will say lines is equal to offer this streaming context object.

73
00:05:20,440 --> 00:05:29,250
I will create a Bub's a socket text stream and this is going to create that stream or data stream will

74
00:05:29,270 --> 00:05:34,380
connect to a hostname and it's going to connect to a local port.

75
00:05:34,400 --> 00:05:40,640
So here I will say local host and then pass a port number that I'm pretty sure is not being used.

76
00:05:40,640 --> 00:05:42,910
So if you have a firewall it may be blocked.

77
00:05:42,920 --> 00:05:45,290
It shouldn't really matter here because we're running on a virtual box.

78
00:05:45,300 --> 00:05:49,990
There's no default firewall like a Windows firewall here just running Ubuntu.

79
00:05:50,060 --> 00:05:56,460
So we're going say nine nine nine nine as our local hosts port connection and we can specify that when

80
00:05:56,460 --> 00:05:58,480
we actually go back to the terminal.

81
00:05:58,830 --> 00:06:02,540
So there are lines remember that's the actual string of data we're going to be typing in.

82
00:06:02,550 --> 00:06:08,350
Now I want to grab that string that single line and turn it into a list of words which means I'm going

83
00:06:08,360 --> 00:06:15,980
to say words point to get that lines object and then I'm going to say flat map.

84
00:06:16,230 --> 00:06:19,210
And this allows me to map something to those lines.

85
00:06:20,040 --> 00:06:26,060
And we're going to use the land expression where we've taken each line and then we split that line based

86
00:06:26,060 --> 00:06:27,380
off whitespace.

87
00:06:27,410 --> 00:06:33,080
So just to make that clear I'll actually specify the argument into that split.

88
00:06:33,080 --> 00:06:39,810
OK so now that we have that list of words I want to create my pairs which are those tuples I was talking

89
00:06:39,810 --> 00:06:49,050
about earlier we're going to take my words and then I'm going to map each word to the tuple just consisting

90
00:06:49,050 --> 00:06:52,680
of the word comma one.

91
00:06:52,780 --> 00:06:53,770
Now my peers.

92
00:06:53,810 --> 00:06:59,730
I want to actually get my word counts so we'll say word counts as equal to those pairs.

93
00:06:59,960 --> 00:07:06,230
And then I'm going to reduce by key and you can essentially almost think of this as a group by mechanism

94
00:07:06,620 --> 00:07:12,530
where reduce by key takes in a tuple and automatically reduces by the first argument in the tuple and

95
00:07:12,530 --> 00:07:16,190
then you can do an operation with the rest of the second arguments.

96
00:07:16,250 --> 00:07:21,410
So we say pairs that reduce by key lambda and we're going to take an x y.

97
00:07:21,440 --> 00:07:28,820
So I'll actually type in Word number and then I'm going to say actually this is probably not a good

98
00:07:28,820 --> 00:07:32,610
choice we'll say number one.

99
00:07:32,610 --> 00:07:37,360
Number two say number one plus number two.

100
00:07:37,370 --> 00:07:40,940
Now this is just a little weird because it's not very intuitive.

101
00:07:40,940 --> 00:07:42,930
What's going on here when you say reduce specky.

102
00:07:42,980 --> 00:07:48,440
And because of this kind of non intuitiveness it's actually Weissberg streaming is moving towards structure

103
00:07:48,440 --> 00:07:50,260
streaming in Weissberg context.

104
00:07:50,360 --> 00:07:54,830
The syntax is moving towards data frames in general just because this sort of stuff is kind of a little

105
00:07:54,830 --> 00:07:56,800
weird to get your head wrapped around.

106
00:07:56,960 --> 00:08:00,210
But basically what's happening here is a lot of times when you're working.

107
00:08:00,230 --> 00:08:07,010
ARDE these eventually get things and map stuff to be in tuple pairs where you have a tuple and you have

108
00:08:07,010 --> 00:08:12,020
some sort of key as the first argument and a tuple occurs item in a tuple and then as a second item

109
00:08:12,020 --> 00:08:13,020
or element in the tuple.

110
00:08:13,040 --> 00:08:14,840
You have a number or a word etc..

111
00:08:15,200 --> 00:08:18,670
And then once you have those tuple pairs you say reduce by key.

112
00:08:18,680 --> 00:08:23,750
And what's interesting about this is using the ardy the syntax is reduced by key automatically knows

113
00:08:23,750 --> 00:08:28,950
that it's going to grab the first item in the tuples and use that as its key to reduce by group grouped

114
00:08:28,970 --> 00:08:34,460
by and then the land expression or the function you pass in that takes in two arguments.

115
00:08:34,610 --> 00:08:39,130
It's not just going to apply that to just two tuples that happen to match the same word.

116
00:08:39,290 --> 00:08:45,840
It's going to keep reducing over and over until you just get one single instance of the word tuple itself

117
00:08:45,890 --> 00:08:47,050
on that key.

118
00:08:47,090 --> 00:08:52,190
So that's a little bit strange to wrap your head around the very first time you see it but I think after

119
00:08:52,190 --> 00:08:54,920
we see some examples of the terminal it will make more sense.

120
00:08:55,010 --> 00:09:00,800
But keep in mind this kind of weird non-intuitive syntax is basically the whole reason people are start

121
00:09:00,800 --> 00:09:02,390
to move towards data frames.

122
00:09:02,390 --> 00:09:06,740
Just gonna take a little longer for Sparke streaming to get there because streaming in itself is a little

123
00:09:06,740 --> 00:09:08,680
more complicated to convert.

124
00:09:08,680 --> 00:09:15,380
But hopefully by the time SPARC 2.2 comes around SPARC structure streaming will be maybe out of Alfon

125
00:09:15,380 --> 00:09:19,640
into a beta phase and then by 2.3 it's you know a little more stable.

126
00:09:19,640 --> 00:09:24,540
Right now it's pretty experimental and I really wouldn't suggest using it in a production environment.

127
00:09:24,740 --> 00:09:25,290
OK.

128
00:09:25,550 --> 00:09:30,830
So we have our word counts the very last thing I want to do is off this are the the when I say word

129
00:09:30,830 --> 00:09:33,170
counts and then we can call the prince.

130
00:09:33,220 --> 00:09:34,470
Kind of like a pretty print.

131
00:09:34,510 --> 00:09:39,360
It's basically just the printing everything with a nice format is word counts themselves.

132
00:09:39,410 --> 00:09:39,890
OK.

133
00:09:40,250 --> 00:09:48,170
So then we're going to do is type in S S C that starts close parentheses and I won't actually run this

134
00:09:48,170 --> 00:09:49,510
quite yet.

135
00:09:49,640 --> 00:09:57,550
So we're going to do is come back to our terminal and in the terminal in an array and see space that's

136
00:09:57,980 --> 00:10:07,340
L.K. space and then that port number 9 9 9 9 and going to enter and then and then start typing.

137
00:10:07,670 --> 00:10:12,080
But before you start typing I'll come back to the Jupiter note book and actually start my streaming

138
00:10:12,080 --> 00:10:13,040
context.

139
00:10:13,040 --> 00:10:15,340
So let's run this.

140
00:10:15,440 --> 00:10:15,730
OK.

141
00:10:15,770 --> 00:10:20,090
So my streaming contex has started and you can already see it's beginning to print every second.

142
00:10:20,240 --> 00:10:21,400
So let's start typing something.

143
00:10:21,410 --> 00:10:28,530
Say hello enter and we'll say hello hello hello and then we can write.

144
00:10:28,550 --> 00:10:33,940
This is a line with multiple words.

145
00:10:33,970 --> 00:10:39,320
Ok so since I'm using the Jupiter note book in order to kind of kill this I either need to say as a

146
00:10:39,340 --> 00:10:43,690
seed that await termination which is going to wait for the computation to terminate.

147
00:10:43,690 --> 00:10:48,580
You can actually put limits on it but since this is just running in one cell it's going to keep running

148
00:10:48,580 --> 00:10:49,860
for a really long time.

149
00:10:49,870 --> 00:10:55,090
So what I will do is say kernel appear and then and when to just interrupt it to force it to stop.

150
00:10:55,090 --> 00:10:55,530
All right.

151
00:10:55,660 --> 00:10:59,310
So if I come all the way down here I should stop seeing the print outs.

152
00:10:59,680 --> 00:11:03,970
And if you come back up here since it was taken every second we can see here that our word count was

153
00:11:03,970 --> 00:11:08,230
in fact actually working this multiple line is a words with etc..

154
00:11:08,560 --> 00:11:11,980
And then if we come back up here we can see those counts.

155
00:11:11,980 --> 00:11:12,810
Hello three.

156
00:11:12,880 --> 00:11:18,610
And the very first one was Helot one etc. and those are the very basics of working with Sparke streaming

157
00:11:18,970 --> 00:11:23,180
and also working with kind of the older Spart context RTD syntax.

158
00:11:23,380 --> 00:11:26,870
Now if you want some more details on that definitely check out the documentation page.

159
00:11:26,860 --> 00:11:32,140
This same example is on the documentation page and we have a little more details on every step for you

160
00:11:32,410 --> 00:11:34,460
as well as different links for more help.

161
00:11:34,630 --> 00:11:35,370
OK.

162
00:11:35,410 --> 00:11:40,210
Coming up next we're going to set up everything we need are the actual Twitter example and then the

163
00:11:40,210 --> 00:11:42,990
lecture after that we will go through it.

164
00:11:43,000 --> 00:11:43,690
Thanks everyone.

165
00:11:43,690 --> 00:11:46,420
And if you have any questions feel free to post the uniforms.

166
00:11:46,420 --> 00:11:47,540
I'll see you at the next lecture.
