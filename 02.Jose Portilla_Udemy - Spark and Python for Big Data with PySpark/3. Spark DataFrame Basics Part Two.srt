1
00:00:05,280 --> 00:00:09,240
Welcome back to part two of the spark to frame basic's lectures.

2
00:00:09,300 --> 00:00:15,130
We're going to jump right back that you put a note book from the previous lecture and continue on here's

3
00:00:15,190 --> 00:00:19,960
a book from the previous lecture where we discussed how to start a spark session read in a data frame

4
00:00:19,960 --> 00:00:25,150
from a jay sun file a couple of methods and attributes from that data frame such as print in the schema

5
00:00:25,180 --> 00:00:30,070
describing it showing the columns and then we have a discussion of how to manually set the data frame

6
00:00:30,070 --> 00:00:31,420
schema.

7
00:00:31,450 --> 00:00:33,670
Now this is what our current data frame looks like.

8
00:00:33,670 --> 00:00:35,710
Has the H column in the name column.

9
00:00:35,710 --> 00:00:38,560
Let's discuss how to actually grab data from this.

10
00:00:38,860 --> 00:00:43,180
There's a couple of different ways we can go about this but I want to discuss what happens when you

11
00:00:43,390 --> 00:00:47,190
select vs just grab data if I want to get a column.

12
00:00:47,200 --> 00:00:52,750
You might be tempted just to say something like an index call off a dictionary def and then passing

13
00:00:52,780 --> 00:00:54,290
the string age.

14
00:00:54,340 --> 00:01:00,460
If I run this I get back a column object meaning if I actually check the type of this by passing this

15
00:01:00,460 --> 00:01:06,400
in through the type function I get back Paice sparked the sequel doc column column.

16
00:01:06,460 --> 00:01:08,180
So that's a column object.

17
00:01:08,350 --> 00:01:14,270
If I actually want to get a data frame with that singular column that way I can see the results.

18
00:01:14,290 --> 00:01:18,850
I use the Select method and that's really all we're going to be doing quite a bit in this course.

19
00:01:19,750 --> 00:01:28,600
You say DFI dot select and then if I just an age here I can see I have a data frame with the singular

20
00:01:28,600 --> 00:01:29,830
column H.

21
00:01:29,830 --> 00:01:38,900
Which means I can then call the show off of this and see that singular column.

22
00:01:39,030 --> 00:01:43,920
So the main differences between these two methods is the fact that one of them the first one is returning

23
00:01:43,920 --> 00:01:49,220
back a column while the second one is returning a data frame that contains a single column.

24
00:01:49,410 --> 00:01:54,350
You get a lot more flexibility with a data frame of a single column versus just a column.

25
00:01:54,390 --> 00:01:59,670
So a lot of times will defer back to select instead of just grabbing that column object.

26
00:01:59,700 --> 00:02:07,730
So again this command using select File Type in type and pass it in it's returning back a data frame.

27
00:02:07,840 --> 00:02:10,730
So and a lot more methods and attributes we can call off of that.

28
00:02:11,080 --> 00:02:14,280
So if you want to check the row objects themselves.

29
00:02:14,410 --> 00:02:18,170
For instance let's say you want to check the first two rows in a data frame.

30
00:02:18,190 --> 00:02:22,720
You can call DFT ahead and then pass in the number of rows you want.

31
00:02:22,720 --> 00:02:26,780
This grabs the top two rows and you can see here.

32
00:02:26,810 --> 00:02:34,700
I gave a list of row objects so that means I can index this list so called 0 off of that and I get back.

33
00:02:34,700 --> 00:02:40,910
This row objects which tells me the age is equal to none and name is equal to Michael so if I scroll

34
00:02:40,910 --> 00:02:48,600
back up that was this row right here and again I can check the type of this to confirm that its sequel

35
00:02:48,750 --> 00:02:49,960
types row.

36
00:02:50,040 --> 00:02:53,810
So keep that in mind that there is actually a row object in that data frame.

37
00:02:54,000 --> 00:02:59,190
And the reason there are so many specialized objects such as a column object or a row object is because

38
00:02:59,310 --> 00:03:04,920
Spark's ability to read from a distributed data source and then map that out to distributed computing

39
00:03:04,930 --> 00:03:10,320
so that's why there are so many specialized types here instead of just something like some sort of series

40
00:03:10,320 --> 00:03:12,810
or list objects for everything.

41
00:03:12,850 --> 00:03:16,000
If you want to select multiple columns that's pretty easy to do as well.

42
00:03:16,010 --> 00:03:23,280
You just passing DMF select and then a list of columns so I can say instead of just aging and passen

43
00:03:23,350 --> 00:03:25,100
names to note the difference here.

44
00:03:25,210 --> 00:03:29,300
I'm saying select but I'm passing and a list of columns of square brackets.

45
00:03:29,470 --> 00:03:35,770
So this returns a data frame of two columns and I can just say that show off the data frame to actually

46
00:03:35,770 --> 00:03:36,550
see the results.

47
00:03:36,550 --> 00:03:42,700
In this case the entire data frame let's discuss creating new columns so you can add a new column with

48
00:03:42,700 --> 00:03:51,510
a simple with column method so we can say F and then we call with column and there is also if column

49
00:03:51,540 --> 00:03:57,300
renamed will you're going to see later on and with column basically returns a new data frame by adding

50
00:03:57,300 --> 00:03:59,840
in a column or replacing an existing column.

51
00:03:59,970 --> 00:04:05,750
So the first thing he pasan is the name of your new column so it will say something like New-Age.

52
00:04:05,850 --> 00:04:09,840
It's just a string here and then you pasan a column.

53
00:04:10,260 --> 00:04:15,960
So in this case we do need to say DFA square brackets age so I actually want to pass in the actual column

54
00:04:15,960 --> 00:04:16,440
itself.

55
00:04:16,470 --> 00:04:20,260
Remember that this doc column doc column data type here.

56
00:04:20,430 --> 00:04:22,640
So I say the name of my new column D.

57
00:04:22,680 --> 00:04:30,370
Age and then I can actually show this just so we can see the results and we see age name new age.

58
00:04:30,510 --> 00:04:33,580
So that's just essentially a copy of New-Age.

59
00:04:33,660 --> 00:04:39,630
If I actually want to perform some operations I can do something like DFI age and something that says

60
00:04:39,630 --> 00:04:40,560
times too.

61
00:04:40,590 --> 00:04:49,160
So let's make this more obvious by saying double age and I'm going to run this and I can see age name

62
00:04:49,470 --> 00:04:49,800
age.

63
00:04:49,810 --> 00:04:52,720
But notice here I'm saying grab this numeric data type.

64
00:04:52,720 --> 00:04:54,160
Multiply it by two.

65
00:04:54,370 --> 00:04:56,820
And here we see 36 the 1938.

66
00:04:57,220 --> 00:05:01,090
So we won't actually be doing this a whole lot but I do want to show that it's possible here especially

67
00:05:01,090 --> 00:05:03,350
with numeric columns.

68
00:05:03,460 --> 00:05:07,860
Now something to keep in mind is these changes aren't permanent on our original data frame.

69
00:05:07,930 --> 00:05:12,500
If I just say the show that it says age name.

70
00:05:12,600 --> 00:05:14,060
So notice what happened here.

71
00:05:14,100 --> 00:05:16,370
This was not an in-place operation.

72
00:05:16,400 --> 00:05:23,790
You would have to save this to a new variable now a really common operation is just renaming a column.

73
00:05:23,810 --> 00:05:27,980
So if you have a column that you just want to simply rename that's actually quite easy.

74
00:05:27,980 --> 00:05:30,740
That was the with column renamed.

75
00:05:30,740 --> 00:05:35,450
So instead of passing in a column all you have to do is pass in the old column name.

76
00:05:35,450 --> 00:05:38,910
So for example age and then as a string the new column name.

77
00:05:38,930 --> 00:05:45,680
So I'll say my new age and I always put in underscores there to make sure I don't get any errors.

78
00:05:45,710 --> 00:05:51,170
They shouldn't be necessary but just keep that in mind and let's show the results of that so I can see

79
00:05:51,200 --> 00:05:53,690
Ivery named age to my new age.

80
00:05:53,870 --> 00:05:58,700
So the difference between with column and with column rename is with Camarena just for two strings the

81
00:05:58,700 --> 00:06:01,700
old column name and the new column name.

82
00:06:01,700 --> 00:06:04,360
So as I mentioned you can do operations.

83
00:06:04,360 --> 00:06:07,780
So here we have the age but you can do a lot of stuff with this.

84
00:06:07,880 --> 00:06:14,780
So I'll put in new stuff and then I could do something like even divide by two.

85
00:06:14,970 --> 00:06:16,160
And that has no problem.

86
00:06:16,170 --> 00:06:19,130
You can do something like plus 2.

87
00:06:19,210 --> 00:06:20,980
Again has no problem running.

88
00:06:21,000 --> 00:06:24,840
So keep that in mind there's a lot of flexibility there and we're going to discuss much more complicated

89
00:06:24,840 --> 00:06:27,200
operations later on.

90
00:06:27,300 --> 00:06:33,960
The very last thing I want to discuss is using pure sequel that's the query language to directly deal

91
00:06:33,960 --> 00:06:35,890
and interact with the data frame.

92
00:06:35,910 --> 00:06:38,700
So in order to do that we're going to scroll all the way down here.

93
00:06:38,940 --> 00:06:41,960
And if you have no idea what sequel is you've never used it before.

94
00:06:42,000 --> 00:06:44,850
Don't worry you can basically finish this lecture off.

95
00:06:44,850 --> 00:06:49,650
But I imagine that if you're a data analyst you probably have a little bit of experience of sequel.

96
00:06:49,680 --> 00:06:55,110
So this is a really cool feature and it's actually why it's called spark that sequel is because it can

97
00:06:55,110 --> 00:06:56,900
interact directly with sequel queries.

98
00:06:57,910 --> 00:07:03,400
So in order to actually do all of this you want to register that data frame as a sequel temporary view.

99
00:07:03,400 --> 00:07:09,980
So I will say DFI dot and then I can start typing creates and I want to say create or replace tenth

100
00:07:10,000 --> 00:07:10,880
view.

101
00:07:11,410 --> 00:07:14,590
That way if I XLE already created this view ill replace it.

102
00:07:15,010 --> 00:07:17,470
And then we pass the string of what we want to call.

103
00:07:17,470 --> 00:07:18,990
Essentially this table.

104
00:07:19,030 --> 00:07:21,850
So we'll call this people.

105
00:07:21,920 --> 00:07:29,780
So I run this and now essentially I've registered this as a sequel temporary view which means I can

106
00:07:29,780 --> 00:07:35,640
do the following or create a variable called results and say spark that sequel.

107
00:07:36,080 --> 00:07:41,680
And as a string here I can pass and direct sequel queries meaning I can do something like this.

108
00:07:41,720 --> 00:07:46,840
Select Asterix from people we're a people.

109
00:07:46,850 --> 00:07:50,260
Is that registered temporary view that I did up here.

110
00:07:50,690 --> 00:07:53,980
So let's run this and then check the results.

111
00:07:53,990 --> 00:07:55,560
So I will show the results here.

112
00:07:56,470 --> 00:07:58,540
And no I get everything back.

113
00:07:58,540 --> 00:08:01,980
So let's actually show a more complicated example.

114
00:08:02,170 --> 00:08:12,450
So I'll say new results are equal to spark thought sequel and I'm going to say select Asterix from people

115
00:08:12,900 --> 00:08:15,700
where age is equal to 30.

116
00:08:15,840 --> 00:08:25,380
So the say direct sequel query analysis shows new results and I get back Andy because his age was 30.

117
00:08:25,670 --> 00:08:28,180
So what's the real positive here.

118
00:08:28,190 --> 00:08:33,380
What's really awesome is if you already have a lot of sequel knowledge you can leverage that with Sparke

119
00:08:33,380 --> 00:08:39,290
sequel and you can do complicated operations really quickly in case you happen to forget some of the

120
00:08:39,290 --> 00:08:42,350
more basic Sparke different operations.

121
00:08:42,350 --> 00:08:48,230
Now keep in mind we won't really be focusing on using direct sequel queery syntax for this course.

122
00:08:48,230 --> 00:08:54,620
In general we're going to be focusing more on the Python and PI spark specific methods of interacting

123
00:08:54,620 --> 00:08:55,770
with a data frame.

124
00:08:55,880 --> 00:09:00,770
But I want you to realize that if you already have that sequel knowledge that's a huge thing you can

125
00:09:00,770 --> 00:09:05,510
leverage with the power of Spark's sequel and that's essentially why we've been importing everything

126
00:09:05,750 --> 00:09:08,270
from sparked up sequel or pi sparked a sequel.

127
00:09:08,450 --> 00:09:12,860
And that's also why when you're looking through the documentation online you see a lot of references

128
00:09:12,860 --> 00:09:18,910
to sequel because of the power that you can say a direct sequel query and grab results from this data

129
00:09:18,910 --> 00:09:19,200
frame.

130
00:09:19,190 --> 00:09:20,640
So that's really awesome.

131
00:09:20,720 --> 00:09:25,700
If you had no idea what I was talking about when I did a sequel and you have no idea what Asterix and

132
00:09:25,700 --> 00:09:27,640
from and where is actually doing.

133
00:09:27,770 --> 00:09:31,690
Don't worry about it because we don't really approach this in the course at all.

134
00:09:31,730 --> 00:09:36,380
There's going to be a little question on the exercises almost like an optional question but as far as

135
00:09:36,440 --> 00:09:40,790
this course is concerned I want you to be aware of it but we're going to be dealing with the pie Sparke

136
00:09:40,790 --> 00:09:43,290
way of interacting for data frame.

137
00:09:43,750 --> 00:09:45,820
Okay that's it for Sparke basics.

138
00:09:45,830 --> 00:09:50,330
Coming up next we're gonna talk about basic operations of Sparke kind of expand what we've been discussing

139
00:09:50,540 --> 00:09:52,670
for these past two lectures.

140
00:09:52,850 --> 00:09:53,630
The next lecture.
