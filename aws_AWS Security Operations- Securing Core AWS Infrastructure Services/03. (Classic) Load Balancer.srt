1
00:00:02,018 --> 00:00:06,018
In this clip, we're going to take a look at the classic load balancer.

2
00:00:06,018 --> 00:00:12,318
So, the classic load balancer has been around at Amazon for a long time,

3
00:00:12,318 --> 00:00:15,018
and its primary job is protection,

4
00:00:15,018 --> 00:00:19,568
and you could also say its primary job is to work with auto

5
00:00:19,568 --> 00:00:22,018
scaling groups to actually give you scalability.

6
00:00:22,018 --> 00:00:26,807
The first concept to have about these load balancers is they're a big,

7
00:00:26,807 --> 00:00:32,334
managed server farm, and when you select a load balancer from the portal,

8
00:00:32,334 --> 00:00:38,403
your load balancer deployed in a public subnet with an elastic IP address,

9
00:00:38,403 --> 00:00:40,710
and that protects your web servers.

10
00:00:40,710 --> 00:00:43,018
That's the first line of defense.

11
00:00:43,018 --> 00:00:43,447
Optionally,

12
00:00:43,447 --> 00:00:46,447
your application servers could use this load

13
00:00:46,447 --> 00:00:49,018
balancer hosted in a private subnet.

14
00:00:49,018 --> 00:00:52,618
So maybe you have application servers that don't need

15
00:00:52,618 --> 00:00:58,783
any more balancing past layer 4, so it might work for you as well.

16
00:00:58,783 --> 00:00:59,371
Now,

17
00:00:59,371 --> 00:01:07,018
the instances can be configured to accept traffic only from your load balancer.

18
00:01:07,018 --> 00:01:10,018
So we ultimately have some protection there as well.

19
00:01:10,018 --> 00:01:12,018
Well how do I do that?

20
00:01:12,018 --> 00:01:15,095
I install it in a virtual private cloud.

21
00:01:15,095 --> 00:01:17,018
I can use security groups.

22
00:01:17,018 --> 00:01:20,334
I can define access in that way.

23
00:01:20,334 --> 00:01:26,018
Now I can also use CloudWatch metrics and monitor my load balancer,

24
00:01:26,018 --> 00:01:29,907
and those metrics can also be used to throw alerts.

25
00:01:29,907 --> 00:01:33,018
Hey, network traffic has increased, add more servers.

26
00:01:33,018 --> 00:01:38,018
Hey, network traffic has decreased, get rid of some of those servers.

27
00:01:38,018 --> 00:01:42,218
And these metrics include things like back-end connection errors,

28
00:01:42,218 --> 00:01:45,018
healthy host count, back-end error codes,

29
00:01:45,018 --> 00:01:47,161
so they're very, very useful.

30
00:01:47,161 --> 00:01:51,018
Logs for the load balancer will capture the requests.

31
00:01:51,018 --> 00:01:52,804
Where are my logs stored?

32
00:01:52,804 --> 00:01:56,018
Oh yeah, S3, and they're published every 5 minutes.

33
00:01:56,018 --> 00:02:00,018
CloudTrail can also track all the calls made to your load balancer.

34
00:02:00,018 --> 00:02:06,018
Your API call history could be really useful to perform security analysis,

35
00:02:06,018 --> 00:02:09,018
tracking of resource changes, compliance auditing.

36
00:02:09,018 --> 00:02:13,143
So up to 20 load balancers can be created per region

37
00:02:13,143 --> 00:02:15,018
for the different client needs.

38
00:02:15,018 --> 00:02:15,371
So,

39
00:02:15,371 --> 00:02:18,194
you could assign multiple load balancers with different

40
00:02:18,194 --> 00:02:21,462
settings for the different types of devices that are

41
00:02:21,462 --> 00:02:23,240
accessing your web applications.

42
00:02:23,240 --> 00:02:24,574
So for example,

43
00:02:24,574 --> 00:02:28,574
you might have desktop users and mobile users using

44
00:02:28,574 --> 00:02:34,218
a specific protocol and port, and so the load balancer is using a listener,

45
00:02:34,218 --> 00:02:38,583
and this is a process that checks for connection requests.

46
00:02:38,583 --> 00:02:41,192
Once that connection is made,

47
00:02:41,192 --> 00:02:49,018
it's sent to a port at the back end to send it to the instances.

48
00:02:49,018 --> 00:02:52,018
Now let's take a look at the classic routing of the load balancer.

49
00:02:52,018 --> 00:02:55,447
So the node of the internet-facing load balancer

50
00:02:55,447 --> 00:02:58,018
has a public elastic IP address.

51
00:02:58,018 --> 00:03:00,860
And when you make your load balancer internet facing,

52
00:03:00,860 --> 00:03:05,185
there's a DNS name that's created, linked to the public IP address,

53
00:03:05,185 --> 00:03:11,018
and Route 53 then knows about that elastic load balancer.

54
00:03:11,018 --> 00:03:12,109
So the client will use this.

55
00:03:12,109 --> 00:03:13,927
They'll say well I'm going to use Route 53 to

56
00:03:13,927 --> 00:03:15,836
resolve the domain name that I know, and this,

57
00:03:15,836 --> 00:03:18,018
of course, could be built into the application.

58
00:03:18,018 --> 00:03:24,018
So if somebody's going to buy coffee from Wired Brain, they get their app.

59
00:03:24,018 --> 00:03:28,018
Embedded in the app is here's where you go, this is the public IP address.

60
00:03:28,018 --> 00:03:30,563
So the client's found the load balancer.

61
00:03:30,563 --> 00:03:32,018
The listener is listening.

62
00:03:32,018 --> 00:03:35,194
The client request goes to a healthy registered instance.

63
00:03:35,194 --> 00:03:38,018
How does the load balancer know it's healthy?

64
00:03:38,018 --> 00:03:41,018
Oh that's right, it's monitoring it, those health checks,

65
00:03:41,018 --> 00:03:44,018
but it's sending it on its private IP address.

66
00:03:44,018 --> 00:03:44,418
Again,

67
00:03:44,418 --> 00:03:50,018
the web server isn't exposed to the public side with the public IP address.

68
00:03:50,018 --> 00:03:53,095
Now the typical technology in the background for

69
00:03:53,095 --> 00:03:55,018
the listening is DNS round-robin.

70
00:03:55,018 --> 00:03:57,018
There are other options you can use.

71
00:03:57,018 --> 00:04:01,018
This is kind of the classic, standard way that it's done for web servers.

72
00:04:01,018 --> 00:04:03,842
Round-robin means, say you've got client number 1,

73
00:04:03,842 --> 00:04:07,018
client number 1 gets sent to server number 1,

74
00:04:07,018 --> 00:04:10,018
client number 2, server number 2, client number 3,

75
00:04:10,018 --> 00:04:11,018
server number 3.

76
00:04:11,018 --> 00:04:14,907
Of course the pool of servers, maybe there's only two,

77
00:04:14,907 --> 00:04:18,018
maybe it balances one, then the other, one,

78
00:04:18,018 --> 00:04:19,281
and then the other.

79
00:04:19,281 --> 00:04:19,913
In fact,

80
00:04:19,913 --> 00:04:24,336
this load balancer is able to determine that the instances that it's talking to,

81
00:04:24,336 --> 00:04:28,473
it will actually be able to determine the size of the instance and

82
00:04:28,473 --> 00:04:31,018
how many requests an actual instance could handle.

83
00:04:31,018 --> 00:04:34,900
Now does it make sense to have an unbalanced number of

84
00:04:34,900 --> 00:04:37,018
sizes in your load balancing pool?

85
00:04:37,018 --> 00:04:41,018
Not really, but the load balancer is smart enough to be able to handle that.

86
00:04:41,018 --> 00:04:44,456
So you're communicating from the front end to the back end.

87
00:04:44,456 --> 00:04:48,240
How long should that messaging, should that channel be open?

88
00:04:48,240 --> 00:04:51,796
Well, the default idle timeout is 60 seconds,

89
00:04:51,796 --> 00:04:54,018
and you can change this,

90
00:04:54,018 --> 00:04:59,018
but the timeout applies to the front-end and the back-end connection.

91
00:04:59,018 --> 00:04:59,951
Some caveats,

92
00:04:59,951 --> 00:05:03,685
the classic load balancer routes requests to your

93
00:05:03,685 --> 00:05:07,844
instances on the private subnet, really want to hammer home that point,

94
00:05:07,844 --> 00:05:10,453
so if you look at your own design and say,

95
00:05:10,453 --> 00:05:13,818
hey, why do we have public IP addresses for these web servers?

96
00:05:13,818 --> 00:05:15,618
We don't have to do that.

97
00:05:15,618 --> 00:05:19,702
The instances don't need a public IP address to receive public requests.

98
00:05:19,702 --> 00:05:24,334
They want them from the load balancer who knows the instance,

99
00:05:24,334 --> 00:05:32,000
it's in that pool, it's in the VPC, the security groups are set up, we're all good.

