WEBVTT

00:00.990 --> 00:07.050
Hello everybody and welcome back in that previous video we try a couple different models and found out

00:07.050 --> 00:12.190
the run for us was the best performing model in our particular dataset.

00:12.210 --> 00:16.800
Now in this PDA what we're going to do is we're going to fine tune this model we're going to do primary

00:16.800 --> 00:23.650
tuning and what this could accomplish is is going to find the best parameters to RUN FOREST that gives

00:23.850 --> 00:25.940
the most accuracy in their model.

00:25.980 --> 00:27.310
So how we're going to do that.

00:27.690 --> 00:33.250
Well let's start first with it's like here second for grid search which is what we're doing.

00:33.570 --> 00:38.850
And before I even begin with the research part I want to show you the arguments the rainforests can

00:38.850 --> 00:39.180
show.

00:39.300 --> 00:41.110
So I run with control.

00:41.130 --> 00:48.080
I run the for as you can see it on the Help site and then we head to the help so we can see the argument

00:48.080 --> 00:49.280
that run for stakes here.

00:49.410 --> 00:49.970
OK.

00:50.190 --> 00:51.040
So run them for us.

00:51.050 --> 00:51.990
There are a couple arguments.

00:52.020 --> 00:57.180
Number of estimators which we decided to be 100 the criteria in which we opted to be entropy.

00:57.210 --> 01:03.740
But they can be Guinea as you can see here the max number of features the max that the main samples

01:03.730 --> 01:04.080
played.

01:04.080 --> 01:08.280
So the number of features here as you can see is a number of features to consider when looking for the

01:08.280 --> 01:09.410
best.

01:09.780 --> 01:14.880
Take the next step is instead the maximum depth of the tree Kingo.

01:15.660 --> 01:22.800
So finally we here see the mean samples are split meaning the minimum number of samples required to

01:22.810 --> 01:24.470
split an internal note.

01:24.960 --> 01:27.140
So what does this all mean and how does that help.

01:27.240 --> 01:30.310
Well how it helps us is in the following way.

01:30.450 --> 01:34.640
There are possible values to these different variables here.

01:34.860 --> 01:39.360
And if you have other models that you are playing with search to they're going to have completely different

01:39.360 --> 01:39.960
parameters.

01:40.010 --> 01:43.200
OK but sometimes you don't understand what it means and you're not.

01:43.290 --> 01:46.090
But it doesn't hurt to try different ones.

01:46.500 --> 01:50.410
So there's a couple different options that we can use for these parameters.

01:50.640 --> 01:57.600
So if we select a range of options to choose for each of those parameters and we try every single combination

01:57.600 --> 02:03.930
of those to see which one performs the best with our data that is pretty much what grid search is doing.

02:04.530 --> 02:06.620
So that's what we're going to start.

02:06.630 --> 02:12.900
We're going to try one set of grid search for Guinea one cell for entropy.

02:13.110 --> 02:17.820
When it was talking about the criteria and of course and we're going to see which of them performs the

02:17.820 --> 02:24.270
best and if at all the research has given us any kind of improvement in our performance it is the case

02:24.270 --> 02:29.300
sometimes that grid search will not help you at all but we're going to see in this video.

02:29.340 --> 02:31.420
So that's been first.

02:31.440 --> 02:37.110
We are going to call this round one because it's the first round that we're going to do it and we're

02:37.110 --> 02:38.440
going to call it entropy.

02:38.490 --> 02:48.030
Round one for entropy we're going to give you the parameters which is going to be a dictionary of column

02:48.030 --> 02:50.550
names and the possible values.

02:50.550 --> 02:56.620
So the first name that we're going to try to differentiate is when we max that.

02:57.120 --> 03:01.600
And as you can see here the default ballot for much in lockstep is none.

03:01.800 --> 03:04.350
So we're going to actually give it a couple of hours.

03:04.380 --> 03:08.010
We're going to give it three and none.

03:08.010 --> 03:12.580
This is a test where the non-default is the best possible way to go with math.

03:12.580 --> 03:18.100
There are maybe a numerical argument like Three's a better way to do it.

03:18.210 --> 03:25.180
We are also going to do the same for Max features and the max features we're going to get three arguments.

03:25.230 --> 03:30.630
Three different possibilities and it's possible they are going to be one five and 10.

03:30.660 --> 03:32.070
We don't know if one is enough.

03:32.070 --> 03:34.520
Five is better a greater better.

03:34.660 --> 03:38.660
It's a lot more they're better we don't really know at this point so we're going to try this range.

03:38.670 --> 03:40.950
We're going to do the same for men sample split

03:43.560 --> 03:46.120
samples split.

03:46.210 --> 03:54.160
This is going to be into a string and for men samples played We're going try a different set.

03:54.210 --> 03:58.030
So we're going to try to five and 10.

03:58.020 --> 04:05.070
The reason we do to pipe in 10 or one private in a BB is because from men samples split the default

04:05.070 --> 04:05.410
is to

04:08.410 --> 04:14.230
then we're going to do another one for mean samples leaf.

04:14.340 --> 04:24.440
Another of the arguments that we found this one is going to be again simply 1 5 and 10.

04:25.080 --> 04:26.290
I keep adding these brackets here.

04:26.340 --> 04:32.010
And then finally we're going to end up with the bootstrap

04:36.570 --> 04:38.090
strap strap.

04:38.370 --> 04:45.530
And this is another argument and it's going to tell us whether or not to bootstrap this model is we're

04:45.540 --> 04:48.030
going to select true and false.

04:48.030 --> 04:51.720
So this could be bootstrap or noble truth.

04:51.810 --> 04:55.720
There's only two possible models for this argument so there's nothing else to try.

04:56.580 --> 05:02.040
And oh one more thing we're going to get the criterion that is just going to insure that we're trying

05:02.040 --> 05:05.840
this with entropy and nothing else.

05:06.580 --> 05:10.040
Actually actually in practice we have to be.

05:11.180 --> 05:11.650
And that's it.

05:11.650 --> 05:14.050
Those are all the primary combination we're going to try.

05:14.200 --> 05:19.030
Of course your own version of grid search you can try a ton more attack and less different arguments

05:19.330 --> 05:20.800
different versions.

05:20.890 --> 05:26.500
It all will depend on what you're trying to test and depending on how many different variations you're

05:26.500 --> 05:31.600
given that it's going to take longer to run because of course the has to run one model for each of the

05:31.600 --> 05:34.400
permutations possible for these features.

05:34.900 --> 05:36.300
So we have this parameter.

05:36.340 --> 05:39.610
We are going to create the parameter dictionary.

05:39.610 --> 05:41.420
And finally we're going to create a grid search.

05:41.620 --> 05:47.440
So we're going to set a great search and it's going to be great search.

05:47.440 --> 05:51.020
Now before we can even use this we've got to actually import it.

05:51.150 --> 06:01.080
So let's do it from scale learn that model selection import quick search.

06:01.080 --> 06:02.890
There you go.

06:02.890 --> 06:08.700
We've run this now we used a grid search C-v to create that grid search estimator.

06:08.860 --> 06:14.910
So we use the argument estimator here which is to model the type of model that we're trying to use.

06:15.130 --> 06:19.480
And we're going to give it classifiers because the last model we use with the random forest.

06:19.480 --> 06:24.640
So this is the kind of model that we want to use around the forest.

06:25.180 --> 06:33.290
Then the program great argument is the dictionary of programmers to try out which is parameters we created.

06:33.910 --> 06:34.720
Excellent.

06:35.120 --> 06:41.290
Then the scoring is going to be based on accuracy so we won the judge which is based simply based on

06:41.290 --> 06:42.710
its accuracy.

06:43.060 --> 06:43.880
OK.

06:44.590 --> 06:53.650
It's going to use K4 cross-pollination is going to use 10 different fault for each and accuracy and

06:53.650 --> 06:54.600
that's about it.

06:54.610 --> 07:04.900
I also give the and Jap's argument as negative one because I wanted to use all of my cores to run these

07:05.650 --> 07:06.690
buntu models.

07:06.820 --> 07:12.670
If you don't want it to take a big strain on your computer you can change these to just one to just

07:12.670 --> 07:16.960
leave it as is has a default and that way doesn't take too much of a toll on your computer when you're

07:16.960 --> 07:17.780
running it.

07:17.800 --> 07:19.520
But I wanted to finish this as soon as possible.

07:19.540 --> 07:24.850
So I'm going to use negative one which is again means just that you're using every single core available

07:24.850 --> 07:25.990
and you can.

07:26.450 --> 07:28.890
OK so we're going to run this.

07:29.170 --> 07:29.950
Excellent.

07:30.220 --> 07:35.270
And now the last thing that we've got to do is actually fit this model or the set of models.

07:35.290 --> 07:42.020
So this is where we use the time library because we want a time how long all of this takes.

07:42.100 --> 07:46.750
So there you can see how long it took on my computer and you can get an estimate of how long it may

07:46.750 --> 07:47.550
take years.

07:47.650 --> 07:53.770
Again depending on how fast your computer is this may take different amounts of time depending on how

07:53.770 --> 08:00.190
many and just decide these are extreme why train

08:04.110 --> 08:10.710
one equals time that time again is to get the final time.

08:11.050 --> 08:15.610
And we're going to get a print statement to print out how long it took and this won't take the form

08:15.610 --> 08:20.670
of the follows took a lot of work.

08:20.690 --> 08:31.200
That's the most second and this is going to map the difference between time 1 and time sir.

08:32.050 --> 08:32.740
Excellent.

08:33.040 --> 08:35.650
So let's run these.

08:36.700 --> 08:41.670
Now this is going to run for a few minutes maybe more depending on how many end jobs you did depending

08:41.670 --> 08:43.310
on how fast your computer is.

08:43.510 --> 08:48.610
So don't worry about I'll give it a minute go out do something else while he's running.

08:48.610 --> 08:52.030
I'm going to wait until this finishes and then come back to you guys.

08:52.030 --> 08:59.650
And before that I will note one more thing if ever you have a problem with running great search this

08:59.650 --> 09:01.720
may happen for a briery reasons.

09:01.900 --> 09:05.370
But I used to get errors based on that.

09:05.650 --> 09:12.910
So if you ever have a problem then you should make sure you have the latest installment of Joplin Apel.

09:12.970 --> 09:24.080
So for example on the terminal you would use install or you would use install job live to make sure

09:24.080 --> 09:25.390
you install the latest one.

09:25.540 --> 09:34.380
If you're an anaconda that will be Conder install in public use to make sure that there is no error

09:34.380 --> 09:36.920
that is happening anyways.

09:37.390 --> 09:39.650
Let's wait for the grid search to finalize.

09:43.610 --> 09:48.320
Now the research has finished and we can see the results.

09:48.470 --> 09:54.340
So if you head to the council you can see that the stoker on 719 seconds.

09:54.470 --> 09:57.050
So definitely over 10 minutes do this.

09:57.110 --> 09:59.600
So let's see what results we actually got.

10:01.770 --> 10:11.860
Let's get these recommendations out of here put him in the top so that you're a member and let's actually

10:11.860 --> 10:12.390
see the results.

10:12.400 --> 10:21.370
So we use our air underscore best accuracy that's where we want to call this variable and it's going

10:21.370 --> 10:31.290
to be the result of grid surge that we just run extracting the best score and we can see it right here.

10:31.540 --> 10:35.320
Now then we're going to also get the best parameters.

10:35.320 --> 10:39.340
So we're going to call it our best parameters

10:41.930 --> 10:52.060
and it's going to be another variable of research which is best perhaps.

10:52.060 --> 10:52.890
Great.

10:53.440 --> 11:04.130
And finally we're going to just return both of these with accuracy and our programs are excellent.

11:04.270 --> 11:07.730
Let's run this and look at the terminal.

11:07.960 --> 11:13.600
So the console shows 63 almost 64 percent accuracy which is pretty good.

11:13.600 --> 11:16.260
Not that much of an improvement maybe by a few points.

11:16.340 --> 11:24.370
Sarah Searle one point here and it follows the best set of parameters are when it's stripped of course

11:24.370 --> 11:26.970
is entropy when the Mac step is set to none.

11:27.010 --> 11:32.940
When the max features to 5 the mean sample leaves it to 1 and sell it to 10.

11:33.580 --> 11:35.020
So what do we do with this.

11:35.020 --> 11:43.450
Well we can use these features run on the test and see how he performs albeit we can keep searching

11:43.450 --> 11:44.680
for a better perhaps.

11:44.810 --> 11:48.430
And that's what we're going to do in the next bit in the next video we're going to play the second round

11:48.430 --> 11:54.040
of grid search through these dataset and see if we can find a slightly better accuracy and once we do

11:54.040 --> 12:00.190
the second round we're going to play the result of the second round into the test set and see how good

12:00.190 --> 12:02.070
of a predictor this new model is.

12:02.230 --> 12:07.810
If it is a relatively better predictor then we can choose instead of the previous run the forest model

12:08.030 --> 12:13.240
a.k.a. we can build the run for tomorrow with all these parameters or all of these arguments.

12:13.240 --> 12:19.360
We can also try the same grid search process for getting instead of entropy.

12:19.390 --> 12:20.980
So that's we're going to do in the next video.

12:20.980 --> 12:22.850
Thank you for watching.

12:22.860 --> 12:23.850
See you then.
