WEBVTT

00:00.900 --> 00:02.280
Welcome back everybody.

00:02.280 --> 00:08.430
Today we're going to be working on balancing a trainset and featuring Schelling both of which are important

00:08.430 --> 00:10.900
for our current model building process.

00:10.980 --> 00:14.810
So we're balancing the trade and say over the years in general.

00:15.190 --> 00:17.650
Well let's explore the why.

00:17.880 --> 00:21.890
Call it trainset and see what we find.

00:22.200 --> 00:27.280
If we look at why trade which is a common question and we do it is simple value counts.

00:27.450 --> 00:30.260
We're going to see the distribution for it.

00:30.480 --> 00:31.150
Great.

00:31.320 --> 00:40.930
So there is around talk hey we were trying to go 0 and then run a almost 9000 Chinese was one since

00:40.940 --> 00:42.810
it's very spread out.

00:43.080 --> 00:50.100
There's nothing we do here but we're going to still explore other more by realizing what will happen

00:50.790 --> 00:54.240
if we push for Martin was only in the 60s.

00:54.240 --> 00:55.600
So what are we talking about.

00:55.730 --> 01:03.310
Let's think about assume our motto is only giving us a little knowledge is still useful and a good lot

01:03.390 --> 01:08.410
of the company but it's not some 80 percent accuracy model it's only 60 percent.

01:08.600 --> 01:09.360
OK.

01:09.660 --> 01:18.900
So if there is 60 percent of zeros in the response variable and say there is 40 percent more than once

01:20.210 --> 01:26.690
and the manone chooses all of them to be zero aka a completely biased model that does not work at all.

01:26.770 --> 01:28.720
Selects everything it goes to zero.

01:28.890 --> 01:36.760
The accuracy is still going to be at the 60 percent mark because its going to be as in the correction.

01:36.870 --> 01:42.270
So don't count for problems like this in which the accuracy may be a little deceiving and or he is in

01:42.270 --> 01:47.460
which the model may be completely biased and still he was an accuracy of 50 percent.

01:47.550 --> 01:55.800
We balance between say that as we balance the amount of zeros and ones that the train set has in response

01:55.800 --> 01:57.290
variable.

01:57.360 --> 02:04.710
That way we can guarantee the one in a list for accuracy within our model is as a result of our model

02:04.710 --> 02:12.220
itself and not a random permutation on how many zeros ones are in the response very often trains.

02:12.720 --> 02:21.630
So this will begin this far by splitting the exit into responsive values and in saying so cost index

02:22.760 --> 02:30.500
is going to be listen to wide training which is our response variable and all of the elements where

02:30.520 --> 02:37.440
the values are equal to 1 8 positive responses and we want to select the index from those which is just

02:37.450 --> 02:39.010
a right in the last five years.

02:39.090 --> 02:44.550
We're not in the balance we're getting in this but as far as we're going to do the same from the next

02:44.550 --> 02:51.000
we're going to do next in this because exactly this but we're waiting to see.

02:51.990 --> 02:54.850
So it's replaces action.

02:55.230 --> 02:56.520
So what have we accomplished so far.

02:56.520 --> 03:04.120
We just laid the positive and negative values for the response variable into its own indexes.

03:04.140 --> 03:05.410
Now we're going to do.

03:05.410 --> 03:08.710
And it feels so good.

03:08.730 --> 03:16.620
The land of the positive for just how many positive volumes there were in the set is greater than the

03:16.620 --> 03:21.480
length of the negative which is Geo's negative index.

03:22.050 --> 03:27.070
Then what we're going to do is we're going to call a higher variable.

03:27.150 --> 03:33.810
We're going to call this higher incidence the cost to the positive because potteries higher based on

03:33.810 --> 03:39.360
these costs and of course then the lower variable is going to be okay.

03:40.240 --> 03:41.090
Okay.

03:41.180 --> 03:47.290
So follow along a little bit more else if that's not the case we're going to do the opposite.

03:47.390 --> 03:53.980
Meaning that higher is going to be a negative value and lower it's going to be the positive.

03:54.390 --> 04:07.260
So we just simply copy is and change the top for lower and the bottom for higher tax on somebody.

04:07.260 --> 04:13.380
So all these what it's accomplishing is selecting which of them are the higher list and which of them

04:13.380 --> 04:15.240
are the smallest list.

04:15.270 --> 04:17.230
Now we're going to use Rundell now.

04:17.460 --> 04:23.640
And first I'm setting a C and why am I saying this because we want to use a random function in the next

04:23.690 --> 04:31.080
lines and I want to be able to be duplicating something to see and see what we do next is the meat of

04:31.080 --> 04:46.360
the set which is set in higher Brentham the choice higher again and slice off land of lower.

04:47.370 --> 04:58.110
So what this accomplishes is that it's going to randomly select the index higher of size length of lower

04:58.440 --> 05:04.870
meaning that we're going to see get hired into a subset that is as big as the lower.

05:04.950 --> 05:10.510
So we're pretty much making higher because the lower by chopping some of the items a randomly select

05:10.560 --> 05:18.830
some of those values now because these resoled returns in a way we're going to make lower into an array

05:18.860 --> 05:19.410
as well.

05:19.470 --> 05:23.470
This is just for consistency not by as array.

05:23.580 --> 05:24.240
Excellent.

05:24.510 --> 05:29.640
And it's going to be lower making both the same types.

05:29.640 --> 05:37.200
And finally we're going to subsetting the trainset by the values that we have selected.

05:37.830 --> 05:43.920
So if we select a lot these finds the items by row index.

05:43.920 --> 05:47.290
So we can select the new indexes.

05:47.430 --> 05:53.490
Now then your indexes are going to be the combination of higher and lower.

05:53.790 --> 05:56.970
So you actually create a variable to possibly holer.

05:57.020 --> 06:06.180
So you're in the US right here going to be the concatenation and the concatenates lower and higher

06:09.720 --> 06:10.650
and higher.

06:11.540 --> 06:18.450
And all of this is accomplishing is that we're combining the higher and lower in this model which have

06:18.450 --> 06:19.900
the same size.

06:19.920 --> 06:26.360
So now we see here lot that new access and all that hops.

06:26.550 --> 06:34.440
So we are subsetting the trend set by another trend set in which he has the response variable back and

06:34.440 --> 06:34.950
forth.

06:35.070 --> 06:41.970
We have to do the same to the wife said the wife said is going to be instead of running costs because

06:41.990 --> 06:43.500
they only has one column.

06:43.500 --> 06:47.170
It's going to be simply the White said which is why train

06:51.450 --> 06:53.640
and all that's coming up.

06:53.880 --> 06:59.700
And we're going to take it to the white to the white train in your view this is that we have and that's

06:59.700 --> 07:02.490
what we see in this is because it's a subset that.

07:03.220 --> 07:04.480
Excellent.

07:04.530 --> 07:06.400
So this should be the final step.

07:06.450 --> 07:13.780
And when we have finished our balancing part of this is the next step is feature scale and if you remember

07:13.780 --> 07:20.120
if it your skill it is simply normalizing all the fields numerical fields of course that we have in

07:20.130 --> 07:27.600
our data set and making sure that they are not to be so that they have a lot more weight than they should

07:28.020 --> 07:28.980
on the equation.

07:29.010 --> 07:30.730
Look you see regression.

07:31.260 --> 07:33.440
So that was kind of a mouthful.

07:33.630 --> 07:39.700
But oh it's I mean it's just it's normalacy on the medical fields so that they are pounds.

07:39.890 --> 07:48.740
So this one stands Scheller than what we do is we're going to create a killer cages and call all the

07:48.760 --> 07:50.500
centers that we just imported.

07:50.520 --> 07:51.440
Excellent.

07:51.480 --> 07:57.390
So we run this then we're going to create a new training center wildlife breeding and utrum said you

07:57.400 --> 08:05.670
see in the moment that is going to be the transforming version of the original X-raying and we're going

08:05.670 --> 08:10.820
to use SIFI transform because we want to face first the X-ray.

08:10.860 --> 08:17.220
And once you fit it in one transform any place not one extra step that we're going to do here is going

08:17.220 --> 08:22.310
to make a really are part of the brain.

08:22.500 --> 08:23.320
Excellent.

08:23.730 --> 08:26.600
And I won't explain why I'm doing it anyways.

08:26.640 --> 08:29.090
So we run this actually works.

08:29.160 --> 08:35.570
So we're going to do something similar for test two which is creating a new later set which is a panacea

08:35.700 --> 08:43.660
from all these standard killer apply to the tests.

08:45.160 --> 08:48.210
So it works as well.

08:48.210 --> 08:56.670
Now the reason I made it into a different frame is because the Scheller returns and non-firing multidimensional

08:56.670 --> 08:57.990
number.

08:58.260 --> 09:03.150
And when we do that we lose the index of the rows and we lose the column names and we don't want to

09:03.150 --> 09:04.080
do that.

09:04.770 --> 09:08.510
So we are going to extract those values.

09:08.730 --> 09:15.010
So these new scale data frame is going to have all of the names of course.

09:15.060 --> 09:23.850
So we're going to change the column names of the original and we can set it up on the new columns that

09:23.850 --> 09:32.740
values excellent tissues period and these should work to run this perfectly.

09:32.750 --> 09:37.790
We're going to do the same for tests.

09:37.800 --> 09:46.050
The test is called I'm going to be focused on this and it works just as well.

09:46.070 --> 09:48.240
Then we're going to do the same for index.

09:48.660 --> 09:55.440
So the idea is almost identical except that we're going to replace columns for Enochs

10:01.730 --> 10:06.050
and for a test in x and x

10:09.170 --> 10:12.730
x when so you work as well.

10:13.140 --> 10:16.490
And if we run this great you works fine.

10:16.490 --> 10:25.990
So finally since we have the new train set we're going to replace your vision with this and to it.

10:26.570 --> 10:33.340
And then the same for test is just going to be access to and we run these two.

10:33.350 --> 10:37.880
And what we have done the feature scaling part of this project.

10:37.940 --> 10:44.180
We can look at the variable extreme to see what the final result looks like.

10:44.180 --> 10:45.770
So let's take a look.

10:46.580 --> 10:54.640
So we have these two right here on this chart sorry the has all the numerical codes now bounce

10:57.180 --> 10:58.410
right.

10:59.090 --> 11:01.150
So we're find less with these systems.

11:01.220 --> 11:07.820
Next we're going to actually build the model so that you very much for watching and see in the next

11:07.860 --> 11:08.140
we.
