WEBVTT

00:00.990 --> 00:02.670
Hello everybody.

00:02.670 --> 00:06.910
Today we're going to begin our process of building the actual classification.

00:07.290 --> 00:10.380
So let's jump right into it.

00:10.440 --> 00:16.350
First of course we need to import the right portion from the Escalante model library and we have done

00:16.350 --> 00:19.700
so by just running this particular line.

00:19.870 --> 00:22.130
Now it's actually build those models.

00:22.320 --> 00:28.080
So we are going to call the model the classifier because it is a classic model and we're going to call

00:28.080 --> 00:28.650
it as such.

00:28.650 --> 00:33.890
We want to use the congressional function that we just imported.

00:34.320 --> 00:41.090
I'm going to ask a random state argument just because I like to make sure I duplicate any work I do.

00:41.400 --> 00:42.030
Good.

00:42.100 --> 00:47.220
We run it and successfully you run me that everything's gotten so far.

00:47.220 --> 00:53.430
Now let's feed our mouth so we put the classifier that felt pretty good.

00:53.430 --> 00:55.600
We really tried.

00:55.680 --> 01:02.940
Which is why we obtained the previous video and that one also from the PC which are the x and y.

01:03.810 --> 01:05.230
And we have got the model.

01:05.250 --> 01:05.990
There you go.

01:06.190 --> 01:07.050
It's true.

01:07.200 --> 01:13.470
Now this is the results were good so again as we have seen before by calling that pretty Fanjul from

01:13.470 --> 01:14.850
the pacifier.

01:15.120 --> 01:22.730
So we're on the CROSSFIRE we call the product function within it and we meet the test set which is X

01:22.740 --> 01:24.210
test.

01:25.050 --> 01:29.860
And that's been the easiest the solution for white test which you were going to call y.

01:30.330 --> 01:36.510
So now that we have the predictions this actually evaluate the model results and see what accuracy we

01:36.510 --> 01:37.190
got.

01:37.590 --> 01:44.340
So the accuracy again we're going to import a couple of functions from the Escalona package and they

01:44.340 --> 01:53.950
are as follows from his learn that metrics great importance confusion metrics.

01:54.090 --> 02:10.860
We're going to import accuracy or as well as one score the precision score and the rigor score actually

02:11.240 --> 02:12.830
we run it and we go.

02:13.320 --> 02:19.600
So now we're going to create the confusion matrix which is GCM and of course it's a simple cold fusion

02:19.830 --> 02:27.900
matrix function and we can get the correct results for the test dataset and the particular results for

02:27.930 --> 02:31.290
this is excellent.

02:31.320 --> 02:33.210
So we have the confusion.

02:33.480 --> 02:37.130
We're going to look at the conversion matrix in a bit with a nice little clock.

02:37.140 --> 02:39.960
We don't have to but we're going to go out of our way to do it.

02:40.230 --> 02:43.980
But we're also we've got a couple of major uses for this.

02:44.190 --> 02:49.980
So let's look at the score which is the accuracy or the accuracy score is.

02:50.040 --> 02:54.050
As you can see a call to the accuracy score function.

02:54.810 --> 02:58.140
And again we get the same arms white tests and white bread.

02:58.270 --> 03:01.810
And this is something that we're going to be using for the next couple of lines.

03:01.830 --> 03:03.460
So let me copy here.

03:03.490 --> 03:09.970
We've paid for it and we write and you see the results you're going to see that the model has an accuracy

03:09.970 --> 03:11.990
of over 61 percent.

03:12.180 --> 03:18.960
Now even though it is not super high accuracy is good for many purposes going to find an industry more

03:18.960 --> 03:24.450
often than not that it's not going to be clean or that it's not going to be too indicative of the response

03:24.470 --> 03:25.360
variable.

03:25.710 --> 03:27.820
So you're going to be happy with.

03:27.830 --> 03:32.810
Fifty five sixty one fifty eight sixty five.

03:33.030 --> 03:37.860
Any kind of accuracy in that range as long is of course greater than 50.

03:38.610 --> 03:41.840
So if you want accuracy is sufficient for our purposes.

03:41.960 --> 03:44.720
So now we're going to do the same for that position score.

03:45.060 --> 03:47.470
So it's clearly the position score.

03:47.490 --> 03:51.570
Now if you guys don't remember what precision score means.

03:51.570 --> 04:01.080
Let me explain the precision score is the score of the true positives divided by the two Basus Plus

04:01.080 --> 04:06.580
the false positives meaning of all the past was predicted.

04:06.780 --> 04:09.040
How many of them are actually true.

04:09.750 --> 04:12.640
In this case the president scores.

04:13.020 --> 04:17.260
Meaning that there is not a lot of good precision.

04:17.280 --> 04:24.440
So out of all the predicted positives we got half of them right which is almost 50 percent.

04:24.480 --> 04:29.030
So this particular result is very important and it's a reason we have to do is accurate precision.

04:29.120 --> 04:33.990
And we don't get the model we built with it in the previous video but we have to do it in this video

04:33.990 --> 04:35.310
is extremely important.

04:35.430 --> 04:38.670
So we see that the procedure is not that great.

04:38.970 --> 04:42.440
Now let's do the same for the recall function recall.

04:42.480 --> 04:43.250
Great.

04:43.830 --> 04:50.880
And we run the risk of of course when we get a 75 percent okay this is pretty interesting.

04:50.880 --> 04:57.720
So if they recall again is the fact that true vacillates the by the true apostles Plus the false negatives

04:58.320 --> 05:02.630
many of for the actual positives they exist.

05:02.710 --> 05:05.000
How many We believe this is true.

05:06.040 --> 05:09.010
And that's the 75 percent which is pretty pretty good.

05:09.010 --> 05:17.170
So whenever you have bad news like this a decent accuracy or precision in a high recall we use the for

05:17.260 --> 05:23.770
calculation that we imported from Escaflowne metrics and that is the fun score to give us a better measure

05:23.910 --> 05:29.440
how our model is performing because the EF 1 score is a function of precision Ringo and he balances

05:29.440 --> 05:30.490
them out.

05:30.520 --> 05:41.770
So let's run one score on the arguments and the X1 score is similar to the accuracy.

05:41.850 --> 05:45.040
A 61 percent almost 60 percent.

05:45.310 --> 05:50.110
So after everything husbanding into consideration the accuracy the precision to recall we know that

05:50.110 --> 05:56.240
the train set is bounce but we know that the test it doesn't have to be bad.

05:56.260 --> 06:00.500
Because in the real world they're not going to be getting into.

06:00.530 --> 06:02.170
I not always want to be bad.

06:02.250 --> 06:03.900
It's never about us.

06:03.970 --> 06:10.660
So we are satisfied with 61 percent because it is of course greater than 50 percent which is what we

06:10.720 --> 06:12.380
were trying to avoid.

06:12.460 --> 06:18.620
And now to end this part we're going to bill the confusion matrix nicely.

06:19.300 --> 06:24.190
And again in front of the board is it could be getting the whole of the class.

06:24.280 --> 06:27.880
So what should I copy the code here and I want to go over it with.

06:28.290 --> 06:34.990
So the data from CM means simply we have quit at the time frame of the completion matrix with the right

06:35.020 --> 06:43.000
index labels in column names then we're blowing the figure with a nice view or size where the font for

06:43.000 --> 06:44.510
all the numbers are.

06:44.890 --> 06:49.250
And finally we're reading the map of four squares.

06:49.310 --> 06:55.960
Our vision matrix with different colors that many of the density of this size and this line right here

06:55.960 --> 07:02.890
is simply to return the actual score because whenever you print a map you also want the accuracy but

07:02.890 --> 07:04.990
the accuracy of course will be printed on the console.

07:04.990 --> 07:07.930
We manage one of these play with them.

07:08.110 --> 07:12.240
So let's run this line and see where we get answers.

07:12.250 --> 07:22.090
Here is the Metrix 60 39 0 0 means that they have been 16:30 nine predictions of Syria when the body

07:22.090 --> 07:23.350
was actually there.

07:23.440 --> 07:25.770
So this is a correct prediction.

07:25.780 --> 07:28.450
So is this now.

07:28.490 --> 07:35.960
These two range in the 16:00 range while this incorrect prediction is on 15:1.

07:36.070 --> 07:43.460
This is the reason why the precision is close to 50 percent because this is almost as big as this.

07:43.780 --> 07:47.420
But this one right here on the other end is not space.

07:47.920 --> 07:54.090
Therefore this is build some models accuracy a lot more because the model is a lot better at predicting

07:54.320 --> 07:58.430
these to accurately than it is happening in these two actually right here.

07:58.630 --> 08:01.220
And that is why we have the results.

08:01.670 --> 08:02.320
OK.

08:02.500 --> 08:04.150
That's fine.

08:04.150 --> 08:05.010
It's not perfect.

08:05.110 --> 08:10.840
But can we build this model for the super-Tuesday examine results that are not perfect but it could

08:10.840 --> 08:12.330
still be used in age.

08:12.370 --> 08:18.640
So this is going to be the end of this video in the next video we're going to go away for cross-pollination

08:18.640 --> 08:23.060
very quickly and then we're going to move into feature selection to finalize our on.

08:23.350 --> 08:24.710
Thank you very much for watching.

08:24.820 --> 08:26.150
And see you in the next video.
