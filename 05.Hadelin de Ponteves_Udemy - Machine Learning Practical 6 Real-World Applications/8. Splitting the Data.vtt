WEBVTT

00:00.330 --> 00:09.330
Now we're going to split the data and the labels into the training data set and the testing data set

00:09.740 --> 00:15.480
and we're also going to use their sikat functions to do that.

00:21.330 --> 00:27.890
So we're going to import the train that's split and to use that.

00:28.320 --> 00:39.640
This will give us 4 outputs that we're going to label as x train x test white train and white tests.

00:39.740 --> 00:40.330
OK.

00:43.870 --> 00:48.260
We're going to give that the x and y Miles.

00:48.520 --> 00:55.230
We're going to tell tell it that the test size will be of 30 percent.

00:55.540 --> 01:00.480
And we're going to just have a fixed random state.

01:00.610 --> 01:01.020
Great.

01:01.030 --> 01:03.450
So that's done now.

01:03.640 --> 01:08.130
We will try to understand the company that we have in our training.

01:08.130 --> 01:10.790
Now we're testing that.

01:11.290 --> 01:15.240
We're going to use the shape function to do that.

01:15.580 --> 01:23.320
So we have almost 200000 votes and 29 Gollum's you know we're trying in data set

01:27.300 --> 01:34.240
on hours testing data set up 85 gay votes.

01:34.570 --> 01:35.520
OK.

01:35.910 --> 01:41.550
Next thing we're going to transform our data sets in two by race.

01:41.580 --> 01:45.170
So we're going to need that in that formats later.

01:47.270 --> 02:18.190
We're going to just use the MP function to do that and we're going to do that for all of our firewalls.

02:18.500 --> 02:26.030
Now we're going to create a deep neural network that will help us predict if a neutral section is fraudulent

02:26.120 --> 02:26.660
or not

02:30.970 --> 02:31.840
reach us.

02:31.850 --> 02:35.700
Leave the comment great.

02:35.760 --> 02:45.490
We're going to import the sequential mail from us and we're also going to import dense layers about

02:45.580 --> 03:09.260
layers.

03:09.290 --> 03:16.160
Next thing we're going to define our model our model will be a sequential model.

03:16.370 --> 03:26.960
That means that one layer will come after the other and when they find a stack of letters for going

03:26.960 --> 03:30.680
to use a whole bunch of dense layers

03:34.870 --> 03:42.550
we're going to use about layers in the middle to avoid overfitting and then more dense layers

03:47.920 --> 03:54.460
how many As many as I think are necessary we're going to do our first advent.

03:54.460 --> 04:01.870
We're going to measure our results and if we need a more complex model we'll just eat it and create

04:01.960 --> 04:02.930
a new model.

04:02.950 --> 04:06.650
Change it once more and measure the results again.

04:10.020 --> 04:13.890
So we be using Velu activation

04:16.410 --> 04:19.430
using almost all the dense layers

04:22.160 --> 04:30.650
except for the last one that will cover sigmoid activation because we're doing binary classification

04:30.730 --> 04:31.550
problem.

04:34.660 --> 04:42.140
We really need to tell our deep neural network how many columns to expect in the first layer.

04:42.310 --> 04:51.490
That's the input they mention that must match our number of columns in our data set.

04:51.520 --> 04:55.740
That's 29 because we explored the shape before.

04:55.940 --> 04:56.620
OK.

04:58.920 --> 05:02.630
We also cup a single output node.

05:02.700 --> 05:10.620
In our last layer that that's the probability of the transaction being fraudulent or not and then we

05:10.620 --> 05:16.000
cannot as many notes in the all the other players as we can't see or necessarily

05:19.630 --> 05:29.930
with that in that unit parameter for every layer we're stopped with 16 will increase that 24

05:34.510 --> 05:41.190
we'll just need to complete the dropout layer and we're going to say that we will help up point five

05:41.530 --> 05:45.040
probability of dropping each node.

05:45.120 --> 05:51.970
So now with our model defined Let's check it out using the summary function.

05:52.170 --> 05:52.900
OK.

05:53.010 --> 05:57.420
So we see that every parameter we just define it much.

05:57.570 --> 06:03.890
And that will come up almost to folks and amateurs to train our neural network.
