WEBVTT
1
1

00:00:00.480  -->  00:00:01.330
<v Instructor>Hello and welcome</v>
2

2

00:00:01.330  -->  00:00:02.900
to this Python tutorial.
3

3

00:00:02.900  -->  00:00:04.680
All right so we just implemented
4

4

00:00:04.680  -->  00:00:07.890
our sample_h function to sample the hidden node
5

5

00:00:07.890  -->  00:00:10.790
according to the probabilities p_h_given_v,
6

6

00:00:10.790  -->  00:00:12.160
and now we're gonna do the same
7

7

00:00:12.160  -->  00:00:14.400
for the visible node because, of course,
8

8

00:00:14.400  -->  00:00:16.500
from the values in the hidden nodes,
9

9

00:00:16.500  -->  00:00:18.770
that is whether they were activated or not,
10

10

00:00:18.770  -->  00:00:21.370
we will also estimate the probabilities
11

11

00:00:21.370  -->  00:00:22.760
of the visible nodes,
12

12

00:00:22.760  -->  00:00:24.730
that is the probabilities that each
13

13

00:00:24.730  -->  00:00:26.740
of the visible node equals one.
14

14

00:00:26.740  -->  00:00:28.950
And that is, of course, because our goal
15

15

00:00:28.950  -->  00:00:32.020
in the end is to output the predicted ratings,
16

16

00:00:32.020  -->  00:00:35.290
zero one, of the movies that were not originally
17

17

00:00:35.290  -->  00:00:38.530
rated by the user, and these new ratings
18

18

00:00:38.530  -->  00:00:40.590
that we get in the end are taken
19

19

00:00:40.590  -->  00:00:43.100
from what we obtained in the hidden node,
20

20

00:00:43.100  -->  00:00:45.500
that is from the samples of the hidden node.
21

21

00:00:45.500  -->  00:00:48.380
So we have to make this function sample_v also,
22

22

00:00:48.380  -->  00:00:49.780
but it's not the only reason.
23

23

00:00:49.780  -->  00:00:52.230
It's because we also need it for Gibbs sampling
24

24

00:00:52.230  -->  00:00:54.770
that we will apply next when we approximate
25

25

00:00:54.770  -->  00:00:56.750
the log likelihood gradience.
26

26

00:00:56.750  -->  00:00:58.640
All right so let's make this function,
27

27

00:00:58.640  -->  00:01:00.860
and good news, it's going to be very simple
28

28

00:01:00.860  -->  00:01:02.500
because, basically, we just need
29

29

00:01:02.500  -->  00:01:06.110
to copy this sample_h function
30

30

00:01:06.110  -->  00:01:07.830
because then you'll see that we will replace
31

31

00:01:07.830  -->  00:01:09.210
just one or two things,
32

32

00:01:09.210  -->  00:01:11.440
and you can already guess what we'll replace.
33

33

00:01:11.440  -->  00:01:15.560
So let's copy that and okay.
34

34

00:01:15.560  -->  00:01:17.860
So first, we're gonna call our function
35

35

00:01:17.860  -->  00:01:20.890
sample_v because we will make some samples
36

36

00:01:20.890  -->  00:01:24.040
of the visible node according to the probabilities
37

37

00:01:24.040  -->  00:01:28.580
p this time v given_h.
38

38

00:01:28.580  -->  00:01:31.500
You know given the values of the hidden nodes
39

39

00:01:31.500  -->  00:01:34.230
we return the probabilities that each
40

40

00:01:34.230  -->  00:01:35.920
of the visible nodes equals one.
41

41

00:01:35.920  -->  00:01:36.870
So here that's the same.
42

42

00:01:36.870  -->  00:01:37.733
It's p_v_given_h,
43

43

00:01:40.060  -->  00:01:41.630
the probabilities that the visible nodes
44

44

00:01:41.630  -->  00:01:44.070
equals one given the values of the hidden nodes
45

45

00:01:44.070  -->  00:01:45.880
that is given whether the hidden nodes
46

46

00:01:45.880  -->  00:01:47.630
are activated or not.
47

47

00:01:47.630  -->  00:01:49.830
So here, again, that's the same p_v_given_h.
48

48

00:01:52.510  -->  00:01:53.610
All right and that's the same.
49

49

00:01:53.610  -->  00:01:56.860
We return the probability of v_given_h,
50

50

00:01:56.860  -->  00:02:00.720
and we return some samples of the visible node
51

51

00:02:00.720  -->  00:02:02.960
still based on that Bernoulli sampling.
52

52

00:02:02.960  -->  00:02:05.890
That is we have our vector of probabilities
53

53

00:02:05.890  -->  00:02:07.000
of the visible nodes.
54

54

00:02:07.000  -->  00:02:10.790
That is since we have 1,682 movies,
55

55

00:02:10.790  -->  00:02:14.040
then we have 1,682 visible nodes.
56

56

00:02:14.040  -->  00:02:17.960
So we have a vector of 1,682 probabilities,
57

57

00:02:17.960  -->  00:02:20.730
one probability for each of the visible nodes,
58

58

00:02:20.730  -->  00:02:22.740
and so each of these probabilities
59

59

00:02:22.740  -->  00:02:24.560
is the probability that the corresponding
60

60

00:02:24.560  -->  00:02:26.730
visible node is equal to one
61

61

00:02:26.730  -->  00:02:29.660
but that remember is given the activations
62

62

00:02:29.660  -->  00:02:31.000
of the hidden nodes.
63

63

00:02:31.000  -->  00:02:32.747
So we have this vector of probabilities
64

64

00:02:32.747  -->  00:02:35.380
p_v_given_h, and from this vector
65

65

00:02:35.380  -->  00:02:38.180
of probabilities we return some sampling
66

66

00:02:38.180  -->  00:02:39.420
of the visible nodes.
67

67

00:02:39.420  -->  00:02:42.390
That is let's say that the i f visible node
68

68

00:02:42.390  -->  00:02:45.070
has a probability of 0.25,
69

69

00:02:45.070  -->  00:02:46.480
then we take a random number
70

70

00:02:46.480  -->  00:02:47.800
between zero and one.
71

71

00:02:47.800  -->  00:02:51.060
If this number is below 0.25,
72

72

00:02:51.060  -->  00:02:53.220
then this visible node will get the value one.
73

73

00:02:53.220  -->  00:02:54.500
So that means that we predict
74

74

00:02:54.500  -->  00:02:57.230
that the movie corresponding to that visible node
75

75

00:02:57.230  -->  00:02:59.420
will get a like by the user,
76

76

00:02:59.420  -->  00:03:01.420
and if this random number is larger
77

77

00:03:01.420  -->  00:03:03.770
than 0.25, then this visible node
78

78

00:03:03.770  -->  00:03:05.010
will get the value zero.
79

79

00:03:05.010  -->  00:03:06.890
And, therefore, we predict that the movie
80

80

00:03:06.890  -->  00:03:08.450
corresponding to that visible node
81

81

00:03:08.450  -->  00:03:11.120
will not get a like by the user.
82

82

00:03:11.120  -->  00:03:12.670
All right so let's see,
83

83

00:03:12.670  -->  00:03:13.960
what do we need to change more?
84

84

00:03:13.960  -->  00:03:16.392
So, okay, we replaced the probabilities
85

85

00:03:16.392  -->  00:03:19.290
p_h_given_v by p_v_given_h here,
86

86

00:03:19.290  -->  00:03:20.540
here and here as well,
87

87

00:03:20.540  -->  00:03:22.000
so that's good, but that's not all.
88

88

00:03:22.000  -->  00:03:24.470
We need to change, of course, what's inside
89

89

00:03:24.470  -->  00:03:26.040
the activation function,
90

90

00:03:26.040  -->  00:03:27.400
and to do the required change
91

91

00:03:27.400  -->  00:03:28.910
well, first, we will replace
92

92

00:03:28.910  -->  00:03:31.660
that variable x by y.
93

93

00:03:31.660  -->  00:03:33.500
You know x in this sample_h function
94

94

00:03:33.500  -->  00:03:35.240
represented the visible node
95

95

00:03:35.240  -->  00:03:37.330
because we apply the sample_h function
96

96

00:03:37.330  -->  00:03:39.070
to the visible node because we want
97

97

00:03:39.070  -->  00:03:41.100
to return the probabilities that the hidden nodes
98

98

00:03:41.100  -->  00:03:43.430
equal one according to the value
99

99

00:03:43.430  -->  00:03:44.370
of the visible nodes.
100

100

00:03:44.370  -->  00:03:46.470
So you know the variable is the visible node,
101

101

00:03:46.470  -->  00:03:49.300
but here we were making this sample_v function
102

102

00:03:49.300  -->  00:03:51.340
that will return the probabilities
103

103

00:03:51.340  -->  00:03:53.940
of the visible nodes given the values
104

104

00:03:53.940  -->  00:03:54.860
of the hidden nodes.
105

105

00:03:54.860  -->  00:03:56.920
So the variable is this time the values
106

106

00:03:56.920  -->  00:03:58.909
of the hidden nodes, and therefore y corresponds
107

107

00:03:58.909  -->  00:04:00.590
to the hidden nodes.
108

108

00:04:00.590  -->  00:04:05.050
So here that's the same we replace wx by wy.
109

109

00:04:05.050  -->  00:04:07.390
Then same we take the torch product
110

110

00:04:07.390  -->  00:04:12.390
of matrices, of tensors, of not x but y
111

111

00:04:12.660  -->  00:04:15.440
by the torch tensor of all the weight,
112

112

00:04:15.440  -->  00:04:17.120
but this time since we're making
113

113

00:04:17.120  -->  00:04:19.470
the product of the hidden nodes
114

114

00:04:19.470  -->  00:04:22.390
and the torch tensor of weight, that is w
115

115

00:04:22.390  -->  00:04:26.150
for the probabilities p_v_given_h, well here
116

116

00:04:26.150  -->  00:04:28.720
we must not take the transpose
117

117

00:04:28.720  -->  00:04:30.583
because we're computing p_v_given_h.
118

118

00:04:31.540  -->  00:04:33.150
Before, we had to the take the transpose
119

119

00:04:33.150  -->  00:04:35.073
because we were computing p_h_given_v.
120

120

00:04:36.070  -->  00:04:37.920
So since w is the weight matrix
121

121

00:04:37.920  -->  00:04:40.440
of p_v_given_h, then that's why we had
122

122

00:04:40.440  -->  00:04:42.430
to take the transpose, okay?
123

123

00:04:42.430  -->  00:04:44.580
And then, we need to remove these parenthesis
124

124

00:04:44.580  -->  00:04:47.270
because that was for the transpose function.
125

125

00:04:47.270  -->  00:04:48.920
Here, you know when we take the transpose
126

126

00:04:48.920  -->  00:04:51.060
we have to take this t plus the parenthesis
127

127

00:04:51.060  -->  00:04:52.480
because this is a function,
128

128

00:04:52.480  -->  00:04:54.140
the transpose function.
129

129

00:04:54.140  -->  00:04:57.750
All right so now we have our wy.
130

130

00:04:57.750  -->  00:05:00.230
We have a warning saying that it is unused.
131

131

00:05:00.230  -->  00:05:01.063
Okay, that's fine.
132

132

00:05:01.063  -->  00:05:03.030
We will use it actually right now.
133

133

00:05:03.030  -->  00:05:05.250
So then we have compute the activation
134

134

00:05:05.250  -->  00:05:08.020
of the hidden neurons inside the sigmoid function,
135

135

00:05:08.020  -->  00:05:12.470
and so, therefore, that's not wx here, but wy.
136

136

00:05:12.470  -->  00:05:15.410
And here that's the same, it's wy.
137

137

00:05:15.410  -->  00:05:17.720
All right and then, of course, let's not forget
138

138

00:05:17.720  -->  00:05:19.940
to the replace the a here by the b
139

139

00:05:19.940  -->  00:05:21.440
because we need to take the bias
140

140

00:05:21.440  -->  00:05:23.290
of the visible nodes, and the bias
141

141

00:05:23.290  -->  00:05:27.020
of the visible nodes are in this self.b variable,
142

142

00:05:27.020  -->  00:05:28.100
and we have to take the self
143

143

00:05:28.100  -->  00:05:30.440
because this is a variable attached
144

144

00:05:30.440  -->  00:05:32.130
specifically to the object.
145

145

00:05:32.130  -->  00:05:33.470
The object that will be created
146

146

00:05:33.470  -->  00:05:35.080
by the RBM class.
147

147

00:05:35.080  -->  00:05:36.620
All right so now I think we got everything,
148

148

00:05:36.620  -->  00:05:38.410
and we need to use the expand functions
149

149

00:05:38.410  -->  00:05:39.630
still for the same reason,
150

150

00:05:39.630  -->  00:05:42.070
that is to apply the bias to each line
151

151

00:05:42.070  -->  00:05:43.420
of the mini-batch.
152

152

00:05:43.420  -->  00:05:45.890
All right so great, so I think we got everything
153

153

00:05:45.890  -->  00:05:48.050
to make this sample_v function.
154

154

00:05:48.050  -->  00:05:48.883
Here that's the same.
155

155

00:05:48.883  -->  00:05:51.320
We take the sigmoid activation function,
156

156

00:05:51.320  -->  00:05:54.070
and here we return the probabilities
157

157

00:05:54.070  -->  00:05:55.740
that the visible nodes equal one
158

158

00:05:55.740  -->  00:05:57.770
given the activations of the hidden nodes.
159

159

00:05:57.770  -->  00:05:59.230
So that's all good.
160

160

00:05:59.230  -->  00:06:00.980
We are ready to move onto the next
161

161

00:06:00.980  -->  00:06:03.170
and final step of the construction
162

162

00:06:03.170  -->  00:06:06.680
of this class, which is about contrastive divergence,
163

163

00:06:06.680  -->  00:06:08.480
and so we'll make a last function
164

164

00:06:08.480  -->  00:06:10.080
that we'll call train.
165

165

00:06:10.080  -->  00:06:11.339
And this last function will take care
166

166

00:06:11.339  -->  00:06:13.090
of contrastive divergence.
167

167

00:06:13.090  -->  00:06:14.810
All right so we'll do that in the next tutorial,
168

168

00:06:14.810  -->  00:06:16.593
and until then enjoy deep learning.
