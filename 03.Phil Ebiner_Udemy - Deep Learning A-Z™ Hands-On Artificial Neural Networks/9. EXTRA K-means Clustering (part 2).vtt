WEBVTT
1
1

00:00:00.510  -->  00:00:03.080
<v ->Hello and welcome back to the course on Machine Learning.</v>
2

2

00:00:03.080  -->  00:00:06.750
Today we're going to talk about a specific aspect of the
3

3

00:00:06.750  -->  00:00:11.430
k-means algorithm which is the random initialization trap.
4

4

00:00:11.430  -->  00:00:13.300
So let's have a look at this phenomenon
5

5

00:00:13.300  -->  00:00:15.800
and see what it's all about.
6

6

00:00:15.800  -->  00:00:17.410
So, random initialization trap.
7

7

00:00:17.410  -->  00:00:22.210
So here we've got a scatter plot again with two variables,
8

8

00:00:22.210  -->  00:00:24.430
so we've got the X and Y coordinates.
9

9

00:00:24.430  -->  00:00:25.760
And in this case,
10

10

00:00:25.760  -->  00:00:28.240
let's say we're going to choose a three clusters.
11

11

00:00:28.240  -->  00:00:30.090
So right away you can kind of tell
12

12

00:00:30.090  -->  00:00:32.280
which is the final result,
13

13

00:00:32.280  -->  00:00:33.560
what is the final result going to look like
14

14

00:00:33.560  -->  00:00:35.150
if we choose three clusters.
15

15

00:00:35.150  -->  00:00:39.240
It does look like you can pretty easily spot them here.
16

16

00:00:39.240  -->  00:00:41.610
But let's nevertheless perform this operation,
17

17

00:00:41.610  -->  00:00:44.160
this algorithm, and if we initialize
18

18

00:00:44.160  -->  00:00:48.110
our centroids like this, then what we'll get is,
19

19

00:00:48.110  -->  00:00:50.740
because we're already kind of can tell that probably,
20

20

00:00:50.740  -->  00:00:52.630
that's a cluster, that's a cluster, and that's a cluster,
21

21

00:00:52.630  -->  00:00:55.290
so just to make the algorithm a bit faster
22

22

00:00:55.290  -->  00:00:57.530
so we don't have to do too many easy steps and iterations,
23

23

00:00:57.530  -->  00:01:00.710
we're gonna select our centroids like this,
24

24

00:01:00.710  -->  00:01:03.210
and, right away, if we perform the algorithm,
25

25

00:01:03.210  -->  00:01:05.190
we'll get to these clusters.
26

26

00:01:05.190  -->  00:01:09.150
And next is, even if we move around the centroids,
27

27

00:01:09.150  -->  00:01:12.120
so we find the centroids of each of these clusters,
28

28

00:01:12.120  -->  00:01:13.140
nothing is going to change.
29

29

00:01:13.140  -->  00:01:16.180
So you can, in your own time, you can perform the steps
30

30

00:01:16.180  -->  00:01:18.590
that we learned about in the previous tutorial,
31

31

00:01:18.590  -->  00:01:22.060
and see that nothing will indeed change because of the way
32

32

00:01:22.060  -->  00:01:23.300
we selected the centroids.
33

33

00:01:23.300  -->  00:01:25.200
This is already the final result.
34

34

00:01:25.200  -->  00:01:27.130
So those are going to be the clusters
35

35

00:01:27.130  -->  00:01:28.600
that we're going to end up with.
36

36

00:01:28.600  -->  00:01:33.310
So that's kind of the end results of the k-means algorithm.
37

37

00:01:33.310  -->  00:01:35.070
Because we selected the clusters,
38

38

00:01:35.070  -->  00:01:37.460
the centroids in the places where we did.
39

39

00:01:37.460  -->  00:01:40.430
Now the question is what if we select the centroids
40

40

00:01:40.430  -->  00:01:41.690
in different locations.
41

41

00:01:41.690  -->  00:01:43.850
Will we be able to change the result?
42

42

00:01:43.850  -->  00:01:45.780
Will the result be different?
43

43

00:01:45.780  -->  00:01:48.190
And, of course, an algorithm has to be
44

44

00:01:48.190  -->  00:01:50.520
what we want from this algorithm is for it to just
45

45

00:01:50.520  -->  00:01:53.180
a deterministic result because we can select the centroids
46

46

00:01:53.180  -->  00:01:55.960
at random and therefore we don't want that selection of
47

47

00:01:55.960  -->  00:02:00.300
centroids to affect how the cluster is going to happen.
48

48

00:02:00.300  -->  00:02:02.230
But let's have a look and see what happens.
49

49

00:02:02.230  -->  00:02:05.730
So what will happen if we had a bad random initialization?
50

50

00:02:05.730  -->  00:02:09.930
So bad is like a term we're going to use loosely for now,
51

51

00:02:09.930  -->  00:02:11.610
but you'll see why we're using
52

52

00:02:11.610  -->  00:02:14.130
bad random initialization just now.
53

53

00:02:14.130  -->  00:02:16.100
So again we're going to go through these steps
54

54

00:02:16.100  -->  00:02:17.510
that we discussed in the previous tutorial.
55

55

00:02:17.510  -->  00:02:18.930
We're going to choose the number of clusters
56

56

00:02:18.930  -->  00:02:20.780
which is three, all selected at random.
57

57

00:02:20.780  -->  00:02:22.700
Three points which will be our centroids.
58

58

00:02:22.700  -->  00:02:25.040
We'll assign each data point to the closest centroid,
59

59

00:02:25.040  -->  00:02:26.540
that'll form k clusters.
60

60

00:02:26.540  -->  00:02:29.690
We'll compute and place a new centroid for each cluster,
61

61

00:02:29.690  -->  00:02:31.820
thinking in terms of the center of mass
62

62

00:02:31.820  -->  00:02:33.090
or center of gravity.
63

63

00:02:33.090  -->  00:02:35.140
And, so far, we will reassign each data point
64

64

00:02:35.140  -->  00:02:36.930
to the new closest centroid.
65

65

00:02:36.930  -->  00:02:40.200
If any reassignment took place, we will return to step four.
66

66

00:02:40.200  -->  00:02:41.750
Otherwise, we'll go to the end
67

67

00:02:41.750  -->  00:02:43.240
because the model has converged.
68

68

00:02:43.240  -->  00:02:45.200
So these are the steps we discussed previously.
69

69

00:02:45.200  -->  00:02:47.610
Let's have a look at them in action.
70

70

00:02:47.610  -->  00:02:50.410
Alright, so three clusters, and this time,
71

71

00:02:50.410  -->  00:02:53.790
instead of selecting a centroids here, here and here,
72

72

00:02:53.790  -->  00:02:54.623
what we're going to do is
73

73

00:02:54.623  -->  00:02:55.745
we're going to select them differently.
74

74

00:02:55.745  -->  00:02:58.840
We're going to select the centroids like this.
75

75

00:02:58.840  -->  00:03:01.820
So we'll put one centroid here on this side,
76

76

00:03:01.820  -->  00:03:04.210
one centroid here, and one centroid here.
77

77

00:03:04.210  -->  00:03:06.050
So let's have a look what happens now.
78

78

00:03:06.050  -->  00:03:09.000
If we draw a line, so this time we have three clusters,
79

79

00:03:09.000  -->  00:03:12.270
three centroids, but the principle is kind of the same.
80

80

00:03:12.270  -->  00:03:14.300
We still have a point which is equidistant
81

81

00:03:14.300  -->  00:03:15.133
from all three of them.
82

82

00:03:15.133  -->  00:03:18.190
So this point over here is the same distance from all three.
83

83

00:03:18.190  -->  00:03:21.500
And then this line is equidistant from these two.
84

84

00:03:21.500  -->  00:03:23.170
This line is equidistant from these two.
85

85

00:03:23.170  -->  00:03:24.800
This line is equidistant from these two.
86

86

00:03:24.800  -->  00:03:26.980
Again this is not part of the algorithm.
87

87

00:03:26.980  -->  00:03:27.940
As part of the algorithm,
88

88

00:03:27.940  -->  00:03:29.387
you will just take each individual point.
89

89

00:03:29.387  -->  00:03:32.140
You'll look at this point and you would see which
90

90

00:03:32.140  -->  00:03:34.030
centroid is the closest, so this time it's green.
91

91

00:03:34.030  -->  00:03:35.300
You'd color it green.
92

92

00:03:35.300  -->  00:03:37.510
This one you check again, you'd color it green,
93

93

00:03:37.510  -->  00:03:39.010
this one you check again, you'd color it green.
94

94

00:03:39.010  -->  00:03:39.843
And so on.
95

95

00:03:39.843  -->  00:03:43.010
Then this one is the closest to red, you'd color it red.
96

96

00:03:43.010  -->  00:03:43.843
And so on.
97

97

00:03:43.843  -->  00:03:45.470
But just to make things easier for ourselves,
98

98

00:03:45.470  -->  00:03:46.820
we're going to use this little hack.
99

99

00:03:46.820  -->  00:03:49.000
We're going to use these lines to say
100

100

00:03:49.000  -->  00:03:52.880
anything in this part of the chart is going to be closest
101

101

00:03:52.880  -->  00:03:56.170
to red just because these are equidistant lines,
102

102

00:03:56.170  -->  00:03:58.160
anything in this part of the chart is going to be green.
103

103

00:03:58.160  -->  00:03:59.940
Anything in this part of the chart is going to be blue.
104

104

00:03:59.940  -->  00:04:01.270
It'll just save us time.
105

105

00:04:01.270  -->  00:04:04.740
So based on this method, we can tell right away that
106

106

00:04:04.740  -->  00:04:06.543
this is the red cluster for now, this is the blue,
107

107

00:04:06.543  -->  00:04:08.060
this is the green.
108

108

00:04:08.060  -->  00:04:10.110
So now we're going to, we've assigned each data point
109

109

00:04:10.110  -->  00:04:11.880
to the closest centroid, that's great.
110

110

00:04:11.880  -->  00:04:14.100
Now we're going to move on to step four.
111

111

00:04:14.100  -->  00:04:17.380
And we're going to move these clusters.
112

112

00:04:17.380  -->  00:04:19.930
So we're going to recalculate, compute and place
113

113

00:04:19.930  -->  00:04:21.480
the new centroids for each cluster.
114

114

00:04:21.480  -->  00:04:24.480
So there we can see that that is probably the center of mass
115

115

00:04:24.480  -->  00:04:27.420
for the reds, uh points, that's the one for blue points,
116

116

00:04:27.420  -->  00:04:28.940
that's the one for green points.
117

117

00:04:28.940  -->  00:04:32.279
So we move our centroids to the new locations.
118

118

00:04:32.279  -->  00:04:35.090
And now we're going to perform a step five.
119

119

00:04:35.090  -->  00:04:36.580
We're going to reassign each data point
120

120

00:04:36.580  -->  00:04:38.220
to the new closest centroid.
121

121

00:04:38.220  -->  00:04:40.990
So again we're going to use that quick hack with the lines.
122

122

00:04:40.990  -->  00:04:43.580
Let's see how the lines will look like this time.
123

123

00:04:43.580  -->  00:04:46.260
There's our new equidistant point,
124

124

00:04:46.260  -->  00:04:48.230
and these are the equidistant lines.
125

125

00:04:48.230  -->  00:04:51.330
So this time you can see that nothing will change.
126

126

00:04:51.330  -->  00:04:54.480
The red points are all already in the red.
127

127

00:04:54.480  -->  00:04:56.150
Corner, blue points are in the blue corner.
128

128

00:04:56.150  -->  00:04:57.870
And green points are in the green corner.
129

129

00:04:57.870  -->  00:04:59.520
So nothing is going to change.
130

130

00:04:59.520  -->  00:05:01.020
There will be no reassignment,
131

131

00:05:01.020  -->  00:05:02.120
so we don't go to step four.
132

132

00:05:02.120  -->  00:05:04.760
We instead go to finalizing the algorithm
133

133

00:05:04.760  -->  00:05:07.000
because it has converged.
134

134

00:05:07.000  -->  00:05:07.940
So there we go.
135

135

00:05:07.940  -->  00:05:09.900
That is our model, it is ready.
136

136

00:05:09.900  -->  00:05:13.040
And as a result, we have these three clusters.
137

137

00:05:13.040  -->  00:05:15.660
Now these three clusters are different
138

138

00:05:15.660  -->  00:05:16.710
to what we saw at the start.
139

139

00:05:16.710  -->  00:05:18.010
So let's have a look.
140

140

00:05:18.010  -->  00:05:19.710
This is what we saw at the start.
141

141

00:05:19.710  -->  00:05:21.750
We're going to call them the true three clusters,
142

142

00:05:21.750  -->  00:05:23.820
because you can tell just from the chart,
143

143

00:05:23.820  -->  00:05:27.490
you can tell that these points would
144

144

00:05:27.490  -->  00:05:28.930
most likely to form a cluster,
145

145

00:05:28.930  -->  00:05:30.810
these would form a cluster and these would form a cluster.
146

146

00:05:30.810  -->  00:05:33.330
Just by looking at it, you can intuitively tell
147

147

00:05:33.330  -->  00:05:34.800
that that is the case.
148

148

00:05:34.800  -->  00:05:36.290
This is what we got in the first,
149

149

00:05:36.290  -->  00:05:37.490
at the start of this tutorial.
150

150

00:05:37.490  -->  00:05:39.360
And this is what we got now.
151

151

00:05:39.360  -->  00:05:42.200
So you can see that the three clusters are different.
152

152

00:05:42.200  -->  00:05:46.280
And therefore what we have is a situation or a phenomenon
153

153

00:05:46.280  -->  00:05:48.240
where the selection of the centroids
154

154

00:05:48.240  -->  00:05:51.930
at the very start of the algorithm can potentially dictate
155

155

00:05:51.930  -->  00:05:53.380
the outcome of the algorithm.
156

156

00:05:53.380  -->  00:05:55.930
And that's not a good thing because the centroids
157

157

00:05:55.930  -->  00:05:57.940
are selected at random.
158

158

00:05:57.940  -->  00:06:01.550
So how do you combat this? How do you battle this?
159

159

00:06:01.550  -->  00:06:06.290
Well the answer is actually not as straightforward.
160

160

00:06:06.290  -->  00:06:10.340
There is a addition or a modification to the k-means
161

161

00:06:10.340  -->  00:06:14.970
algorithm, that allows you to correctly select the centroids
162

162

00:06:14.970  -->  00:06:19.500
and the solution here is the k-means plus plus algorithm.
163

163

00:06:19.500  -->  00:06:22.780
Now at the same time, I wanted to mention that we're not
164

164

00:06:22.780  -->  00:06:27.100
actually going to delve deeply into the k-means plus plus
165

165

00:06:27.100  -->  00:06:29.280
algorithm and how it's structured.
166

166

00:06:29.280  -->  00:06:32.140
You can definitely read up more about it on Wikipedia
167

167

00:06:32.140  -->  00:06:33.860
or other sources.
168

168

00:06:33.860  -->  00:06:36.630
It is quite a involved approach
169

169

00:06:36.630  -->  00:06:41.020
in how that selection occurs, but the good news is that
170

170

00:06:41.020  -->  00:06:42.490
all this happens in the background.
171

171

00:06:42.490  -->  00:06:47.010
So the k-means plus plus happens either in R or Python
172

172

00:06:47.010  -->  00:06:48.340
or whatever tool you're using.
173

173

00:06:48.340  -->  00:06:50.980
You don't need to actually implement it.
174

174

00:06:50.980  -->  00:06:54.350
So it's just a good idea to be aware of this issue.
175

175

00:06:54.350  -->  00:06:59.350
That there's a true cluster result that you're after.
176

176

00:06:59.480  -->  00:07:04.040
And they can be some false or some non-desirable
177

177

00:07:04.040  -->  00:07:06.560
clustering results, clustering outcomes of the k-mean
178

178

00:07:06.560  -->  00:07:08.490
clustering algorithm.
179

179

00:07:08.490  -->  00:07:11.030
It's good to be aware of that issue and it's also good
180

180

00:07:11.030  -->  00:07:14.530
to know that the tools that you use will be,
181

181

00:07:14.530  -->  00:07:16.810
or make sure that the tools you're using,
182

182

00:07:16.810  -->  00:07:20.680
are going to be implementing that specific selection of the
183

183

00:07:20.680  -->  00:07:23.390
random centroids at the very start so that you get the
184

184

00:07:23.390  -->  00:07:24.440
good result.
185

185

00:07:24.440  -->  00:07:27.320
So definitely if you are more interested to learn more
186

186

00:07:27.320  -->  00:07:29.130
about the k-means plus plus algorithm,
187

187

00:07:29.130  -->  00:07:30.380
definitely read up about it.
188

188

00:07:30.380  -->  00:07:31.590
But otherwise it's not something that
189

189

00:07:31.590  -->  00:07:32.423
you really have to worry about.
190

190

00:07:32.423  -->  00:07:35.220
It's just something that you need to keep in mind
191

191

00:07:35.220  -->  00:07:38.800
and make sure, or be confident that the tools you're using
192

192

00:07:38.800  -->  00:07:42.480
are bypassing this initialization trap.
193

193

00:07:42.480  -->  00:07:44.210
So hopefully you enjoyed today's tutorial,
194

194

00:07:44.210  -->  00:07:46.250
and I look forward to seeing you next time.
195

195

00:07:46.250  -->  00:07:48.233
Until then, enjoy Machine Learning.
