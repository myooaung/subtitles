WEBVTT
1
1

00:00:00.150  -->  00:00:02.310
<v Instructor>Hello and welcome to this tutorial.</v>
2

2

00:00:02.310  -->  00:00:05.500
So, we are almost done with part one, data pre-processing.
3

3

00:00:05.500  -->  00:00:07.360
We just need three more tutorials
4

4

00:00:07.360  -->  00:00:09.220
to make our dataset perfectly prepared
5

5

00:00:09.220  -->  00:00:10.730
before starting the models
6

6

00:00:10.730  -->  00:00:12.727
and then we'll be good to go.
7

7

00:00:12.727  -->  00:00:13.660
So, today we're going to talk
8

8

00:00:13.660  -->  00:00:16.870
about the fact that we need to split the dataset
9

9

00:00:16.870  -->  00:00:19.560
into a training set and a test set
10

10

00:00:19.560  -->  00:00:22.520
and I'll explain why we need to do that right now.
11

11

00:00:22.520  -->  00:00:24.550
So, we have our 10 observations
12

12

00:00:24.550  -->  00:00:28.165
and this is the dataset, this is the whole dataset
13

13

00:00:28.165  -->  00:00:31.520
and what we should do in any machine learning models
14

14

00:00:31.520  -->  00:00:33.660
is that we're gonna split this dataset
15

15

00:00:33.660  -->  00:00:35.500
into two separate sets
16

16

00:00:35.500  -->  00:00:38.700
which are gonna be the training set and the test set.
17

17

00:00:38.700  -->  00:00:40.610
Now, why do we need to do this?
18

18

00:00:40.610  -->  00:00:42.280
Well, when you take a step back
19

19

00:00:42.280  -->  00:00:45.210
and focus on the name machine learning itself,
20

20

00:00:45.210  -->  00:00:47.650
you understand that this is about a machine
21

21

00:00:47.650  -->  00:00:49.940
that is going to learn something.
22

22

00:00:49.940  -->  00:00:52.030
Here it's your algorithm, it's your model
23

23

00:00:52.030  -->  00:00:54.090
that is going to learn from your data
24

24

00:00:54.090  -->  00:00:57.550
to make predictions or other machine learning goals.
25

25

00:00:57.550  -->  00:00:58.960
And so, your machine learning model
26

26

00:00:58.960  -->  00:01:02.130
is going to learn to do something on your dataset
27

27

00:01:02.130  -->  00:01:03.910
by understanding some correlations
28

28

00:01:03.910  -->  00:01:05.720
that there is in your dataset
29

29

00:01:05.720  -->  00:01:07.550
and imagine your machine learning model
30

30

00:01:07.550  -->  00:01:09.180
is learning too much on the dataset,
31

31

00:01:09.180  -->  00:01:12.170
like it's learning too much to correlations,
32

32

00:01:12.170  -->  00:01:15.150
then I'm not sure its performance would be great
33

33

00:01:15.150  -->  00:01:18.260
on the new set with slightly different correlations.
34

34

00:01:18.260  -->  00:01:21.210
It's like a student who's learning by heart his lesson
35

35

00:01:21.210  -->  00:01:23.410
and then when we takes the exam, he might be in trouble
36

36

00:01:23.410  -->  00:01:26.240
because he learned too much his lesson by heart
37

37

00:01:26.240  -->  00:01:28.020
and he does not manage to make the connection
38

38

00:01:28.020  -->  00:01:30.630
between what he learned and the exam
39

39

00:01:30.630  -->  00:01:32.360
and it's the same for machine learning.
40

40

00:01:32.360  -->  00:01:34.630
We're going to build our machine learning models
41

41

00:01:34.630  -->  00:01:37.850
on a dataset but then we have to test it on a new set
42

42

00:01:37.850  -->  00:01:40.300
which is gonna be slightly different from the dataset
43

43

00:01:40.300  -->  00:01:42.500
on which we build the machine learning model.
44

44

00:01:42.500  -->  00:01:45.940
So, we have to make two different sets,
45

45

00:01:45.940  -->  00:01:48.610
a training set on which we build the machine learning model
46

46

00:01:48.610  -->  00:01:52.050
and a test set on which we test the performance
47

47

00:01:52.050  -->  00:01:53.570
of this machine learning model
48

48

00:01:53.570  -->  00:01:55.390
and the performance on the test set
49

49

00:01:55.390  -->  00:01:56.810
shouldn't be that different
50

50

00:01:56.810  -->  00:01:58.870
from the performance on the training set
51

51

00:01:58.870  -->  00:01:59.910
because this would mean
52

52

00:01:59.910  -->  00:02:02.410
that the machine learning models understood well
53

53

00:02:02.410  -->  00:02:05.210
the correlations and didn't learn them by heart
54

54

00:02:05.210  -->  00:02:09.830
so that he can adapt to new sets and new situations.
55

55

00:02:09.830  -->  00:02:12.640
So, that's the idea about splitting the dataset
56

56

00:02:12.640  -->  00:02:14.990
into a training set and a test set,
57

57

00:02:14.990  -->  00:02:18.020
so I'm gonna jump straight to Python, here we are.
58

58

00:02:18.020  -->  00:02:20.610
And I have my section ready, splitting the dataset
59

59

00:02:20.610  -->  00:02:22.673
into the Training set and the Test set.
60

60

00:02:23.620  -->  00:02:25.510
So, you're gonna see that it's very simple,
61

61

00:02:25.510  -->  00:02:27.420
it's gonna take us two lines
62

62

00:02:27.420  -->  00:02:30.950
and as usual, let's start by importing the library
63

63

00:02:30.950  -->  00:02:32.860
that is going to do the job for us
64

64

00:02:32.860  -->  00:02:34.560
because we want to be efficient,
65

65

00:02:34.560  -->  00:02:36.080
the world is going so fast,
66

66

00:02:36.080  -->  00:02:38.000
so we wanna solve our business problems
67

67

00:02:38.000  -->  00:02:40.090
in the most efficient way.
68

68

00:02:40.090  -->  00:02:42.247
So, the library we're going to import
69

69

00:02:42.247  -->  00:02:45.460
is a new library we haven't met yet.
70

70

00:02:45.460  -->  00:02:47.660
It's the cross_validation library,
71

71

00:02:47.660  -->  00:02:49.530
still from scikit-learn.
72

72

00:02:49.530  -->  00:02:52.130
So, let's import the library.
73

73

00:02:52.130  -->  00:02:55.780
So, we type from sklearn.cross_validation,
74

74

00:02:59.520  -->  00:03:02.220
so here it is, I just have to press Enter, Validation.
75

75

00:03:03.080  -->  00:03:07.370
Import and now we're going to import the train_test_split,
76

76

00:03:08.890  -->  00:03:12.100
remember when I told you that the libraries' name
77

77

00:03:12.100  -->  00:03:13.060
are quite intuitive?
78

78

00:03:13.060  -->  00:03:15.670
Well, that's the case, train_test_split,
79

79

00:03:15.670  -->  00:03:17.685
it couldn't be more clear.
80

80

00:03:17.685  -->  00:03:20.110
So, we imported the library, we're fine with that
81

81

00:03:20.110  -->  00:03:23.810
and now let's build our training and test sets.
82

82

00:03:23.810  -->  00:03:27.483
So, what we're going to do is we're going create X_train,
83

83

00:03:29.430  -->  00:03:33.160
then X_test comma
84

84

00:03:33.160  -->  00:03:37.927
and then y_train and then y_test.
85

85

00:03:40.366  -->  00:03:45.040
So, X_train is the training part of the matrix of features,
86

86

00:03:45.040  -->  00:03:49.490
X_test is the test part of the matrix of features,
87

87

00:03:49.490  -->  00:03:53.150
y_train is the training part of the dependent variable
88

88

00:03:53.150  -->  00:03:55.620
that is associated to X_train here,
89

89

00:03:55.620  -->  00:03:57.800
that means that we have the same indexes for both
90

90

00:03:57.800  -->  00:03:59.540
with the same observations
91

91

00:03:59.540  -->  00:04:03.340
and y_test is the test part of the dependent variable vector
92

92

00:04:03.340  -->  00:04:05.500
associated to X_test.
93

93

00:04:05.500  -->  00:04:08.630
And then we're gonna add an equal
94

94

00:04:08.630  -->  00:04:11.430
because we're going to define these four variables
95

95

00:04:11.430  -->  00:04:12.950
at the same time.
96

96

00:04:12.950  -->  00:04:14.760
So, train_test_split
97

97

00:04:18.420  -->  00:04:20.090
and then we're gonna put an argument,
98

98

00:04:20.090  -->  00:04:23.430
so let's inspect it, let's press Command + I
99

99

00:04:23.430  -->  00:04:25.660
to see what we have to input.
100

100

00:04:25.660  -->  00:04:27.200
So, train_test_split.
101

101

00:04:27.200  -->  00:04:30.670
The first parameter is arrays and what is arrays?
102

102

00:04:30.670  -->  00:04:33.160
That's simply the matrix X,
103

103

00:04:33.160  -->  00:04:35.370
that is the matrix X of features
104

104

00:04:35.370  -->  00:04:37.860
of independent variables of our dataset
105

105

00:04:37.860  -->  00:04:41.260
and then y which is the dependent variable.
106

106

00:04:41.260  -->  00:04:43.150
So, you know my putting X and y,
107

107

00:04:43.150  -->  00:04:44.930
it's like we're putting the whole dataset
108

108

00:04:44.930  -->  00:04:47.453
and that's what they mean by arrays here.
109

109

00:04:48.740  -->  00:04:51.470
Then the next parameter is test_size.
110

110

00:04:51.470  -->  00:04:53.603
So, we're gonna add here test_size
111

111

00:04:56.370  -->  00:05:00.270
equals, so very simply that's the size
112

112

00:05:00.270  -->  00:05:02.350
of the test set you wanna choose,
113

113

00:05:02.350  -->  00:05:05.413
so for example, if I put test_size equals 0.5,
114

114

00:05:06.780  -->  00:05:09.160
that is 50%, that means
115

115

00:05:09.160  -->  00:05:11.960
that there is gonna be half of your data going
116

116

00:05:11.960  -->  00:05:13.900
to the test set and half of your data
117

117

00:05:13.900  -->  00:05:15.370
going to the training set.
118

118

00:05:15.370  -->  00:05:18.050
But usually we never choose 50% for the test size,
119

119

00:05:18.050  -->  00:05:20.450
we choose a smaller percentage.
120

120

00:05:20.450  -->  00:05:24.920
A good choice of the test_size is generally 0.2, like 20%,
121

121

00:05:24.920  -->  00:05:28.880
that's a good choice or 0.25, 25%
122

122

00:05:28.880  -->  00:05:30.950
or even sometimes 0.3
123

123

00:05:30.950  -->  00:05:33.010
and in some rare cases, you will find 0.4
124

124

00:05:34.070  -->  00:05:37.030
but really I've never seen 0.5.
125

125

00:05:37.030  -->  00:05:40.500
So, here we're gonna choose 0.2, 20%.
126

126

00:05:40.500  -->  00:05:43.300
So, that means that since we have 10 observations,
127

127

00:05:43.300  -->  00:05:44.760
let's go back to Variable Explorer
128

128

00:05:44.760  -->  00:05:48.040
and find our dataset, we have 10 observations,
129

129

00:05:48.040  -->  00:05:51.570
so that means that once we do the train_test_split,
130

130

00:05:51.570  -->  00:05:54.660
we're gonna have two observations in a test set
131

131

00:05:54.660  -->  00:05:57.630
and eight observations in the training set.
132

132

00:05:57.630  -->  00:05:58.530
So, let's click OK
133

133

00:05:59.690  -->  00:06:02.110
and is that all that we have to input?
134

134

00:06:02.110  -->  00:06:04.330
Well, let's go back to Object Inspector
135

135

00:06:04.330  -->  00:06:06.360
to see the next parameter.
136

136

00:06:06.360  -->  00:06:07.870
So, then we have train_size
137

137

00:06:07.870  -->  00:06:10.900
but since test_size plus train_size equals one,
138

138

00:06:10.900  -->  00:06:12.300
we don't need to input train_size,
139

139

00:06:12.300  -->  00:06:13.820
that would be redundant.
140

140

00:06:13.820  -->  00:06:15.880
But then we're gonna use this parameter
141

141

00:06:15.880  -->  00:06:17.890
and that's just for the purpose of this course
142

142

00:06:17.890  -->  00:06:19.560
because I don't want you to worry
143

143

00:06:19.560  -->  00:06:21.800
about having different results than mine.
144

144

00:06:21.800  -->  00:06:24.290
You're gonna have the same logical results
145

145

00:06:24.290  -->  00:06:26.070
but you might have different results
146

146

00:06:26.070  -->  00:06:28.790
if we don't put a random_state parameter,
147

147

00:06:28.790  -->  00:06:30.820
so we're gonna use this random_state
148

148

00:06:30.820  -->  00:06:32.700
and set it to the same number
149

149

00:06:32.700  -->  00:06:35.120
so that we have all the same results.
150

150

00:06:35.120  -->  00:06:38.830
So, let's add here random_state
151

151

00:06:40.470  -->  00:06:43.260
equals then we can choose whatever we want.
152

152

00:06:43.260  -->  00:06:45.890
A good choice number is 42
153

153

00:06:45.890  -->  00:06:49.680
and the regular number I choose is zero.
154

154

00:06:49.680  -->  00:06:50.855
Random_state equals zero.
155

155

00:06:50.855  -->  00:06:53.470
You can put random_state equals zero in your code
156

156

00:06:53.470  -->  00:06:55.920
if you want to have exactly the same results as mine.
157

157

00:06:55.920  -->  00:06:57.730
It's really as you want.
158

158

00:06:57.730  -->  00:06:59.190
Okay, so we're done actually.
159

159

00:06:59.190  -->  00:07:01.940
That's the two lines that we have to write
160

160

00:07:01.940  -->  00:07:04.507
to split correctly the dataset into the training set
161

161

00:07:04.507  -->  00:07:05.950
and the test set.
162

162

00:07:05.950  -->  00:07:07.650
So let's see what happens.
163

163

00:07:07.650  -->  00:07:09.643
Let's select these lines.
164

164

00:07:10.780  -->  00:07:14.010
Command or Control + Enter to execute.
165

165

00:07:14.010  -->  00:07:17.040
Here we are, it executed properly.
166

166

00:07:17.040  -->  00:07:19.000
Now of course let's look at what happened.
167

167

00:07:19.000  -->  00:07:20.800
Let's go to Variable Explorer.
168

168

00:07:20.800  -->  00:07:22.920
Here we have some new variables.
169

169

00:07:22.920  -->  00:07:25.010
Remember before we had the dataset,
170

170

00:07:25.010  -->  00:07:26.630
the X matrix of features
171

171

00:07:26.630  -->  00:07:28.940
and the y dependent variable vector
172

172

00:07:28.940  -->  00:07:31.450
and now we also have X_train, X_test,
173

173

00:07:31.450  -->  00:07:32.803
y_train and y_test.
174

174

00:07:33.770  -->  00:07:35.570
So, let's look at them one by one.
175

175

00:07:35.570  -->  00:07:36.403
X_train.
176

176

00:07:37.452  -->  00:07:41.400
Since we chose a test size of 20% or .2,
177

177

00:07:41.400  -->  00:07:43.690
we would normally have eight observations
178

178

00:07:43.690  -->  00:07:46.320
in a training set and two observation in a test set.
179

179

00:07:46.320  -->  00:07:48.620
So, let's make sure that's the case.
180

180

00:07:48.620  -->  00:07:51.357
So, we have our eight observations in the training set
181

181

00:07:51.357  -->  00:07:53.353
and now let's look at the test set.
182

182

00:07:54.450  -->  00:07:56.880
Two observations in the test set, perfect
183

183

00:07:56.880  -->  00:07:59.840
and now let's check that it's the same for y_train,
184

184

00:07:59.840  -->  00:08:01.430
eight observations, fine
185

185

00:08:01.430  -->  00:08:03.923
and y_test, two observations.
186

186

00:08:05.460  -->  00:08:09.192
And now let's open the four, X_train, X_test,
187

187

00:08:09.192  -->  00:08:10.759
y_train and y_test.
188

188

00:08:10.759  -->  00:08:13.770
To summarize what the train_test_split is about,
189

189

00:08:13.770  -->  00:08:15.950
here above we have the training set
190

190

00:08:15.950  -->  00:08:18.710
with the X_test matrix of independent variables
191

191

00:08:18.710  -->  00:08:21.620
and the y_train dependent variable vector
192

192

00:08:21.620  -->  00:08:23.230
and below we have the test set
193

193

00:08:23.230  -->  00:08:26.580
with the matrix of independent variables, X_test
194

194

00:08:26.580  -->  00:08:29.050
and the dependent variable vector y_test
195

195

00:08:29.050  -->  00:08:32.150
and so, what happens is that we are building
196

196

00:08:32.150  -->  00:08:35.210
our machine learning model on this training set
197

197

00:08:35.210  -->  00:08:37.360
by establishing some correlations
198

198

00:08:37.360  -->  00:08:39.930
between the independent variables here
199

199

00:08:39.930  -->  00:08:42.010
and the dependent variable here
200

200

00:08:42.010  -->  00:08:44.680
and then once the machine learning model understands
201

201

00:08:44.680  -->  00:08:47.270
the correlations between the independent variables
202

202

00:08:47.270  -->  00:08:48.870
and the dependent variable,
203

203

00:08:48.870  -->  00:08:51.510
we will test if the the machine learning model
204

204

00:08:51.510  -->  00:08:54.710
can apply the correlations here understood based
205

205

00:08:54.710  -->  00:08:57.370
on the training set on the test set.
206

206

00:08:57.370  -->  00:08:59.590
That means that we will see if you can predict
207

207

00:08:59.590  -->  00:09:02.530
that this customer number zero here
208

208

00:09:02.530  -->  00:09:05.840
is not going to buy the product
209

209

00:09:05.840  -->  00:09:07.520
and if this customer number one here
210

210

00:09:07.520  -->  00:09:09.126
is not going to buy the product
211

211

00:09:09.126  -->  00:09:12.580
and he's going to be able to predict that based
212

212

00:09:12.580  -->  00:09:15.050
on what he learned on the training set.
213

213

00:09:15.050  -->  00:09:17.980
So, the better he learns the correlations
214

214

00:09:17.980  -->  00:09:19.210
in a training set,
215

215

00:09:19.210  -->  00:09:22.630
the better he will be predicting the results
216

216

00:09:22.630  -->  00:09:24.010
in the test set.
217

217

00:09:24.010  -->  00:09:26.450
But if you learn too much by heart the correlations
218

218

00:09:26.450  -->  00:09:27.610
of the training set,
219

219

00:09:27.610  -->  00:09:29.130
you know by learning them by heart
220

220

00:09:29.130  -->  00:09:30.772
and not understanding them,
221

221

00:09:30.772  -->  00:09:32.750
then he will have trouble predicting
222

222

00:09:32.750  -->  00:09:34.240
what's happening on the test set
223

223

00:09:34.240  -->  00:09:36.414
because since he learned by heart the correlations,
224

224

00:09:36.414  -->  00:09:38.830
he didn't understand quite well the logic
225

225

00:09:38.830  -->  00:09:41.440
and he won't be able to make good predictions.
226

226

00:09:41.440  -->  00:09:42.560
That's called over-fitting.
227

227

00:09:42.560  -->  00:09:44.840
We will be talking about that in further details
228

228

00:09:44.840  -->  00:09:46.140
in the regression section
229

229

00:09:46.140  -->  00:09:49.260
and we will learn how to use regularization techniques
230

230

00:09:49.260  -->  00:09:51.240
to prevent this but for now,
231

231

00:09:51.240  -->  00:09:53.270
it's really important that you understand
232

232

00:09:53.270  -->  00:09:55.872
that we need to make two different datasets,
233

233

00:09:55.872  -->  00:09:59.470
the training sets on which the machine learning model learns
234

234

00:09:59.470  -->  00:10:01.590
and the test set on which we test
235

235

00:10:01.590  -->  00:10:02.992
if the machine learning model
236

236

00:10:02.992  -->  00:10:05.900
learned correctly the correlations.
237

237

00:10:05.900  -->  00:10:08.550
So, let's click OK and close that.
238

238

00:10:08.550  -->  00:10:11.420
So, that's it for this tutorial.
239

239

00:10:11.420  -->  00:10:14.220
You now know how to split your dataset
240

240

00:10:14.220  -->  00:10:16.440
into a training set and a test set.
241

241

00:10:16.440  -->  00:10:18.810
This is a must-do in any machine learning models.
242

242

00:10:18.810  -->  00:10:20.960
You have to test the performance
243

243

00:10:20.960  -->  00:10:22.350
of your machine learning model
244

244

00:10:22.350  -->  00:10:24.230
into a separate test set,
245

245

00:10:24.230  -->  00:10:26.510
so congratulations, now you are almost ready
246

246

00:10:26.510  -->  00:10:27.958
to begin the journey
247

247

00:10:27.958  -->  00:10:31.020
of making exciting machine learning models.
248

248

00:10:31.020  -->  00:10:34.010
We just have one thing to do left, feature scaling.
249

249

00:10:34.010  -->  00:10:35.480
You'll understand in the next tutorial
250

250

00:10:35.480  -->  00:10:37.030
why it's so important to do this,
251

251

00:10:37.030  -->  00:10:38.640
so I look forward to see you there
252

252

00:10:38.640  -->  00:10:40.590
and until then, enjoy machine learning.
