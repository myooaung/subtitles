1
00:00:05,370 --> 00:00:09,670
Welcome back everyone to part two of deep learning on custom images.

2
00:00:09,690 --> 00:00:10,410
A quick note.

3
00:00:10,620 --> 00:00:15,960
In part two we're actually going to be building out the model and I'm going to introduce some slightly

4
00:00:15,960 --> 00:00:19,830
different imports to reflect some of the most recent changes to cars.

5
00:00:19,830 --> 00:00:21,770
These are just a few different imports.

6
00:00:21,810 --> 00:00:24,140
Essentially just the wording is slightly changed.

7
00:00:24,150 --> 00:00:29,310
So for instance we'll be saying Max pooling to D instead of Max Poole to the like we did in the previous

8
00:00:29,310 --> 00:00:30,050
lectures.

9
00:00:30,270 --> 00:00:34,720
Since we're using the latest version of course as of this filming it's Cara's 2.2.

10
00:00:34,800 --> 00:00:36,540
They both actually still work.

11
00:00:36,660 --> 00:00:39,900
So you're going to find both in online resources quite often.

12
00:00:39,900 --> 00:00:43,790
But I do want to show you the latest updates the syntax changes.

13
00:00:43,830 --> 00:00:46,080
So these functions are going to work exactly the same.

14
00:00:46,080 --> 00:00:47,780
They're just spelt slightly differently.

15
00:00:47,790 --> 00:00:52,340
Also we'll show you how you can add in activation functions separately from a dense layer.

16
00:00:52,410 --> 00:00:54,010
So just a couple of minor changes.

17
00:00:54,060 --> 00:00:55,400
Just want to give you a heads up.

18
00:00:55,440 --> 00:00:59,550
So if you start wondering why is the syntax slightly different than the previous lectures.

19
00:00:59,550 --> 00:01:03,710
That's why I want to show you the most recent updates to the documentation.

20
00:01:03,890 --> 00:01:08,760
So as always these libraries tend to change quite often so you'll always want to check the official

21
00:01:08,760 --> 00:01:11,420
documentation to see what the latest updates are.

22
00:01:11,430 --> 00:01:16,320
But since Max pool to me is still quite commonly found in online tutorials I wanted to introduce that

23
00:01:16,320 --> 00:01:17,050
one as well.

24
00:01:17,160 --> 00:01:19,140
But let's go ahead now use max pooling to the.

25
00:01:19,230 --> 00:01:20,370
It's the exact same function.

26
00:01:20,400 --> 00:01:22,350
It's just spelt slightly differently.

27
00:01:22,440 --> 00:01:24,990
So we're going head over to the you know book and build their model.

28
00:01:24,990 --> 00:01:25,220
All right.

29
00:01:25,230 --> 00:01:31,710
Here we are at our model and previously we set up the image data generator along with a bunch of random

30
00:01:31,710 --> 00:01:37,440
manipulations that could occur things like rotation changing the width and height rescaling Shearing's

31
00:01:37,440 --> 00:01:42,810
zoom range and more make sure don't introduce a typo there and then we can see the range of transformations

32
00:01:42,810 --> 00:01:44,510
it does on the dog image.

33
00:01:44,580 --> 00:01:49,140
And as I previously mentioned we're going to be changing our syntax very slightly for some of the imports

34
00:01:50,460 --> 00:02:02,250
Soulsby saying from Karris that models in poor sequential Elisei from carious layers in poor are an

35
00:02:02,340 --> 00:02:07,170
import activation which is something we haven't seen before it's basically a way to add in an activation

36
00:02:07,170 --> 00:02:13,560
function after you provide a dense layer and then we also do a drop out which is another layer we haven't

37
00:02:13,560 --> 00:02:14,310
seen before.

38
00:02:14,550 --> 00:02:16,320
And then everything else you actually have seen before.

39
00:02:16,330 --> 00:02:26,460
Flaten convolution to me and then as I previously mentioned we have both Max pool and Max pulling to

40
00:02:26,460 --> 00:02:27,150
the.

41
00:02:27,180 --> 00:02:32,670
We'll go ahead and use max pulling to the because the updates to the latest documentation.

42
00:02:32,880 --> 00:02:38,040
Just to reiterate here there's really no difference between Max pool to the max pulling to the if you

43
00:02:38,040 --> 00:02:41,400
actually search the documentation on pooling layer's the latest updates.

44
00:02:41,400 --> 00:02:43,660
Now also a pooling of energy.

45
00:02:43,830 --> 00:02:48,570
But if you were actually to be using tensor Flo's version of Cara's they still call it if you look up

46
00:02:48,570 --> 00:02:50,300
here Max pool to the.

47
00:02:50,310 --> 00:02:52,330
So that's why both versions still exist.

48
00:02:52,380 --> 00:02:56,880
Tensor flow which is running on the back and then our version does it without the i n g.

49
00:02:56,910 --> 00:02:59,220
And you can see here it actually links to both classes.

50
00:02:59,220 --> 00:03:03,260
They have aliases Max pool to the point to the exact same function.

51
00:03:03,270 --> 00:03:06,370
It's just an alias a different way of importing it.

52
00:03:06,380 --> 00:03:08,430
So let's go in and create the model.

53
00:03:08,900 --> 00:03:12,150
Will same model sequential.

54
00:03:12,280 --> 00:03:19,760
And then we're going to add in a couple of players we'll say a model and I'm going to add in a 2D convolutional

55
00:03:19,780 --> 00:03:25,350
for and we're going to start off with filter's equal to 32.

56
00:03:25,410 --> 00:03:32,060
We're going to go for slightly smaller kernel size three by three and then my input shape is going to

57
00:03:32,060 --> 00:03:36,310
be 150 by 150 by three.

58
00:03:36,560 --> 00:03:41,840
So I chose this input shape a little arbitrarily tried to choose something that was more or less around

59
00:03:41,870 --> 00:03:43,810
the average of these images.

60
00:03:43,880 --> 00:03:48,010
And depending on what your images are you may have to choose something larger or smaller.

61
00:03:48,020 --> 00:03:51,880
And what I wanted to do is I'm actually going to define above this model.

62
00:03:52,870 --> 00:03:59,170
Input put shape equal to one fifty one fifty three.

63
00:03:59,170 --> 00:04:00,310
So you can go ahead and do that.

64
00:04:00,340 --> 00:04:03,240
And then if you want you can replace this tuple with the input variable.

65
00:04:03,310 --> 00:04:04,070
It's up to you.

66
00:04:04,150 --> 00:04:08,380
But we'll be using this input shape and basically we're going to do is when we actually call flow from

67
00:04:08,390 --> 00:04:11,780
directory there's going to be another variable or parameter.

68
00:04:11,980 --> 00:04:17,590
And if you shift tab here you can see it there's target size and you can manually then set the target

69
00:04:17,590 --> 00:04:20,040
size to be 150 by 150.

70
00:04:20,050 --> 00:04:25,060
And what Chris is going to do is it will shrink down images that are larger than that or stretch out

71
00:04:25,060 --> 00:04:26,620
images that are smaller than that.

72
00:04:26,620 --> 00:04:29,740
So Ill make sure they're all the same size 150 150.

73
00:04:29,770 --> 00:04:34,050
That way you don't need to worry about manually resetting all the sizes yourself for all your images.

74
00:04:34,300 --> 00:04:34,760
OK.

75
00:04:35,020 --> 00:04:37,040
So we have the input shape ready to go.

76
00:04:37,060 --> 00:04:39,650
The last we're going to do is set the activation.

77
00:04:39,840 --> 00:04:46,120
And for all these convolutional is we'll just say that the activation function chosen is the rectified

78
00:04:46,180 --> 00:04:48,370
linear unit.

79
00:04:48,400 --> 00:04:55,970
Then after that we'll go ahead and add in a max pulling function will say Max pulling to the same thing

80
00:04:55,970 --> 00:04:58,140
as Max pool to the just an alias.

81
00:04:58,310 --> 00:05:03,350
And then we provide a pool size and will choose two by two and then what I'm going to do is I'm going

82
00:05:03,350 --> 00:05:04,500
to copy this.

83
00:05:04,730 --> 00:05:09,800
And since these images are quite complex we're going to add in two more convolutional layers with Max

84
00:05:09,800 --> 00:05:10,620
pulling.

85
00:05:10,650 --> 00:05:14,120
And I'm also going to do is add in a couple of more filters later on.

86
00:05:14,370 --> 00:05:17,130
And you can feel free to experiment with filter's here.

87
00:05:17,130 --> 00:05:23,100
Maybe start off of 64 unreduced on the 32 or start of 32 and then up to 64.

88
00:05:23,130 --> 00:05:28,410
Really it's a lot of experimentation and a lot of reading about the latest papers and what filters work

89
00:05:28,410 --> 00:05:31,730
best and what kernel sizes work best if you want.

90
00:05:31,770 --> 00:05:36,480
You can feel free to add more published next pulling but after this we're just going to say model ad

91
00:05:36,970 --> 00:05:45,720
and we're going to flatten this and then we'll say model ad and we'll add in a then Slayer and I'll

92
00:05:45,720 --> 00:05:49,040
go ahead and say 128 neurons in that then Slayer.

93
00:05:49,110 --> 00:05:52,050
Typically we also provide an activation function.

94
00:05:52,140 --> 00:05:56,310
So notice we can provide active phase activation function within dance but I also want to show you that

95
00:05:56,310 --> 00:05:59,810
if you needed to you could provide activation separately.

96
00:06:00,300 --> 00:06:04,430
So if you wanted to maybe easily swap out activations you can do that as well.

97
00:06:04,500 --> 00:06:11,990
So you can say activation are you and that's the same thing as providing within the dance as well.

98
00:06:12,560 --> 00:06:16,230
Okay the next one is adding in a dropout layer.

99
00:06:16,560 --> 00:06:20,260
So the dropout layer is actually a layer that we haven't seen before of course.

100
00:06:20,370 --> 00:06:26,070
And as we previously mentioned what this does is it helps reduce overfitting by randomly turning neurons

101
00:06:26,100 --> 00:06:27,540
off during training.

102
00:06:27,720 --> 00:06:31,280
And here we're going to randomly turn off 50 percent of the neurons.

103
00:06:31,320 --> 00:06:35,640
So you provide a percentage that you want of neurons randomly turned off.

104
00:06:35,640 --> 00:06:40,140
So we're going to turn off 50 percent neurons randomly during training and that's going to help with

105
00:06:40,140 --> 00:06:49,680
overfitting that it will say model ad and I'm going to add our last output and it's just one year on

106
00:06:49,710 --> 00:06:57,480
because this is a binary target class it's either 0 for cat or 1 for dog and then we'll say model.

107
00:06:57,970 --> 00:07:05,360
And I can add in the activation sigmoid again up to you whether you want to do this as one line or two

108
00:07:05,360 --> 00:07:07,970
lines just different syntax here.

109
00:07:07,970 --> 00:07:11,300
That may be reflective of Curiosus future.

110
00:07:11,310 --> 00:07:20,330
Finally we're going to say model compile and I'll say loss is equal to binary cross entropy Stradling

111
00:07:20,370 --> 00:07:26,900
binary classification binary meaning we only have two and then we'll say that the optimizer is Adam

112
00:07:29,230 --> 00:07:34,400
and then the metrics we're going to be using our accuracy.

113
00:07:34,430 --> 00:07:36,770
So go ahead and run that let's make sure we it.

114
00:07:36,820 --> 00:07:40,520
So that should be con with a V.

115
00:07:40,570 --> 00:07:44,080
So let's fix those run that again.

116
00:07:44,090 --> 00:07:44,430
OK.

117
00:07:44,510 --> 00:07:51,180
So got rid of those typos and then let's say model summary and there we go you can see the letters as

118
00:07:51,180 --> 00:07:52,560
well as the different shapes.

119
00:07:52,560 --> 00:07:54,360
Now it's time to train the model.

120
00:07:54,570 --> 00:07:59,970
So the way this works is you're going to create image training generation objects for both training

121
00:08:00,060 --> 00:08:00,990
and testing.

122
00:08:00,990 --> 00:08:09,780
You need to choose a batch size so a good starting point for batch size is 16.

123
00:08:09,820 --> 00:08:12,240
And again it really depends on the situation.

124
00:08:12,250 --> 00:08:15,170
There's no real right or 100 percent correct answer.

125
00:08:15,190 --> 00:08:17,440
You don't want to do too huge of a batch size.

126
00:08:17,500 --> 00:08:20,830
Otherwise it'll take too long on each cycle to train your network.

127
00:08:20,830 --> 00:08:25,400
So 16 is a fair amount especially for images of the size.

128
00:08:25,750 --> 00:08:32,390
And then I'm going to say training image generator is equal to imagen.

129
00:08:32,820 --> 00:08:37,420
And we're going to call that flow from the rectory and we're going to point it to the training data

130
00:08:37,600 --> 00:08:42,860
which right now the way I've organized it is under Katz dog train.

131
00:08:43,050 --> 00:08:49,760
And then what we need to do is provide the target size so the target size is the shape so we can say

132
00:08:49,780 --> 00:08:57,750
target size and you can either manually say 150 50 or you can just provide what we already define which

133
00:08:57,750 --> 00:09:06,760
is input shape and then say Colan up to 2 because remember we find the 150 about 150 further up in this

134
00:09:06,760 --> 00:09:07,670
notebook.

135
00:09:08,020 --> 00:09:15,390
Next we find the batch size we will say batch size is equal to batch size.

136
00:09:15,430 --> 00:09:22,730
And then the class mode is binary because we're only dealing of two types of classes and after running

137
00:09:22,730 --> 00:09:27,960
that you should see some sort of report on how many images it found belonging to how many classes were

138
00:09:27,960 --> 00:09:30,200
going to do the exact same thing for the test.

139
00:09:30,200 --> 00:09:38,590
Feel free to just copy this and paste it here and switch where it says Treen folder to test and then

140
00:09:38,590 --> 00:09:41,130
we'll call this the test image generator.

141
00:09:41,500 --> 00:09:47,080
Run that and then I'll say it found so many images belong into two classes in that Test folder.

142
00:09:47,140 --> 00:09:52,810
And what's nice about this is off of that train image generation object you're going to have a lot of

143
00:09:52,810 --> 00:09:58,790
different methods and attributes but a really useful one is class indices and this will actually tell

144
00:09:58,790 --> 00:10:00,940
you what index belongs to what class.

145
00:10:00,950 --> 00:10:05,460
So it's going to define zero as cats and one as dog notice.

146
00:10:05,480 --> 00:10:09,950
It basically just kind of goes in alphabetical order or whatever or order it found the folders in and

147
00:10:09,950 --> 00:10:12,260
then just labels them 0 1 and so on.

148
00:10:12,560 --> 00:10:15,740
OK now it's time to actually get the generator.

149
00:10:15,740 --> 00:10:18,550
This is going to take a really long time to get a good model.

150
00:10:18,550 --> 00:10:23,350
I'm going to run it just for any POC so you can see what it will look like.

151
00:10:23,600 --> 00:10:31,620
But then we're going to load up our own model sort of say model fit generator you're going to pass in

152
00:10:31,680 --> 00:10:36,440
the training image you're going to set the amount of epoxy you want to train for.

153
00:10:36,450 --> 00:10:38,070
How many passes.

154
00:10:38,070 --> 00:10:45,860
So here we can say just one pass and the next parameter you can specify is steps per e.

155
00:10:45,900 --> 00:10:51,570
Keep in mind typically eat Poch means that you've done a single full pass through the entire training

156
00:10:51,570 --> 00:10:52,180
set.

157
00:10:52,200 --> 00:10:59,100
So if you didn't have that IPAC here one IPAC would be a pass through all almost 19000 images.

158
00:10:59,100 --> 00:11:04,140
Sometimes in your training that's just too much and you don't want each IPAC to be an entire set through

159
00:11:04,140 --> 00:11:05,220
the training pass.

160
00:11:05,220 --> 00:11:10,810
So what you could do is limit that by saying a certain amount of steps pretty.

161
00:11:10,860 --> 00:11:14,460
You're only allowed to do 150 steps per Poch.

162
00:11:14,520 --> 00:11:17,730
Remember we're also taking batch size into account here.

163
00:11:18,610 --> 00:11:24,010
So that means you're grabbing batches of 16 150 times and you're labeling that as an epoch.

164
00:11:24,010 --> 00:11:29,810
So that's really a close around 2400 training images instead of the full 18 thousands per epoch.

165
00:11:29,980 --> 00:11:35,140
It's up to you how big you want to make these steps pretty you can think of this more as of a limiter

166
00:11:35,440 --> 00:11:39,220
on the full Poch and it's really just to save you training time.

167
00:11:39,220 --> 00:11:44,500
Granted you're not going to get as good a results if you don't train on as many images but it will take

168
00:11:44,500 --> 00:11:50,780
way longer if you don't limit the steps for epoch that after that we're going to pass on our validation

169
00:11:50,780 --> 00:11:51,270
data.

170
00:11:53,390 --> 00:12:02,420
So we say validation underscore data and that's we're going to pass the test image generator.

171
00:12:02,510 --> 00:12:07,510
And what's nice is as we actually fit the trainer We'll also be evaluating at the same time on the test

172
00:12:07,510 --> 00:12:12,080
data and the validation can also have a certain amount of steps.

173
00:12:12,110 --> 00:12:15,140
So we'll say validation steps is equal to 12.

174
00:12:15,140 --> 00:12:19,160
So we'll go ahead and run that a should end up seeing a result.

175
00:12:19,160 --> 00:12:24,620
So here's just one IPAC and those right now it's only going through 150 steps for that one epoch.

176
00:12:24,770 --> 00:12:28,840
If you don't have that it would end up going through the entire training site.

177
00:12:28,880 --> 00:12:34,530
OK so we should expect really great results here because we only did one epoch and we're not even going

178
00:12:34,530 --> 00:12:35,940
through all the data.

179
00:12:35,940 --> 00:12:38,920
Keep in mind you may get warnings as it trains.

180
00:12:39,000 --> 00:12:40,760
You can feel free to ignore these warnings.

181
00:12:40,770 --> 00:12:45,400
They're basically just telling you that it's not able to read certain images certain images in the data

182
00:12:45,430 --> 00:12:49,200
set are blank or they're super small or maybe they're pure black.

183
00:12:49,200 --> 00:12:51,660
So if you get these warnings there's no need to worry.

184
00:12:51,720 --> 00:12:54,620
It just has to do with the particular images in the data set.

185
00:12:54,990 --> 00:13:00,180
OK so I fast forward in time a bit that took around a minute to train on one epoch where we limited

186
00:13:00,180 --> 00:13:01,400
the stats per eat pop.

187
00:13:01,620 --> 00:13:06,180
And as I mentioned these are just warnings if you would like to ignore those warnings and not see them

188
00:13:06,690 --> 00:13:12,780
then you can just copy and paste these two lines of code above the results model that fit generator.

189
00:13:12,780 --> 00:13:16,110
It basically just says import warnings filter ignore the warnings.

190
00:13:16,110 --> 00:13:18,690
Again these are just warnings or not actual errors.

191
00:13:18,700 --> 00:13:19,900
It's basically just telling you.

192
00:13:20,070 --> 00:13:21,990
Sorry I couldn't read that specific image.

193
00:13:21,990 --> 00:13:23,630
I'm going to go ahead and skip it.

194
00:13:23,640 --> 00:13:28,050
Typically that happens we have really tiny small images and if you actually take a look at some of these

195
00:13:28,050 --> 00:13:29,020
data images.

196
00:13:29,030 --> 00:13:33,690
There's like micro images of cats that are like one by one pixel so it's just going to go ahead and

197
00:13:33,690 --> 00:13:34,700
skip those.

198
00:13:34,740 --> 00:13:35,230
OK.

199
00:13:35,380 --> 00:13:36,270
So go ahead run that.

200
00:13:36,300 --> 00:13:40,960
Even though it's not really relevant to us anymore and we can also then evaluate the model.

201
00:13:41,430 --> 00:13:48,240
So now we have the results remember we were validating during this process of fit generator and results

202
00:13:48,300 --> 00:13:55,750
has a history that we can then call A.S.C. for accuracy.

203
00:13:55,830 --> 00:13:59,700
And if you run that it will show you the historical results of its accuracy.

204
00:13:59,760 --> 00:14:05,330
So on this very first pass remember only ran for one epoch it got 53 percent accuracy.

205
00:14:05,430 --> 00:14:11,010
If you were to run this for more than one Apoc you would actually then see an array of historical accuracy

206
00:14:11,040 --> 00:14:12,230
that you could plot.

207
00:14:12,240 --> 00:14:16,350
Let me bring in the lecture notebooks so you can see what this would look like when I'm bringing in

208
00:14:16,350 --> 00:14:17,490
over here.

209
00:14:17,490 --> 00:14:22,770
So in this lecture notebook that we have here for you this is an example of training and evaluating

210
00:14:22,770 --> 00:14:25,200
the model on 100 epochs.

211
00:14:25,200 --> 00:14:27,510
Granted there's only 150 steps pretty Poch.

212
00:14:27,620 --> 00:14:31,170
So you can see here it trained for hundred pocks to quite a bit of time.

213
00:14:31,410 --> 00:14:33,480
I think I left it running for about two hours.

214
00:14:33,630 --> 00:14:39,620
And if you then see historical accuracy it will show you this historical array of accuracy that you

215
00:14:39,630 --> 00:14:45,780
can then call Piel t plot on and you get to see the accuracy plotted out and eventually it will begin

216
00:14:45,780 --> 00:14:46,410
to level off.

217
00:14:46,410 --> 00:14:52,620
So we're looking at around 80 percent accuracy on our training set and then we can't predict on new

218
00:14:52,620 --> 00:14:53,480
images.

219
00:14:53,520 --> 00:14:57,510
We're not going to get very good prediction if we use the one IPAC model.

220
00:14:57,540 --> 00:15:01,320
So instead we're going to load a model that already trained for you.

221
00:15:01,350 --> 00:15:07,440
In fact it's this model right here the 82 83 ish percent on the training set and I've saved that model

222
00:15:07,440 --> 00:15:10,810
for you inside of the same folder that this note book is in.

223
00:15:10,830 --> 00:15:18,070
So let's go ahead and load it up and come back to my notebook here and remember to load a model.

224
00:15:18,210 --> 00:15:21,340
We just say from.

225
00:15:21,680 --> 00:15:28,020
We import that load model functionality so that command in case you don't remember is just from carious

226
00:15:29,060 --> 00:15:33,480
the models import load under underscore model.

227
00:15:34,000 --> 00:15:40,090
And then we can say that the new model is equal to load model.

228
00:15:40,660 --> 00:15:47,470
And in this case it's called Cat Dog 100 epochs thought H5.

229
00:15:47,470 --> 00:15:48,970
So go ahead and load in that model.

230
00:15:48,970 --> 00:15:53,110
It might take a little bit of time because it's quite a large model it's around 30 megabytes which is

231
00:15:53,110 --> 00:15:54,160
pretty big for a model.

232
00:15:54,340 --> 00:15:57,080
And then what we're going to do is predict a new class.

233
00:15:57,100 --> 00:16:03,320
So let's imagine that we just train this results or whatever your model happens to be called for 100

234
00:16:03,460 --> 00:16:07,030
epochs and then we save that and then we load it up again.

235
00:16:07,030 --> 00:16:12,520
Now the question is if I'm presented a new image of a dog that I haven't seen before how do we actually

236
00:16:12,550 --> 00:16:14,700
predict whether or not it's a dog.

237
00:16:15,160 --> 00:16:17,890
So we're going to do is the following.

238
00:16:17,890 --> 00:16:22,160
And again this is the process for predicting on an image that it's never seen before.

239
00:16:22,270 --> 00:16:27,400
All we need to say is the dog file and actually find the path.

240
00:16:27,400 --> 00:16:29,330
So let's go ahead and grab data.

241
00:16:29,710 --> 00:16:32,230
We'll say cats.

242
00:16:32,250 --> 00:16:34,860
It's actually just under cats for me here.

243
00:16:35,050 --> 00:16:36,660
So undercuts dog.

244
00:16:36,720 --> 00:16:42,200
I'm going to grab a test from dog and let's just grab kind of around that number here.

245
00:16:42,340 --> 00:16:44,620
So there's lots of images you can choose from.

246
00:16:44,650 --> 00:16:46,310
I'll just use any dog image.

247
00:16:46,320 --> 00:16:47,840
I encourage you to do the same.

248
00:16:47,930 --> 00:16:55,240
And what we need to do then is say from Paris pre-processing import image and what we need to do is

249
00:16:55,240 --> 00:17:01,410
we need to resize the image that the neural network expects that we train on 150 by 50 pixel images.

250
00:17:01,420 --> 00:17:03,050
So that's what we're going to do here.

251
00:17:03,190 --> 00:17:14,680
We will say dog image is equal to image and I say load image will pass in the dog file and then say

252
00:17:14,680 --> 00:17:24,810
target size is equal to 150 by 150 So there is our dog image and then we're going to turn it to an array.

253
00:17:25,240 --> 00:17:33,260
So I will say dog image is equal to image and then say image to array and then pass in the dog image.

254
00:17:33,950 --> 00:17:34,550
OK.

255
00:17:34,550 --> 00:17:36,490
So check out the size right now.

256
00:17:39,050 --> 00:17:43,330
Now there's two more steps we need to do before we actually predicts on the stock image.

257
00:17:43,370 --> 00:17:48,190
The first one is right now the dimensions are 150 by 150 by three.

258
00:17:48,290 --> 00:17:52,310
We need to change this so that the neural network thinks it's a batch of one image.

259
00:17:52,310 --> 00:17:56,690
So we need to be one comma one fifty one fifty three.

260
00:17:56,690 --> 00:18:03,500
So in order to do that we can use important up-I as MP and expand expanded Dimensions we'll say dog

261
00:18:03,500 --> 00:18:11,400
image is equal to the dots expand dimensions and then pasand the dog image.

262
00:18:12,630 --> 00:18:14,910
And then say axis equals to zero.

263
00:18:15,120 --> 00:18:21,300
And then if you check out the document shape it will have been expanded once along the axes remember

264
00:18:21,300 --> 00:18:23,120
you shouldn't rerun the cell multiple times.

265
00:18:23,130 --> 00:18:24,710
Otherwise you'll keep expanding it.

266
00:18:25,000 --> 00:18:29,430
OK so now that we have that in place we're going to do is make sure all the values are between 0 and

267
00:18:29,430 --> 00:18:30,040
1.

268
00:18:30,160 --> 00:18:36,110
So we'll say dog image is equal to dog image divided by 255.

269
00:18:36,360 --> 00:18:37,910
And we want to predict.

270
00:18:38,160 --> 00:18:40,480
We can say model predicts.

271
00:18:40,770 --> 00:18:42,880
And there's a couple of things we can do here.

272
00:18:42,920 --> 00:18:48,870
One of the rectory predict the class you can say pretty classes and then pass in the documents run it

273
00:18:49,110 --> 00:18:54,470
and I'll predict that it's class 1 which remember if we come all the way back a peer that's a dog.

274
00:18:54,570 --> 00:18:58,740
So it successfully predicted on a test image it's never seen before.

275
00:18:58,830 --> 00:19:01,170
That is a dog that it was a dog.

276
00:19:01,230 --> 00:19:07,190
If we want to see how sure it was that it was a dog we can just run predict by itself.

277
00:19:07,260 --> 00:19:13,320
Pasand dog image and Ill say what percent sure it was so it had a prediction probability that it was

278
00:19:13,320 --> 00:19:16,220
around 57 percent probability that it was a dog.

279
00:19:16,230 --> 00:19:17,850
So 50 percent is the cutoff.

280
00:19:17,850 --> 00:19:19,790
If it's less than that they'll think it's a cat.

281
00:19:20,140 --> 00:19:20,580
OK.

282
00:19:20,880 --> 00:19:23,400
So that's it for this lecture.

283
00:19:23,400 --> 00:19:27,560
I hope you found that useful and I hope you now know how to train on your own image data.

284
00:19:27,600 --> 00:19:31,600
Do you have any questions feel free to post the Kewney forums and make sure to check out the notebook

285
00:19:31,680 --> 00:19:33,120
that goes with this lecture.

286
00:19:33,120 --> 00:19:34,100
We'll see at the next one.
