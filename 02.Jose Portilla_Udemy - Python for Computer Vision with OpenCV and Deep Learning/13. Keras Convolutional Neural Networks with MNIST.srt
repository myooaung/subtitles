1
00:00:05,230 --> 00:00:07,390
Welcome back everyone in this lecture.

2
00:00:07,390 --> 00:00:12,160
We're going to actually use cars as a convolutional neural network with the data set.

3
00:00:12,190 --> 00:00:16,460
Make sure you take a look at the previous lecture or recover details about the dataset.

4
00:00:16,690 --> 00:00:17,290
Let's get started.

5
00:00:17,290 --> 00:00:21,190
By opening up Jupiter lab right here I am in a freshen up a can Jupiter lab.

6
00:00:21,370 --> 00:00:28,350
I won't say the following from carious dot datasets import this.

7
00:00:29,080 --> 00:00:33,340
And then once you have that you may see a little sign that's telling you you're using a particular and

8
00:00:33,490 --> 00:00:34,680
that's totally fine.

9
00:00:34,960 --> 00:00:37,300
And then we'll say the following will say X train.

10
00:00:38,540 --> 00:00:48,810
Why train such as just a little bit of tuple and here and then comma X test Y test and then set that

11
00:00:48,860 --> 00:00:53,090
equal to this load data.

12
00:00:53,310 --> 00:00:57,220
And what this is going to do is it's going to load the end this data for you.

13
00:00:57,240 --> 00:00:59,190
Keep in mind it may take a little longer for you.

14
00:00:59,190 --> 00:01:04,170
I've really fast internet connection right now so there's the data and the next thing I want to do is

15
00:01:04,170 --> 00:01:07,220
just visualize the data just we can get an understanding of it.

16
00:01:07,230 --> 00:01:11,710
I know we already saw the visualization in the previous lecture but it's always nice to do it yourself.

17
00:01:12,500 --> 00:01:16,770
So I will be importing map lib so we can actually do this.

18
00:01:16,940 --> 00:01:19,920
We'll take a look at the actual shape of our training data.

19
00:01:19,920 --> 00:01:23,260
So here we have sixty thousand and then 28 by 28.

20
00:01:23,280 --> 00:01:27,480
Notice right now there is no color channel so we may have to reshape this data to actually have that

21
00:01:27,480 --> 00:01:28,710
color channel.

22
00:01:28,710 --> 00:01:34,960
Then the next thing I want to do is just grab a single image so I will say single image is equal to

23
00:01:36,160 --> 00:01:40,660
extreme and it is going to grab the very first sample by indexing at zero.

24
00:01:41,110 --> 00:01:44,510
So if I take a look at the actual array it looks something like this.

25
00:01:44,530 --> 00:01:46,770
You can see some values but most of them are zero.

26
00:01:46,780 --> 00:01:52,810
Which kind of makes sense because most of the image is probably white and then we will say peel t show

27
00:01:54,030 --> 00:01:56,510
and I'll pass and that single image.

28
00:01:56,740 --> 00:02:01,560
And if you pass in the gray Color Mapping we actually end up getting the inverse here but you get the

29
00:02:01,560 --> 00:02:03,420
idea.

30
00:02:03,640 --> 00:02:09,550
If you actually want the more realistic Color Mapping where the digit is dark all you need to do is

31
00:02:09,550 --> 00:02:15,670
to reverse any color mapping you have the Color Mapping name and do underscore are run that you should

32
00:02:15,670 --> 00:02:19,220
see then this dark 5 on the white background.

33
00:02:19,510 --> 00:02:25,040
OK now that we understand what the training data looks like let's take a look at the actual labels.

34
00:02:25,360 --> 00:02:26,870
So I'll start with the training labels.

35
00:02:26,890 --> 00:02:28,560
We take a look at why train.

36
00:02:28,600 --> 00:02:34,760
Notice right now it responded back with just 60000 values indicating the actual number.

37
00:02:34,960 --> 00:02:41,850
So here it just says 5 because this number its label is 5 and then the next number is 0 and so on.

38
00:02:41,860 --> 00:02:48,790
However we translate this to one hot encoding because if we take a look at the shape right now it's

39
00:02:48,790 --> 00:02:50,540
really just 60000 values.

40
00:02:50,740 --> 00:02:53,640
And what could happen if you tried to feed the values this way.

41
00:02:53,830 --> 00:02:57,790
Is the network gets confused and it thinks this is some sort of regression problem.

42
00:02:58,030 --> 00:03:05,310
As if 5 0 and 4 our values on some sort of continuous scale instead of actual distinct categories.

43
00:03:05,470 --> 00:03:09,670
So it may think that there's values like 4.5 that are in between some of these labels.

44
00:03:09,850 --> 00:03:13,240
The network itself won't understand that these are categories.

45
00:03:13,240 --> 00:03:14,480
If you feed them in this way.

46
00:03:14,680 --> 00:03:18,540
So what you need to do is actually convert them to one high end coding.

47
00:03:18,640 --> 00:03:25,290
So I'll show you as an example what this will look like will say from Cara's utils and.

48
00:03:26,640 --> 00:03:29,610
And then say import to categorical.

49
00:03:29,910 --> 00:03:35,640
And what we're going to do is we're actually going to grab our Y test in y train and pass it into this

50
00:03:35,640 --> 00:03:37,430
two categorical function.

51
00:03:37,740 --> 00:03:47,430
So I will create y underscore cat test and y underscore cat train.

52
00:03:47,630 --> 00:03:55,520
So these are my categorical versions of the Y train and Y test and only need to do is pass into categorical

53
00:03:56,570 --> 00:04:01,260
and then pass in the labels and the second argument is a number of classes.

54
00:04:01,280 --> 00:04:06,830
And in this case I have classes 0 3 9 so I have 10 possible classes and it's going to be pretty much

55
00:04:06,830 --> 00:04:11,340
the same thing for this second one except it will be.

56
00:04:11,400 --> 00:04:20,310
Why train so go ahead and run that and then double check that these new variables like categorical test

57
00:04:20,700 --> 00:04:22,270
looks something like this.

58
00:04:22,290 --> 00:04:24,610
Notice now it's been one hot uncoated.

59
00:04:24,720 --> 00:04:30,060
In fact let's take a look at why cat train is 0.

60
00:04:30,250 --> 00:04:31,940
You remember why that train of 0.

61
00:04:32,070 --> 00:04:34,320
That's the five right here.

62
00:04:34,320 --> 00:04:36,860
So we converted this 5 to be 100 coded.

63
00:04:37,020 --> 00:04:42,420
So if I go along and start counting in the expedition's zero one two three four five.

64
00:04:42,510 --> 00:04:43,160
Bingo.

65
00:04:43,350 --> 00:04:47,140
At the fifth in the index position I'm one hundred could it to be a 1.

66
00:04:47,160 --> 00:04:49,240
Now clearly these are categories.

67
00:04:49,260 --> 00:04:51,410
This is something that a neural network can understand.

68
00:04:51,570 --> 00:04:56,730
And it works especially well with the sigmoid function which is going to output zeros or ones.

69
00:04:57,080 --> 00:05:01,910
OK so now we have our categorical test and training labels.

70
00:05:01,920 --> 00:05:04,600
Let's move on to processing the X data.

71
00:05:05,160 --> 00:05:09,530
So we're going to come over here and let's check out that single image again.

72
00:05:09,570 --> 00:05:11,250
So here we have that single image.

73
00:05:11,250 --> 00:05:14,670
And notice this one actually hasn't been normalized.

74
00:05:14,730 --> 00:05:16,230
So if I take a look at the max value

75
00:05:19,260 --> 00:05:21,180
it's still 255.

76
00:05:21,180 --> 00:05:25,130
We should normalize this to be within 0 and 1.

77
00:05:25,170 --> 00:05:29,550
There's lots of different ways you can do this but I want to show you just manually how you do this

78
00:05:29,550 --> 00:05:33,530
process in case for some reason you didn't have access to sikat learn.

79
00:05:33,870 --> 00:05:35,240
The idea is really simple.

80
00:05:35,250 --> 00:05:42,660
All we need to do is divide by the max value and it will normalize everything to be between 0 and 1.

81
00:05:42,750 --> 00:05:51,720
So we can say X train is equal to extremely divided by X train Max.

82
00:05:51,720 --> 00:05:56,040
In this case that's also the same as saying divided by 255.

83
00:05:56,100 --> 00:06:01,190
So I can just copy that run that and then I'm going to do the same thing for X test.

84
00:06:01,190 --> 00:06:07,030
So X test is equal to x test divided by X tests Max.

85
00:06:07,330 --> 00:06:09,940
And if I take a look at one of these images now.

86
00:06:10,000 --> 00:06:15,350
So let's go ahead and say scaled image is equal to x.

87
00:06:15,350 --> 00:06:20,440
Train 0 for Take a look at the scaled image.

88
00:06:20,440 --> 00:06:25,020
Notice now they're just zeros and all the values are now between 0 and 1.

89
00:06:25,030 --> 00:06:26,530
This is going to help our network.

90
00:06:26,560 --> 00:06:33,950
Otherwise it may kind of blow up on us with such large values and we'll say check the max.

91
00:06:33,970 --> 00:06:34,440
There we go.

92
00:06:34,450 --> 00:06:35,860
It's one.

93
00:06:35,860 --> 00:06:38,220
And yet all the ratios will still be there.

94
00:06:38,260 --> 00:06:44,140
So I should still be able to show my scaled image say See map is equal to gray.

95
00:06:44,140 --> 00:06:46,310
Underscore are run that.

96
00:06:46,390 --> 00:06:47,930
And I see the image just fine.

97
00:06:47,950 --> 00:06:53,950
In fact visually there is no distinct difference between having a scale from 0 to 255 versus just the

98
00:06:53,950 --> 00:06:56,950
same scaling scale down from 0 to 1.

99
00:06:56,950 --> 00:07:02,740
Now the next step is to reshape the data because if I take a look at my data right now specifically

100
00:07:02,770 --> 00:07:04,570
my training data.

101
00:07:04,570 --> 00:07:12,570
So if I take a look at x train or X test and ask for the shape of it it's right now sixty thousand by

102
00:07:12,580 --> 00:07:14,260
28 by 28.

103
00:07:14,270 --> 00:07:20,930
However I want to make this into a generalized network that can work on just any sort of image data.

104
00:07:20,950 --> 00:07:26,740
So in that case I need to reshape to also include the color channels in this specific case we just have

105
00:07:26,740 --> 00:07:31,570
one color channel which is why they just left the empty but I'm going to reshape this so we can actually

106
00:07:31,570 --> 00:07:37,160
see how the actual multidimensional arrays would look with for them actions.

107
00:07:37,300 --> 00:07:40,150
One for the number of training images.

108
00:07:40,330 --> 00:07:43,930
Then your X and then your Y and then the color channels.

109
00:07:43,930 --> 00:07:50,490
So let's set this up we'll say X train is equal to x train.

110
00:07:50,830 --> 00:07:53,710
Reshape it to be 60000.

111
00:07:53,790 --> 00:08:02,250
Whoops by 20 eights by 28 and then by one essentially just the finding of the fact that there is a channel

112
00:08:02,250 --> 00:08:02,930
there.

113
00:08:03,360 --> 00:08:10,410
So if you run that nothing really gets distorted We just happened to clarify that we have one in one

114
00:08:10,410 --> 00:08:14,850
dimension and that fourth dimension there is a single color channel there and will do the exact same

115
00:08:14,850 --> 00:08:17,440
thing for the Tesa.

116
00:08:17,540 --> 00:08:22,070
So I will copy and paste this code except remember the test set is a little smaller.

117
00:08:22,140 --> 00:08:23,680
It's 10000 images.

118
00:08:23,760 --> 00:08:26,610
So we change the 60000 to 10.

119
00:08:26,850 --> 00:08:32,520
Run that and then your accessit should essentially be the same thing just reorganized to have that x

120
00:08:32,550 --> 00:08:34,070
in colored color channel.

121
00:08:34,380 --> 00:08:36,760
And I can check the shape there to confirm this.

122
00:08:36,870 --> 00:08:40,430
And there it is 10000 by 28 by 28 by 1.

123
00:08:40,440 --> 00:08:41,400
Now we're ready to do.

124
00:08:41,400 --> 00:08:43,020
Is that the data has been processed.

125
00:08:43,050 --> 00:08:44,010
We've understood the data.

126
00:08:44,010 --> 00:08:45,060
We visualize that.

127
00:08:45,060 --> 00:08:47,470
We also fix the labels to be 100 coded.

128
00:08:47,490 --> 00:08:50,190
It's time to actually build and train our model.

129
00:08:50,670 --> 00:08:51,050
OK.

130
00:08:51,120 --> 00:09:01,800
So in order to build out the model we will say from Cara's dot models import sequential just as we did

131
00:09:01,800 --> 00:09:04,680
when we were starting off with the very basics of cars.

132
00:09:04,830 --> 00:09:09,580
We're going to be using a sequential model essentially just a bunch of sequential series of layers.

133
00:09:10,080 --> 00:09:12,160
And then for the actual layers we're going to be using.

134
00:09:12,360 --> 00:09:17,280
It's going to be a little more than before previously we just used a dense layer that now since we're

135
00:09:17,280 --> 00:09:25,200
using convolutional neural network we're going to be using a Slayer as well as a convolutional 2D layer

136
00:09:25,710 --> 00:09:27,280
because working up to the images.

137
00:09:27,600 --> 00:09:31,830
And then a max pooling layer also to the.

138
00:09:32,130 --> 00:09:37,740
And then a final air called Flaten which flattens out the two dimensional image.

139
00:09:39,250 --> 00:09:42,430
Let's go ahead and import those.

140
00:09:42,970 --> 00:09:46,890
And the first that let me scroll down a little bit give ourselves some more space.

141
00:09:46,900 --> 00:09:52,270
The first step is actually create the model so we create the sequential object and then we're going

142
00:09:52,270 --> 00:09:55,610
to start off with a convolutional air.

143
00:09:56,560 --> 00:10:06,580
So we'll say model add in and we'll add in this con the to the layer and we're going to set filters

144
00:10:06,970 --> 00:10:16,500
to 32 filters well set the kernel size 2 4 by 4 and obviously these are things you can adjust and play

145
00:10:16,500 --> 00:10:17,090
around with.

146
00:10:17,100 --> 00:10:19,920
But these tend to be pretty good standard values.

147
00:10:19,920 --> 00:10:25,740
Typically the kernel size is three by three or four by four and filters 32 is a good choice for these

148
00:10:25,740 --> 00:10:26,580
particular images.

149
00:10:26,600 --> 00:10:31,050
They're pretty straightforward and simple but if you're dealing with very complex images you may want

150
00:10:31,050 --> 00:10:33,470
to actually up the number of filters used.

151
00:10:33,480 --> 00:10:35,370
Now we have kernel size there.

152
00:10:35,400 --> 00:10:41,820
The next parameter is input shape and that one is actually something you can't really mess around with.

153
00:10:41,820 --> 00:10:44,620
What is the actual input shape of each individual image.

154
00:10:44,700 --> 00:10:47,550
And it's pretty straightforward it's just 28 by 20 by 1.

155
00:10:47,850 --> 00:10:52,800
And if you had color images it would be the X and Y and the three color channels.

156
00:10:52,820 --> 00:10:54,500
So I'm going to copy and paste those.

157
00:10:54,510 --> 00:11:02,400
So at 28 by 28 by 1 images and then we get to choose an activation function and typically the rectified

158
00:11:02,430 --> 00:11:04,120
linear unit or three.

159
00:11:04,140 --> 00:11:05,070
Works quite well.

160
00:11:05,250 --> 00:11:07,750
So we'll use that one OK.

161
00:11:07,860 --> 00:11:11,550
Now that we have a compilation of convolutional Leor we need a pooling layer

162
00:11:15,610 --> 00:11:21,390
so will say model add and then we're going to add any Max pool to the.

163
00:11:21,400 --> 00:11:27,000
And then we get to choose the pool size and two by two is a good default size to start off with.

164
00:11:27,040 --> 00:11:29,930
And again this pool size is something you can experiment with.

165
00:11:29,950 --> 00:11:35,290
Often what people do is they'll read the latest publications and people will say what actual size sizes

166
00:11:35,470 --> 00:11:38,250
kernels or filter's or pool size that they use.

167
00:11:38,380 --> 00:11:43,480
And you can kind of copy the best ideas from the latest papers and then add them to your own networks.

168
00:11:43,960 --> 00:11:48,610
OK once we have the pooling layer we need to do is eventually transform these convolutional employing

169
00:11:48,730 --> 00:11:52,900
layers into something that a single dense layer can understand.

170
00:11:52,900 --> 00:11:55,480
So in order to do that we need to flatten that out.

171
00:11:56,080 --> 00:11:58,460
So Will same model add.

172
00:11:58,670 --> 00:12:03,780
And we're going to add in a flat layer because remember these two layers can understand too that missional

173
00:12:03,780 --> 00:12:04,500
images.

174
00:12:04,620 --> 00:12:11,940
Our very last layer is going to be a single layer of 10 on the sigmoid function that takes in and outputs

175
00:12:11,940 --> 00:12:18,460
the correct label which means we eventually have to flatten out the two dimensional stuff to be one

176
00:12:18,460 --> 00:12:19,330
dimensional.

177
00:12:19,540 --> 00:12:21,360
So we can do that with this Flaten.

178
00:12:21,430 --> 00:12:30,280
So this ends up going from to the to the OK once we're able to flatten this out.

179
00:12:30,320 --> 00:12:39,000
Well we're going to do is add in one more dense layer we'll say a model at pass and then Slayer and

180
00:12:39,000 --> 00:12:41,940
then we need to choose a number of neurons for this dense layer.

181
00:12:42,120 --> 00:12:47,190
Really there again is kind of no right or wrong answer but typical values here specifically for this.

182
00:12:47,220 --> 00:12:55,710
And this data set to perform well is 128 say activation is rectified linear unit again lots of stuff

183
00:12:55,720 --> 00:12:56,620
you can experiment here.

184
00:12:56,620 --> 00:13:00,820
I encourage you to kind of play around with these number of neurons in this last dense layer.

185
00:13:01,240 --> 00:13:04,240
The last one is something that we actually can't really play around with.

186
00:13:04,420 --> 00:13:08,220
It's going to be the output layer which is essentially the classifier.

187
00:13:08,440 --> 00:13:16,840
So this will take in or output to 10 and it's activation is going to be soft max.

188
00:13:16,920 --> 00:13:20,800
So that will directly output what the classes it thinks it is.

189
00:13:21,420 --> 00:13:30,950
They will say model compile and I will be choosing categorical cross entropy as their last function

190
00:13:34,200 --> 00:13:38,750
then will also be choosing an optimizer which is going to be a mess.

191
00:13:41,030 --> 00:13:47,750
And then the metrics that we're concerned with we'll just take a look at accuracy OK go ahead and then

192
00:13:47,880 --> 00:13:55,750
run that and then we'll say model summary and this will summarize your model in a really cool way.

193
00:13:55,770 --> 00:14:00,540
It just tells you the different layers the output shapes and the relevant parameters then are ready

194
00:14:00,540 --> 00:14:01,670
to train our model.

195
00:14:01,680 --> 00:14:09,630
So we will say model fit and we'll passen our extremely data and all person our categorical why train

196
00:14:09,630 --> 00:14:15,090
data and we'll go ahead and run this for two epochs and IPAC is just one entire run through the entire

197
00:14:15,090 --> 00:14:15,830
training set.

198
00:14:15,960 --> 00:14:18,670
So we'll be running through the entire training set twice.

199
00:14:18,720 --> 00:14:20,100
So go ahead and run this.

200
00:14:20,130 --> 00:14:23,510
Keep in mind depending on how fast your computer is this may take some time.

201
00:14:23,520 --> 00:14:26,430
I have a pretty fast computer so you're going to see it run pretty fast in real time.

202
00:14:26,430 --> 00:14:29,860
But let's go ahead and fast forward until this is done training.

203
00:14:30,280 --> 00:14:30,630
OK.

204
00:14:30,660 --> 00:14:31,550
It just finished for me.

205
00:14:31,590 --> 00:14:36,030
It took nine seconds on the first six seconds on the second one so pretty fast.

206
00:14:36,090 --> 00:14:39,930
We're going to do next is actually grab and evaluate the model.

207
00:14:39,930 --> 00:14:44,700
So remember we can say model metrics name so has lost an accuracy.

208
00:14:44,700 --> 00:14:46,330
These are the things reported right here.

209
00:14:46,350 --> 00:14:49,890
We're already getting like 90 percent accuracy in the training set which is pretty darn good for just

210
00:14:49,890 --> 00:14:50,840
two bucks.

211
00:14:50,850 --> 00:14:53,300
So let's see how it actually performed on the.

212
00:14:54,100 --> 00:15:01,210
You'll see a model evaluates on X test and y categorical test.

213
00:15:01,660 --> 00:15:06,700
So if you run that you'll notice that even on the Tesa as well it gets 98 percent accuracy.

214
00:15:06,700 --> 00:15:11,050
In fact it's performing up slightly better on the test set than it did on the train set.

215
00:15:11,050 --> 00:15:15,160
So it's good that you're getting good performance on both training and test.

216
00:15:15,160 --> 00:15:16,780
They should be relatively similar.

217
00:15:16,900 --> 00:15:21,210
Otherwise if you're performing a really poorly on the test set that really well in the training set

218
00:15:21,480 --> 00:15:24,130
that means you're probably overfitting the training set.

219
00:15:24,550 --> 00:15:30,850
OK so now that we've evaluate our model let's go ahead and actually predict classes on images that the

220
00:15:30,850 --> 00:15:32,700
model hasn't seen before.

221
00:15:32,800 --> 00:15:37,000
We'll say from S-K learn that metrics in.

222
00:15:37,070 --> 00:15:39,010
And let's just do a classification report.

223
00:15:40,680 --> 00:15:43,390
We'll say predictions.

224
00:15:43,440 --> 00:15:47,870
So how do we actually use this model to predict on new images that it hasn't seen before.

225
00:15:48,060 --> 00:15:54,270
All we need to do is say model predict classes and this is where you can passen images that it hasn't

226
00:15:54,270 --> 00:15:54,980
seen before.

227
00:15:54,990 --> 00:15:57,660
In our case we already have images it has seen before.

228
00:15:57,660 --> 00:16:03,150
That's ex-best so it will run that and we know the correct answers for that.

229
00:16:03,150 --> 00:16:04,710
It's white cat test.

230
00:16:04,770 --> 00:16:06,450
So remember we have the correct answer here.

231
00:16:06,450 --> 00:16:10,740
Let's actually then compare the values using the cat classification report.

232
00:16:10,800 --> 00:16:22,320
Say Prince classification report and compare Y test and those here I'm saying why test because these

233
00:16:22,320 --> 00:16:27,840
classes if you take a look at the results of the predictions they're actually in the original format

234
00:16:28,260 --> 00:16:30,460
so they're no longer 100 coded.

235
00:16:30,630 --> 00:16:34,070
The result of predict classes actually predicts these classes correctly.

236
00:16:34,230 --> 00:16:37,620
But lucky for us we saved that white test.

237
00:16:37,620 --> 00:16:40,950
So we have it right here and there is one of them that's doing pretty good.

238
00:16:40,950 --> 00:16:48,270
So I'll say why test compared to the predictions run that and we're getting about ninety nine percent

239
00:16:48,270 --> 00:16:51,460
precision recall and EF 1 score that's really quite well.

240
00:16:51,540 --> 00:16:57,810
So complex neural networks can easily saw this otherwise seemingly complex problem of classifying hand-reared

241
00:16:57,810 --> 00:16:58,550
digits.

242
00:16:58,790 --> 00:17:05,040
OK so let's move on to showing you how to work on another similar dataset with convolutional neural

243
00:17:05,040 --> 00:17:07,680
networks and Cara's and images will see their.
