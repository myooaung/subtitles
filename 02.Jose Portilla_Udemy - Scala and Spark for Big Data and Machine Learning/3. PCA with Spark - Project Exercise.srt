1
00:00:05,770 --> 00:00:11,110
Hello everyone and welcome to the project exercise overview lecture for the principal component analysis

2
00:00:11,110 --> 00:00:12,520
section of the Course.

3
00:00:12,730 --> 00:00:17,950
This lecture we're going to briefly explain what you're going to be doing for your project exercise.

4
00:00:17,950 --> 00:00:20,640
Let's open up the skull a script file and get started.

5
00:00:21,070 --> 00:00:26,890
All right here we are at the Adam text editor I've opened up the PC underscore project underscore exercise

6
00:00:26,890 --> 00:00:31,960
that Skala script and if you're looking for the solutions you can check out the next lecture or you

7
00:00:31,960 --> 00:00:37,090
can just open up the exercise underscore solutions that Skoll a script and this project you're going

8
00:00:37,090 --> 00:00:42,940
to just be completing the tasks below to try to transform a data set with 30 features into a data set

9
00:00:42,940 --> 00:00:44,770
with fewer principal components.

10
00:00:44,890 --> 00:00:48,870
And keep in mind there are some things here that we haven't actually explicitly shown.

11
00:00:49,000 --> 00:00:54,160
And this is because part of this project is to discover how to do something on your own by reading through

12
00:00:54,160 --> 00:00:55,450
the documentation.

13
00:00:55,870 --> 00:01:00,640
And if you start off there's a data set description which is just a brief description of the data so

14
00:01:00,640 --> 00:01:03,070
we're going to be using the number of characteristics.

15
00:01:03,060 --> 00:01:09,100
Number of instances number of attributes and in this case it's 30 numeric attributes about ADD cancer

16
00:01:09,190 --> 00:01:13,300
and tumors so you can see the radius of a tumor or texture perimeter area etc..

17
00:01:13,310 --> 00:01:17,980
So there's a lot of actual features here that we're going to be checking out and you can see the minimax

18
00:01:18,120 --> 00:01:19,470
values here for all of them.

19
00:01:19,510 --> 00:01:24,070
So just keep scrolling down through this and eventually you will see the project exercise tests here

20
00:01:24,460 --> 00:01:29,680
and you're just going to follow along and do what it asks you to do import spark you spark to read the

21
00:01:29,680 --> 00:01:31,810
file print the schema the data etc..

22
00:01:32,020 --> 00:01:37,510
And eventually as you go down here there's one line of code that's actually filled out for you.

23
00:01:37,630 --> 00:01:42,580
And this is because there are so many columns that you're going to find this line useful when you want

24
00:01:42,580 --> 00:01:49,150
to do something like set input columns on a feature assembler or a vector Sembler object.

25
00:01:49,150 --> 00:01:52,520
So I've already left this little convenient array here for you.

26
00:01:52,570 --> 00:01:57,760
That way you can just past call names if you ever need to pass in an array of the string names of the

27
00:01:57,760 --> 00:01:58,990
columns in that data frame.

28
00:01:58,990 --> 00:02:01,710
So I'm just gonna leave that there for you to figure out how to use that.

29
00:02:01,720 --> 00:02:06,050
But that should hopefully save you some time from writing out 30 column names.

30
00:02:06,920 --> 00:02:11,880
Now if you come down here you'll notice that there's a little section talking about normalization.

31
00:02:11,960 --> 00:02:17,270
Now often it's usually a good idea to normalize each feature to have the unit standard deviation and

32
00:02:17,270 --> 00:02:22,970
or zero mean when using principal component analysis it is essentially just a pre step to principal

33
00:02:22,970 --> 00:02:26,910
component analysis is not always necessary to do this sort of normalization.

34
00:02:27,050 --> 00:02:28,990
But sometimes it's a pretty good idea.

35
00:02:29,030 --> 00:02:33,590
So what you're going to be doing is looking at the meld of feature documentation.

36
00:02:33,590 --> 00:02:38,840
So to spark that Apache or check out the documentation that we're always referring to and figure out

37
00:02:38,900 --> 00:02:43,670
how you can standardize the cancer dataset and you can refer to the solutions for hints if you get stuck

38
00:02:43,670 --> 00:02:44,510
on the step.

39
00:02:44,570 --> 00:02:49,110
But basically you're going to be trying to figure out how to use this standard scaler on that data.

40
00:02:49,400 --> 00:02:54,380
And there's more tasks for you to do as you figure out more and more how to reference documentation

41
00:02:54,380 --> 00:02:57,000
to figure out how to use that standard scalar scalar.

42
00:02:57,020 --> 00:03:01,730
Once you've done that you can come down here and continue on with the rest of the project using PCA.

43
00:03:01,730 --> 00:03:02,420
All right.

44
00:03:02,420 --> 00:03:06,290
Hope you guys enjoy the project and I will see you at the next lecture where we go over the solutions.
