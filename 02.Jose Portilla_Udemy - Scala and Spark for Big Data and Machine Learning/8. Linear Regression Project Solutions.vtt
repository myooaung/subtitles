WEBVTT
1
00:00:05.020 --> 00:00:10.310
Hello everyone and welcome to the solutions lecture for the project exercise of the regression with

2
00:00:10.320 --> 00:00:12.420
SPARK section of this course.

3
00:00:12.490 --> 00:00:15.160
Let's jump to her editor and get started.

4
00:00:15.160 --> 00:00:15.670
All right.

5
00:00:15.760 --> 00:00:19.620
I went ahead and opened the Lin exercise thought Skala.

6
00:00:19.990 --> 00:00:23.150
Let's just go along and finish these tests.

7
00:00:23.170 --> 00:00:28.570
First thing I want to do is import Linaria Russian something to know as you go through this exercise

8
00:00:28.650 --> 00:00:31.860
is that it asks you to import things a little bit out of order.

9
00:00:32.020 --> 00:00:34.740
Usually you would just import everything at the top of a script.

10
00:00:34.930 --> 00:00:40.930
But hopefully making things in sections like this helps your understanding of what imports go with what

11
00:00:40.930 --> 00:00:56.270
actions you import or Apache spark M-L regression loops to s's and then say linear regression and later

12
00:00:56.270 --> 00:00:58.890
on you can explore using other regression models.

13
00:00:58.910 --> 00:01:01.410
Right now I'll stick with the simplest linear regression.

14
00:01:01.790 --> 00:01:06.410
Then as an option you can use the following code below to say error reporting.

15
00:01:06.440 --> 00:01:13.100
This just will diminish the amount of error or warnings you see in the output in the terminal.

16
00:01:13.160 --> 00:01:24.430
Then you want to start a simple Sparke session sual say import or Patchi that spark dot sequel and then

17
00:01:24.430 --> 00:01:28.560
say Sparke session next.

18
00:01:28.910 --> 00:01:36.450
You want to create a value called Spark and set it equal to spark session and keep things simple.

19
00:01:36.530 --> 00:01:39.440
We will just say builder and then get.

20
00:01:39.650 --> 00:01:45.390
Or creates So far we have our spring session.

21
00:01:45.390 --> 00:01:50.830
Up next we want to use SPARC to read in the e-commerce customers CXXVI file.

22
00:01:50.900 --> 00:02:01.780
So I will create a value called data and then say spark the read option will specify Hetter to be true

23
00:02:04.400 --> 00:02:13.500
and we will also specify the option to infer the schema as we've done in the past.

24
00:02:13.500 --> 00:02:19.000
Next up we want to format this to be CXXVI.

25
00:02:19.060 --> 00:02:22.330
And finally we want to make sure we know the file name.

26
00:02:22.330 --> 00:02:25.540
So the file name is that e-commerce customers file.

27
00:02:25.540 --> 00:02:28.360
So we will load that up load

28
00:02:30.580 --> 00:02:33.870
e-commerce customers.

29
00:02:34.000 --> 00:02:39.340
Keep in mind that the way I have the file here I don't actually need to type in that stuff cxxviii extension

30
00:02:39.670 --> 00:02:41.890
since not present here.

31
00:02:42.080 --> 00:02:46.080
And another thing to keep in mind is that you don't have to write this all in one line.

32
00:02:46.090 --> 00:02:50.270
You can use parentheses to separate this out into multiple lines.

33
00:02:50.290 --> 00:02:56.330
Or put this all in an object to separate these options out into multiple lines will keep them all on

34
00:02:56.330 --> 00:02:57.620
one line for now.

35
00:02:57.950 --> 00:03:01.000
Up next we want to just print schema of the data frame.

36
00:03:01.340 --> 00:03:08.490
So I will say data that print schema save that.

37
00:03:08.540 --> 00:03:15.130
Let's open up a terminal here I've already have a terminal Sparke shell running in the regression folder

38
00:03:15.640 --> 00:03:23.600
and I will load when Reg exercise Skala and make sure everything worked out.

39
00:03:24.580 --> 00:03:30.390
All right started or spark session got some warnings but looks like we have no errors yet.

40
00:03:30.720 --> 00:03:34.650
Let's make sure we're actually able to read in the state and print out the schema.

41
00:03:34.670 --> 00:03:35.090
All right.

42
00:03:35.130 --> 00:03:36.420
There it is.

43
00:03:36.420 --> 00:03:38.070
So what is our scheme actually look like.

44
00:03:38.100 --> 00:03:44.550
We have an email string an address string an avatar string average session length time on an app time

45
00:03:44.550 --> 00:03:46.590
on a Web site length of the membership.

46
00:03:46.590 --> 00:03:48.540
And then that yearly amount spent.

47
00:03:48.540 --> 00:03:51.840
Remember that's the label everything else is going to be features.

48
00:03:51.930 --> 00:03:57.050
So we want to add the next assignments print out an example row.

49
00:03:57.070 --> 00:03:58.830
Now there's various ways to do this.

50
00:03:58.870 --> 00:04:00.800
You can just choose whatever way you prefer.

51
00:04:00.910 --> 00:04:04.870
The easiest way to do this is actually just by calling head off at this data.

52
00:04:04.900 --> 00:04:12.420
So to say head let's go ahead and just show the first two rows and you get something looks like this

53
00:04:12.570 --> 00:04:13.790
you can see someone's e-mail.

54
00:04:13.790 --> 00:04:18.380
And again this is all just fake data so you don't worry about someone's actual email getting exposed.

55
00:04:18.440 --> 00:04:19.790
Here's a fake address.

56
00:04:19.790 --> 00:04:22.130
The avatar looks like it's just a color.

57
00:04:22.490 --> 00:04:24.590
And then here's another row of data.

58
00:04:24.590 --> 00:04:27.050
Now it's up to you how you actually want to print this.

59
00:04:27.050 --> 00:04:30.580
There's another example if you go to the solutions you will click open.

60
00:04:30.590 --> 00:04:37.670
This right now you scroll down on the solutions you'll see that you can also copy and paste this for

61
00:04:37.670 --> 00:04:41.550
loop which kind of prints everything out and maybe a little bit of a nicer format.

62
00:04:41.660 --> 00:04:47.200
Just one value at a time and we'll paste this just so you can see what that actually looks like.

63
00:04:48.360 --> 00:04:54.240
Usually you probably want do something this expansive as far as a for loop but this may be a clear way

64
00:04:54.240 --> 00:04:55.910
of showing what the actual data looks like.

65
00:04:55.910 --> 00:04:59.530
So you can see time on app is this time a Web site is that etc..

66
00:04:59.610 --> 00:05:04.260
And don't worry about the kind of ridiculous number of significant figures here.

67
00:05:04.410 --> 00:05:06.650
That's just the way that the data was saved.

68
00:05:07.080 --> 00:05:09.900
Let's clear that and continue on.

69
00:05:09.900 --> 00:05:12.620
Next up we want to set up the data frame for our machine learning.

70
00:05:12.750 --> 00:05:17.730
And in my opinion is probably one of the most important parts of the machine learning section in general

71
00:05:17.820 --> 00:05:22.590
of making sure how to actually set up your data correctly remember needs to be in the form of two columns

72
00:05:22.680 --> 00:05:24.420
label and features.

73
00:05:24.450 --> 00:05:29.310
So I'll start off by using that vector assembler tool and I need to import that.

74
00:05:29.310 --> 00:05:33.870
And you can always just reference the notes as far as where to import this or hopefully you can also

75
00:05:33.870 --> 00:05:36.360
feel comfortable referencing the documentation.

76
00:05:36.360 --> 00:05:44.350
So this comes from Orrery that Apache that sparked the HTML feature dot vector assembler and then also

77
00:05:44.350 --> 00:05:47.620
from linear algebra to make sure this all works together.

78
00:05:47.650 --> 00:05:59.240
I want to say Sparke M-L Len Owch vectors notes to make sure that we have no issues with vector assembler.

79
00:05:59.560 --> 00:06:03.310
Then we want to rename the yearly amount spent column as label.

80
00:06:03.310 --> 00:06:08.920
We also only want to grab the numerical columns from the data later on in subsequent lectures will show

81
00:06:08.920 --> 00:06:10.330
you how to the categorical data.

82
00:06:10.420 --> 00:06:13.890
But for right now we're just dealing with numerical information.

83
00:06:13.900 --> 00:06:17.280
We want to set all of this as a new data frame called día.

84
00:06:17.590 --> 00:06:19.690
Let's go ahead and do that.

85
00:06:19.690 --> 00:06:27.520
We will say Val the f is equal to data and the first thing I want to do is grab that yearly amount Spence

86
00:06:27.610 --> 00:06:30.170
and rename it as label.

87
00:06:30.170 --> 00:06:47.100
So I will say select data yearly amount spent and then I will say as label all lower case and then the

88
00:06:47.100 --> 00:06:51.060
next thing I want to do is grab those numerical column values.

89
00:06:51.060 --> 00:06:52.290
Now a quick way to do this.

90
00:06:52.350 --> 00:06:54.170
This is just do something like this.

91
00:06:54.330 --> 00:06:59.100
Since we're dealing with Spark's shell and we don't have everything in an object I can simply say data

92
00:07:00.150 --> 00:07:03.370
columns and get an array of all these columns strings.

93
00:07:03.370 --> 00:07:06.960
This is going to help me out as far as what actually wants in this case.

94
00:07:06.990 --> 00:07:11.650
I want average session length time on App time on a Web site and length of membership.

95
00:07:11.700 --> 00:07:20.000
I will copy these paste them in here make sure we're back where we want to be wups sick of that and

96
00:07:20.000 --> 00:07:20.690
actually copy that.

97
00:07:20.690 --> 00:07:21.880
Let's try this again.

98
00:07:22.130 --> 00:07:27.760
We'll highlight these right click copy right click paste.

99
00:07:27.760 --> 00:07:28.840
There we go.

100
00:07:28.900 --> 00:07:33.800
And now just convert these into those skulls strings that we need them to be.

101
00:07:33.910 --> 00:07:36.870
So I will actually put this in multiple lines.

102
00:07:37.760 --> 00:07:39.880
Using print says.

103
00:07:40.940 --> 00:07:48.990
And we want to close off these quotes so we want the average session length the time on the application

104
00:07:50.370 --> 00:07:57.030
and then we can start a new line there bring that back then time on Web site and again you need to use

105
00:07:57.030 --> 00:07:59.860
those dollar signs since we're using Scullin notation here.

106
00:08:01.180 --> 00:08:07.280
And then length of membership if you want and you could also use that sequence notation let's delete

107
00:08:07.310 --> 00:08:07.890
that.

108
00:08:07.990 --> 00:08:09.410
All right there you have it.

109
00:08:10.350 --> 00:08:14.700
Let's save this and make sure our formatting works with those extra parentheses.

110
00:08:15.020 --> 00:08:18.090
So I will load Lynne right exercise that skull again.

111
00:08:19.100 --> 00:08:22.830
That prints out as example rows and looks like everything's working well.

112
00:08:22.880 --> 00:08:26.500
I will go ahead and delete this for loop so you don't see this every time.

113
00:08:26.570 --> 00:08:27.590
Rerun the script

114
00:08:30.250 --> 00:08:32.310
and back quite quickly back.

115
00:08:32.430 --> 00:08:33.010
There you go.

116
00:08:33.970 --> 00:08:35.610
Moving along.

117
00:08:35.670 --> 00:08:40.270
Next up we want the assembler to convert the input values to a vector.

118
00:08:40.290 --> 00:08:44.120
Remember that a vector is what the algorithm reads to train the model.

119
00:08:44.160 --> 00:08:50.820
So coming up next we need to use a vector assembler to convert the input column of DFA to a single output

120
00:08:50.820 --> 00:08:52.920
column of an array called features.

121
00:08:52.920 --> 00:08:54.270
This is something I keep reiterating.

122
00:08:54.290 --> 00:08:58.950
But it's really important to kind of get this sort of workflow in your mind that we want to set the

123
00:08:59.010 --> 00:09:04.140
input columns from which we are supposed to read the values and call this entire new object assembler.

124
00:09:05.130 --> 00:09:12.740
So I will say all assembler is equal to new vector assembler.

125
00:09:13.810 --> 00:09:22.650
I will set my input calls to an array consisting of these actual feature columns and I can just copy

126
00:09:22.650 --> 00:09:29.220
and paste this here so I will copy this and paste this.

127
00:09:29.230 --> 00:09:34.640
It may look a little strange on my screen just because I have the font so large but this is what you

128
00:09:34.640 --> 00:09:37.250
should be doing is dollar signs.

129
00:09:37.250 --> 00:09:40.100
We just need strings not columns here.

130
00:09:40.100 --> 00:09:42.900
Looks like I have my average session length time on App time.

131
00:09:42.900 --> 00:09:44.240
Website length of membership.

132
00:09:44.240 --> 00:09:47.330
Those are my numerical features that I want to be working with.

133
00:09:47.330 --> 00:09:52.660
And then finally I need to also set the output column to be features set to organize this.

134
00:09:52.670 --> 00:09:57.260
I can break this up into multiple lines if I want to but I'm just going to scroll all the way to the

135
00:09:57.260 --> 00:10:08.510
end here and take Carolis to say set output call to features all lowercase and let's go ahead and move

136
00:10:08.510 --> 00:10:09.310
along.

137
00:10:09.370 --> 00:10:12.740
Save that and something that's nice about SPARK shell.

138
00:10:12.770 --> 00:10:16.090
You can just keep loading this as long as your data isn't humongous.

139
00:10:16.090 --> 00:10:20.330
You can keep playing around this and making sure everything works and you can even just type in one

140
00:10:20.330 --> 00:10:23.830
line at a time if you want into your SPARC shell.

141
00:10:23.840 --> 00:10:29.960
Next we need to use the assembler to transform our data frame to the two columns.

142
00:10:30.050 --> 00:10:32.620
So once you've created that assembler it actually use it.

143
00:10:32.690 --> 00:10:37.910
So we will save our output is equal to assembler will say.

144
00:10:37.910 --> 00:10:42.480
Transform DMF.

145
00:10:42.590 --> 00:10:52.720
I will say selects and then I only want to select the label and the features.

146
00:10:52.900 --> 00:10:59.050
Then I'm going to create a linear regression model object so save Val L-R as equal to new.

147
00:10:59.050 --> 00:11:02.960
Remember we already imported linear regression so we're good to go there.

148
00:11:03.010 --> 00:11:07.540
Sorry I've created my linear regression model object haven't added any extra parameters we'll get into

149
00:11:07.540 --> 00:11:10.060
that later when we talk about parameter grids.

150
00:11:10.150 --> 00:11:18.000
And next I want to fit the model to the data and call this model LR model so I will say that all L-R

151
00:11:18.000 --> 00:11:26.220
model is equal to LR fit output.

152
00:11:26.220 --> 00:11:30.710
Next we want to print the coefficients in print the intercept for linear regression.

153
00:11:30.720 --> 00:11:31.950
That's actually quite easy.

154
00:11:31.950 --> 00:11:43.070
We'll just say print line and then I want to say with some string interpretation here ass I'll say Coeff

155
00:11:44.880 --> 00:11:47.530
dollar sign and you don't really need to use these curly brackets.

156
00:11:47.550 --> 00:11:50.690
But it's good form coefficients.

157
00:11:50.780 --> 00:11:53.760
And then I will go ahead and say int..

158
00:11:56.580 --> 00:12:00.580
And call L.R. model int..

159
00:12:02.080 --> 00:12:06.650
And then close off these double quotes.

160
00:12:06.750 --> 00:12:09.290
Let's make sure that all actually works.

161
00:12:09.300 --> 00:12:12.440
We may need to possibly debug syntax error.

162
00:12:12.450 --> 00:12:17.890
So just to Chickaree things working correctly I went ahead and ran that OK.

163
00:12:17.940 --> 00:12:21.600
And again if you get warnings don't worry as long as you're not getting a whole error you should be

164
00:12:21.600 --> 00:12:22.680
good to go.

165
00:12:22.680 --> 00:12:28.170
Looks like we're able to successfully print out those coefficients and print out that intercept.

166
00:12:28.170 --> 00:12:32.870
Now let's actually summarize the model over the training set and print out some metrics.

167
00:12:33.000 --> 00:12:38.760
Again just to reiterate you shouldn't usually get the summary off your own training set.

168
00:12:38.760 --> 00:12:41.580
We haven't reached train test validation splits yet.

169
00:12:41.580 --> 00:12:45.840
So keep that in mind that you usually would split your data into a training set and a testing set.

170
00:12:45.840 --> 00:12:50.220
Right now we're just going to grab summary.

171
00:12:50.480 --> 00:12:55.120
Call it training summary instead of equal to L.R. model

172
00:12:57.610 --> 00:12:59.460
summary.

173
00:12:59.650 --> 00:13:03.460
And then I want to show the residuals the root mean squared error.

174
00:13:03.460 --> 00:13:07.480
The mean square there and then the R-squared values.

175
00:13:07.490 --> 00:13:14.440
So this model or this model summary actually makes this really easy I will just say training summary

176
00:13:15.970 --> 00:13:20.400
residuals that show for the residuals themselves.

177
00:13:20.630 --> 00:13:22.520
And then I can say print line.

178
00:13:22.550 --> 00:13:31.760
Let's go ahead and print out the root means squirter there and that's just going to be the training

179
00:13:31.760 --> 00:13:33.310
summary dots.

180
00:13:33.320 --> 00:13:39.830
And in this case it's the root mean square close française finish off.

181
00:13:40.130 --> 00:13:44.240
And I will copy and paste this line two more times because we're going to do something really similar

182
00:13:44.690 --> 00:13:47.790
for the means corridor and the R-squared value.

183
00:13:47.840 --> 00:13:55.170
So we're going change here is the square that is just this means quarter and then R-squared value.

184
00:13:55.290 --> 00:14:02.850
I'll say Art 2 is just going to be our to save that run it.

185
00:14:03.150 --> 00:14:06.520
And that should be importing everything.

186
00:14:06.570 --> 00:14:09.930
Making sure print schema looks good using that assembler.

187
00:14:09.930 --> 00:14:15.150
There are the residual values and looks like we're able to explain 98 percent of the variance so this

188
00:14:15.150 --> 00:14:16.500
is a pretty good model.

189
00:14:16.500 --> 00:14:21.870
Again we don't know how well this model perform on data it hasn't seen yet but given the fact that it's

190
00:14:21.870 --> 00:14:27.570
doing a pretty nice explanation of variance here with Point 9 as it's R-squared value this should be

191
00:14:27.570 --> 00:14:29.250
a pretty good model for this data.

192
00:14:29.250 --> 00:14:33.990
And since this is artificial data I can just give you a verification right now.

193
00:14:33.990 --> 00:14:37.620
This data is really easy to fit to a very simple linear regression.

194
00:14:37.740 --> 00:14:40.930
So you shouldn't be surprised if you performed really well in this data.

195
00:14:41.070 --> 00:14:45.720
Now in real world data is going to be a different story but we'll get to that later when we actually

196
00:14:45.720 --> 00:14:48.330
deal with Kaggle project data.

197
00:14:48.330 --> 00:14:50.500
Let's just quickly review everything we did.

198
00:14:50.580 --> 00:14:56.250
Hopefully you're able to more or less follow along with the previous lectures as far as actually filling

199
00:14:56.250 --> 00:14:58.550
out this linear Russian exercise.

200
00:14:58.740 --> 00:15:01.030
Personally did was imported linear regression.

201
00:15:01.170 --> 00:15:05.720
Again as I noted before usually all imports will go to the top of the script.

202
00:15:05.940 --> 00:15:07.990
They wanted to start a simple Spark's session.

203
00:15:08.060 --> 00:15:13.580
Just did that spark session read in the e-commerce customer CSFB file printed out the schema of that

204
00:15:13.590 --> 00:15:18.370
data frame explore the data frame a little more by just pointing out that head of the data frame.

205
00:15:18.690 --> 00:15:20.140
And then this is the crucial part.

206
00:15:20.190 --> 00:15:22.140
Setting up a data frame for machine learning.

207
00:15:22.140 --> 00:15:25.500
Right now we're just dealing with numerical data haven't thought of categorical features yet in this

208
00:15:25.500 --> 00:15:31.230
course but we wanted to make sure to import the vector assembler into vectors making sure that we can

209
00:15:31.230 --> 00:15:37.950
actually grab all those features and set the label column as label as far as its name goes.

210
00:15:38.010 --> 00:15:42.840
Select those numerical features or at least the features we want to use and then create an assembler

211
00:15:42.840 --> 00:15:45.290
object using new vector assembler.

212
00:15:45.400 --> 00:15:51.310
Set the input columns of those features as an array and then set an output column as features.

213
00:15:51.320 --> 00:15:57.440
Up next we want to actually use that assembler to transform the data frame that we had select the data

214
00:15:57.770 --> 00:16:02.730
and we only want to select now the label column and the features column set that has output.

215
00:16:02.900 --> 00:16:06.830
Create a new linear regression model objects fit the model to the data.

216
00:16:06.830 --> 00:16:13.000
Call that model LR model and then print the coefficients intercept as well as the summary data.

217
00:16:13.000 --> 00:16:13.570
All right.

218
00:16:13.730 --> 00:16:18.990
Hopefully by now you're feeling a lot more comfortable with using machine learning with Scala and Sparke.

219
00:16:19.100 --> 00:16:23.180
I know it can be really intimidating at first especially if it's your first time just browsing through

220
00:16:23.180 --> 00:16:27.950
the documentation it seems almost impossible there's a lot of debugging to do but hopefully splitting

221
00:16:27.950 --> 00:16:33.500
it up into these separate chunks and these smaller steps helps your understanding of setting up any

222
00:16:33.500 --> 00:16:39.180
data source into a data frame that a machine learning library and SPARC can't read.

223
00:16:39.350 --> 00:16:44.930
If you have any questions go ahead and make sure you check out the solutions script to this has some

224
00:16:44.930 --> 00:16:46.650
more data and more information there.

225
00:16:46.790 --> 00:16:52.040
And also feel free to post the Q&amp;A forums as well as exploring Web sites like stack overflow or the

226
00:16:52.040 --> 00:16:53.790
spark documentation.

227
00:16:53.810 --> 00:16:56.140
Thanks everyone and I'll see you at the next lecture.
