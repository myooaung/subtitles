WEBVTT

00:00.240 --> 00:08.000
Hello and welcome to step five implementing the convolutional Nouel network variational are in color

00:08.210 --> 00:16.020
the sea and the and mostly welcome to the first implementation phase because indeed you've just seen

00:16.110 --> 00:22.920
in the four previous steps the required theory needed to understand before implementing of course the

00:22.920 --> 00:23.860
moral.

00:23.910 --> 00:31.950
And so what we're about to implement in this Step Five is exactly this part composed of the CNN and

00:32.220 --> 00:33.040
the V.

00:33.120 --> 00:39.990
And what's important to understand is that the C and the convolutional neural network allows the vision

00:40.140 --> 00:46.620
of the model so that the model is able to see just like a human the input frames on the game on the

00:46.620 --> 00:52.150
car racing game just as if it was playing the game like some humans would play video games.

00:52.290 --> 01:00.150
And then the Wii this bar here is the part that dreams remember that the specific feature of this new

01:00.300 --> 01:06.660
Fool world model is that it is a model that is able to dream because indeed the core added value of

01:06.660 --> 01:10.310
the full world model is that it gains better performance.

01:10.410 --> 01:17.110
Inside the dream that is inside the reconstructed environment happening here in the Wii.

01:17.280 --> 01:23.160
So basically we call it a dream because you know when we dream when we humans dream Well what happens

01:23.160 --> 01:28.460
is that our brain remembers the real environment of earth in which we live.

01:28.650 --> 01:35.820
And during our sleep our mind reconstruct the environment images that our brain remembers and sometimes

01:35.970 --> 01:42.030
it's true that the dreams seem quite different from the reality because the reconstruction can be very

01:42.030 --> 01:42.870
abstract.

01:42.870 --> 01:45.540
That's why sometimes we have very weird dreams.

01:45.660 --> 01:50.520
And so here that's the same we have the input frames which are the reality.

01:50.520 --> 01:54.650
The model sees it and then with the V.A. it happening here.

01:54.750 --> 02:02.040
Well the moral will first encode the real images the real input frames into what we called a latent

02:02.040 --> 02:09.170
vector which you saw was real in his variational or encoder intuition lectures and then from the latent

02:09.180 --> 02:14.130
vector that we will reconstruct the images as in a dream.

02:14.190 --> 02:20.180
And that's why here this whole a part of the Fool world normal corresponds to the dream.

02:20.340 --> 02:22.250
And then of course we have the memory.

02:22.320 --> 02:28.590
We will see that an implement that later on that will of course improve the model because it will leverage

02:28.680 --> 02:35.880
the temporal relationship of the environment to be able to predict some better future actions that will

02:35.880 --> 02:38.770
come in step 6 with the regular neural network.

02:38.820 --> 02:41.350
Then Step Seven mixture in that work.

02:41.460 --> 02:45.550
And then again we'll implement together the endian Arnon.

02:45.600 --> 02:46.200
All right.

02:46.200 --> 02:50.870
So here we go for this step 5 implementing the CNN V.

02:50.940 --> 02:52.220
I can't wait to start.

02:52.230 --> 02:59.220
We're going to build a big class that is going to contain not only the fool architecture of the convolutional

02:59.220 --> 03:05.100
variational our encoder but also we will implement the training operations.

03:05.100 --> 03:08.000
So this will take about 80 lines of code.

03:08.010 --> 03:09.030
I hope you're ready.

03:09.180 --> 03:15.630
And now the exciting thing that I wanted to show you is that the architecture that I just mentioned

03:15.790 --> 03:21.960
and that we're going to build in this implementation you know in this huge convolutional the class is

03:21.960 --> 03:29.670
going to be exactly the same architecture as the one given in this article because indeed here that's

03:29.730 --> 03:32.150
the part explain the V8 immoral.

03:32.160 --> 03:33.740
Make sure to read it.

03:33.840 --> 03:37.080
If it's not done yet you'll get the right intuition.

03:37.080 --> 03:44.790
But if we scroll down down to the putting everything together section you'll see at the end that for

03:44.790 --> 03:50.220
more specific information about the morals training procedures and environments Please refer to the

03:50.220 --> 03:51.050
appendix.

03:51.110 --> 03:58.370
And if you click it well you will find out the whole architecture of the variational are in core.

03:58.560 --> 04:04.230
And so what I was saying is that the architecture we will build in our implementation of this Step Five

04:04.380 --> 04:08.140
is exactly that same architecture that we see here.

04:08.300 --> 04:18.870
I mean some first convolutional layers of 32 64 128 and 256 sensor input then will create the latent

04:18.870 --> 04:25.710
vector which will be a one dimensional vector of course but composed of 1024 elements which will be

04:25.710 --> 04:29.670
the result of the flattening after the convolutions.

04:29.850 --> 04:37.440
And then we'll use the deconvolution or also called to transpose convolutions or even the inverted convolutions

04:37.740 --> 04:43.400
to recreate or to reconstruct the images from the latent vectors.

04:43.630 --> 04:44.200
All right.

04:44.220 --> 04:46.790
And this will create the dream right here.

04:46.800 --> 04:49.020
The dream is created right here.

04:49.050 --> 04:50.430
That's the reality.

04:50.460 --> 04:58.080
The input images coming from the environment and all this process happens to create in the end the dream.

04:58.140 --> 05:04.570
And so this is really fascinating because the AI manages to gain performance you know to become stronger

05:04.570 --> 05:07.390
and more intelligent by training.

05:07.420 --> 05:08.650
Inside the dream.

05:08.680 --> 05:15.730
So that's why I remember I said one of the pros was that this whole invention is based on a fascinating

05:15.970 --> 05:16.770
idea.

05:17.140 --> 05:23.860
All right so if you're ready now we're going to move on to Python to build all this plus the training

05:23.920 --> 05:24.830
operations.

05:24.970 --> 05:28.340
And so speaking of Python Here it is.

05:28.660 --> 05:30.840
Right now we are indeed on Python.

05:30.850 --> 05:36.160
But more specifically we are on the spider idea from Anaconda.

05:36.190 --> 05:42.270
So if you like this idea you can download Anaconda which you can find very easily on Google.

05:42.310 --> 05:47.170
And then inside Anaconda You will launch spider and eventually at the end of the Course you'll see that

05:47.170 --> 05:52.700
we will create a virtual environment in which we will install all the required packages.

05:52.740 --> 05:58.840
And inside this virtual environment will of course execute the whole code that is who will run the full

05:58.840 --> 06:05.260
world model on the car racing environment and we will play against it like I did in the first lecture

06:05.530 --> 06:06.390
of this course.

06:06.670 --> 06:13.420
But we're still far from that before we have to build our first model the first moral component of the

06:13.420 --> 06:14.560
full world model.

06:14.710 --> 06:17.930
And this is the variational our encoder.

06:18.190 --> 06:20.860
And so where is that either.

06:20.950 --> 06:22.530
I found that I created.

06:22.640 --> 06:27.370
Well first of all no worries because we will give you everything at the end of the course you will get

06:27.460 --> 06:34.120
not only the inference for that but also the training folder in both AI programming languages which

06:34.120 --> 06:38.800
are sense of flow and keras we will implement that intensive flow.

06:39.010 --> 06:43.590
But where did I create this the pipe and fell well here.

06:43.630 --> 06:46.860
As you can see I am on my desktop on my desktop.

06:46.900 --> 06:49.340
I created a master class folder.

06:49.540 --> 06:55.840
And if we open it we will get as you will get when we give you the folder to subfolder is inference

06:55.930 --> 06:58.730
and training an inference for there.

06:58.750 --> 07:05.230
That's where I created the API and fell which we will implement in the step 5.

07:05.290 --> 07:06.220
Are you ready.

07:06.220 --> 07:06.980
Here we go.

07:07.030 --> 07:11.140
Let's start with the first code section importing the libraries.

07:11.530 --> 07:18.600
So we will only need two libraries here to build this convolutional the class.

07:18.790 --> 07:25.490
And these are first non-Thai for which will give the shortcut and P.

07:25.690 --> 07:34.950
And of course as we've just said of flow for which we will give the shortcut T F and perfect that's

07:34.950 --> 07:35.490
it.

07:35.490 --> 07:40.150
That's only what we'll need to create our convolutional the Emo.

07:40.290 --> 07:47.380
And now we're ready to build the convolutional emotional and we'll build that as you can see within

07:47.390 --> 07:50.830
a class which will call count the.

07:51.150 --> 07:57.460
But this is going to be a big code section no big class with a lot of things to do including building

07:57.460 --> 08:01.370
the whole architecture which as you saw is not a simple architecture.

08:01.530 --> 08:03.860
And also the training operations.

08:04.060 --> 08:05.190
Let's take a break here.

08:05.200 --> 08:09.610
Let's get some good energy and let's start tackling it in the next tutorial.

08:09.630 --> 08:11.240
Until then enjoy AI.
