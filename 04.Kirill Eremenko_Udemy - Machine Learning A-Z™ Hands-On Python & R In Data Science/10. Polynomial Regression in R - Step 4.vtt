WEBVTT
1

00:00:00.330  -->  00:00:02.800
Hello and welcome to this are two Tauriel.

2

00:00:02.820  -->  00:00:05.980
So in the previous tutorials we did the exciting step.

3

00:00:06.000  -->  00:00:11.910
We created our two regressors to linear aggressor and the polynomial repressor and we visualized their

4

00:00:11.910  -->  00:00:12.740
results.

5

00:00:12.990  -->  00:00:15.700
So if we look at our graphs here.

6

00:00:15.810  -->  00:00:21.690
Well if we take the first one that we plotted that is the linear regression graph we obtained this trade

7

00:00:21.690  -->  00:00:22.270
line here.

8

00:00:22.280  -->  00:00:27.450
That's besides its name indicates that it's a linear model and we thought that this model doesn't fit

9

00:00:27.780  -->  00:00:28.750
the data very well.

10

00:00:28.770  -->  00:00:34.430
Because as you can see most of the prediction points are far from the real observation points.

11

00:00:34.680  -->  00:00:40.050
And then we were more satisfied when we visualize the polynomial regression results first with the third

12

00:00:40.050  -->  00:00:40.560
degrees.

13

00:00:40.560  -->  00:00:45.330
That's the Paulism regression model with a 3 degree and it's actually much better.

14

00:00:45.330  -->  00:00:51.450
We can see that the model is fitting much better to the data set since obviously the predictions are

15

00:00:51.450  -->  00:00:56.910
getting much closer to the real values than the previous predictions with the linear regression model

16

00:00:56.910  -->  00:00:57.260
.

17

00:00:57.270  -->  00:00:58.590
So that was much better.

18

00:00:58.800  -->  00:01:04.530
And then we did even better by adding a new degree to our bill in a regression model and we actually

19

00:01:04.530  -->  00:01:10.380
obtained this model that we have here and now we can clearly see that this model is fitting very well

20

00:01:10.380  -->  00:01:15.730
the data set because all the predictions are very very close to the real values.

21

00:01:15.730  -->  00:01:18.570
And for some of them it's actually the same.

22

00:01:18.600  -->  00:01:24.450
So that's definitely an excellent model for us because we are trying to make the most accurate prediction

23

00:01:24.530  -->  00:01:25.280
as possible.

24

00:01:25.290  -->  00:01:29.970
We are trying to predict the previous salary of a potential future employee that is about to be hired

25

00:01:30.270  -->  00:01:35.550
and this predicted salary is at the heart of the negotiation because this employee is telling that it's

26

00:01:35.550  -->  00:01:39.770
pretty salary was 160 OK and he's asking for more than that.

27

00:01:39.900  -->  00:01:45.770
And therefore we are trying to predict if there's 160 ok salary is the truth or above.

28

00:01:46.150  -->  00:01:51.780
Ok so now that we get this curve and now that we see that we have an excellent model for our problem

29

00:01:52.010  -->  00:01:53.730
we are going to validate this moral.

30

00:01:53.820  -->  00:01:59.610
And this is the model we are going to choose to make our final accurate prediction and that is what

31

00:01:59.610  -->  00:02:01.620
we are going to do in this tutorial.

32

00:02:01.800  -->  00:02:03.680
So let's do it.

33

00:02:03.690  -->  00:02:07.080
I'm actually going to this new code section that I prepared for you.

34

00:02:07.080  -->  00:02:14.020
So first one to predict the salary associated to a 6.5 level according to a linear regression model

35

00:02:14.220  -->  00:02:20.520
and then the second code section will predict the salary of the 6.5 level according to our polynomial

36

00:02:20.520  -->  00:02:21.590
regression.

37

00:02:21.630  -->  00:02:24.880
This one right here with a fourth degree.

38

00:02:25.050  -->  00:02:25.280
Okay.

39

00:02:25.290  -->  00:02:28.440
So let's start with the linear regression prediction.

40

00:02:28.440  -->  00:02:34.460
So we're going to do exactly the same as in simple regression we are going to use the product function

41

00:02:34.980  -->  00:02:40.290
but actually something is going to be different and it will interest many of you this time we're not

42

00:02:40.290  -->  00:02:45.390
going to make some predictions on a whole test set that is on a vector of observations.

43

00:02:45.540  -->  00:02:51.810
We're going to make a single prediction that is we're going to make a prediction of a single level which

44

00:02:51.810  -->  00:02:53.820
is going to be the 6.5 level.

45

00:02:53.880  -->  00:02:58.830
So are we going to see that the syntax is going to change the technique to make this prediction is going

46

00:02:58.830  -->  00:02:59.670
to change.

47

00:02:59.670  -->  00:03:02.320
But it's actually as easy.

48

00:03:02.370  -->  00:03:03.550
So let's do it.

49

00:03:03.570  -->  00:03:08.910
We're going to call this prediction widespread as before so be careful why pred was before a vector

50

00:03:09.210  -->  00:03:11.900
and now it's only going to be a single prediction of value.

51

00:03:11.910  -->  00:03:14.460
So let's still call it white bread anyway.

52

00:03:14.640  -->  00:03:16.280
And same as before.

53

00:03:16.320  -->  00:03:18.660
We're going to take the Predict function.

54

00:03:18.660  -->  00:03:20.660
So let's here take predict.

55

00:03:20.660  -->  00:03:21.480
Here we go.

56

00:03:21.700  -->  00:03:26.400
And now in this predict function remember we need to specify first the regressors we want to make the

57

00:03:26.400  -->  00:03:27.230
predictions with.

58

00:03:27.300  -->  00:03:28.730
So that's the first argument.

59

00:03:28.950  -->  00:03:34.310
And then the second argument is the new data of which we want to make the predictions.

60

00:03:34.560  -->  00:03:38.440
OK so let's put the first argument the first argument is our aggressor.

61

00:03:38.610  -->  00:03:44.160
And since are predicting the result with the linear regression regress or and since we call this regress

62

00:03:44.160  -->  00:03:50.510
or Lynn raggie then the first argument we need to put here is Lendrick.

63

00:03:51.330  -->  00:03:51.700
All right.

64

00:03:51.700  -->  00:03:53.210
So that's our aggressor.

65

00:03:53.520  -->  00:03:58.500
And now we need to input the new data of which we want to make the prediction.

66

00:03:58.500  -->  00:04:05.610
So this new data is as you understood a single element a single observation point and this observation

67

00:04:05.610  -->  00:04:09.330
point is actually the 6.5 level here.

68

00:04:09.330  -->  00:04:16.980
So what we'll do now is to actually you know since this six point five level doesn't exist in our dataset

69

00:04:17.340  -->  00:04:21.980
we actually need to create a new data frame containing the 6.5 value.

70

00:04:21.990  -->  00:04:25.790
We're not going to add this 6.5 level in our dataset.

71

00:04:25.890  -->  00:04:32.660
We're going to create a new data set of only one line and only one column that is of only one cell actually

72

00:04:32.660  -->  00:04:32.790
.

73

00:04:32.880  -->  00:04:36.490
And this cell will contain the 6.5 level.

74

00:04:36.660  -->  00:04:37.650
So let's do this.

75

00:04:37.650  -->  00:04:43.650
The syntax and are to do that is very simple we just need to type here data frame separated by a dot

76

00:04:43.650  -->  00:04:44.120
.

77

00:04:44.130  -->  00:04:50.610
So frame it we go data frame and now as you can see it automatically added some parenthesis.

78

00:04:50.730  -->  00:05:00.940
And in these parenthesis we need to input level equals six point five and that's it that's actually

79

00:05:00.940  -->  00:05:06.390
all you need to do to make a single prediction using the pretty function with a specific regressive

80

00:05:06.400  -->  00:05:08.350
that is here the are aggressor.

81

00:05:08.590  -->  00:05:09.530
Let's check it out.

82

00:05:09.690  -->  00:05:13.970
Let's select this line and executes OK.

83

00:05:13.990  -->  00:05:18.370
y pred correctly generated so as you can see why it has no values.

84

00:05:18.400  -->  00:05:23.320
We can already see the predictive value of the 6.5 level salary.

85

00:05:23.680  -->  00:05:32.320
And it's actually $330000 so much higher than what this employee mentions salary was so that's actually

86

00:05:32.310  -->  00:05:33.140
a good start for us.

87

00:05:33.140  -->  00:05:38.860
But remember we don't want to keep the linear regression all we want to keep the most accurate regression

88

00:05:38.860  -->  00:05:39.550
model.

89

00:05:39.670  -->  00:05:41.710
That is of course the polynomial regression model.

90

00:05:41.710  -->  00:05:47.580
So what we're going to do now is make the same prediction but this time according to our polynomial

91

00:05:47.590  -->  00:05:48.570
regression.

92

00:05:49.030  -->  00:05:54.280
So let's do this let's be efficient and copy this line because we will only need to change a few things

93

00:05:54.290  -->  00:05:54.340
.

94

00:05:54.390  -->  00:05:59.280
But you're going to see that this time it's not going to be that simple as here it's going to be simple

95

00:05:59.470  -->  00:06:00.480
but not that simple.

96

00:06:00.480  -->  00:06:04.210
We just need to add several arguments in ways that the reason is very logic.

97

00:06:04.290  -->  00:06:10.770
It's because since our polling of the regression model learns the correlations on this data set containing

98

00:06:10.780  -->  00:06:15.470
the level column and also the level 2 level 3 and level 4 columns.

99

00:06:15.610  -->  00:06:21.890
Well when we create this new data frame containing only the 6.5 level observation.

100

00:06:21.970  -->  00:06:27.180
Well since we're pulling on the regressors based upon these four columns here level level 2 level 3

101

00:06:27.190  -->  00:06:33.570
and level 4 then that means that in this new observation cell that we created for our level 6.5 we not

102

00:06:33.580  -->  00:06:39.220
only need to input the level but also the level to the level 3 and level 4.

103

00:06:39.430  -->  00:06:40.840
And that's what's going to change here.

104

00:06:40.870  -->  00:06:45.430
That's the only thing that is a little less simple than what we did before.

105

00:06:45.550  -->  00:06:51.050
But it's still very simple because as you can see it will be very quick and easy to add this values

106

00:06:51.060  -->  00:06:51.530
.

107

00:06:51.690  -->  00:06:55.140
So let's do this let's not forget to change of course the regressors here.

108

00:06:55.240  -->  00:06:56.600
It's not Liberec anymore.

109

00:06:56.620  -->  00:07:02.410
It's probably wrecked because polygraph is the name we gave to our polynomial regression regrets or

110

00:07:02.730  -->  00:07:04.630
in this formula right here.

111

00:07:05.140  -->  00:07:05.870
OK.

112

00:07:06.000  -->  00:07:12.220
And so now as I just explained we just need to add here to put in the features of our levels.

113

00:07:12.220  -->  00:07:16.420
So that means that we need at level 2 right here.

114

00:07:16.810  -->  00:07:19.060
And don't worry we don't need to compute it ourselves.

115

00:07:19.120  -->  00:07:27.220
We just need to add here 6.5 squared and that will do it because you know level 2 contains the square

116

00:07:27.220  -->  00:07:30.170
values of the values and the level column.

117

00:07:30.310  -->  00:07:34.660
And that's why here we add level 2 equals 6.5 squared.

118

00:07:34.930  -->  00:07:36.670
And same for the other levels.

119

00:07:36.670  -->  00:07:40.490
We actually made a fourth degree polynomial regression model.

120

00:07:40.540  -->  00:07:42.360
So we need to add here four levels.

121

00:07:42.500  -->  00:07:43.610
And so I'm adding here.

122

00:07:43.690  -->  00:07:47.410
Level 3 equals 6.5.

123

00:07:47.520  -->  00:07:48.610
That's the power of three.

124

00:07:48.750  -->  00:07:49.920
And our last level.

125

00:07:50.010  -->  00:07:54.620
Level four equals six point five The power four.

126

00:07:54.750  -->  00:07:59.120
In that sense it was only this little simple thing to do but now it's ready.

127

00:07:59.130  -->  00:08:00.190
So let's check it out.

128

00:08:00.250  -->  00:08:06.340
And actually we're about to find out the final verdict of the heart of the negotiation which is the

129

00:08:06.340  -->  00:08:12.180
most accurate predicted salary that this future potential employee had in its previous company.

130

00:08:12.390  -->  00:08:13.440
So let's find out.

131

00:08:13.450  -->  00:08:19.180
I'm going to select all this and press command and control pass and to execute.

132

00:08:19.180  -->  00:08:19.950
Here we go.

133

00:08:20.010  -->  00:08:21.480
So what is the final value.

134

00:08:21.490  -->  00:08:26.930
It's a hundred and fifty eight thousand dollars so very close to what the employee said.

135

00:08:26.980  -->  00:08:31.130
He said hundred and sixty K and we predicted a hundred and fifty eight 158 OK.

136

00:08:31.360  -->  00:08:37.030
So that's awesome news because not only we can proceed to the right direction of our negotiation but

137

00:08:37.020  -->  00:08:43.420
also we can now be relieved that this new future potential employee is very horniest And that's one

138

00:08:43.410  -->  00:08:47.260
of the best quality to have in life including professional life.

139

00:08:47.320  -->  00:08:49.740
So verdict is a truth or bluff.

140

00:08:49.750  -->  00:08:52.200
Well the final verdict is truth.

141

00:08:52.480  -->  00:08:57.460
So we are ending the Statoil as well as the section about pulling the regression on a good note.

142

00:08:57.510  -->  00:08:58.670
So a happy ending.

143

00:08:58.720  -->  00:09:04.740
Not only the verdict as truth but also we can be proud of having built your very first on in their regression

144

00:09:04.740  -->  00:09:05.410
model.

145

00:09:05.400  -->  00:09:10.200
So congratulations again and you're going to see that in the next sections will be introduced to some

146

00:09:10.210  -->  00:09:14.040
new non-linear regression models and some of them are fascinating.

147

00:09:14.250  -->  00:09:17.410
So you'll see I look forward to seeing you in the next section.

148

00:09:17.430  -->  00:09:20.830
I'll just add a final tutorial here but that's not to build any more model.

149

00:09:20.830  -->  00:09:24.990
It's just that we're going to make a regression templates you know to build a lot more efficiently the

150

00:09:25.000  -->  00:09:30.090
next regression models you'll have of course the code templates and you'll see how it will be very useful

151

00:09:30.100  -->  00:09:30.570
.

152

00:09:30.580  -->  00:09:32.620
So I look forward to seeing you in the next section.

153

00:09:32.620  -->  00:09:33.940
Congratulations again.

154

00:09:33.930  -->  00:09:35.720
And until then enjoy machine learning
