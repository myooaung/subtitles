WEBVTT
1
00:00:00.330 --> 00:00:02.600
Hello and welcome to this art tutorial.

2
00:00:02.700 --> 00:00:08.400
So in the U.S. We introduced a multi armed benefit program for this ads click through rates optimization

3
00:00:08.400 --> 00:00:09.130
problem.

4
00:00:09.330 --> 00:00:16.230
And we already tried to Algorithms the first algorithm was the simple random selection algorithm that

5
00:00:16.230 --> 00:00:21.180
consists of selecting at pure random and AD at each round.

6
00:00:21.330 --> 00:00:27.990
And this algorithm gave us a totally ward of 1200 on average because you know there is this random factor

7
00:00:28.140 --> 00:00:31.550
that on average we got 1200 total reward.

8
00:00:31.650 --> 00:00:37.520
And of course when we plotted the histogram every ad was selected more or less the same number of times.

9
00:00:37.740 --> 00:00:44.700
And then we tried another algorithm which was the upper found on rhythm and there we got much better

10
00:00:44.700 --> 00:00:51.130
results because not only we managed to almost double the total reward because we got it all we want

11
00:00:51.130 --> 00:00:53.420
of 2170 8.

12
00:00:53.520 --> 00:01:00.030
So almost double of what we obtained with random selection and the even better thing is that we managed

13
00:01:00.030 --> 00:01:06.780
to figure out which version was the best to show to the user that is which adversion had the highest

14
00:01:06.900 --> 00:01:11.210
conversion rate the highest ETR that is the highest click through rate.

15
00:01:11.460 --> 00:01:17.940
And now in this section we are going to try a new algorithm which is called Thomsons sampling.

16
00:01:17.940 --> 00:01:20.910
And so in this section we're going to look at two things.

17
00:01:20.910 --> 00:01:27.720
First thing is Ken Thompson simply beat the African fins boundaries is Ken Thompson simply give us a

18
00:01:27.720 --> 00:01:31.880
tool reward that is even higher than 2170 8.

19
00:01:31.920 --> 00:01:35.290
You know we almost doubled the total reward of random selection.

20
00:01:35.310 --> 00:01:37.600
Let's see if we can beat that again.

21
00:01:37.770 --> 00:01:40.710
Like more than double or even triple it.

22
00:01:40.710 --> 00:01:41.130
I don't know.

23
00:01:41.130 --> 00:01:41.780
Let's see.

24
00:01:41.910 --> 00:01:47.340
And the second thing that we're going to look at is if we get the same adversion that has the highest

25
00:01:47.340 --> 00:01:48.240
conversion rate.

26
00:01:48.300 --> 00:01:54.630
Let's see if we get adversion number 5 which was found by the upper confidence about algorithm it found

27
00:01:54.720 --> 00:01:56.000
adversion number five.

28
00:01:56.010 --> 00:01:59.540
So let's hope that we also get at version number five.

29
00:01:59.550 --> 00:02:05.270
This should logically be the case if we manage to beat upper confidence down in terms of total we want.

30
00:02:05.340 --> 00:02:10.650
So let's do this let's implement Tomsen sampling in this section we're actually going to do that in

31
00:02:10.650 --> 00:02:17.340
one step because when you think about it we will only need to change the strategy here in this for and

32
00:02:17.340 --> 00:02:22.740
loop and then keep the same to implement Thompson something because you know we'll keep these parameters

33
00:02:22.740 --> 00:02:24.800
here that is this number of rounds.

34
00:02:24.870 --> 00:02:30.980
This number adds this at select to the vector that contains all the different ads selected at each round.

35
00:02:30.990 --> 00:02:35.710
And this will need to change because these are the parameters of the Opera confidence about algorithms

36
00:02:35.760 --> 00:02:37.000
so we will need to change it.

37
00:02:37.170 --> 00:02:43.440
And of course we will keep this total reward because we want to get the total reward accumulated through

38
00:02:43.440 --> 00:02:47.060
the execution of this Thompson sampling algorithm.

39
00:02:47.070 --> 00:02:55.560
So what we're going to do now is simply take everything from here to here copy and then paste it here

40
00:02:55.650 --> 00:02:58.100
and we will only change what we need to change.

41
00:02:58.110 --> 00:03:02.330
That is the right to run hitters for the Tompson sampling algorithm.

42
00:03:02.640 --> 00:03:04.190
All right so let's do it.

43
00:03:04.260 --> 00:03:14.100
We can already replace UCAP here by Thomson Semlin And now let's change the strategy before.

44
00:03:14.340 --> 00:03:15.660
Let's start with the basics.

45
00:03:15.660 --> 00:03:22.380
Let's set the rightful there as working directory so let's go to our mission folder then point six reinforcement

46
00:03:22.380 --> 00:03:28.660
learning Thompson stumbling and then make sure that you have this as a city are optimizations Yes that

47
00:03:28.680 --> 00:03:33.740
is of course the same c as the file as the one we had in Opera Company confidence found.

48
00:03:33.930 --> 00:03:38.520
So if you have this data set you are now ready to click on this more button here and then set as working

49
00:03:38.520 --> 00:03:39.500
directory.

50
00:03:40.020 --> 00:03:44.280
All right so now let's implement our Thomson sampling algorithm.

51
00:03:44.490 --> 00:03:49.600
So let's directly jump to the slide of the Tompson something algorithm.

52
00:03:49.730 --> 00:03:51.700
All right so where do we see here this.

53
00:03:51.710 --> 00:03:54.560
THOMPSON something algorithm takes three steps.

54
00:03:54.560 --> 00:03:59.800
First step is and each round we need to consider two numbers for each add.

55
00:04:00.200 --> 00:04:05.000
The first number is the number of times he and I got we were one up to around and.

56
00:04:05.240 --> 00:04:08.400
And the second number is the number of times that I got.

57
00:04:08.420 --> 00:04:10.130
We were zero up to around.

58
00:04:10.140 --> 00:04:13.500
And so that's the first thing we'll do here.

59
00:04:13.550 --> 00:04:20.480
We will consider these parameters and declare the variables corresponding to these parameters and we

60
00:04:20.480 --> 00:04:25.940
can notice that if we compare this Thompson something algorithm to the UCB algorithm.

61
00:04:26.150 --> 00:04:32.330
Well it's the same step one with different parameters because as you can notice here in the step one

62
00:04:32.330 --> 00:04:38.540
of the upper confidence about algorithm we also consider two numbers and these two numbers are the number

63
00:04:38.540 --> 00:04:44.500
of times he and I were selected up to around and and the sum of the words of the add up to around.

64
00:04:44.500 --> 00:04:50.300
And so if we have a look at this code section here which is the code section for the above comes from

65
00:04:50.300 --> 00:04:51.400
spell logarithm.

66
00:04:51.530 --> 00:04:58.610
Well we can see that these two parameters are here and that these parameters are no longer the parameters

67
00:04:58.610 --> 00:05:04.760
for Tomson sampling and these two parameters that we consider in step 1 in the UCB algorithm are actually

68
00:05:04.760 --> 00:05:09.410
replaced by two new parameters in the Thompson sampling algorithm.

69
00:05:09.410 --> 00:05:15.170
So what we'll do right now is simply to remove these two parameters that are the parameters considered

70
00:05:15.170 --> 00:05:21.410
and the step one of the use of the algorithm and replace them by these two new parameters that we need

71
00:05:21.410 --> 00:05:23.750
to consider for Tompson sampling algorithm.

72
00:05:23.780 --> 00:05:25.740
So let's replace them right away.

73
00:05:25.820 --> 00:05:28.820
And therefore let's declare two new marbles.

74
00:05:28.880 --> 00:05:32.240
So first longer the number of times the ADD I got.

75
00:05:32.240 --> 00:05:41.180
We were one up to around and so let's call this number numbers of words and then underscore and one

76
00:05:41.410 --> 00:05:48.260
to specify that it's the number of times the ad got keyword one and then the second number is the number

77
00:05:48.260 --> 00:05:51.370
of times the ad I got we were 0 up to around.

78
00:05:51.420 --> 00:05:57.140
And so saying we're going to create this variable numbers of rewards zero.

79
00:05:57.170 --> 00:05:59.570
Now what are we going to be these two variables.

80
00:05:59.570 --> 00:06:05.120
So these are the parameters of Tompson sampling at the essence of the future strategy that we're going

81
00:06:05.120 --> 00:06:06.160
to have here.

82
00:06:06.170 --> 00:06:12.280
So these two variables here are going to be some vectors of the elements that has ten elements.

83
00:06:12.470 --> 00:06:17.950
And as you might have guessed they will contain for each add the number of times they got we worked

84
00:06:18.050 --> 00:06:21.260
one up to around and and zero up to around.

85
00:06:21.270 --> 00:06:27.550
And so we're going to initialize these vectors the same way as we did for opera confidence and that

86
00:06:27.550 --> 00:06:35.570
is we're going to take this integer D that creates a vector of d elements and those elements are zeroes.

87
00:06:35.600 --> 00:06:43.110
So that's exactly how we are going to initialize these two variables here by a vector of 10 zeros.

88
00:06:43.250 --> 00:06:48.440
Because of course at the beginning the number of words of each add is of course zero.

89
00:06:48.620 --> 00:06:50.960
Because simply each add wasn't selected yet.

90
00:06:51.260 --> 00:06:51.620
All right.

91
00:06:51.650 --> 00:06:53.680
So we have our two arguments.

92
00:06:53.720 --> 00:06:57.070
That means that step 1 is done and we can move onto Step 2.

93
00:06:57.290 --> 00:06:59.940
So Step two is for each add.

94
00:06:59.980 --> 00:07:05.670
I we take a random draw from this distribution below which is the beta distribution.

95
00:07:05.810 --> 00:07:06.720
And why is that.

96
00:07:06.740 --> 00:07:11.680
It's because we have two important assumptions here which are related to Bayesian inference.

97
00:07:11.720 --> 00:07:17.940
So the first assumption is this first line here we suppose that each and I gets reward from a Bernoulli

98
00:07:17.960 --> 00:07:24.230
distribution of parameter Theta I which is the probability of success and you can picture this probability

99
00:07:24.230 --> 00:07:30.470
of success by showing the ad to a huge amount of users like one million users and theder I could be

100
00:07:30.470 --> 00:07:33.830
interpreted as the number of times the outcomes were one.

101
00:07:33.890 --> 00:07:39.500
That is the number of successes divided by the total number of times we selected the ADD that is 1 million.

102
00:07:39.620 --> 00:07:45.650
So basically theta is the probability of success that is the probability of getting we one when we select

103
00:07:45.670 --> 00:07:46.390
the add.

104
00:07:46.640 --> 00:07:53.600
And so the assumption is that each ad I get rewards zero and one from this Vernou the distribution of

105
00:07:53.600 --> 00:08:00.170
parameter theta which is the probability of success and then the second assumption a less strong assumption

106
00:08:00.170 --> 00:08:03.310
than the first one which is the strongest assumption that we have.

107
00:08:03.310 --> 00:08:08.660
The second assumption which is this second line here and that is that we assume that theta has a uniform

108
00:08:08.660 --> 00:08:14.260
distribution which has the prior distribution and then we use the Bayes Rule to get to a particular

109
00:08:14.270 --> 00:08:19.090
distribution which is BTG given the rewards that we got up to the round end.

110
00:08:19.210 --> 00:08:25.130
And so by using base rule that's how we get this better distribution in step 2 here.

111
00:08:25.190 --> 00:08:29.310
And so by taking at each round these random draws of these beta distribution.

112
00:08:29.480 --> 00:08:34.760
Well since these random draws represent nothing else and this probability of success we get the strategy

113
00:08:34.790 --> 00:08:40.940
here which is to take the maximum of these drones because the maximum of these random drops is approximating

114
00:08:41.180 --> 00:08:43.730
the highest probability of success.

115
00:08:43.910 --> 00:08:49.860
And that's the whole idea behind Tompson something that we are trying to estimate these parameters features

116
00:08:50.070 --> 00:08:53.000
that are the probability of success of each of these 10.

117
00:08:53.010 --> 00:08:59.030
And then by taking these random draws and taking the highest of them we are estimating the highest probability

118
00:08:59.030 --> 00:09:05.020
of success and this highest probability of success corresponds to one specific ad and each round.

119
00:09:05.180 --> 00:09:08.960
So when we take these random draw that is specific round we might be wrong.

120
00:09:09.110 --> 00:09:14.990
But when we take these random draws over thousands of rounds we'll just based on the essence of probability

121
00:09:15.320 --> 00:09:21.300
we obtain over all the data that corresponds to the ad that has the highest probability of success.

122
00:09:21.440 --> 00:09:24.180
That is the highest probability of getting reward calls 1.

123
00:09:24.410 --> 00:09:26.620
And that's the idea behind Thomsons sampling.

124
00:09:26.690 --> 00:09:31.730
And by the way taking these maximum of these random draws that is the maximum of these estimations of

125
00:09:31.730 --> 00:09:34.020
the probability of getting rewarded cause 1.

126
00:09:34.160 --> 00:09:36.580
Well that's nothing else but step three.

127
00:09:36.680 --> 00:09:43.030
And so right now what we'll do is to implement this strategy composed of step two and step three in

128
00:09:43.040 --> 00:09:44.360
this code section here.

129
00:09:44.420 --> 00:09:47.970
Replacing the old strategy of getting the upper confidence spells.

130
00:09:48.320 --> 00:09:54.380
OK so let's do it efficiently Let's keep the logic behind this code section let's not delete everything

131
00:09:54.380 --> 00:09:55.120
too quickly.

132
00:09:55.250 --> 00:09:58.710
You know since we'll get to different random draws of each add at each round.

133
00:09:58.880 --> 00:10:04.730
And since we need to take this highest random draw well we should keep this coding strategy here that

134
00:10:05.030 --> 00:10:07.840
gets the maximum value of something.

135
00:10:08.000 --> 00:10:16.310
So we'll replace this Max up about here by a max random because you know in the U.S. algorithm we needed

136
00:10:16.310 --> 00:10:19.030
to take the maximum upper bound.

137
00:10:19.190 --> 00:10:22.750
And here for Tompson something we need to take the maximum random draw.

138
00:10:22.760 --> 00:10:26.640
So we call this maximum random draw Max random.

139
00:10:26.690 --> 00:10:27.230
All right.

140
00:10:27.230 --> 00:10:33.080
And then of course we keep this at equal zero because no that's just to initialize the ad that will

141
00:10:33.200 --> 00:10:39.380
select a specific round because of course with Tompson sampling we will you pick and not to show to

142
00:10:39.370 --> 00:10:40.050
the user.

143
00:10:40.160 --> 00:10:41.910
So we will keep this article zero.

144
00:10:41.930 --> 00:10:43.730
And this ad equals I hear.

145
00:10:43.880 --> 00:10:51.440
But then what we absolutely need to change here is this if else because if else is directly specific

146
00:10:51.560 --> 00:10:53.610
to the upper confidence about strategy.

147
00:10:53.660 --> 00:10:59.330
So we will remove this and now we will implement the Tompson sampling strategy.

148
00:10:59.390 --> 00:11:05.430
So first thing we need to do is to generate the random draws of each of the 10 ads.

149
00:11:05.510 --> 00:11:10.140
So we keep this for in one day because we will need this group to go through different ads.

150
00:11:10.280 --> 00:11:12.340
And so now we need to take the random draws.

151
00:11:12.470 --> 00:11:19.010
So we are going to declare here a new variable that we'll call random on the score data and that of

152
00:11:19.010 --> 00:11:23.510
course will correspond to the different run and draws because these are random draws taken from the

153
00:11:23.580 --> 00:11:25.120
data distribution.

154
00:11:25.490 --> 00:11:26.660
So that equals.

155
00:11:26.660 --> 00:11:34.850
And now we are going to use a function of r which is our beta function which will give us exactly what

156
00:11:34.850 --> 00:11:35.290
we want.

157
00:11:35.300 --> 00:11:40.730
That is it will give us some random draws of the beta distribution of parameters that we choose.

158
00:11:41.000 --> 00:11:46.180
And as we can see on the slide here the first parameter is the number of times the average and I got

159
00:11:46.180 --> 00:11:52.670
we were one plus one and the second parameter is the number of times the add I got we've got zero plus

160
00:11:52.670 --> 00:11:53.110
1.

161
00:11:53.300 --> 00:11:57.250
So let's do it let's press 1 here to get some info about this.

162
00:11:57.260 --> 00:11:58.580
Our beta function.

163
00:11:58.820 --> 00:12:01.370
So we will need only three of these arguments here.

164
00:12:01.370 --> 00:12:07.340
The first argument we need is an the number of observations so here and equals one because we only want

165
00:12:07.340 --> 00:12:13.430
to take one random draw and then shape one and shape two other two parameters of our beta distribution

166
00:12:13.580 --> 00:12:19.700
that is shape one is the number of times the Akhet we were one plus one and two is the number of times

167
00:12:19.700 --> 00:12:21.660
the odds that we were zero plus 1.

168
00:12:21.770 --> 00:12:28.650
So here for shape one we input shape one equals numbers of rewards one.

169
00:12:28.730 --> 00:12:35.050
And of course since this corresponds to a specific ad I will add some brackets here and take the adversion.

170
00:12:35.050 --> 00:12:39.950
I this we're dealing with at this specific time in this four island here that it's discrete parts to

171
00:12:39.950 --> 00:12:41.180
a specific add.

172
00:12:41.390 --> 00:12:46.810
And let's not forget the plus one here and then come out to put the second parameter.

173
00:12:46.820 --> 00:12:53.590
And of course the second parameter is going to be the IFE index of these numbers if we want zero vector.

174
00:12:53.810 --> 00:13:01.520
And then let's not forget the plus 1 here and that are two parameters of this beta distribution from

175
00:13:01.520 --> 00:13:03.470
which we are getting the random draws.

176
00:13:03.880 --> 00:13:06.200
OK so we have everything we need.

177
00:13:06.230 --> 00:13:12.140
And now of course we will need to play with this if condition here to get the maximum of these random

178
00:13:12.140 --> 00:13:12.760
draws.

179
00:13:12.920 --> 00:13:18.970
So a good exercise for you would be to pass on this video and try to finish this code section here to

180
00:13:18.980 --> 00:13:21.480
guess the last elements of this code here.

181
00:13:21.590 --> 00:13:23.370
So I'm going to tell you right now.

182
00:13:23.600 --> 00:13:26.730
Well right now we need to take the maximum of these random draws.

183
00:13:26.810 --> 00:13:33.220
We already declared this Max random viable here that will be this maximum of these random draws and

184
00:13:33.230 --> 00:13:34.880
so well you guessed it.

185
00:13:34.880 --> 00:13:42.980
Now we need to replace this Max up about here by Max random and here of course we need to replace this

186
00:13:43.130 --> 00:13:46.480
upper bound here by random data.

187
00:13:46.610 --> 00:13:47.240
OK.

188
00:13:47.390 --> 00:13:55.550
And then same here we replaced Max up prevailing here by Max random and average down here by random

189
00:13:56.330 --> 00:13:57.040
data.

190
00:13:57.530 --> 00:14:00.970
And eventually of course we keep this as equals here.

191
00:14:01.190 --> 00:14:01.460
OK.

192
00:14:01.490 --> 00:14:04.000
So let's re-explained quickly what's happening here.

193
00:14:04.070 --> 00:14:06.530
For each AM I IN THIS FOR loop here.

194
00:14:06.740 --> 00:14:10.880
Well we're taking a random draw from this failed distribution of parameters.

195
00:14:10.910 --> 00:14:16.340
Number of times the Akhet we want one plus one and number of times the ad because we were 0 plus 1 and

196
00:14:16.340 --> 00:14:19.690
then each time we take a random draw from this distribution.

197
00:14:19.820 --> 00:14:24.770
Well we checked to see if this random draw is higher than this Max random here.

198
00:14:24.770 --> 00:14:30.190
So of course for the first and this will be the case because Max random was initialized to zero.

199
00:14:30.290 --> 00:14:35.450
So this condition will be true for the first ad and therefore Max random will be equal to this first

200
00:14:35.630 --> 00:14:36.800
random draw here.

201
00:14:36.980 --> 00:14:38.710
And so we keep this for us at here.

202
00:14:38.870 --> 00:14:44.000
And then when we move on to the next and what happens is that we take another random draw from this

203
00:14:44.210 --> 00:14:48.850
beta distribution of these parameters here that corresponds to this you and I.

204
00:14:49.010 --> 00:14:54.140
And then if this new random draw is higher than this maximum here that was equal to the previous random

205
00:14:54.140 --> 00:14:54.640
draw.

206
00:14:54.770 --> 00:15:00.020
Well that means that this condition is true and therefore Max random takes the value of this new random

207
00:15:00.020 --> 00:15:03.230
draw and therefore we select this new adversion.

208
00:15:03.260 --> 00:15:08.150
I hear that has the highest random draw and we forget about the previous ad that was selected because

209
00:15:08.150 --> 00:15:10.300
simply it has a lower random draw.

210
00:15:10.310 --> 00:15:15.560
All right so that's the idea and that's the strategy of Tomsen sampling that we are implementing at

211
00:15:15.620 --> 00:15:17.060
each round.

212
00:15:17.060 --> 00:15:17.870
Great.

213
00:15:17.870 --> 00:15:19.860
So now we almost have everything we need.

214
00:15:19.910 --> 00:15:26.690
The thing that we need to update now is what's happening here because this comes from the upper confidence

215
00:15:26.690 --> 00:15:27.880
bound algorithm.

216
00:15:27.890 --> 00:15:32.540
So this is you know the parameter of step 1 in the UCB algorithm.

217
00:15:32.540 --> 00:15:34.670
So we will need to remove this line.

218
00:15:34.670 --> 00:15:39.900
We don't need this and we have to keep this because this is to get the real reward.

219
00:15:40.070 --> 00:15:45.280
As we explained the UCB algorithm know this is actually how we proceed to get the reward.

220
00:15:45.320 --> 00:15:51.250
In this simulation data sets and then what do we have we have this line containing the sums of words.

221
00:15:51.290 --> 00:15:56.990
And of course the sums of rewards is a parameter of the UCAP algorithm so we need to remove that as

222
00:15:56.990 --> 00:15:58.060
well.

223
00:15:58.160 --> 00:16:03.820
And now we are ready to update what we need to update for the Thompson something algorithm.

224
00:16:03.830 --> 00:16:08.090
All right and then we have the total we weren't there of course who must keep because this is the exciting

225
00:16:08.090 --> 00:16:08.830
result.

226
00:16:09.020 --> 00:16:12.010
And this is kind of a performance evaluator.

227
00:16:12.050 --> 00:16:14.450
So now according to you what do we need to update.

228
00:16:14.600 --> 00:16:18.310
Well of course what we need to date are these two vectors here.

229
00:16:18.320 --> 00:16:21.250
Numbers of words 1 and numbers if we want zero.

230
00:16:21.350 --> 00:16:26.720
Because you know in this strategy here we are importing the index of these two vectors.

231
00:16:26.930 --> 00:16:31.570
But you know we need to update them on the trend because otherwise they will always be equal to zero

232
00:16:31.820 --> 00:16:33.990
because they were initialized 0.

233
00:16:34.250 --> 00:16:35.570
So now what do we need to do.

234
00:16:35.570 --> 00:16:39.870
We need to increment their values when we get the reward.

235
00:16:40.040 --> 00:16:43.370
So let's see what we need to increment for this variable.

236
00:16:43.370 --> 00:16:44.980
Here are the numbers if we want one.

237
00:16:45.080 --> 00:16:48.370
Well this corresponds to the different numbers of times each add got.

238
00:16:48.380 --> 00:16:49.700
We won one round.

239
00:16:49.700 --> 00:16:53.890
And so we need to increment it only when the ADD got we wanted one.

240
00:16:53.900 --> 00:16:55.160
And what about this vector.

241
00:16:55.280 --> 00:16:56.160
Well that's the same.

242
00:16:56.170 --> 00:17:01.480
That's the vector containing the different numbers of times each add got we were 0 At around and and

243
00:17:01.490 --> 00:17:07.080
so we need to increment this vector only when the adults we selected got we were 0.

244
00:17:07.310 --> 00:17:13.500
So since this depends on the reward we get when we select the add we will need an if condition.

245
00:17:13.700 --> 00:17:20.750
And so we're going to write this if condition here if and so the condition is simply if we Ward equals

246
00:17:20.750 --> 00:17:22.210
equals 1.

247
00:17:22.460 --> 00:17:29.540
So if this reward we get at this specific round when we select a specific add here if this reward is

248
00:17:29.540 --> 00:17:34.070
1 then what do we need to do we need to increment this number of words.

249
00:17:34.080 --> 00:17:41.300
1 but only for the index because this index here corresponds to the index of the ad that was selected.

250
00:17:41.330 --> 00:17:49.130
So let's do it let's increment this numbers of rewards one let's copy that and let's face it here and

251
00:17:49.130 --> 00:17:56.270
now let's take the ad index corresponding to the index of the ad that was selected and then that's where

252
00:17:56.270 --> 00:17:57.460
we need to increment it.

253
00:17:57.560 --> 00:18:04.610
So I'm going to copy this and paste it here and add a plus one.

254
00:18:04.610 --> 00:18:05.090
All right.

255
00:18:05.150 --> 00:18:10.400
So when we word this one well of course what we need to do is to add a plus one to the number of times

256
00:18:10.400 --> 00:18:13.180
this add here got the word one.

257
00:18:13.200 --> 00:18:13.550
All right.

258
00:18:13.550 --> 00:18:20.840
And then we have this else and this else corresponds to the situation where we word here is equal to

259
00:18:20.840 --> 00:18:21.520
zero.

260
00:18:21.560 --> 00:18:26.010
That is when he added we selected go to zero the word specific around and.

261
00:18:26.240 --> 00:18:31.820
And therefore when that happens we need to increment the numbers of the words zero this time.

262
00:18:31.820 --> 00:18:41.710
So I'm copying this line and facing it right here and then replace the next I buy add because we need

263
00:18:41.710 --> 00:18:48.890
to increment the numbers of words zero but only for the value corresponding to this add index here.

264
00:18:48.900 --> 00:18:49.330
All right.

265
00:18:49.360 --> 00:18:50.530
Now we're done.

266
00:18:50.530 --> 00:18:53.430
Thompson something is actually fully implemented.

267
00:18:53.840 --> 00:18:57.760
So now time for the exciting step visualizing the results.

268
00:18:57.910 --> 00:19:01.720
So we'll do that in the next tutorial and until then enjoy machine learning.
