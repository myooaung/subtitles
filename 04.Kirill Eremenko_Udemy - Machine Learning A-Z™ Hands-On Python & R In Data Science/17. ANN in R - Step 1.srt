1
00:00:00,270 --> 00:00:04,770
Hello and welcome to this art Tauriel I'm super excited to be in the deep learning part.

2
00:00:04,770 --> 00:00:09,750
This is one of the most fascinating and exciting brand of machine learning and besides it's one of the

3
00:00:09,750 --> 00:00:14,880
most powerful and the following tutorials who are going to solve the business problem described by curial

4
00:00:14,940 --> 00:00:19,980
at the beginning of this section and you will see that we're going to get strong results thanks to this

5
00:00:20,040 --> 00:00:23,890
artificial neural network that we are about to build with our.

6
00:00:24,030 --> 00:00:28,590
So as usual we are going to make this artificial neural network model very efficiently and we're going

7
00:00:28,590 --> 00:00:33,600
to use the best package for that which I will let you find out about in the next two titles.

8
00:00:33,900 --> 00:00:34,950
So let's start.

9
00:00:34,950 --> 00:00:41,400
And the first step of our journey is the boring step data processing but we will do it very efficiently

10
00:00:41,610 --> 00:00:45,860
because we have our template our classification template that I've prepared here.

11
00:00:45,930 --> 00:00:48,600
And why can we use this classification template.

12
00:00:48,600 --> 00:00:53,760
Well it's by nature of the business problem you saw in the business problem description that you have

13
00:00:53,940 --> 00:00:59,130
some independent variables and with these independent variables you have to predict a dependent variable

14
00:00:59,130 --> 00:01:00,990
that has a binary outcome.

15
00:01:00,990 --> 00:01:06,190
And since the outcome of the dependent variable is binary that means it's a categorical variable.

16
00:01:06,240 --> 00:01:12,420
That means we have to predict classes 0 and 1 and therefore that makes our problem a classification

17
00:01:12,420 --> 00:01:13,170
problem.

18
00:01:13,170 --> 00:01:18,300
And so OK we're going to build a deep learning model but this deep learning model is going to be nothing

19
00:01:18,300 --> 00:01:20,280
else than a classification model.

20
00:01:20,460 --> 00:01:25,590
And that's why we are going to use our classification some places we have here and that will save us

21
00:01:25,590 --> 00:01:28,870
a lot of time to build our typical neural network.

22
00:01:28,950 --> 00:01:32,550
And besides we want to focus on the deep learning model itself.

23
00:01:32,610 --> 00:01:36,630
So we will get there very quickly thanks to this template.

24
00:01:36,630 --> 00:01:44,010
All right so let's take everything from this template from the top down to here because we cannot use

25
00:01:44,010 --> 00:01:48,960
this section here because you know this is the section to visualize the trainings that results and the

26
00:01:48,960 --> 00:01:50,360
test results as well.

27
00:01:50,460 --> 00:01:56,100
But only when we have two independent variables because one independent variable corresponds to one

28
00:01:56,100 --> 00:01:57,060
dimension.

29
00:01:57,060 --> 00:01:57,540
And since.

30
00:01:57,540 --> 00:02:02,440
Now in the data set of the business problem we have I think 10 or 11 independent variables.

31
00:02:02,580 --> 00:02:06,510
Well then it's a little bit hard to represent something in 11 dimensions.

32
00:02:06,690 --> 00:02:11,520
So we won't take this but we will definitely take everything that's above.

33
00:02:11,520 --> 00:02:12,980
So I'm going to copy that.

34
00:02:13,140 --> 00:02:20,050
And let's go back to our aid and moral and paste this classification template right here.

35
00:02:20,370 --> 00:02:21,030
All right.

36
00:02:21,120 --> 00:02:24,130
And now in this template we're going to change a very few things.

37
00:02:24,240 --> 00:02:30,360
And of course we are going to build our artificial neural network right here in this section create

38
00:02:30,630 --> 00:02:31,890
your classify here.

39
00:02:32,010 --> 00:02:37,160
We can already replace class 5 here by and then to then build them model.

40
00:02:37,170 --> 00:02:37,800
All right.

41
00:02:38,010 --> 00:02:42,590
But of course we need to make sure everything is OK and all the data pre-processing step.

42
00:02:42,810 --> 00:02:45,210
And that's what we're going to do right now.

43
00:02:45,210 --> 00:02:47,870
All right so let's start let's start with the basic step.

44
00:02:47,940 --> 00:02:50,340
Setting the right there as a working directory.

45
00:02:50,340 --> 00:02:53,780
So right now I'm on my desktop and going into my machine in a folder.

46
00:02:53,790 --> 00:02:59,280
Then we are in port eight deep learning and now Section 40 artificial neural networks.

47
00:02:59,280 --> 00:03:00,060
Here we go.

48
00:03:00,150 --> 00:03:02,940
Make sure that you have the turn modeling Dotsie as you file.

49
00:03:03,010 --> 00:03:07,850
And if that's the case you can click on this more about near and then set as working directory.

50
00:03:08,180 --> 00:03:08,580
Great.

51
00:03:08,610 --> 00:03:10,610
And now let's change a few things.

52
00:03:10,620 --> 00:03:14,100
So first of all let's start with this section importing the dataset.

53
00:03:14,310 --> 00:03:17,140
Well the name of the data set is not social network adds.

54
00:03:17,220 --> 00:03:21,630
It's now churn modeling.

55
00:03:21,630 --> 00:03:22,440
All right.

56
00:03:22,440 --> 00:03:24,480
We are now ready to import the data set.

57
00:03:24,510 --> 00:03:25,710
So let's do it right now.

58
00:03:25,710 --> 00:03:30,380
I'm going to select this line and executes all right dataset one important.

59
00:03:30,570 --> 00:03:36,940
Well we have actually 14 variables but let's see if we include all these variables in the real data

60
00:03:36,940 --> 00:03:37,550
set.

61
00:03:37,650 --> 00:03:40,840
You know the one on which we want to build our differently model.

62
00:03:40,890 --> 00:03:47,400
So let's see I'm going to click on this dataset here to see which independent variables we include in

63
00:03:47,400 --> 00:03:48,240
the mall.

64
00:03:48,600 --> 00:03:54,810
All right so just a quick reminder this dataset contains 10000 observations containing some informations

65
00:03:54,870 --> 00:04:01,560
of customers in a bank like the surname the credit score geography gender age and all the other information

66
00:04:01,590 --> 00:04:02,130
here.

67
00:04:02,310 --> 00:04:06,120
And during six months the bank looked for each customer.

68
00:04:06,120 --> 00:04:11,970
If the customer stayed or left the bank within the six month period and this result whether the customer

69
00:04:11,970 --> 00:04:13,630
stayed or left is given.

70
00:04:13,630 --> 00:04:15,700
In this last column here exited.

71
00:04:15,840 --> 00:04:21,630
So one means that the customer left the bank during the six months and 0 means that the customer stayed

72
00:04:21,630 --> 00:04:23,340
in the bank during the six months.

73
00:04:23,700 --> 00:04:29,880
So what's important to understand now is that all these variables here from row number to estimated

74
00:04:29,880 --> 00:04:32,260
salary are the independent variables.

75
00:04:32,400 --> 00:04:35,980
And the last column here exited is the dependent variable.

76
00:04:36,000 --> 00:04:43,080
So right now our goal is to make MRO where we can predict this result exited here whether the customer

77
00:04:43,080 --> 00:04:44,930
left or stayed in the bank.

78
00:04:45,060 --> 00:04:51,540
From the information contained in all these independent variables here but the thing is that in these

79
00:04:51,540 --> 00:04:57,120
independent variables some definitely don't have an impact on this dip in or it will exit it.

80
00:04:57,180 --> 00:05:04,140
And so now what we have to do is only take the independent variables that could have an impact and correlations

81
00:05:04,350 --> 00:05:08,170
with the decision of the customer to leave or stay in the bank.

82
00:05:08,340 --> 00:05:09,620
And so that's what we're going to do right now.

83
00:05:09,630 --> 00:05:15,660
So let's look at each of these in the bin and Vogels one by one and let's see which one we keep in our

84
00:05:15,660 --> 00:05:16,620
model.

85
00:05:16,650 --> 00:05:16,950
All right.

86
00:05:16,950 --> 00:05:18,220
So let's start with the first one.

87
00:05:18,330 --> 00:05:19,170
Row number.

88
00:05:19,350 --> 00:05:23,170
Well row number has definitely no impact on the dependable exit.

89
00:05:23,310 --> 00:05:26,810
So of course we will not include it then Customer ID.

90
00:05:26,950 --> 00:05:28,470
Well Customer ID does the same.

91
00:05:28,470 --> 00:05:30,710
That's just an identification number.

92
00:05:30,720 --> 00:05:35,790
This definitely doesn't have any impact on the decision of the customer to stay or leave in the bank.

93
00:05:35,790 --> 00:05:38,040
So we will not include that either.

94
00:05:38,040 --> 00:05:38,970
Then the surname.

95
00:05:39,090 --> 00:05:43,740
Well that's the same system because your name is Andrewes that you have more chance to leave the bank

96
00:05:43,980 --> 00:05:46,820
than if your name is Romeo.

97
00:05:46,830 --> 00:05:47,310
All right.

98
00:05:47,550 --> 00:05:53,790
So we don't include her name either but then we have credit score and credit score might have an impact

99
00:05:53,880 --> 00:05:56,740
on the decision of the customer to stay or leave in the bank.

100
00:05:56,760 --> 00:06:02,250
Indeed we can assume that customers with a low credit score are more likely to leave the bank than customers

101
00:06:02,250 --> 00:06:03,570
with a high credit score.

102
00:06:03,690 --> 00:06:07,500
So definitely we're willing to credit score in our model.

103
00:06:07,500 --> 00:06:09,310
All right then we have geography.

104
00:06:09,450 --> 00:06:14,550
Well maybe some customers are more likely to leave the bank in one specific country and that can be

105
00:06:14,550 --> 00:06:18,620
due to external factors like the economy of the country or any other factors.

106
00:06:18,630 --> 00:06:23,880
But yes definitely there might be some girlishness between the countries and the decision to stay or

107
00:06:23,880 --> 00:06:24,840
leave the bank.

108
00:06:24,990 --> 00:06:27,750
So we're willing to do that as well than gender.

109
00:06:27,930 --> 00:06:33,380
Well that's the same maybe men or women are more likely to stay in the bank than the other.

110
00:06:33,450 --> 00:06:35,720
So we need to check it out then age.

111
00:06:35,760 --> 00:06:38,830
Well that's the same and that's even quite intuitive.

112
00:06:39,000 --> 00:06:44,580
We might expect that younger people are more likely to leave the bank than older people because all

113
00:06:44,580 --> 00:06:49,720
the people who have more balance and have more stability when to age as well and tenure.

114
00:06:49,770 --> 00:06:52,910
So tenure as for how long the customer has been in the bank.

115
00:06:53,070 --> 00:06:57,540
And so that's the same we might expect that customers that have been in the bank for a long time are

116
00:06:57,540 --> 00:07:00,580
more likely to stay in the bank than recent customers.

117
00:07:00,750 --> 00:07:07,740
So yes we'll take that then balance well balance of course we might expect that this customer with this

118
00:07:07,830 --> 00:07:14,670
high balance has a lot more chance to stay in the bank than this customer with a zero balance.

119
00:07:14,670 --> 00:07:14,990
All right.

120
00:07:14,990 --> 00:07:19,500
And the number of products so that's the number of banking products the customers have in the bank.

121
00:07:19,560 --> 00:07:24,720
And so of course maybe that the customers with many products in the bank are more likely to stay than

122
00:07:24,990 --> 00:07:27,690
customers with for example one product in the bank.

123
00:07:27,690 --> 00:07:28,820
So we wanted to check it out.

124
00:07:28,950 --> 00:07:33,670
That's just assumptions that's the model that we'll find out about these correlations more thoroughly.

125
00:07:33,700 --> 00:07:40,200
But you know definitely from our intuition we need to include number of products as well then has credit

126
00:07:40,200 --> 00:07:40,670
card.

127
00:07:40,710 --> 00:07:45,810
Well that's a little bit of the same as this variable customers that have a credit card might be more

128
00:07:45,810 --> 00:07:49,100
likely to stay in the bank than customers that don't have a credit card.

129
00:07:49,230 --> 00:07:51,190
So yes is active member.

130
00:07:51,210 --> 00:07:56,190
That's the same if a customer is active then this customer is more likely to stay in the bank than a

131
00:07:56,190 --> 00:07:57,810
customer that is not active.

132
00:07:57,810 --> 00:08:02,440
So yes that might be a significant and viable than estimated salary.

133
00:08:02,580 --> 00:08:08,160
Well that's the salary of the customer estimated by the bank and it would make sense that customers

134
00:08:08,160 --> 00:08:14,280
with a high estimated salary have more chance to leave the bank and customers with a low estimated salary.

135
00:08:14,280 --> 00:08:14,630
All right.

136
00:08:14,630 --> 00:08:18,010
So that was the last independent viable of this data set.

137
00:08:18,150 --> 00:08:22,140
So now we know which independent variables we include in our data set.

138
00:08:22,380 --> 00:08:27,840
And that's what we're going to specify right now by updating our data set taking only the indexes of

139
00:08:27,840 --> 00:08:30,680
the independent variables we want to include in the model.

140
00:08:30,690 --> 00:08:32,760
So let's see what these indexes are.

141
00:08:33,030 --> 00:08:35,270
OK so indexes are start at 1.

142
00:08:35,430 --> 00:08:41,790
And so basically we're taking all the independent variables from credit score up to estimated salary.

143
00:08:41,820 --> 00:08:42,780
So let's see.

144
00:08:42,780 --> 00:08:46,040
Index one index to index 3 index 4.

145
00:08:46,050 --> 00:08:54,300
So we are taking the indexes 4 5 6 7 8 9 10 11 12 and 13.

146
00:08:54,300 --> 00:08:54,650
All right.

147
00:08:54,660 --> 00:09:01,860
So we are taking the indexes from 4 to 14 because you know in our it's not like in Python when we separate

148
00:09:01,950 --> 00:09:07,950
a matrix of features and the inevitable vector we includes all the variables in one frame.

149
00:09:08,010 --> 00:09:10,050
And so we include the dependent variable.

150
00:09:10,080 --> 00:09:10,410
Great.

151
00:09:10,410 --> 00:09:12,500
So let's input these indexes.

152
00:09:12,690 --> 00:09:16,540
So we just said that we want to take the indexes from 4.

153
00:09:16,680 --> 00:09:23,290
So that's the index of the first independent viable up to the index 14 which is the index of the dependent

154
00:09:23,330 --> 00:09:25,380
variable and that's great.

155
00:09:25,380 --> 00:09:30,360
Now we can update our data set by selecting this line and execute.

156
00:09:30,600 --> 00:09:31,130
Great.

157
00:09:31,140 --> 00:09:37,890
And now as you can see if I will go back to the dataset here we have all are potentially statistically

158
00:09:37,890 --> 00:09:44,160
significant independent variables that might have an impact on the dependent Voivode exited.

159
00:09:44,310 --> 00:09:48,440
And so now the first step of data processing is completed.

160
00:09:48,630 --> 00:09:53,830
We imported correctly the data set by choosing all the relevant independent variables.

161
00:09:54,210 --> 00:09:54,480
Okay.

162
00:09:54,480 --> 00:10:00,450
Now let's move on to the second step the second step is and coding the target feature as vector Well

163
00:10:00,480 --> 00:10:05,340
we don't really need to do that because the dependent variable of our data set is a categorical variable

164
00:10:05,340 --> 00:10:08,050
with a binary outcome one or zero.

165
00:10:08,220 --> 00:10:13,590
And the thing to understand is that the package we are going to use is going to recognize it as a categorical

166
00:10:13,590 --> 00:10:15,380
variable with a binary outcome.

167
00:10:15,450 --> 00:10:22,830
So we actually don't need to encode this target feature exited as Efexor so I'm going to remove this

168
00:10:22,830 --> 00:10:23,040
line.

169
00:10:23,040 --> 00:10:24,000
We don't need it.

170
00:10:24,000 --> 00:10:28,300
However we do need to do something regarding some categorical variables.

171
00:10:28,320 --> 00:10:34,560
Of course I'm talking about the two categorical independent variables we have in our dataset and these

172
00:10:34,560 --> 00:10:38,610
two variables are of course geography and gender.

173
00:10:38,610 --> 00:10:40,140
So we have two problems here.

174
00:10:40,320 --> 00:10:42,720
So we need to do two things here for these variables.

175
00:10:42,720 --> 00:10:48,600
The first thing we need to do is to convert them as factors and then we wanted to do something more

176
00:10:48,810 --> 00:10:54,620
than we used to do when encoding our categorical variables to set them as numeric.

177
00:10:54,780 --> 00:10:57,600
And to do this we'll use the as the numeric function.

178
00:10:57,600 --> 00:11:00,030
And why do we need to do this especially here.

179
00:11:00,150 --> 00:11:04,330
Well that is just because the deep learning package that we're going to use is requiring it.

180
00:11:04,410 --> 00:11:10,690
And that's the only reason it expects factors but set as numeric numeric factors.

181
00:11:10,830 --> 00:11:11,920
So let's do this.

182
00:11:11,970 --> 00:11:18,090
I'm going back to my end in model and so first we're going to change this to say that we're encoding

183
00:11:18,420 --> 00:11:23,430
the categorical foibles as factors.

184
00:11:23,700 --> 00:11:24,180
All right.

185
00:11:24,220 --> 00:11:29,700
And now we're going to take this categorical data file that we made in part one day to pre-processing

186
00:11:30,150 --> 00:11:35,100
because you know there is the code ready to encode any categorical data.

187
00:11:35,280 --> 00:11:43,110
So I'm going to select all this and paste it here in this second step of data pre-processing to encode

188
00:11:43,110 --> 00:11:45,830
the categorical variables as factors.

189
00:11:45,840 --> 00:11:47,190
All right so let's do this.

190
00:11:47,190 --> 00:11:53,520
We just need to replace the names of the variables and then add this as the numeric function to set

191
00:11:53,520 --> 00:11:55,140
the factors as numeric.

192
00:11:55,140 --> 00:11:57,540
So let's start by replacing all the names here.

193
00:11:57,780 --> 00:12:02,100
Well the first categorical variable gives to countries but it is not called country.

194
00:12:02,100 --> 00:12:04,140
It is called geography.

195
00:12:04,320 --> 00:12:09,180
So we will replace here country by geography.

196
00:12:09,360 --> 00:12:10,390
Same here.

197
00:12:13,050 --> 00:12:17,960
And the good news is that now we don't need to change the names of the categories here.

198
00:12:17,960 --> 00:12:21,460
France Spain and Germany because that's the same names.

199
00:12:21,540 --> 00:12:22,980
So that's great.

200
00:12:22,980 --> 00:12:24,390
And we will keep the labels.

201
00:12:24,420 --> 00:12:25,310
One two three.

202
00:12:25,560 --> 00:12:26,450
All right that's good.

203
00:12:26,520 --> 00:12:34,970
And now we add this as that numeric function to set the factors as numeric.

204
00:12:34,990 --> 00:12:41,250
So I'm putting all these facts to function here inside the parenthesis of the as numeric function.

205
00:12:41,250 --> 00:12:44,090
And now I just need to align everything well.

206
00:12:44,160 --> 00:12:45,010
Here we go.

207
00:12:45,240 --> 00:12:47,320
And same for here.

208
00:12:48,270 --> 00:12:49,530
All right great.

209
00:12:49,670 --> 00:12:52,740
And now let's do the same for the second category go viral.

210
00:12:52,770 --> 00:12:56,260
So we need to replace purchase here by gender.

211
00:12:56,660 --> 00:12:57,710
So let's do it.

212
00:12:57,840 --> 00:13:01,530
Purchased replaced by gender.

213
00:13:01,530 --> 00:13:02,280
All right.

214
00:13:02,280 --> 00:13:03,940
Same here.

215
00:13:03,940 --> 00:13:07,050
Gender and now we replace the two categories.

216
00:13:07,050 --> 00:13:12,050
No and yes by female and male.

217
00:13:12,420 --> 00:13:14,670
And here we can give the labels we want.

218
00:13:14,670 --> 00:13:20,100
So let's for example take labels one for female and two female.

219
00:13:20,100 --> 00:13:20,660
All right.

220
00:13:20,760 --> 00:13:28,440
And let's not forget to add the as that numeric function which I remind we just do for the future deep

221
00:13:28,440 --> 00:13:30,300
learning package that we're going to use.

222
00:13:30,300 --> 00:13:35,710
So parenthesis here parenthesis here and now that's the line everything.

223
00:13:35,730 --> 00:13:37,070
Here we go.

224
00:13:37,080 --> 00:13:37,770
All right.

225
00:13:37,920 --> 00:13:38,900
Great.

226
00:13:38,940 --> 00:13:45,480
So now everything is ready this section is ready that encodes as required by the deeper and package

227
00:13:45,700 --> 00:13:48,360
are categorical independent variables.

228
00:13:48,360 --> 00:13:54,290
All right so I'm going to select the section here and let's execute.

229
00:13:54,300 --> 00:13:56,070
All right executed properly.

230
00:13:56,070 --> 00:13:59,940
Now let's have a look at the data set to see what the variables became.

231
00:13:59,940 --> 00:14:00,570
Perfect.

232
00:14:00,570 --> 00:14:08,640
Geography was encoded into one two and three categories that are numeric categories and the gender one

233
00:14:08,640 --> 00:14:11,320
for female and two female greats.

234
00:14:11,340 --> 00:14:14,790
And again as numeric factors perfect.

235
00:14:14,840 --> 00:14:17,030
So this section is now completed.

236
00:14:17,150 --> 00:14:19,280
And let's move on to the next one.

237
00:14:19,340 --> 00:14:21,960
We can see how we're getting very efficient at this.

238
00:14:22,000 --> 00:14:27,050
The next one is about splitting the data sets into the training set and a test that we need to do that

239
00:14:27,050 --> 00:14:33,170
because we will train our artificial neural network on the training set and we will test its performance

240
00:14:33,260 --> 00:14:34,330
on the test set.

241
00:14:34,370 --> 00:14:35,360
So we'll do that.

242
00:14:35,360 --> 00:14:37,220
But let's not execute too fast.

243
00:14:37,220 --> 00:14:45,120
We need to replace purchased here by the name of the dependent variable which is exited and maybe we

244
00:14:45,120 --> 00:14:51,450
can change the aspect ratio as well you know put 80 percent for the training set so that we have 8000

245
00:14:51,510 --> 00:14:59,070
observations to train artificial neural network and 2000 observations to test its performance on new

246
00:14:59,070 --> 00:15:00,030
observations.

247
00:15:00,030 --> 00:15:02,470
That is the new observations of the test.

248
00:15:02,490 --> 00:15:03,610
So now that's ready.

249
00:15:03,630 --> 00:15:05,340
We don't have to do anything more here.

250
00:15:05,340 --> 00:15:09,620
The most important thing is not to forget to replace purchased by exited.

251
00:15:09,660 --> 00:15:14,510
And so now I'm going to select all the section and exit routes.

252
00:15:14,730 --> 00:15:15,540
Perfect.

253
00:15:15,540 --> 00:15:21,460
Now we have our training set and our tests at Great.

254
00:15:21,510 --> 00:15:27,720
So that is the whole dataset that is our training set with 8000 observations and that is our test set

255
00:15:27,870 --> 00:15:30,810
with 2000 observations perfect.

256
00:15:30,810 --> 00:15:36,420
Now let's go back to our CNN and we are finally getting to the last step of data pre-processing and

257
00:15:36,420 --> 00:15:38,210
that is feature scaling.

258
00:15:38,220 --> 00:15:43,750
So now the question is do we need to apply future scaling to train an artificial neural network.

259
00:15:43,770 --> 00:15:46,740
And the answer is yes absolutely.

260
00:15:46,770 --> 00:15:49,130
That's 100 percent compulsory.

261
00:15:49,440 --> 00:15:54,110
And that is because training an artificial neural network is highly compute intensive.

262
00:15:54,270 --> 00:15:58,670
So there is going to be a lot of computer actions and besides parallel considerations.

263
00:15:58,710 --> 00:16:03,820
So definitely we need to like future Skilling and besides it is required by the package.

264
00:16:03,990 --> 00:16:05,440
So we will execute this.

265
00:16:05,460 --> 00:16:12,600
But before let's not forget to change the indexes these indexes three here where the index of the dependent

266
00:16:12,600 --> 00:16:14,950
variable in part one data preprocessing.

267
00:16:15,150 --> 00:16:21,620
So right now we just need to replace this index three here by our new index of the depende inviolable.

268
00:16:21,690 --> 00:16:25,740
And so where is this index that is the index of the exited column.

269
00:16:25,740 --> 00:16:27,520
Well we can see that directly here.

270
00:16:27,780 --> 00:16:30,550
This dataset has 11 variables.

271
00:16:30,660 --> 00:16:34,870
So that means that the exited column here has indexed 11.

272
00:16:35,010 --> 00:16:44,780
So let's replace three here by 11 then here as well 11 11 and 11.

273
00:16:44,840 --> 00:16:45,650
Great.

274
00:16:45,720 --> 00:16:47,800
And now the features getting section is ready.

275
00:16:47,970 --> 00:16:53,840
So let's select the whole section and executes great.

276
00:16:53,910 --> 00:16:56,950
And now if we have a look at our training set.

277
00:16:57,250 --> 00:16:58,990
Well well yes definitely.

278
00:16:59,070 --> 00:17:00,130
Everything is scaled.

279
00:17:00,240 --> 00:17:03,770
And our test set same everything is definitely scaled.

280
00:17:03,810 --> 00:17:10,560
We are happy we are ready to build our artificial neural network and that's what we're going to do in

281
00:17:10,560 --> 00:17:11,730
the next toile.

282
00:17:11,730 --> 00:17:13,590
So I'm super excited to start.

283
00:17:13,590 --> 00:17:16,850
I look forward to seeing you there and until then enjoy machine learning
