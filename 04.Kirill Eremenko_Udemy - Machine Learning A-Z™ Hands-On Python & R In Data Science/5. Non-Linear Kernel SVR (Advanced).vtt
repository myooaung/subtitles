WEBVTT
1
00:00:00.300 --> 00:00:03.890
Hello and welcome back to your machine learning A to Z course.

2
00:00:03.960 --> 00:00:09.510
Are you super excited because I am super excited about this tutorial we're talking about non-linear

3
00:00:09.540 --> 00:00:11.160
Support Vector regression.

4
00:00:11.220 --> 00:00:13.860
This is going to be quite an advanced tutorial.

5
00:00:13.860 --> 00:00:20.240
But don't worry we will break it down and as per our mission will make the complex simple.

6
00:00:20.280 --> 00:00:23.270
So before we start I just wanted to make sure we're on the same page.

7
00:00:23.280 --> 00:00:28.640
So this is one of the most advanced materials in the Support Vector series of tutorials.

8
00:00:28.650 --> 00:00:35.730
Please make sure that you've completed all the previous tutorials on SVR and SVM and kernels before

9
00:00:35.730 --> 00:00:40.250
proceeding with this material because you'll need all that knowledge to be able to tackle this one.

10
00:00:40.290 --> 00:00:40.730
All right.

11
00:00:40.740 --> 00:00:41.700
And off we go.

12
00:00:41.700 --> 00:00:43.710
Here it is.

13
00:00:43.710 --> 00:00:46.890
So imagine you have a data set like this.

14
00:00:47.310 --> 00:00:54.180
And you're trying to fit a support support vector regression onto this point you want to see what kind

15
00:00:54.180 --> 00:01:00.330
of trend line is there or what kind of equation is behind this.

16
00:01:00.330 --> 00:01:05.430
How do you model is what kind of model can we fit to this support vector regression model so that you

17
00:01:05.430 --> 00:01:11.040
can predict what the next value is going to be for a new point that is added to the plots if you know

18
00:01:11.040 --> 00:01:12.450
X or what is going to be Y.

19
00:01:12.450 --> 00:01:18.120
Well you might want to try and fit as linear Support Vector regression and look something like this.

20
00:01:18.120 --> 00:01:23.820
You'll have these support vectors but as you can see like intuitively you can tell it doesn't fit right

21
00:01:23.830 --> 00:01:27.030
like you can tell that something is going on here beyond linear.

22
00:01:27.030 --> 00:01:34.320
And like while this it might model may be OK there somewhere at some point clearly if you get a point

23
00:01:34.320 --> 00:01:39.780
of X over here you're going to get the incorrect value or if X is over here you're going to get an incorrect

24
00:01:39.780 --> 00:01:41.490
value does doesn't fit.

25
00:01:41.490 --> 00:01:43.510
Looks like something else is going on.

26
00:01:43.560 --> 00:01:47.030
You might try something like that then that won't fit as well.

27
00:01:47.310 --> 00:01:48.050
That doesn't fit.

28
00:01:48.080 --> 00:01:54.300
So it doesn't look like a linear model fits here and it looks like something more complex is going on.

29
00:01:54.330 --> 00:02:00.900
So how do we build a support vector regression that will fit our data here.

30
00:02:01.650 --> 00:02:04.270
Well this is where nonlinear SPRO comes in.

31
00:02:04.290 --> 00:02:10.470
It's gonna be quite interesting because we need to go to a new dimension and that's what that's why

32
00:02:10.470 --> 00:02:14.880
we're going to add this box is just for visualization purposes like our data hasn't changed our axes

33
00:02:14.880 --> 00:02:20.160
are the same but just for us once we're transitioning to a third dimension to keep track of things we

34
00:02:20.160 --> 00:02:25.940
can add this box and we're going to add these diagonals as well as a point a red circle in the middle

35
00:02:25.950 --> 00:02:29.550
just so visually we can see what's going on.

36
00:02:29.550 --> 00:02:34.530
It'll help us is just like a visual aid has nothing to do with the algorithm itself it's for illustrative

37
00:02:34.530 --> 00:02:35.470
purposes.

38
00:02:35.490 --> 00:02:42.000
So now we're going to actually take this and look at it from a different perspective at an angle.

39
00:02:42.080 --> 00:02:43.950
So at an angle it looks like this.

40
00:02:45.010 --> 00:02:48.260
And that will allow us to build that dimensions Z.

41
00:02:48.390 --> 00:02:55.980
Now let's get rid of the previous view and we're going to make a copy of it because there's gonna be

42
00:02:55.980 --> 00:02:57.390
quite a lot of things going on.

43
00:02:57.420 --> 00:03:01.680
And in order to keep track of everything we'll have two charts are developing in parallel.

44
00:03:02.040 --> 00:03:07.530
So now on the right what we're going to do is just as we did previously with supposed to support vector

45
00:03:07.530 --> 00:03:10.440
machine and that's why it's important to have seen those tutorials.

46
00:03:10.620 --> 00:03:17.850
We're going to add a kernel and in this case we're going to add a new function to take us into a third

47
00:03:17.850 --> 00:03:22.230
dimension we're going to add a real basis function or the RPF.

48
00:03:22.290 --> 00:03:23.190
So here we go.

49
00:03:23.190 --> 00:03:24.960
That's what it looks like that's with the RPF.

50
00:03:24.960 --> 00:03:28.950
You can see our data vaguely underneath but here you can see it more clearly.

51
00:03:29.370 --> 00:03:35.700
And just as a reminder the formula for the RBA a function is over there.

52
00:03:35.700 --> 00:03:42.390
Now if we project our data into onto this RBA you'll see how it works.

53
00:03:42.390 --> 00:03:51.150
So first will the centre zero or this point 0 0 0 0 or X the y axis projects straight into the very

54
00:03:51.150 --> 00:03:51.630
top.

55
00:03:51.700 --> 00:03:57.960
Then if you we we discussed this before in the tutorials you put 0 0 0 l is the distance from the center

56
00:03:58.560 --> 00:04:02.840
you'll get the very top you'll get a one.

57
00:04:02.850 --> 00:04:08.100
Now let's see how these other points the other points in our observation will be projected onto the

58
00:04:08.100 --> 00:04:08.300
view.

59
00:04:08.310 --> 00:04:10.130
So we're going to start with this point over here.

60
00:04:10.290 --> 00:04:15.810
So that point where we projected into this point in the z axis somewhere here.

61
00:04:15.900 --> 00:04:21.840
By the way some of these things might not be absolutely horrible and accurate as I'm drawing them here

62
00:04:21.840 --> 00:04:25.620
but they deliver hopefully they deliver the point home.

63
00:04:26.050 --> 00:04:26.340
Okay.

64
00:04:26.460 --> 00:04:33.900
So now this point we projected to over here somewhere next point there in this point this point and

65
00:04:33.900 --> 00:04:36.180
then the following points A B almost a zero.

66
00:04:36.180 --> 00:04:41.460
So all this blue stuff over here the bottom is very very close as there is there will be a very close.

67
00:04:41.820 --> 00:04:44.940
So you can see we've been keeping track on on the left.

68
00:04:44.940 --> 00:04:47.140
We've done all of these points over here.

69
00:04:47.190 --> 00:04:53.190
Now the other points the remaining points these ones there actually we can't see them and not two in

70
00:04:53.190 --> 00:04:58.230
order not to clutter things anything in this quadrant in this triangle here we're not going to plotted

71
00:04:58.230 --> 00:05:05.470
because it's on the back it's on the opposite side of this radial base dysfunctional or this view.

72
00:05:05.730 --> 00:05:12.150
And we just got appointed but just we can just imagine that they are also projecting onto this mountain

73
00:05:12.240 --> 00:05:13.570
on the other side.

74
00:05:13.680 --> 00:05:14.940
Now what happens next.

75
00:05:14.970 --> 00:05:17.750
Well next we need to.

76
00:05:17.750 --> 00:05:25.020
In these three dimensions we need to create run a linear model.

77
00:05:25.020 --> 00:05:26.730
So now we're in three dimensions.

78
00:05:26.730 --> 00:05:32.340
Now we can run a linear model in a linear model in three dimensions is not a line so in two dimensions

79
00:05:32.370 --> 00:05:37.590
it's a straight line in a three them in three dimensions a linear model is a hyper plane.

80
00:05:37.680 --> 00:05:41.310
So now if we run a linear model you'll see that it will.

81
00:05:41.310 --> 00:05:45.720
How does it fit our data would fit our there is something like this.

82
00:05:46.080 --> 00:05:48.480
And what do we want from here.

83
00:05:48.480 --> 00:05:53.490
So once we fit the hyper plane to our data in these three dimensions what do we want from here.

84
00:05:53.550 --> 00:05:56.490
We want to see where does it actually cross.

85
00:05:56.490 --> 00:05:58.530
Where does it intersect.

86
00:05:58.590 --> 00:06:04.130
Our RB off our radial base function so bases all the surface area C here including the floor.

87
00:06:04.260 --> 00:06:08.040
This whole surface where does intersect will intersect over across this yellow line.

88
00:06:08.040 --> 00:06:11.280
So that's the point of intersect or the line of intersect.

89
00:06:11.280 --> 00:06:18.930
Now if we get rid of the plane we're left of this line and if we projected back down onto the two dimensions

90
00:06:18.930 --> 00:06:22.640
the x and y look watch what happens so we're not gonna draw it on this plot.

91
00:06:22.650 --> 00:06:23.520
We can draw on this plot.

92
00:06:23.520 --> 00:06:24.700
So watch what happens.

93
00:06:24.750 --> 00:06:25.140
There we go.

94
00:06:25.140 --> 00:06:26.680
That's our two dimensional line.

95
00:06:26.690 --> 00:06:26.950
So.

96
00:06:27.140 --> 00:06:31.000
So that's how our intersect line projected on the two dimensional plot.

97
00:06:31.140 --> 00:06:32.970
And that effectively is our model.

98
00:06:32.970 --> 00:06:38.700
So if we now look at it in the perspective that we started with you'll see that that is what it looks

99
00:06:38.700 --> 00:06:38.910
like.

100
00:06:38.910 --> 00:06:41.980
That's the nonlinear SVR.

101
00:06:42.030 --> 00:06:50.160
Now I know you probably have a few questions that's tried to dig into some of the comments or some of

102
00:06:50.160 --> 00:06:51.700
the concepts behind this.

103
00:06:51.710 --> 00:06:58.320
So first of all here we have this two dimensional plot here as our three dimensional three dimensions.

104
00:06:58.320 --> 00:07:00.990
So why is this SVR right.

105
00:07:00.990 --> 00:07:02.400
So where are the support vectors.

106
00:07:02.430 --> 00:07:08.430
Well you know three them in three dimensional space the SVR would run very similarly to high runs in

107
00:07:08.430 --> 00:07:14.760
a two dimensional space instead of having a sort of having like a Epsilon and says sort of tube we would

108
00:07:14.760 --> 00:07:18.230
have an absolute and sensitive space between hyper planes.

109
00:07:18.240 --> 00:07:21.090
So we did we would add these two new hyper planes.

110
00:07:21.090 --> 00:07:22.830
One would be absolute above.

111
00:07:22.980 --> 00:07:24.890
One would be Epsilon below.

112
00:07:24.900 --> 00:07:28.590
Remember how we had for linear SVR we had just a tube.

113
00:07:28.590 --> 00:07:31.150
But now here we have this space in between them.

114
00:07:31.200 --> 00:07:42.210
And so basically what that means is any points that are in between these two X like the most outmost

115
00:07:42.690 --> 00:07:43.450
hyper planes.

116
00:07:43.470 --> 00:07:44.710
Any points in between them.

117
00:07:44.850 --> 00:07:50.380
They won't be considered two wards like the Arab.

118
00:07:50.400 --> 00:07:55.710
For those points will not be considered what we want to do is we want to minimize the error from this

119
00:07:55.890 --> 00:08:01.070
Epsilon insensitive space to the remaining points that are outside and what this looks like.

120
00:08:01.080 --> 00:08:04.790
Over here is that's our ballroom hyper plane.

121
00:08:04.800 --> 00:08:05.800
That's its projection right.

122
00:08:05.810 --> 00:08:12.870
Or that's a projection of the part where it intersects with our real base function.

123
00:08:12.870 --> 00:08:19.260
And that's the top hyper plane and that's its intersection of the projection or its intersection.

124
00:08:19.260 --> 00:08:22.370
So this line or here is projected into that one.

125
00:08:22.500 --> 00:08:30.620
And basically anything in between was the absolute insensitive space now has become this Epsilon sensitive

126
00:08:30.630 --> 00:08:33.690
tube and these are the support vectors.

127
00:08:33.870 --> 00:08:39.690
The crucial point here is that this is the outcome originally this is these hyper planes are identified

128
00:08:39.690 --> 00:08:45.540
or built from this view from the three dimensional view so that's where these points come in place so

129
00:08:45.540 --> 00:08:49.680
this point is actually underneath we can't see it it's over there and there's also these two points

130
00:08:49.680 --> 00:08:50.770
that are on the left.

131
00:08:50.790 --> 00:08:52.500
So from here they're built.

132
00:08:52.500 --> 00:08:57.310
And then this is just a projection just to put it into a perspective.

133
00:08:57.420 --> 00:09:02.870
So that's why it's still a support vector regression because we have these points now.

134
00:09:03.090 --> 00:09:05.760
Hopefully that explains why it's a support extra regression.

135
00:09:05.800 --> 00:09:12.480
There's just one last thing I wanted to mention the final thing is that everything we've been talking

136
00:09:12.480 --> 00:09:15.510
about here is for illustrative purposes.

137
00:09:15.540 --> 00:09:23.250
In reality the way this works is very similar to the how the support vector machine works how what we

138
00:09:23.250 --> 00:09:29.610
discussed about the kernel trick that in reality we don't have to go into a third dimension to all these

139
00:09:29.610 --> 00:09:37.320
projections and then find our hyper planes find this Epsilon sensitive space and then predict everything

140
00:09:37.320 --> 00:09:40.100
back and get this it would be too computationally expensive.

141
00:09:40.110 --> 00:09:46.550
So what we actually discussed here is a more complex approach this would be like the full fledged approach

142
00:09:46.600 --> 00:09:52.110
of going into the third dimension doing the hyper planes coming back getting our end result that would

143
00:09:52.110 --> 00:10:00.800
be like the full Monty in a way but effectively what happens or in reality is that the colonel trick.

144
00:10:00.820 --> 00:10:05.910
So just like with the support vector machine we don't have to go into third dimension.

145
00:10:05.910 --> 00:10:07.650
Everything happens in the same space.

146
00:10:07.740 --> 00:10:09.540
Simply by how we use the colonel.

147
00:10:09.660 --> 00:10:16.440
Now we want to dive into more detail and that I'll let you think about that in your own time on how

148
00:10:16.590 --> 00:10:18.300
the colonel trick would be used here.

149
00:10:18.300 --> 00:10:24.060
Because simply it's a it's a easier concept than what we discussed by looking at the example the colonel

150
00:10:24.060 --> 00:10:29.250
trick in SVM we can extrapolate how that would work or how that would benefit us here as well.

151
00:10:29.940 --> 00:10:34.290
But in a nutshell this is what the nonlinear support vector regression is all about.

152
00:10:34.290 --> 00:10:41.520
And the best part is of course the result that it allows us to model non-linear relationships like this

153
00:10:41.880 --> 00:10:45.120
and get insights from our data.

154
00:10:45.120 --> 00:10:46.280
I hope you enjoyed this tutorial.

155
00:10:46.280 --> 00:10:50.940
This was quite an advanced concept so congratulations on making it to the end and I look forward to

156
00:10:50.940 --> 00:10:53.180
seeing you on the future tutorials in the course.

157
00:10:53.190 --> 00:10:55.170
And until then happy analyzing.
