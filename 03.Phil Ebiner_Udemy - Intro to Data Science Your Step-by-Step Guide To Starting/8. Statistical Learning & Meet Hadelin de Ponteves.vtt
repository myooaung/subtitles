WEBVTT
1
00:00:04.630 --> 00:00:06.300
Hello this is our law here.

2
00:00:06.310 --> 00:00:12.340
The second instructor of this course now it is my time to welcome you in this introduction to data science

3
00:00:12.630 --> 00:00:13.610
journal.

4
00:00:13.630 --> 00:00:20.080
So since this is an introduction the best starting point I can give you is actually the starting point

5
00:00:20.260 --> 00:00:25.810
I did when I started my career or when I started my journey in today's science and the starting point

6
00:00:25.810 --> 00:00:28.290
for me was to get two books.

7
00:00:28.300 --> 00:00:35.530
This book here an introduction to statistical learning and the second book The Elements of statistical

8
00:00:35.680 --> 00:00:36.560
learning.

9
00:00:36.730 --> 00:00:44.560
And so these are from the same authors except for one Trevor has the rubber tip Shivani and as you can

10
00:00:44.560 --> 00:00:45.870
see Trevor has the end.

11
00:00:46.060 --> 00:00:47.740
Robert tip she ran.

12
00:00:48.010 --> 00:00:54.970
So these books whatever is your starting point wherever you go wherever is the approach you want to

13
00:00:54.970 --> 00:00:56.830
take into data science.

14
00:00:56.860 --> 00:01:03.520
I highly recommend to have these books because they will help you get the right theory and the right

15
00:01:03.610 --> 00:01:10.720
mathematical concepts behind every algorithm or every model you will implement in your career and in

16
00:01:10.720 --> 00:01:11.930
your projects.

17
00:01:12.160 --> 00:01:18.850
For example if you have a look at our courses maybe you read to them but we make a lot of models in

18
00:01:18.850 --> 00:01:23.250
our courses and perhaps you already know we only explain intuition.

19
00:01:23.380 --> 00:01:28.810
We only expend the intuition and we don't go deep into the math concepts of the models.

20
00:01:28.810 --> 00:01:34.540
But if you have these books not only you will get the right intuition of the models but also you will

21
00:01:34.540 --> 00:01:37.830
get all the mathematical details of them all.

22
00:01:38.050 --> 00:01:44.260
If you look inside this book we see that indeed there are all the mathematics behind linear regression

23
00:01:44.680 --> 00:01:51.640
classification which we cover a lot in our courses but are also decision trees and random forests and

24
00:01:51.640 --> 00:01:56.130
even boosting by the way which we also cover support vector machines.

25
00:01:56.170 --> 00:01:57.450
You have all the math here.

26
00:01:57.490 --> 00:02:03.970
And of course unsupervised learning principal components analysis here PCa and Kamins.

27
00:02:03.970 --> 00:02:04.720
Here it is.

28
00:02:04.910 --> 00:02:06.640
So and that's what the first book.

29
00:02:06.730 --> 00:02:13.270
But then if you go deeper into machine learning deeper green or artificial intelligence whether you

30
00:02:13.270 --> 00:02:19.600
take our courses or some other courses on the Internet well you will see down the second book The Elements

31
00:02:19.600 --> 00:02:21.320
of statistical learning.

32
00:02:21.460 --> 00:02:23.950
You will also find other models.

33
00:02:24.100 --> 00:02:33.070
So here you have other regression models linear regression but also read regression laso which are regularisation

34
00:02:33.070 --> 00:02:33.970
techniques.

35
00:02:34.300 --> 00:02:40.660
And if we go more inside the book you can see that there is also LDK which we cover as well.

36
00:02:40.810 --> 00:02:44.130
Then the fundamental logistic regression just below.

37
00:02:44.230 --> 00:02:48.710
And of course kernel methods as well as Navy base.

38
00:02:48.820 --> 00:02:55.120
And you also have the mathematical details of Caple cross-validation the Bies Varians decomposition

39
00:02:55.120 --> 00:03:01.600
which are fundamental concepts to understand in data science model inference which we also talk about

40
00:03:01.600 --> 00:03:08.430
in our courses and more trees regression trees classification trees boosting and additive trees.

41
00:03:08.560 --> 00:03:12.510
And of course neural networks you know that we also have deep Marine Corps.

42
00:03:12.520 --> 00:03:17.830
But again it doesn't matter whether you take our course or some other courses if you take some of the

43
00:03:17.830 --> 00:03:18.920
deeper courses.

44
00:03:19.060 --> 00:03:26.170
Well this book will also explain not only in details but in an excellent way how the mathematics work

45
00:03:26.350 --> 00:03:28.740
in depth for neural networks.

46
00:03:28.750 --> 00:03:33.580
So here you have neural networks and then you have again support vector machines.

47
00:03:33.670 --> 00:03:41.230
Maybe it's not as well structured as we tried to do in our courses but at least the math are here and

48
00:03:41.230 --> 00:03:42.850
there explained in a great way.

49
00:03:43.180 --> 00:03:49.030
And then you have some more unsupervised learning you know unsupervised ranges when you don't know what

50
00:03:49.030 --> 00:03:49.810
you want to predict.

51
00:03:49.810 --> 00:03:56.230
You don't know what you want to identify and unsupervised learning will identify some clusters or some

52
00:03:56.230 --> 00:04:02.290
segments of data for you and it will categorize the data into these different segments.

53
00:04:02.290 --> 00:04:04.810
So these are the unsupervised learning techniques.

54
00:04:04.810 --> 00:04:11.580
And again it covers the diverse models that are in our courses Association learning.

55
00:04:11.580 --> 00:04:17.620
We have a full section in association rule learning cluster analysis or I guess here there will be some

56
00:04:17.620 --> 00:04:23.640
more Kamins Goshen mixtures which we haven't covered and of course hierarchical clustering.

57
00:04:23.980 --> 00:04:25.760
So that's why our huge mission in course.

58
00:04:25.780 --> 00:04:32.620
But if you go further in our courses you'll see that in the deep learning course we cover self organizing

59
00:04:32.620 --> 00:04:33.240
maps.

60
00:04:33.280 --> 00:04:36.990
And here again you can get the math behind self organizing maps.

61
00:04:37.280 --> 00:04:37.690
All right.

62
00:04:37.690 --> 00:04:41.260
And then you have some more concepts which we haven't covered as I can see.

63
00:04:41.470 --> 00:04:47.390
But if you take other courses I'm sure this will accompany you very well.

64
00:04:47.410 --> 00:04:50.740
All right then last sections of the course.

65
00:04:50.740 --> 00:04:56.230
Some more random forests and Semmel learning you know you understand now why I recommend to buy the

66
00:04:56.230 --> 00:05:02.080
two know the two compliment each other very well and most of all it contains everything you'll need

67
00:05:02.410 --> 00:05:09.380
to go very science then you have and symbol learning if you want to go more into you know gradient boosting

68
00:05:09.410 --> 00:05:15.870
or extra boost and you have a little theory about probabilistic graphical models which are very used

69
00:05:15.890 --> 00:05:22.240
and which we cover also in our deep learning course in the second volume unsupervised deep learning.

70
00:05:22.400 --> 00:05:29.090
Because indeed in the second volume we cover Boseman machines which is a probabilistic graphical model.

71
00:05:29.120 --> 00:05:34.050
And speaking of Boseman machine you can find them here restricted Boseman missions.

72
00:05:34.070 --> 00:05:40.520
So again you have the map behind even if we explained intuition that's always good to have some mathematics

73
00:05:40.520 --> 00:05:43.070
notions behind the algorithm.

74
00:05:43.070 --> 00:05:43.460
All right.

75
00:05:43.460 --> 00:05:49.550
And then some more high dimensional problems where the number of attributes that has number of features

76
00:05:49.570 --> 00:05:52.780
P is much bigger than the number of observations.

77
00:05:52.820 --> 00:05:59.990
And that's also a situation to understand really well and does science well everything is covered here.

78
00:05:59.990 --> 00:06:00.980
So there we go.

79
00:06:00.980 --> 00:06:08.060
These two books the elements of statistical learning which I recommend to see after this one that is

80
00:06:08.510 --> 00:06:10.950
an introduction to statistical learning.

81
00:06:11.210 --> 00:06:13.580
But anyway I recommend to have the two.

82
00:06:13.670 --> 00:06:20.750
There will be some great resources to use any time for any project in your data science career.

83
00:06:20.750 --> 00:06:27.670
So that's my first step even though I showed you here in this tutorial some pretty advanced morals.

84
00:06:27.830 --> 00:06:33.330
I recommend the purchase of these two books to be the first step in your daily science journey.
