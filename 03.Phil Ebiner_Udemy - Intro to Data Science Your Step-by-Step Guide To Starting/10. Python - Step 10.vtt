WEBVTT
1
00:00:04.750 --> 00:00:08.320
Hello and welcome to the finals tutorial of this section.

2
00:00:08.380 --> 00:00:16.060
Yes this is the final tutorial section because we will and this double chance journey by making this

3
00:00:16.060 --> 00:00:23.020
confusion matrix which will allow us to see how many incorrect predictions we did for this breast cancer

4
00:00:23.020 --> 00:00:23.900
prediction.

5
00:00:24.130 --> 00:00:29.140
And so a quick reminder the confusion matrix will return a table of four cells.

6
00:00:29.140 --> 00:00:35.020
I will explain in detail what these four cells are but mostly two of them will give us the number of

7
00:00:35.020 --> 00:00:40.350
correct predictions and the other two of them will give us a number of incorrect predictions.

8
00:00:40.450 --> 00:00:42.100
So that will be very interesting to see.

9
00:00:42.100 --> 00:00:49.060
For example if we did maybe one or two or 10 incorrect predictions and only really that from 1 to 10

10
00:00:49.060 --> 00:00:54.810
incorrect predictions is really good compared to the 137 observations of the test set.

11
00:00:55.120 --> 00:01:01.090
But then the other interesting thing we'll get is that thanks to this tall number of correct predictions

12
00:01:01.450 --> 00:01:07.570
we'll be able to compute the accuracy which is either the number of correct predictions divided by the

13
00:01:07.570 --> 00:01:15.640
total number of observations in the test set which is 137 or 1 minus the error rate that is one minus

14
00:01:15.730 --> 00:01:20.940
the total number of incorrect predictions divided by the total number of observations we'll compute

15
00:01:20.950 --> 00:01:24.600
that at the variance of this little Python adventure.

16
00:01:24.630 --> 00:01:28.530
And now let's start making the confusion matrix.

17
00:01:28.630 --> 00:01:35.380
So the confusion matrix can either be built directly by you know making a table and making all the calculations

18
00:01:35.770 --> 00:01:39.110
with some functions but of course we're not going to do it this way.

19
00:01:39.160 --> 00:01:44.190
We're going to do with efficient way and the way to do with the efficient way is with sikat learn.

20
00:01:44.410 --> 00:01:50.660
Again sikat learned contains a module that is not model selection or in symbol.

21
00:01:50.710 --> 00:01:59.530
It is the metrics much all the metrics module contains a bunch of functions to compute some metrics

22
00:01:59.830 --> 00:02:03.490
that most of them evaluate the most performance.

23
00:02:03.520 --> 00:02:08.730
So you have for example the accuracy metric you have the R-squared you have the edges that are squared.

24
00:02:08.770 --> 00:02:14.500
You have all these metrics that evaluate your model on a certain scale and which are very useful if

25
00:02:14.500 --> 00:02:17.170
you want to compare for example several modules.

26
00:02:17.320 --> 00:02:21.780
And one of these functions is of course the confusion matrix.

27
00:02:21.780 --> 00:02:26.400
It is a function that will just take two arguments the truth and the predictions.

28
00:02:26.530 --> 00:02:32.710
That is of course why test the truth containing all the true results and why pred containing all the

29
00:02:32.710 --> 00:02:33.950
predicted results.

30
00:02:34.200 --> 00:02:40.120
And so it will take these two arguments and to return a table of four cells the true positives the two

31
00:02:40.120 --> 00:02:43.240
negatives the false positives and the false negatives.

32
00:02:43.240 --> 00:02:47.250
So I explain what they are and a few minutes it will be easier to understand.

33
00:02:47.350 --> 00:02:49.540
Once we have the stable in front of us.

34
00:02:49.540 --> 00:02:57.130
So first let's import what we need to call this confusion matrix function and so it is something we

35
00:02:57.130 --> 00:03:03.220
import of course from sikat learn and then more precisely from a module by side learn which is called

36
00:03:03.340 --> 00:03:05.620
as we just said metrics.

37
00:03:05.610 --> 00:03:13.660
And from this metrics module of cycle learn we are going to import this confusion on this core matrix

38
00:03:13.660 --> 00:03:20.260
function confusion matrix function perfect we have it and now we are basically ready to get what we

39
00:03:20.260 --> 00:03:20.840
want.

40
00:03:20.980 --> 00:03:22.660
Because the way to get it.

41
00:03:22.690 --> 00:03:26.530
Well first it's a function that returns something its function returns.

42
00:03:26.590 --> 00:03:33.940
This table of 4 cells and so I'm introducing new Voivode that I'm going to call C M for confusion matrix

43
00:03:34.330 --> 00:03:37.910
which will be the result returned by this function.

44
00:03:37.910 --> 00:03:44.050
And so now to call this function simply we take our confusion matrix function than some parenthesis

45
00:03:44.470 --> 00:03:47.030
which are first the truth.

46
00:03:47.230 --> 00:03:55.540
The true results which are contained in Y test and then the predicted result which are contained in

47
00:03:55.630 --> 00:03:58.610
white bread and that's it.

48
00:03:58.700 --> 00:04:01.030
We are ready to get the confusion matrix.

49
00:04:01.030 --> 00:04:07.950
So let's lay these two lines of code and let's press command control plus answer to execute.

50
00:04:08.080 --> 00:04:09.070
And here we go.

51
00:04:09.130 --> 00:04:09.980
We have it.

52
00:04:10.150 --> 00:04:14.820
It's indeed a table of four cells two by two and containing integers.

53
00:04:14.820 --> 00:04:15.120
All right.

54
00:04:15.130 --> 00:04:16.210
Let's have a look.

55
00:04:16.210 --> 00:04:23.510
Double clicking on it and wow the number of incorrect predictions is only three plus two.

56
00:04:23.530 --> 00:04:29.810
That is five incorrect predictions and that is out of the total number of incorrect predictions of the

57
00:04:29.810 --> 00:04:34.420
test set which I remind the 20 percent of the total number of observations.

58
00:04:34.510 --> 00:04:39.910
That is 20 percent of 683 which is one hundred and thirty seven.

59
00:04:39.910 --> 00:04:44.760
So we only have five incorrect predictions out of 137.

60
00:04:44.800 --> 00:04:46.960
All observations in the test.

61
00:04:47.060 --> 00:04:52.870
So that's really really good you'll see the accuracy will be around 95 percent which is an excellent

62
00:04:52.930 --> 00:04:55.360
accuracy so that's great results.

63
00:04:55.360 --> 00:05:01.180
Again that shows the power of gradient boosting gradient boosting classification and now we have the

64
00:05:01.180 --> 00:05:02.680
number of incorrect predictions.

65
00:05:02.670 --> 00:05:09.890
We're now ready to compute the see but before this I like to explain four important concepts in science

66
00:05:10.280 --> 00:05:14.930
which are the true positives to negatives the false positives and the false negatives.

67
00:05:15.200 --> 00:05:22.070
So let's start with the true positives the true positives are the predictions that the tumor was cancerous

68
00:05:22.460 --> 00:05:28.010
and there are correct number of true positives is basically the number of correct predictions that the

69
00:05:28.010 --> 00:05:36.470
tumor was cancerous and therefore that this number here 48 then we have the true negatives which are

70
00:05:36.470 --> 00:05:39.340
the predictions that the tumor was benign.

71
00:05:39.340 --> 00:05:42.010
That is not cancerous and that were correct.

72
00:05:42.020 --> 00:05:47.960
Again no true positives correct predictions that it was malignant and true negatives correct predictions

73
00:05:47.960 --> 00:05:50.360
that it was not malignant that is benign.

74
00:05:50.660 --> 00:05:58.100
And this is this number that was 84 correct predictions that the tumor was benign.

75
00:05:58.100 --> 00:05:58.510
All right.

76
00:05:58.520 --> 00:06:03.050
And then we have the false positives and the false negatives.

77
00:06:03.150 --> 00:06:05.790
So the false positives is this number here.

78
00:06:05.900 --> 00:06:13.520
And as you might guess this corresponds to the number of incorrect predictions that the tumor was cancerous.

79
00:06:13.520 --> 00:06:16.100
Now it's easy to see it false positive.

80
00:06:16.130 --> 00:06:20.520
You break that something is positive but your prediction is false false positive.

81
00:06:20.720 --> 00:06:22.780
And there were three British signs like that.

82
00:06:22.820 --> 00:06:26.000
Incorrect reactions that the tumor was cancerous.

83
00:06:26.000 --> 00:06:29.370
And then finally there is the number of false negatives.

84
00:06:29.370 --> 00:06:36.080
And so here you get this is the number of false negatives is the number of incorrect predictions that

85
00:06:36.080 --> 00:06:38.740
the tumor was not cancerous.

86
00:06:38.750 --> 00:06:45.560
You know negative not cancerous and therefore there were only two incorrect predictions that the tumor

87
00:06:45.560 --> 00:06:50.370
was not cancerous to incorrect predictions that the tumor was benign.

88
00:06:50.810 --> 00:06:53.210
OK so that's a plus to know this.

89
00:06:53.240 --> 00:06:58.160
It's actually a question that comes up from time to time and interview so you might want to get this

90
00:06:58.160 --> 00:06:58.980
well.

91
00:06:59.000 --> 00:07:00.270
So here we go.

92
00:07:00.320 --> 00:07:01.080
You get it.

93
00:07:01.080 --> 00:07:08.480
And now let's finish this by section by something which is also important in data science but also that

94
00:07:08.480 --> 00:07:10.490
will show you something else in Python.

95
00:07:10.490 --> 00:07:16.850
Well something really simple but at least that will remind you that you can use the console any time

96
00:07:16.850 --> 00:07:18.290
to make some calculus.

97
00:07:18.290 --> 00:07:20.370
You don't have to create a new valuable here.

98
00:07:20.390 --> 00:07:23.620
You can just use the console to get some information you want.

99
00:07:23.660 --> 00:07:27.050
And right now the information we want is the accuracy.

100
00:07:27.290 --> 00:07:29.570
So the accuracy there are two ways to compute it.

101
00:07:29.600 --> 00:07:34.970
The first way is simply dividing the number of correct predictions by a little number of observations

102
00:07:35.300 --> 00:07:39.650
in the test set of course because we want to do that for new observations.

103
00:07:39.650 --> 00:07:47.930
So this total number will be 137 to set and then the second way is to compute 1 minus the error rate

104
00:07:48.200 --> 00:07:51.230
that is 1 minus the total number of errors.

105
00:07:51.290 --> 00:07:56.450
That is the total number of incorrect predictions divided by the total number of observations in the

106
00:07:56.450 --> 00:07:57.560
test.

107
00:07:57.560 --> 00:07:58.820
So which one would you like.

108
00:07:58.820 --> 00:08:00.760
I'm going to do one you'll do the other.

109
00:08:00.920 --> 00:08:05.930
I'll do the simplest one the simplest one is of course the number of correct predictions divided by

110
00:08:05.930 --> 00:08:07.660
the total number of observations.

111
00:08:07.910 --> 00:08:12.950
So let's keep in mind the number of correct relations was 84 plus 48.

112
00:08:12.950 --> 00:08:13.740
And here we go.

113
00:08:13.820 --> 00:08:18.260
Let's do this 84 plus 48.

114
00:08:18.680 --> 00:08:24.470
That's the number of correct predictions which we have to divide by the total number of observations

115
00:08:24.470 --> 00:08:28.450
in the test set which is one hundred and thirty seven.

116
00:08:28.560 --> 00:08:35.000
And now you simply to press enter to get the accuracy which is even more than 95 percent.

117
00:08:35.000 --> 00:08:37.180
It is 96 percent.

118
00:08:37.370 --> 00:08:42.290
That's an amazing result especially for this kind of problem you know you want to be as accurate as

119
00:08:42.290 --> 00:08:46.160
possible because you want to be responsible when predicting cancer.

120
00:08:46.430 --> 00:08:47.030
So there we go.

121
00:08:47.030 --> 00:08:49.390
And Sean we can do it for fun.

122
00:08:49.490 --> 00:08:57.350
We can also do the other way one minus the total number of errors which was five 5 divided by the total

123
00:08:57.350 --> 00:09:02.020
number of observations and said which is again 137.

124
00:09:02.030 --> 00:09:02.730
Here we go.

125
00:09:02.750 --> 00:09:04.700
We get exactly the same thing.

126
00:09:05.150 --> 00:09:05.960
Perfect.

127
00:09:05.960 --> 00:09:08.000
So congratulations.

128
00:09:08.000 --> 00:09:14.810
These were your first steps and bison and not only now you know bison they're also you know how to tackle

129
00:09:15.080 --> 00:09:22.100
two main data science problems regression and classification and you know how to tackle them with one

130
00:09:22.100 --> 00:09:25.730
of the most efficient ways that is with gradient boosting.

131
00:09:25.730 --> 00:09:27.340
All right so I hope you enjoyed it.

132
00:09:27.460 --> 00:09:34.520
And now I will end this section by probably the most important thing I can tell you in all this section

133
00:09:34.520 --> 00:09:41.600
or even in all this course and this thing is practice as much as you can practice and every day try

134
00:09:41.600 --> 00:09:48.020
to make it functional try to solve a machinery mole or even build a machinery of from scratch whatever

135
00:09:48.020 --> 00:09:48.440
you want.

136
00:09:48.440 --> 00:09:54.810
But practice practice and practice because that's the key to success in data science.

137
00:09:54.810 --> 00:10:00.370
So right now go back to UCLA and whenever you're ready start smashing the cable challenges.

138
00:10:00.440 --> 00:10:03.700
And on that note I'll wish you a very good day of science journal.
