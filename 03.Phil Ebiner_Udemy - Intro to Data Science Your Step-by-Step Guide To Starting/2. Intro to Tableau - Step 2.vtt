WEBVTT
1
00:00:04.760 --> 00:00:09.180
Welcome back to the viz. section of that intro to data science course.

2
00:00:09.750 --> 00:00:13.480
And previously we successfully installed Tablo public.

3
00:00:13.680 --> 00:00:16.060
So we're almost ready to visualize things.

4
00:00:16.090 --> 00:00:21.750
There's just one component missing and that's the data that we need to get a data set that we're going

5
00:00:21.750 --> 00:00:24.330
to be working with in order to start visualizing.

6
00:00:24.360 --> 00:00:25.620
And that's exactly what we're going to do.

7
00:00:25.620 --> 00:00:26.930
In today's tutorial.

8
00:00:27.150 --> 00:00:34.590
So in order to get the data set we're going to go ahead to Super data science dot com slash intro hyphen

9
00:00:34.710 --> 00:00:36.970
to hyphen data science.

10
00:00:37.380 --> 00:00:43.860
So this is the page on super science where all of the materials for this call for this course are hosted

11
00:00:44.310 --> 00:00:49.010
so you can download all the data sets here and or any additional materials we're talking about.

12
00:00:49.230 --> 00:00:52.470
And the data set for today is in part two.

13
00:00:52.520 --> 00:00:57.560
There are signs of Tablo and we're going to download this one here Bag Marketing days.

14
00:00:58.320 --> 00:00:59.210
So there we go.

15
00:00:59.220 --> 00:01:08.180
It's downloaded and now I'm going to go to the downloads folder and unzip the file.

16
00:01:08.250 --> 00:01:09.010
There it is.

17
00:01:09.000 --> 00:01:10.720
Bank marketing data set.

18
00:01:11.070 --> 00:01:19.290
So right away what we're going to do is we're going to create a new folder on our desktop for this course

19
00:01:19.340 --> 00:01:24.100
that's going to be called intro to data science.

20
00:01:24.990 --> 00:01:30.870
And then inside this folder we're going to create a folder for our project is always a good idea to

21
00:01:30.990 --> 00:01:35.250
keep your projects in separate folders so that you know where everything is.

22
00:01:35.250 --> 00:01:38.060
Bank marketing.

23
00:01:38.900 --> 00:01:47.460
So that's the name of our project and here we're going to copy the files into our wonderful So now we

24
00:01:47.460 --> 00:01:51.150
can just get rid of these too.

25
00:01:51.760 --> 00:01:52.610
And yeah.

26
00:01:52.620 --> 00:01:59.010
So there's our data so we can open it up to have a look what it's what and get a feel for it what it's

27
00:01:59.010 --> 00:02:00.240
all about.

28
00:02:00.240 --> 00:02:00.780
All right.

29
00:02:00.810 --> 00:02:01.580
There it is.

30
00:02:01.600 --> 00:02:08.700
There's our bank marketing data set as you can see it's quite large and quite confusing at this stage

31
00:02:08.970 --> 00:02:15.030
because it's almost a very it's a semi-colon separated values file.

32
00:02:15.150 --> 00:02:22.320
And if you scroll down to the very bottom you'll actually see there's a lot of roses for 1188 records

33
00:02:22.440 --> 00:02:23.920
not including the header.

34
00:02:24.180 --> 00:02:27.550
And yes it's quite a large dataset.

35
00:02:27.690 --> 00:02:33.000
And what we're going to do is actually we're going to close this Excel and we're going to import the

36
00:02:33.000 --> 00:02:35.430
dataset into Tablo.

37
00:02:35.430 --> 00:02:37.120
You can use the menu here.

38
00:02:37.290 --> 00:02:41.820
You need to select a text file because a comma SUPERVALU files consider a text file.

39
00:02:41.820 --> 00:02:47.030
But what we're going to do is just going to take a shortcut and we're going to drag the data set in

40
00:02:47.030 --> 00:02:48.310
to tabel like that.

41
00:02:48.360 --> 00:02:52.950
As simple as the table is a very drag and drop tool as you'll see further down and even when you're

42
00:02:52.950 --> 00:02:58.290
connecting to data you can do that and you can see is identified dataset as a text file.

43
00:02:58.290 --> 00:02:58.580
All right.

44
00:02:58.590 --> 00:03:01.740
So that's our dataset imported here.

45
00:03:01.760 --> 00:03:06.750
It will show the top thousand rows so you can just like scroll through them and get a feel for the dataset.

46
00:03:06.750 --> 00:03:10.160
And now right away they're much better organized.

47
00:03:10.480 --> 00:03:12.260
And so we're almost done.

48
00:03:12.270 --> 00:03:17.220
I'm just going to show you where you can find the information about these columns what exactly they

49
00:03:17.220 --> 00:03:19.850
mean and what this whole dataset is about.

50
00:03:19.860 --> 00:03:21.390
There's a filing here.

51
00:03:21.540 --> 00:03:26.430
There's there's that information which will tell you a bit about the data it comes from the source.

52
00:03:26.460 --> 00:03:33.600
You can also get it on the UCI machine learning repository and Atlanta will tell you a bit more about

53
00:03:33.660 --> 00:03:37.330
that repository in his tutorials on Python.

54
00:03:37.470 --> 00:03:39.120
But here's a data information.

55
00:03:39.120 --> 00:03:44.490
The data is related with direct marketing campaigns of a Portuguese banking institution.

56
00:03:44.670 --> 00:03:48.930
The marketing campaigns were based on phone calls often more than one contact to the same.

57
00:03:49.030 --> 00:03:51.640
Was required in order to assess.

58
00:03:51.650 --> 00:03:58.320
I'm assuming they should be assessed that access if the product banked on deposit would be yes or no

59
00:03:58.320 --> 00:04:00.480
would not be subscribed.

60
00:04:00.480 --> 00:04:09.630
So basically the question is the buyer the bank is trying to sell a new product or another product will

61
00:04:09.700 --> 00:04:11.900
grow to the customer's bank term deposit.

62
00:04:12.060 --> 00:04:18.470
And so they want to predict is that person going to subscribe or not subscribe to that.

63
00:04:18.540 --> 00:04:19.930
And so it's a real world there.

64
00:04:19.940 --> 00:04:28.680
So it's it's a real world problem it's real world customers of coastal desensitized or it's very similar

65
00:04:28.680 --> 00:04:30.220
to what was in the real world.

66
00:04:30.540 --> 00:04:35.880
And here you we've got the information about the cold so the columns as you see here you can find information

67
00:04:35.880 --> 00:04:36.480
about them here.

68
00:04:36.480 --> 00:04:41.100
So these columns they describe every single person I was contacted.

69
00:04:41.190 --> 00:04:43.320
So that's their age 56.

70
00:04:43.320 --> 00:04:44.400
That's their job.

71
00:04:44.460 --> 00:04:47.750
Housemaid or admin or blue collar technician.

72
00:04:47.940 --> 00:04:49.110
That's a marital status.

73
00:04:49.110 --> 00:04:55.230
Married single is divorced as if you are the ones education default.

74
00:04:55.230 --> 00:04:59.790
So some of them are intuitive like these ones for instance like Grace for years highs high schools or

75
00:04:59.970 --> 00:05:00.830
some are not.

76
00:05:00.840 --> 00:05:04.800
So if they're not into that you can just go back and find out what they are and you'll see us doing

77
00:05:04.800 --> 00:05:11.560
this throughout the coming to chorro so default for instance means has created in default.

78
00:05:11.580 --> 00:05:12.110
Yes and No.

79
00:05:12.120 --> 00:05:14.070
Does this person have credit in default.

80
00:05:14.250 --> 00:05:15.280
So usually it's not.

81
00:05:15.300 --> 00:05:17.530
Some of them are those are some of the my.

82
00:05:17.530 --> 00:05:25.110
Yes housing loan you know life here does housing has a housing loan or loan.

83
00:05:25.110 --> 00:05:28.790
Is has a personal loan so does that person have a housing loan.

84
00:05:29.070 --> 00:05:30.040
Yes or no.

85
00:05:30.120 --> 00:05:31.990
Does that person have a personal loan.

86
00:05:32.040 --> 00:05:36.060
Yes or no contact is how was the person contacted.

87
00:05:36.180 --> 00:05:38.700
So here you see these are bank decline data.

88
00:05:38.700 --> 00:05:40.560
The first one we've gone through them.

89
00:05:40.560 --> 00:05:44.020
Then we've got it related with the last contact of the campaign.

90
00:05:44.280 --> 00:05:46.430
And then you've got some other attributes.

91
00:05:46.470 --> 00:05:47.250
So there you go.

92
00:05:47.250 --> 00:05:49.210
That's the set.

93
00:05:49.360 --> 00:05:53.680
Oh and by the way at the end the last part is the Y variable.

94
00:05:53.700 --> 00:05:55.390
This is the most important one.

95
00:05:55.530 --> 00:06:00.930
It's the yes no variable is the actual target.

96
00:06:00.930 --> 00:06:03.890
So has the client subscribed to a term deposit.

97
00:06:03.890 --> 00:06:08.720
It's actually what we know we already know whether or not they subscribe to a term deposit.

98
00:06:08.760 --> 00:06:13.560
We're going to be trying to predict that we're going to be trying to see if there's any correlation

99
00:06:13.560 --> 00:06:18.690
with this variable among you know between the previous variables of any of them are correlated with

100
00:06:18.690 --> 00:06:19.020
this.

101
00:06:19.020 --> 00:06:26.190
So in the future we can say people with more education or with less education are more likely to subscribe

102
00:06:26.190 --> 00:06:29.280
to this law to this new product.

103
00:06:29.490 --> 00:06:33.790
So that's how it works and you'll see all of this happening in detail in the coming year.

104
00:06:33.820 --> 00:06:37.690
So don't worry if it's a bit confusing at this stage we'll get through it.

105
00:06:38.100 --> 00:06:43.310
It's a typical data size problem but we're going to be approaching it from a non typical standpoint.

106
00:06:43.320 --> 00:06:48.920
So it will be a different approach than what usually people expect or people would do if this data sets

107
00:06:48.970 --> 00:06:50.060
that's going to be exciting.

108
00:06:50.310 --> 00:06:52.050
So on that note I'll leave you to it.

109
00:06:52.050 --> 00:06:58.230
I'll leave you with this file and the data set as it is here to explore and have a look at the different

110
00:06:58.290 --> 00:07:04.080
attributes that we that are available to us and we'll start analyzing in the next tutorial.

111
00:07:04.320 --> 00:07:06.690
Until then enjoy data sites.
