1
00:00:01,100 --> 00:00:06,330
And now, let's discuss the high correlated features problem.

2
00:00:06,330 --> 00:00:09,230
The highly correlated features are in short,

3
00:00:09,230 --> 00:00:13,720
multicollinearity happens when the independent variable, in this case,

4
00:00:13,720 --> 00:00:16,640
features are linearly correlated,

5
00:00:16,640 --> 00:00:20,930
which means that changing one of them means changing the other.

6
00:00:20,930 --> 00:00:24,560
A valid question would be why this would be considered a problem. In

7
00:00:24,560 --> 00:00:28,640
particular, why is it a problem for regression models?

8
00:00:28,640 --> 00:00:31,940
The simple answer would be that multicollinearity by

9
00:00:31,940 --> 00:00:35,110
definition violates the definition of regression.

10
00:00:35,110 --> 00:00:39,740
The main goal of regression algorithms is to separate the relationship

11
00:00:39,740 --> 00:00:43,840
between each independent variable and the dependent variable.

12
00:00:43,840 --> 00:00:47,110
The definition of a regression coefficient is that it represents

13
00:00:47,110 --> 00:00:50,940
the average change in the dependent variable for each way

14
00:00:50,940 --> 00:00:55,060
changed in the independent variable when we hold all of other

15
00:00:55,060 --> 00:00:57,240
independent variables fixed.

16
00:00:57,240 --> 00:01:01,610
So the idea is that when we change a single independent variable,

17
00:01:01,610 --> 00:01:03,910
it should not change the others.

18
00:01:03,910 --> 00:01:08,660
If that happens, and that some other independent variables change,

19
00:01:08,660 --> 00:01:12,880
that would be very tricky for our algorithm since other variables

20
00:01:12,880 --> 00:01:16,240
will be a moving target rather than fixed one.

21
00:01:16,240 --> 00:01:19,480
If you want to think about it from an intuitive point of view,

22
00:01:19,480 --> 00:01:23,110
we can claim that a variable that's highly correlated

23
00:01:23,110 --> 00:01:25,610
is unlikely to provide more value.

24
00:01:25,610 --> 00:01:27,110
For example,

25
00:01:27,110 --> 00:01:31,410
if I take our dataset that we talk in the demo and I

26
00:01:31,410 --> 00:01:35,940
clear that, for certain home, the garage is too large and

27
00:01:35,940 --> 00:01:38,940
the garage can hold many cars.

28
00:01:38,940 --> 00:01:43,320
I had the same statements implicitly mean the same thing.

29
00:01:43,320 --> 00:01:46,560
Let's now discuss the possible solutions for the

30
00:01:46,560 --> 00:01:50,140
highly correlated features challenge.

31
00:01:50,140 --> 00:01:54,920
The first approach would be to use the correlation metrics. From the

32
00:01:54,920 --> 00:01:58,740
correlation metrics, we will identify the highly correlated features

33
00:01:58,740 --> 00:02:03,660
and remove them. The disadvantage of that approach is that it will be

34
00:02:03,660 --> 00:02:07,750
limited comparison between one feature to another feature without a

35
00:02:07,750 --> 00:02:11,380
holistic view and how this feature correlated with other features, in

36
00:02:11,380 --> 00:02:13,230
general.

37
00:02:13,230 --> 00:02:17,970
And that is why various inflation factor was introduced.

38
00:02:17,970 --> 00:02:21,350
The variance inflation factor is a value that tells us how

39
00:02:21,350 --> 00:02:26,070
much collinearity a particular independent variable has with

40
00:02:26,070 --> 00:02:28,480
all other independent variables,

41
00:02:28,480 --> 00:02:31,940
which means that it provides a holistic view we

42
00:02:31,940 --> 00:02:34,850
lacked in the correlation metrics.

43
00:02:34,850 --> 00:02:36,200
To understand that,

44
00:02:36,200 --> 00:02:39,040
let's assume we would like to create one independent

45
00:02:39,040 --> 00:02:44,170
variable, call it Xj. From other linearly independent

46
00:02:44,170 --> 00:02:48,340
variables, we add regression techniques.

47
00:02:48,340 --> 00:02:52,740
After doing the regression on Xj, we will calculate its R squared value,

48
00:02:52,740 --> 00:02:56,350
which is the accounted variability.

49
00:02:56,350 --> 00:03:02,540
In other words, how much percentage of the variability was accounted for?

50
00:03:02,540 --> 00:03:05,080
If you are not familiar with R2 squared,

51
00:03:05,080 --> 00:03:07,870
you can learn about it in my Building Your First Machine

52
00:03:07,870 --> 00:03:11,140
Learning course in the shown link.

53
00:03:11,140 --> 00:03:19,100
From that, we calculate the various inflation factor as 1 over 1 â€‘ R squared.

54
00:03:19,100 --> 00:03:24,510
If R squared is one, which means that all the variability was accounted for, the

55
00:03:24,510 --> 00:03:29,440
variance inflation factor will be infinity since that variable will be perfectly

56
00:03:29,440 --> 00:03:32,620
accounted for from other independent variables.

57
00:03:32,620 --> 00:03:37,250
However, if R squared is 0, it means that the variability was not

58
00:03:37,250 --> 00:03:41,440
accounted for. The various inflation factor will be one,

59
00:03:41,440 --> 00:03:44,800
which means that the variable cannot be linearly

60
00:03:44,800 --> 00:03:48,740
constructed from other independent variables.

61
00:03:48,740 --> 00:03:49,550
In general,

62
00:03:49,550 --> 00:03:51,620
we can use the following rule of thumb when

63
00:03:51,620 --> 00:03:54,410
analyzing the variance inflation factor.

64
00:03:54,410 --> 00:03:58,250
If the variable has a variance inflation factor value of one,

65
00:03:58,250 --> 00:04:02,740
that means it cannot be linearly constructed from other variables,

66
00:04:02,740 --> 00:04:05,820
and hence, it's not correlated at all with them.

67
00:04:05,820 --> 00:04:09,650
A value between one and five indicates that the variable is moderately

68
00:04:09,650 --> 00:04:14,070
correlated with other variables. A value higher than five would indicate

69
00:04:14,070 --> 00:04:21,000
that the variable is highly correlated and we usually want to remove values that are higher than five.

