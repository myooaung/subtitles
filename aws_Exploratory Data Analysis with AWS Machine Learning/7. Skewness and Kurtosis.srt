1
00:00:01,100 --> 00:00:06,340
Let's now discuss an important topic, which is the data distribution.

2
00:00:06,340 --> 00:00:09,600
The importance in data distribution is that to make

3
00:00:09,600 --> 00:00:11,590
machine learning algorithms happy,

4
00:00:11,590 --> 00:00:18,040
simply put. Machine learning algorithms make specific assumptions on our data.

5
00:00:18,040 --> 00:00:18,910
For example,

6
00:00:18,910 --> 00:00:21,890
some machine learning algorithms assume that data

7
00:00:21,890 --> 00:00:23,630
should be normally distributed.

8
00:00:23,630 --> 00:00:26,040
We are going to discuss that soon.

9
00:00:26,040 --> 00:00:26,900
Therefore,

10
00:00:26,900 --> 00:00:31,160
we will need to do several steps on our data to make our machine

11
00:00:31,160 --> 00:00:34,720
learning happy with it, and that's what we will do later when we

12
00:00:34,720 --> 00:00:37,410
reach the feature engineering module.

13
00:00:37,410 --> 00:00:41,700
Let's now introduce the most common use distribution called

14
00:00:41,700 --> 00:00:45,440
normal distribution, or Gaussian distribution.

15
00:00:45,440 --> 00:00:48,970
The first thing you can note here is that the distribution looks like a

16
00:00:48,970 --> 00:00:54,010
bell; hence, it's also called a bell curve distribution.

17
00:00:54,010 --> 00:00:59,050
Notice that it is symmetric around its center. On the horizontal axis, we

18
00:00:59,050 --> 00:01:02,760
have the data points in a standard deviation scale, one standard

19
00:01:02,760 --> 00:01:06,990
deviation, two standard deviation, and three standard deviation and four

20
00:01:06,990 --> 00:01:11,790
standard deviation, both in the positive and negative sides. On the

21
00:01:11,790 --> 00:01:17,570
vertical axis, we have the probability of each point. The average, or the

22
00:01:17,570 --> 00:01:21,870
mean, of the normal distribution is on 0, which is the center of the

23
00:01:21,870 --> 00:01:23,980
normal distribution.

24
00:01:23,980 --> 00:01:27,510
It is also possible to have a normal distribution that is

25
00:01:27,510 --> 00:01:30,770
centered around another point than the 0.

26
00:01:30,770 --> 00:01:36,530
The special thing about normal distribution is that 68% of the data points are

27
00:01:36,530 --> 00:01:42,690
within one standard deviation from the mean, while 95% of the points are within

28
00:01:42,690 --> 00:01:48,880
two standard deviations from the mean, and 99.7% of the points are within three

29
00:01:48,880 --> 00:01:51,980
standard deviations from the mean.

30
00:01:51,980 --> 00:01:56,870
Let's now discuss few characteristics of the normal distribution that

31
00:01:56,870 --> 00:02:00,840
makes it a role model for distributions in data science.

32
00:02:00,840 --> 00:02:04,540
The normal distribution is considered a good fit to describe

33
00:02:04,540 --> 00:02:08,100
everyday events, like rainfall rate per year,

34
00:02:08,100 --> 00:02:11,340
number of accidents per year, and so on.

35
00:02:11,340 --> 00:02:16,390
The main reason behind that is something called the central tendency theory,

36
00:02:16,390 --> 00:02:19,010
which says that in some situations,

37
00:02:19,010 --> 00:02:23,430
if a fairly large number of random variables are added together,

38
00:02:23,430 --> 00:02:27,870
they tend to sum towards a normal distribution. Many machine learning

39
00:02:27,870 --> 00:02:32,320
algorithms assume that the underlying data follows normally distributed

40
00:02:32,320 --> 00:02:36,540
fashion, so it is good to have your data in that fashion.

41
00:02:36,540 --> 00:02:37,380
Finally,

42
00:02:37,380 --> 00:02:42,000
the normal distribution is considered mathematically resilient in the sense

43
00:02:42,000 --> 00:02:47,240
that applying certain mathematical operations on a normally distributed data

44
00:02:47,240 --> 00:02:49,990
will still result in normally distributed data,

45
00:02:49,990 --> 00:02:54,990
which makes it very handy for data science purposes. And now,

46
00:02:54,990 --> 00:02:59,020
let's discuss two metrics that are used to measure the

47
00:02:59,020 --> 00:03:03,580
distribution of the data, skewness and kurtosis.

48
00:03:03,580 --> 00:03:07,220
The first measure we are going to discuss is the skewness, and it's a

49
00:03:07,220 --> 00:03:12,250
measure of how symmetric our data is. A distribution can be either

50
00:03:12,250 --> 00:03:16,710
symmetrical, as shown in the diagram in the middle, or positively

51
00:03:16,710 --> 00:03:21,000
skewed, as shown on the left, where we see that the distribution has a

52
00:03:21,000 --> 00:03:25,930
sort of tail in the positive direction and hence the name positive. The

53
00:03:25,930 --> 00:03:30,350
skewed value will also be positive or negatively skewed, as shown on

54
00:03:30,350 --> 00:03:31,540
the right,

55
00:03:31,540 --> 00:03:34,610
where we see that the distribution has a sort of tail in the

56
00:03:34,610 --> 00:03:37,570
negative direction and hence the name negative.

57
00:03:37,570 --> 00:03:42,660
The skewed value will also be negative. If we want to quantify the

58
00:03:42,660 --> 00:03:47,590
cases of skewness, we can describe three cases off skewness. If the

59
00:03:47,590 --> 00:03:51,160
absolute value of skewness is between 0and .5,

60
00:03:51,160 --> 00:03:54,940
we see that our data is fairly symmetrical.

61
00:03:54,940 --> 00:03:59,190
However, if the absolute value is between .5 and 1,

62
00:03:59,190 --> 00:04:02,140
we say that our data is moderately skewed.

63
00:04:02,140 --> 00:04:08,180
If the absolute value is greater than 1, we say that our data is highly skewed.

64
00:04:08,180 --> 00:04:12,330
The importance of skewness in data analysis and especially in machine learning

65
00:04:12,330 --> 00:04:17,500
tasks lies in the fact that skewed data needs to be transferred if we are

66
00:04:17,500 --> 00:04:20,620
going to use certain machine learning algorithms.

67
00:04:20,620 --> 00:04:24,340
Therefore, it's important thing to detect.

68
00:04:24,340 --> 00:04:29,100
Another measure we would like to discuss is the kurtosis, and it

69
00:04:29,100 --> 00:04:32,810
is an indicator of how pointy our data is,

70
00:04:32,810 --> 00:04:36,540
whether our data tends to be sharp or flat.

71
00:04:36,540 --> 00:04:40,060
Usually, this is measured against normal distribution,

72
00:04:40,060 --> 00:04:43,690
which has a kurtosis value of 3.

73
00:04:43,690 --> 00:04:49,820
Let's now examine the possible cases of kurtosis. A kurtosis value of 3

74
00:04:49,820 --> 00:04:55,090
indicates a dataset that is closed to the normal distribution pointiness. An

75
00:04:55,090 --> 00:04:58,840
example will be the blackâ€‘colored distribution.

76
00:04:58,840 --> 00:05:04,640
While kurtosis value more than 3 indicates a very pointy distribution.

77
00:05:04,640 --> 00:05:08,690
An example would be the redâ€‘colored distribution.

78
00:05:08,690 --> 00:05:13,220
While kurtosis value less than 3 indicates a flat distribution.

79
00:05:13,220 --> 00:05:17,620
An example would be the blueâ€‘colored distribution. In the next

80
00:05:17,620 --> 00:05:21,180
clip, we are going to see these concepts in practice and use

81
00:05:21,180 --> 00:05:26,000
statistics to understand our data. Be ready.

