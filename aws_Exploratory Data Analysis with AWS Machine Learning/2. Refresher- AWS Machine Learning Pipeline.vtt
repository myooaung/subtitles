WEBVTT
1
00:00:01.150 --> 00:00:04.520
First things first. Let's now go briefly on the

2
00:00:04.520 --> 00:00:06.750
overall machine learning pipeline.

3
00:00:06.750 --> 00:00:11.630
I quickly discuss what relevant AWS services we could use there and

4
00:00:11.630 --> 00:00:16.430
clearly define the scope our course within that pipeline. The

5
00:00:16.430 --> 00:00:19.840
machine learning pipeline can be split into seven steps in general.

6
00:00:19.840 --> 00:00:23.710
You might see different pipelines with a slightly different number

7
00:00:23.710 --> 00:00:26.900
of steps or names, but it doesn't matter.

8
00:00:26.900 --> 00:00:28.710
The difference is usually where you draw your

9
00:00:28.710 --> 00:00:33.140
separation line among different steps, if you know what I mean.

10
00:00:33.140 --> 00:00:35.790
The first step in the machine learning pipeline is to

11
00:00:35.790 --> 00:00:39.130
define our problem, simply, what are we planning to

12
00:00:39.130 --> 00:00:41.740
achieve using machine learning power?

13
00:00:41.740 --> 00:00:44.240
Do we want to predict the number of sales?

14
00:00:44.240 --> 00:00:46.780
Do we want to categorize our data?

15
00:00:46.780 --> 00:00:49.540
Do we want to cluster or group our data?

16
00:00:49.540 --> 00:00:51.430
Based on these simple questions,

17
00:00:51.430 --> 00:00:55.090
we will decide many decisions forward in our pipeline,

18
00:00:55.090 --> 00:00:59.990
such as which algorithm we are going to use and so on.

19
00:00:59.990 --> 00:01:04.190
The next step is sourcing or gathering our data. Usually,

20
00:01:04.190 --> 00:01:07.740
especially in enterprises, we will have scattered and

21
00:01:07.740 --> 00:01:11.910
heterogeneous data sources we would like to gather and capture as

22
00:01:11.910 --> 00:01:14.940
rich information as possible from them,

23
00:01:14.940 --> 00:01:19.340
whether it's structured data, such as database tables and CSV files, or

24
00:01:19.340 --> 00:01:25.900
unstructured data, such as videos and text. In the AWS world, certain

25
00:01:25.900 --> 00:01:30.120
services help with data sourcing part, such as Amazon Glue,

26
00:01:30.120 --> 00:01:33.690
which is fully managed serverless service that help

27
00:01:33.690 --> 00:01:36.390
us to perform ETL on our data,

28
00:01:36.390 --> 00:01:39.610
which stands for extract, transform, and load,

29
00:01:39.610 --> 00:01:42.440
extracting our data from the source,

30
00:01:42.440 --> 00:01:47.840
transforming it to a different shape, and loading it somewhere else.

31
00:01:47.840 --> 00:01:49.760
Amazon Kinesis, on the other hand,

32
00:01:49.760 --> 00:01:54.940
is a service that makes it easy to collect and analyze real‑time data quickly.

33
00:01:54.940 --> 00:02:00.720
Suitable data formats would be video, audio, and IoT telemetry.

34
00:02:00.720 --> 00:02:05.480
You can think of AWS Glue as more suitable for structured data while Amazon

35
00:02:05.480 --> 00:02:10.740
Kinesis is more suitable for unstructured and real‑time data.

36
00:02:10.740 --> 00:02:14.790
Another important part of the machine learning pipeline is the data preparation

37
00:02:14.790 --> 00:02:18.650
part, and this is where many things are done on the data,

38
00:02:18.650 --> 00:02:22.690
such as analyzing and visualizing our data,

39
00:02:22.690 --> 00:02:25.570
and we usually do this to understand what's going

40
00:02:25.570 --> 00:02:29.140
on in our data, what's missing, what's irrelevant,

41
00:02:29.140 --> 00:02:32.870
how the data distribution looks like, and so on.

42
00:02:32.870 --> 00:02:37.220
Then processing and feature engineering our data. After we understood

43
00:02:37.220 --> 00:02:41.440
our data, we will need to do some fixes and changes on the data so

44
00:02:41.440 --> 00:02:44.890
that it works well for our subsequent steps in the machine learning

45
00:02:44.890 --> 00:02:48.040
pipeline. We will scale our data,

46
00:02:48.040 --> 00:02:53.240
remove outliers, impute missing values, label features, and so on.

47
00:02:53.240 --> 00:02:56.080
Don't worry about those terminologies if you are not used to

48
00:02:56.080 --> 00:02:59.380
them. We are going to discuss them at a considerable level

49
00:02:59.380 --> 00:03:02.240
of detail across the course.

50
00:03:02.240 --> 00:03:08.240
In AWS world, two services that we will use mainly is Amazon QuickSight.

51
00:03:08.240 --> 00:03:12.390
This is simple and interactive service that helps us to create interactive

52
00:03:12.390 --> 00:03:17.020
visualizations. We will learn later on how this service works.

53
00:03:17.020 --> 00:03:22.040
Amazon SageMaker, which is the bread and butter of machine learning AWS.

54
00:03:22.040 --> 00:03:24.910
It's a fully managed machine learning service that helps to

55
00:03:24.910 --> 00:03:28.240
develop a machine learning pipeline on the cloud.

56
00:03:28.240 --> 00:03:31.770
The service supports notebooks that are quite similar to

57
00:03:31.770 --> 00:03:35.730
Jupyter Notebooks, the data science recognized de facto

58
00:03:35.730 --> 00:03:38.340
method of doing machine learning.

59
00:03:38.340 --> 00:03:41.610
Amazon SageMaker contains many Python libraries,

60
00:03:41.610 --> 00:03:46.460
such as scikit‑learn, pandas, seaborn, that makes it easy to analyze,

61
00:03:46.460 --> 00:03:51.770
preprocess, and visualize data. Amazon SageMaker Ground Truth is another

62
00:03:51.770 --> 00:03:56.500
useful service that makes data labeling cheap and automated by using

63
00:03:56.500 --> 00:04:00.720
machine learning technology and providing access to certain underlying

64
00:04:00.720 --> 00:04:05.600
manual labelers, such as Amazon Turk and other Amazon prescreened

65
00:04:05.600 --> 00:04:08.290
labeling companies.

66
00:04:08.290 --> 00:04:12.570
After we have prepared our data and made it in an acceptable format for the

67
00:04:12.570 --> 00:04:16.390
machine learning algorithm, the training step begins.

68
00:04:16.390 --> 00:04:19.940
This is where we choose a particular machine learning algorithm and train it to

69
00:04:19.940 --> 00:04:24.690
obtain the model that we will use for future predictions.

70
00:04:24.690 --> 00:04:26.330
After we have trained our model,

71
00:04:26.330 --> 00:04:30.580
we need to evaluate its quality through certain accuracy metrics.

72
00:04:30.580 --> 00:04:33.410
There are many metrics to consider depending on the type

73
00:04:33.410 --> 00:04:36.240
of the machine learning algorithm.

74
00:04:36.240 --> 00:04:40.450
In AWS world, AWS SageMaker is used to train and evaluate

75
00:04:40.450 --> 00:04:44.940
machine learning model using underlying processing power and

76
00:04:44.940 --> 00:04:47.740
Python machine learning libraries.

77
00:04:47.740 --> 00:04:53.040
The next step would be deploying our models for production usage and then

78
00:04:53.040 --> 00:04:59.270
monitoring our model and make sure that it works as intended. Again, AWS

79
00:04:59.270 --> 00:05:03.200
SageMaker will be available to help you in production.

80
00:05:03.200 --> 00:05:08.640
It can provide HTTPS points to make your model easy for consumption.

81
00:05:08.640 --> 00:05:12.360
Also, AWS SageMaker helps in model monitoring,

82
00:05:12.360 --> 00:05:13.210
for example,

83
00:05:13.210 --> 00:05:16.450
by enabling developers to set alerts to observe certain

84
00:05:16.450 --> 00:05:21.370
deviations on the model quality. Model deployment and monitoring

85
00:05:21.370 --> 00:05:24.660
referred to as model operationalization,

86
00:05:24.660 --> 00:05:27.850
which is the operational concern of the machine learning model.

87
00:05:27.850 --> 00:05:31.500
In cloud environment, you will need to consider other

88
00:05:31.500 --> 00:05:34.190
operational concerns, such as performance,

89
00:05:34.190 --> 00:05:37.640
security, scalability, and so on.

90
00:05:37.640 --> 00:05:38.260
Finally,

91
00:05:38.260 --> 00:05:41.450
it's worth nothing that even though the data sourcing and

92
00:05:41.450 --> 00:05:45.740
data preparation parts are only two steps out of seven steps

93
00:05:45.740 --> 00:05:47.850
in the machine learning pipeline,

94
00:05:47.850 --> 00:05:52.680
they are known to take 70 to 80% of the machine learning effort,

95
00:05:52.680 --> 00:05:55.940
which tells us that they are nontrivial steps.

96
00:05:55.940 --> 00:06:05.000
Our focus on this course will be purely the data preparation phase, which corresponds to the exploratory data analysis as the course titled.

