1
00:00:00,710 --> 00:00:05,100
Hello everyone and welcome to this python tutorial in the previous with you.

2
00:00:05,110 --> 00:00:12,480
We have compiled our model and basically our model is ready to be trained but before we start with our

3
00:00:12,480 --> 00:00:18,850
training process there are some steps that we have to do about data in the previous sections.

4
00:00:18,860 --> 00:00:26,780
We performed all data sets pre processing steps manually from scaling to reshaping the data set in this

5
00:00:26,780 --> 00:00:34,390
section and we haven't done any of these things except extracting the data set and now for the first

6
00:00:34,390 --> 00:00:41,500
time we are going to use tensor flow data generators to accomplish all of those data celebrate processing

7
00:00:41,500 --> 00:00:44,320
steps since we are working with Image Data.

8
00:00:44,320 --> 00:00:51,700
We are going to use imagery data generator and not only that but we are going to create two generators

9
00:00:52,120 --> 00:00:59,070
one for each data subset one for our training data and another one for validation.

10
00:00:59,110 --> 00:01:05,110
This is good practice in general because sometimes we are going to perform different year processing

11
00:01:05,110 --> 00:01:08,220
steps on a different data set subset.

12
00:01:08,260 --> 00:01:14,710
Here we have some essential nodes that we are going to use to create our data cell prior processing

13
00:01:14,710 --> 00:01:15,910
steps.

14
00:01:15,910 --> 00:01:23,350
If you remember from a few years ago we have set a very specific AMG shape for our data set.

15
00:01:23,350 --> 00:01:31,720
You may hear wondered why that shape each retrain the model supports only specific inputs sizes.

16
00:01:31,720 --> 00:01:39,340
And if you want to use those models we have to reshape our data set to match some of those.

17
00:01:39,490 --> 00:01:44,270
In the case of mobile led here you can see all of supportive input sizes.

18
00:01:44,760 --> 00:01:45,160
Okay.

19
00:01:45,180 --> 00:01:52,300
Now that we have that cleared let's write the code for our data set the generators to define our First

20
00:01:52,300 --> 00:01:53,350
Data generator.

21
00:01:53,350 --> 00:02:03,480
Define a variable called Data Jan and then specify for what subset it is to train for this one then

22
00:02:03,480 --> 00:02:07,000
the right image data generator.

23
00:02:07,230 --> 00:02:14,430
And if we check into doctoring we will see that it accepts a lot of arguments in all of those arguments

24
00:02:14,520 --> 00:02:21,790
are used for pre processing of image in some way I encourage you to study them in more detail for our

25
00:02:21,790 --> 00:02:27,790
example we are going to use only reskill which is what we did so far.

26
00:02:27,790 --> 00:02:36,010
Divide each pixel by two hundred and fifty five to make them between 0 and 1 since these re scale works

27
00:02:36,010 --> 00:02:39,250
by multiplying each pixel and not dividing it.

28
00:02:39,820 --> 00:02:47,810
We will said that to tourist scale by 1 divided by two hundred and fifty five let's copy this line to

29
00:02:47,810 --> 00:02:55,820
create a data generator for our validation data set pasted below and rename these data and train to

30
00:02:55,820 --> 00:02:56,200
data.

31
00:02:56,210 --> 00:02:59,100
Jan Barrett.

32
00:02:59,170 --> 00:03:08,250
The next step is to specify for each generator where to find the data set and how to process it defined

33
00:03:08,250 --> 00:03:11,270
the train generator and set it to data.

34
00:03:11,310 --> 00:03:15,220
Jan train as you can see there are a lot of things.

35
00:03:15,240 --> 00:03:23,570
What we can do but since our data set is in the folder we have to use these function flow from directory

36
00:03:23,570 --> 00:03:30,830
function this function will load our data set from the specific folder in the background so it won't

37
00:03:30,890 --> 00:03:37,900
occupy any room for us or slow down the train process for arguments of this function.

38
00:03:37,900 --> 00:03:43,730
There is the directory where all images are located and that is the first argument.

39
00:03:43,900 --> 00:03:50,680
Then we have target shape which should be the same as I am the shape that we defined before then we

40
00:03:50,680 --> 00:03:56,220
are going to specify the batch size or how many images we feed through the model.

41
00:03:56,220 --> 00:03:57,800
At the same time.

42
00:03:57,970 --> 00:04:01,820
Lastly we are going to specify class name.

43
00:04:01,930 --> 00:04:08,680
It can be a binary categorical or input since we only have two classes in our data set.

44
00:04:08,740 --> 00:04:13,920
We are going to specify these two binary okay for the first argument.

45
00:04:13,980 --> 00:04:15,350
Use the train Dir.

46
00:04:15,430 --> 00:04:24,210
Let's be defined at the very beginning of a dissection target size is 128 by 128 which is the same as

47
00:04:24,210 --> 00:04:30,470
our AMG shape then said batch size to 128 as well.

48
00:04:30,660 --> 00:04:35,860
You can set this to higher if you want since we have a lot of resources in Google column.

49
00:04:36,480 --> 00:04:45,390
And lastly said the class mode 2 binary execute a cell and as you can see it automatically detected

50
00:04:45,600 --> 00:04:51,510
two classes in our dataset and how many images we have as well.

51
00:04:51,630 --> 00:04:58,860
Let's copy the whole declaration for the train generator and pasted in the free cell instead of train

52
00:04:59,150 --> 00:04:59,560
right.

53
00:04:59,630 --> 00:05:08,910
Valid and instead of data Gen train set data Gen valid and the first argument is train their specify

54
00:05:09,000 --> 00:05:12,660
validation the rest of arguments to stay the same.

55
00:05:13,870 --> 00:05:15,140
And now we have data.

56
00:05:15,130 --> 00:05:19,940
Generally there is for our train data set and validation data set.

57
00:05:20,920 --> 00:05:23,560
That's all what we have to do for this video.

58
00:05:23,560 --> 00:05:29,080
If you have any questions or comments please post them in the comments section otherwise I'll see in

59
00:05:29,080 --> 00:05:29,950
the next tutorial.
