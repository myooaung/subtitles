WEBVTT
1
00:00:00.210 --> 00:00:07.530
Hi guys and welcome to the third step of this implementation about data processing so data processing

2
00:00:07.560 --> 00:00:13.350
is definitely not the most exciting part in our implementation but that's something we always have to

3
00:00:13.350 --> 00:00:19.950
do especially before building a new network because indeed you have to pre process the data in order

4
00:00:19.950 --> 00:00:21.630
to set it in the right format.

5
00:00:21.720 --> 00:00:24.020
Expected by your new network.

6
00:00:24.090 --> 00:00:30.840
And so here the data processing phase will consist of first loading the data set then normalizing the

7
00:00:30.840 --> 00:00:38.340
images then reshaping the data set you know into this one vector format that is expected by a fully

8
00:00:38.340 --> 00:00:41.650
connected new network as explained in the previous tutorial.

9
00:00:41.820 --> 00:00:42.780
And then that's it.

10
00:00:42.810 --> 00:00:45.510
We just want to set the right format.

11
00:00:45.510 --> 00:00:47.040
Expected by the new network.

12
00:00:47.490 --> 00:00:53.220
So let's do this let's see each of these sections one by one starting with loading the data set.

13
00:00:53.400 --> 00:00:54.180
And so here.

14
00:00:54.180 --> 00:01:00.960
Well we're lucky to have this fashion next module by carers because indeed it contains this low data

15
00:01:00.960 --> 00:01:07.580
function which will allow us to get directly the training set and the test set of the whole dataset.

16
00:01:07.590 --> 00:01:13.470
You know 60000 images in the training set and 10000 images in the test.

17
00:01:13.470 --> 00:01:18.540
So right now what's important to understand is that at this stage when we import the training set and

18
00:01:18.540 --> 00:01:19.490
it test this way.

19
00:01:19.740 --> 00:01:28.020
Well these are the images you know extra and contains 60000 2d arrays you know containing all the pixels

20
00:01:28.020 --> 00:01:29.070
of the images.

21
00:01:29.070 --> 00:01:34.890
And same for access it contains 10000 2d arrays containing the pixels of the images.

22
00:01:35.010 --> 00:01:36.590
And of course why train.

23
00:01:36.600 --> 00:01:39.920
Are the classes meaning the targets of the training set.

24
00:01:39.960 --> 00:01:43.070
And why test are the classes the targets of the test set.

25
00:01:43.410 --> 00:01:51.670
So right now no reshaping you know with this vector of 784 pixels has been created.

26
00:01:51.690 --> 00:01:54.530
That's what we'll do in a further code section.

27
00:01:54.540 --> 00:02:00.390
So basically at this stage we just import the images and there are targets in other classes Darling

28
00:02:00.480 --> 00:02:02.700
which close is each image.

29
00:02:03.210 --> 00:02:09.330
So when you execute this cell then you get this which basically downloads all the data.

30
00:02:09.330 --> 00:02:15.660
And then here we go for the next step in the very real First Data Processing step which is about normalizing

31
00:02:15.660 --> 00:02:16.830
the images.

32
00:02:16.860 --> 00:02:23.070
So indeed when working with new networks we always have or it is always highly recommended to normalize

33
00:02:23.340 --> 00:02:24.670
your inputs.

34
00:02:24.720 --> 00:02:25.770
Why is this.

35
00:02:25.770 --> 00:02:30.780
Simply because by normalizing your inputs Well your new network will trend faster.

36
00:02:30.780 --> 00:02:31.080
Right.

37
00:02:31.080 --> 00:02:34.230
I specify this here by normalizing images.

38
00:02:34.230 --> 00:02:38.000
We make sure that our model and then trains faster.

39
00:02:38.100 --> 00:02:44.850
And so here very simply to normalize the image as well since each pixel of the image is a value between

40
00:02:44.850 --> 00:02:46.730
0 and 255.

41
00:02:47.040 --> 00:02:54.870
Well the simple way to normalize the images is to divide each of their pixels by the maximum number

42
00:02:54.870 --> 00:02:57.610
of pixel which is 255.

43
00:02:57.660 --> 00:03:04.500
And that's why here we do a simple tensor operation as seen in the previous section which simply consists

44
00:03:04.650 --> 00:03:06.200
of dividing your tensor.

45
00:03:06.230 --> 00:03:13.470
So extra an index test by two hundred and fifty five and point zero because we're doing a float operation

46
00:03:13.840 --> 00:03:14.140
right.

47
00:03:14.160 --> 00:03:21.220
And so you know this will divide each value inside the cells of your tensor is by 255.

48
00:03:21.330 --> 00:03:27.880
Therefore putting all the pixels of your images between 0 and 1 and eventually normalizing the images.

49
00:03:27.900 --> 00:03:34.560
Right so very very simple you'll see that many many times when doing deep learning for image classification

50
00:03:34.830 --> 00:03:41.040
or you know for a computer vision you will always see this simple operation dividing your pixels by

51
00:03:41.040 --> 00:03:45.990
the maximum 255 that we're putting all the pixels between 0 and 1.

52
00:03:45.990 --> 00:03:47.820
All right so very simple so far.

53
00:03:47.850 --> 00:03:54.330
Now next step step you know next data processing step which is about reshaping the data sets so that's

54
00:03:54.330 --> 00:04:00.190
where we will really set the input of the new network into the right format.

55
00:04:00.300 --> 00:04:02.290
Expected by that neural network.

56
00:04:02.430 --> 00:04:03.540
And so what do we have to do.

57
00:04:03.810 --> 00:04:12.630
Well remember that X train contains the sixty thousand images meaning it's actually a 3D tensor where

58
00:04:12.630 --> 00:04:17.880
the first dimension gives the index of the images you know telling which image it is.

59
00:04:17.970 --> 00:04:24.630
And then the other two dimensions are the dimensions of the arrays which contain the pixels of the images.

60
00:04:24.660 --> 00:04:31.770
And so what we want to do now is flatten basically every image meaning we're going to transform each

61
00:04:31.770 --> 00:04:39.650
of the two the arrays in exchange of each of the 60000 to the arrays in exchange into sixty thousand

62
00:04:39.810 --> 00:04:48.920
one day vectors by flattening all the pixels into a single one vector and we will do that through reshape

63
00:04:49.290 --> 00:04:52.470
but just to make sure you understand what we'll get after this reshape.

64
00:04:52.470 --> 00:04:54.000
We actually have it right here.

65
00:04:54.000 --> 00:04:59.940
We will get it to the array you know before it was a 3D array but this time we'll get it to the array

66
00:05:00.270 --> 00:05:05.490
where the first dimension will be the same first dimension as an extreme meaning the dimension that

67
00:05:05.490 --> 00:05:11.640
gives the index of the image you know just to tell which row corresponds to the image.

68
00:05:11.640 --> 00:05:20.010
And then the second dimension will be that produced single vector containing all the pixels of each

69
00:05:20.070 --> 00:05:24.480
image and therefore in this to the array that we're about to get.

70
00:05:24.480 --> 00:05:27.400
Well each row well corresponds to a limit.

71
00:05:27.430 --> 00:05:32.820
And inside the row the columns will contain all the pixels of that image.

72
00:05:32.820 --> 00:05:33.110
All right.

73
00:05:33.120 --> 00:05:35.130
So helps you visualize as well.

74
00:05:35.160 --> 00:05:42.000
Basically we just keep the same first dimension of the image but we transform all the 2d arrays in X

75
00:05:42.000 --> 00:05:44.780
train into one dimensional vectors.

76
00:05:44.970 --> 00:05:53.280
And the way we do this is by using the reshape function taken from X train which will return the reshaped

77
00:05:53.430 --> 00:05:54.380
X train.

78
00:05:54.480 --> 00:05:58.060
And inside this reshape function we have to input two arguments.

79
00:05:58.110 --> 00:06:05.580
First is minus one year which says that we want to reshape all the images in extremely we want to take

80
00:06:05.670 --> 00:06:10.830
all the elements in the first dimension of extreme which is corresponds to the images.

81
00:06:10.830 --> 00:06:12.260
No they're indexes.

82
00:06:12.510 --> 00:06:20.310
And the second element here 28 by 28 is of course how many columns we want to get in that new X strain

83
00:06:20.320 --> 00:06:24.440
and since we actually want to get all the pixels into the columns.

84
00:06:24.480 --> 00:06:31.410
Well since we have 28 times 28 pixels in each image and we want to flatten all these pixels into one

85
00:06:31.410 --> 00:06:39.420
the horizontal vectors as well you'll get 28 by 28 columns to receive the 28 times 28 pixels.

86
00:06:39.480 --> 00:06:40.620
And that's why here.

87
00:06:40.620 --> 00:06:45.550
By reshaping into a 2D array of 60000 rows.

88
00:06:45.570 --> 00:06:49.450
Because here we specify minus 1 and 28 by 28 columns.

89
00:06:49.470 --> 00:06:51.490
Well we'll exactly get what we want.

90
00:06:51.510 --> 00:06:57.390
Meaning add to the array with all the rows corresponding to the images and all the columns corresponding

91
00:06:57.390 --> 00:06:59.740
to the pixels of these images.

92
00:06:59.880 --> 00:07:00.350
Right.

93
00:07:00.360 --> 00:07:07.950
And then each image of this to the array or you know some batch of images taken from this to the array

94
00:07:08.190 --> 00:07:13.890
will enter the new network and will be accepted by it because they will be in the right format after

95
00:07:13.890 --> 00:07:19.060
which you know there will be four propagated to get the final predictions.

96
00:07:19.110 --> 00:07:19.440
All right.

97
00:07:19.440 --> 00:07:22.370
And then we do the same reshape for the test set.

98
00:07:22.380 --> 00:07:23.230
Here it is.

99
00:07:23.280 --> 00:07:28.800
And that's of course because then you know we'll use the test set to evaluate our model and see which

100
00:07:28.800 --> 00:07:30.330
final accuracy we get.

101
00:07:30.560 --> 00:07:31.240
Okay.

102
00:07:31.470 --> 00:07:33.030
So there we go.

103
00:07:33.060 --> 00:07:33.570
Congrats.

104
00:07:33.570 --> 00:07:41.190
We did the little boring phase data processing and now good news we can move on to the exciting step

105
00:07:41.190 --> 00:07:47.610
exciting phase which is about building the artificial new network and that's where tend to flow 2.0

106
00:07:47.880 --> 00:07:48.630
comes into play.
