WEBVTT
1
00:00:00.150 --> 00:00:03.420
Hello everyone and welcome to this python tutorial.

2
00:00:03.420 --> 00:00:10.210
In the previous video we worked on the data set pre processing on the C4 10 data set and in this video

3
00:00:10.240 --> 00:00:17.580
we are going to define the model compile it train it and evaluated since this is not the core of this

4
00:00:17.580 --> 00:00:18.240
section.

5
00:00:18.270 --> 00:00:24.640
I just copy and paste the code from the convolution on neural networks section of this course.

6
00:00:24.650 --> 00:00:31.760
Now let's take a minute to see how we define the model what they are territories what how to compile

7
00:00:31.760 --> 00:00:39.580
the model What arguments did we use and so on for the model we started by defining two convolution layers

8
00:00:40.150 --> 00:00:47.380
each with thirty two filters followed by Max pooling layer to decrease the shape of the input by two

9
00:00:48.980 --> 00:00:57.110
after that we did the same thing two more coalition of layers but this time each had 64 filters and

10
00:00:57.110 --> 00:01:04.130
again followed by Max pulling layer to decrease the INPUT SIZE even further after our convolution all

11
00:01:04.130 --> 00:01:11.330
part of the network we used flattening layer to victories the input before we use dense layers for the

12
00:01:11.330 --> 00:01:19.930
classification in the dance part of the network we have two layers one hidden layer which has 128 units

13
00:01:20.270 --> 00:01:21.790
we activation the value.

14
00:01:21.880 --> 00:01:29.140
And finally our output layer which 10 units because we have 10 classes in our data set and activation

15
00:01:29.140 --> 00:01:31.970
here is solved Max.

16
00:01:32.050 --> 00:01:37.480
Now it's time to compile the model for the optimizer we are using Adam which is just another version

17
00:01:37.480 --> 00:01:44.500
of stochastic gradient descent for our last function we are using sparse categorical cross entropy since

18
00:01:44.500 --> 00:01:52.090
we don't have one hot encoding version of our targets and finally for our metrics we are using accuracy

19
00:01:52.240 --> 00:02:01.010
by the sparse version of it now we have everything to begin the training process in the fifth function

20
00:02:01.040 --> 00:02:10.450
we are providing X train for our images and Y train for our targets for the batch size we chose 128

21
00:02:10.660 --> 00:02:18.030
and finally for epochs just set it to 10 the training process will take a while so I'll skip to the

22
00:02:18.030 --> 00:02:21.960
end of it and welcome back to the lesson.

23
00:02:21.960 --> 00:02:28.320
As you can see the final accuracy for the training set is eighty nine percent let's evaluate the model

24
00:02:28.320 --> 00:02:35.480
to track the accuracy on the test set execute excel and as you can see we have seventy four percent

25
00:02:35.600 --> 00:02:43.780
on the test set let's execute the next cell for better visualization of the accuracy score and we have

26
00:02:44.050 --> 00:02:51.430
accuracy of almost 74 percent which is excellent for these data set and the model is now ready to be

27
00:02:51.430 --> 00:02:57.220
deployed to a server if you have any questions or comments please pause them in the comments section

28
00:02:57.820 --> 00:02:59.770
otherwise see in the next tutorial.
