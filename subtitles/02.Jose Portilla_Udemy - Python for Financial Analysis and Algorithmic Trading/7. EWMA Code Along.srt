1
00:00:05,300 --> 00:00:11,120
Hello everyone and welcome to the E.W. or exponentially weighted moving average coatl long lecture.

2
00:00:11,120 --> 00:00:15,970
This lecture we're going to review a simple moving average using rolling pin method from Panchos and

3
00:00:15,970 --> 00:00:20,430
it will show you how to use the exponentially weighted moving average capabilities with pandas.

4
00:00:20,630 --> 00:00:22,970
Let's open up a new Jupiter notebook and get started.

5
00:00:23,680 --> 00:00:28,750
OK I've opened up a Jupiter note book Inside the time series analysis folder inside that time series

6
00:00:28,750 --> 00:00:29,590
analysis folder.

7
00:00:29,590 --> 00:00:32,880
There's a C S V file called airline passengers CXXVIII.

8
00:00:33,070 --> 00:00:36,230
That's the C as we fall we're going to be using before we actually use it.

9
00:00:36,280 --> 00:00:44,610
We're going to need to import a few things we'll see import pandas as PD important up-I and we will

10
00:00:44,610 --> 00:00:52,350
import map plot lib pipe plot as Piazzi And then since I want to see the visualizations in my book will

11
00:00:52,350 --> 00:00:54,910
say map lib in line.

12
00:00:54,960 --> 00:00:55,530
All right.

13
00:00:55,710 --> 00:01:00,610
So once that's actually imported Well we're going to do is read in our data.

14
00:01:00,630 --> 00:01:07,360
I'll create a variable called airline to hold the data Freeman and it's a C as we files all say airline

15
00:01:07,360 --> 00:01:17,770
passengers thought cxxviii you can use to autocomplete and we'll set the index column to be month.

16
00:01:17,770 --> 00:01:23,410
Now typically what we do is we would say something like parse dates equals true but it's actually not

17
00:01:23,410 --> 00:01:27,930
going to work for us because there is a couple of missing data points inside this data set.

18
00:01:28,270 --> 00:01:35,650
So it would end up doing is once we see our airline checkup the head of it we see that we have this

19
00:01:35,650 --> 00:01:37,500
month index and thousands of passengers.

20
00:01:37,510 --> 00:01:42,130
But if we check out the index itself it's actually not a date time index that just happens to be like

21
00:01:42,170 --> 00:01:45,030
street index in order to fix that.

22
00:01:45,040 --> 00:01:51,970
We're going to do say airline index or first we'll say airline drop and away and we'll have that in

23
00:01:51,970 --> 00:01:54,790
place to be true.

24
00:01:54,820 --> 00:02:02,140
So we got rid of all the airline missing values here and there we're going to say airline index is equal

25
00:02:02,140 --> 00:02:12,920
to the to date time and then passing the index again we'll see airline index now.

26
00:02:13,090 --> 00:02:14,690
Check out the head of our data frame

27
00:02:17,860 --> 00:02:21,880
and we see that includes Now the first day of the month kind of indicating that it's now a date time

28
00:02:21,880 --> 00:02:22,320
index.

29
00:02:22,330 --> 00:02:29,470
And if we want to check again we can just say airline index and here we see the date time index.

30
00:02:29,470 --> 00:02:30,100
All right.

31
00:02:30,100 --> 00:02:33,950
So we've actually already shown how to create a simple moving average to just as a quick review.

32
00:02:34,270 --> 00:02:38,500
We can create a simple moving average just by creating a new column in our data frame.

33
00:02:38,500 --> 00:02:47,930
For example let's say six month civil moving average and all set equal to the airline.

34
00:02:48,490 --> 00:02:56,050
And it's called Thousands of passengers just tab out complete that we call rolling off this column and

35
00:02:56,050 --> 00:03:01,840
you give it a window we'll give it a six month window that's in relation to our actual periods and those

36
00:03:01,930 --> 00:03:03,680
periods are a month each.

37
00:03:03,680 --> 00:03:06,040
So took us from the first and second month third month.

38
00:03:06,040 --> 00:03:08,500
Obviously if you had daily data you'd have to change that.

39
00:03:08,620 --> 00:03:14,230
But there's a six month simple moving average and don't work is going to call the mean off of this so

40
00:03:14,280 --> 00:03:20,210
called Mean and we can just copy and paste this and let's create a 12 month moving average so a yearly

41
00:03:21,230 --> 00:03:23,590
and we actually saw this in the slides.

42
00:03:23,690 --> 00:03:29,880
So then I'm going to take my airline data frame and anoints plotted out and this is how you can get

43
00:03:29,880 --> 00:03:34,440
the thousands of passer's six months simple moving average 12 month moving average to get a lot more

44
00:03:34,440 --> 00:03:37,900
clarity you can also specify the size.

45
00:03:38,150 --> 00:03:41,780
So we can specify something like Timba.

46
00:03:43,180 --> 00:03:44,610
And you get something that looks like this.

47
00:03:44,620 --> 00:03:50,100
I'm also zoomed in so it looks a little blurry in my screen zooming out to a normal zoom a look a little

48
00:03:50,100 --> 00:03:50,720
better.

49
00:03:51,030 --> 00:03:51,560
OK.

50
00:03:51,750 --> 00:03:54,690
So that was a simple moving average just using the simple rolling.

51
00:03:54,690 --> 00:03:57,640
Now we're going to do is show you the exponentially weighted moving average.

52
00:03:57,660 --> 00:04:02,910
And remember that the exponentially weighted moving average overcomes a lot of the weaknesses of a simple

53
00:04:02,910 --> 00:04:06,570
moving average things like smaller windows leading to more noise.

54
00:04:06,570 --> 00:04:07,900
You always have this lag.

55
00:04:08,040 --> 00:04:12,030
If you notice at the beginning of this plot there's kind of a lag there are going to be able to fix

56
00:04:12,030 --> 00:04:17,430
that with E.W. may it also never really reaches the full peak or value of the data due to averaging.

57
00:04:17,430 --> 00:04:21,960
So you can see here no matter what our window sizes we're never really going to actually reach the top

58
00:04:21,960 --> 00:04:22,820
peak here.

59
00:04:23,070 --> 00:04:27,690
And what we want to do if exponentially wait a moving averages is let these more recent points have

60
00:04:27,690 --> 00:04:30,540
more weight than these past points.

61
00:04:30,540 --> 00:04:32,470
So let's go ahead and try that out.

62
00:04:33,710 --> 00:04:42,330
The way you do this is you simply zoom back in here call airline and then we create a new column we'll

63
00:04:42,330 --> 00:04:52,360
just say E.W. Amay and I will say 12 here and then we'll say the airline will grab that thousands of

64
00:04:52,360 --> 00:04:59,980
passengers call them again and then instead of calling rolling you call the W.M. you can do shift tab

65
00:04:59,980 --> 00:05:03,150
here and it says provides exponential weighted functions.

66
00:05:03,280 --> 00:05:06,190
And you'll notice that there's a couple of arguments here.

67
00:05:06,220 --> 00:05:12,310
Their CEO m span and Half-Life and you can see here it stands for the dictate terms.

68
00:05:12,310 --> 00:05:18,820
So you can you specify the Kames decay in terms of cion them spam or Half-Life or even an alpha term

69
00:05:19,040 --> 00:05:21,270
and to discuss what all that means in just a second.

70
00:05:21,490 --> 00:05:26,280
But let's show the span first lips span not Spain.

71
00:05:26,620 --> 00:05:34,850
And then set that equal to 12 and let's grab the mean here run that and then what we're gonna do is

72
00:05:34,850 --> 00:05:46,790
say airline and we're going to plot the original thousands of passengers and they will also plot E.W.

73
00:05:46,940 --> 00:05:49,420
may 12th.

74
00:05:49,670 --> 00:05:51,160
Let's see what this looks like.

75
00:05:53,020 --> 00:05:57,010
So if we look at this plot and let's actually create the physics side just a little better so we can

76
00:05:57,520 --> 00:05:59,010
really get a good look at it.

77
00:05:59,210 --> 00:06:01,960
Well say 10 by 8.

78
00:06:02,120 --> 00:06:06,380
If we look at this plot we can see that the behavior at the beginning is different than the behavior

79
00:06:06,380 --> 00:06:07,300
at the end.

80
00:06:07,310 --> 00:06:11,810
You'll notice that the sort of seasonality trend is a lot more clear.

81
00:06:11,810 --> 00:06:14,240
Towards the end points than versus the beginning points.

82
00:06:14,240 --> 00:06:19,760
And that's because we've waited the points closer to the present time heavier than the points during

83
00:06:19,760 --> 00:06:23,130
the more historical values of the older values.

84
00:06:23,190 --> 00:06:28,770
So let's now take a little bit of time to describe the mathematics or the formula behind this sort of

85
00:06:28,830 --> 00:06:34,320
exponentially weighted moving average and then how you can decide what kind of parameters you want to

86
00:06:34,320 --> 00:06:37,600
use when you call DOT GWM in order to do that.

87
00:06:37,680 --> 00:06:40,670
We're going to hop over to the notebook that's provided for you.

88
00:06:40,680 --> 00:06:44,340
There's actually some mathematical equations in there they'll be useful to reference so let's go to

89
00:06:44,340 --> 00:06:45,440
that notebook now.

90
00:06:45,790 --> 00:06:52,270
OK so here I am at the notebook we provide which is the GWM exponentially weighted moving average notebook.

91
00:06:52,370 --> 00:06:57,630
It's just under the time series analysis folder and I'm going to hide that header and I'm going to zoom

92
00:06:57,630 --> 00:06:58,460
in just a little bit.

93
00:06:58,470 --> 00:07:01,110
It's going to be some equations and no book that we're going to be referencing.

94
00:07:01,230 --> 00:07:05,410
So I'll kind of zoom in a lot and then I'm also going to toggle the toolbar.

95
00:07:05,580 --> 00:07:06,760
So let's scroll down.

96
00:07:06,780 --> 00:07:10,980
Here's all the code that we just went through as far as the simple moving averages so we can see we

97
00:07:10,980 --> 00:07:16,230
created the six months simple moving average the twelvemonth's simple moving average etc. and then we

98
00:07:16,230 --> 00:07:18,890
kind of saw here and it's a little blurry because I'm zoomed in.

99
00:07:19,130 --> 00:07:22,890
But now let's go ahead and move on to the exponentially weighted moving average.

100
00:07:22,890 --> 00:07:25,090
How does it actually work mathematically.

101
00:07:25,260 --> 00:07:29,410
And what are the important parameters that we need to know as users of pantless.

102
00:07:29,820 --> 00:07:36,000
So as we just discussed in the previous slides lecture E.W. M.A. it takes into account and tries to

103
00:07:36,000 --> 00:07:37,710
improve on some weaknesses.

104
00:07:37,800 --> 00:07:39,710
Esmay are simple moving average.

105
00:07:40,200 --> 00:07:44,490
Some of those weaknesses just to review them are things like smaller windows leading to more noise.

106
00:07:44,640 --> 00:07:47,050
You always have this lag where the size of the window.

107
00:07:47,160 --> 00:07:50,680
It never really reaches the full peak or values of the data due to averaging.

108
00:07:50,760 --> 00:07:53,660
And that doesn't really inform you about possible future behavior.

109
00:07:53,670 --> 00:07:55,610
It just describes general trends in your data.

110
00:07:55,740 --> 00:08:03,210
So in order to fix those things we use E.W. M8 so E.W. may exponentially weighted moving averages will

111
00:08:03,210 --> 00:08:08,160
allow us to reduce the lag effect from simple moving averages and it will put more weight on values

112
00:08:08,160 --> 00:08:09,780
that occurred more recently.

113
00:08:09,780 --> 00:08:14,850
So really we want to figure out is how do I define that particular weight that w variable.

114
00:08:14,880 --> 00:08:17,710
So there's full details and the mathematics behind this in this link.

115
00:08:17,850 --> 00:08:22,050
So if you're really interested in this you can just click on this link and kind of dive into the mathematics

116
00:08:22,050 --> 00:08:22,600
of it.

117
00:08:22,620 --> 00:08:25,460
We're going to kind of give you a higher level overview of the math.

118
00:08:25,470 --> 00:08:29,670
We'll talk about the alpha parameter a little bit and we'll talk about the three parameters that you

119
00:08:29,670 --> 00:08:32,150
can use when working with pandas.

120
00:08:32,250 --> 00:08:37,230
So the general formula for exponentially weighted moving averages is this following formula right here.

121
00:08:37,410 --> 00:08:45,750
You have a Y value at time t you have X of T being the input value you have w of I is the applied weight

122
00:08:45,930 --> 00:08:50,650
and know how the applied way w of-I changes as you go from equals zero.

123
00:08:50,690 --> 00:08:53,100
The very first value 2 equals T.

124
00:08:53,850 --> 00:08:59,570
And then as I mentioned why is the output So really the question is here how do we define this weight

125
00:08:59,570 --> 00:09:00,140
term.

126
00:09:00,140 --> 00:09:01,440
They'll be of I.

127
00:09:01,610 --> 00:09:07,070
So how am I taking in these input values and getting the output values of that exponentially weighted

128
00:09:07,070 --> 00:09:10,480
moving average How do we decide that weight term as it changes.

129
00:09:10,610 --> 00:09:13,560
When you start from the beginning of the series all the way to the end.

130
00:09:13,820 --> 00:09:17,510
So that really depends on what the adjusts parameter you provide.

131
00:09:17,670 --> 00:09:19,310
E.W. method is.

132
00:09:19,310 --> 00:09:22,250
So there's a parameter we haven't seen yet called adjust.

133
00:09:22,790 --> 00:09:27,980
So when it just is true and that's the default value that Pandanus provide the weighted averages are

134
00:09:27,980 --> 00:09:29,900
calculated using these weights.

135
00:09:29,900 --> 00:09:38,150
So you have y of t the actual output value is equal to x of T plus 1 minus Alpha times x of T minus

136
00:09:38,150 --> 00:09:45,980
one plus one of minus Alpha squared times x of T minus 2 plus etc. so on and so on and so you get this

137
00:09:45,980 --> 00:09:52,880
find a formula where we have one minus alpha to the power of t for that original input value x not only

138
00:09:52,910 --> 00:09:55,590
divide the whole thing by the sum of all the weight.

139
00:09:55,610 --> 00:10:01,790
You can see here this is essentially a expanded formula of what we have up here where we're just replacing

140
00:10:01,790 --> 00:10:06,580
W of I with this one minus Alpha at time t.

141
00:10:06,830 --> 00:10:11,990
And that's important because we can see that there's a decreasing weight as you move further and further

142
00:10:11,990 --> 00:10:18,720
into the time series because we'll have one minus Alpha and Alpha needs to be between 0 and the 1.

143
00:10:18,740 --> 00:10:24,250
And what that will happen or what that what that will cause is that this is a decimal number or a fraction.

144
00:10:24,410 --> 00:10:29,850
And then if you keep squaring a fraction are taken a fraction to the power of some other higher number.

145
00:10:29,930 --> 00:10:32,310
Then what happens is you get a smaller and smaller value.

146
00:10:32,360 --> 00:10:37,680
So you can see we're providing smaller and smaller weights for the data as it gets older and older.

147
00:10:37,850 --> 00:10:40,880
So that very first data point has a small sway attached to it.

148
00:10:41,030 --> 00:10:47,400
And the very most recent data point has the most weight attached to essentially just one OK.

149
00:10:47,500 --> 00:10:50,750
And then we divide that by the value or sum of all the weights.

150
00:10:51,070 --> 00:10:51,960
So that's the formula.

151
00:10:51,980 --> 00:10:58,530
When it just is true when it just equals false specified moving averages are calculated as the following

152
00:10:58,940 --> 00:10:59,360
you have.

153
00:10:59,360 --> 00:11:00,110
Why not.

154
00:11:00,110 --> 00:11:05,210
Is equal to x not mean that first input values equal to the first output value and then the rest of

155
00:11:05,210 --> 00:11:13,550
the outputs y at times t is equal to 1 minus Alpha times Y at T minus 1 plus Alpha multiplied by X of

156
00:11:13,550 --> 00:11:18,050
t the input value which is equivalent to using these weights right here.

157
00:11:18,050 --> 00:11:25,100
There'll be a Y is equal to Alpha times 1 minus Alpha power of II if II is less than c and if I happens

158
00:11:25,100 --> 00:11:28,210
to be equal to t have one minus alpha to the power of-I.

159
00:11:28,250 --> 00:11:29,860
So basically that's what's going on here.

160
00:11:29,870 --> 00:11:33,130
Just another way of rewriting w of-I.

161
00:11:33,150 --> 00:11:38,500
OK so again one must have Alpha B between 0 and the 1.

162
00:11:38,730 --> 00:11:43,640
And while since version of Pandurs 0.18 it's impossible to pass an alpha directly.

163
00:11:43,830 --> 00:11:49,980
It's often easier to think about either the span the center of mass or c o m or the half life of the

164
00:11:49,980 --> 00:11:51,790
exponentially weighted moment.

165
00:11:51,810 --> 00:11:56,010
So this whole thing that we've been discussing kind of comes down to these three terms that we're about

166
00:11:56,010 --> 00:11:56,870
to discuss.

167
00:11:56,910 --> 00:11:58,570
So how do we actually choose this weight term.

168
00:11:58,590 --> 00:12:04,560
Well with pandas The easiest way to think about it is when you say Alpha equal to one of these three

169
00:12:04,560 --> 00:12:08,120
possible methods you either think of it as the span.

170
00:12:08,130 --> 00:12:12,410
Think of it as a center of mass or think of it as the half life.

171
00:12:12,420 --> 00:12:18,240
So what are these three terms actually correspond to in a general higher level sense.

172
00:12:18,320 --> 00:12:26,030
So span that is s corresponds to what's commonly called in and day exponentially weighted moving average.

173
00:12:26,040 --> 00:12:30,960
So in our case we were dealing with month values but typically you'll be dealing with daily values.

174
00:12:30,960 --> 00:12:36,300
So if you want to use an exponentially weighted moving average where you can do is use the span argument

175
00:12:36,540 --> 00:12:41,700
and set that in your mind as an end they exponentially weighted moving average where you just define

176
00:12:41,700 --> 00:12:47,910
spanned by that kind of period that you're thinking of maybe a seven day or a 14 day and they exponentially

177
00:12:47,910 --> 00:12:52,740
weighted moving average So that's how you can think a span center of mass that is the C value that you

178
00:12:52,740 --> 00:12:58,860
provide has a more physical interpretation and it can be thought in terms of c is equal to S minus 1

179
00:12:58,950 --> 00:13:00,380
divided by two.

180
00:13:00,390 --> 00:13:04,440
So it's kind of a inverse relationship with spanne itself.

181
00:13:05,070 --> 00:13:10,580
Then there's half life and half life is the period of time for the exponential way to reduce to one

182
00:13:10,580 --> 00:13:11,290
half.

183
00:13:11,430 --> 00:13:16,900
And then you can also do Alpha directly which just specifies a smoothing factor directly.

184
00:13:17,100 --> 00:13:22,080
Typically when we're working with exponential weighted moving averages the easiest one to think about

185
00:13:22,170 --> 00:13:23,260
is spam.

186
00:13:23,370 --> 00:13:26,630
And if you want more explanation on the mathematics find this again.

187
00:13:26,640 --> 00:13:27,460
Check out that link.

188
00:13:27,480 --> 00:13:32,640
But typically we'll just be working with this span parameter because it's the easiest one that is intuitively

189
00:13:32,640 --> 00:13:33,450
understand.

190
00:13:33,690 --> 00:13:38,100
I would say the one that's second easiest to understand is the halflife especially if you've dealt with

191
00:13:38,100 --> 00:13:42,620
things that have the sort of halflife mathematics before.

192
00:13:42,640 --> 00:13:49,030
So what we end up doing like we just did is we set a new column and in this case we said DWM is the

193
00:13:49,030 --> 00:13:53,860
span of 12 meaning kind of a yearly span in our case because 12 months is one year and then we take

194
00:13:53,860 --> 00:13:57,170
the average and we get this exponentially weighted moving average.

195
00:13:57,250 --> 00:14:02,200
And you can see here each year is kind of more and more strongly weighted as you get closer and closer

196
00:14:02,200 --> 00:14:03,600
to the end of the time series.

197
00:14:03,700 --> 00:14:06,650
And you can kind of play around with these and explore them yourself.

198
00:14:06,910 --> 00:14:07,440
All right.

199
00:14:07,480 --> 00:14:11,700
So that's really all there is for now as far as exponentially weighted moving averages.

200
00:14:11,920 --> 00:14:16,120
If you're interested in this further than what we've discussed here definitely check out the link in

201
00:14:16,120 --> 00:14:21,060
the notebook that gives you the full details on the mathematics behind this and how it works with pandas.

202
00:14:21,420 --> 00:14:22,000
OK.

203
00:14:22,030 --> 00:14:23,880
Thanks everyone and I'll see you at the next lecture.
