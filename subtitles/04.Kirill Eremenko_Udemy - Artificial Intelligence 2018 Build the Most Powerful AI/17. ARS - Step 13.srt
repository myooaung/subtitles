1
00:00:00,420 --> 00:00:02,360
Hello and welcome to this new tutorial.

2
00:00:02,360 --> 00:00:04,380
The first step of the training.

3
00:00:04,500 --> 00:00:12,390
So we made that loop to loop over all the different steps which are going to be 1000 total which corresponds

4
00:00:12,390 --> 00:00:19,040
to the number of update we're going to apply to our policy or in other words the number of steps of

5
00:00:19,050 --> 00:00:20,440
gradient descent.

6
00:00:20,520 --> 00:00:27,030
And here we go with the first step inside this for loop which is to initialize the perturbations deltas

7
00:00:27,420 --> 00:00:29,680
and the positive and negative rewards.

8
00:00:29,940 --> 00:00:35,580
So indeed we are going to apply a lot of perturbations and I remind that these perturbations will be

9
00:00:35,580 --> 00:00:43,970
sampled following a normal distribution and we already made a method here in the policy class that simple

10
00:00:43,980 --> 00:00:45,620
these perturbations deltas.

11
00:00:45,840 --> 00:00:49,750
So of course we're going to use this function to sample the perturbations.

12
00:00:50,010 --> 00:00:59,010
This will remind return a list of 16 directions because here we did a full loop on the HP Data and be

13
00:00:59,010 --> 00:01:06,600
directions which is 16 and therefore we're going to get some perturbation deltas for each of the 16

14
00:01:06,600 --> 00:01:12,240
directions that will initialize the perturbations and then we'll initialize the reward.

15
00:01:12,480 --> 00:01:14,400
So we've made two separate variables.

16
00:01:14,520 --> 00:01:16,920
We were positive and we were negative.

17
00:01:17,040 --> 00:01:18,190
We were positive.

18
00:01:18,300 --> 00:01:25,110
Be initialized to zeros but will contain Liron all the reward obtained by applying the perturbations

19
00:01:25,110 --> 00:01:28,600
in the positive directions and reward negative.

20
00:01:28,710 --> 00:01:34,480
Same will be initialized to zeros but later on will contain all the reward which will be attained by

21
00:01:34,480 --> 00:01:40,250
applying the perturbations in the opposite direction as the previous positive directions.

22
00:01:40,590 --> 00:01:43,350
All right so let's initialize of this.

23
00:01:43,350 --> 00:01:46,710
It's going to be all clear once we start typing everything.

24
00:01:46,710 --> 00:01:49,690
So first we want to initialize the Delta.

25
00:01:49,950 --> 00:01:59,010
And as we just said we're going to get those deltas by applying the simple delta method from our policy

26
00:01:59,660 --> 00:02:05,160
object which is an instance of the policy class.

27
00:02:05,160 --> 00:02:14,770
All right so policia object from this policy object we use the simple deltas the simple deltas method

28
00:02:15,100 --> 00:02:19,510
which I remind we can see here doesn't take any argument.

29
00:02:19,610 --> 00:02:28,030
So all good that initializers are perturbations dealt us and we get 16 matrices of perturbations for

30
00:02:28,120 --> 00:02:32,040
each of the 16 different directions that we're testing.

31
00:02:32,530 --> 00:02:33,280
Great.

32
00:02:33,280 --> 00:02:36,780
Now let's initialize the puzzle if we want.

33
00:02:36,790 --> 00:02:42,040
So I remind these are going to be the rewards that will get by playing the perturbations in the positive

34
00:02:42,040 --> 00:02:42,900
directions.

35
00:02:43,150 --> 00:02:51,170
And so we're going to call these rewards positive underscore we want and we want to initialize them

36
00:02:51,290 --> 00:02:59,600
as a list of 16 elements because indeed we'll get these rewards for each of the 16 directions and how

37
00:02:59,600 --> 00:03:01,840
can we initialize a list of 16 elements.

38
00:03:01,850 --> 00:03:03,360
Well that's very simple.

39
00:03:03,370 --> 00:03:09,370
Well first we want to initialize them as only zeroes because we'll update these words later.

40
00:03:09,470 --> 00:03:12,080
And so to initialize a list of 16 zeroes.

41
00:03:12,260 --> 00:03:18,470
The trick is to put a zero here in square brackets and then multiply this by the number of elements

42
00:03:18,470 --> 00:03:26,180
you want to have in your list which is of course H-P that and B directions and you can notice I didn't

43
00:03:26,180 --> 00:03:33,250
forget the HP hyper parameter object because this and the directions here is a variable of this object.

44
00:03:33,260 --> 00:03:36,770
And we will create the HP object later on.

45
00:03:36,770 --> 00:03:43,520
All right so prefix that initializes the reward will get by playing the perturbations in the 16 positive

46
00:03:43,520 --> 00:03:47,680
directions order and B directions positive directions.

47
00:03:47,710 --> 00:03:53,330
Now we need to initialize the same but for the words we'll get by applying the perturbations in the

48
00:03:53,450 --> 00:03:55,430
opposite directions.

49
00:03:55,460 --> 00:03:59,940
And I'm going to call this new list negative rewards but be careful.

50
00:04:00,020 --> 00:04:05,720
Please do not confuse it with some negative words like some rewards below zero.

51
00:04:05,750 --> 00:04:11,300
It's just that negative is the opposite it's positive to highlight the fact that these words are the

52
00:04:11,300 --> 00:04:16,420
words will get by applying the opposite perturbation as this one.

53
00:04:16,430 --> 00:04:21,530
So it's just to highlight the position here between positive and negative but it has nothing to do with

54
00:04:21,770 --> 00:04:24,110
some negative values below zero.

55
00:04:24,220 --> 00:04:24,830
OK.

56
00:04:24,890 --> 00:04:26,520
Please keep that in mind.

57
00:04:26,810 --> 00:04:29,270
And therefore now to initialize.

58
00:04:29,450 --> 00:04:36,590
Well those negative rewards or those rewards we get by playing the perturbations in the opposite direction.

59
00:04:36,770 --> 00:04:43,070
Well that's the same you know we want to get 16 couples of words into positive directions and we words

60
00:04:43,070 --> 00:04:49,800
in the opposite negative directions and therefore we will also initialize this list as a list of 16

61
00:04:50,040 --> 00:04:50,930
zeros.

62
00:04:50,990 --> 00:04:56,660
Each of the 16 elements corresponding to the 16 directions and therefore what we all need to do here

63
00:04:56,720 --> 00:05:01,660
is just to copy this and paste that just below.

64
00:05:01,670 --> 00:05:02,380
All right.

65
00:05:02,480 --> 00:05:09,630
And here we go that initializers are perturbations deltas are we words in the positive directions.

66
00:05:09,650 --> 00:05:12,260
And are we words in the opposite directions.

67
00:05:12,560 --> 00:05:13,550
Good step done.

68
00:05:13,550 --> 00:05:18,410
Now we can move on to the next step which will be to update our positive rewards.

69
00:05:18,440 --> 00:05:20,080
So far they're equal to zero.

70
00:05:20,180 --> 00:05:26,870
And now we're going to explore the policy on one full episode which I remind is from the beginning until

71
00:05:26,930 --> 00:05:32,270
either the AI falls or until it plays one thousand actions.

72
00:05:32,330 --> 00:05:39,380
And so what we're going to do is that for each of the 16 directions we're going to explore that on one

73
00:05:39,380 --> 00:05:45,980
full episode using our explore function and we'll get the positive rewards for each of these 16 different

74
00:05:45,980 --> 00:05:47,090
directions.

75
00:05:47,090 --> 00:05:48,720
So let's do this in the next story.

76
00:05:48,770 --> 00:05:50,310
And until then enjoy.

