1
00:00:05,260 --> 00:00:09,670
Hello everyone and welcome to this lecture on convolutional neural networks.

2
00:00:09,670 --> 00:00:13,620
Now previously we created a neural network for already defined features.

3
00:00:13,720 --> 00:00:19,030
But what do we have the actual raw image data we need to learn about convolutional neural networks in

4
00:00:19,030 --> 00:00:23,910
order to effectively solve the problems that image data can present such as how to deal with two that

5
00:00:23,920 --> 00:00:24,910
missional data.

6
00:00:24,970 --> 00:00:29,440
And how do you have multiple color channels like the red green and blue color channels and for that

7
00:00:29,650 --> 00:00:35,500
we're going to need to understand how tensors can be used in order to form our data correctly with high

8
00:00:35,680 --> 00:00:37,210
end color channels.

9
00:00:37,680 --> 00:00:38,160
Okay.

10
00:00:38,400 --> 00:00:42,490
So let's continue by learning about CNN's.

11
00:00:42,520 --> 00:00:47,360
Now it's really cool but convolutional neural networks is just like the simple perception model.

12
00:00:47,440 --> 00:00:51,100
They have their origins directly linked in biological research.

13
00:00:51,100 --> 00:00:57,610
Recall that when we were designing our preset Tron model we directly converted a biological neuron into

14
00:00:57,610 --> 00:00:59,830
our own artificial representation.

15
00:01:00,070 --> 00:01:04,660
And we're going to do a similar idea with convolutional neural networks and the biological research.

16
00:01:04,660 --> 00:01:10,420
We base this off of is from a pair of scientists David Heibel and Torsen Weisel who were studying the

17
00:01:10,420 --> 00:01:17,680
structure of the visual cortex in mammals and their research is actually so fundamental to the field

18
00:01:17,680 --> 00:01:24,300
of biological vision that actually won them a Nobel Prize in 1981.

19
00:01:24,500 --> 00:01:29,270
One of the key components that their research revealed was that neurons in the visual cortex had what

20
00:01:29,270 --> 00:01:35,720
they call a small local receptive field that is the same these neurons are actually only looking at

21
00:01:35,810 --> 00:01:42,490
a local a smaller subsection of the entire image that the person is viewing.

22
00:01:42,620 --> 00:01:50,420
And then these local subsections can then later on overlap and create a larger image and visual field.

23
00:01:50,420 --> 00:01:56,090
What's also important to note is that these certain neurons in the visual cortex are only activated

24
00:01:56,090 --> 00:01:57,840
when they detect certain things.

25
00:01:57,890 --> 00:02:03,020
They realize that neurons may be only active when they detect the horizontal line or a black circle

26
00:02:03,020 --> 00:02:03,770
etc..

27
00:02:04,100 --> 00:02:10,360
So we can see here we already have this idea of local portions of the entire image.

28
00:02:10,490 --> 00:02:16,460
This idea of these local subsets directly inspired the artificial neural network architecture that would

29
00:02:16,460 --> 00:02:22,920
become the convolutional neural network and it was famously implemented in the 1998 paper by man in

30
00:02:22,940 --> 00:02:28,610
the can who is actually now the director of AI research at Facebook and they created what they call

31
00:02:28,610 --> 00:02:35,570
the Linette 5 architecture that was first used to classify that dataset.

32
00:02:35,570 --> 00:02:39,920
So when you're learning about convolutional networks maybe you're Googling around you often see a diagram

33
00:02:39,950 --> 00:02:41,490
that looks something like this.

34
00:02:41,600 --> 00:02:45,830
And when you're reading papers on different convolutional neural network architectures you see a lot

35
00:02:45,830 --> 00:02:47,330
of images that look like this.

36
00:02:47,330 --> 00:02:52,400
And I remember when I was first learning about convolutional neural networks this basically looks like

37
00:02:52,400 --> 00:02:53,720
a foreign language to me.

38
00:02:53,720 --> 00:02:56,690
It was pretty hard for me to understand what was actually going on.

39
00:02:56,690 --> 00:03:02,440
Each of these steps so we're to break down the various aspects of the convolutional neural network seen

40
00:03:02,440 --> 00:03:07,930
here and the two main aspects we haven't really seen before are these ideas of these convolutions and

41
00:03:07,930 --> 00:03:09,530
subsampling or pooling.

42
00:03:09,750 --> 00:03:14,440
So that entire feature extraction portion is we're really going to focus our attention to and learn

43
00:03:14,440 --> 00:03:17,210
about in this come illusional neural network lecture.

44
00:03:17,320 --> 00:03:21,760
That second half of classification is actually stuff we've already covered before basically fully connected

45
00:03:21,760 --> 00:03:25,260
networks and soft Max regression for multiple outputs.

46
00:03:25,300 --> 00:03:30,660
Well we're going to focus on is this idea of convolutions and subsampling or pooling.

47
00:03:30,680 --> 00:03:34,210
So in order to learn about that we need to break down into various topics.

48
00:03:34,220 --> 00:03:39,200
So will first have to review what are tensors then we'll compare a densely connected neural network

49
00:03:39,200 --> 00:03:44,690
to convolutional neural network that will dive deeper into convolutions and filters will learn about

50
00:03:44,690 --> 00:03:51,390
padding as well as pooling layers or subsampling and then we'll also review dropout.

51
00:03:51,430 --> 00:03:54,070
So let's get started by talking about tensors.

52
00:03:54,070 --> 00:04:01,130
Recall that tensors are just n dimensional arrays that we build up to as we increase levels of dimension.

53
00:04:01,180 --> 00:04:02,950
So we start off with just scalar numbers.

54
00:04:02,950 --> 00:04:06,690
Those are just individual digits or floating point numbers.

55
00:04:06,730 --> 00:04:12,250
Then we can have a vector of numbers essentially just a one dimensional array of various scalar numbers

56
00:04:12,570 --> 00:04:16,900
that we can actually have a matrix when they mentioned higher up for that which is then basically a

57
00:04:16,900 --> 00:04:18,310
list of vectors.

58
00:04:18,310 --> 00:04:22,630
And beyond that we have tensors Where are just higher than missional arrays.

59
00:04:23,950 --> 00:04:29,650
So tensors make it really convenient to feed in sets of images into our model which is why it's really

60
00:04:29,650 --> 00:04:34,420
vital that we understand tensors and their shapes when we end up building these models.

61
00:04:34,420 --> 00:04:42,170
Intenser flow so we can imagine that if we have a group of trainee images such as those thousand training

62
00:04:42,170 --> 00:04:48,290
images and the data set that we can have for them missional tensor where one dimension are the images

63
00:04:48,290 --> 00:04:54,260
themselves along another dimension we have the height of the image in pixels so that pixel representation

64
00:04:54,560 --> 00:04:59,690
in the height along another dimension we can have the width of the images and then if we want we can

65
00:04:59,690 --> 00:05:04,580
have four of them mentioned for the color channels where right now for em the digits were only dealing

66
00:05:04,580 --> 00:05:05,400
of grayscale.

67
00:05:05,480 --> 00:05:11,300
But later on for color images will have three channels red green and blue.

68
00:05:11,320 --> 00:05:16,960
So let's explore now the difference between a densely connected neural network those CNN's any convolutional

69
00:05:16,960 --> 00:05:21,820
neural network and recall that we actually already been able to create then only connect to neural networks

70
00:05:21,850 --> 00:05:26,250
easily with the T.F. estimator API.

71
00:05:26,260 --> 00:05:31,060
So remember a densely connected layer basically just looks like this where every neuron in one layer

72
00:05:31,420 --> 00:05:34,530
is directly connected to every other neuron in the next layer.

73
00:05:35,750 --> 00:05:39,650
Then for convolutional air we have a different approach.

74
00:05:39,830 --> 00:05:46,850
Each unit is connected to a smaller number of nearby units in the next layer basically directly inspired

75
00:05:46,850 --> 00:05:54,960
by that idea of the biological visual cortex where you're only looking at local receptive fields.

76
00:05:54,990 --> 00:05:59,550
So now the question arises why bother if it convolutional neural network instead of a densely connected

77
00:05:59,550 --> 00:06:05,820
neural network Well the this dataset was 28 by 28 pixels.

78
00:06:05,820 --> 00:06:08,160
So that's 784 total pixels.

79
00:06:08,250 --> 00:06:15,090
When you feed it in the most images are going to be much larger at least 256 by 256 pixels.

80
00:06:15,090 --> 00:06:22,310
And that would be 56000 total pixels and that's just for a relatively small image of 256 by 256.

81
00:06:22,320 --> 00:06:27,660
So as your images get larger and larger if you were to have a densely connected neural network that

82
00:06:27,660 --> 00:06:33,090
would lead to way too many parameters and it would just be unscalable to image images because you'd

83
00:06:33,090 --> 00:06:37,380
have so many parameters that you've already fit.

84
00:06:37,400 --> 00:06:44,750
So instead of convolutions and convolutions also have a major advantage for image processing that are

85
00:06:44,750 --> 00:06:47,570
directly inspired by that biological research.

86
00:06:47,690 --> 00:06:53,480
We can know intuitively that if we're looking at an image pixels that are nearby each other they're

87
00:06:53,480 --> 00:06:58,760
much more correlated to each other for image detection which is directly related to this idea of those

88
00:06:58,760 --> 00:07:02,960
convolutional layers only being connected to those local neurons.

89
00:07:04,970 --> 00:07:11,000
So each convolutional neural network layer looks at an increasingly larger part of the image and having

90
00:07:11,000 --> 00:07:15,400
units only connected to nearby units also aids in invariance.

91
00:07:15,440 --> 00:07:20,060
So convolutional neural networks help with regularisation and they also limit the search of weights

92
00:07:20,270 --> 00:07:23,800
to the size of the convolution.

93
00:07:23,810 --> 00:07:25,040
Let's go ahead and explore.

94
00:07:25,060 --> 00:07:29,810
This is a very high level overview what the convolutional neural network would look like as it relates

95
00:07:29,810 --> 00:07:31,550
to image recognition.

96
00:07:31,550 --> 00:07:37,260
You would basically just start with some input layer which is the image itself then come layers are

97
00:07:37,290 --> 00:07:40,130
only connected to pixels in their respective fields.

98
00:07:40,140 --> 00:07:45,390
So if we kind of think about this on a to the plane we can see that the illusional errors only have

99
00:07:45,390 --> 00:07:51,660
those local connections and then another higher level of convolution is again only connected to the

100
00:07:51,660 --> 00:07:55,490
local connections of that first convolutional layer.

101
00:07:55,500 --> 00:08:01,470
Now there is an issue here as you get towards the edge of the image there may not be any input neurons

102
00:08:01,800 --> 00:08:08,740
from the actual input data so we can fix this by adding a padding of zeros around the image.

103
00:08:08,740 --> 00:08:12,990
Then this is just generally known as padding OK.

104
00:08:13,260 --> 00:08:17,850
Let's now walk through a one dimensional convolution in more detail and then we're going to expand this

105
00:08:17,850 --> 00:08:20,250
to the idea of a two dimensional convolution.

106
00:08:20,490 --> 00:08:25,710
And this is going to begin to look like some of those images we first saw describing the architecture

107
00:08:25,810 --> 00:08:28,150
the convolutional neural network.

108
00:08:28,170 --> 00:08:33,270
So again let's take that back revisit then only connect in your own networks and convert that to a one

109
00:08:33,270 --> 00:08:36,540
dimensional convolution.

110
00:08:36,550 --> 00:08:39,430
So here we have an example of how densely connected neural network.

111
00:08:39,610 --> 00:08:40,900
Again same idea.

112
00:08:40,900 --> 00:08:46,690
We have one dimension of neurons densely connected to every neuron in the next layer that's the blue

113
00:08:46,690 --> 00:08:47,210
layer.

114
00:08:47,320 --> 00:08:50,310
And again densely connected to everything in the output layer.

115
00:08:51,280 --> 00:08:59,980
However let's convert that first input layer to a one the convolution So what we see here is just local

116
00:08:59,980 --> 00:09:05,650
connections to that next layer of neurons and what's really interesting is we can then treat these weights

117
00:09:06,010 --> 00:09:11,080
of these local edges as what we call a filter.

118
00:09:11,110 --> 00:09:19,570
So let's take an example of one filter we can see here on that bottom we have y is equal to w one or

119
00:09:19,570 --> 00:09:28,300
wait 1 times the input X plus W2 or two times the input x 2 and that will be the output Y which is then

120
00:09:28,300 --> 00:09:30,200
fed into that next neuron.

121
00:09:31,320 --> 00:09:37,340
So if w 1 and 2 are equal to 1 a negative one respectively then we have the equation.

122
00:09:37,380 --> 00:09:40,970
Why is equal to x 1 minus x 2.

123
00:09:40,980 --> 00:09:45,930
So I kind of chose these arbitrary weights here and given that they've chosen one a negative one.

124
00:09:45,960 --> 00:09:52,650
We ask ourselves well what is why at a maximum so one is that maximum activation there and that occurs

125
00:09:52,730 --> 00:09:56,530
at x 1 equal to 1 and x 2 equal to zero.

126
00:09:56,670 --> 00:10:03,120
And that is basically an example of a filter that is specifically designed for edge detection because

127
00:10:03,120 --> 00:10:08,610
remember edges when we represent them as pixels are essentially just a large difference in the actual

128
00:10:08,610 --> 00:10:12,330
darkness darkness of two pixels that are right next to each other.

129
00:10:12,540 --> 00:10:16,210
So if we have one pixel one right next to it we have a pixel zero.

130
00:10:16,350 --> 00:10:20,690
Then we're essentially describing an edge of really dark pixel versus the really light pixel.

131
00:10:20,910 --> 00:10:26,580
And we can see here if we describe these weights as one common negative one then when why is that a

132
00:10:26,580 --> 00:10:31,980
maximum we have an edge so we have a filter here that's essentially now an edge detector.

133
00:10:32,050 --> 00:10:36,760
So then we can apply that to the rest of these edges.

134
00:10:36,860 --> 00:10:41,690
So we have a set of weights that can act as a filter for detection and we can then expand this idea

135
00:10:41,690 --> 00:10:44,360
to multiple filters.

136
00:10:44,390 --> 00:10:46,990
So here's an example of having just one filter.

137
00:10:47,000 --> 00:10:52,400
So that's the same way across where the filter size is too because I have two weights there and the

138
00:10:52,400 --> 00:10:53,830
stride is two.

139
00:10:53,840 --> 00:10:55,950
So let's talk about this stride term.

140
00:10:56,060 --> 00:11:03,610
You can see here in this first layer of pink neurons I'm moving up these weights two neurons at a time.

141
00:11:03,620 --> 00:11:10,280
So if we start from the bottom I have w 1 and w 2 I repeat them every two neurons along the input and

142
00:11:10,280 --> 00:11:13,810
that's known as a stride of this filter.

143
00:11:13,940 --> 00:11:18,920
And if this visualization doesn't make a whole lot of sense to you don't worry we'll later on show you

144
00:11:18,980 --> 00:11:24,980
in other visualization representation of filters that might make more sense.

145
00:11:25,090 --> 00:11:27,360
So really lock in on this idea of stride.

146
00:11:27,380 --> 00:11:30,330
Let's fix this so now we have a stride of one.

147
00:11:30,500 --> 00:11:34,140
So if we're going up one unit at a time then we have something that looks like this.

148
00:11:34,280 --> 00:11:35,880
We can see there'll be one and there'll be two.

149
00:11:35,900 --> 00:11:38,190
But now we're only moving up one year on at a time.

150
00:11:38,360 --> 00:11:40,790
So we have blue than orange than red.

151
00:11:41,060 --> 00:11:45,430
So you can see here this is a stripe of two moving up two neurons at a time.

152
00:11:45,470 --> 00:11:50,490
This is a streite of one moving up one neuron out of time.

153
00:11:50,490 --> 00:11:53,700
Now remember we can see here that we have some neurons that aren't connected.

154
00:11:53,850 --> 00:11:59,310
That is where we could have added in some zero padding to include more edge pixels so I could add in

155
00:11:59,310 --> 00:12:03,400
a top neuron above my top pick neuron and just have that be zero.

156
00:12:03,450 --> 00:12:08,700
So I can kind of finish off that stride count.

157
00:12:08,730 --> 00:12:14,490
So that was just showing one filter we can actually then expand to multiple filters or multiple sets

158
00:12:14,490 --> 00:12:15,470
of weights.

159
00:12:15,480 --> 00:12:20,630
So here I can see this is a representation of two filters where my stride is still one.

160
00:12:20,640 --> 00:12:26,040
But now my filter size is two seconds here and added another set of neurons ready to accept another

161
00:12:26,040 --> 00:12:27,920
set of weights for another filter.

162
00:12:28,470 --> 00:12:31,890
And we expand this idea to any number of filters we want.

163
00:12:31,890 --> 00:12:33,690
So here I have four filters.

164
00:12:33,690 --> 00:12:40,250
So now four different sets of weights filter sizes now two and streite is still one.

165
00:12:40,260 --> 00:12:47,640
So each filter is attempting a different feature and realistically the representation would kind of

166
00:12:47,640 --> 00:12:53,640
get a little messy as we begin to draw arrows to every feature as we are every filter as we come in

167
00:12:53,640 --> 00:12:54,740
through the input.

168
00:12:54,750 --> 00:12:59,820
So instead of trying to represent it like this you'll often see it represented as sets of blocks.

169
00:12:59,820 --> 00:13:04,440
So for simplicity simplicity we're going to begin to describe this and visualize all this as a set of

170
00:13:04,440 --> 00:13:05,910
blocks instead.

171
00:13:07,250 --> 00:13:10,460
So we're going to convert our input to just be one by L..

172
00:13:10,470 --> 00:13:12,410
This one dimensional convolution.

173
00:13:12,410 --> 00:13:20,480
We just have one set by a length L of pixels and then we describe that set of filters as just this tensor

174
00:13:20,480 --> 00:13:25,460
which is the number of filters by the number of units in that actual layer.

175
00:13:26,960 --> 00:13:32,900
So we now have these concepts of these neurons converted to these block images for it to the convolution.

176
00:13:32,900 --> 00:13:35,500
We're mainly going to be dealing with images.

177
00:13:35,570 --> 00:13:37,190
So it's a really similar structure.

178
00:13:37,220 --> 00:13:42,890
We have our input image but now instead of being one D it's to the where we have a height and width

179
00:13:43,040 --> 00:13:44,330
to the image itself.

180
00:13:44,570 --> 00:13:50,690
And then for that next layer we have this tensor of the number of filters and the number of units for

181
00:13:50,690 --> 00:13:53,060
the width by the number of units for the height.

182
00:13:53,060 --> 00:14:00,960
So now we have this three missional tensor object and we can see that subsections are going to directly

183
00:14:00,960 --> 00:14:03,300
be related to this tensor.

184
00:14:03,300 --> 00:14:09,360
So if we're looking at a local section of the input image of a height and width then it actually directly

185
00:14:09,360 --> 00:14:13,290
belongs to a local section of that next tensor.

186
00:14:13,290 --> 00:14:21,020
So again height by with my number filters if we're working of color images it's basically a really similar

187
00:14:21,020 --> 00:14:25,040
concept except we add in one dimension for the number of color channels.

188
00:14:25,040 --> 00:14:30,230
So for a grayscale images we just have one color channel but for color images we typically have three

189
00:14:30,530 --> 00:14:31,700
red green and blue

190
00:14:34,570 --> 00:14:39,340
and it's the same idea here you have height width and then color and actually then corresponds to number

191
00:14:39,340 --> 00:14:43,840
filter's number of units still the number of units for height.

192
00:14:43,880 --> 00:14:47,980
Now convolution filters are commonly visualized with a grid system.

193
00:14:47,990 --> 00:14:52,300
So in case the last explanation of convolution filters wasn't clear enough.

194
00:14:52,340 --> 00:14:58,200
Let's go ahead and walk through how they work with grids on a to the input here on the left hand side.

195
00:14:58,220 --> 00:15:01,550
I have an input that's already been padded with zeros.

196
00:15:01,550 --> 00:15:07,820
So my original input was just that inner four by four grid where ones represent the darkest pixels and

197
00:15:07,820 --> 00:15:10,070
negative ones represent the lightest pixels.

198
00:15:10,070 --> 00:15:13,560
So if we pretend this is a handwritten digit it's basically a zero.

199
00:15:13,700 --> 00:15:20,010
And then I've padded it with an edge of zeros as far as pixel values around that I take a three by three

200
00:15:20,010 --> 00:15:20,910
filter.

201
00:15:20,910 --> 00:15:26,340
So I have weights inside this three by three filter and I'm going to apply it to the image and then

202
00:15:26,340 --> 00:15:33,450
one I'm going to do is multiply the pixels in the image by the basically weight values in the filter.

203
00:15:33,450 --> 00:15:38,100
Then once I multiply by those filter weights I'll get some results and then I'll take the some of that

204
00:15:38,400 --> 00:15:41,930
and I'll end up with whatever value in this case it was 0.

205
00:15:41,940 --> 00:15:47,640
So this is a way people commonly visualize filter's with a grid system where you have the filter of

206
00:15:47,670 --> 00:15:54,000
weights on a grid and you multiply the input by the filter weights and then you take that result take

207
00:15:54,000 --> 00:16:00,210
the sum and then that's going to be your output value for your convoluted image.

208
00:16:01,480 --> 00:16:07,990
Now stride distance also takes into account how fast you're going to move across image with your filters.

209
00:16:07,990 --> 00:16:10,960
Here we see a stride distance of one as an example.

210
00:16:11,110 --> 00:16:15,910
So I'm basically taking the filter moving over by one pixel and then applying all those changes.

211
00:16:16,120 --> 00:16:17,830
Or I could do it too.

212
00:16:17,850 --> 00:16:22,270
So here I'm moving over by two pixels and then applying those changes.

213
00:16:22,330 --> 00:16:28,360
Let's go ahead and jump to a really cool visualization Web site that again shows this process in even

214
00:16:28,360 --> 00:16:29,250
more detail.

215
00:16:29,290 --> 00:16:30,580
I'm going to jump to it now.

216
00:16:30,640 --> 00:16:35,590
So here I am at Sentosa the I O which has a really awesome visualization Web site and they have this

217
00:16:35,590 --> 00:16:40,120
really interesting visualization for convolution kernels which is basically what we've been explaining

218
00:16:40,120 --> 00:16:40,680
here.

219
00:16:40,960 --> 00:16:45,760
And on the left hand side you can see I have this little red cursor that's highlighting a pixel value

220
00:16:46,120 --> 00:16:50,610
and then it highlights the corresponding pixel in the actual representation of the image.

221
00:16:50,610 --> 00:16:54,550
You can kind of move around the play of this and then well we're going to do is walk through applying

222
00:16:54,550 --> 00:16:58,510
a 3:23 sharp kernel to the image of the face from above.

223
00:16:59,270 --> 00:17:02,420
So here we have our filter or a kernel with those weights.

224
00:17:02,420 --> 00:17:04,940
Here we have zero negative 1 5 et cetera.

225
00:17:05,150 --> 00:17:07,840
And then what we end up doing is the following.

226
00:17:07,850 --> 00:17:09,030
So here's our input image.

227
00:17:09,050 --> 00:17:12,240
You can see my little convolution filter moving across.

228
00:17:12,440 --> 00:17:20,150
So I have those pixel values I multiply them by the filter or kernel waits and then that ends up representing

229
00:17:20,330 --> 00:17:26,130
once I sum them the output of that actual location in the output image.

230
00:17:26,180 --> 00:17:28,670
So you can kind of move along and see how this is working.

231
00:17:28,670 --> 00:17:30,480
So we kind of hover above this.

232
00:17:30,490 --> 00:17:37,760
I then I have nine values that I'm going to multiply by my filter weights and then take that sum and

233
00:17:37,760 --> 00:17:41,200
then that's going to be in the output image at that location.

234
00:17:41,240 --> 00:17:43,200
So this is a sharpened filter.

235
00:17:43,220 --> 00:17:47,100
We can also see other convolution kernels such as a blur.

236
00:17:47,240 --> 00:17:50,510
So this is the result of this blur filter.

237
00:17:50,510 --> 00:17:51,940
You can see the weights there.

238
00:17:52,130 --> 00:17:56,330
And I encourage you to check out the resources and play around of this but hopefully this gives you

239
00:17:56,330 --> 00:17:58,610
a good idea of the actual process.

240
00:17:58,610 --> 00:18:02,810
So again we're just passing along this filter and then getting out the output so you can see here as

241
00:18:02,810 --> 00:18:08,370
I go along the edge as a straight distance of one there is my actual value of the output as I multiply

242
00:18:08,370 --> 00:18:10,870
by those filter weights and then take the sum.

243
00:18:11,240 --> 00:18:13,090
OK let's go back to the presentation.

244
00:18:13,160 --> 00:18:18,410
So we just covered those convolution filters and if you have multiple filters you could visually represent

245
00:18:18,410 --> 00:18:19,160
them like this.

246
00:18:19,190 --> 00:18:24,170
Here we can see we have multiple three by three convolution filters and this is the sort of representation

247
00:18:24,530 --> 00:18:28,700
that is actually being shown in that original convolutional neural network diagram.

248
00:18:28,700 --> 00:18:30,770
So here's that five by five convolution.

249
00:18:30,770 --> 00:18:32,750
So earlier we were using three by three.

250
00:18:32,800 --> 00:18:35,220
The here they're using five by five.

251
00:18:35,310 --> 00:18:37,410
So that's exactly what we saw here.

252
00:18:37,410 --> 00:18:42,370
And now we have an understanding of what convolution is and how a convolution filters work.

253
00:18:42,690 --> 00:18:46,060
But we still have to discuss subsampling or pooling.

254
00:18:46,080 --> 00:18:50,730
So in the very next lecture we're going to continue right where we left off here and talk about pooling

255
00:18:50,730 --> 00:18:51,890
and subsampling.

256
00:18:51,930 --> 00:18:52,880
I'll see you at the next lecture.
