1
00:00:05,340 --> 00:00:06,640
Welcome back everyone.

2
00:00:06,660 --> 00:00:11,170
We're going to continue a couple of examples using cures for convolutional neural networks.

3
00:00:11,190 --> 00:00:13,470
This time we're going to work with color images.

4
00:00:13,470 --> 00:00:18,600
We'll be working with the famous Safari 10 dataset which is color images of various objects.

5
00:00:18,750 --> 00:00:19,570
Let's get started.

6
00:00:19,740 --> 00:00:24,800
OK so here we are in Jupiter Lab. we're going to begin by importing the data set we'll say from curiousest

7
00:00:24,820 --> 00:00:25,790
datasets.

8
00:00:26,030 --> 00:00:28,450
Import Safar A10.

9
00:00:28,710 --> 00:00:30,170
Go ahead and run that.

10
00:00:30,390 --> 00:00:41,740
And then we will actually load the data by saying X train y train Khama X test Y test.

11
00:00:41,850 --> 00:00:47,700
Make sure that's an underscore and then set that equal to Safar 10.

12
00:00:47,810 --> 00:00:51,170
The load underscore data.

13
00:00:51,170 --> 00:00:53,040
So go ahead and run that.

14
00:00:53,750 --> 00:00:59,300
And if we check the shape of our actual data there is fifty thousand thirty two thirty two and three.

15
00:00:59,300 --> 00:01:03,140
So this is actually already formatted to have three color channels.

16
00:01:03,140 --> 00:01:07,160
Let's take a look at just one of the training data points.

17
00:01:07,160 --> 00:01:11,620
So there's 50000 images each 32 by 32 or three color channels.

18
00:01:11,620 --> 00:01:17,680
And if we take a look at a single one and check its shape then we get 32 by 32 by 3.

19
00:01:17,690 --> 00:01:24,450
Let's actually view some of these nor to view them we do an import that lived up high plot as Piazzi

20
00:01:24,720 --> 00:01:31,830
And just in case you need it you can do that live in line for viewing in the notebook will say Pulte

21
00:01:32,010 --> 00:01:37,240
show and then say X train 0.

22
00:01:37,460 --> 00:01:40,860
And here we see an instance of one of the types.

23
00:01:40,880 --> 00:01:42,650
So this is a frog.

24
00:01:42,680 --> 00:01:43,840
It's a little blurry to see.

25
00:01:43,850 --> 00:01:48,320
But if you kind of squint your eyes a little bit or back away from the computer screen you can see it

26
00:01:48,320 --> 00:01:51,860
it's a frog and other object type is horses.

27
00:01:51,890 --> 00:01:57,380
So here you can see an image of a horse again pretty low resolution just 32 by 32 but the general shape

28
00:01:57,380 --> 00:01:59,150
and outlines is what we can tell here.

29
00:01:59,150 --> 00:02:01,160
Also the fact that we have color.

30
00:02:01,370 --> 00:02:04,360
So what we want to do now is actually a little bit of pre-processing.

31
00:02:04,640 --> 00:02:10,930
If we took out the max values here noticed that they go to 255.

32
00:02:11,000 --> 00:02:16,390
So we're going to do is just divide x train and X test by 255.

33
00:02:16,570 --> 00:02:25,450
We will say X train is equal to x train divided by 255 and X test is equal to x test divided by 255.

34
00:02:25,460 --> 00:02:28,030
Just as we did for the this dataset.

35
00:02:28,040 --> 00:02:34,450
So now this is scaled if we check out the shape of our X test this is 10000 images.

36
00:02:34,460 --> 00:02:38,840
We have 50000 trainee images and then 10000 images for testing.

37
00:02:38,840 --> 00:02:42,710
And each of these images is 32 by 32 with three color channels.

38
00:02:42,710 --> 00:02:49,070
Now if we take a look at the labels such as white train you'll notice that the labels are actually still

39
00:02:49,220 --> 00:02:51,950
in their normal integer category forms.

40
00:02:51,950 --> 00:02:56,760
So we need to convert these to be one high and coded just as we did in the previous lecture.

41
00:02:57,050 --> 00:03:03,200
So we will say from carious utils import to categorical.

42
00:03:03,500 --> 00:03:05,570
And this is actually the same function as we did before.

43
00:03:05,570 --> 00:03:06,640
So there's two ways to import it.

44
00:03:06,650 --> 00:03:11,330
You can then do from the tills or from Cara's thought you tale's just want to show you both options

45
00:03:11,600 --> 00:03:14,440
in case you're run into both during the documentation.

46
00:03:14,490 --> 00:03:18,400
OK so now let's go ahead and convert our white labels.

47
00:03:18,410 --> 00:03:23,110
We will say why cat train is equal to two categorical.

48
00:03:23,240 --> 00:03:25,650
And then we'll pasan why train.

49
00:03:25,670 --> 00:03:33,400
And for this specific set there's 10 possible labels and then we will say why cat test is equal to two

50
00:03:34,360 --> 00:03:37,820
categorical why test 10.

51
00:03:38,290 --> 00:03:40,910
So then go ahead and run those to have the actual categories.

52
00:03:42,420 --> 00:03:46,890
Now if you're interested in what the actual ten categories are you can check out the Wikipedia page

53
00:03:46,950 --> 00:03:48,320
for Safar 10.

54
00:03:48,390 --> 00:03:51,280
So it's from the Canadian Institute for Advanced Research.

55
00:03:51,300 --> 00:03:56,820
You can see it has airplanes cars birds cats thier dogs frogs horses ships and trucks.

56
00:03:56,820 --> 00:03:58,200
So it's actually not all animals.

57
00:03:58,200 --> 00:04:00,970
There's also some messes of Transportation there as well.

58
00:04:01,000 --> 00:04:06,030
And what's also cool from the Wikipedia article you can check out the error rates and their publication

59
00:04:06,030 --> 00:04:06,500
dates.

60
00:04:06,510 --> 00:04:10,800
So in August 2010 the error rate was twenty one point one percent.

61
00:04:10,890 --> 00:04:15,780
And we're going to blow that out of the water even if just using simple cares and our own little models

62
00:04:15,780 --> 00:04:16,440
here.

63
00:04:16,490 --> 00:04:20,160
And then you can check out kind of state of the art 1.4 8 percent error rates.

64
00:04:20,190 --> 00:04:22,470
So let's go ahead and come back here.

65
00:04:22,770 --> 00:04:25,770
We have a categorical one hot and coded labels.

66
00:04:25,780 --> 00:04:26,960
So those are good to go.

67
00:04:26,970 --> 00:04:29,930
Now it's time to actually build our model.

68
00:04:29,950 --> 00:04:40,720
We're going to do is say from Cara's that models import sequential and then from carious the layers

69
00:04:41,820 --> 00:04:48,290
import dense Canvey are delusional to the.

70
00:04:48,330 --> 00:04:52,200
Also to max pool to the.

71
00:04:52,260 --> 00:04:57,200
And then we'll import Flaten and let's construct our network.

72
00:04:57,600 --> 00:05:03,900
So I begin by saying model is equal to sequential and we're going to have a convolutional there.

73
00:05:03,930 --> 00:05:10,080
So we'll add that in model add convolutional to the.

74
00:05:10,390 --> 00:05:17,780
And also the number of filters to 32 kernel size will be four by four.

75
00:05:17,900 --> 00:05:25,520
The input shape for these images if we say put shape that's equal to 32 by 32 and of three sensors three

76
00:05:25,520 --> 00:05:31,820
color channels and then the last thing I want to mention is what the activation is here we'll just choose

77
00:05:32,300 --> 00:05:35,640
activation is equal to rectified linear unit.

78
00:05:36,340 --> 00:05:39,990
Okay then we're going to do is have a pooling layer.

79
00:05:40,010 --> 00:05:51,200
So right after that we will say model the add and then say Max Poole to the and then say pool size is

80
00:05:51,200 --> 00:05:53,650
equal to 2 by 2.

81
00:05:53,960 --> 00:05:57,120
And what we're going to do is have a second set of convolutional errors.

82
00:05:57,140 --> 00:06:04,040
So in fact I'm just going to copy these exact two layers and then paste them again because these images

83
00:06:04,040 --> 00:06:05,290
are slightly more complex.

84
00:06:05,300 --> 00:06:10,860
They're a little larger than this or 32 by 32 instead of 28 by 28 plus we have the three color channels.

85
00:06:10,940 --> 00:06:16,240
So another convolutional there is probably a good idea then we'll go ahead and flatten the images or

86
00:06:16,240 --> 00:06:20,180
see a model at Flaten

87
00:06:23,470 --> 00:06:25,970
and then we'll have a dense hidden layer.

88
00:06:26,230 --> 00:06:29,990
So we will say model and dance.

89
00:06:30,280 --> 00:06:33,580
And again it's up to you how many neurons you want in this dense hidden layer.

90
00:06:33,580 --> 00:06:38,920
What's really common especially in working with image data is that people like to add in neurons as

91
00:06:38,920 --> 00:06:43,270
it gets more and more complex and orders of two to the power something.

92
00:06:43,480 --> 00:06:51,770
So you'll see often values like 1:28 and then that up power is then 2:56 and then 5:12 and so on.

93
00:06:52,000 --> 00:06:56,680
People and researchers tend to do that and will go ahead and follow their example.

94
00:06:56,950 --> 00:07:01,360
So we'll use 2:56 again there's no no real right or wrong value here.

95
00:07:01,370 --> 00:07:07,720
We can play around with it and encourage you to do so and we'll say this dance is going to have an activation

96
00:07:07,720 --> 00:07:15,660
function of rectified linear unit then we want the last layer to be the classifier will say model add

97
00:07:16,620 --> 00:07:25,650
dance and there's only 10 categories so we'll say 10 and this activation is going to be a soft Max that

98
00:07:25,660 --> 00:07:34,460
we will compile this by saying model compile the last will be equal to categorical cross entropy

99
00:07:37,270 --> 00:07:43,990
that the optimizer will be equal to armis prop and the metrics used.

100
00:07:44,070 --> 00:07:45,390
Let me scroll down here.

101
00:07:46,600 --> 00:07:50,530
We'll just use accuracy as our main metric.

102
00:07:50,530 --> 00:07:54,780
Go ahead and run that and then let's check out the model summary.

103
00:07:56,430 --> 00:08:02,830
So here we can see all the various layers we're doing are using an outside to fit the model we'll St

104
00:08:02,880 --> 00:08:13,350
model fit x train and we'll pass in the categorical values for white train and go ahead and say verbose

105
00:08:13,350 --> 00:08:19,260
is equal to 1 so you can see a little more details as it's training and then say e pocks and I personally

106
00:08:19,260 --> 00:08:23,100
train this model on 10 e POCs that actually takes a little bit of time.

107
00:08:23,100 --> 00:08:28,260
So if you have a slow computer you may want to lower the number of epochs and as a quick mention we

108
00:08:28,260 --> 00:08:33,780
actually have an h file for you if you have a slow computer you don't want to wait for the training

109
00:08:33,780 --> 00:08:34,360
time.

110
00:08:34,500 --> 00:08:41,160
You can load our file and the file is called and let me copy the string from our notebook.

111
00:08:41,280 --> 00:08:44,050
It's Safar underscore 10 E.

112
00:08:44,140 --> 00:08:44,870
H5.

113
00:08:45,000 --> 00:08:49,590
So if you look at our file we have a file here ready for you.

114
00:08:49,590 --> 00:08:53,610
It's fitted already to 10 e POCs if you want to use that instead of training your own.

115
00:08:53,700 --> 00:08:55,090
That's totally ok too.

116
00:08:55,110 --> 00:08:59,220
You can check out the SpaceX lecture on how to load in that sort of model.

117
00:08:59,220 --> 00:09:03,260
So we have several H5 files ready for you to go if you want to use those instead.

118
00:09:03,570 --> 00:09:06,080
I'll go ahead and fit this and let it train.

119
00:09:06,770 --> 00:09:07,970
All right so I fast forward in time.

120
00:09:07,980 --> 00:09:11,450
It looks like we're hitting around 80 percent accuracy after 20 pucks.

121
00:09:11,450 --> 00:09:12,280
That's all right.

122
00:09:12,290 --> 00:09:15,570
We could keep trying for more epochs But we'll sit on that for now.

123
00:09:15,580 --> 00:09:16,210
Now go ahead.

124
00:09:16,220 --> 00:09:18,440
Just quickly evaluate our model.

125
00:09:18,470 --> 00:09:26,210
We're going to say model number took up the metric names its loss and accuracy just as shown here.

126
00:09:26,390 --> 00:09:36,280
So let's evaluate on the Tesa we will see model that evaluate and say X test and then say y categorical

127
00:09:36,280 --> 00:09:41,620
test run that that will evaluate the model and we can see here on the test set.

128
00:09:41,730 --> 00:09:43,400
It's actually not performing super well.

129
00:09:43,440 --> 00:09:46,080
It's performing about 63 percent accuracy.

130
00:09:46,110 --> 00:09:48,510
So let's actually perform a classification report.

131
00:09:48,510 --> 00:09:53,220
There may be certain types of images that are harder to classify than others will say from S-K learn

132
00:09:54,180 --> 00:10:04,360
metrics import classification report and let's grab some new predictions off data it hasn't seen before.

133
00:10:04,680 --> 00:10:13,220
So will say model predicts classes and then person X test and let's run a classification report on that

134
00:10:13,310 --> 00:10:21,600
it will print out the classification report on why tests and predictions run that.

135
00:10:21,740 --> 00:10:23,790
And now we see a classification report.

136
00:10:23,960 --> 00:10:27,940
So we can see here it's doing fairly similar across all categories.

137
00:10:27,950 --> 00:10:31,040
It's probably Category 2 and 3 where it's not doing that well.

138
00:10:31,190 --> 00:10:35,750
But overall there isn't some category that really stands out as super well and there isn't really a

139
00:10:35,750 --> 00:10:38,140
category it sounds as very poor.

140
00:10:38,150 --> 00:10:43,760
What I want to quickly show you is we've actually trained a larger model for you in case you want to

141
00:10:43,760 --> 00:10:45,480
load it and play around with that.

142
00:10:45,740 --> 00:10:49,970
And if you actually look at our lecture notebook that corresponds with this lecture.

143
00:10:49,990 --> 00:10:55,020
So open up right here this is the Cara's CNN Safar 10 0 2 notebook.

144
00:10:55,130 --> 00:11:00,440
If you take a look at this notebook as you scroll down and go all the way to the bottom you'll notice

145
00:11:00,440 --> 00:11:02,480
there's an optional large model.

146
00:11:02,480 --> 00:11:05,870
So if you're running on a faster computer you can go ahead and run this larger model.

147
00:11:05,870 --> 00:11:11,380
We've gone ahead and added some more layers and specifically we have a much larger dense layer that's

148
00:11:11,380 --> 00:11:12,860
five hundred and twelve neurons.

149
00:11:12,860 --> 00:11:19,520
Now it can go through this and see that it actually still doesn't perform super well but it performs

150
00:11:19,580 --> 00:11:22,490
slightly better on the actual predictions.

151
00:11:22,490 --> 00:11:26,960
And we went ahead and say that as larger Safar 10 model H5.

152
00:11:27,080 --> 00:11:32,560
So feel free to play around with those values and feel free also run this for more epochs.

153
00:11:32,570 --> 00:11:36,950
We can do is also run this while you're sleeping at night in case you want to test the accuracy that

154
00:11:36,950 --> 00:11:37,370
way.

155
00:11:37,490 --> 00:11:41,030
But you can see that it begins hovering around the 70s here.

156
00:11:41,030 --> 00:11:46,190
So if you start getting very slow growth in accuracy and you're probably hitting your limits.

157
00:11:46,350 --> 00:11:46,870
OK.

158
00:11:46,970 --> 00:11:48,580
So that's it for this project.

159
00:11:48,650 --> 00:11:53,570
Coming up next we're going to expand on this and show you how to work with custom images.

160
00:11:53,570 --> 00:11:58,190
Keep in mind for these custom images we're going have to download an external data set we'll see at

161
00:11:58,190 --> 00:11:58,830
the next lecture.
