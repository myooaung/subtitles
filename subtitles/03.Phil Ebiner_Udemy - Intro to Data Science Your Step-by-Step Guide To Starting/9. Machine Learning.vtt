WEBVTT

nce of the 21st century machine learn cool science yes simple science.
1
00:00:13.200 --> 00:00:16.770
Definitely no machine learning is super broad.

2
00:00:16.910 --> 00:00:24.020
It's a huge world of many branches inside which you have many problems to solve and many impacts to

3
00:00:24.020 --> 00:00:24.520
make.

4
00:00:24.650 --> 00:00:31.400
But if you take it the right way if you take the right path instead of losing yourself in a maze you

5
00:00:31.400 --> 00:00:33.170
can smash machinery.

6
00:00:33.440 --> 00:00:39.500
And so this tutorial is exactly for that purpose to give you the right guidance to make a successful

7
00:00:39.560 --> 00:00:41.930
entrance in machine learning.

8
00:00:41.930 --> 00:00:47.800
So speaking of guidance that's directly related to the structure of your path.

9
00:00:47.840 --> 00:00:50.720
You know you will find many resources on machine learning.

10
00:00:50.840 --> 00:00:54.710
But if you decide to take them separately you will not find the right structure.

11
00:00:55.130 --> 00:01:01.040
And that's why in order to guide you in this fantastic huge world well I'm going to walk you through

12
00:01:01.280 --> 00:01:07.230
the structure of our course simply because we know that was the most important thing to work on.

13
00:01:07.310 --> 00:01:11.380
And we actually worked several months to find that ultimate structure.

14
00:01:11.630 --> 00:01:16.400
And so that's why in front of me I have the whole structure of our course machinery.

15
00:01:16.430 --> 00:01:21.400
It is that and this is not to tell you to take the course this has nothing to do with this.

16
00:01:21.440 --> 00:01:27.310
Feel free to take our course or any other course the machining course by Andrew Engy is also amazing.

17
00:01:27.350 --> 00:01:31.160
And you have some other courses on machinery on the Internet.

18
00:01:31.160 --> 00:01:32.280
They're all so great.

19
00:01:32.360 --> 00:01:38.120
I'm just thinking here the structure of our course because this is for us the best path you can take

20
00:01:38.300 --> 00:01:39.780
in your machine learning journey.

21
00:01:40.130 --> 00:01:40.970
So here we go.

22
00:01:41.090 --> 00:01:48.380
Let's start with the first step towards one data processing data processing should be the first step

23
00:01:48.470 --> 00:01:49.970
of your machine or in Journey.

24
00:01:49.970 --> 00:01:50.830
Why is that.

25
00:01:50.840 --> 00:01:56.810
It's because without their preprocessing you cannot apply your machinery models your machine or the

26
00:01:56.810 --> 00:02:04.100
models need a certain cleaned format of their inputs to be able to return the outputs because you know

27
00:02:04.280 --> 00:02:05.860
so far in 2018.

28
00:02:05.980 --> 00:02:09.650
Machine learning works on the input and output process.

29
00:02:09.650 --> 00:02:15.920
You feed your machine or animal with some input and it will return some output whether it is something

30
00:02:15.920 --> 00:02:21.890
you know you want to predict that's supervised mission learning or something you don't even know you

31
00:02:21.890 --> 00:02:25.790
want to identify which is unsupervised machine learning.

32
00:02:25.790 --> 00:02:28.970
So data processing is essential.

33
00:02:29.030 --> 00:02:34.520
And as you can see we tell you everything we give you the central steps how to import the data sets

34
00:02:34.760 --> 00:02:40.880
how to handle missing data how to smash categorical data splitting the data set into the training set

35
00:02:41.030 --> 00:02:47.060
to train your model and it's set to test your model features scaling to put all the variables onto the

36
00:02:47.060 --> 00:02:54.140
same scale and we give you a template so that you can save a lot of time on data processing.

37
00:02:54.140 --> 00:02:55.330
So that's the first step.

38
00:02:55.340 --> 00:03:01.220
Don't forget it because the more you work on it the more you handle it the better your future machine

39
00:03:01.220 --> 00:03:02.410
or journey will be.

40
00:03:02.780 --> 00:03:09.790
And then speaking of this machine learning journey there it goes because the next step is regression.

41
00:03:10.010 --> 00:03:12.650
That's the part 2 of our machinery of course.

42
00:03:12.800 --> 00:03:18.660
And in this part we tackle all the essential regression modules.

43
00:03:18.710 --> 00:03:26.270
So what is regression regression is when you want to predict continuous real number like a salary or

44
00:03:26.450 --> 00:03:29.460
a temperature or an energy output.

45
00:03:29.510 --> 00:03:34.850
You will see that in the Python section we will solve a regression problem and we will have to predict

46
00:03:35.120 --> 00:03:36.340
some energy output.

47
00:03:36.560 --> 00:03:38.270
Well that's regression.

48
00:03:38.270 --> 00:03:43.390
And you have many regression models we introduce you to the most useful ones.

49
00:03:43.470 --> 00:03:49.880
Simple regression when you have one feature to predict something multipole in their regression where

50
00:03:49.880 --> 00:03:55.070
you have several features to predict something polynomial regression when the relationships between

51
00:03:55.310 --> 00:04:01.910
what you want to predict and the predictors is not linear then support vector regression another regression

52
00:04:01.910 --> 00:04:08.510
model based on as VM support vector machines decision tree regression and random for us regression.

53
00:04:08.690 --> 00:04:13.970
And in the end you need to know how to evaluate the performance of your regression models and we give

54
00:04:13.970 --> 00:04:16.340
you the right tools for the right metrics.

55
00:04:16.340 --> 00:04:17.710
Which other means quit.

56
00:04:17.960 --> 00:04:24.320
The R-squared and just add R-squared and then we also provide some regularisation method in order to

57
00:04:24.320 --> 00:04:26.130
avoid overfilling.

58
00:04:26.150 --> 00:04:28.730
All right so that's the second step regression.

59
00:04:28.820 --> 00:04:37.000
And then what comes next is Step 3 classification so classification is this time about predicting a

60
00:04:37.010 --> 00:04:39.830
category or what we call a class.

61
00:04:39.830 --> 00:04:42.680
So that's a discrete category you want to predict.

62
00:04:42.680 --> 00:04:49.040
For example the winner of a football game or the next president of the United States or the winner of

63
00:04:49.040 --> 00:04:54.020
the Super Bowl or if yes or no your customer will buy your next product.

64
00:04:54.020 --> 00:05:00.210
So very useful and actually this can be applicable to many business problems whether it is in sales

65
00:05:00.210 --> 00:05:07.510
and marketing or any other business purpose and again for classification you have several classification

66
00:05:07.510 --> 00:05:08.100
models.

67
00:05:08.280 --> 00:05:13.100
The most classic one but yet powerful one is logistic regression.

68
00:05:13.180 --> 00:05:18.630
Then you have the Canaan's then you have the super vector machine then you have the kernel as YEM for

69
00:05:18.840 --> 00:05:25.170
nonlinear problems and same base for nonlinear problems and also when they have a probabilistic approach

70
00:05:25.560 --> 00:05:29.440
then Decision Tree classification random forest classification.

71
00:05:29.610 --> 00:05:36.480
And again we give you some metrics to evaluate the performance of your classification models and that's

72
00:05:36.480 --> 00:05:43.050
a lot of models but nowhere is this is because all the data centers problems don't have the same best

73
00:05:43.170 --> 00:05:44.690
model to solve them.

74
00:05:44.730 --> 00:05:51.240
And that's why we give you several machinery models and we explain in which situation you should use

75
00:05:51.240 --> 00:05:52.360
one or the other.

76
00:05:52.590 --> 00:05:58.380
But even if that's still too much for you well you'll see in this course in the section on Python I'll

77
00:05:58.380 --> 00:06:03.990
give you the solution when you actually don't know which model to choose for your problem.

78
00:06:03.990 --> 00:06:08.000
You know when there is no prior analysis of the data set the problem.

79
00:06:08.100 --> 00:06:14.520
And when you don't know which model to choose Well there is actually one best option by default which

80
00:06:14.640 --> 00:06:17.820
is the model we will implement in the Python section.

81
00:06:17.820 --> 00:06:18.930
So you'll see what it is.

82
00:06:18.930 --> 00:06:21.060
I will let you find out the surprise.

83
00:06:21.060 --> 00:06:22.220
All right so that's next step.

84
00:06:22.230 --> 00:06:26.150
And then fourth step part for clustering.

85
00:06:26.310 --> 00:06:29.910
So clustering is designed unsupervised machine learning.

86
00:06:29.910 --> 00:06:32.190
It's when you actually don't know what to predict.

87
00:06:32.190 --> 00:06:39.570
So it can be for example identifying some segments of customers which will respond to a certain concern

88
00:06:39.570 --> 00:06:46.410
you're having but you also apply clustering for MRI scans to identify tumors in the brain.

89
00:06:46.410 --> 00:06:52.500
So clustering has many applications and it has two major models which are Kamins the most popular one

90
00:06:52.800 --> 00:06:54.880
and hierarchical clustering.

91
00:06:54.930 --> 00:06:56.390
So feel free to check them out.

92
00:06:56.400 --> 00:06:58.520
They are classic in their designs.

93
00:06:58.690 --> 00:07:06.090
Then next step is association rules or an association rule learning allows you to predict what the customers

94
00:07:06.090 --> 00:07:08.650
will buy knowing what they bought before.

95
00:07:08.820 --> 00:07:16.200
So for example you see on Amazon or other online stores people who bought also but well that's thanks

96
00:07:16.200 --> 00:07:21.570
to association with learning and it has two major models briery and Ekla.

97
00:07:21.740 --> 00:07:25.210
But I highly recommend to at least master Priory.

98
00:07:25.230 --> 00:07:26.950
It can be very useful.

99
00:07:27.060 --> 00:07:30.240
Then the next step is reinforcement learning.

100
00:07:30.270 --> 00:07:36.750
So here you know you notice we are storing the specialized branches of machine learning and that includes

101
00:07:36.750 --> 00:07:42.520
even Association learning but here reinforcement learning is even more specialized.

102
00:07:42.600 --> 00:07:48.120
And for those of you who aren't intimidated by artificial intelligence and want to get into it well

103
00:07:48.300 --> 00:07:50.700
you must start with reinforcement learning.

104
00:07:50.700 --> 00:07:56.100
I will highlight this in two or three tutorials when I introduce you to artificial intelligence but

105
00:07:56.550 --> 00:08:00.720
reinforcement learning is the foundation of artificial intelligence.

106
00:08:00.720 --> 00:08:08.820
Here we cover two powerful reinforcement learning models that can be extremely useful for business purposes

107
00:08:09.090 --> 00:08:15.560
for example to choose the right ad to show to the users so that they will click more to buy your product.

108
00:08:15.660 --> 00:08:21.820
So we do this with two reinforcement learning models are preconditions bound and Tompson sampling.

109
00:08:22.110 --> 00:08:23.320
So maybe start with this.

110
00:08:23.370 --> 00:08:29.160
And if you're interested in that maturing branch definitely continue with artificial intelligence.

111
00:08:29.160 --> 00:08:35.130
Then nextstep another specialized branch of machine learning natural language processing.

112
00:08:35.340 --> 00:08:41.550
So here actually it's interesting because natural language processing is just combining the classification

113
00:08:41.550 --> 00:08:48.510
branch of machinery which is part two with text and voice you know to apply emotion or any classification

114
00:08:48.510 --> 00:08:55.530
Mole's on text and voice to break for example if some reviews are positive or negative or to predict

115
00:08:55.560 --> 00:09:02.190
if some Twitter tweets are kind or mean or if they should be reported whatever you want and it can even

116
00:09:02.190 --> 00:09:09.180
be predicting the job of a book you know the input of your LP model can even be a book and you have

117
00:09:09.180 --> 00:09:15.000
to break the jaw of the book or it can be some newspaper articles for which you have to break the subject

118
00:09:15.150 --> 00:09:15.900
for example.

119
00:09:16.110 --> 00:09:20.420
So that's very powerful and that's widely used in modern applications.

120
00:09:20.420 --> 00:09:28.570
They like chat boards or assistants or any other products that integrate text or voice then nextstep

121
00:09:28.690 --> 00:09:29.870
deep learning.

122
00:09:29.910 --> 00:09:32.060
You probably have heard of deeper.

123
00:09:32.070 --> 00:09:35.660
This is one of the most powerful branch of machine learning.

124
00:09:35.820 --> 00:09:42.210
And we introduce you to neural networks and we call them artificial neural networks as opposed to the

125
00:09:42.210 --> 00:09:48.690
real neural networks inside the human brains and we apply them for a business problem which is to predict

126
00:09:48.780 --> 00:09:52.320
which customers are more likely to leave a bank.

127
00:09:52.440 --> 00:09:55.050
And that problem is called customer churn.

128
00:09:55.050 --> 00:10:01.380
Then we also have the convolutional neural networks which are like adding AIs to your previous artificial

129
00:10:01.380 --> 00:10:07.490
neural networks because basically these convolutional layers the model can really look at images.

130
00:10:07.530 --> 00:10:13.480
And for example predict what's inside them detect some object or recognize some features.

131
00:10:13.500 --> 00:10:19.320
So these are very powerful and these are why you say in deep hearing and of course if you're interested

132
00:10:19.320 --> 00:10:20.890
in deep mourning Carol.

133
00:10:20.910 --> 00:10:26.230
We'll introduce you to deep learning in the next tutorial to say more about this.

134
00:10:26.490 --> 00:10:30.350
And then the next step is dimensionality reduction.

135
00:10:30.420 --> 00:10:37.500
Once you master all the previous branches of machinery you will need to push your analysis further by

136
00:10:37.500 --> 00:10:42.280
considering some even more powerful tools to solve your machinery problems.

137
00:10:42.360 --> 00:10:48.360
And one of them is dimensionality reduction because today we're working with some huge and huge amount

138
00:10:48.360 --> 00:10:51.510
of data and sometimes we work with terabytes of data.

139
00:10:51.750 --> 00:10:59.970
And for this you need some techniques to reduce the dimensionality of your dataset dimensionality reduction

140
00:10:59.970 --> 00:11:05.200
can be essential for this kind of data set and to improve even more humas.

141
00:11:05.220 --> 00:11:12.240
And so we introduce you to the most powerful dimensionality reduction techniques principal components

142
00:11:12.250 --> 00:11:18.840
analysis linear or discriminants analysis and kernel PCa in case the data relationships inside your

143
00:11:18.840 --> 00:11:20.860
data are not linear.

144
00:11:21.120 --> 00:11:21.590
All right.

145
00:11:21.600 --> 00:11:26.010
And then final step parts and model selection and boosting.

146
00:11:26.010 --> 00:11:30.620
Actually today we say that there are two most powerful machinery modules.

147
00:11:30.630 --> 00:11:38.100
These are deep remodels and extra boost and that's why right here we introduce you to this graden with

148
00:11:38.110 --> 00:11:38.600
Steimle.

149
00:11:38.610 --> 00:11:42.950
It is a gradient boosting model for you to have this model in your tool kit.

150
00:11:43.260 --> 00:11:49.020
And also we have this model selection section because most of the time you have several options and

151
00:11:49.020 --> 00:11:54.360
you actually don't know which one is best but that's OK because there are some what we call model selection

152
00:11:54.360 --> 00:12:01.590
techniques which can help you find this best Moe and it help you find this best model by applying K4

153
00:12:01.620 --> 00:12:08.080
cross-validation which is the most relevant way of evaluating the performance of your model.

154
00:12:08.310 --> 00:12:11.760
But we combine everything in what we call the pipeline.

155
00:12:11.940 --> 00:12:19.470
We combine people cross-validation to what we call grid search to find the best hyper parameters that

156
00:12:19.470 --> 00:12:27.120
will lead to the best accuracy or other performance metric measured by this careful preservation technique

157
00:12:27.480 --> 00:12:32.510
which I'll say it again is the most relevant way to measure the performance of your model.

158
00:12:32.520 --> 00:12:38.570
So these are essential to know in science but that's of course to be applied after you build your machinery

159
00:12:38.570 --> 00:12:39.290
models.

160
00:12:39.310 --> 00:12:40.660
That's why it's important.

161
00:12:40.740 --> 00:12:43.750
The last step and that's the end of the journey.

162
00:12:43.830 --> 00:12:49.320
We know it is a long journ
