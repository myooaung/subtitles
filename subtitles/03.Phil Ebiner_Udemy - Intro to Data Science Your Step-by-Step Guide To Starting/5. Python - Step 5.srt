1
00:00:04,770 --> 00:00:12,540
Hello and welcome to this new life and so we are adding for data sets in the previous tutorial and now

2
00:00:12,680 --> 00:00:13,750
you code section.

3
00:00:13,790 --> 00:00:20,470
We are going to split the data set that is we're going to split x and y into a training set and it tests

4
00:00:20,470 --> 00:00:21,210
it.

5
00:00:21,270 --> 00:00:27,870
So I remind that a training set will be the subset of the whole dataset which will train our future

6
00:00:27,870 --> 00:00:35,040
model that will build in the next Etoile and a test set will be to test the model on new observations

7
00:00:35,040 --> 00:00:41,880
that weren't used for the training and therefore it will be exactly like having some brand new observations

8
00:00:42,150 --> 00:00:47,790
on which the model has no idea of the outcome because it wasn't trained on this set and therefore it

9
00:00:47,790 --> 00:00:52,410
will be interesting to see the predictive power on new observations.

10
00:00:52,410 --> 00:00:55,410
But we'll see that in the final story of the section.

11
00:00:55,470 --> 00:01:01,710
But for now let's split this data set and to do this we're going to use a function by sikat learn and

12
00:01:01,710 --> 00:01:03,770
sikat learn welcome to it.

13
00:01:03,780 --> 00:01:06,810
It's one of the best machine learning libraries.

14
00:01:06,810 --> 00:01:12,830
It contains an amazing collection of machinery models all into classes objects.

15
00:01:12,840 --> 00:01:18,750
Functions that you can use to make your predictions whether you're dealing with regression classification

16
00:01:19,110 --> 00:01:20,860
or clustering.

17
00:01:20,870 --> 00:01:28,020
No new right now we're going to cycle learn to split the data into training set in a set but also the

18
00:01:28,020 --> 00:01:33,220
model creates in the next tutorial will also be taken from sikat learn.

19
00:01:33,480 --> 00:01:34,300
So here we go.

20
00:01:34,320 --> 00:01:37,010
Let's use for the first time cycler.

21
00:01:37,110 --> 00:01:44,250
And so what we want to do now is to take a function by sikat learn which is called the train test split

22
00:01:44,250 --> 00:01:51,390
function and this function is taken from a module by Cyc learned because the cycling library is divided

23
00:01:51,390 --> 00:01:53,100
into several modules.

24
00:01:53,100 --> 00:01:59,670
One module for data pre-processing one module for regression one module that will contain some classification

25
00:01:59,670 --> 00:02:00,280
models.

26
00:02:00,420 --> 00:02:06,750
You have a lot of modules and sikat learn and the ones who want to use right now is model selection

27
00:02:07,110 --> 00:02:13,170
because this is in this module that will find the function we want to split our data set into a training

28
00:02:13,170 --> 00:02:14,780
set and a test set.

29
00:02:14,790 --> 00:02:15,570
So here we go.

30
00:02:15,600 --> 00:02:18,590
Let's import this trend to split function.

31
00:02:18,810 --> 00:02:26,370
So we need to start with a from because we will import this function from sikat learn that has a good

32
00:02:26,380 --> 00:02:27,760
name as Kaylor.

33
00:02:27,930 --> 00:02:29,750
That's the name of the library.

34
00:02:29,880 --> 00:02:35,730
And then as we said we're not directly importing it from Second learn but from a module of sikat learn

35
00:02:36,090 --> 00:02:39,750
which is called moral selection.

36
00:02:39,750 --> 00:02:45,930
And basically this model selection module contains a lot of tools to do some model selection.

37
00:02:45,930 --> 00:02:51,900
That is to select the best model for the specific challenge you're dealing with because you know that

38
00:02:52,050 --> 00:02:58,650
there is not there is definitely not the same machinery model that will work best for every problem.

39
00:02:58,650 --> 00:03:05,740
Each problem has its own best machine learning model that will work the best for this specific problem

40
00:03:06,120 --> 00:03:11,680
and that's why there is a whole model selection Mudgal anti-cyclist And so there we go.

41
00:03:11,690 --> 00:03:19,530
As Kaylor and model selection and from this module we will import the function we want which is train

42
00:03:20,580 --> 00:03:26,930
test split with underscores separating prenticed and split rights.

43
00:03:26,940 --> 00:03:28,760
That's the function here.

44
00:03:28,770 --> 00:03:33,440
The interesting thing to see is that we have our very first warning in Python.

45
00:03:33,630 --> 00:03:40,390
A scale model selection or trying to split that is Trenta split is important but unused no worries.

46
00:03:40,440 --> 00:03:42,960
Were about to use it right now.

47
00:03:43,470 --> 00:03:47,600
So this trend to split function actually returns for variables.

48
00:03:47,640 --> 00:03:53,550
The first one is X train which will be a subset of X containing the training said data.

49
00:03:53,550 --> 00:03:58,980
That is the observations or the lines that will go into the training set but of course containing the

50
00:03:58,980 --> 00:04:03,350
independent variables because X is the matrix of the enviro's.

51
00:04:03,510 --> 00:04:11,200
And the next test which same will contain the observations that will go into the test set and also containing

52
00:04:11,200 --> 00:04:12,300
the independent variables.

53
00:04:12,300 --> 00:04:19,200
Only then why train which will contain the dependent variable values that will go into the training

54
00:04:19,200 --> 00:04:25,650
data and eventually weightiest which same will contain the dependent variable values that will go into

55
00:04:25,650 --> 00:04:27,310
the test data.

56
00:04:27,420 --> 00:04:33,560
And therefore since this train to split function is now going to return for variables.

57
00:04:33,750 --> 00:04:41,610
Well the first thing we need to do is get these four variables separately which are extra in X test

58
00:04:42,830 --> 00:04:51,890
Y train and why test and now we can call the function because it Trenta split function will populate

59
00:04:52,040 --> 00:04:53,540
these four variables.

60
00:04:53,870 --> 00:04:59,140
All right so now it's time to call this function train test split.

61
00:04:59,480 --> 00:05:04,700
And since this is a function we're going to add here some parenthesis by the way the warning just disappeared

62
00:05:04,940 --> 00:05:06,410
because now we use it.

63
00:05:06,470 --> 00:05:13,250
And so now we have to specify for arguments and let's check what these arguments are to check them.

64
00:05:13,340 --> 00:05:20,660
We can go here just in front of the name of the function and then press command and control plus eye

65
00:05:21,110 --> 00:05:23,090
to inspect this function.

66
00:05:23,090 --> 00:05:29,000
And as you can see I just pressed Kim and I because I'm on a Mac and this automatically showed up which

67
00:05:29,030 --> 00:05:33,210
as you can see contains all the information of this train display function.

68
00:05:33,230 --> 00:05:38,060
So that's very practical and that's why I like spider and that's why I was saying that spider is very

69
00:05:38,060 --> 00:05:44,180
user friendly because it helps you on the same studio containing several windows implementer model.

70
00:05:44,570 --> 00:05:50,780
So I just said that we're about to input for arguments in this train display function and the first

71
00:05:50,780 --> 00:05:58,280
one is the arrays which are respectively the array of independent variables that contains the whole

72
00:05:58,400 --> 00:06:05,480
data set and that is X and the array and more precisely a vector of the dependent variable that contains

73
00:06:05,810 --> 00:06:07,300
the whole dataset.

74
00:06:07,490 --> 00:06:09,800
And so that's our first two arguments.

75
00:06:09,800 --> 00:06:16,260
These arrays here and therefore inputting first here X the matrix of an been invaluable.

76
00:06:16,490 --> 00:06:19,650
And why the vector of the dependent variable.

77
00:06:19,700 --> 00:06:21,270
That's our first two arguments.

78
00:06:21,410 --> 00:06:23,720
And then let's see what we have to input.

79
00:06:23,990 --> 00:06:31,740
Well it's the test size to test size which is the percentage of data you want to include in the test.

80
00:06:32,120 --> 00:06:37,240
And a common value we choose and which is the value I recommend is 20 percent.

81
00:06:37,340 --> 00:06:43,310
You want to keep a large enough amount of data for the training that is to train your model.

82
00:06:43,310 --> 00:06:47,300
And by large enough I mean 80 percent 80 percent is a good value.

83
00:06:47,450 --> 00:06:53,480
And then you can keep separately 20 percent of your data to test the predictive power of your model

84
00:06:53,710 --> 00:06:55,020
on your observations.

85
00:06:55,310 --> 00:07:04,780
And that is why right now I'm taking the test size arguments and I'm choosing to value 20 percent 0.2.

86
00:07:04,780 --> 00:07:05,500
All right.

87
00:07:05,630 --> 00:07:12,440
Perfect So now since the days that had around 10000 lines that is 10000 observations that means that

88
00:07:12,440 --> 00:07:19,430
I will have eight thousand observations to train the model and 2000 observations to test its predictive

89
00:07:19,430 --> 00:07:21,680
power and that's good enough.

90
00:07:21,680 --> 00:07:22,030
All right.

91
00:07:22,040 --> 00:07:24,670
And then let's have a look at the other arguments.

92
00:07:24,710 --> 00:07:27,400
There is a trend size but you don't need a trend size.

93
00:07:27,400 --> 00:07:34,340
If you put the size because basically to size and size equals one that would be redundant.

94
00:07:34,400 --> 00:07:41,540
But we're going to use this random state because this will introduce a seed in our implementation so

95
00:07:41,540 --> 00:07:47,540
that when we execute it several times we get the same split of the training set and test that if we

96
00:07:47,540 --> 00:07:53,920
didn't include a random state arguments with a specific value well by executing the code several time

97
00:07:54,170 --> 00:07:57,000
we would have different test sets and training sets.

98
00:07:57,020 --> 00:08:02,570
So you know it's just for you to have the same training center set as mine as to what I'm about to have

99
00:08:02,570 --> 00:08:03,380
here.

100
00:08:03,380 --> 00:08:10,940
All right so let's include random state here and we are going to choose the value zero you can choose

101
00:08:11,270 --> 00:08:12,440
any value you want.

102
00:08:12,560 --> 00:08:19,100
But basically if you want the same training set and to set as mine well just put random Seddiqui zero

103
00:08:19,340 --> 00:08:21,140
will get the same thing.

104
00:08:21,140 --> 00:08:22,010
And here we go.

105
00:08:22,010 --> 00:08:28,040
That's actually done we are ready to select these two lines of code and I'm going to go back to avoid

106
00:08:28,030 --> 00:08:29,620
we'll explore first.

107
00:08:30,140 --> 00:08:32,410
We select just like them again.

108
00:08:32,660 --> 00:08:34,370
We select these two lines of code.

109
00:08:34,490 --> 00:08:37,180
And what happens when we execute.

110
00:08:37,220 --> 00:08:38,070
There we go.

111
00:08:38,090 --> 00:08:44,070
Executed properly and now we have extrem X test Y trend Y test.

112
00:08:44,130 --> 00:08:48,020
So now I'm going to open all of them but I'm not going to show you this because this will take me a

113
00:08:48,020 --> 00:08:48,740
while.

114
00:08:48,770 --> 00:08:49,910
Let's do this.

115
00:08:50,150 --> 00:08:50,840
And here we go.

116
00:08:50,840 --> 00:08:52,310
I gathered everything.

117
00:08:52,550 --> 00:08:56,050
So here is extra in here is X test.

118
00:08:56,120 --> 00:08:57,140
Here is why train.

119
00:08:57,170 --> 00:08:59,120
And here is why test.

120
00:08:59,240 --> 00:09:05,090
And so basically what you need to understand is that we are going to train our regression model on these

121
00:09:05,090 --> 00:09:12,410
two sets extreme and why trends so the MO is going to understand the correlations between the independent

122
00:09:12,410 --> 00:09:15,760
variables of X strain and the dependent variable.

123
00:09:15,760 --> 00:09:16,720
In y train.

124
00:09:16,970 --> 00:09:23,990
And then once it is trained it will have all its parameters configured in a way to predict new observations

125
00:09:24,330 --> 00:09:30,170
and we will test the predictive power on some new observations which will be the observations of X test

126
00:09:30,500 --> 00:09:31,460
and weightiest.

127
00:09:31,460 --> 00:09:38,090
So what we'll do is we'll take the values of X test and put them as inputs of the moral of our future

128
00:09:38,090 --> 00:09:45,670
model then this model will outputs some predictions and we will compare these predictions with the real

129
00:09:45,670 --> 00:09:51,850
values content in weightiest So we'll have operations here and we'll see if they're close to the real

130
00:09:51,850 --> 00:09:58,210
values and if they're close to the real values that means that our model was trained well well enough

131
00:09:58,210 --> 00:10:04,390
to understand the correlations between the temperature the pressure the vacuum the humidity with the

132
00:10:04,390 --> 00:10:10,460
energy so that it can predict the energy on new observations.

133
00:10:10,460 --> 00:10:16,030
That is a new data here that werent use any time for the training.

134
00:10:16,330 --> 00:10:20,910
So I can't wait to show you this model we're going to build a powerful model.

135
00:10:20,950 --> 00:10:24,590
Actually one of the best you'll see that in the next tutorial.

136
00:10:24,640 --> 00:10:26,490
Until then enjoy the science.
