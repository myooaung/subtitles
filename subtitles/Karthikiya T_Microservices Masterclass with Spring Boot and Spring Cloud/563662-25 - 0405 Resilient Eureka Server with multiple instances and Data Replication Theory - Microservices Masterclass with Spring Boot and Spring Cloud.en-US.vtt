WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:02.010
All the services registered

00:00:02.010 --> 00:00:03.840
themselves with eudicots server.

00:00:03.840 --> 00:00:07.215
And then periodically
every 30 seconds or so.

00:00:07.215 --> 00:00:09.060
They also need to
keep on informing

00:00:09.060 --> 00:00:11.580
Eureka server that
there are still alive.

00:00:11.580 --> 00:00:13.020
And they do it by sending

00:00:13.020 --> 00:00:15.210
a rest request to
the Eureka server.

00:00:15.210 --> 00:00:18.780
If for some reason Eureka
server doesn't receive any kind

00:00:18.780 --> 00:00:22.199
of response from any
particular service,

00:00:22.199 --> 00:00:24.120
then Eureka would assume

00:00:24.120 --> 00:00:26.580
that service or the
instances down,

00:00:26.580 --> 00:00:29.415
in which case it would
update its records,

00:00:29.415 --> 00:00:31.830
as well as inform all
the other clients

00:00:31.830 --> 00:00:35.080
regarding the unavailable
to up that instance.

00:00:35.080 --> 00:00:36.830
In order to better handle

00:00:36.830 --> 00:00:40.025
such scenarios where
a service might fail,

00:00:40.025 --> 00:00:42.140
we can actually have
multiple instances of

00:00:42.140 --> 00:00:45.125
that service and have a load
balancer in front of it.

00:00:45.125 --> 00:00:48.710
However, we're going to talk
about it in next chapter.

00:00:48.710 --> 00:00:51.335
But if you really absorb

00:00:51.335 --> 00:00:54.530
the service registry or
the attacker server in

00:00:54.530 --> 00:00:56.675
itself is also a microservice

00:00:56.675 --> 00:01:00.664
and it is equally
susceptible to failure.

00:01:00.664 --> 00:01:02.750
If it is some other service,

00:01:02.750 --> 00:01:05.075
then maybe we can
afford to lose it.

00:01:05.075 --> 00:01:06.770
But we really cannot afford to

00:01:06.770 --> 00:01:09.590
lose a service like
service registry,

00:01:09.590 --> 00:01:11.390
because it plays a key role

00:01:11.390 --> 00:01:13.235
in interservice communication.

00:01:13.235 --> 00:01:16.999
We can't afford to have
failures for service registry.

00:01:16.999 --> 00:01:19.490
So in order to improve
the resiliency as well as

00:01:19.490 --> 00:01:22.355
the high availability
of service registry.

00:01:22.355 --> 00:01:24.590
We can actually create
multiple instances

00:01:24.590 --> 00:01:26.014
of service registry.

00:01:26.014 --> 00:01:28.295
And each one of them
could be running on

00:01:28.295 --> 00:01:30.800
multiple geographical
locations and

00:01:30.800 --> 00:01:33.740
have the data replicated
amongst themselves.

00:01:33.740 --> 00:01:37.564
If a service registers with
any one of these servers,

00:01:37.564 --> 00:01:41.750
then the same register
information would be cloned or

00:01:41.750 --> 00:01:44.420
replicated across all
the other servers

00:01:44.420 --> 00:01:46.655
or peers as we call it.

00:01:46.655 --> 00:01:50.300
This mechanism is called
peer communication.

00:01:50.300 --> 00:01:51.530
And in this case,

00:01:51.530 --> 00:01:53.330
if one server what to go around,

00:01:53.330 --> 00:01:55.190
we have other servers as

00:01:55.190 --> 00:01:58.520
backup to handle this
august discovery.

00:01:58.520 --> 00:02:00.470
Next, we wouldn't
actually take a look

00:02:00.470 --> 00:02:02.810
at how can we create
multiple instances of

00:02:02.810 --> 00:02:04.880
Eureka server and then have

00:02:04.880 --> 00:02:07.609
the data replicate
amongst themselves.

00:02:07.609 --> 00:02:09.200
I'm also going to demonstrate

00:02:09.200 --> 00:02:12.785
a scenario where one of
the servers would go down.

00:02:12.785 --> 00:02:14.660
And then we'll see how
other servers would

00:02:14.660 --> 00:02:17.640
take care of service discovery.
