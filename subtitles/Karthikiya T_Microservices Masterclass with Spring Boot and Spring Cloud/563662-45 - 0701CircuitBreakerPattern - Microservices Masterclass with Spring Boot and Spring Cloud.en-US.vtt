WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:03.405
Let's talk about circuit
breaker pattern.

00:00:03.405 --> 00:00:06.075
Imagine we have
multiple microservices,

00:00:06.075 --> 00:00:08.520
M1, M2, M3, and so on.

00:00:08.520 --> 00:00:10.230
Now let's say that m and receive

00:00:10.230 --> 00:00:11.760
the request from the client,

00:00:11.760 --> 00:00:16.004
and m1 has in turn send
the request to M2.

00:00:16.004 --> 00:00:18.270
Now let's say that
for whatever reason,

00:00:18.270 --> 00:00:20.339
M2 has become faulty.

00:00:20.339 --> 00:00:22.170
And so it is taken
a lot of time to

00:00:22.170 --> 00:00:25.185
respond or it's not
responding at all.

00:00:25.185 --> 00:00:27.510
In which case, this would cause

00:00:27.510 --> 00:00:30.120
the other functioning
micro-services be

00:00:30.120 --> 00:00:33.030
essentially
non-functional as well.

00:00:33.030 --> 00:00:34.515
If you're wondering why,

00:00:34.515 --> 00:00:36.470
then each of the requests would

00:00:36.470 --> 00:00:39.665
demand some crucial
resources like a thread.

00:00:39.665 --> 00:00:42.395
And if it is taking
forever to respond,

00:00:42.395 --> 00:00:44.240
then thread would just keep on

00:00:44.240 --> 00:00:46.459
waiting forever
for the response,

00:00:46.459 --> 00:00:48.020
making it an available to

00:00:48.020 --> 00:00:50.285
process other incoming requests.

00:00:50.285 --> 00:00:54.275
For example, whenever M1
sends the request to m2,

00:00:54.275 --> 00:00:56.480
a thread from its
thread pool would be

00:00:56.480 --> 00:00:58.730
picked up to solve that request.

00:00:58.730 --> 00:01:01.265
If m2 is taking
forever to respond,

00:01:01.265 --> 00:01:04.640
the thread would be unavailable
to process the request.

00:01:04.640 --> 00:01:07.040
And if there are hundreds
of requests to M2,

00:01:07.040 --> 00:01:09.890
M1 may not be having
enough threats to send

00:01:09.890 --> 00:01:10.970
requests to other functioning

00:01:10.970 --> 00:01:13.910
microservices like
m3, m5, and M6.

00:01:13.910 --> 00:01:16.430
So this is clearly
a problem way to

00:01:16.430 --> 00:01:18.610
address just because of

00:01:18.610 --> 00:01:21.475
the reason one of the
microservices is faulty.

00:01:21.475 --> 00:01:23.470
It is causing the
entire application

00:01:23.470 --> 00:01:25.285
to be non-functional.

00:01:25.285 --> 00:01:27.475
And as you might have guessed,

00:01:27.475 --> 00:01:31.270
if we use React to programming
using Spring Web Flux,

00:01:31.270 --> 00:01:34.105
then this is not all
that often a problem.

00:01:34.105 --> 00:01:35.440
But if you're making

00:01:35.440 --> 00:01:38.185
synchronous calls
using rest template,

00:01:38.185 --> 00:01:41.485
then this is surely a
problem we need to address.

00:01:41.485 --> 00:01:43.945
You would most certainly
come across with this issue.

00:01:43.945 --> 00:01:46.180
And real-time applications.

00:01:46.180 --> 00:01:49.015
Historx would come for
rescue in this case,

00:01:49.015 --> 00:01:50.590
instructs would kind of act like

00:01:50.590 --> 00:01:52.930
a wrapper to send the request.

00:01:52.930 --> 00:01:54.160
This time.

00:01:54.160 --> 00:01:56.680
Whenever I'm months
sensory posts to m2.

00:01:56.680 --> 00:01:59.985
If M two response back
on time, that's fine.

00:01:59.985 --> 00:02:01.685
Everything would be normal.

00:02:01.685 --> 00:02:03.620
If it doesn't if it is taken

00:02:03.620 --> 00:02:05.480
longer than the configured time,

00:02:05.480 --> 00:02:09.500
then high-stakes would just
simply break the circuit and

00:02:09.500 --> 00:02:11.300
the circuit trips so that

00:02:11.300 --> 00:02:13.430
no further calls
will be made on.

00:02:13.430 --> 00:02:16.205
No further requests
would be sent to m2,

00:02:16.205 --> 00:02:20.180
so that at least threats
would be available to send

00:02:20.180 --> 00:02:22.610
requests to other
functioning microservices

00:02:22.610 --> 00:02:24.155
which are working fine.

00:02:24.155 --> 00:02:25.850
And so at least some of

00:02:25.850 --> 00:02:28.025
the application would
be up and running.

00:02:28.025 --> 00:02:31.100
In order to compensate
the loss of M2.

00:02:31.100 --> 00:02:32.870
Hystrix will allow
us to configure

00:02:32.870 --> 00:02:35.360
a fallback mechanism
where we can

00:02:35.360 --> 00:02:37.805
execute some default behavior

00:02:37.805 --> 00:02:40.955
that would compensate
the loss of M2.

00:02:40.955 --> 00:02:42.755
But at the same time,

00:02:42.755 --> 00:02:44.150
Hystrix would keep track of

00:02:44.150 --> 00:02:47.210
M2 and see if it has
come back to normal.

00:02:47.210 --> 00:02:49.385
Once it comes back to normal,

00:02:49.385 --> 00:02:53.225
instincts would again start
sending the request to M2.

00:02:53.225 --> 00:02:56.030
Essentially, Hystrix is
making our application more

00:02:56.030 --> 00:02:59.780
fault-tolerant and
less prone to errors.

00:02:59.780 --> 00:03:02.705
Now, I'm not an electrical guy.

00:03:02.705 --> 00:03:05.420
But if you're coming from
electrical background and then

00:03:05.420 --> 00:03:08.420
you can go let what I mean
by breaking a circuit.

00:03:08.420 --> 00:03:11.750
I guess it has something to
do with breaking the circuit.

00:03:11.750 --> 00:03:15.590
The fault is detected
and then resuming

00:03:15.590 --> 00:03:17.600
the service once the fault

00:03:17.600 --> 00:03:20.045
is rectified something
in those lines.

00:03:20.045 --> 00:03:22.700
Next, we're going to see
how we can implement

00:03:22.700 --> 00:03:25.805
circuit breaker pattern
in our application.

00:03:25.805 --> 00:03:27.410
We'll even see how we can have

00:03:27.410 --> 00:03:31.500
a fallback mechanism to
compensate the loss.
