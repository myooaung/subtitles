WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:03.210
Okay, Now that we have
configured ZIP can let

00:00:03.210 --> 00:00:04.440
us take a look at everything in

00:00:04.440 --> 00:00:06.970
action with a quick example.

00:00:08.000 --> 00:00:12.060
I already have all the
microservices up and running.

00:00:12.060 --> 00:00:13.874
Let us go to Postman

00:00:13.874 --> 00:00:17.775
and send the request
to product service.

00:00:17.775 --> 00:00:22.840
Let's take a look at how
everything looks on Zip can UI.

00:00:22.840 --> 00:00:25.760
But before that,
let us get hold of

00:00:25.760 --> 00:00:27.890
the trace ID that got

00:00:27.890 --> 00:00:31.459
propagated that corresponds
to that request.

00:00:31.459 --> 00:00:35.720
We go to zip can and we
can search stressors based

00:00:35.720 --> 00:00:40.370
on the trace ID and would
be taken to this page.

00:00:40.370 --> 00:00:43.025
If you don't have
dress ID handy,

00:00:43.025 --> 00:00:44.900
then you can also search

00:00:44.900 --> 00:00:47.790
dress as based on
the service name.

00:00:48.190 --> 00:00:51.245
You can choose a
service of your choice.

00:00:51.245 --> 00:00:54.154
Let us just brought
service for instance.

00:00:54.154 --> 00:00:56.975
You can also choose
the duration.

00:00:56.975 --> 00:01:00.530
Would like to fetch
all the traces that

00:01:00.530 --> 00:01:04.380
are within the past 15 minutes.

00:01:05.260 --> 00:01:08.675
You'd have the trace
which when you click,

00:01:08.675 --> 00:01:10.400
you'll be taken
to the same page,

00:01:10.400 --> 00:01:13.505
what we have seen a moment ago.

00:01:13.505 --> 00:01:16.700
You also have other
ways to filter.

00:01:16.700 --> 00:01:21.035
For example, you can
filter by max duration,

00:01:21.035 --> 00:01:23.045
mean duration or tack query.

00:01:23.045 --> 00:01:25.850
In this case, the duration
is about 1 second,

00:01:25.850 --> 00:01:30.035
roughly it's 1.078 seconds.

00:01:30.035 --> 00:01:38.555
Maybe I can choose MIN
duration, ten milliseconds.

00:01:38.555 --> 00:01:41.990
I want to fetch all the traces

00:01:41.990 --> 00:01:45.575
with the minimum duration
of ten milliseconds.

00:01:45.575 --> 00:01:48.770
This might come in handy
when you don't have dress

00:01:48.770 --> 00:01:50.240
ID and you don't know

00:01:50.240 --> 00:01:54.230
the service name that might
be involved in the request.

00:01:54.230 --> 00:01:57.360
Once you run the query,

00:01:57.640 --> 00:02:01.700
you would again see all
the traces and get a sense

00:02:01.700 --> 00:02:03.590
of boot service you need to look

00:02:03.590 --> 00:02:06.870
into and find the problem.

00:02:07.390 --> 00:02:10.760
Similarly, we got that query,

00:02:10.760 --> 00:02:14.480
an example of which on how
to use it as given here.

00:02:14.480 --> 00:02:17.420
You can specify
multiple parameters or

00:02:17.420 --> 00:02:22.040
tags with an end RR.

00:02:22.040 --> 00:02:24.710
So for example,
you can filter out

00:02:24.710 --> 00:02:29.150
all the traces that
correspond to a post request.

00:02:29.150 --> 00:02:32.070
For instance.

00:02:32.980 --> 00:02:36.150
Let us go here.

00:02:37.480 --> 00:02:41.120
Let me choose product
service for instance.

00:02:41.120 --> 00:02:44.915
You can also fold the filter
out using a span name,

00:02:44.915 --> 00:02:47.690
which is nothing
but the endpoint.

00:02:47.690 --> 00:02:49.925
You could be having
multiple requests

00:02:49.925 --> 00:02:51.800
coming to the same service,

00:02:51.800 --> 00:02:53.720
but to different endpoints,

00:02:53.720 --> 00:02:56.870
in which case you can choose
endpoint or what we call

00:02:56.870 --> 00:03:01.020
span name and filter out
the traces accordingly.

00:03:02.530 --> 00:03:05.630
Assume that we have an
issue that our customers

00:03:05.630 --> 00:03:08.030
might be experiencing
without application.

00:03:08.030 --> 00:03:11.900
And as somebody who is
trying to debug the issue,

00:03:11.900 --> 00:03:14.570
you can get hold of
the trace ID from

00:03:14.570 --> 00:03:18.605
the logs and search the
traces and zip kin.

00:03:18.605 --> 00:03:21.050
Or you can filter out
based on the service name

00:03:21.050 --> 00:03:23.630
that you suspect might
be having issues.

00:03:23.630 --> 00:03:26.450
But if you don't
know either of them,

00:03:26.450 --> 00:03:29.120
you can take a look at
all the traces within

00:03:29.120 --> 00:03:34.710
a particular time span are
with the response code, etc.

00:03:34.840 --> 00:03:38.460
So let's click on this.

00:03:39.730 --> 00:03:43.430
Let us start from this
section right here.

00:03:43.430 --> 00:03:46.295
It already duration to
process this request

00:03:46.295 --> 00:03:49.850
is around 1.078 seconds.

00:03:49.850 --> 00:03:52.250
And total number of
services and mold

00:03:52.250 --> 00:03:55.070
our three because we
have products service,

00:03:55.070 --> 00:03:56.150
which is making call to

00:03:56.150 --> 00:03:58.940
both pricing as well
as inventory service.

00:03:58.940 --> 00:04:01.490
And depth is two.

00:04:01.490 --> 00:04:03.980
That's because we don't have

00:04:03.980 --> 00:04:05.120
any other services down

00:04:05.120 --> 00:04:08.090
the line that we're
making call to.

00:04:08.090 --> 00:04:10.550
For example, let's say
we have service one,

00:04:10.550 --> 00:04:12.560
service to and service three.

00:04:12.560 --> 00:04:14.960
This one is making
call to service

00:04:14.960 --> 00:04:19.220
to service to his making
call to service three.

00:04:19.220 --> 00:04:22.805
In that case, the
depth would be three.

00:04:22.805 --> 00:04:25.100
In order to better explain this,

00:04:25.100 --> 00:04:27.200
I have actually got

00:04:27.200 --> 00:04:30.110
an image from the
official ZIP can cite.

00:04:30.110 --> 00:04:34.745
This sort of demonstrates
what I'm talking about.

00:04:34.745 --> 00:04:38.045
So here we have four
levels of service call.

00:04:38.045 --> 00:04:42.439
We have routing, which is
calling the main service,

00:04:42.439 --> 00:04:47.880
which in turn is
calling them cash.

00:04:47.980 --> 00:04:51.500
Then we have Yelp
service which is

00:04:51.500 --> 00:04:54.905
making call to a bunch
of other services.

00:04:54.905 --> 00:05:00.395
So that's 12344 levels
of service call,

00:05:00.395 --> 00:05:03.530
which means depth of four.

00:05:03.530 --> 00:05:06.665
There are total of
ten services involved

00:05:06.665 --> 00:05:11.120
because memcache is being
called multiple times.

00:05:11.120 --> 00:05:12.590
If you take a look at number of

00:05:12.590 --> 00:05:14.270
unique services that are

00:05:14.270 --> 00:05:16.655
involved to process
this request.

00:05:16.655 --> 00:05:19.110
The number would be ten.

00:05:19.420 --> 00:05:22.910
There are total of 13 spans

00:05:22.910 --> 00:05:25.355
for each and every
individual operation.

00:05:25.355 --> 00:05:28.205
We have a unique span
idea associated.

00:05:28.205 --> 00:05:30.560
We also have the trace ID that

00:05:30.560 --> 00:05:33.510
represents the
entire transaction.

00:05:33.730 --> 00:05:37.070
On the right you can see
the information that

00:05:37.070 --> 00:05:40.250
is specific to the service
that we've chosen here.

00:05:40.250 --> 00:05:43.835
In this case, we've chosen
the product service,

00:05:43.835 --> 00:05:45.815
and its corresponding
information.

00:05:45.815 --> 00:05:47.465
We have span ID,

00:05:47.465 --> 00:05:51.470
which is same as the trace
ID because fructose is

00:05:51.470 --> 00:05:53.870
a first service
which is involved in

00:05:53.870 --> 00:05:56.570
the request for service.

00:05:56.570 --> 00:06:00.215
For the span ID as well as
the trace ID would be same.

00:06:00.215 --> 00:06:04.565
By default. We have
bid and ID as none.

00:06:04.565 --> 00:06:06.890
Parent idea is nothing but if

00:06:06.890 --> 00:06:09.545
service is calling service B,

00:06:09.545 --> 00:06:12.575
then service B spirit
idea would be,

00:06:12.575 --> 00:06:14.795
we say span ID.

00:06:14.795 --> 00:06:18.965
You'd better understand
it with pricing service.

00:06:18.965 --> 00:06:22.685
Inside pricing service,
we have span ID,

00:06:22.685 --> 00:06:25.040
which is different
from the trace ID.

00:06:25.040 --> 00:06:27.155
We have parent ID,

00:06:27.155 --> 00:06:31.205
which is a span ID of
its parent Service,

00:06:31.205 --> 00:06:33.350
which is the product service.

00:06:33.350 --> 00:06:36.290
Let's go to inventory service.

00:06:36.290 --> 00:06:38.780
We have the unexpanded AT that

00:06:38.780 --> 00:06:40.955
is specific to that operation.

00:06:40.955 --> 00:06:43.400
And its parent ID is going to be

00:06:43.400 --> 00:06:46.190
the span ID of the
product service.

00:06:46.190 --> 00:06:48.080
Just by looking at this,

00:06:48.080 --> 00:06:50.150
you will get a
complete picture as to

00:06:50.150 --> 00:06:53.075
what's happening and where
the problem might be.

00:06:53.075 --> 00:06:54.860
Even somebody who doesn't have

00:06:54.860 --> 00:06:56.870
any experience in using zip kin.

00:06:56.870 --> 00:06:58.340
It can actually
figure out something

00:06:58.340 --> 00:07:00.290
from the stresses compared

00:07:00.290 --> 00:07:01.880
to the manually
checking the logs

00:07:01.880 --> 00:07:04.055
off each and every
micro-service.

00:07:04.055 --> 00:07:05.630
They can, for example,

00:07:05.630 --> 00:07:08.990
take a look at the duration
of each service hop.

00:07:08.990 --> 00:07:12.560
The total time it took
is 1 second note of

00:07:12.560 --> 00:07:17.330
which pricing service has
taken for 40 milliseconds.

00:07:17.330 --> 00:07:21.110
And inventory service
is about 1 second.

00:07:21.110 --> 00:07:24.200
1 other services
taking way too long.

00:07:24.200 --> 00:07:25.820
They can check the logs off

00:07:25.820 --> 00:07:29.315
that service and try to
solve the latency issues.

00:07:29.315 --> 00:07:32.580
Let us continue from next video.
