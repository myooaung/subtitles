WEBVTT
1
00:00:00.300 --> 00:00:03.510
Hello everyone and welcome to this python tutorial.

2
00:00:03.510 --> 00:00:08.970
In this video we are going to perform data analysis and validation with tens offload data validation

3
00:00:08.970 --> 00:00:10.200
package.

4
00:00:10.260 --> 00:00:17.250
We will talk about the concept of schema and what is its use for data analysis and generate some statistics

5
00:00:17.280 --> 00:00:19.440
based on our training data.

6
00:00:19.650 --> 00:00:25.470
In the previous video we use the described function to generate some statistics based on our training

7
00:00:25.470 --> 00:00:27.780
data and test the data.

8
00:00:28.070 --> 00:00:28.970
And that was cool.

9
00:00:28.980 --> 00:00:32.080
But those statistics are relatively small.

10
00:00:32.100 --> 00:00:38.520
We had the minimum standard deviation and some other column information but nothing more than that.

11
00:00:38.550 --> 00:00:46.440
In contrast we had the training data and statistics generated by tensor flow data validation package.

12
00:00:46.440 --> 00:00:50.960
Those statistics will describe the whole structure of the data set.

13
00:00:50.970 --> 00:00:57.570
Firstly let us do that and afterwards we will explain why the concept of schema actually is let's write

14
00:00:57.920 --> 00:01:04.040
trains that is equal to t of DV which is our tens of flow data validation package.

15
00:01:04.140 --> 00:01:10.140
Then we will have to write dot generate and it is going to offer you a few things that you can choose

16
00:01:10.140 --> 00:01:11.040
from.

17
00:01:11.160 --> 00:01:17.880
We can generate statistics from CSB data frame and tell the flow record since we already loaded our

18
00:01:17.880 --> 00:01:23.530
data set using Panda's library we are going to use that from data frame.

19
00:01:23.580 --> 00:01:31.980
If you were to use directly on the CSC that we uploaded to our Google collab you can use that from the

20
00:01:31.980 --> 00:01:33.800
CSP function here.

21
00:01:33.810 --> 00:01:40.290
As we said we will select the data frame one and we can provide a few things to this function in our

22
00:01:40.290 --> 00:01:40.650
case.

23
00:01:40.650 --> 00:01:47.370
We only need to provide the data frame name besides the data frame you can provide number of jobs which

24
00:01:47.370 --> 00:01:51.040
represents a number of processes that will run this function.

25
00:01:51.120 --> 00:01:54.690
If you have the bigger data set you will should go for this.

26
00:01:54.720 --> 00:01:59.370
For example if you had a CPO with four course you would specify four.

27
00:01:59.370 --> 00:02:05.730
Under this argument and this function will utilize all four cores to faster process the whole dataset

28
00:02:06.940 --> 00:02:12.490
let's provide the data frame to this function let's say data frame is equal to data set.

29
00:02:12.520 --> 00:02:19.070
Execute a cell and it is going to generate some statistics for us those statistics that we generate

30
00:02:19.070 --> 00:02:25.640
the right now are for example column information data information in everything we can compare our training

31
00:02:25.640 --> 00:02:34.170
set to our new dataset now that we have our statistics it is time to generate our schema the concept

32
00:02:34.170 --> 00:02:40.620
of schema is the most important concept in the tens offload data validation package it is going to contain

33
00:02:40.740 --> 00:02:47.600
every single information about our training dataset and use that information to check our newly received

34
00:02:47.610 --> 00:02:54.660
the data how good is it is there are some anomalies or differences based on that information it is going

35
00:02:54.660 --> 00:03:00.810
to proceed further in the end to end pipeline the schema concept and object is going to contain information

36
00:03:00.810 --> 00:03:08.220
such as column data types is the column numerical or categorical is the column is a must or there is

37
00:03:08.230 --> 00:03:14.520
an option to be an absent then what is the distribution of that column is it normal distribution or

38
00:03:14.580 --> 00:03:16.610
union from 1 and so on.

39
00:03:16.680 --> 00:03:22.290
All of these statistics about the dataset are going to be incorporated in the schema and use that to

40
00:03:22.290 --> 00:03:29.640
compare our training dataset to our newly received dataset and that's why we have to generate and create

41
00:03:29.670 --> 00:03:39.960
our schema let's do this step type schema is equal to t of DV dot infers schema and then as you can

42
00:03:39.960 --> 00:03:43.140
see there are few things that we need to provide.

43
00:03:43.560 --> 00:03:49.740
The first one and the most important one for us is our statistics and that is our train stats that we

44
00:03:49.740 --> 00:03:55.350
calculated in the previous step the next two arguments can be left as they are.

45
00:03:55.350 --> 00:04:02.970
So we will see statistics is equal to train stats and executor so it is going to generate our schema.

46
00:04:03.300 --> 00:04:08.400
For now we don't have any information what it looks like and what information it contains.

47
00:04:08.400 --> 00:04:13.770
So let's use a function to display the schema the function that we are going to use for this is very

48
00:04:13.770 --> 00:04:14.490
intuitive.

49
00:04:14.550 --> 00:04:21.600
It is t v the display schema and this function takes only one argument and that is the schema that you

50
00:04:21.600 --> 00:04:22.820
want to display.

51
00:04:23.160 --> 00:04:30.360
As you can see to recognize all columns in our dataset the type of the column whether it is required

52
00:04:30.360 --> 00:04:37.890
or not if this were categorical data it would be even recognized the domain of the data set and so on.

53
00:04:38.050 --> 00:04:43.740
You can see that it contains every single information that we need to describe the data set and compare

54
00:04:43.740 --> 00:04:49.720
it would receive the data and that's it for now in the next video we are going to generate our test

55
00:04:49.720 --> 00:04:53.990
statistics if you have any questions or comments so far.

56
00:04:54.290 --> 00:04:58.460
Please post them in the comments section otherwise the scene the next tutorial.
