1
00:00:00,390 --> 00:00:03,690
Hello everyone and welcome to this biting tutorial.

2
00:00:03,780 --> 00:00:10,150
In this video we are going to pre process and prepared the data set for the training of our neural network.

3
00:00:10,260 --> 00:00:13,990
So before we jump into the data set pre processing.

4
00:00:14,070 --> 00:00:21,240
Well as this comes a few libraries that we have to import for the project the first one is ice.

5
00:00:21,270 --> 00:00:29,040
It helps us with working with folders and perhaps the Jason library is maybe the most important library

6
00:00:29,130 --> 00:00:30,690
for this section.

7
00:00:30,840 --> 00:00:37,770
If you haven't worked with Jason before it is a way of receiving and sending data over the Internet.

8
00:00:37,830 --> 00:00:40,830
It looks basically like a Python dictionary.

9
00:00:40,830 --> 00:00:46,570
It will help us to send data to the model then we have the random library.

10
00:00:46,610 --> 00:00:52,380
It will help us to choose random images from the data set to perform our predictions.

11
00:00:52,420 --> 00:00:57,040
So process is a library to be working with multiple threads in the code.

12
00:00:57,380 --> 00:01:03,230
Probably we won't use it at all in this section just imported in the case.

13
00:01:03,230 --> 00:01:04,540
Then we have none by.

14
00:01:04,610 --> 00:01:11,360
And as always it is a library of choice to work with math operations and matrices that the flow is here

15
00:01:11,360 --> 00:01:16,190
to build neural networks and multiple partly to visualize the data set.

16
00:01:16,190 --> 00:01:24,400
Images the data said that we are going to use for this project is safer than in the last line in this

17
00:01:24,400 --> 00:01:29,520
cell with this percentage is called Magic command.

18
00:01:29,600 --> 00:01:35,230
It is there to specify to note that all visualization should be kept inside of it.

19
00:01:36,650 --> 00:01:43,040
And lastly we print the version of the tensor flow to make sure that we are using one point thirteen

20
00:01:43,040 --> 00:01:50,250
point one since the tensor flows serving is not working well yet on the tensor flow 2.0.

21
00:01:51,130 --> 00:01:57,400
But don't worry all the things that we are going to write for our dissection will work perfectly in

22
00:01:57,400 --> 00:01:59,160
the tens of float 2.0 as well.

23
00:01:59,680 --> 00:02:08,950
Let me jump to the data said processing the first thing for this lesson is to load the data set when

24
00:02:08,950 --> 00:02:16,600
using the Load method for the tens of low data set it returns to outputs one for the training and other

25
00:02:16,600 --> 00:02:17,970
one for testing.

26
00:02:18,220 --> 00:02:25,220
Each can be split up into two more parts features and labels now that we know that.

27
00:02:25,260 --> 00:02:30,090
Let's write in brackets X train y train comma.

28
00:02:30,300 --> 00:02:38,810
Then getting brackets x test y test and that is equal to C for 10 that load data.

29
00:02:38,880 --> 00:02:44,460
This function doesn't take any arguments just execute the cell and the function will download the data

30
00:02:44,460 --> 00:02:49,860
set and stored and loaded in our environment OK.

31
00:02:49,870 --> 00:02:56,630
The data set is downloaded and ready to be used in the meantime I've created this array of all class

32
00:02:56,630 --> 00:02:59,250
names found in the separate end data set.

33
00:03:00,340 --> 00:03:08,260
If you wonder how I knew what class names are you can find them on the C for 10 main page listed here

34
00:03:08,260 --> 00:03:16,890
from airplane to the truck the next part of the dataset pre processing is to normalize images so let's

35
00:03:16,890 --> 00:03:17,960
write x.

36
00:03:17,970 --> 00:03:26,560
Train is equal to x train divided by two hundred fifty five point zero since this is the maximum value

37
00:03:26,590 --> 00:03:30,930
of a pixel found in an image we are defining that to scale.

38
00:03:30,940 --> 00:03:39,580
All images in the train said to be between 0 and 1 let's perform the same scaling method on the test

39
00:03:39,580 --> 00:03:41,470
set as well right.

40
00:03:41,470 --> 00:03:50,940
X test is equal to x test divided by two hundred fifty five point zero and we have all images scaled.

41
00:03:51,180 --> 00:03:56,270
The last thing for this video is to track the shape of the data set right.

42
00:03:56,280 --> 00:04:04,290
X train dart shape as you can see we have fifty thousand images in the training set each is thirty two

43
00:04:04,290 --> 00:04:07,460
by forty two by three.

44
00:04:07,590 --> 00:04:14,640
These free at the end is because we are working with colored images so our GP each will represent each

45
00:04:14,640 --> 00:04:17,650
colour channel and that's it.

46
00:04:17,650 --> 00:04:22,120
If you have any questions or comments please post them in the comments section.

47
00:04:22,120 --> 00:04:24,070
Otherwise I've seen the next tutorial.
