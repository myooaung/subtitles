WEBVTT
1
00:00:00.390 --> 00:00:06.270
Hello everyone and welcome to the distributed training section of the course in this section we will

2
00:00:06.270 --> 00:00:14.690
talk about the ways on how to train a single model on multiple Jeep use computers or even servers.

3
00:00:14.690 --> 00:00:22.380
The first question is why do we need distributed training at all when we have a complex machine learning

4
00:00:22.380 --> 00:00:23.100
model.

5
00:00:23.250 --> 00:00:29.440
It can take days or even weeks to complete the training process did it through with the training is

6
00:00:29.440 --> 00:00:36.890
here to help us decrease the training time as much as possible having multiple GP use at our disposal

7
00:00:36.920 --> 00:00:43.070
for a single model training it can decrease the training time of a model from a week to a few hours

8
00:00:44.100 --> 00:00:52.110
there are two main categories of distributed strategies synchronous and as cross the synchronous strategies.

9
00:00:52.110 --> 00:00:58.170
Generally train models on the different parts of the data set at the same time and at the end of one

10
00:00:58.260 --> 00:01:07.010
epoch those gradients are aggregated and use to update one model but in the synchronous strategies all

11
00:01:07.010 --> 00:01:15.310
workers are training at the same time independently and updating wait and see chronically let's talk

12
00:01:15.310 --> 00:01:23.550
about the most common distributed strategies that we can find in that as a flow 2.0 the first one is

13
00:01:23.550 --> 00:01:31.040
the mirrored strategy we will use this strategy in the section as well we start by defining a model

14
00:01:31.130 --> 00:01:35.990
on a single computer or in our case Google colored.

15
00:01:36.060 --> 00:01:43.400
Now let's see how this mirrored strategy is going to help us in decreasing the training time these strategies

16
00:01:43.400 --> 00:01:52.160
use when we have multiple devices on a single computer multiple GP use or CPE use and it leverages all

17
00:01:52.160 --> 00:01:56.440
of them by creating a copy of the same model for each device.

18
00:01:56.600 --> 00:02:02.600
In the end we will end up with as many copies of the model as the number of devices on that computer

19
00:02:03.850 --> 00:02:09.940
each will train independently and at the end of one epoch it will consider all weights and Abdi the

20
00:02:09.940 --> 00:02:17.200
main copy of the model the aggregation of weights in the most cases is done on the CPO or on the specific

21
00:02:17.200 --> 00:02:19.120
dedicated GPO for that.

22
00:02:19.690 --> 00:02:26.080
But sometimes you're going to have multiple servers or computers where each could have multiple devices

23
00:02:26.080 --> 00:02:29.840
on its own how to scale this strategy to that level.

24
00:02:30.690 --> 00:02:33.260
And that's where the next strategy comes into play.

25
00:02:33.450 --> 00:02:42.370
Multi workers Myriad's strategy in this case we still have a primary model but now it is not replicated

26
00:02:42.370 --> 00:02:51.360
for each device but for each computer in the network where each machine is called a worker each worker

27
00:02:51.420 --> 00:02:53.620
could have multiple devices.

28
00:02:53.880 --> 00:02:58.860
In that case it works the same way that mirrors strategy worked.

29
00:02:59.340 --> 00:03:07.340
And at the end of one epoch we consider all versions of the model to update the primary one before we

30
00:03:07.340 --> 00:03:08.690
finish with this video.

31
00:03:08.760 --> 00:03:11.820
Let's mention a few more strategies that exist.

32
00:03:11.930 --> 00:03:20.570
We have a strategy which is primarily used for JCP or Google Cloud Platform because they have deep use

33
00:03:20.840 --> 00:03:26.740
on their servers and we have these parameter server strategy and that's it.

34
00:03:26.750 --> 00:03:33.710
I know that all of this sounds very scary and complicated but in reality we can implement these strategies

35
00:03:33.920 --> 00:03:36.000
in a single line of code.

36
00:03:36.020 --> 00:03:41.420
Stay tuned for that and if you have any questions or comments so far please post them in the comments

37
00:03:41.420 --> 00:03:44.300
section otherwise I'll see in the next tutorial.
