1
00:00:00,480 --> 00:00:00,950
All right.

2
00:00:00,960 --> 00:00:02,910
Exciting tutorial ahead.

3
00:00:02,910 --> 00:00:04,800
Welcome back to of course on deep learning.

4
00:00:04,800 --> 00:00:08,010
Today we're talking about holiday neural networks work.

5
00:00:08,040 --> 00:00:13,770
Now we've led a lot of groundwork we've talked about how neural networks are structured what elements

6
00:00:13,800 --> 00:00:16,580
they consist of and even their functionality.

7
00:00:16,590 --> 00:00:21,980
And today we're going to look at a real example of how a new neural network can be applied and we're

8
00:00:21,990 --> 00:00:28,080
actually going to work step by step through the process of its application so we know what's going on.

9
00:00:28,290 --> 00:00:29,190
So let's have a look.

10
00:00:29,190 --> 00:00:30,650
What example are going to be talking about.

11
00:00:30,730 --> 00:00:37,110
We're going to be looking at property valuation so we're going to look at a neural network that takes

12
00:00:37,110 --> 00:00:39,510
in some parameters of a property and value values.

13
00:00:39,570 --> 00:00:44,670
And the thing here there's a small caveat for today's tutorial and that is we're not actually going

14
00:00:44,670 --> 00:00:45,750
to train the network.

15
00:00:45,780 --> 00:00:50,910
So a very important part in neural networks is training them up and we're going to look at that in the

16
00:00:50,910 --> 00:00:53,370
next tutorials in this section.

17
00:00:53,370 --> 00:00:57,480
For now we're going to focus on the actual application so we're going to work with a neural network

18
00:00:57,480 --> 00:01:04,500
that we're going to pretend is already trained up and that will allow us to focus on the application

19
00:01:04,500 --> 00:01:08,910
side of things and not get bogged down in the training aspect and then we'll color off the training

20
00:01:09,120 --> 00:01:12,600
when we're ready know the end goal we're working towards some good.

21
00:01:12,600 --> 00:01:15,100
All right let's jump straight into it.

22
00:01:15,210 --> 00:01:19,050
So let's say we have some input parameters.

23
00:01:19,050 --> 00:01:19,280
Right.

24
00:01:19,280 --> 00:01:24,600
So let's say we have four parameters about the property we have area in the squared feet we have the

25
00:01:24,600 --> 00:01:27,820
number of bedrooms that distance the city in Miles.

26
00:01:27,990 --> 00:01:33,580
The nearer city and the age of the property and all of those four are going to comprise our input layer.

27
00:01:33,600 --> 00:01:40,770
Now of course they're probably way more parameters that define the price of a property but for simplicity's

28
00:01:40,770 --> 00:01:47,460
sake we're going to look at just these for now in its very basic form a neural network only has an input

29
00:01:47,460 --> 00:01:48,330
learn and output layer.

30
00:01:48,330 --> 00:01:52,230
So no hidden layers and our output layer is the price that we're predicting.

31
00:01:52,230 --> 00:02:00,930
So in this forum What's these input variables would do is they would just be weighted up by the synopsis

32
00:02:00,960 --> 00:02:06,150
and then the output there would be calculated basically the price would recalculate and we'd get a price.

33
00:02:06,160 --> 00:02:14,190
And for instance the price could be calculated as simple as the weighted sum of all of the inputs.

34
00:02:14,220 --> 00:02:17,820
And again here you could use pretty much any function you could use.

35
00:02:17,820 --> 00:02:24,810
What we're using now we could use any of the activation functions we had previously you could use a

36
00:02:24,810 --> 00:02:31,140
logistics regression you could use a squared function you could use prior to anything here.

37
00:02:31,140 --> 00:02:33,500
But the point is that you get a certain output.

38
00:02:33,500 --> 00:02:40,940
And moreover most of the machine learning algorithms that exist can be represented in this form.

39
00:02:40,950 --> 00:02:46,350
This is basically a diagram attic representation of how you deal with the variables by changing the

40
00:02:46,350 --> 00:02:51,870
way it's the formulas you can accomplish quite a lot of the machine learning algorithm that we've talked

41
00:02:51,870 --> 00:02:55,370
about before and put them into this form.

42
00:02:55,380 --> 00:02:58,760
And that just stands to show how powerful new neural networks are.

43
00:02:58,890 --> 00:03:04,200
Even without the hidden layers we are already where you have a representation that works for most other

44
00:03:04,200 --> 00:03:10,170
machine learning algorithms but in neural networks what we do have is an extra advantage that gives

45
00:03:10,170 --> 00:03:17,010
us lots of flexibility and power which is where that increase in accuracy comes from.

46
00:03:17,010 --> 00:03:21,990
And that power is the hidden layers and there we go.

47
00:03:21,990 --> 00:03:28,230
That's our hidden layer we've added it in and now we're going to understand how that hidden layer gives

48
00:03:28,230 --> 00:03:30,110
us that extra power.

49
00:03:30,250 --> 00:03:34,050
And in fact to do that we're going to walk through an example.

50
00:03:34,050 --> 00:03:38,520
So as we agreed this neural network has already been trained up and now we're just going to plug in

51
00:03:38,520 --> 00:03:44,160
we're going to imagine that we're plugging in a property and we're going to walk step by step through

52
00:03:44,160 --> 00:03:51,210
how the neural network will deal with the input variables and calculate the hidden layer and then calculate

53
00:03:51,210 --> 00:03:51,840
the output layer.

54
00:03:51,870 --> 00:03:54,370
So let's go through this is going to be exciting.

55
00:03:54,390 --> 00:04:00,180
All right we've got all four variables on the left and we going to first start with the top neuron on

56
00:04:00,180 --> 00:04:01,360
the hidden layer.

57
00:04:01,380 --> 00:04:08,250
Now as we previously saw in the procedurals all of the neurons from the input layer they have synapses

58
00:04:08,250 --> 00:04:09,550
connecting it.

59
00:04:09,720 --> 00:04:13,120
Each one of them to the top neuron in a hidden layer.

60
00:04:13,440 --> 00:04:15,180
And those systems have weights.

61
00:04:15,180 --> 00:04:20,430
Now let's agree that some weights will have a non-zero value some weights will have a zero value because

62
00:04:20,670 --> 00:04:28,320
basically not all inputs will be valid or not all inputs will be important for every single neuron sometimes

63
00:04:28,320 --> 00:04:32,700
inputs will not be important and here we can see two examples that X1 next three the area in the distance

64
00:04:32,700 --> 00:04:37,950
to the city in miles are important for that neuron whereas bedrooms and age are not like let's think

65
00:04:37,950 --> 00:04:45,660
about this for a second why how would that be the case like why would a neuron be linked to the area

66
00:04:45,660 --> 00:04:47,310
in the distance what does that what could that mean.

67
00:04:47,310 --> 00:04:53,370
Well that could mean that normally the further we get from the city the cheaper real estate becomes

68
00:04:53,370 --> 00:04:58,290
and therefore the space in square feet of properties becomes larger.

69
00:04:58,380 --> 00:05:01,830
So for the same price you can get property of the further way you go from the city.

70
00:05:01,830 --> 00:05:02,490
That's normal right.

71
00:05:02,490 --> 00:05:08,930
That that makes sense and probably what this neuron is doing is it is looking specifically it's like

72
00:05:08,940 --> 00:05:16,920
like a sniper it's looking for area properties which have which are not so far from the city but have

73
00:05:16,920 --> 00:05:17,550
a large area.

74
00:05:17,580 --> 00:05:24,770
So for their distance from the city they have an unfair square foot area.

75
00:05:24,810 --> 00:05:25,050
Right.

76
00:05:25,040 --> 00:05:27,590
So something as as abnormals as higher than average.

77
00:05:27,590 --> 00:05:31,950
So they're quite close to the city but there's still large as opposed to the other ones at the same

78
00:05:31,950 --> 00:05:32,460
distance.

79
00:05:32,860 --> 00:05:38,760
And so that neuron again we're speculating here but that neuron might be picking out laser picking out

80
00:05:38,820 --> 00:05:44,080
those specific properties and it will activate and hence the activation function it will activate it'll

81
00:05:44,100 --> 00:05:49,560
fire up only when the certain criteria is met that you know the distance and the area of the proper

82
00:05:49,560 --> 00:05:54,720
distance city and there of the area of the property and it performs his own calculations inside itself

83
00:05:55,380 --> 00:06:00,390
and it combines those two and as soon as certain counter-terrorism and fires up and that contributes

84
00:06:00,390 --> 00:06:05,430
to the price in the output layer and therefore this neuron doesn't really care about bedrooms and age

85
00:06:05,430 --> 00:06:10,350
of the property because it's focused on that specific thing that's where the power of the neural network

86
00:06:10,350 --> 00:06:14,050
comes from because you have many of these theories and we'll see just now how the other ones work.

87
00:06:14,080 --> 00:06:20,850
So but what I wanted to agree here is that let's not even draw these lines for the Simpsons that are

88
00:06:20,850 --> 00:06:25,440
not in play so that we don't clutter up our image that's the only reason we're not going to draw on

89
00:06:25,440 --> 00:06:25,560
them.

90
00:06:25,560 --> 00:06:29,480
So let's just get rid of those two and that way we will know exactly OK.

91
00:06:29,490 --> 00:06:33,830
So this neuron is focused on area and distance to the city.

92
00:06:33,900 --> 00:06:34,140
All right.

93
00:06:34,860 --> 00:06:36,780
So as long as we agree on that let's move on to next.

94
00:06:36,810 --> 00:06:42,020
Let's take them one in the middle here we've got three parameters feeding into this neuron.

95
00:06:42,050 --> 00:06:45,840
So we've got the area the bedrooms and the age of the property.

96
00:06:45,960 --> 00:06:48,390
So what could be the reason here.

97
00:06:48,420 --> 00:06:55,620
Let's again let's try to understand the intuition that the thinking of this neuron how is this neuron

98
00:06:55,620 --> 00:06:58,740
thinking why is it picking these three apartments what could it be.

99
00:06:58,800 --> 00:07:02,060
What could have a hit like found in the data.

100
00:07:02,060 --> 00:07:02,250
Right.

101
00:07:02,250 --> 00:07:04,530
So we've already established this a trained up dataset.

102
00:07:04,530 --> 00:07:09,440
The training has happened a long time ago maybe like a day ago or somebody already train opposites.

103
00:07:09,450 --> 00:07:14,010
And now we're just applying and we know that this neuron through all the thousands of examples of properties

104
00:07:14,310 --> 00:07:20,530
has found out that the area plus the bedrooms plus the age combination of those parameters is important.

105
00:07:20,550 --> 00:07:21,570
Why could that be the case.

106
00:07:21,570 --> 00:07:29,340
Well for instance maybe in that specific city in those suburbs that this neural network has been trained

107
00:07:29,340 --> 00:07:40,290
up in perhaps there's a lot of families with kids with two or more children who are looking for large

108
00:07:40,290 --> 00:07:47,400
properties with lots of bedrooms but which are new rights which are not old properties because maybe

109
00:07:47,400 --> 00:07:53,810
in that's in that area almost all properties are kind of like big properties are usually old but there's

110
00:07:53,850 --> 00:08:00,030
lots of modern families and you maybe there has been a social demographic shift and or maybe there's

111
00:08:00,030 --> 00:08:07,470
been like a lot of like some growth in terms of employment and jobs for the younger set of population

112
00:08:07,510 --> 00:08:15,480
maybe just you know the like the population demographics have changed and now younger couples or younger

113
00:08:15,480 --> 00:08:22,140
families are looking for properties but they prefer newer properties so they want the age of the property

114
00:08:22,140 --> 00:08:28,600
to be lower and hence from the training that this neural network has undergone it knows that when there

115
00:08:28,600 --> 00:08:33,750
is a property of a large area and with lots of bedrooms at least through at least three bedrooms for

116
00:08:33,750 --> 00:08:38,650
the parents for the first shelter the second child for at least three bedrooms maybe a guest room where

117
00:08:38,700 --> 00:08:45,900
a new property with a high area and lots of bedrooms that is valued that in that market that is valuable

118
00:08:45,910 --> 00:08:49,750
so that neuron has picked that up it knows that's OK.

119
00:08:49,770 --> 00:08:51,420
So this is what I'm going to be looking for.

120
00:08:51,420 --> 00:08:56,550
I don't care about the distance of the Syrian Miles wherever it is as long as it has high area lots

121
00:08:56,550 --> 00:08:57,050
of bedrooms.

122
00:08:57,090 --> 00:09:01,680
As soon as that criteria is met the neuron fires up and the combination of these two parameters and

123
00:09:01,680 --> 00:09:06,120
this is again this is where the power of the neural network is coming from because it combines these

124
00:09:06,120 --> 00:09:15,800
three parameters into a brand new parameter into a brand new attribute that helps with the evaluation

125
00:09:15,800 --> 00:09:20,340
of the helps with the valuation of the property and combines them into a new attribute and therefore

126
00:09:20,340 --> 00:09:21,150
it's more precise.

127
00:09:21,870 --> 00:09:22,380
So there we go.

128
00:09:22,380 --> 00:09:23,880
That's how that neuron works.

129
00:09:24,210 --> 00:09:30,000
And let's look at another one let's look at the very bottom one for instance this neuron could be could

130
00:09:30,000 --> 00:09:35,460
even have picked up just one parameter it could have just picked up H and not any of the other ones

131
00:09:35,460 --> 00:09:37,840
and how could that be the case.

132
00:09:37,860 --> 00:09:45,720
Well this is a classic example of when age could mean like as we all know the older property is usually

133
00:09:45,720 --> 00:09:50,370
it's less valuable because it's worn out probably the building is old probably no things are falling

134
00:09:50,370 --> 00:09:51,860
apart more maintenance is required.

135
00:09:51,870 --> 00:09:56,790
So the price drops in terms of the price of the real estate whereas a brand new building it would be

136
00:09:56,790 --> 00:10:02,660
more expensive because it's brand new but perhaps if a property is over a certain age that could indicate

137
00:10:02,660 --> 00:10:03,920
that it's a historic property.

138
00:10:03,950 --> 00:10:11,250
For instance if a property is under 100 years old then the older it is the less valuable it is.

139
00:10:11,300 --> 00:10:17,000
But as soon as it jumps over 100 years old all of a sudden it becomes a historic property because this

140
00:10:17,000 --> 00:10:20,790
is a property where people used to live hundreds of years ago.

141
00:10:20,810 --> 00:10:26,090
It tells a story it's got all this history behind it and some people like that some people value that

142
00:10:26,210 --> 00:10:32,060
in fact quite a lot of people would like that and would be proud to live in a property and especially

143
00:10:32,060 --> 00:10:37,910
in the higher socio economic classes they would show off to their friends or things like that and therefore

144
00:10:38,030 --> 00:10:43,970
properties that are over 100 years old could be deemed as historic and therefore this neuron as soon

145
00:10:43,970 --> 00:10:49,970
as it sees a property over 100 years old it'll fire up and contribute to the overall price and otherwise

146
00:10:50,120 --> 00:10:52,760
if it's under 100 years old then it won't do work.

147
00:10:52,760 --> 00:10:54,680
And this is a good example of.

148
00:10:55,090 --> 00:10:57,530
The rectifying function being applied.

149
00:10:57,530 --> 00:11:04,580
So here you've got like a very like a zero until a certain point and then let's say 100 years old and

150
00:11:04,580 --> 00:11:09,020
then after a hundred years old the older it gets the higher the value the higher the contribution of

151
00:11:09,020 --> 00:11:11,320
this neuron to the overall price.

152
00:11:11,420 --> 00:11:18,640
And there's just a wonderful example of a very simple example of this rectify or fan function in action.

153
00:11:18,830 --> 00:11:25,100
So there we go that could be this neuron and moreover the neural network could have you picked up things

154
00:11:25,100 --> 00:11:28,310
that we wouldn't have thought of ourselves right.

155
00:11:28,490 --> 00:11:34,280
For instance bedrooms plus distance the city maybe that's in combination somehow contributes to the

156
00:11:34,280 --> 00:11:38,630
price maybe it's not as strong as the other neurons and it contributes but it still contributes or maybe

157
00:11:38,840 --> 00:11:43,460
it detracts from the price that could also be the case or other things like that and maybe you and your

158
00:11:43,460 --> 00:11:50,390
own picked up all for a combination of all four of these parameters and as you can see the that these

159
00:11:50,390 --> 00:11:58,490
neurons this whole hidden layer situation allows you to increase the flexibility of your neural network

160
00:11:58,520 --> 00:12:04,910
and allows you to really look allows the neural network to look for very specific things and then in

161
00:12:04,910 --> 00:12:10,670
combination that's where the power comes from it's like that example for ants right like an ad by itself

162
00:12:10,670 --> 00:12:15,950
cannot build an anthill but when you have like a thousand or one hundred thousand ads they can build

163
00:12:15,950 --> 00:12:18,550
an anthill together and that's that's the situation here.

164
00:12:18,560 --> 00:12:24,230
Each one of these neurons by itself cannot predict the price but together they have superpowers and

165
00:12:24,230 --> 00:12:29,870
they predict the price and they can do quite an accurate job if trained properly if set up properly

166
00:12:30,680 --> 00:12:35,290
and that's what this whole course is about in understanding how to utilize them.

167
00:12:35,300 --> 00:12:42,050
There we go so that is a step by step example and walk through of how neural networks actually work.

168
00:12:42,410 --> 00:12:45,430
I hope you enjoyed today's tutorial and I can't wait to see you next time.

169
00:12:45,560 --> 00:12:47,300
Until then enjoy deep learning.
