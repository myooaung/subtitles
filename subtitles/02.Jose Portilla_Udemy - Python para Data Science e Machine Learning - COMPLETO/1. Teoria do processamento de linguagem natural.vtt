WEBVTT

00:09.320 --> 00:15.060
Então pessoal bem vindo à Seção de Processamento de linguagem natural e saudável fala um pouco sobre

00:15.060 --> 00:21.060
os conceitos teóricos que eu vou apresentando para vocês para a gente conseguir criar modelos que consigam

00:21.910 --> 00:27.250
realizar algum tipo de performance computacional com o Centro de Inteligência de texto.

00:27.510 --> 00:35.250
Estão no livro Toda escola não tem um artigo específico para isso mas eu sugiro que vocês leiam o artigo

00:35.250 --> 00:38.080
da Wikipedia sobre o processamento de linguagem natural.

00:38.170 --> 00:45.660
Aqui a resposta está no chão de duas formas pipeline em português ou o termo NP em inglês que é natural

00:45.660 --> 00:48.740
léguas e léguas processo processo.

00:49.570 --> 00:56.250
Ao avançar aqui então qualquer ideia por trás disso tudo que eles consigam pensar infinitas eu consigo

00:56.250 --> 01:03.130
pensar em várias e colocar sistemas inteligentes que consigam gerar informações relevantes e textos.

01:04.320 --> 01:09.080
Quero deixar claro que os conceitos que eu vou apresentar aqui não são os mais avançados sobre o assunto

01:09.460 --> 01:14.350
acredito que os mais avançados são modelos VEC e 55.

01:14.970 --> 01:19.950
Ouvi eles neurais mais complexos do que os mais comuns.

01:19.980 --> 01:24.750
Podem estar utilizando esses termos que eu falei bicho falar para pesquisar sobre esses métodos mais

01:24.780 --> 01:31.270
complexos mas já está falando sobre Metro ergométrica trata na sala que é o metro.

01:31.620 --> 01:39.370
TF 10 e seguinte qualquer ideia desse crescimento imagina que você trabalha para o Google uniu está

01:39.520 --> 01:45.410
e que conseguiu agrupar isso por tópicos desse de certa forma vai conseguir te ajudar a fazer isso.

01:46.090 --> 01:50.680
Imagine que você trabalha para o escritório de advocacia precisa pesquisar por centenas de páginas de

01:50.680 --> 01:54.400
documentos para encontrar os mais relevantes para ti naquele momento.

01:54.430 --> 01:55.990
é aí que o PL pode te ajudar.

01:58.330 --> 02:04.240
Então como lá a gente vai ter por objetivo utilizando a metodologia que eu vou apresentar aqui.

02:04.240 --> 02:10.900
Primeiro compilar os documentos pois a gente tem que conseguir categorizar los e depois comparar os

02:10.900 --> 02:14.210
seus parâmetros que a gente criou parâmetros a partir do segundo.

02:14.240 --> 02:18.950
O segundo passo dar um exemplo bem simples.

02:18.980 --> 02:24.290
A gente tem dois documentos onde os documentos são basicamente uma frase pequena onde você tem documento

02:24.290 --> 02:27.940
chamado Casa Azul o chamado Casa Vermelha.

02:28.580 --> 02:33.170
O processo de categorização deles que é o segundo passo que é apresentado eternamente.

02:33.190 --> 02:40.370
A gente pode a gente é relevante para o computador que consiga fazer operações matemáticas nisso uma

02:40.370 --> 02:44.380
representação matemática que esses dois documentos podem ter.

02:44.390 --> 02:51.300
A gente pode criar um vetor bem grande que contenha todas as palavras de algum idioma qualquer a gente

02:51.300 --> 02:56.600
pode nesse vetor colocar por documento a contagem de vezes que alguma palavra aparece nele.

02:56.640 --> 02:58.210
A gente tem n 0 1 1.

02:58.260 --> 03:05.610
Por exemplo se esse título ele fosse sempre vermelho aparecesse ele coloca um 0 no vetor ou uma casa

03:05.610 --> 03:10.050
na Casa Azul por exemplo o documento Casa Azul.

03:10.050 --> 03:14.230
Nessa representação que eu acabei de dar ele será representado pelo vetor 01.

03:14.670 --> 03:19.860
Quando a Casa Vermelha será apresentada pelo vetor zero.

03:20.010 --> 03:23.260
Dessa forma um documento pode ser apresentado como vetor de palavras.

03:23.340 --> 03:25.400
Ele é chamado de saco de palavras.

03:25.470 --> 03:32.790
Eu sei que é uma notação boa meu Rei mas a tradução do tradução da forma como feita no idioma inglês

03:32.790 --> 03:34.570
que é bem.

03:34.860 --> 03:40.010
Podem pesquisar tanto por saco de palavras como fortes modelos de saco de palavras.

03:41.260 --> 03:43.690
Eu coloquei ele as apresentações que acabei de citar.

03:44.570 --> 03:50.700
A gente pode pegar esses vetores finais e usar a similaridade do conceito nos vetores para conseguir

03:50.720 --> 03:56.550
determinar com similares são uns os outros equacionamento entre eles.

03:57.000 --> 04:02.220
A gente pode otimizar a técnica do saco de palavras ajustando a contagem de palavras pela frequência

04:02.220 --> 04:07.470
que elas aparecem no conjunto inteiro de documentos e para isso a gente faz uso do método que eu comentei

04:07.470 --> 04:16.470
anteriormente que FDR inglês Seletores de Frequência em cores muito frias ou frequência do termo inverso

04:16.470 --> 04:24.030
da frequência um documento que quer a gente quer dizer com isso tão frequentes e sem importância do

04:24.030 --> 04:31.780
termo no documento que a gente vai chamar se essa variável TF número de ocorrências daquele terão documento

04:31.800 --> 04:37.270
B e o inverso documento será a importância do termo no conjunto dos documentos.

04:37.290 --> 04:45.120
O ideal F seria o blog do D sobre o ter um judeu número total de documentos que a gente tem e o teu

04:45.120 --> 04:46.740
número de documentos com o termo.

04:47.930 --> 04:52.190
Daí a importância do termo no conjunto de documentos que tu tem.

04:52.310 --> 04:59.190
Isso é quando a gente quer conseguir utilizar esse método para caracterizar ele documentos e aqui eu

04:59.190 --> 05:05.980
tenho conhecimento de como é que a gente pode expressar matematicamente o top 10 top 10.

05:06.000 --> 05:10.010
Ele vai ser a multiplicação daqueles dois outros dois valores do TF peso e deve

05:13.360 --> 05:18.400
antes começar utilizando PNL Python que se instala a biblioteca NL TK.

05:18.420 --> 05:28.150
Você pode estar lá pesquisando quando estou n TK ou Pippin só N N no TK e após isso eu vou tá criando

05:28.150 --> 05:36.000
um modelo comum da primeira aula que vai filtrar basicamente mensagens de texto em spams ou ramos que

05:36.260 --> 05:45.520
é uma notação que esse conjunto de dados que eu puxei para fazer essa aula marginal só expansão e Ramos

05:45.520 --> 05:52.640
ele considera como sendo e-mails meus mensagens de texto que têm conteúdo relevante para o usuário vou

05:53.280 --> 05:58.740
estar utilizando esse termo também no seu projeto final que vai trabalhar com dados da época e um site

05:58.750 --> 06:06.700
basicamente um site envios sobre comidas restaurantes lugares para você não proximal e mais.
