WEBVTT

00:08.510 --> 00:15.000
O pessoal minha primeira aula sobre regressão linear vou começar trabalhando no notebook.

00:15.070 --> 00:22.450
O conjunto de dados de preços de casas vai criar um modelo para tentar predizer o preço das casas baseando

00:22.470 --> 00:31.520
em suas características baseados em quartos e salas baseado na renda média das pessoas no bairro.

00:31.510 --> 00:38.450
Enfim essa ideia do projeto inicial é como regressão linear o primeiro modelo de algoritmo de Machine

00:38.450 --> 00:43.990
Manny Beta também inclui artificiais da Cultura indicou que a possibilidade de você trabalhar com o

00:43.990 --> 00:47.860
dado da quebra tem dados reais sobre o mesmo.

00:47.930 --> 00:55.160
Na mesma linha e antes disso é importante instalar o site começou anteriormente que é a biblioteca principal

00:55.590 --> 01:01.880
de Python para trabalhar com uma solução de sim que está basicamente tem o Digital um dos dois códigos

01:02.230 --> 01:04.470
de comando e principal sei lá.

01:04.890 --> 01:12.380
O quando está satisfeito com o produto porque agora começa a trabalhar com isso deixa algumas coisas

01:12.380 --> 01:13.450
um pouco mais claras.

01:14.170 --> 01:20.030
O pessoal bom começar trabalhando aqui com o nosso projeto então vamos começar com os impostos padrões

01:20.160 --> 01:21.930
que é o que sempre penso.

01:22.040 --> 01:25.510
Começar importando bandas Portaluppi

01:28.490 --> 01:29.980
totalmente pouco me

01:33.470 --> 01:41.410
importa o símbolo e vou mudar o método.

01:43.940 --> 01:52.380
Quanto a isso o pessoal deve ter notado que a gente tem um arquivo CSV na pasta nesse último quer fazer

01:52.550 --> 02:03.950
uso dele para começar utilizando aqui colocar e usá los aos soldados por já nos preços de casa e algumas

02:03.950 --> 02:09.660
características antes que as casas da região tinham que definir o seu preço de venda.

02:10.100 --> 02:15.740
Utilizando se aqui para criar o modelo linear para predizer preços de mais casas a gente consegue criar

02:15.740 --> 02:17.580
um bom modelo para isso.

02:17.600 --> 02:25.170
Colocar aqui vou usar muito SSD sei house house para rodar esse cara daqui.

02:25.870 --> 02:31.340
A gente pode começar aqui definindo por exemplo por exemplo que uma só planta.

02:31.890 --> 02:38.630
A gente tem aqui algumas informações então brincamos seria quantas pessoas em médio da região na qual

02:38.630 --> 02:46.000
a casa foi vendida recebe por ano em dólares da média da Casa das casas da região.

02:46.070 --> 02:49.900
Todos os aqui são a média de casas da região.

02:49.940 --> 02:53.670
Há menos casas de quartos médios na região.

02:53.660 --> 03:00.230
O número de quartos aqui sejam de ambientes.

03:00.510 --> 03:06.730
A população da região e o preço da casa com a qual saiu o endereço dela todos esses caras aqui além

03:06.950 --> 03:13.580
do preço eles vão ser as nossas variáveis acabou sendo usado para tentar predizer o preço das casas

03:13.580 --> 03:19.430
e construir o modelo utilizando esses dados aqui como Excel.

03:19.520 --> 03:26.260
A ideia me deu um pouco mais os dados antes de traçar uma estratégia de criação desse modelo colocar

03:26.290 --> 03:30.040
aqui um ponto em que não existem as informações aqui os chips os dados.

03:30.060 --> 03:36.000
A gente tem cinco mil entradas aqui as informações e os tipos deles.

03:36.340 --> 03:39.140
E essa variável final vai fazer uso daquele endereço.

03:39.140 --> 03:45.340
O endereço aqui é uma esfinge eu não consigo as informações dele.

03:45.380 --> 03:50.810
Dessa forma precisaria fazer algum tipo de tratamento que não envolve em questão deveria nesse curso

03:50.810 --> 03:51.870
aqui.

03:52.490 --> 03:58.920
Outra coisa que a gente pode fazer também pode estar colocando no colo e verificando como se processou.

03:59.800 --> 04:06.290
A começar então o pessoal fazendo as portas para gente poder visualizar mais ou menos como é que os

04:06.290 --> 04:08.910
dados estão expostos sem tem alguma.

04:09.080 --> 04:14.250
Como é que eles aparecem como se relacionam também.

04:14.690 --> 04:19.060
Eu me colocar aqui Blog eu vou passar aqui.

04:19.210 --> 04:29.420
Eu sei só que demora um pouquinho porque vou começar jogando em grandes cidades um pouquinho que essa

04:29.420 --> 04:30.460
distribuição.

04:30.650 --> 04:36.920
Podem ver que alguns alimentos como uma distribuição um pouquinho diferente está basicamente aqui se

04:36.920 --> 04:39.910
valoriza são mais ou menos isso cria se um democratizado.

04:39.910 --> 04:49.670
A gente tem aqui valores médios em torno de 2 mil 2 3 4 que é o número de quartos ou o número de ambientes.

04:49.840 --> 04:55.310
Percebendo também que se a gente for verificar aqui com o preço a gente tem que estar interessado nessa

04:55.310 --> 05:04.230
coluna aqui nessa coluna quem souber para perceber o que existe de certa forma uma relação linear as

05:04.320 --> 05:10.070
casas e as outras variáveis que a gente quer utilizar as outras para predizer o preço.

05:10.650 --> 05:16.230
Então por exemplo existe uma relação linear aqui existe uma relação linear aqui existe uma relação linear

05:16.230 --> 05:17.710
aqui aqui não.

05:18.270 --> 05:21.390
Não está tão claro até existe mas não está tão claro.

05:21.490 --> 05:29.060
Aqui existe então uma análise prévia e claro muito simplista da questão não se baseia apenas nisso aqui.

05:29.580 --> 05:34.910
Existem outras métricas para acompanhar seu modelo linear e o melhor modelo para tentar predizer coisas

05:35.640 --> 05:40.650
mas vendo dessa forma que a gente pode ver que as variáveis de certa forma têm um grau explicativo linear

05:40.650 --> 05:41.260
sobre o preço.

05:41.940 --> 05:50.220
Então é isso vai fazer você ver também aqui por exemplo visualizar um pouco mais ou soldados colocar

05:50.240 --> 05:59.130
aquilo como parâmetro porque somente os caras podem ver que o gráfico de correlações estava o preço

05:59.130 --> 06:02.060
ele possui de certa forma a correlação linear.

06:02.220 --> 06:10.320
São coisas diferentes fizeram tirando aquele cara daqui que é o número de quartos menos mas basicamente

06:11.010 --> 06:15.390
eu não descarto não descartaria fazer um modelo linear dessa forma por essas duas áreas que eu fiz aqui

06:15.810 --> 06:23.550
tanto pelo método de correlação quanto pela pelo que pode começar que começa a fazer no seguinte pessoal

06:23.610 --> 06:30.060
eu vou definir o que vai ser o nosso X ou seja quais vão ser os nossos parâmetros a partir de agora

06:30.060 --> 06:35.580
botar utilizando no curso da simulação sempre são os nossos parâmetros ou seja o que vai predizer o

06:35.580 --> 06:41.420
modelo e o Y vai ser o que vai ser dito pelo nosso modelo.

06:41.640 --> 06:47.780
Para começar aqui eu vou colocar o último jogo algo novo e vou colocar como uma questão qualquer.

06:47.780 --> 06:54.870
Nossa intenção aqui eu quero pegar encontrar o quero usar como o X ou seja variáveis explicativas.

06:54.870 --> 07:07.130
Todo mundo aqui com exceção do preço e sem o endereço também não porque ainda tem o seu olho lá.

07:07.550 --> 07:13.200
A gente excluiu a gente fez um prime na qual a gente discutiu o preço só as variáveis para editoras

07:14.600 --> 07:24.670
como o y eu vou colocar aqui o que será predito no caso vai ser o caso vai ser o preço.

07:26.030 --> 07:27.570
A divisão dos meus dados.

07:27.560 --> 07:28.810
Cortei e me separei.

07:29.720 --> 07:33.840
Qual seria o próximo passo hoje infestada pela parte de vocês bem lembro daquela aula onde eu apresentava

07:33.840 --> 07:38.550
um pouco do processo de criação de um modelo usando machine learning uma parte do tratamento de dados

07:38.550 --> 07:47.520
ainda está uma parte do processo agora eu vou estar utilizando o site para que a gente passe para fazer

07:47.520 --> 07:48.400
uso dele.

07:48.450 --> 08:01.820
Seguindo essa linha Model Selection importe em testes o PC roda.

08:03.750 --> 08:05.220
Então o que eu fiz aqui pessoal.

08:05.290 --> 08:12.450
Eu tenho um método na biblioteca sei que ela é capaz de fazer o espírito ou seja a divisão dos meus

08:12.450 --> 08:13.820
dados X e Y.

08:13.850 --> 08:21.630
Treino e teste e se você tiver também a parte importante do processo de concessão do modelo eu vou precisar

08:21.720 --> 08:23.000
quebrar esses dados aqui.

08:23.020 --> 08:28.580
Dados apresentados os testes e associados sempre os parâmetros com o preço da casa.

08:28.960 --> 08:37.300
O que esse modelo vai fazer se eu colocar em testes pedidos ou passar pelo parâmetro x parâmetro z mas

08:37.300 --> 08:38.770
parâmetro y.

08:38.850 --> 08:46.320
Sugiro também lerem a documentação do modelo caso vocês têm alguma dúvida em relação a isso.

08:46.350 --> 08:52.110
Basicamente ele vai explicar para vocês que ele vai pegar os seus dados e vai quebrar cada um deles

08:52.110 --> 08:58.610
em dois anos vai quebrar o teu X em duas partes quebra o teu y duas partes.

08:59.070 --> 09:04.950
O conta onde é feito o corte ele n é igual nos dois caras porque é necessário manter a relação entre

09:04.950 --> 09:10.200
as variáveis associadas com o cara porque esse modelo aqui é um algoritmo de supervisão.

09:10.590 --> 09:18.150
Ou seja a gente vai informando para o modelo os parâmetros e as respostas e a partir disso ele vai se

09:18.150 --> 09:25.210
otimizar e criar um modelo que faça sentido e que ele consiga predizer outros caras apenas o do parâmetro.

09:25.740 --> 09:32.790
Ele vai aprender com o conjunto de treino e vai testar o modelo no conjunto de testes que eu vou fazer

09:32.790 --> 09:33.400
aqui.

09:33.750 --> 09:37.420
Vou colocar o x passar o Y.

09:38.060 --> 09:42.310
Ele definiu que ele vai trabalhar com esses dados aqui.

09:42.870 --> 09:48.880
Posso passar o teste ou seja eu quero saber quantos por cento dos meus dados ele vai deixar em formato

09:48.890 --> 09:54.330
de teste enquanto o formato de treino vou colocar aqui para poder mudar um pouco o quadro geral o pessoal

09:54.330 --> 10:04.090
costuma usar 0 3 deixar 70 por cento dos dados como treino é 30 por cento de dados como teste 0 4 o

10:04.230 --> 10:11.760
que quiserem é que no final vou colocar os tuites e colocar um valor qualquer aqui que eu não gostei

10:11.770 --> 10:13.700
que basicamente esse.

10:13.860 --> 10:19.860
Essa explicado aqui essa divisão é feita com base em um algoritmo aleatório aleatoriamente que vai criar

10:19.860 --> 10:20.650
essa divisão.

10:20.880 --> 10:22.980
Mas eu posso especificar ou não está aqui.

10:23.250 --> 10:27.470
E se fosse colocarem esse mesmo parâmetro aqui igual assentiu submeter a mesma divisão que eu estou

10:27.530 --> 10:30.820
tendo aqui só para caso você queira obter as mesmas respostas.

10:31.630 --> 10:38.820
é o seguinte esse modelo seu modelo é que agora ele pega com o push e a resposta dele inimiga torna

10:38.820 --> 10:45.000
uma dupla com quatro elementos e retorna a resposta dele seria uma coisa semelhante.

10:46.330 --> 10:48.210
A B C D.

10:49.100 --> 10:54.210
A definição da função existe alguma coisa no final onde ele retorna isso aqui.

10:54.680 --> 11:00.240
Então quando a gente tem um retorno com quatro valores assim é que a gente faz o que escolhe está utilizando

11:00.360 --> 11:06.210
o chamado tu com Pequim seria empacotamento dupla.

11:06.460 --> 11:19.300
Eu vou passar quatro variáveis finais aqui colocar x x testes y competentes para desempenhar contato

11:19.320 --> 11:24.780
pela resposta dele e grava nessas quatro variáveis e a ordem que eu coloquei aqui é a ordem que ele

11:24.780 --> 11:31.650
sai é a ordem padrão do modelo pegar quebrar salvar os dados.

11:31.650 --> 11:39.440
Treino aqui os dados de testes aqui variáveis algo que a gente quer prever de treino aqui de teste aqui

11:40.000 --> 11:47.460
eu vou contar isso aqui feito eu posso fazer mesuras aos meus anos de treino aqui ele fez uma seleção

11:47.460 --> 11:48.680
aleatória dos dados.

11:48.870 --> 11:54.980
Podem ver que os índices estão totalmente fora de posição aqui eu posso verificar o tamanho do sotaque

11:55.010 --> 11:56.100
também.

11:56.670 --> 12:10.310
Eu tenho 13 mil para botar o X teste porque eu vou ter dois mil exatamente como especificar que eu sou

12:10.520 --> 12:15.210
o próximo passo agora vai ser sempre criar uma instância da classe que contém um modelo que a gente

12:15.210 --> 12:22.650
quer utilizar no nosso caso aqui a gente quer usar um modelo linear posso fazer uso disso usando escala

12:24.090 --> 12:25.590
linear móvel.

12:26.100 --> 12:31.520
Existem outras outras classes a gente pode estar aqui ou puxar

12:35.040 --> 12:43.940
ou rodar isso aqui próximo passo vou criar essa instância colocar o.

12:44.760 --> 12:45.840
C.

12:46.010 --> 12:53.730
Agora tenho o objeto de que eu posso fazer uso pra criar o nosso o nosso modelo é que a gente faça vou

12:53.730 --> 13:00.710
colocar aqui mineiro modo pouco Fit esse objeto que contém uma função chamada Fit um método chamada

13:00.710 --> 13:07.290
Fit que permite que eu encontro os parâmetros para modelo linear passando como parâmetro um X de treino

13:07.480 --> 13:16.050
ele passar o meu aí meu y de treino como resposta peguei esse conjunto de dados aqui encontra os parâmetros

13:16.050 --> 13:18.350
desse cara que eu rodei aqui.

13:19.210 --> 13:23.580
Pronto acabei de fazer o primeiro modelo de machine learning.

13:23.730 --> 13:31.110
Simples assim como é que a gente pode começar agora avaliar como é que o nosso modelo pega o modelo

13:31.110 --> 13:32.460
aqui.

13:32.590 --> 13:35.790
Era moda agora ele vai ter o parâmetro que a gente pode estar acessando.

13:35.910 --> 13:38.980
Dentre eles vou colocar um print aqui uso eficiente.

13:39.080 --> 13:45.660
Aliás o intercepta por mês que ele cruzou o eixo y posso dar um tapa aqui percebe o valor.

13:47.580 --> 13:53.060
Posso colocar por exemplo aqui vou visualizar como estão os coeficientes dele e aí sim eu vou interpretá

13:53.060 --> 13:56.850
los com epicentro como vocês daqui a pouquinho vão mostrar como aquele em que acesso a eles

14:00.580 --> 14:06.080
tem alguns valores aqui associados a cada variável que eu já explico o porquê disso.

14:07.040 --> 14:14.700
Interpretar esse cara daqui é um baita frame porque eu vou passar como parâmetro vou colocar como valores

14:14.760 --> 14:20.070
dos coeficientes como o índice que vou passar apenas as colunas.

14:20.100 --> 14:27.320
No meu estudo meus dados previsões aqui porque esse coeficiente aqui estão associados ao meu X.

14:27.830 --> 14:38.640
E como colunas eu vou colocar só colocar o coeficiente só sei lá fora eu vou chamar isso aqui de quarks

14:40.350 --> 14:41.670
e vou rodar.

14:41.690 --> 14:46.110
Se eu visualizar isso aqui eu tenho essa associação aqui.

14:46.950 --> 14:53.910
Então o que isso significa que significam 140 134 mil 122 mil.

14:53.910 --> 15:02.320
Significa o seguinte cada um acréscimo de unidade em qualquer um desses caras aqui vão acarretar num

15:02.340 --> 15:11.100
acréscimo de preço nessa unidade aqui por exemplo se aumentar muito sucesso seguindo nosso modelo pode

15:11.480 --> 15:14.620
se aumentar em uma dólar médio.

15:14.690 --> 15:17.830
A receita anual das pessoas que moram no bairro.

15:18.110 --> 15:22.400
As casas deveriam ser pacificadas 21 dólares a mais.

15:22.400 --> 15:27.980
O mesmo vale para esse cara daqui por exemplo se aumentar a idade média das casas da região em um ano

15:28.070 --> 15:31.400
a gente tem um acréscimo de 104 mil dólares.

15:31.450 --> 15:36.570
Claro que eventualmente sei que pode ser que não faça muito sentido para pessoal mas o que o nosso mundo

15:36.570 --> 15:41.690
não encontrou nada que ele aprendeu como é que sonha com o trem bala.

15:42.280 --> 15:51.570
Basicamente fez que ficar por aqui na sala seguinte eu vou ver um pouco mais sobre como tirar previsões

15:51.570 --> 15:56.060
do modelo como interpretar esses dados que fazem uso na prática.

15:56.130 --> 16:03.160
Verdade mas basicamente tudo aquilo que a gente fez cortou os dados de uma vez visualizando pode.

16:03.360 --> 16:09.080
Eu verifiquei isso verifiquei empiricamente não é a melhor forma de se fazer isso mas é uma forma possível

16:09.080 --> 16:14.480
para verificar que existe uma relação linear entre as variáveis e o preço então concluiu que o modelo

16:14.480 --> 16:21.590
linear por si só seria um bom modelo que também pode ser verificado aqui deles faz uso dos rápidos correlações

16:21.890 --> 16:30.910
correlações acima de 65 por cento diferentes x0 para diferentes x0 entre as variáveis aqui o preço então

16:30.980 --> 16:38.430
baseado nisso que eu fiz Penny meus dados utilizei o método de espíritos no último ano para poder quebrar

16:38.430 --> 16:45.530
os nossos dados e utilizar os dados de treino x treino e pessoal de treino para a para uma expansão

16:45.530 --> 16:47.070
da classe linear.

16:48.110 --> 16:53.870
Ou seja essa instância agora contém o nosso modelo perfeito para o modelo afetado está ajustado aos

16:53.870 --> 16:55.290
dados que a gente passou para ele.

16:55.520 --> 17:00.200
Ele pode utilizar esse modelo aqui agora para começar a gerar previsões dos dados.

17:00.400 --> 17:07.220
é isso que é feito pessoal qualquer dúvida esse fluxo básico porque esse fluxo que eu apresentei aqui

17:07.220 --> 17:09.790
agora não vai ser o padrão das aulas.

17:10.290 --> 17:14.680
E qualquer dúvida esse fluxo ou qualquer outra coisa não tem entendido Nassau aqui por favor.

17:14.680 --> 17:16.970
Segundo Carlos perguntas e respostas têm mais.
