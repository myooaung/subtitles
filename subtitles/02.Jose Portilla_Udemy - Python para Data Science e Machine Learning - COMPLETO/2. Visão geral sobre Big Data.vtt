WEBVTT

00:09.860 --> 00:17.100
Com pessoal bem vindo à primeira aula sobre a sessão de Big Data estão basicamente nessa sessão voltou

00:17.100 --> 00:24.770
tratando dos principais métodos e algoritmos disponíveis no momento para tratar basicamente big data.

00:24.770 --> 00:32.550
Então vou explicando sobre Duke que produz Spark e a versão do Spark no Python que é o pai Spark.

00:33.130 --> 00:37.790
Na sala eu vou ter explicado um pouco para você sobre as comparações entre sistemas locais e sistemas

00:37.790 --> 00:38.880
distribuídos.

00:38.970 --> 00:44.870
é basicamente sistema distribuído são aqueles que vão nos permitir tratá los a suas grandes conjuntos

00:44.870 --> 00:46.920
de dados o big data de forma otimizada.

00:47.300 --> 00:55.040
Então é em volta dos sistemas distribuídos que basicamente nasce toda possibilidade tratarmos esses

00:55.040 --> 00:55.570
dados.

00:56.360 --> 01:01.490
Então o fato de se fazer uma revisão sobre o ecossistema do DUP uma revisão detalhada sobre isso para

01:01.490 --> 01:06.250
que nas próximas aulas e os primeiros passos que a gente pode estar para utilizar o Amazon observe se

01:06.350 --> 01:12.730
que a Amazon observa se basicamente para manter a gama de ferramentas disponíveis na da Amazon para

01:12.740 --> 01:13.710
cloud computing.

01:13.720 --> 01:22.430
E caso vocês queiram aprofundar um pouco mais sobre isso existem outros recursos nisso e o domínio é

01:22.670 --> 01:29.470
basicamente é uma plataforma que hoje em dia já tem gente colocando no currículo um domínio sobre a

01:29.570 --> 01:35.120
Amazon observe sou muito mais conhecido como A WS devido à sua grande possibilidade de uso dentre elas

01:35.180 --> 01:41.460
Big Data indo até agora pessoal a gente basicamente trabalhou com conjuntos de dados que cabem em conteúdo

01:41.470 --> 01:43.450
local na escala de 0 8 giga.

01:44.600 --> 01:48.640
Então eles conseguem gerar algo por tais dados minha memória RAM é tratado na memória RAM irei ouvir

01:48.660 --> 01:55.010
pelo computador assim se tiver um conjunto de dados muito maior então depois de tratar os dados usar

01:55.100 --> 02:01.300
por exemplo o servidor SQL promovermos os dados para o HD ao invés de hoje pode usar o sistema distribuído

02:01.300 --> 02:06.620
já que o sistema distribuído que basicamente distribui os dados em múltiplas máquinas então esse é o

02:06.620 --> 02:14.900
conceito por trás dos sistemas distribuídos é aí que nasce a ideia de como tratar os dados utilizo de

02:15.020 --> 02:23.150
Big Data tem uma comparação aqui no sistema local ele tem basicamente um computador no sistema distribuído

02:23.150 --> 02:26.870
o juiz tem um computador que controla múltiplos outros computadores.

02:27.540 --> 02:34.310
Eu já esperei para estar enxergando isso como CPU usa como unidade de núcleos de processadores.

02:34.820 --> 02:38.580
Então por exemplo local teria um só aqueles núcleos dos processadores enquanto o sistema distribuído

02:38.590 --> 02:41.410
já estaria diversos.

02:42.650 --> 02:48.910
Quando a gente compara um sistema local com um sistema distribuído basicamente é um processo local.

02:48.930 --> 02:51.520
Ele vai usar o poder computacional de apenas uma máquina.

02:52.010 --> 02:56.000
Então o sistema distribuído vai ter acesso a toda capacidade de processamento dentro do número de máquinas

02:56.000 --> 02:59.230
conectadas uma rede e a posterior ponto.

02:59.240 --> 03:05.300
é mais fácil a gente ganhar capacidade computacional com muita CPU de baixa qualidade do que com uma

03:05.300 --> 03:08.710
única CPU super PC CPU desculpa como vou dizer assim

03:16.000 --> 03:21.820
um sistema distribuídos eles tem a possibilidade de gente aumentar esse caos com muita facilidade.

03:21.820 --> 03:25.640
Basta adicionar mais computadores podem ser corredores de baixo custo.

03:25.780 --> 03:30.700
A gente tem um ganho na capacidade de processamento do sistema como um todo o investimento é muito menor

03:31.330 --> 03:36.010
então aumentou mais são mais tolerantes a falhas uma vez que a máquina sabe das máquinas falhar todo

03:36.010 --> 03:39.230
o sistema a todo será que este sistema vai continuar trabalhando.

03:40.300 --> 03:47.790
Então vão fazer explicação agora sobre como é que o duque utiliza esse conceito para poder se envolver

03:47.800 --> 03:56.650
e enfim tratar big data tão rápido que basicamente é um conjunto de ferramentas que foi desenvolvido

03:57.040 --> 04:04.930
há cerca de dez anos atrás e o nome do app é o nome de um elefante filho de um dos desenvolvedores da

04:04.930 --> 04:05.560
plataforma.

04:05.860 --> 04:06.780
Um elefante de brinquedo.

04:06.790 --> 04:13.060
Só uma curiosidade é tão bom como pesquisar mais sobre passar essa ferramenta.

04:13.060 --> 04:19.360
Vocês vão ver que o longa é um elefante e ele basicamente é uma forma de distribuir grandes arquivos

04:19.360 --> 04:21.730
e múltiplas tarefas em múltiplas máquinas.

04:22.150 --> 04:24.730
Então ele utiliza o conceito por trás do rato Duck.

04:24.730 --> 04:31.810
Ele utiliza o HD e oferece a duck Distributed System um HD fixo também duplica blocos de dados para

04:31.810 --> 04:34.110
que o mesmo tem uma tolerância maior a erros.

04:35.360 --> 04:42.040
Ele permite que a gente use uma funcionalidade dele chamada reprodução que basicamente vai permitir

04:42.040 --> 04:46.160
operações dos dados com uma eficiência muito maior que estão aqui.

04:46.170 --> 04:53.860
O conceito de processamento paralelo de dados que consiste toda a base totalmente do Big Data e supercomputação

04:53.860 --> 05:00.370
nos dias de hoje passando aí os dados mais técnicos o HD fios HD FS desculpa.

05:00.490 --> 05:04.330
Ele usa blocos de dados com tamanho padrão de 128 mil cada um deles.

05:04.390 --> 05:09.370
Cada um desses blocos replicar o 13 vezes e os blocos são distribuídos de forma que sejam menos sensíveis

05:09.370 --> 05:10.060
às falhas.

05:10.060 --> 05:15.640
Então se um dos contadores está tratando um desses blocos de dados e falhar de alguma forma os demais

05:15.640 --> 05:17.180
blocos têm cópias desse.

05:17.190 --> 05:22.110
Esses conjuntos conseguem dar continuidade a qualquer que seja a operação que a gente esteja fazendo

05:22.350 --> 05:22.880
com eles.

05:25.240 --> 05:30.670
Blocos menores permitem mais paralização durante o processo dispusesse de blocos muito grandes não conseguiria

05:30.670 --> 05:36.580
ter tanta transferência de dados entre os nós e múltiplas cópias provem que como havia anteriormente

05:37.000 --> 05:40.180
menor risco de perder esse conjunto de dados que a gente tem.

05:41.110 --> 05:46.600
E aí eu tenho um desenho do lado e basicamente explicando a ideia por trás do processamento paralelo

05:46.630 --> 05:55.480
que do que nos permite falar sobre métodos e produção eu vou entrar mais detalhes especificamente depois

05:55.540 --> 06:00.460
sobre que tipo de operação a gente consegue fazer nele mas ele é uma forma que a gente tem que dividir

06:01.390 --> 06:04.460
uma operação computacional para o conjunto de arquivos como HD e afins.

06:05.110 --> 06:08.210
Ele consiste em um jogo checa e músicos de jazz.

06:08.760 --> 06:17.340
Então eles vão receber jogos da checa e vão fazer as operações o jogo basicamente vai só avaliar o desempenho

06:17.340 --> 06:18.670
de cada um dos nós.

06:20.230 --> 06:22.530
Então o que perdemos pode ser passado de duas formas.

06:23.470 --> 06:28.940
Ele consiste num Drop Shaker e múltiplos outros backups.

06:29.590 --> 06:34.040
Quem viu colhe código como havia comentado anteriormente para rodar no teste de todos os testes com

06:34.060 --> 06:40.180
CPU memória para funções que monitoram o trabalho também conhecidos como o nosso.

06:41.120 --> 06:45.460
E para finalizar pessoal posso estar dizendo que o cliente vai cobrir pode ser dividido em duas etapas

06:45.520 --> 06:50.340
então a gente basicamente usa um lado para distribuir grandes conjuntos de dados e usar meu produto

06:50.350 --> 06:55.050
para distribuir tarefas computacionalmente pesadas um conjunto de dados distribuídos.

06:55.570 --> 07:00.160
Após isso pessoal vou explicando um pouco sobre as últimas tecnologias conhecidas nesse meio como o

07:00.170 --> 07:01.830
Spark como utilizar em Python.

07:01.840 --> 07:08.170
A ideia por trás disso é deixar registrado que o Spark melhora todos os conceitos e ideias que existem

07:08.170 --> 07:11.610
por trás o uso de distribuição de arquivos.

07:11.830 --> 07:14.580
Aqui essa foi uma introdução luzinha sobre como tratar de sucessão.

07:15.970 --> 07:20.860
Espero que vocês tenham curiosidade em seguir nessa área e aprender um pouco mais sobre isso porque

07:20.860 --> 07:24.510
isso aqui é o futuro das grandes empresas grandes.

07:24.670 --> 07:31.840
Enfim hoje em dia tudo é Big Data a gente diariamente hoje enche a nossa própria cortina deixa traços

07:31.840 --> 07:33.850
de comportamento em diversas fontes.

07:33.850 --> 07:40.640
Seja no Google seja no Facebook seja Instagram enfim nós deixamos traços comportamentais o tempo inteiro.

07:40.990 --> 07:43.520
E enfim dados são gerados diariamente.

07:43.810 --> 07:49.330
Então a gente está chegando uma geração mas numa época de Big Data e esse conceito aqui por mais que

07:49.330 --> 07:54.340
eu esteja apresentando para vocês uma mapa em curso uma explicação introdutória sobre isso é sobre o

07:54.340 --> 07:58.870
futuro deles para vocês as próximas aos demais.
