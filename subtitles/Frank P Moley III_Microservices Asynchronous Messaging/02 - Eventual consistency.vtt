WEBVTT
1
00:00:00.005 --> 00:00:03.002
- [Instructor] Eventual consistency is a paramount concept

2
00:00:03.002 --> 00:00:04.009
in distributed data.

3
00:00:04.009 --> 00:00:06.004
We often hear about this model

4
00:00:06.004 --> 00:00:09.000
but never consider that it is achieved

5
00:00:09.000 --> 00:00:12.007
through a mechanism of asynchronous activities.

6
00:00:12.007 --> 00:00:13.009
Before we dig too deep,

7
00:00:13.009 --> 00:00:16.005
we need to understand ACID and BASE.

8
00:00:16.005 --> 00:00:18.004
ACID is a calling card

9
00:00:18.004 --> 00:00:21.003
of relational database management systems.

10
00:00:21.003 --> 00:00:23.004
It is what allows transactional writes

11
00:00:23.004 --> 00:00:26.002
and consistent reads in a database.

12
00:00:26.002 --> 00:00:28.005
ACID, however, becomes painful at best

13
00:00:28.005 --> 00:00:30.009
in a microservices world,

14
00:00:30.009 --> 00:00:34.000
especially in a distributed one.

15
00:00:34.000 --> 00:00:35.008
Atomic transactions are usually

16
00:00:35.008 --> 00:00:37.008
what people think of with ACID,

17
00:00:37.008 --> 00:00:40.001
meaning that the data is either all written

18
00:00:40.001 --> 00:00:41.005
or it isn't.

19
00:00:41.005 --> 00:00:44.000
Of course, the rest of the acronyms are important too,

20
00:00:44.000 --> 00:00:47.005
consistent, isolated and durable.

21
00:00:47.005 --> 00:00:50.008
BASE, however, is a different way of thinking.

22
00:00:50.008 --> 00:00:53.006
We seldom care that the data is written immediately

23
00:00:53.006 --> 00:00:56.001
in a microservices architecture.

24
00:00:56.001 --> 00:00:58.009
We have already broken down the transactional boundaries

25
00:00:58.009 --> 00:01:01.002
with our service domains.

26
00:01:01.002 --> 00:01:04.001
What we do care about is that the data is going

27
00:01:04.001 --> 00:01:06.004
it be there when we need it.

28
00:01:06.004 --> 00:01:10.004
This is the E in BASE, eventual consistency.

29
00:01:10.004 --> 00:01:13.001
For the record, B is basically available

30
00:01:13.001 --> 00:01:15.004
and S is a soft state,

31
00:01:15.004 --> 00:01:19.002
meaning the data shifts and is eventually consistent,

32
00:01:19.002 --> 00:01:21.006
so it is always soft and malleable,

33
00:01:21.006 --> 00:01:24.002
and not durable like an ACID.

34
00:01:24.002 --> 00:01:27.000
And the A is just part of basically.

35
00:01:27.000 --> 00:01:30.001
This eventual consistency model allows us

36
00:01:30.001 --> 00:01:32.007
to speed up writes to a database

37
00:01:32.007 --> 00:01:36.000
with trust that the technology will distribute the data

38
00:01:36.000 --> 00:01:37.008
to wherever it is needed.

39
00:01:37.008 --> 00:01:40.007
Again, this is paramount in distributed computing

40
00:01:40.007 --> 00:01:43.009
when an atomic write across the globe

41
00:01:43.009 --> 00:01:47.002
may time out the client calling the service.

42
00:01:47.002 --> 00:01:49.004
We allow the tooling to do its job

43
00:01:49.004 --> 00:01:53.003
through asynchronous communications.

44
00:01:53.003 --> 00:01:56.003
Now, I'm not going to go into actual algorithms at play

45
00:01:56.003 --> 00:01:58.005
in a tool like Apache Cassandra,

46
00:01:58.005 --> 00:02:01.007
and how it achieves eventual consistency

47
00:02:01.007 --> 00:02:03.009
but I am going to talk about the processing

48
00:02:03.009 --> 00:02:06.005
at a very high level.

49
00:02:06.005 --> 00:02:09.003
We have our distributed database clusters.

50
00:02:09.003 --> 00:02:12.004
In this model, I am sowing a single instance

51
00:02:12.004 --> 00:02:14.004
but usually, this is a cluster,

52
00:02:14.004 --> 00:02:16.007
which will be clear in a moment.

53
00:02:16.007 --> 00:02:19.002
These databases are geographically distributed

54
00:02:19.002 --> 00:02:22.007
across a region or the entire globe.

55
00:02:22.007 --> 00:02:25.001
These databases know about each other,

56
00:02:25.001 --> 00:02:28.008
and in this example, all have the same data.

57
00:02:28.008 --> 00:02:32.002
Sharding is a concept outside the scope of this course,

58
00:02:32.002 --> 00:02:35.002
so we still have full replication.

59
00:02:35.002 --> 00:02:36.005
We have a client that connects

60
00:02:36.005 --> 00:02:39.007
to its regional database for information.

61
00:02:39.007 --> 00:02:42.004
When it writes data, it sends it to the local database

62
00:02:42.004 --> 00:02:45.003
and gets a response that it is written.

63
00:02:45.003 --> 00:02:46.008
Now, at this point,

64
00:02:46.008 --> 00:02:49.002
the other two instances don't have the data,

65
00:02:49.002 --> 00:02:50.009
only A does.

66
00:02:50.009 --> 00:02:52.003
Now, within A,

67
00:02:52.003 --> 00:02:55.002
there may be internal replication of the data,

68
00:02:55.002 --> 00:02:59.000
and really, there should be to ensure that it isn't lost.

69
00:02:59.000 --> 00:03:01.007
This can be asynchronous or synchronous depending

70
00:03:01.007 --> 00:03:03.005
on the configuration.

71
00:03:03.005 --> 00:03:05.006
In Apache Cassandra, for instance,

72
00:03:05.006 --> 00:03:07.009
you can use quorum to determine how many nodes

73
00:03:07.009 --> 00:03:09.009
of the ring needs to have the data

74
00:03:09.009 --> 00:03:12.004
before the acknowledgement is even sent.

75
00:03:12.004 --> 00:03:13.008
But staying at a high level,

76
00:03:13.008 --> 00:03:18.000
let's just ignore how data is replicated internally.

77
00:03:18.000 --> 00:03:20.006
Now, the client goes away with its work

78
00:03:20.006 --> 00:03:22.007
but now the asynchronous messaging

79
00:03:22.007 --> 00:03:25.001
of the database comes into play.

80
00:03:25.001 --> 00:03:27.008
It will use messaging of some form

81
00:03:27.008 --> 00:03:29.004
to replay the state change

82
00:03:29.004 --> 00:03:31.008
to the other two databases.

83
00:03:31.008 --> 00:03:35.005
At some point, they will become consistent.

84
00:03:35.005 --> 00:03:39.002
Now, while this is done through asynchronous communications,

85
00:03:39.002 --> 00:03:41.009
the developer really has nothing to do here.

86
00:03:41.009 --> 00:03:43.009
The tooling does it all.

87
00:03:43.009 --> 00:03:47.000
However, you can achieve similar characteristics

88
00:03:47.000 --> 00:03:49.006
on your own or other systems,

89
00:03:49.006 --> 00:03:52.008
and we'll talk a little bit about that later.

90
00:03:52.008 --> 00:03:55.002
Now, of course, there are a few trades-offs

91
00:03:55.002 --> 00:03:57.009
and while this isn't a course on distributed data,

92
00:03:57.009 --> 00:04:00.002
your microservices architecture needs

93
00:04:00.002 --> 00:04:02.000
to take these into account

94
00:04:02.000 --> 00:04:04.006
because they can directly impact the utilization

95
00:04:04.006 --> 00:04:06.005
of the system.

96
00:04:06.005 --> 00:04:09.003
Latent reads are possible in this model.

97
00:04:09.003 --> 00:04:10.008
If you write data

98
00:04:10.008 --> 00:04:12.009
and then immediately read it,

99
00:04:12.009 --> 00:04:14.007
if you hit a new node in your cluster

100
00:04:14.007 --> 00:04:16.000
or global distribution,

101
00:04:16.000 --> 00:04:20.001
you may not have the data available that you just wrote.

102
00:04:20.001 --> 00:04:23.009
This impacts the design of your microservices in general.

103
00:04:23.009 --> 00:04:25.007
You either need localized caches

104
00:04:25.007 --> 00:04:27.008
to prevent this from happening,

105
00:04:27.008 --> 00:04:30.000
increase the likelihood of data being there

106
00:04:30.000 --> 00:04:33.004
by taking a performance hit through higher quorum counts

107
00:04:33.004 --> 00:04:38.003
or just accept it and build in safeguards.

108
00:04:38.003 --> 00:04:40.004
You also may have to deal with these issues

109
00:04:40.004 --> 00:04:42.007
for longer periods of time.

110
00:04:42.007 --> 00:04:46.006
If communications between distributed systems fails,

111
00:04:46.006 --> 00:04:50.005
the asynchronous communications can also fail.

112
00:04:50.005 --> 00:04:53.007
As such, your microservices architecture

113
00:04:53.007 --> 00:04:56.000
may need to take this into account.

114
00:04:56.000 --> 00:04:58.008
You may need to inject configuration

115
00:04:58.008 --> 00:05:00.004
that allows for a fallback read

116
00:05:00.004 --> 00:05:03.000
from another instance of a database

117
00:05:03.000 --> 00:05:07.000
or load balance globally to prevent issues.

118
00:05:07.000 --> 00:05:08.008
This can be an ugly problem

119
00:05:08.008 --> 00:05:11.005
that isn't easy to solve.

120
00:05:11.005 --> 00:05:14.007
You may also have to deal with catastrophic failures.

121
00:05:14.007 --> 00:05:16.009
You could write data through a data service

122
00:05:16.009 --> 00:05:18.009
and the entire cluster goes down

123
00:05:18.009 --> 00:05:20.009
before distributing the data.

124
00:05:20.009 --> 00:05:24.000
You may not lose the data, though you may.

125
00:05:24.000 --> 00:05:27.007
But regardless, the data may not be available anywhere

126
00:05:27.007 --> 00:05:29.006
for a while at least.

127
00:05:29.006 --> 00:05:33.003
Your systems need to be built as fault tolerant as possible

128
00:05:33.003 --> 00:05:35.006
to help resolve these issues.

129
00:05:35.006 --> 00:05:37.002
Circuit breaker patterns

130
00:05:37.002 --> 00:05:40.000
can often help in this scenario.

