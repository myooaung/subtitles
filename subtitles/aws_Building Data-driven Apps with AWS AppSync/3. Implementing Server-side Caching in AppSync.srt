1
00:00:01,440 --> 00:00:05,310
To improve the performance of our GraphQL API we can implement caching.

2
00:00:05,310 --> 00:00:07,720
To view the caching settings for API,

3
00:00:07,720 --> 00:00:11,440
we need to navigate to the Caching tab on our API properties.

4
00:00:11,440 --> 00:00:15,320
Here we get to choose how we want to do server‑side caching.

5
00:00:15,320 --> 00:00:17,640
We can cache pull requests,

6
00:00:17,640 --> 00:00:21,540
which means all requests that come from the same user will be cached.

7
00:00:21,540 --> 00:00:25,440
And for subsequent requests, cached data will be returned.

8
00:00:25,440 --> 00:00:28,440
If we choose this option, we don't have to change anything,

9
00:00:28,440 --> 00:00:32,640
and all requests will be cached automatically.

10
00:00:32,640 --> 00:00:35,040
We can also do per‑resolver caching,

11
00:00:35,040 --> 00:00:40,340
which will return cached data for only specific operations.

12
00:00:40,340 --> 00:00:41,720
If we choose this option,

13
00:00:41,720 --> 00:00:47,060
then each resolver has to opt in to cache because by default

14
00:00:47,060 --> 00:00:50,120
nothing will be cached unless we tell it so.

15
00:00:50,120 --> 00:00:53,570
For this demo, let's choose per‑resolver caching,

16
00:00:53,570 --> 00:00:56,040
as this is more complicated to set up.

17
00:00:56,040 --> 00:01:02,840
And we will opt into cache list.GlobomanticsTask query later on.

18
00:01:02,840 --> 00:01:06,940
For either caching options, we need to choose some caching settings.

19
00:01:06,940 --> 00:01:09,740
First, we need to choose on instance type.

20
00:01:09,740 --> 00:01:13,340
This will heavily depend on your application size.

21
00:01:13,340 --> 00:01:17,740
If you have a small application, then you might choose a small instance type.

22
00:01:17,740 --> 00:01:21,540
Each instance has the amount of cache that can be stored in it.

23
00:01:21,540 --> 00:01:23,880
For this demo let's use the smallest cache,

24
00:01:23,880 --> 00:01:29,740
which is cache.small so we can incur the least amount of charges.

25
00:01:29,740 --> 00:01:33,640
We also need to specify a time to live for cached entries.

26
00:01:33,640 --> 00:01:37,140
The default is 60 seconds, or 1 minute.

27
00:01:37,140 --> 00:01:39,840
Typically, 1 minute is a good option.

28
00:01:39,840 --> 00:01:42,880
But if we need data to be cached for longer or less,

29
00:01:42,880 --> 00:01:45,280
then we will need to set this here.

30
00:01:45,280 --> 00:01:48,800
Depending on the frequency at which our data changes and how

31
00:01:48,800 --> 00:01:51,110
important it is that we have the information right away,

32
00:01:51,110 --> 00:01:53,890
we need to provide an appropriate value here.

33
00:01:53,890 --> 00:01:57,270
For this demo I'm going to leave it as 60 seconds.

34
00:01:57,270 --> 00:02:02,340
And finally, we can decide if and how we want to encrypt the data.

35
00:02:02,340 --> 00:02:04,290
We have both options for in transit,

36
00:02:04,290 --> 00:02:07,960
which will encrypt the data over the network and at rest,

37
00:02:07,960 --> 00:02:11,840
which will encrypt the data that is in the cache as well.

38
00:02:11,840 --> 00:02:12,660
For this demo,

39
00:02:12,660 --> 00:02:14,940
I'm going to leave these options and unchecked since I

40
00:02:14,940 --> 00:02:17,240
don't want my data to be encrypted.

41
00:02:17,240 --> 00:02:20,960
Also, it's important to know that caching is priced separately,

42
00:02:20,960 --> 00:02:23,040
which means we need to take into consideration the

43
00:02:23,040 --> 00:02:24,870
cost as well when we set this up.

44
00:02:24,870 --> 00:02:27,510
To view the list of prices for each instance,

45
00:02:27,510 --> 00:02:31,140
we can use the pricing link at the top.

46
00:02:31,140 --> 00:02:34,310
Here we can see a list of all instance types,

47
00:02:34,310 --> 00:02:38,440
the CPUs, memory, network performance, and price.

48
00:02:38,440 --> 00:02:39,720
The price is hourly.

49
00:02:39,720 --> 00:02:43,880
Since this is a dedicated instance, we are going to be charged constantly,

50
00:02:43,880 --> 00:02:48,450
not for the amount that we use, but we can delete it at any time.

51
00:02:48,450 --> 00:02:52,540
Now let's navigate back to our API settings and create our caching.

52
00:02:52,540 --> 00:02:57,840
As soon as we hit the Create button, our cache instance will start provisioning.

53
00:02:57,840 --> 00:03:02,970
Now, if we scroll up, at the very top we can see the cache status.

54
00:03:02,970 --> 00:03:05,740
Right now, the cache status is still creating.

55
00:03:05,740 --> 00:03:08,380
Here we get the option to delete the cache.

56
00:03:08,380 --> 00:03:11,450
Optionally we can flush the cache as well if for some

57
00:03:11,450 --> 00:03:13,740
reason our records become stale.

58
00:03:13,740 --> 00:03:16,010
Now that our cache has been created,

59
00:03:16,010 --> 00:03:20,840
we need to go into our resolver and specify the caching settings.

60
00:03:20,840 --> 00:03:21,300
First,

61
00:03:21,300 --> 00:03:27,820
we need to navigate to the schema and find our list.GlobomanticsTask query.

62
00:03:27,820 --> 00:03:33,640
Here let's open up the resolver details.

63
00:03:33,640 --> 00:03:38,450
And now if we navigate to the very bottom we have a new

64
00:03:38,450 --> 00:03:40,670
setting tab called Cache settings.

65
00:03:40,670 --> 00:03:44,440
Here we can decide to enable or disable caching for this resolver.

66
00:03:44,440 --> 00:03:48,150
This option was not there before until we enabled caching for our API.

67
00:03:48,150 --> 00:03:53,840
Now let's enable caching and set the time to live to 60 seconds.

68
00:03:53,840 --> 00:03:59,340
And also we need to save our changes using the Save Resolver button.

69
00:03:59,340 --> 00:04:01,060
Now that our changes are saved,

70
00:04:01,060 --> 00:04:03,350
let's head back to our client application and make a few

71
00:04:03,350 --> 00:04:07,040
requests so we can generate some metrics.

72
00:04:07,040 --> 00:04:10,850
We can quickly generate some requests using the Refresh button which will

73
00:04:10,850 --> 00:04:14,320
call the loadTasks function and load all the tasks.

74
00:04:14,320 --> 00:04:17,560
After we have called the back end a couple of times now,

75
00:04:17,560 --> 00:04:20,780
let's navigate back to our API definition.

76
00:04:20,780 --> 00:04:24,700
Here we need to navigate to the Monitoring tab so we

77
00:04:24,700 --> 00:04:26,510
can view the cache statistics.

78
00:04:26,510 --> 00:04:30,450
Here on the Monitoring tab now we have some caching

79
00:04:30,450 --> 00:04:33,100
information since we enabled caching on our API.

80
00:04:33,100 --> 00:04:35,810
We can see that our cache is being hit.

81
00:04:35,810 --> 00:04:40,400
Instead of calling the DynamoDB, now our API is getting data from the cache.

82
00:04:40,400 --> 00:04:44,880
Also, on the right side, we can see the cached amount of data in megabytes.

83
00:04:44,880 --> 00:04:48,940
And also If we look at the latency graph,

84
00:04:48,940 --> 00:04:53,730
we can see that the latency for the latest requests has dropped because now

85
00:04:53,730 --> 00:04:57,340
it's getting data from the cache and not from the DynamoDB.

86
00:04:57,340 --> 00:04:59,970
If we have a big application that users continuously

87
00:04:59,970 --> 00:05:07,000
request data that could be cached, then enabling caching will improve our API drastically.

