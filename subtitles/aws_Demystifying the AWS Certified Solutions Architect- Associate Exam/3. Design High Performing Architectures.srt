1
00:00:02,340 --> 00:00:05,580
[Autogenerated] we're not going to discuss our next exam.

2
00:00:05,580 --> 00:00:10,400
Objective-C Designing high performance architectures In

3
00:00:10,400 --> 00:00:12,640
order to really grasp what's here,

4
00:00:12,640 --> 00:00:18,240
you need to understand storage things like S3 things like apps,

5
00:00:18,240 --> 00:00:21,130
things like AD FS different storage types.

6
00:00:21,130 --> 00:00:24,080
You also need to be familiar with different compute options,

7
00:00:24,080 --> 00:00:28,300
both serverless computing like Lambda Functions or containers,

8
00:00:28,300 --> 00:00:31,140
as well as two instances.

9
00:00:31,140 --> 00:00:33,850
Networking is also another factor that can come up,

10
00:00:33,850 --> 00:00:39,180
so make sure you're familiar with VPC and virtual

11
00:00:39,180 --> 00:00:41,300
private gateways and even direct connect.

12
00:00:41,300 --> 00:00:44,340
We've covered these a little bit and other objectives,

13
00:00:44,340 --> 00:00:49,340
but you may want to spend more time researching these things.

14
00:00:49,340 --> 00:00:52,110
You also wanna be familiar with different types of database

15
00:00:52,110 --> 00:00:54,730
is we won't cover them specifically here.

16
00:00:54,730 --> 00:00:58,190
You need to have study these on your own need to make sure you're

17
00:00:58,190 --> 00:01:04,940
familiar with our AD DS with dynamodb with document DB With red shift

18
00:01:04,940 --> 00:01:10,110
with elastic cache These are key database is even Neptune that you

19
00:01:10,110 --> 00:01:11,280
need to be familiar with them.

20
00:01:11,280 --> 00:01:12,740
You don't even know a lot of detail,

21
00:01:12,740 --> 00:01:14,800
but you need to know the basics so that you can answer

22
00:01:14,800 --> 00:01:19,250
questions to help you when you are asked for a particular type

23
00:01:19,250 --> 00:01:22,740
of database to use for a given solution.

24
00:01:22,740 --> 00:01:26,170
This will help you tackle these tough questions on the exam,

25
00:01:26,170 --> 00:01:31,040
so make sure you'd spend time in this area.

26
00:01:31,040 --> 00:01:37,190
Understanding, storage and database is is key to creating performance,

27
00:01:37,190 --> 00:01:40,740
storage and architectures.

28
00:01:40,740 --> 00:01:43,440
These topics can be quite deep,

29
00:01:43,440 --> 00:01:47,060
so it's important that you have experience with each of

30
00:01:47,060 --> 00:01:51,540
these and understand the key features.

31
00:01:51,540 --> 00:01:56,460
We talked about EBS volumes earlier from a different perspective.

32
00:01:56,460 --> 00:01:59,440
Talking about resiliency and reliability.

33
00:01:59,440 --> 00:02:03,430
The focus in this area of the exam is to choose the

34
00:02:03,430 --> 00:02:06,950
correct volume type for a given need,

35
00:02:06,950 --> 00:02:10,240
knowing the performance characteristics of the volume,

36
00:02:10,240 --> 00:02:14,900
it's important to understand when an SSD Docker is best and when

37
00:02:14,900 --> 00:02:18,240
traditional hard Docker technology is best.

38
00:02:18,240 --> 00:02:26,040
SSD technology dominates when you have random reads from the Docker.

39
00:02:26,040 --> 00:02:30,230
But if you're looking for sequential reads and writes than a

40
00:02:30,230 --> 00:02:35,040
traditional HDD is going to provide much better performance.

41
00:02:35,040 --> 00:02:39,060
The exam questions will attempt to confuse you on

42
00:02:39,060 --> 00:02:41,400
when to use which storage type,

43
00:02:41,400 --> 00:02:53,140
so make sure you understand when to use each type for a given use case.

44
00:02:53,140 --> 00:02:58,520
The next area of storage will look at is S3.

45
00:02:58,520 --> 00:03:03,140
If you're not familiar with the various storage classes within S3,

46
00:03:03,140 --> 00:03:08,640
you should learn them and know when to use one storage class versus another.

47
00:03:08,640 --> 00:03:12,280
The cost aspects of S3 are important to understand.

48
00:03:12,280 --> 00:03:14,100
For this knowledge area,

49
00:03:14,100 --> 00:03:19,730
make sure that you know that you only pay for what you use

50
00:03:19,730 --> 00:03:22,740
and it's measured in gigabytes per month.

51
00:03:22,740 --> 00:03:23,340
Also,

52
00:03:23,340 --> 00:03:26,650
make sure you understand that you pay for transferring data

53
00:03:26,650 --> 00:03:31,640
out of the region where the data resides.

54
00:03:31,640 --> 00:03:38,570
You also will pay for puts copies post list and get requests

55
00:03:38,570 --> 00:03:44,470
from your S3 bucket and off those get requests or the most

56
00:03:44,470 --> 00:03:48,840
expensive operation you can perform in S3.

57
00:03:48,840 --> 00:03:52,890
If you need to cache frequently access data such as

58
00:03:52,890 --> 00:03:55,650
company logos or product manuals.

59
00:03:55,650 --> 00:04:03,140
Other static content, then S3 convey a great place to store this type of data.

60
00:04:03,140 --> 00:04:07,840
Although there are other types of database is available within AD DS,

61
00:04:07,840 --> 00:04:11,340
the exam tends to focus on three of these,

62
00:04:11,340 --> 00:04:17,540
and knowing when to use each one for a given use case is important.

63
00:04:17,540 --> 00:04:23,640
RDS is Amazon's manage relational database,

64
00:04:23,640 --> 00:04:26,430
and there are several database types to choose from

65
00:04:26,430 --> 00:04:30,460
within our AD DS for the exam.

66
00:04:30,460 --> 00:04:35,940
Make sure you know all six database engines that are supported.

67
00:04:35,940 --> 00:04:42,120
Also, make sure you understand how read replicas are used with our AD DS,

68
00:04:42,120 --> 00:04:47,340
as well as how multi ese deployments function within RDS,

69
00:04:47,340 --> 00:04:48,160
particularly,

70
00:04:48,160 --> 00:04:51,170
you need to understand that replication from the master to the

71
00:04:51,170 --> 00:04:55,940
standby instantiate is done synchronously.

72
00:04:55,940 --> 00:04:59,440
If you need to manage no SQL database is,

73
00:04:59,440 --> 00:05:05,340
then you can use dynamodb, which allows you to allocate throughput based on read.

74
00:05:05,340 --> 00:05:08,240
Write capacity requirements.

75
00:05:08,240 --> 00:05:13,950
Reads can either be what we call strongly consistent,

76
00:05:13,950 --> 00:05:18,680
which are measured in one read per second or eventually consistent,

77
00:05:18,680 --> 00:05:21,340
which gives you two reads per second.

78
00:05:21,340 --> 00:05:23,700
Rights will always be measured.

79
00:05:23,700 --> 00:05:25,740
Is one right per second.

80
00:05:25,740 --> 00:05:27,460
If any of this is unclear,

81
00:05:27,460 --> 00:05:34,040
go back and review other Pluralsight courses that deep dive into dynamodb.

82
00:05:34,040 --> 00:05:37,640
If you need to set up a data warehouse within Amazon,

83
00:05:37,640 --> 00:05:41,780
Red shift is a much more efficient and cheaper option than

84
00:05:41,780 --> 00:05:44,340
a commercial products such as Oracle.

85
00:05:44,340 --> 00:05:46,500
Since this is an Amazon exam,

86
00:05:46,500 --> 00:05:50,950
you should never expect Oracle to be the correct answer unless the

87
00:05:50,950 --> 00:05:55,160
question focuses on least efficient or most expensive.

88
00:05:55,160 --> 00:06:00,240
But typically, Amazon does not word their questions this way.

89
00:06:00,240 --> 00:06:05,250
It's important to understand the use cases in the question and select the

90
00:06:05,250 --> 00:06:10,510
appropriate database technology when you need to cache content.

91
00:06:10,510 --> 00:06:15,190
In AWS, there are many ways this could be accomplished,

92
00:06:15,190 --> 00:06:19,640
but the exam we only focus on three of these.

93
00:06:19,640 --> 00:06:21,500
The first of these is cloudfront,

94
00:06:21,500 --> 00:06:28,940
which can be used to cache both dynamic and static content at the edge.

95
00:06:28,940 --> 00:06:34,010
When we use cloudfront to cache the content close to our end users,

96
00:06:34,010 --> 00:06:38,610
Cloudfront takes advantage of the AWS edge locations.

97
00:06:38,610 --> 00:06:44,850
How it works is the user request is routed to the lowest latency edge location.

98
00:06:44,850 --> 00:06:47,690
It may not be the closest one geographically,

99
00:06:47,690 --> 00:06:49,940
but it will have the lowest latency.

100
00:06:49,940 --> 00:06:54,740
Non cache content is then copied from the origin to the edge,

101
00:06:54,740 --> 00:07:00,620
and as soon as the first bite is received from the origin and into cloudfront,

102
00:07:00,620 --> 00:07:03,180
the content is then served out to the user.

103
00:07:03,180 --> 00:07:08,610
When the next user requests the same data, it will already be in the cache.

104
00:07:08,610 --> 00:07:18,440
If you want to protect content with cloud front, you can use Oh a uh, SSL.

105
00:07:18,440 --> 00:07:22,140
Ohh stands for origin, access identity,

106
00:07:22,140 --> 00:07:28,400
and it's used to restrict access by only allowing access to the origin by

107
00:07:28,400 --> 00:07:32,840
going through cloudfront and it's URL instead of directly,

108
00:07:32,840 --> 00:07:35,240
maybe like you could within S3 bucket.

109
00:07:35,240 --> 00:07:40,740
Cloudfront also supports SSL certificates This works great

110
00:07:40,740 --> 00:07:43,340
for the web layer of our architecture.

111
00:07:43,340 --> 00:07:46,820
But what about the application and database layers?

112
00:07:46,820 --> 00:07:50,340
How does caching work for those services?

113
00:07:50,340 --> 00:07:51,900
Well, we have a couple of options.

114
00:07:51,900 --> 00:07:56,440
The first of these is the last two cache men cache D.

115
00:07:56,440 --> 00:07:57,430
And with this,

116
00:07:57,430 --> 00:08:00,330
we're gonna place in the last two cache note in front of

117
00:08:00,330 --> 00:08:05,120
our database to cache frequently access queries to take

118
00:08:05,120 --> 00:08:07,070
pressure off of the database.

119
00:08:07,070 --> 00:08:12,940
The whole focus of caching is to take the pressure off the database.

120
00:08:12,940 --> 00:08:17,610
Men cache is best served and best suited to cache

121
00:08:17,610 --> 00:08:20,440
content from relational databases,

122
00:08:20,440 --> 00:08:25,720
whereas Red is is a better choice when we're dealing with.

123
00:08:25,720 --> 00:08:32,850
No SQL database is such as dynamodb, even though it's not covered in the exam.

124
00:08:32,850 --> 00:08:37,210
Dax or Dynamo DB accelerator is actually a better choice

125
00:08:37,210 --> 00:08:40,120
when we're working with Dynamodb because it's designed to

126
00:08:40,120 --> 00:08:42,840
work specifically with it.

127
00:08:42,840 --> 00:08:47,620
Many modern online games make use of red is because of its ability to

128
00:08:47,620 --> 00:08:52,040
create leaderboards and perform calculations in real time.

129
00:08:52,040 --> 00:08:52,490
Also,

130
00:08:52,490 --> 00:08:56,380
its support for read replicas makes it very powerful because if you lose a node,

131
00:08:56,380 --> 00:08:59,040
you don't lose all your data that's in cache.

132
00:08:59,040 --> 00:09:03,610
Unlike men, cache T in order to make our infrastructure perform,

133
00:09:03,610 --> 00:09:09,040
regardless of customer traffic, we must be able to scale it.

134
00:09:09,040 --> 00:09:13,840
There are two types of scaling that you should be familiar with for the exam,

135
00:09:13,840 --> 00:09:18,120
horizontal scaling and vertical scaling With vertical scaling.

136
00:09:18,120 --> 00:09:21,330
There's upper limits to to how far we can scale.

137
00:09:21,330 --> 00:09:24,900
Because we're gonna hit physical hardware limitations because we're

138
00:09:24,900 --> 00:09:29,880
increasing the number of CPUC and the amount of RAM and we can only

139
00:09:29,880 --> 00:09:33,740
increase these by so much they have finite limits.

140
00:09:33,740 --> 00:09:37,200
The other type of scaling is horizontal scaling,

141
00:09:37,200 --> 00:09:38,960
and with horizontal scaling,

142
00:09:38,960 --> 00:09:43,050
it is only limited by the capacity allocation of your account.

143
00:09:43,050 --> 00:09:44,670
If you need more instances,

144
00:09:44,670 --> 00:09:51,140
you can always submit a ticket and requests a limit increase for your account.

145
00:09:51,140 --> 00:09:55,540
Horizontal scaling takes advantage of auto scaling,

146
00:09:55,540 --> 00:09:58,400
which allows instances to be created and terminated

147
00:09:58,400 --> 00:10:01,310
automatically whenever you use auto scaling.

148
00:10:01,310 --> 00:10:04,450
You will also want to take advantage of the elastic load

149
00:10:04,450 --> 00:10:08,110
balance or capabilities to help you evenly distribute

150
00:10:08,110 --> 00:10:10,440
traffic between your instances.

151
00:10:10,440 --> 00:10:13,160
When you use theological load balancer,

152
00:10:13,160 --> 00:10:18,170
you can also distribute traffic across multiple availability zones to

153
00:10:18,170 --> 00:10:21,940
provide high availability as well as fault tolerance.

154
00:10:21,940 --> 00:10:27,120
To answer questions on the exam related to auto scaling make sure you understand

155
00:10:27,120 --> 00:10:32,140
the three components of auto scaling launch configurations,

156
00:10:32,140 --> 00:10:37,740
which specifies the instant size in the AM I that you're gonna use.

157
00:10:37,740 --> 00:10:40,420
These can only be copied or replaced.

158
00:10:40,420 --> 00:10:44,140
You cannot modify a launch configuration.

159
00:10:44,140 --> 00:10:47,400
So if an exam question says, modify the launch configuration,

160
00:10:47,400 --> 00:10:51,140
you can immediately eliminated because that's not possible.

161
00:10:51,140 --> 00:10:56,480
The second aspect of auto scaling is auto scaling groups.

162
00:10:56,480 --> 00:10:59,440
They will reference the launch config.

163
00:10:59,440 --> 00:11:01,100
They'll specify the men,

164
00:11:01,100 --> 00:11:04,110
the max and the desired size of the auto scaling

165
00:11:04,110 --> 00:11:08,540
group with the elastic load balancer.

166
00:11:08,540 --> 00:11:14,040
You can also references the auto skip from the auto Scaling group,

167
00:11:14,040 --> 00:11:18,040
and health checks can be set up for the group.

168
00:11:18,040 --> 00:11:22,130
The third component is three auto scaling policy.

169
00:11:22,130 --> 00:11:26,840
This specifies how much we should scale in and out,

170
00:11:26,840 --> 00:11:32,740
and multiple policies can be attached to an auto scaling group.

171
00:11:32,740 --> 00:11:39,240
The third area to pay attention to on the exam is CloudWatch metrics.

172
00:11:39,240 --> 00:11:44,440
Make sure you know what metrics can do monitored at the hyper visor

173
00:11:44,440 --> 00:11:49,140
level like CPU utilization and network bandwidth,

174
00:11:49,140 --> 00:11:54,640
as well as metrics like disk space utilization that can't be seen

175
00:11:54,640 --> 00:11:59,920
at the hyper visor level that require CloudWatch agent to be

176
00:11:59,920 --> 00:12:02,940
installed inside of the two instance.

177
00:12:02,940 --> 00:12:06,900
Also remember that default monitoring is at five minute intervals,

178
00:12:06,900 --> 00:12:11,040
and detailed monitoring is at one minute intervals.

179
00:12:11,040 --> 00:12:15,270
Make sure you know how to read CloudWatch logs and

180
00:12:15,270 --> 00:12:19,240
understand the metrics involved with those.

181
00:12:19,240 --> 00:12:23,640
When you put all of these components together,

182
00:12:23,640 --> 00:12:26,760
it's common moving to the next exam objectives.

183
00:12:26,760 --> 00:12:29,240
Let's take a look officially auto scale.

184
00:12:29,240 --> 00:12:32,270
Your internet get you ready for me to understand how these all

185
00:12:32,270 --> 00:12:36,950
fit together and how we can use CloudWatch alarms to monitor

186
00:12:36,950 --> 00:12:40,840
metrics like CPI utilization in scale.

187
00:12:40,840 --> 00:12:46,560
Based on that other services that are covered on the exam around

188
00:12:46,560 --> 00:12:53,370
this objective are as follows CloudFormation What you need to

189
00:12:53,370 --> 00:12:55,950
remember about CloudFormation that is,

190
00:12:55,950 --> 00:13:00,740
uses a declarative programming language for resource deployment.

191
00:13:00,740 --> 00:13:06,630
It supports both JSON and YAML file in CloudFormation is used to create

192
00:13:06,630 --> 00:13:10,780
automated and repeatable deployments of our cloud infrastructure,

193
00:13:10,780 --> 00:13:12,730
using something called stacks.

194
00:13:12,730 --> 00:13:16,920
CloudFormation is a very large subject by itself,

195
00:13:16,920 --> 00:13:19,390
so please make sure to review the recommended

196
00:13:19,390 --> 00:13:22,640
resource is before attempting the exam.

197
00:13:22,640 --> 00:13:26,570
The next thing we want to look at is auto scaling auto.

198
00:13:26,570 --> 00:13:29,930
Skilling was discussed in another portion of this module.

199
00:13:29,930 --> 00:13:34,450
The key take away is that it is an important component for

200
00:13:34,450 --> 00:13:39,140
designing scalable and resilient architectures.

201
00:13:39,140 --> 00:13:42,620
The last service that you wanna pay attention to on the exam for

202
00:13:42,620 --> 00:13:48,700
this component is Lambda Lambda is a fully managed compute service

203
00:13:48,700 --> 00:13:53,710
that runs stateless code multiple programming languages supported

204
00:13:53,710 --> 00:13:58,440
with lambda like python and C#, for example,

205
00:13:58,440 --> 00:14:02,680
Lambda actually has the support to bring other languages.

206
00:14:02,680 --> 00:14:08,240
So if an engineer wanted to use something like COBOL, that would be possible.

207
00:14:08,240 --> 00:14:10,360
Lambda is what is known as serve.

208
00:14:10,360 --> 00:14:15,770
URL is computing because you can execute code without having to

209
00:14:15,770 --> 00:14:19,760
manage servers before we move on to the next exam.

210
00:14:19,760 --> 00:14:20,710
Objective-C.

211
00:14:20,710 --> 00:14:23,680
Let's take a few minutes to review a couple of sample

212
00:14:23,680 --> 00:14:27,520
exam questions and discuss how to tackle these types of

213
00:14:27,520 --> 00:14:30,440
questions When taking the exam.

214
00:14:30,440 --> 00:14:33,540
Take a look at our first practice question.

215
00:14:33,540 --> 00:14:34,360
The RDS.

216
00:14:34,360 --> 00:14:37,770
My SQL database is getting lots of reads and has become

217
00:14:37,770 --> 00:14:41,640
a bottleneck for the application.

218
00:14:41,640 --> 00:14:45,450
What actions can be performed to ensure that the database

219
00:14:45,450 --> 00:14:50,090
does not remain a performance bottleneck?

220
00:14:50,090 --> 00:14:54,620
Set up a cloudfront distribution in front of the database set up

221
00:14:54,620 --> 00:14:58,950
in elastic load balancer in front of the database set up in the

222
00:14:58,950 --> 00:15:04,470
last two cache cluster in front of the database or D set up s and

223
00:15:04,470 --> 00:15:07,310
s in front of the database.

224
00:15:07,310 --> 00:15:09,830
Take a moment and think about it.

225
00:15:09,830 --> 00:15:15,640
Pause your video, and when you're ready to answer, come back.

226
00:15:15,640 --> 00:15:17,740
So the answer is C.

227
00:15:17,740 --> 00:15:24,050
We already know from the question that the database has become a

228
00:15:24,050 --> 00:15:26,940
performance bottleneck for the application.

229
00:15:26,940 --> 00:15:29,640
So we need to address that.

230
00:15:29,640 --> 00:15:33,950
Well, a cloudfront distribution is not gonna help you in front of a database.

231
00:15:33,950 --> 00:15:37,040
That's not a typical architecture that we see.

232
00:15:37,040 --> 00:15:38,510
So that's not a good answer.

233
00:15:38,510 --> 00:15:40,740
So they could be eliminated,

234
00:15:40,740 --> 00:15:43,960
be to set up in elastic load balancer in front of the database.

235
00:15:43,960 --> 00:15:47,500
We don't typically do that because you don't use database is that

236
00:15:47,500 --> 00:15:49,360
way where you put him behind a load balancers.

237
00:15:49,360 --> 00:15:52,840
Those are for application servers and Web servers.

238
00:15:52,840 --> 00:15:56,180
And then option D is to set up S and s in front of the database.

239
00:15:56,180 --> 00:15:57,480
That's not gonna help you, either.

240
00:15:57,480 --> 00:16:00,340
All that's going to do is send notifications.

241
00:16:00,340 --> 00:16:04,340
C is the only choice in this case to set up in Alaska cache

242
00:16:04,340 --> 00:16:08,750
cluster in front of the database because the Alaska cache cluster

243
00:16:08,750 --> 00:16:11,540
can do take pressure off of the database.

244
00:16:11,540 --> 00:16:15,950
If you remember when we talked about databases and caching?

245
00:16:15,950 --> 00:16:17,200
We talked about men.

246
00:16:17,200 --> 00:16:22,770
Cache de and read is men cache D would be what we would use for

247
00:16:22,770 --> 00:16:25,740
this RDS database to take the pressure off of it.

248
00:16:25,740 --> 00:16:28,340
Let's look at another question.

249
00:16:28,340 --> 00:16:32,050
A company has an application hosted in AWS.

250
00:16:32,050 --> 00:16:34,650
The applications deployed on a set of E C two

251
00:16:34,650 --> 00:16:37,200
instances across two availability zones.

252
00:16:37,200 --> 00:16:39,140
For high availability.

253
00:16:39,140 --> 00:16:44,840
The infrastructure is deployed behind application load balancer.

254
00:16:44,840 --> 00:16:49,940
The following are requirements from an administrative perspective.

255
00:16:49,940 --> 00:16:53,260
Make sure notifications are sent when read requests

256
00:16:53,260 --> 00:16:56,240
exceed 1000 requests for a minute.

257
00:16:56,240 --> 00:17:01,840
Ensure notifications are sent when latency exceeds 15 seconds.

258
00:17:01,840 --> 00:17:08,440
And any API activity, which calls sensitive data, has to be monitored.

259
00:17:08,440 --> 00:17:11,120
So those are the requirements that must be met.

260
00:17:11,120 --> 00:17:14,540
For this to be a good answer.

261
00:17:14,540 --> 00:17:18,240
What meets the requirement choose to In this case,

262
00:17:18,240 --> 00:17:22,440
some of the exam questions will have you choose more than one answer.

263
00:17:22,440 --> 00:17:25,450
It will always be clear because the question itself

264
00:17:25,450 --> 00:17:29,270
won't let you pick too many or too few.

265
00:17:29,270 --> 00:17:33,330
When you're answering the questions, the exam ege and is set up to.

266
00:17:33,330 --> 00:17:34,380
Check that,

267
00:17:34,380 --> 00:17:37,790
And so if you try to have too many choices it'll give you an Arab

268
00:17:37,790 --> 00:17:40,140
won't let you advance to the next question.

269
00:17:40,140 --> 00:17:44,940
By the same token, if you have too few choices, it won't let you advance.

270
00:17:44,940 --> 00:17:47,540
So what meets the requirements?

271
00:17:47,540 --> 00:17:48,190
CloudTrail.

272
00:17:48,190 --> 00:17:55,040
To monitor API activity CloudWatch logs to monitor app activity

273
00:17:55,040 --> 00:18:00,030
CloudWatch metrics to create customer metrics and set up an alarm to

274
00:18:00,030 --> 00:18:03,640
send out notifications when the threshold is reached,

275
00:18:03,640 --> 00:18:07,300
or custom blog software to monitor latency and read request

276
00:18:07,300 --> 00:18:11,940
to the application load balancer again.

277
00:18:11,940 --> 00:18:12,920
Take a minute,

278
00:18:12,920 --> 00:18:18,840
pause the video and think about the answer to the question and come back.

279
00:18:18,840 --> 00:18:23,740
As you can see, the answer is A and C.

280
00:18:23,740 --> 00:18:27,240
If we look at the answer choices,

281
00:18:27,240 --> 00:18:30,740
you can see it says use CloudTrail to monitor API activity in choice.

282
00:18:30,740 --> 00:18:34,840
Be says, use CloudWatch logs to monitor API activity.

283
00:18:34,840 --> 00:18:38,720
CloudWatch is not used to monitor API activity.

284
00:18:38,720 --> 00:18:44,540
That is a function of CloudTrail, so you can eliminate Be immediately.

285
00:18:44,540 --> 00:18:47,640
CloudTrail is for monitoring API activity.

286
00:18:47,640 --> 00:18:50,970
The other option is to use CloudWatch metrics to create

287
00:18:50,970 --> 00:18:55,660
custom metrics and set up an alarm to send notifications

288
00:18:55,660 --> 00:18:58,040
when the thresholds are reached.

289
00:18:58,040 --> 00:19:02,540
Both of those address the key requirements in the question

290
00:19:02,540 --> 00:19:06,070
Option D is really a distracter because we don't need custom

291
00:19:06,070 --> 00:19:09,350
log software for these purpose.

292
00:19:09,350 --> 00:19:14,240
CloudWatch metrics will work great because we can create custom metrics.

293
00:19:14,240 --> 00:19:17,240
Let's look at another example.

294
00:19:17,240 --> 00:19:22,160
An application is being designed for deployment in to S3 application will

295
00:19:22,160 --> 00:19:27,640
use Amazon S3 buckets restoring as well as reading data.

296
00:19:27,640 --> 00:19:32,650
The right traffic is expected to be 6500 requests per second,

297
00:19:32,650 --> 00:19:37,640
and the re traffic is around 8000 requests per second.

298
00:19:37,640 --> 00:19:41,350
What is the best way to architect this solution for maximum

299
00:19:41,350 --> 00:19:45,460
Amazon S3 performance uses many S3 prefixes,

300
00:19:45,460 --> 00:19:50,140
as you need in parallel to achieve the required throughput,

301
00:19:50,140 --> 00:19:56,540
prefix each object name with a hex hash value along with the current date.

302
00:19:56,540 --> 00:20:01,710
Enable versioning on the S3 bucket or set up cross region replication

303
00:20:01,710 --> 00:20:07,440
and performed reads from the secondary bucket Again.

304
00:20:07,440 --> 00:20:11,140
Pause the video and think about it.

305
00:20:11,140 --> 00:20:13,200
The correct answer is B.

306
00:20:13,200 --> 00:20:15,040
Did you get that one?

307
00:20:15,040 --> 00:20:22,440
It says prefix each object name with a hex hash key along with the current date.

308
00:20:22,440 --> 00:20:26,930
Because of the amount of data that we're sending into the S3

309
00:20:26,930 --> 00:20:30,490
bucket because of all the right request going on,

310
00:20:30,490 --> 00:20:32,520
we're creating a lot of objects,

311
00:20:32,520 --> 00:20:36,870
and we're gonna want to randomize these values as much as

312
00:20:36,870 --> 00:20:44,440
possible so that our keys are clearly distinctive.

313
00:20:44,440 --> 00:20:47,300
The problem with not doing this is we can create hot

314
00:20:47,300 --> 00:20:52,240
partitions and S3 and make it more difficult to achieve

315
00:20:52,240 --> 00:20:54,310
the performance were looking for.

316
00:20:54,310 --> 00:20:57,540
So Option B is the correct answer.

317
00:20:57,540 --> 00:20:59,400
Did you get that one right?

318
00:20:59,400 --> 00:21:04,040
Let's take a look at one more question.

319
00:21:04,040 --> 00:21:07,710
A company has a workflow that sends video files through their data

320
00:21:07,710 --> 00:21:12,680
center into the cloud for trans coded they use to worker instances

321
00:21:12,680 --> 00:21:17,240
to pull trans coating jobs from sqs.

322
00:21:17,240 --> 00:21:23,040
Why is Sqs the best choice for creating a decoupled architectures?

323
00:21:23,040 --> 00:21:26,490
Sqs guarantees the order of messages.

324
00:21:26,490 --> 00:21:30,340
Sqs checks the health of the worker instances.

325
00:21:30,340 --> 00:21:36,240
Sqs makes it easier to carry out horizontal scaling of the encoding tasks

326
00:21:36,240 --> 00:21:42,340
or D sqs synchronously provides trans coating output.

327
00:21:42,340 --> 00:21:43,390
Again.

328
00:21:43,390 --> 00:21:47,340
Pause the video and think about it.

329
00:21:47,340 --> 00:21:48,570
The answer is C.

330
00:21:48,570 --> 00:21:49,750
Did you get that one?

331
00:21:49,750 --> 00:21:55,540
Sqs makes it easier to carry out horizontal scaling of the encoding tasks.

332
00:21:55,540 --> 00:21:56,870
If you remember,

333
00:21:56,870 --> 00:22:00,860
cues can help us with our worker processes because we can store

334
00:22:00,860 --> 00:22:04,920
the jobs in the queues and we can monitor the queues with

335
00:22:04,920 --> 00:22:08,170
CloudWatch as the queues get large.

336
00:22:08,170 --> 00:22:10,720
We could scale up more systems as we need to,

337
00:22:10,720 --> 00:22:14,040
and we can do this horizontally for our encoding tasks.

338
00:22:14,040 --> 00:22:18,140
That makes see the the best answer for this question.

339
00:22:18,140 --> 00:22:23,740
Let's take a look at the exam takeaways for this objective.

340
00:22:23,740 --> 00:22:32,540
First of all, for unstructured data, S3 is usually a good storage choice to pick.

341
00:22:32,540 --> 00:22:37,870
Look for caching options to improve performance like we saw in that question,

342
00:22:37,870 --> 00:22:45,710
Alaska cache I can Be very useful to take pressure off of our database is know

343
00:22:45,710 --> 00:22:50,600
when to use auto scaling for a given architectures again.

344
00:22:50,600 --> 00:22:53,800
If you go back and study the well architected framework white

345
00:22:53,800 --> 00:22:58,840
paper that will help you with this Objective-C.

346
00:22:58,840 --> 00:23:05,640
And finally, you want to select the best instantiation size for a given workload.

347
00:23:05,640 --> 00:23:10,440
You know, for a Web application, maybe you wanna use a T two.

348
00:23:10,440 --> 00:23:14,250
But if you're dealing with some CPU intensive operations,

349
00:23:14,250 --> 00:23:16,860
a T two might not be the best option.

350
00:23:16,860 --> 00:23:19,800
Maybe a C five again.

351
00:23:19,800 --> 00:23:23,280
You just have to look at what's there,

352
00:23:23,280 --> 00:23:26,810
and you need to understand all of the available options that

353
00:23:26,810 --> 00:23:33,000
that can be created for two instances. Let's move on to the next objective for the exam

