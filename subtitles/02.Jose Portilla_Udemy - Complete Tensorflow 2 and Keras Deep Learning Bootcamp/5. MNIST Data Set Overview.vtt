WEBVTT
1
00:00:05.310 --> 00:00:06.220
Welcome back.

2
00:00:06.240 --> 00:00:11.530
In this lecture we're going to discuss the amnesty dataset before we actually get started.

3
00:00:11.540 --> 00:00:13.610
Compositional neural networks and cares.

4
00:00:13.910 --> 00:00:17.780
I want to quickly take a brief moment to really understand this classical dataset.

5
00:00:17.960 --> 00:00:22.130
And if you've ever had any other course or even write a book on deep learning you've probably already

6
00:00:22.130 --> 00:00:27.050
encountered this dataset before it's super famous in the field especially accomplished on your own networks

7
00:00:27.110 --> 00:00:28.360
and deep learning.

8
00:00:28.370 --> 00:00:32.810
I want to quickly cover some basics about it since we're going to be using really similar data concepts

9
00:00:32.870 --> 00:00:37.910
specifically the way we organize these datasets into four dimensional arrays.

10
00:00:37.920 --> 00:00:44.140
So the reason that idea quite frequently throughout the course I want to briefly cover that OK now for

11
00:00:44.140 --> 00:00:46.970
this particular dataset fortunately it's really easy to access.

12
00:00:47.000 --> 00:00:53.070
Kerry's use upload it with a built in function and carers and it has 60000 training images and 10000

13
00:00:53.110 --> 00:00:54.690
test images right off the bat.

14
00:00:54.700 --> 00:01:00.520
You can tell that it's a huge dataset and the M this dataset in case you're not familiar with it it

15
00:01:00.520 --> 00:01:04.460
contains handwritten single digits from 0 to 9.

16
00:01:04.480 --> 00:01:09.190
So here we see some examples of all the different ways people draw zeroes ones twos threes and so on

17
00:01:10.840 --> 00:01:11.100
now.

18
00:01:11.110 --> 00:01:18.060
As you may imagine a single digit image can be represented as an array so specifically in this dataset

19
00:01:18.330 --> 00:01:24.810
the arrays are 28 by 28 and they're just pixels where the value of 0 represents white and the value

20
00:01:24.870 --> 00:01:27.270
of 1 represents black.

21
00:01:27.300 --> 00:01:32.190
So these values are grayscale meaning we only have a single colour channel and it's also important to

22
00:01:32.190 --> 00:01:38.160
note here is that it's been standardised or normalized so you can see all the values fall between 0

23
00:01:38.190 --> 00:01:41.650
and 1 instead of values from 0 to two hundred fifty five.

24
00:01:41.760 --> 00:01:46.370
That's really gonna help our new old network learn on this particular sorts of datasets.

25
00:01:46.380 --> 00:01:51.450
So often when we're working with Image Data we will normalize things to fall between 0 and 1.

26
00:01:51.450 --> 00:01:55.760
This dataset already has that step for us.

27
00:01:55.830 --> 00:02:01.650
Now we can think of the entire group of sixty thousand images or for the test sets ten thousand images

28
00:02:02.040 --> 00:02:07.920
as a four dimensional array and it's four dimensions because we have the dimension for all the images

29
00:02:08.360 --> 00:02:10.250
the dimension for the colour channel.

30
00:02:10.260 --> 00:02:13.790
In this case it's one and then dimension for the X and Y 28.

31
00:02:14.070 --> 00:02:16.920
So have this really large for the marginal array.

32
00:02:17.160 --> 00:02:21.750
And so it's gonna have for that mentions of sixty thousand twenty eight by twenty eight and then one.

33
00:02:21.750 --> 00:02:25.860
So we have the samples the X and the Y and then number of colour channels.

34
00:02:25.860 --> 00:02:30.450
In this case we have just a single colour channel because it's grayscale the four colour images that

35
00:02:30.450 --> 00:02:35.640
last dimension value would be three because we'd have one value for red one value for green and a one

36
00:02:35.640 --> 00:02:42.850
vote for blue all standardized between 0 and 1 now for the actual labels we're going to use something

37
00:02:42.850 --> 00:02:44.750
known as one hot encoding.

38
00:02:44.950 --> 00:02:50.500
This means that instead of having categorical labels such as strings of 1 2 etc. We'll have a single

39
00:02:50.500 --> 00:02:53.490
array for each image.

40
00:02:53.510 --> 00:02:57.920
Now the original labels when you upload it and carries they're actually given as a list of numbers.

41
00:02:57.980 --> 00:03:03.590
So if the very first image is a drawing of the number five then it's corresponding label is just the

42
00:03:03.590 --> 00:03:04.560
digit five.

43
00:03:04.670 --> 00:03:07.920
And what we need to do is we need to convert that to one hot encoding.

44
00:03:07.940 --> 00:03:10.580
Again this transformation is actually really easily done of carers.

45
00:03:10.730 --> 00:03:15.980
But I want to make sure that we understand what's happening behind the scenes so what happens is the

46
00:03:15.980 --> 00:03:22.370
label is represented based off the index position in the label array the corresponding label will be

47
00:03:22.520 --> 00:03:26.310
a one at the index location and zero everywhere else.

48
00:03:26.360 --> 00:03:32.420
For example if you happen to have a drawn digit A4 then it would have this particular label array.

49
00:03:32.420 --> 00:03:39.460
Notice the index 4 so 0 1 2 3 4 that is one hot encoded to be a 1.

50
00:03:39.560 --> 00:03:45.710
And the reason we use this one hot encoding is because it works really well with a single layer output

51
00:03:46.070 --> 00:03:54.950
where we have ten neurons and then each of them is trigger to fire off a sigmoid to either 0 or 1 now

52
00:03:55.070 --> 00:03:55.850
as a result.

53
00:03:55.850 --> 00:03:59.780
The labels for the training data ends up being a really large to the array.

54
00:03:59.780 --> 00:04:06.090
So we end up having sixty thousand by ten because each of those labels is now an array of ten.

55
00:04:06.080 --> 00:04:10.490
And in case this image isn't really clear when we actually see it in num pi it looks something like

56
00:04:10.490 --> 00:04:10.760
this.

57
00:04:10.760 --> 00:04:15.030
So here's our white train for instance and we have all these one hot and coatings.

58
00:04:15.080 --> 00:04:20.690
So that means if you look at the second row that number its label is 0 because it's one hot encoded

59
00:04:20.750 --> 00:04:22.770
at one index 0.

60
00:04:22.880 --> 00:04:27.220
And for some of these other ones it deleted well has an ellipses for the middle value.

61
00:04:27.230 --> 00:04:33.660
So we can't quite tell OK so now that we understand the end this data set and one high encoding let's

62
00:04:33.660 --> 00:04:38.310
apply our new knowledge of convolution on neural networks with Kerry's on this dataset.

63
00:04:38.310 --> 00:04:39.120
Let's get started.

64
00:04:39.240 --> 00:04:40.200
I'll see you at the next lecture.
