1
00:00:05,350 --> 00:00:06,470
Welcome back everyone.

2
00:00:06,700 --> 00:00:10,930
As we begin to finish up this section on pandas we're going to take a little bit of time to discuss

3
00:00:10,930 --> 00:00:12,680
some useful operations.

4
00:00:12,710 --> 00:00:17,950
So in this lecture we're gonna go over a few but very very useful operations that didn't fit into the

5
00:00:17,950 --> 00:00:19,260
previous lectures.

6
00:00:19,270 --> 00:00:20,200
Let's get started.

7
00:00:20,200 --> 00:00:22,120
All right here I am at the Jupiter notebook.

8
00:00:22,150 --> 00:00:27,190
I've gone ahead and just copied and pasted the first cell from the operations notebook.

9
00:00:27,220 --> 00:00:32,530
So if you're here under pen this Crash Course you can go ahead and open up the operations notebook and

10
00:00:32,530 --> 00:00:36,050
essentially just copy and paste this content of the first cell.

11
00:00:36,160 --> 00:00:38,260
Once you've done that it should return back.

12
00:00:38,260 --> 00:00:44,930
This DLF one or data frame one that gives us this K1 column call 1 and call 2.

13
00:00:45,100 --> 00:00:50,980
We have just ABC and k 1 and call 1 we have one hundred two hundred etc. notice there's a repeat here

14
00:00:51,010 --> 00:00:53,120
with three hundred and in call two.

15
00:00:53,170 --> 00:00:58,270
You'll notice that states and again repeats and you can notice here that rose 2 and 3 are actually exactly

16
00:00:58,270 --> 00:00:58,660
the same.

17
00:00:59,380 --> 00:01:03,010
So first let's show you how to get information on unique values.

18
00:01:03,010 --> 00:01:08,250
Let's imagine you wanted to figure out if a data frame was maybe thousands of rows.

19
00:01:08,350 --> 00:01:11,000
What the actual unique values were.

20
00:01:11,020 --> 00:01:18,100
So here we can easily see that in column 2 we have the states New York California Washington and Arkansas

21
00:01:18,160 --> 00:01:18,940
and Nevada.

22
00:01:19,060 --> 00:01:23,440
But for a very large data frame we're not compelled to visualize everything or read everything.

23
00:01:23,680 --> 00:01:32,740
So I can say DFA one call two and I can ask for unique as a method call and return back any unique values

24
00:01:33,160 --> 00:01:39,280
so that if I do that for k 1 the unique values are ABC.

25
00:01:39,640 --> 00:01:43,920
I can also just ask for and unique which it turns back the length of that list.

26
00:01:43,960 --> 00:01:50,410
The actual number of uniques so I could do the same thing for a call 2 and see I have five unique states.

27
00:01:50,420 --> 00:01:58,260
OK finally if we wanted to get a count of all these I can say value counts and it returns back the actual

28
00:01:58,260 --> 00:02:00,750
counts per unique entry.

29
00:02:00,750 --> 00:02:06,380
This is essentially doing a group by on this column with a dot count aggregation method.

30
00:02:06,480 --> 00:02:14,180
I can also drop the duplicates so I can say D F 1 and I can call the drop duplicates method.

31
00:02:14,250 --> 00:02:21,260
Here I just had autocomplete that open in close parentheses I notice it's gonna to drop the second duplicate.

32
00:02:21,690 --> 00:02:29,040
So once it has an entry that is unique such as B 300 Washington every other entry that is exactly the

33
00:02:29,040 --> 00:02:30,350
same as that gets dropped.

34
00:02:30,360 --> 00:02:34,830
So it's going to end up keeping the very first instance and notice it jumps from two to four because

35
00:02:34,830 --> 00:02:38,790
I went ahead and dropped this three which was a duplicate if there was another row further along.

36
00:02:38,790 --> 00:02:42,420
There was also a duplicate it would drop that one as well.

37
00:02:42,430 --> 00:02:47,920
Next I want to show you how to create new columns with operations and functions specifically with the

38
00:02:47,980 --> 00:02:49,050
Apply Operator.

39
00:02:49,420 --> 00:02:53,140
So we already know that if I want to create a new column I can do something like this.

40
00:02:53,140 --> 00:03:01,870
I can say the F one reference the new column and then say based off some old column like call 1 Go ahead

41
00:03:01,870 --> 00:03:04,400
and multiply those values by 10.

42
00:03:04,900 --> 00:03:10,770
And then if I take a look at the f one I have this new column which is column 1 multiplied by 10.

43
00:03:10,810 --> 00:03:14,650
However what if I actually want to do something a lot more complex and just.

44
00:03:14,650 --> 00:03:17,900
Times it by ten or just add two other columns.

45
00:03:18,100 --> 00:03:24,550
I can actually use something known as D dot apply method to apply any functionality I want to every

46
00:03:24,550 --> 00:03:26,340
value in a column.

47
00:03:26,410 --> 00:03:32,290
So step number one is to actually define the function that will operate on every row entry in a column.

48
00:03:32,500 --> 00:03:40,420
For example let's imagine I wanted to grab the first letter here and set that as a new column first.

49
00:03:40,870 --> 00:03:45,460
I'm going to define a function called grab first letter.

50
00:03:45,460 --> 00:03:53,560
So this function takes in some state string and then it returns back the very first item in that state

51
00:03:53,560 --> 00:03:53,950
string.

52
00:03:54,670 --> 00:03:59,510
So if I were to call a grab first letter on NY it should return back.

53
00:03:59,550 --> 00:04:06,670
And now let's imagine that I wanted to use this function and create a new column based off this function

54
00:04:06,670 --> 00:04:19,190
being applied to every value in column 2 what I can do then is say def 1 and maybe I say call 2 here

55
00:04:20,630 --> 00:04:27,530
and I call the DOT apply method and I pass in that function grab first letter.

56
00:04:27,530 --> 00:04:31,460
The important thing to note here is I just pass in the raw function.

57
00:04:31,520 --> 00:04:34,250
I do not add in parentheses to call it.

58
00:04:34,790 --> 00:04:38,950
Instead I will leave that to pan this to call across the entire column.

59
00:04:39,080 --> 00:04:45,020
So if I run that this returns back the first letter of all those states which I if I wanted to I could

60
00:04:45,020 --> 00:04:54,940
then assign that to some new column like first letter is equal to column 2 with the grab first letter

61
00:04:55,000 --> 00:04:56,360
being applied to it.

62
00:04:56,470 --> 00:05:00,850
So then when I call the f 1 notice my column 2 is still in its original state.

63
00:05:00,850 --> 00:05:06,340
However I have this new first letter column based off applying this function to every item.

64
00:05:06,370 --> 00:05:12,730
Now these functions can be as complex as you want as long as it can accept the items in each row.

65
00:05:12,730 --> 00:05:16,350
So you should watch out for some data type issues that sometimes occur.

66
00:05:16,390 --> 00:05:23,300
But let me show you a slightly more complex function so we'll call this complex letter.

67
00:05:23,530 --> 00:05:29,920
Same deal it takes an estate however maybe it has some if statement check so it says hey if the state

68
00:05:30,580 --> 00:05:43,050
first letter is equal to W. then I want you to return Washington else go ahead and just return an error

69
00:05:43,420 --> 00:05:43,820
notice.

70
00:05:43,860 --> 00:05:48,540
I should be returning everything I should not be printing any sort of statement out in these apply to

71
00:05:48,540 --> 00:05:57,180
functions so the next I can say the F one column two here.

72
00:05:57,670 --> 00:06:06,100
Go ahead and apply this complex letters run it in here I can see error error Washington Washington error

73
00:06:06,190 --> 00:06:06,910
error.

74
00:06:06,910 --> 00:06:13,180
You can imagine now that you have a lot of flexibility over what you can do with your own custom functions

75
00:06:13,300 --> 00:06:18,970
applied to a column you should now be able to theoretically create any sort of column you want as long

76
00:06:18,970 --> 00:06:24,920
as I can think of a function that can be applied to every item in the actual column.

77
00:06:24,940 --> 00:06:27,340
Keep in mind you want to watch out for data type errors.

78
00:06:27,430 --> 00:06:31,810
So for example clearly this complex letter function expects a string.

79
00:06:32,200 --> 00:06:39,100
If I were to try to apply it to column 1 here which is numerical and run it I would get a type error

80
00:06:39,370 --> 00:06:44,380
and it would immediately report back hey this integer object is not something that subscript all meaning

81
00:06:44,380 --> 00:06:46,500
I can't go ahead and index off an integer.

82
00:06:46,630 --> 00:06:48,700
So keep that in mind if you get this type error.

83
00:06:48,880 --> 00:06:53,200
Check your function very carefully and then also check to make sure the column is in the correct data

84
00:06:53,200 --> 00:06:59,140
type and other thing I want to show you to quickly create new columns is mapping.

85
00:06:59,520 --> 00:07:06,270
So often you want to map different names to current values in your actual data frame.

86
00:07:06,360 --> 00:07:11,350
So if I take a look at the f one let's take a look at the K 1 column.

87
00:07:11,610 --> 00:07:12,210
It's right now.

88
00:07:12,240 --> 00:07:18,000
A's B's and C's but maybe actually wanted to map D to be one twos and threes instead.

89
00:07:18,480 --> 00:07:27,510
What I do is I define some sort of mapping dictionary so I can say my map is equal to and here I'm going

90
00:07:27,510 --> 00:07:35,760
to define a dictionary that takes an A and sets it to one takes in a b sets it to two and then takes

91
00:07:35,760 --> 00:07:39,240
an A C and sets it to three.

92
00:07:39,240 --> 00:07:47,910
So there's my mapping dictionary then all I need to do is grab the corresponding column and map my map

93
00:07:47,910 --> 00:07:51,480
to it and here it can see the results.

94
00:07:51,480 --> 00:08:01,380
So now I can maybe reassign this to be something like numbers is equal to the F one K K1 maps to my

95
00:08:01,380 --> 00:08:02,240
map.

96
00:08:02,550 --> 00:08:06,230
And then if I take a look at my data frame I see these numbers.

97
00:08:06,360 --> 00:08:12,750
Keep in mind the way the map should work is that the keys should be the existing values in the column.

98
00:08:12,750 --> 00:08:18,360
You want to map this to those values in that dictionary should then be the new result.

99
00:08:18,390 --> 00:08:21,020
So kind of pay attention closely to the ordering here.

100
00:08:21,030 --> 00:08:23,290
8 to 1 be the 2 seat the 3.

101
00:08:23,400 --> 00:08:26,020
And then you just call dot map on this.

102
00:08:26,300 --> 00:08:32,180
Finally I want to show you how to locate the index positions of Max and Min values as well as sometimes

103
00:08:32,180 --> 00:08:34,520
get column and index names.

104
00:08:34,520 --> 00:08:36,390
So we have this giant data free now.

105
00:08:36,400 --> 00:08:40,950
The f 1 let's imagine I wanted to grab the max value of column 1.

106
00:08:40,970 --> 00:08:47,330
Well I know I can do that easily by saying def 1 max and in fact I can be more specific by just saying

107
00:08:47,360 --> 00:08:54,740
Call 1 and it returns back 500 as the max if I actually wanted to figure out the location of that Max.

108
00:08:54,770 --> 00:08:57,680
All I need to do is say Ida X Max.

109
00:08:57,890 --> 00:09:03,700
And it returns back the integer based location in my case since that happens to be the index.

110
00:09:03,740 --> 00:09:04,920
It's the same for minimum.

111
00:09:05,000 --> 00:09:12,770
If I call Ida x min it returns back zero since the minimum actually happened at the very first index

112
00:09:12,770 --> 00:09:13,510
location.

113
00:09:13,640 --> 00:09:20,750
So you can use Ida x men or write the X Max to figure out the actual index for the men in the max for

114
00:09:20,750 --> 00:09:24,650
column names and index names you've actually already seen this before but just in case you don't remember

115
00:09:25,130 --> 00:09:28,430
to grab all the columns use DFA and columns.

116
00:09:28,470 --> 00:09:32,610
No it's an attribute you do not add parentheses you just have it like this.

117
00:09:32,610 --> 00:09:36,920
And what's useful about this is sometimes there's weird spacing in the strings or capitalizations a

118
00:09:36,920 --> 00:09:37,790
little strange.

119
00:09:37,820 --> 00:09:44,300
This shows you exactly what the string calls should be in actually to call those columns then we can

120
00:09:44,350 --> 00:09:45,590
use maybe reassign them.

121
00:09:45,620 --> 00:09:50,630
So if you really wanted to you could say something like the F one that columns is equal to.

122
00:09:50,870 --> 00:10:04,120
And if I wanted to I could say C1 C to make sure these are strings C three see for C5 and this should

123
00:10:04,120 --> 00:10:10,770
it match up to the exact length of the current amount of columns I have and now I have reassign the

124
00:10:10,770 --> 00:10:11,430
columns.

125
00:10:11,430 --> 00:10:15,330
Keep in mind this effect is permanent so you always want to be careful when reassigning those column

126
00:10:15,330 --> 00:10:18,050
names for ordering the data frame.

127
00:10:18,090 --> 00:10:23,100
I can always say the F1 call sort values and then choose what I want to sort fi.

128
00:10:23,310 --> 00:10:30,330
So maybe I want to sort by C3 so I run that and I notice C3 is alphabetical.

129
00:10:30,570 --> 00:10:33,840
Then I could also call ascending or descending.

130
00:10:33,840 --> 00:10:37,710
So if we expand on this you'll notice it says ascending is equal to true.

131
00:10:37,710 --> 00:10:43,290
I could just make that ascending equal to False and then I'll start at Washington and go all the way

132
00:10:43,290 --> 00:10:44,150
down.

133
00:10:44,160 --> 00:10:49,080
Notice what's really cool here is your index still keeps the same label so you can still identify it

134
00:10:49,080 --> 00:10:51,110
based off that index.

135
00:10:51,240 --> 00:10:55,590
There's just two more things left I want to show you which has to do with concatenated data frames and

136
00:10:55,590 --> 00:10:59,910
creating what are called dummy variable features which is something we'll see later on when dealing

137
00:10:59,910 --> 00:11:02,180
with the machine learning part of this course.

138
00:11:02,220 --> 00:11:08,340
So I'm going to copy and paste the cell here that's located under concatenated data frames and this

139
00:11:08,340 --> 00:11:11,340
is typically what our data structure is going to look like.

140
00:11:11,580 --> 00:11:17,400
We're gonna have some multitude of features such as feature a and feature B and then maybe we'll have

141
00:11:17,400 --> 00:11:19,790
our predictions or our labels.

142
00:11:19,830 --> 00:11:21,390
So here we can see our predictions.

143
00:11:21,390 --> 00:11:24,570
Here we have predictions of the class zeros and ones.

144
00:11:24,600 --> 00:11:28,950
Let's imagine that I wanted to join these two data frames back together.

145
00:11:28,980 --> 00:11:37,260
Well what I can do is say PD dot concatenate and I pass in a list of the data frames I want to join

146
00:11:37,260 --> 00:11:37,930
back together.

147
00:11:37,950 --> 00:11:40,710
Essentially concatenate or glue them together.

148
00:11:40,710 --> 00:11:44,550
So I would say features and then predictions.

149
00:11:44,550 --> 00:11:50,520
Now one thing to keep in mind here is you have this axes argument which by default is zero which that

150
00:11:50,520 --> 00:11:53,400
means join them along the rows.

151
00:11:53,520 --> 00:11:59,220
So you'll notice that there's this little warning that pops up because you have these issues of these

152
00:11:59,220 --> 00:12:00,050
null values.

153
00:12:00,090 --> 00:12:03,470
So this join them together but it didn't join them along the right axis.

154
00:12:03,480 --> 00:12:07,480
It took the first data frame and then took the second one and put it on the bottom.

155
00:12:07,500 --> 00:12:13,820
What I should probably do is join them along the columns say x equal to one run that.

156
00:12:13,820 --> 00:12:16,040
And that gives me the correct result that I was expecting.

157
00:12:16,460 --> 00:12:23,900
So if you want to join these like so long columns you'll passin a list into PD dot com cat and then

158
00:12:24,110 --> 00:12:29,690
say x equal to 1 and then maybe you assign this to some new data frame or overwrite an existing data

159
00:12:29,690 --> 00:12:30,530
frame.

160
00:12:30,770 --> 00:12:40,470
Finally to create dummy variables if we take a look at D F 1 we have these categories of a B's and C's

161
00:12:40,530 --> 00:12:48,540
in C 1 so I can see see one here have those categories often in machine learning you need to do what's

162
00:12:48,540 --> 00:12:57,270
known as one hot encoding and the way we can do that is called PD dot get dummies and then call D of

163
00:12:57,270 --> 00:13:05,600
1 C 1 and essentially what this does is it returns back as many columns as there are categories in that

164
00:13:05,600 --> 00:13:12,400
particular column and then it provides a 1 if the category matches up and a 0.

165
00:13:12,410 --> 00:13:14,680
If it did not so we can see the pattern here.

166
00:13:14,780 --> 00:13:19,310
2 ones on A's then 2 ones on B's and then 2 ones on C's.

167
00:13:19,460 --> 00:13:23,510
We're gonna talk a lot more detail about why this is useful for machine learning but right now I just

168
00:13:23,510 --> 00:13:28,300
want to get you introduced to the actual function call which is PD dot get dummies.

169
00:13:28,520 --> 00:13:30,980
All right so we talked about a lot here.

170
00:13:30,980 --> 00:13:37,010
The most important thing I would say for this lecture is that you get a lot of practice using this apply

171
00:13:37,010 --> 00:13:37,990
functionality.

172
00:13:38,000 --> 00:13:43,520
It's a super powerful tool of pandas and essentially lets you create any columns and your only limitation

173
00:13:43,550 --> 00:13:44,570
is what you can think of.

174
00:13:44,600 --> 00:13:47,780
For a python function which is quite flexible.

175
00:13:47,950 --> 00:13:48,580
All right.

176
00:13:48,740 --> 00:13:50,300
Thanks and I'll see you at the next lecture.
