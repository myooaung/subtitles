WEBVTT
1
00:00:05.230 --> 00:00:06.450
Welcome back everyone.

2
00:00:06.700 --> 00:00:11.050
In this series of lectures we're going to now learn how to deal with color data and we'll do this with

3
00:00:11.050 --> 00:00:17.440
the Safa 10 data set some part 1 to focus on the actual data itself as well as creating our model and

4
00:00:17.440 --> 00:00:21.100
the sofar 10 dataset are slightly larger images and what we just dealt with.

5
00:00:21.100 --> 00:00:27.490
They're 32 by 32 images of 10 different objects so the different types of objects available are airplanes

6
00:00:27.490 --> 00:00:30.840
cards birds cats deers dogs etc..

7
00:00:30.970 --> 00:00:33.170
And the main thing to note is these are color images.

8
00:00:33.190 --> 00:00:33.690
Keep in mind.

9
00:00:33.690 --> 00:00:39.850
Thirty two by thirty two is still quite small but you'll be able to see some level detail that a human

10
00:00:39.850 --> 00:00:42.670
can discern what's actually in the image.

11
00:00:42.700 --> 00:00:46.570
So in this series of lectures we're actually going to be re reusing a lot of the previous compositional

12
00:00:46.570 --> 00:00:47.690
neural network code.

13
00:00:47.740 --> 00:00:52.900
So really we're going to focus on is the additions necessary due to the introduction of the three color

14
00:00:52.900 --> 00:00:53.330
channels.

15
00:00:53.350 --> 00:00:55.630
That is the red green and blue color channels.

16
00:00:55.630 --> 00:01:00.430
So let's head to a notebook and get started and we'll be copy and pasting quite a bit of the code because

17
00:01:00.760 --> 00:01:04.220
about 90 percent of the code is the exact same as the previous series.

18
00:01:04.270 --> 00:01:07.390
It's just a couple of additions to deal with the three color channels.

19
00:01:07.660 --> 00:01:09.300
Let's add to a notebook to get started.

20
00:01:09.460 --> 00:01:09.720
Okay.

21
00:01:09.730 --> 00:01:12.230
Here I am at a notebook I've already imported the basics.

22
00:01:12.250 --> 00:01:13.900
Let's load up our data set.

23
00:01:13.900 --> 00:01:17.950
This one is also built into cares for learning purposes.

24
00:01:17.950 --> 00:01:21.780
We will say from tensor flow that carris thought data sets.

25
00:01:21.830 --> 00:01:27.460
Import sofar 10 and then we'll load it really similar to the way we did last time.

26
00:01:27.460 --> 00:01:30.400
It's actually already split for us when we run low data.

27
00:01:30.520 --> 00:01:44.240
We load up the training pairs and the test pairs and then we set that equal to so far 10 low data.

28
00:01:44.410 --> 00:01:48.760
Go ahead and run that and we'll load up the data for you and let's take a look now at the shape of our

29
00:01:48.760 --> 00:01:49.050
data.

30
00:01:52.030 --> 00:01:56.920
So notice now the shape has an extra dimension to it because there's three color channels so there's

31
00:01:56.920 --> 00:02:03.160
fifty thousand images there are 32 by 32 and there's three color channels a red green and blue color

32
00:02:03.160 --> 00:02:03.930
channel.

33
00:02:03.970 --> 00:02:10.570
So let's take a look at just the single image X train 0 and it's this array right here.

34
00:02:10.610 --> 00:02:12.680
Let's go ahead and check out the shape of it.

35
00:02:12.900 --> 00:02:24.080
It's 32 by 32 by three three let's say peel t that M show and show you with the sexual image looks like

36
00:02:24.170 --> 00:02:28.940
and hopefully you can kind of blow your vision a little bit and see that this is an image of a frog

37
00:02:29.330 --> 00:02:35.480
and you can pass and ran the numbers here within the fifty thousand points to see different images.

38
00:02:35.480 --> 00:02:37.870
So here we can see this is an image of a horse.

39
00:02:37.880 --> 00:02:43.700
These are very small images are only 32 by 32 but there is enough information here for a human to detect

40
00:02:44.000 --> 00:02:44.930
what it's looking at.

41
00:02:44.990 --> 00:02:48.110
Some of these keep in mind are a little less clear.

42
00:02:48.200 --> 00:02:52.750
So I'm just kind of randomly choosing here this one maybe a little less clear to me it looks like it

43
00:02:52.750 --> 00:02:54.590
there and we can check that against the labels.

44
00:02:54.590 --> 00:02:55.610
I believe this is it there.

45
00:02:55.670 --> 00:02:58.750
But you can see that because the images are so small.

46
00:02:58.790 --> 00:03:01.340
Some of these are kind of bound to be misclassified.

47
00:03:01.340 --> 00:03:04.850
So it won't get as good performance as we did on the end this dataset.

48
00:03:05.570 --> 00:03:06.130
OK.

49
00:03:06.200 --> 00:03:11.990
So just before we need to perform pre processing right now if we take a look at one of these images

50
00:03:12.530 --> 00:03:19.430
and ask for the max value they go from 0 to 255 for each of the color channels.

51
00:03:19.480 --> 00:03:28.280
So we'll do the same thing as before we'll simply say X train is equal to x train divided by 255 and

52
00:03:28.290 --> 00:03:32.850
keep in mind you should only be running these commands one time otherwise you'll be dividing by two

53
00:03:32.850 --> 00:03:33.750
fifty five twice.

54
00:03:33.750 --> 00:03:39.620
So keep that in mind then we'll say excess divided by two fifty five.

55
00:03:39.690 --> 00:03:40.900
Go ahead and run that.

56
00:03:41.070 --> 00:03:47.620
And if we take a look at the size or shape of X test there's ten thousand images in the test set.

57
00:03:47.750 --> 00:03:48.440
Okay.

58
00:03:48.580 --> 00:03:50.300
Also just like before.

59
00:03:50.300 --> 00:03:56.700
If we take a look at our y training data you'll see that the labels themselves are just as we did last

60
00:03:56.700 --> 00:03:57.380
time.

61
00:03:57.470 --> 00:04:00.110
Are labeled by an integer.

62
00:04:00.150 --> 00:04:06.240
So what we actually need is not have these be read in as continuous values but as categorical values

63
00:04:07.260 --> 00:04:16.890
and just as before we can convert these by saying tensor flow that carries that utilize import to categorical

64
00:04:18.000 --> 00:04:23.610
and then we'll transform these to be categorical so we'll say that my Y categorical for my training

65
00:04:23.610 --> 00:04:32.220
set is equal to two categorical on y train and we can specify that there's 10 classes here and we'll

66
00:04:32.220 --> 00:04:39.940
do the exact same thing for our test set to categorical on y test 10.

67
00:04:39.990 --> 00:04:46.500
So so far as far as reshaping anything nothing has changed from what we did with the black and white

68
00:04:46.500 --> 00:04:51.410
images the scaling still works exactly the same because of num pi luckily this division by two fifty

69
00:04:51.410 --> 00:04:55.860
five happens across all three dimensions on the color channels.

70
00:04:55.860 --> 00:05:01.020
So it scaled across all of those so we don't need to worry about that and the labels themselves same

71
00:05:01.020 --> 00:05:07.330
deal as last time we convert them to categories and as a quick no a common question is well what did

72
00:05:07.330 --> 00:05:09.320
these numbers actually represent.

73
00:05:09.380 --> 00:05:17.120
Because if we take a look at for example why tests of zero recall that number three if we take a look

74
00:05:17.120 --> 00:05:21.240
at actually let's take a look at train so why train of zero.

75
00:05:21.250 --> 00:05:23.220
It says the label is six.

76
00:05:23.230 --> 00:05:29.320
Well let's say PDT M show on X train of zero.

77
00:05:29.390 --> 00:05:30.190
And we see the result.

78
00:05:30.190 --> 00:05:31.420
That was a frog.

79
00:05:31.450 --> 00:05:35.380
So how do we know that six actually connects to frog if you just google search.

80
00:05:35.410 --> 00:05:40.420
So far ten label names it will show you the list that airplane 0 automobiles 1.

81
00:05:40.450 --> 00:05:43.850
So I can see here frog is six or you can go to the official website.

82
00:05:43.870 --> 00:05:46.690
So far 10 dataset and it hasn't organized in that order.

83
00:05:46.690 --> 00:05:49.570
So airplane zero automobiles 1 et cetera.

84
00:05:49.600 --> 00:05:50.670
So this is the official Web site.

85
00:05:50.680 --> 00:05:55.450
If you just go to so far ten data set and then just look up the official Web site on Google you'll find

86
00:05:55.450 --> 00:06:02.400
that there's also a larger labels so there's this a far one hundred but that is much too big of a dataset

87
00:06:02.410 --> 00:06:03.120
for us to run.

88
00:06:03.160 --> 00:06:04.050
And it's the same ideas.

89
00:06:04.060 --> 00:06:04.710
So far 10.

90
00:06:05.160 --> 00:06:05.710
OK.

91
00:06:05.890 --> 00:06:07.160
So we'll come back to our notebook.

92
00:06:07.210 --> 00:06:08.460
We understand how to work off the data.

93
00:06:08.470 --> 00:06:09.700
We understand the labels.

94
00:06:09.700 --> 00:06:15.730
Let's go ahead and build out our model and what I'm going to do is I'll be copying and pasting some

95
00:06:15.730 --> 00:06:20.930
of this code from our notebook because it's pretty much the exact same as we did last time.

96
00:06:20.950 --> 00:06:24.310
The only thing we need to edit is our input shapes.

97
00:06:24.310 --> 00:06:30.100
So let's go ahead and build out our sequential model just as we did before.

98
00:06:30.560 --> 00:06:33.920
And let's add in a conversational layer as well as a pulling layer.

99
00:06:33.920 --> 00:06:39.310
I will copy and paste this code from our notebook and then just note the changes.

100
00:06:39.310 --> 00:06:43.010
So the main change years will sleep the same number of filters the same kernel size.

101
00:06:43.120 --> 00:06:46.780
However recall that the input shape is defined by our data.

102
00:06:46.780 --> 00:06:51.600
So this should be 32 by 32 by three which is defined up.

103
00:06:51.640 --> 00:06:54.150
When we checked out the actual shape of a single image.

104
00:06:54.160 --> 00:06:58.000
Next test which is 32 by 32 by three.

105
00:06:58.040 --> 00:06:58.790
OK.

106
00:06:58.990 --> 00:07:07.540
Now when you're dealing with more complex images recall now that a single image if we just take a look

107
00:07:07.540 --> 00:07:15.160
or we if we think about the number of pixels or data points really inside of a black and white m this

108
00:07:15.220 --> 00:07:19.960
image the total number of values was twenty eight times twenty eight which is seven hundred eighty four

109
00:07:20.470 --> 00:07:28.480
the total number of values within a color image here is going to be 32 times 32 times three as you can

110
00:07:28.480 --> 00:07:34.570
see there is a lot more information within this color image than there was in the previous m this dataset

111
00:07:34.990 --> 00:07:40.540
because of that it's probably a good idea that as our images get more complex and larger and also more

112
00:07:40.540 --> 00:07:45.190
complexity to the color that we add in more compositional and pulling layers.

113
00:07:45.190 --> 00:07:50.590
So we'll go ahead and copy and paste this and add in another compositional layer as well as another

114
00:07:50.590 --> 00:07:51.390
pulling layer.

115
00:07:51.550 --> 00:07:57.250
And often researchers also like to have different amounts of filters in the different number of layers

116
00:07:57.430 --> 00:08:02.710
so you can have an expanding number of filters as the congressional leaders go deeper for our use case.

117
00:08:02.710 --> 00:08:06.390
These images are pretty simple so we'll keep everything the same.

118
00:08:06.400 --> 00:08:12.640
OK then we'll go ahead and keep it to just two compositional layers followed by two pulling layers and

119
00:08:12.640 --> 00:08:15.690
we'll flatten out the images just as we did before.

120
00:08:15.910 --> 00:08:18.280
So we flatten out the images.

121
00:08:18.280 --> 00:08:23.260
And because of the added complexity of the number of points here when we're adding in our dense layer

122
00:08:24.720 --> 00:08:26.250
we'll go ahead and add more neurons to it.

123
00:08:26.250 --> 00:08:32.970
We'll say 256 neurons with the activation function equal to Iraq to fight linear unit.

124
00:08:32.970 --> 00:08:38.010
And then finally everything else going to be pretty much the same we'll say model.

125
00:08:38.010 --> 00:08:45.370
Go ahead and add dense the activation function should be equal to soft Max because it's a multi class

126
00:08:45.370 --> 00:08:47.320
function.

127
00:08:47.320 --> 00:08:58.530
And then we compile the models say it model compile the loss should be categorical cross entropy you

128
00:08:58.530 --> 00:09:00.950
can choose whatever optimizer you want we'll go.

129
00:09:00.970 --> 00:09:03.660
Just choose the atom optimizer that's should be fine.

130
00:09:03.660 --> 00:09:08.070
And if you want to keep track of different metrics speak beyond just loss you could say metrics is equal

131
00:09:08.070 --> 00:09:12.440
to and I can pass in that accuracy call.

132
00:09:12.680 --> 00:09:14.770
Okay run that make sure you have no typos.

133
00:09:14.850 --> 00:09:16.610
Looks like that went well.

134
00:09:16.740 --> 00:09:19.890
You can order a summary of your model by saying model that summary.

135
00:09:19.890 --> 00:09:25.470
Here we can see the different layers and let's go ahead and add in early stopping so we'll say from

136
00:09:25.470 --> 00:09:36.260
tensor flow that carries that callbacks import early stopping just as we did before we'll create an

137
00:09:36.290 --> 00:09:43.330
early stop call we'll say early stopping we'll monitor the loss.

138
00:09:43.350 --> 00:09:47.790
You could also technically monitor the accuracy if that was your most important metric.

139
00:09:48.300 --> 00:09:55.120
And then let's give it a patients of 2 and let's fit this will say a model that fit fit to the training

140
00:09:55.120 --> 00:09:55.790
data.

141
00:09:55.900 --> 00:10:02.320
Make sure you correctly fit to the categorical versions of the labels say epochs.

142
00:10:02.440 --> 00:10:03.650
Just choose a larger number.

143
00:10:03.670 --> 00:10:08.590
Probably won't change or train for 15 total but we have the early stopping to make sure make sure you

144
00:10:08.590 --> 00:10:10.780
specify your validation data.

145
00:10:11.050 --> 00:10:16.600
That's equal to x test and Y categorical test.

146
00:10:16.840 --> 00:10:24.320
And then finally add in the callbacks for the early stopping fit that makes you you see that first output

147
00:10:24.320 --> 00:10:27.250
to make sure you're doing this correctly and that's pretty much it.

148
00:10:27.290 --> 00:10:33.350
So you notice on this very first epoch the accuracy isn't so good but as we continue training we should

149
00:10:33.350 --> 00:10:39.050
see that accuracy goes go up and that's what's kind of nice about adding an accuracy as a metrics call

150
00:10:39.050 --> 00:10:44.290
here because it's pretty hard to interpret the loss beyond just that it should be going down.

151
00:10:44.300 --> 00:10:50.540
What's nice is I can really interpret the accuracy very intuitively and can see it go up as the epochs

152
00:10:50.570 --> 00:10:52.880
get trained further and further okay.

153
00:10:53.000 --> 00:10:57.890
The other thing keep in mind is that default accuracy by random guessing should actually be 10 percent.

154
00:10:58.040 --> 00:11:01.910
So the fact that we're going above 10 percent is really good and we're going way beyond that because

155
00:11:01.910 --> 00:11:06.920
if you were to randomly guess what class an image belonged to you'd have a 10 percent chance of getting

156
00:11:06.920 --> 00:11:12.080
it right here based on epoch 7 we're already performing that zero point seventy five percent accuracy

157
00:11:12.410 --> 00:11:14.500
so we're doing pretty well on this dataset.

158
00:11:14.510 --> 00:11:19.220
All right I'll end this lecture here and coming up next we'll talk about evaluating the model and we'll

159
00:11:19.220 --> 00:11:22.470
also talk about performing predictions on new data.

160
00:11:22.490 --> 00:11:23.360
I'll see you there.
