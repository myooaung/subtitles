1
00:00:05,340 --> 00:00:06,550
Welcome back everyone.

2
00:00:06,630 --> 00:00:11,820
In this lecture we're going to focus on creating the actual model for the congressional neural network

3
00:00:12,060 --> 00:00:13,650
on these custom images.

4
00:00:13,650 --> 00:00:17,060
And the model is going to be fitting to a generator.

5
00:00:17,070 --> 00:00:17,700
Let's get started.

6
00:00:18,530 --> 00:00:18,790
OK.

7
00:00:18,800 --> 00:00:21,110
Here we are in the notebook where we left off last time.

8
00:00:21,180 --> 00:00:22,830
Let's get to creating our model.

9
00:00:23,010 --> 00:00:26,280
We'll say from tensor flow thought carris stop models.

10
00:00:26,280 --> 00:00:33,190
And just as we did before we're going to import sequential and then we'll say from tensor flow that

11
00:00:33,210 --> 00:00:36,310
carries that layers import.

12
00:00:36,310 --> 00:00:39,820
And we're going to do is we're going to import a dense layer.

13
00:00:39,960 --> 00:00:45,310
This is for the very end plus we can add some dense layers after a conversational layers go ahead and

14
00:00:45,430 --> 00:00:47,800
import compositional layers that's come to D.

15
00:00:48,280 --> 00:00:50,690
And then we'll also import our pulling layers.

16
00:00:50,800 --> 00:00:56,170
So there's Max Poole a common point of confusion for students is what's different scene Max Poole versus

17
00:00:56,170 --> 00:00:57,430
Max pooling.

18
00:00:57,430 --> 00:00:58,380
They're actually the same thing.

19
00:00:58,420 --> 00:01:03,400
And you can check this out if you go to the 10th floor documentation you'll notice a lot of these classes

20
00:01:03,400 --> 00:01:08,380
have subsections called aliases which basically means there's multiple names for the same function call.

21
00:01:08,380 --> 00:01:10,130
So just keep that in mind.

22
00:01:10,330 --> 00:01:17,140
It's really common almost like an issue with tensor flow that is the fact that it has so many versions

23
00:01:17,260 --> 00:01:21,670
that there's a lot of aliases for the same thing even within something like Charisse.

24
00:01:21,700 --> 00:01:23,910
So we have both Max Poole and Max pulling too.

25
00:01:23,950 --> 00:01:29,460
They're actually the exact same thing so we're going to say dense compositional to the max pulling to

26
00:01:29,460 --> 00:01:33,200
the end because it's going to be a bit of a larger network.

27
00:01:33,210 --> 00:01:41,290
Let's also add in the drop out so it can prevent over fitting hopefully we'll say model sequential and

28
00:01:41,290 --> 00:01:44,480
now it's going to be time to add in compositional layers.

29
00:01:44,500 --> 00:01:51,460
So what I'm going to do is set up a base compositional layer so we first say conditional to the.

30
00:01:52,720 --> 00:01:59,880
And then we're going to decide to have a 32 filters here and I'll choose a smaller kernel size something

31
00:01:59,880 --> 00:02:01,400
like three by three.

32
00:02:01,830 --> 00:02:07,710
And then the input shape and this becomes very important the input shapes should be equal to the input

33
00:02:07,710 --> 00:02:09,480
shape we defined earlier.

34
00:02:09,480 --> 00:02:14,910
So input shape is going to be equal to the image shape that we defined.

35
00:02:14,910 --> 00:02:20,100
So recall earlier we define the image shape based off the average size of these images.

36
00:02:20,100 --> 00:02:22,870
And that's what was up here is 130 by 130 by three.

37
00:02:23,070 --> 00:02:24,950
And this is something you can play around with.

38
00:02:24,960 --> 00:02:28,920
Keep in mind if you choose an image shape that's too large especially if you're dealing with extremely

39
00:02:28,920 --> 00:02:29,770
large files.

40
00:02:29,880 --> 00:02:31,980
You may run out of memory on your computer.

41
00:02:32,070 --> 00:02:34,820
Again that's too dependent on your hardware.

42
00:02:34,940 --> 00:02:37,520
OK so one third about 130 those aren't too bad.

43
00:02:37,550 --> 00:02:43,940
So we'll going to keep image shape there their analysts choose activation function we'll say activation

44
00:02:43,940 --> 00:02:50,770
is equal to rectified linear unit and then after that we will add in our pooling layer.

45
00:02:50,770 --> 00:02:53,130
So Max pull to the.

46
00:02:53,200 --> 00:02:58,230
And we'll just go ahead and keep the default pool size just so we can see it so we can keep it in mind.

47
00:02:58,300 --> 00:02:59,920
It's two by two.

48
00:03:00,010 --> 00:03:03,650
So let's go ahead and add in a couple more compositional errors.

49
00:03:04,000 --> 00:03:09,250
The larger the image sizes and the more complex of a task you're dealing with the more competition layers

50
00:03:09,280 --> 00:03:10,670
that you should probably have.

51
00:03:10,780 --> 00:03:13,420
And there's a link for you in the notebook.

52
00:03:13,420 --> 00:03:18,130
So if you check out our deep learning notebook and scroll down there's a link here to a really nice

53
00:03:18,130 --> 00:03:23,650
explanatory post on different rules for selecting the number of neurons and number of filters and conversational

54
00:03:23,650 --> 00:03:24,040
layers.

55
00:03:24,040 --> 00:03:27,880
So definitely check out that explanatory post.

56
00:03:28,160 --> 00:03:32,750
OK so the one thing going to edit here is as we get deeper in this network I'm going to create more

57
00:03:32,750 --> 00:03:41,290
filters so have these two kind of inside hidden compositional layers up 64 filters each.

58
00:03:41,400 --> 00:03:46,610
Then after this we will flatten out our models so we'll say go ahead and flatten this out.

59
00:03:46,810 --> 00:03:49,350
Add in our flatten layer and it looks like I forgot to import it.

60
00:03:49,350 --> 00:03:51,120
So let me do that as well.

61
00:03:51,270 --> 00:03:56,840
So we'll say flatten import that and then I can call flat in here.

62
00:03:56,940 --> 00:03:59,610
So that flattens it out for our dense layer.

63
00:03:59,870 --> 00:04:09,270
So we'll say model add thence go four hundred twenty eight neurons and we'll say our activation is equal

64
00:04:09,270 --> 00:04:15,660
to rectified linear unit something I want to point out and you may see this as you explore more complex

65
00:04:15,780 --> 00:04:17,640
compositional models.

66
00:04:17,640 --> 00:04:22,440
You can do a lot of exploring online to see how other people kind of attack different datasets with

67
00:04:22,440 --> 00:04:28,470
different images at different sizes you may see some people add in the activation after dance.

68
00:04:28,590 --> 00:04:35,430
So in other kind of Alias you can do and I'll come back here to show you is in our notebook.

69
00:04:35,430 --> 00:04:40,530
There's essentially an example of doing this in two steps where it's you add the dance and then add

70
00:04:40,530 --> 00:04:42,990
the activation function after the dance layer.

71
00:04:42,990 --> 00:04:48,270
That's the exact same thing as what we did here which is just calling it inside of the dance.

72
00:04:48,270 --> 00:04:53,540
So it's up to you one you want to use and then we're going to do here as well is will add in our drop

73
00:04:53,540 --> 00:04:55,070
out.

74
00:04:55,120 --> 00:05:00,190
We're gonna turn off half the neurons randomly to prevent overfishing.

75
00:05:00,190 --> 00:05:04,280
After that we have our final dense layer.

76
00:05:04,360 --> 00:05:09,730
So say that's one and then say model and lips.

77
00:05:09,760 --> 00:05:16,530
You can add in the sigmoid function or just say here activation is equal to sigmoid.

78
00:05:16,540 --> 00:05:20,410
We also show the alternative method here which is adding it after the fact.

79
00:05:20,410 --> 00:05:21,070
Either one.

80
00:05:21,070 --> 00:05:24,790
Totally OK so we have dense activation sigmoid.

81
00:05:24,790 --> 00:05:30,940
Last thing I want to show you is the compiling of the model we'll say compile the model loss see binary

82
00:05:30,940 --> 00:05:31,990
classification problem.

83
00:05:31,990 --> 00:05:42,030
So it should be binary cross entropy and then our optimizer will be atom and optionally if we want to

84
00:05:42,030 --> 00:05:50,110
check out the metrics we can say metrics is equal to accuracy run that makes sure we have no errors.

85
00:05:50,130 --> 00:05:50,390
OK.

86
00:05:50,410 --> 00:05:52,020
Looks like our model is working.

87
00:05:52,050 --> 00:05:57,350
Go ahead and check out a model summary so call summary on your model and you can see the different layers

88
00:05:57,380 --> 00:06:02,800
and you can see the different parameters per layer notice that we have a ton of parameters by the time

89
00:06:02,800 --> 00:06:03,750
we get to the dense layer.

90
00:06:03,760 --> 00:06:08,170
So this model will take a long time to train to make sure we can pick the right amount of epochs to

91
00:06:08,170 --> 00:06:17,980
train for we can say from tensor flow dark stock callbacks import early stopping and then create just

92
00:06:17,980 --> 00:06:21,800
as we did before and early stopping callback.

93
00:06:22,090 --> 00:06:29,510
We'll do this based off monitoring validation loss and we can have a patients of one or two epochs.

94
00:06:29,510 --> 00:06:31,690
That's something you can play around as well.

95
00:06:31,730 --> 00:06:38,550
Okay so that's creating the model for training the model we have to select a batch size so we'll go

96
00:06:38,550 --> 00:06:43,350
ahead and train on that size of 16 images at a time.

97
00:06:43,620 --> 00:06:49,580
So it's pretty typical again to choose something in the power of two so two to the power of two is four

98
00:06:49,590 --> 00:06:55,890
four to the power of two is then 16 and the larger your hardware the larger the batch size you can probably

99
00:06:55,890 --> 00:07:00,420
reasonably choose the smaller the batch size the longer the train time takes because you're fitting

100
00:07:00,420 --> 00:07:03,560
in less images at a time.

101
00:07:03,630 --> 00:07:11,280
So what we're going to do is we're going to create two generators just as we did before and the generators

102
00:07:11,280 --> 00:07:18,140
will say train image generator is going to be one of them and then the other one we're going to do is

103
00:07:18,140 --> 00:07:20,410
a test image generator.

104
00:07:20,440 --> 00:07:21,990
This is gonna be very similar.

105
00:07:22,040 --> 00:07:26,750
The only difference going to be the source of their data and we already went through this on the flow

106
00:07:26,750 --> 00:07:28,940
from directory.

107
00:07:28,940 --> 00:07:34,660
Now we need to put in the training path and there's a couple other parameters we're going to state here.

108
00:07:34,730 --> 00:07:40,790
So we have to also state is beyond the directory which we already have a training path is the target

109
00:07:40,790 --> 00:07:41,230
size.

110
00:07:41,240 --> 00:07:42,830
So what is our target size.

111
00:07:42,860 --> 00:07:45,860
Notice the target size just cares about width and height.

112
00:07:45,860 --> 00:07:52,850
So what we do is we say that our target size is equal to the image shape that we defined earlier.

113
00:07:52,850 --> 00:07:58,790
So just to remind you the image shape from earlier is 130 by one three by three.

114
00:07:58,820 --> 00:08:04,820
I really only care about those first two dimensions so let's call in two to get one 30 by one 30.

115
00:08:04,940 --> 00:08:06,970
So that's why I'm gonna pass in here.

116
00:08:07,010 --> 00:08:13,080
I could do this manually or I can kind of set it off that variable Next I need to make sure my color

117
00:08:13,080 --> 00:08:19,770
mode is correct so since I'm dealing of color images my color mode is red green blue.

118
00:08:19,840 --> 00:08:21,930
If we come down here we can see the different parameters.

119
00:08:21,940 --> 00:08:27,550
So it's either gonna be grayscale or red green blue or four for some reason dealing with an alpha channel

120
00:08:27,550 --> 00:08:28,240
as well.

121
00:08:28,360 --> 00:08:29,980
Alpha is transparency.

122
00:08:29,980 --> 00:08:32,170
You can pass an R GPA.

123
00:08:32,250 --> 00:08:36,100
OK so there is our color mode last couple of things we want to set.

124
00:08:36,100 --> 00:08:44,140
Here are the batch size so the batch size equal the batch size and then the class mode is going to be

125
00:08:44,140 --> 00:08:47,200
binary because it's binary classification.

126
00:08:47,320 --> 00:08:56,140
I'm essentially going to copy this and then paste it for my test image generator.

127
00:08:56,140 --> 00:08:59,110
Go ahead and run the first generator.

128
00:08:59,170 --> 00:09:00,450
That one's ready to go.

129
00:09:00,580 --> 00:09:05,950
The things I need to change here is the test path should be for the test images.

130
00:09:06,040 --> 00:09:12,380
And you'll notice that one of the parameters here is this shuffle call.

131
00:09:12,390 --> 00:09:18,810
So shuffling essentially shuffles your data before it kind of makes this random batch of data points

132
00:09:18,810 --> 00:09:20,980
for you during training.

133
00:09:21,060 --> 00:09:22,800
You should be shuffling your data.

134
00:09:22,800 --> 00:09:26,670
However when you're generating for the test set you don't actually need to shuffle.

135
00:09:26,670 --> 00:09:33,960
In fact you shouldn't be shuffling otherwise your labels will get shuffled around from your actual feature

136
00:09:33,960 --> 00:09:34,570
points.

137
00:09:34,590 --> 00:09:39,300
So we want to say shuffle is equal to False when running and test data.

138
00:09:39,340 --> 00:09:45,570
OK so that's our training image generator and our test image generator and what we can do is now take

139
00:09:45,570 --> 00:09:46,560
a look at these objects.

140
00:09:46,590 --> 00:09:53,460
So for example our training image generator and we can say class indices and it reports back that 0

141
00:09:53,460 --> 00:10:01,850
belongs to the parasite one belongs to uninfected and then we're going to do here is we can say my resulting

142
00:10:01,850 --> 00:10:13,930
model or results is equal to the model that fit generator we pass in our training image generator pass

143
00:10:13,950 --> 00:10:19,260
and some number of epochs can choose a larger one here because we're going to do is pass in our validation

144
00:10:19,260 --> 00:10:27,530
set that's the test image generator and then the callbacks will be equal to early stop.

145
00:10:27,530 --> 00:10:32,070
So we can go ahead and run that and then that should be in training.

146
00:10:32,070 --> 00:10:34,710
Keep in mind this is going to take a long time to train.

147
00:10:34,710 --> 00:10:40,380
So what I'm going to do is I'm actually going to interrupt my colonel and we actually already have a

148
00:10:40,380 --> 00:10:43,330
file for you underneath compositional neural networks.

149
00:10:43,380 --> 00:10:47,190
We have a malaria the texture the H5 file.

150
00:10:47,310 --> 00:10:53,430
Let's go ahead and load data to save some time so you can if you want to bring your own model especially

151
00:10:53,430 --> 00:10:58,770
if it's different than the one that we find that our notebook or what you can do is say from tensor

152
00:10:58,770 --> 00:11:01,790
flow that Harris not models.

153
00:11:02,120 --> 00:11:12,990
Import load model and what we can go ahead and do is say model is equal to load model and then pass

154
00:11:12,990 --> 00:11:14,880
in malaria detector.

155
00:11:14,900 --> 00:11:20,500
I would highly encourage this especially if you're running this on a kind of simpler hardware computer.

156
00:11:20,540 --> 00:11:24,950
Go ahead and load in that model and to confirm that the model worked.

157
00:11:24,950 --> 00:11:29,510
Same model summary you should see something that essentially looks like that's the model we just created.

158
00:11:29,510 --> 00:11:32,110
Except what's nice is this model has been fully trained.

159
00:11:32,120 --> 00:11:37,490
Something to note here is if you do decide to load our model what is not going to be available to you

160
00:11:37,580 --> 00:11:39,540
is the models training history.

161
00:11:39,710 --> 00:11:46,340
So if we try tried model history the history is going to say it can't find it because it doesn't actually

162
00:11:46,340 --> 00:11:47,170
have it.

163
00:11:47,180 --> 00:11:51,020
That's because you loaded the model and this is just saving the train the model.

164
00:11:51,080 --> 00:11:53,570
It's not saving the history of the training model.

165
00:11:53,570 --> 00:11:57,350
Keep in mind you can optionally save the model history if you really want to.

166
00:11:57,740 --> 00:12:02,370
So if you just google search save model history Charisse basically hit this first link.

167
00:12:02,410 --> 00:12:06,290
There's code here on how to actually essentially save this as a pickle file.

168
00:12:06,340 --> 00:12:11,290
The actual history of the training but the reason we didn't save it is because we actually show you

169
00:12:11,620 --> 00:12:12,610
the history of the model.

170
00:12:12,610 --> 00:12:17,860
If you come to our provide a notebook and scroll down we will actually show you kind of the history

171
00:12:17,890 --> 00:12:22,660
here of loss validation plot so you can essentially just see the history of the training here and this

172
00:12:22,660 --> 00:12:24,830
is the model that we saved for you.

173
00:12:24,940 --> 00:12:29,860
If for some reason you want to evaluate the model on the test data that should still work.

174
00:12:29,860 --> 00:12:38,350
You could say model evaluate generator and then pass the test image generator run that and you should

175
00:12:38,350 --> 00:12:40,840
get similar results as what we're about to get.

176
00:12:40,870 --> 00:12:46,540
Keep in mind depending on the actual shuffling of the training data and the random initialization this

177
00:12:46,540 --> 00:12:49,650
could look slightly differently from what we have here.

178
00:12:49,810 --> 00:12:53,110
But overall you should get something in this range.

179
00:12:53,140 --> 00:13:02,350
If we say model dot metrics names it's loss and accuracy your accuracy should be somewhere between like

180
00:13:02,460 --> 00:13:07,820
eighty five and ninety five percent which is pretty good considering that base accuracy is 50 percent.

181
00:13:08,380 --> 00:13:14,260
Okay so we'll go ahead and load the model since we don't want to kind of spend all this time retraining

182
00:13:14,280 --> 00:13:16,050
the model that we already provided for you.

183
00:13:16,150 --> 00:13:21,070
If you are interested in the actual history of this thought H5 file you can check it out in the actual

184
00:13:21,070 --> 00:13:21,850
provided notebook.

185
00:13:21,850 --> 00:13:25,420
Here we actually show the full history of that training of that model.

186
00:13:25,420 --> 00:13:30,430
OK so there's the model for you coming up next we're going to basically talk more about evolving the

187
00:13:30,430 --> 00:13:35,190
model not just the history but predicting on your images classification reports et cetera.

188
00:13:35,350 --> 00:13:36,310
We'll see you at the next lecture.
