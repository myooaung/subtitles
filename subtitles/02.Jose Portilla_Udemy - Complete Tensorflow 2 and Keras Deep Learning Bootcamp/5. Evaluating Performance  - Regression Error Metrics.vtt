WEBVTT
1
00:00:05.570 --> 00:00:06.700
Welcome back everyone.

2
00:00:06.710 --> 00:00:10.460
We just discussed how to evaluate performance for classification problems.

3
00:00:10.490 --> 00:00:16.810
Now let's understand how to evaluate performance for regression tests so we can take a moment to discuss

4
00:00:16.840 --> 00:00:20.930
how do we evaluate a model which is performing some sort of regression task.

5
00:00:21.010 --> 00:00:25.650
And in general a regression is the task when a model attempts to predict continuous values.

6
00:00:25.840 --> 00:00:31.930
Unlike those classification tasks where we're trying to predict categorical values so you may have heard

7
00:00:31.930 --> 00:00:37.010
of some evaluation metrics such as accuracy or recall or precision like we just discussed.

8
00:00:37.090 --> 00:00:41.290
However these sort of metrics aren't going to be useful for regression problems.

9
00:00:41.300 --> 00:00:47.590
It doesn't really makes sense to calculate the accuracy or recall of a regression task since you are

10
00:00:47.680 --> 00:00:49.390
actually classifying things.

11
00:00:49.390 --> 00:00:51.870
Instead you're predicting a continuous value.

12
00:00:52.300 --> 00:00:56.130
So we need new metrics designed for those continuous values.

13
00:00:56.140 --> 00:01:00.730
For example imagine we're attempting to predict the price of a house given its features.

14
00:01:00.730 --> 00:01:04.550
That would be a regression task or attempting to predict the country.

15
00:01:04.660 --> 00:01:05.560
A house is in.

16
00:01:05.560 --> 00:01:08.340
Given its features that would be a classification task.

17
00:01:08.410 --> 00:01:13.180
And again we're focused right now on how to evaluate that regression task where a label is continuous

18
00:01:13.240 --> 00:01:16.180
and it's not separate categories.

19
00:01:16.310 --> 00:01:20.650
So again to discuss the most common evaluation metrics for regression which are mean absolute error

20
00:01:20.940 --> 00:01:25.000
means squared error and then root mean square error.

21
00:01:25.130 --> 00:01:27.790
So let's begin with the simplest which is mean absolute error.

22
00:01:28.220 --> 00:01:33.560
And this one is the easiest to understand essentially all you're gonna do is you're going to compare

23
00:01:33.590 --> 00:01:38.960
your predictions and remember we're comparing a continuous value here since this is a regression task

24
00:01:39.320 --> 00:01:44.840
we're going to compare our predictions to the true y label for example compare the actual prediction

25
00:01:44.840 --> 00:01:51.260
of the house price with the true house price and what we do is we just take difference between the true

26
00:01:51.650 --> 00:01:57.410
price minus our predicted price that's why we take the absolute value of that and the reason we take

27
00:01:57.410 --> 00:02:02.570
the absolute value is because technically our predictions could be over or under the true value and

28
00:02:02.570 --> 00:02:07.720
since we want to averages out across all our predictions we take the absolute value.

29
00:02:07.800 --> 00:02:13.520
Okay so that's the mean absolute error essentially you're just taking the differences between your prediction

30
00:02:13.550 --> 00:02:18.020
versus the true label you take the absolute value of that and then you average that out for all your

31
00:02:18.020 --> 00:02:20.190
predictions.

32
00:02:20.200 --> 00:02:25.420
Now the issue with mean absolute error is it won't punish large errors.

33
00:02:25.480 --> 00:02:31.810
So here we have what's known as ans comes quartet and we can see here that we have a wide variety of

34
00:02:31.900 --> 00:02:34.610
different scatters of data points here.

35
00:02:34.660 --> 00:02:38.400
However the line of best fit for all of these is actually the same.

36
00:02:38.440 --> 00:02:41.310
So we want to make sure that we're aware of situations like this.

37
00:02:41.410 --> 00:02:44.950
For example let's take a look at this specific situation.

38
00:02:44.960 --> 00:02:52.900
We have one point that's a huge outlier so we want our air metrics to actually account for these.

39
00:02:53.050 --> 00:02:56.450
So what we can do is actually use mean square error.

40
00:02:56.500 --> 00:02:58.770
And this is the mean of the squared errors.

41
00:02:58.810 --> 00:03:04.630
So we're doing here is we're gonna take the difference between the true value minus our predicted value

42
00:03:05.020 --> 00:03:05.950
and we're going to square it.

43
00:03:06.310 --> 00:03:12.550
And as you can imagine when we actually take that square the larger errors are noted more than with

44
00:03:12.610 --> 00:03:17.320
mean absolute error which makes means squared error more popular because you're really going to punish

45
00:03:17.320 --> 00:03:21.470
your model for those outlier situations that it's not fitting to.

46
00:03:21.500 --> 00:03:26.320
And we no longer need to take the absolute value because anything squared ends up being positive.

47
00:03:26.350 --> 00:03:33.040
However there's another issue that we run to with means squared error that's squaring of the actual

48
00:03:33.100 --> 00:03:34.840
label minus her prediction.

49
00:03:34.840 --> 00:03:37.910
Actually also squares the units themselves.

50
00:03:37.930 --> 00:03:43.480
So for example if you're predicting the price of a house then our error metric with mean absolute error

51
00:03:43.900 --> 00:03:47.170
would be in dollars but with means squared error.

52
00:03:47.320 --> 00:03:54.350
We end up getting an error metric in units of dollars squared which is difficult to interpret so the

53
00:03:54.350 --> 00:03:59.780
way we fix this is with the root means squared error essentially at the end you just take the square

54
00:03:59.780 --> 00:04:02.440
root of your means squared error.

55
00:04:02.690 --> 00:04:09.650
So this is the most popular because it does both punish those larger error values and at the end of

56
00:04:09.650 --> 00:04:16.480
the day it has the same metrics or same units as y now.

57
00:04:16.500 --> 00:04:21.110
The most common question again I get from students is hey is this value of root means squared error

58
00:04:21.120 --> 00:04:22.500
I got good.

59
00:04:22.500 --> 00:04:25.050
And as always context is everything.

60
00:04:25.050 --> 00:04:29.850
Let's imagine you were performing some sort of machinery model and you got a root mean square error

61
00:04:29.910 --> 00:04:34.620
of ten dollars and you're asking me Is this good enough routine squared error.

62
00:04:34.710 --> 00:04:37.830
Well it really depends on the context of the situation.

63
00:04:37.960 --> 00:04:42.510
Means quarter of ten dollars would be fantastic if you're predicting the price of a house since ten

64
00:04:42.510 --> 00:04:46.040
dollars is tiny compared to the average price of a house.

65
00:04:46.140 --> 00:04:50.460
But if you're machine learning model was supposed to predict the price of a candy bar based on its features

66
00:04:50.730 --> 00:04:52.860
and your route means quarter was ten dollars.

67
00:04:52.860 --> 00:04:59.110
That's actually really bad so we should do is you should compare your error metric for the regression

68
00:04:59.110 --> 00:05:01.680
task to the average value of the label.

69
00:05:01.680 --> 00:05:07.190
That is the mean value in your dataset to try to get an intuition of its overall performance.

70
00:05:07.240 --> 00:05:11.620
And as always domain knowledge also plays a really important role here.

71
00:05:11.650 --> 00:05:17.240
So machine learning again it's not done in a vacuum it's usually done with a collaborative process.

72
00:05:17.260 --> 00:05:21.490
So if you're predicting the prices of a house and you wanted to get an idea if your routine scored error

73
00:05:21.490 --> 00:05:25.660
was good or not it's probably a good idea to start talking to someone with experience like a real estate

74
00:05:25.660 --> 00:05:26.770
agent.

75
00:05:26.770 --> 00:05:33.340
OK so now we understand the different metrics you can use for evaluating the performance of a regression

76
00:05:33.370 --> 00:05:34.240
task.

77
00:05:34.340 --> 00:05:36.010
Thanks and I'll see you at the next lecture.
