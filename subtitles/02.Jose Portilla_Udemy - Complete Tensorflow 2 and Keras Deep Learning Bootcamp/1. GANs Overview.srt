1
00:00:05,840 --> 00:00:12,600
Welcome everyone to this section on generative adversarial networks generative adversarial networks

2
00:00:12,660 --> 00:00:19,290
or Ganz for short were invented in 2014 by Ian Goodfellow and his fellow researchers and the main idea

3
00:00:19,320 --> 00:00:25,280
behind them is to use two networks competing against each other to generate new unseen data.

4
00:00:25,440 --> 00:00:29,610
Gangs are often described as a counterfeiter versus a detective.

5
00:00:29,610 --> 00:00:37,140
Let's get an intuition of how they work so we can think of the counterfeiter as the generator.

6
00:00:37,140 --> 00:00:39,840
The generator is going to receive random noise.

7
00:00:39,840 --> 00:00:45,120
Typically a Gaussian or normal distribution of noise and it's going to attempt to output data.

8
00:00:45,120 --> 00:00:53,870
So generators are often used for image data the discriminator IS THE DETECTIVE It takes a dataset consisting

9
00:00:53,870 --> 00:00:58,500
of real images from a real data set in fake images from the generator.

10
00:00:58,520 --> 00:01:03,710
These counterfeit images and attempts to classify real versus fake images.

11
00:01:03,710 --> 00:01:09,490
So keep in mind regardless of your source of images whether it's something like the MLS dataset the

12
00:01:09,500 --> 00:01:15,800
had 10 separate classes the discriminator itself is always performing a binary classification it's just

13
00:01:15,800 --> 00:01:20,760
trying to tell us things real or fake so let's actually see this process.

14
00:01:20,760 --> 00:01:26,790
We first start off with just some noise some Gaussian distribution of noise data and we feed that directly

15
00:01:26,790 --> 00:01:34,040
to the generator as input the generator goal is to create images that fooled the discriminator.

16
00:01:34,040 --> 00:01:38,960
So keep in mind in the very first stage of training what's going to happen is the generator given noise

17
00:01:39,050 --> 00:01:46,190
is just going to produce noise and then we also grab images from our real data set and then what we

18
00:01:46,190 --> 00:01:53,720
do is in phase one we train the discriminator essentially labelling the fake generated images as zeros

19
00:01:54,200 --> 00:01:57,390
and then the real data generate images as one.

20
00:01:57,410 --> 00:02:04,100
So basically zero if you're fake one if you're true we feed it to discriminator and a discriminator

21
00:02:04,130 --> 00:02:11,750
then gets trained to detect a real image versus a fake image and then as time goes on the generator

22
00:02:12,500 --> 00:02:18,740
during the second phase of training is going to keep improving its images trying to fool discriminator

23
00:02:20,100 --> 00:02:26,580
until it's able to hopefully generate images that appear to mimic the real data set and discriminator

24
00:02:26,610 --> 00:02:34,400
can eventually no longer tell the difference between the false generated image versus a real image so

25
00:02:34,400 --> 00:02:35,990
there's really two training phases.

26
00:02:35,990 --> 00:02:42,850
Phase one is train the discriminator and then phase two is training the generator in phase 1.

27
00:02:42,870 --> 00:02:48,180
What we do is we take real images and we label those as one for being truly real and they're combined

28
00:02:48,180 --> 00:02:54,960
with fake images from a generator labeled zero the discriminator then trains distinguish real images

29
00:02:54,960 --> 00:02:56,570
from fake images.

30
00:02:56,610 --> 00:03:03,290
Keep in mind in phase one of training the back propagation is only occurring on the discriminator.

31
00:03:03,330 --> 00:03:10,230
So we're only optimizing the discriminator weights during phase one of training then in face to what

32
00:03:10,230 --> 00:03:17,250
we do is we have the generator produce more fake images and then in phase two we only feed the fake

33
00:03:17,280 --> 00:03:21,450
images to the generator with all the labels set as real.

34
00:03:21,450 --> 00:03:26,430
And this causes a generator to attempt to produce images that the discriminator believes to be real

35
00:03:27,240 --> 00:03:31,900
and what's important to note here in phase two because we're feeding and just all fake images labeled

36
00:03:31,900 --> 00:03:37,650
the one we only perform back propagation on the generator weights in this step.

37
00:03:37,650 --> 00:03:42,770
So we're not going to be able to do a typical fit call on all the training data as we did before.

38
00:03:42,780 --> 00:03:48,510
Since we're dealing with two different models a discriminator model and a generator model we'll also

39
00:03:48,510 --> 00:03:54,590
have two different phases of training what's really interesting though and something should always keep

40
00:03:54,590 --> 00:04:02,300
in mind is the generator itself never actually gets to see the real images it generates convincing images

41
00:04:02,480 --> 00:04:09,010
only based off gradients flowing back through discriminator during its phase of training.

42
00:04:09,020 --> 00:04:14,810
You should also keep in mind the discriminator is also improving as training phases continue.

43
00:04:14,960 --> 00:04:24,250
So meaning the generated images will also need to hopefully get better and better in order to fold discriminator.

44
00:04:24,300 --> 00:04:30,200
This can lead to really impressive results in video research has published many models such as style

45
00:04:30,200 --> 00:04:37,650
Gan and also a face scan to actually produce fake human face images that are extremely detailed in nature.

46
00:04:37,830 --> 00:04:43,250
So all of these faces you see here were actually generated using a Gan based system.

47
00:04:43,260 --> 00:04:46,620
So pretty impressive results.

48
00:04:46,630 --> 00:04:52,000
Now let's briefly talk about the difficulties with Gan networks and those are things like training resources

49
00:04:52,300 --> 00:04:53,980
mode collapse and instability.

50
00:04:53,990 --> 00:05:00,890
Will also try to give you potential solutions for each of these problems so right off the bat Ganz are

51
00:05:00,890 --> 00:05:07,100
most often used with image based data and due to the fact that you have two networks competing against

52
00:05:07,100 --> 00:05:12,990
each other they usually require graphical processing units or GP use for a reasonable training time.

53
00:05:13,010 --> 00:05:16,830
Now fortunately for us Google collab currently has GP is available for free.

54
00:05:17,030 --> 00:05:22,100
As discussed in the setup lecture but just keep in mind realistically we are training Ganz you're not

55
00:05:22,100 --> 00:05:25,070
really gonna be able to train them on CPR it'll just take too long.

56
00:05:26,800 --> 00:05:30,910
The next problem that curves of Ganz is something called the mode collapse.

57
00:05:30,910 --> 00:05:35,920
So often what happens is the generator figure out just a few images or even sometimes a single image

58
00:05:36,220 --> 00:05:41,160
that can fold to discriminator and eventually it collapses to only produce that image.

59
00:05:41,410 --> 00:05:47,050
So you can imagine that back in that situation where it's producing faces maybe it figured out how to

60
00:05:47,050 --> 00:05:50,510
produce one single face that falls discriminator.

61
00:05:50,770 --> 00:05:57,370
Well then the generator ends up just learning to produce that same face over and over again so in theory

62
00:05:57,730 --> 00:06:02,950
it would be preferable to have a variety of images such as multiple numbers or multiple faces or multiple

63
00:06:02,950 --> 00:06:08,900
images etc. But Ganz again can quickly collapse to only produce a single number or a single face or

64
00:06:08,900 --> 00:06:09,700
a single image.

65
00:06:09,700 --> 00:06:15,670
Whatever your dataset happens to be regardless of the input noise which means you can feed in any type

66
00:06:15,670 --> 00:06:20,820
of random noise you want but the generator figured out the one image that it can use to fool discriminator.

67
00:06:20,890 --> 00:06:28,110
So in its batch of images that it produces it just produces copies of the same image now a couple of

68
00:06:28,110 --> 00:06:32,910
different ways of trying to fight this problem is by using deep convolution Gantz which we'll see later

69
00:06:32,910 --> 00:06:37,890
on in the section of the course and they're typically better for a voting mode avoiding mode collapse

70
00:06:38,220 --> 00:06:43,160
because they are more complex and they have deeper layers to them.

71
00:06:43,320 --> 00:06:48,690
Now researchers have also experimented with what's known as mini batch discrimination which essentially

72
00:06:48,690 --> 00:06:52,540
punishes the generated batches of images that are all too similar.

73
00:06:52,800 --> 00:06:59,160
So if the generator starts having mode collapse and getting batches of very very similar looking images

74
00:06:59,610 --> 00:07:06,930
it will begin to basically punish that particular batch inside of discriminator for having the images

75
00:07:06,930 --> 00:07:08,210
be all too similar.

76
00:07:09,900 --> 00:07:15,200
And the last problem that we discussed was instability and it can be difficult to ascertain performance

77
00:07:15,260 --> 00:07:20,300
and appropriate training epochs since all the generated images at the end of the day they're all truly

78
00:07:20,300 --> 00:07:26,810
fake so it's difficult to tell just how well your model is performing at generating images because just

79
00:07:26,810 --> 00:07:32,090
because a discriminator thinks something is real doesn't mean that a human like us will think a face

80
00:07:32,090 --> 00:07:34,010
or a number looks real enough.

81
00:07:34,020 --> 00:07:38,190
So so it's difficult to ascertain that sort of true performance.

82
00:07:38,560 --> 00:07:44,300
And again due to the design of the generative adversarial network the generator and discriminator are

83
00:07:44,300 --> 00:07:47,120
constantly at odds they're fighting each other.

84
00:07:47,120 --> 00:07:54,730
So that can lead to performance oscillation between the two so typically when you're dealing with Ganz

85
00:07:54,790 --> 00:07:59,770
you'll have to experiment with hyper parameters such as the number of layers number of neurons activation

86
00:07:59,770 --> 00:08:07,300
functions learning rates etc. especially when it comes to complex images a few final thoughts before

87
00:08:07,300 --> 00:08:12,400
we continue on to actually creating our own games with Python and Caris and tensor flow is that Ganz

88
00:08:12,460 --> 00:08:20,110
are a very popular area of research and often this the results are so fascinating and so cool that researchers

89
00:08:20,110 --> 00:08:21,690
even like just to do this for fun.

90
00:08:21,700 --> 00:08:27,940
So you'll see a ton of hub repos on all sorts of different Ganz so I would highly encourage you to make

91
00:08:27,940 --> 00:08:32,200
sure to do a quick search on Google Scholar for the latest research papers on this topic.

92
00:08:32,200 --> 00:08:37,690
This is something that you'll see a paper almost every month just on some really interesting research

93
00:08:37,750 --> 00:08:39,400
in generative adversarial network.

94
00:08:39,400 --> 00:08:45,920
So I highly encourage you to just do a google search and see what has come out in the last few months.

95
00:08:45,950 --> 00:08:50,820
OK with that being said let's get started in programming our own hands.

96
00:08:50,920 --> 00:08:51,850
I'll see you at the next lecture.
