1
00:00:05,490 --> 00:00:06,990
Welcome back everyone.

2
00:00:06,990 --> 00:00:11,040
In this lecture we're going to focus on creating the model and train the model.

3
00:00:11,160 --> 00:00:17,190
And we're also going to emphasize the aspects of the model that you can play around with an edit versus

4
00:00:17,190 --> 00:00:22,920
the aspects that based off the constraints of your problem should essentially always be fixed.

5
00:00:22,920 --> 00:00:26,190
OK let's get started by heading back to the notebook.

6
00:00:26,190 --> 00:00:26,370
All right.

7
00:00:26,370 --> 00:00:30,670
So here we are the notebook where we left off last time just as before we're creating a model.

8
00:00:30,690 --> 00:00:39,320
We're going to say from tensor flow dot care stop models import and we'll import a sequential model

9
00:00:39,320 --> 00:00:39,760
builder.

10
00:00:39,800 --> 00:00:43,090
WE'LL STILL BUILD OUR MODEL sequentially by adding layers.

11
00:00:43,100 --> 00:00:46,890
The main difference is going to be the kind of layers we actually add to this.

12
00:00:46,970 --> 00:00:53,840
So we will say from tensor flow Dr. Harris that layers import and we're going to import a dense layer

13
00:00:53,870 --> 00:01:00,560
just as we did before but also a completion layer for handling to these images which has come to capital

14
00:01:00,560 --> 00:01:05,090
D and then also Max Poole to the.

15
00:01:05,340 --> 00:01:11,040
And then eventually you need to flatten out these images to fit it into our final dense layers which

16
00:01:11,040 --> 00:01:12,910
will actually perform the classification.

17
00:01:12,990 --> 00:01:14,760
So there is a special flatten layer for that.

18
00:01:15,600 --> 00:01:21,420
OK so let's begin building out our model and we're going to focus on a couple of parameters throughout

19
00:01:21,420 --> 00:01:30,330
the actual adding of the layers so just before we start off by building out our sequential model then

20
00:01:30,450 --> 00:01:35,730
the next thing to do is typically for accomplishing on your own network the first layer that it encounters

21
00:01:36,030 --> 00:01:37,550
is a volitional error.

22
00:01:37,680 --> 00:01:46,900
So we will say model add and I'm going to add in convolution loops to capital D parentheses and if you

23
00:01:46,900 --> 00:01:49,920
do shift tab here it'll show you the documentation string.

24
00:01:49,930 --> 00:01:54,430
Remember we we've already imported it and we have princes here so I can see the documentation string.

25
00:01:54,430 --> 00:02:00,310
Otherwise just call help on the actual class call but there's four main parameters that I want to essentially

26
00:02:00,310 --> 00:02:08,040
explain to you here and that is the filters the kernel size the strides and the padding Stream.

27
00:02:08,050 --> 00:02:12,470
Now we actually already understand filters kernel side strides and padding.

28
00:02:12,500 --> 00:02:16,020
Theoretically based off the theory lectures that we just went over.

29
00:02:16,240 --> 00:02:19,800
The main thing we have to figure out is what values do I choose for this.

30
00:02:19,930 --> 00:02:23,130
And a lot of times there's not 100 percent correct answer.

31
00:02:23,200 --> 00:02:27,570
It's based roughly off of the input data that's coming in.

32
00:02:27,580 --> 00:02:33,640
So really typical values for number of filters is the more complex the data set.

33
00:02:33,640 --> 00:02:38,800
So essentially the larger the images the more variety and images and the more classes you're trying

34
00:02:38,800 --> 00:02:41,830
to classify then the more filters you should have.

35
00:02:41,830 --> 00:02:45,830
And it's really common to choose filters based off powers of two.

36
00:02:45,850 --> 00:02:51,370
So a very common starting point for no filters could be something like 32 but you can imagine that if

37
00:02:51,370 --> 00:02:56,260
you're dealing with a really complex set of really large images and maybe you're trying to classify

38
00:02:56,260 --> 00:03:01,630
something like the number of or the types of road signs so you have a stop sign a yield sign a turn

39
00:03:01,630 --> 00:03:07,870
left turn right and you have a lot of classes it probably makes sense to then add a lot more filters

40
00:03:08,260 --> 00:03:13,600
to try to begin to understand or have your convolution on your own network understand the various shapes

41
00:03:13,660 --> 00:03:15,640
that come off all these different signs.

42
00:03:15,640 --> 00:03:21,100
Now in our case we have really simple data set of just handwritten numbers where we have 10 classes

43
00:03:21,160 --> 00:03:29,500
so filters with a Power of 32 or excuse me if a chosen value of 32 is a good step to start at the next

44
00:03:29,500 --> 00:03:32,630
we need to decide is that image Col size.

45
00:03:32,830 --> 00:03:40,560
And again typical sizes of image kernels are something in the range of two by two or four by four.

46
00:03:40,600 --> 00:03:44,620
And then you can keep expanding it based off again your data.

47
00:03:44,620 --> 00:03:47,890
A good starting point for this is four by four.

48
00:03:47,890 --> 00:03:52,090
OK so what about the other two parameters that we discussed in theory.

49
00:03:52,150 --> 00:03:58,480
So the next one is the side or the size of the strides and there's two dimensions here because you can

50
00:03:58,480 --> 00:04:05,650
stride in both X and Y and recall that the stride is basically how big of a stride are we taking as

51
00:04:05,650 --> 00:04:11,530
removing the colonel along this image in our case the test images are actually pretty small they're

52
00:04:11,530 --> 00:04:13,360
only 28 by 28 pixels.

53
00:04:13,510 --> 00:04:19,360
And since our colonel is four by four we can actually then determine how long of a time or essentially

54
00:04:19,360 --> 00:04:24,550
how many pixels is it going to take to go over by just saying 28 divided by four we can get an idea

55
00:04:24,880 --> 00:04:30,100
of that scanning of the image if you're dealing with really large images and you're still dealing with

56
00:04:30,100 --> 00:04:35,920
a smaller Colonel you would probably want to expand on that stride size in our case though we'll go

57
00:04:35,920 --> 00:04:39,100
ahead and leave it of the default of just one by one pixel.

58
00:04:39,130 --> 00:04:45,730
So essentially just striding along by default pixel and X pixel 10 x pixel etc. and then the next one

59
00:04:45,790 --> 00:04:46,930
is padding.

60
00:04:46,930 --> 00:04:49,500
And if you take a look at padding it's either valid.

61
00:04:49,570 --> 00:04:50,650
So it's a string code valid.

62
00:04:50,650 --> 00:04:56,240
And if we scroll down here you'll say that it's either valid or same.

63
00:04:56,260 --> 00:04:57,910
And those are your only two options.

64
00:04:57,910 --> 00:05:00,050
So what do these strings actually mean.

65
00:05:00,160 --> 00:05:04,660
If you do a quick google search for what is a difference between valid and same in the string you get

66
00:05:04,660 --> 00:05:09,280
this nice link to a stack overflow post that basically talks about what's the difference between this

67
00:05:09,340 --> 00:05:11,330
same and valid padding.

68
00:05:11,380 --> 00:05:16,440
And this actually links to Max pool of tension flow but it's the same code for Caris as well.

69
00:05:16,600 --> 00:05:21,520
And if we come down here there's an example here talking about same versus valid pad but I like some

70
00:05:21,520 --> 00:05:27,940
of these more visual examples and probably the clearest explanation is if you scroll down here the clearest

71
00:05:27,940 --> 00:05:33,940
to me was essentially this quick explanation right here and it's worth the bottom.

72
00:05:34,000 --> 00:05:39,490
All of these explanations essentially say the same thing but the string valid basically tells you do

73
00:05:39,490 --> 00:05:45,220
not apply any padding or we're going to do is we're going to assume that all dimensions are valid so

74
00:05:45,220 --> 00:05:51,070
that the input image fully gets covered by the filter and stride that I specified.

75
00:05:51,100 --> 00:05:53,740
So is that going to be the case here.

76
00:05:53,740 --> 00:05:54,990
Well let's think about this.

77
00:05:55,060 --> 00:06:03,960
If I have 28 and I divide it by four that goes evenly seven times and I'm only doing a stride of one.

78
00:06:04,030 --> 00:06:11,160
So if I just move my colonel which is four by four along my 28 by 28 image I shouldn't have a need for

79
00:06:11,180 --> 00:06:18,100
padding because I won't actually overshoot because I fit perfectly with a stride of one.

80
00:06:18,100 --> 00:06:24,460
But if this begins to give out decimal numbers you may end up encountering some errors because you're

81
00:06:24,460 --> 00:06:28,510
overshooting and in that case we have to decide are we just going to drop those points are we going

82
00:06:28,510 --> 00:06:32,080
to pad it with zeros or ones et cetera.

83
00:06:32,140 --> 00:06:36,010
And so then what we do is we'd have to specify the string same.

84
00:06:36,430 --> 00:06:37,260
So nice.

85
00:06:37,270 --> 00:06:41,530
What's nice about same is they automatically figures out what the padding should be.

86
00:06:41,530 --> 00:06:47,550
So what happens here is it's going to apply padding to the input only if needed so that the input image

87
00:06:47,580 --> 00:06:51,480
gets fully covered by the filter and strike that you specified.

88
00:06:51,480 --> 00:06:57,120
So for example if we decided on a straight of one that ensures that the output image size is the same

89
00:06:57,570 --> 00:06:59,310
as the input image.

90
00:06:59,310 --> 00:07:05,700
OK so there's lots of other explanations here one that goes in to the math of it and another one here

91
00:07:06,030 --> 00:07:12,000
that shows you essentially what this is doing through a little bit of kind of a visual explanation.

92
00:07:12,000 --> 00:07:16,590
So I encourage you that if you just google search if we go back here valid versus same padding you get

93
00:07:16,680 --> 00:07:19,070
a lot of outputs here.

94
00:07:19,190 --> 00:07:19,830
OK.

95
00:07:19,890 --> 00:07:22,020
So again you can look at those explanations.

96
00:07:22,020 --> 00:07:27,810
In our case we'll just go ahead and keep the default which will work fine for us in our case or we just

97
00:07:27,810 --> 00:07:31,160
have padding is valid.

98
00:07:31,160 --> 00:07:31,630
OK.

99
00:07:31,880 --> 00:07:34,210
So that's our filters and or kernel size.

100
00:07:34,370 --> 00:07:40,440
The couple things we need to now add in is define what is the input shape that we expect here.

101
00:07:40,460 --> 00:07:47,760
So it's going to be input shape is equal to and in our case is just the input shape for a single image

102
00:07:47,820 --> 00:07:51,670
which is twenty eight by twenty eight by one color channel.

103
00:07:51,990 --> 00:07:55,630
And then finally we choose what kind of activation function do we want.

104
00:07:55,650 --> 00:08:03,480
So the activation function will choose is rectified linear unit so say activation is equal to rectified

105
00:08:03,570 --> 00:08:05,070
linear unit.

106
00:08:05,070 --> 00:08:05,540
Okay.

107
00:08:05,700 --> 00:08:11,460
So let's put this all on one line here and I can zoom out just a little bit so we can see the whole

108
00:08:11,460 --> 00:08:17,460
call our compositional error has some determine number of filters a kernel size if we want we can specify

109
00:08:17,460 --> 00:08:17,870
padding.

110
00:08:17,880 --> 00:08:19,760
But in this case we have to.

111
00:08:19,800 --> 00:08:23,210
And then we can specify the input shape and the activation function.

112
00:08:23,220 --> 00:08:23,760
Okay.

113
00:08:23,970 --> 00:08:25,290
So it's a conventional error.

114
00:08:25,470 --> 00:08:28,200
After your accomplishment layer you should have a pooling layer.

115
00:08:28,330 --> 00:08:36,310
You will say model add here I will call Max Poole to the and the main thing to choose here is the pool

116
00:08:36,310 --> 00:08:36,910
size.

117
00:08:36,940 --> 00:08:43,450
You can also add in things like strides padding etc. but really the key factor is pool size and we'll

118
00:08:43,450 --> 00:08:46,040
go ahead and do a pool size that's half of our kernel size.

119
00:08:46,190 --> 00:08:50,280
A two by two is a really common metric here.

120
00:08:50,360 --> 00:08:52,270
So we'll go ahead and just say pool size is 2 by 2.

121
00:08:52,270 --> 00:08:52,970
That is the default.

122
00:08:52,970 --> 00:08:58,500
So technically that I have to specify that but I do want the visibility of what I'm doing here.

123
00:08:58,520 --> 00:09:03,510
Okay now we're going to just keep it as having one convolution earlier and one pooling layer.

124
00:09:03,530 --> 00:09:05,750
So very simple accomplished on the whole network.

125
00:09:05,750 --> 00:09:09,650
Now what I could do is keep adding compositional and pulling layers and we'll do that later on for more

126
00:09:09,650 --> 00:09:10,750
complex images.

127
00:09:10,850 --> 00:09:12,310
But right now we'll just keep it simple.

128
00:09:12,320 --> 00:09:17,360
One compositional error one pulling layer after your series accomplishment and putting layers.

129
00:09:17,360 --> 00:09:19,520
You'll need to flatten out the images.

130
00:09:19,700 --> 00:09:26,420
So when we're flattening out the images that essentially means take a 28 by 20 image and then flatten

131
00:09:26,420 --> 00:09:29,290
it out to be just a single array of.

132
00:09:29,300 --> 00:09:32,270
In our case seven hundred and eighty four points.

133
00:09:32,330 --> 00:09:37,280
So take one of these two by two images and then flatten it out into internal rate of 784 which is 28

134
00:09:37,310 --> 00:09:38,340
times 28.

135
00:09:38,570 --> 00:09:45,420
So we can do that by simply saying model add and then we flatten out the image.

136
00:09:45,420 --> 00:09:49,580
Once we're able to flatten out the image well we can do is we can start adding in our dense layers.

137
00:09:49,630 --> 00:09:57,150
It's usually a good idea to add in one final dense layer that more or less matches the same scale of

138
00:09:57,150 --> 00:09:57,480
this.

139
00:09:57,480 --> 00:10:02,430
So the scale should be somewhere between zero and one thousand we'll go ahead and say dense and we'll

140
00:10:02,430 --> 00:10:04,490
keep kind of the power of two.

141
00:10:04,590 --> 00:10:11,940
Same here and we'll say 120 neurons in the sense layer activation is equal to rectified linear unit.

142
00:10:11,940 --> 00:10:16,810
And if you want you can keep adding dense layers but eventually we have our final output layer.

143
00:10:16,950 --> 00:10:20,580
So how many neurons should be in my final output layer.

144
00:10:20,850 --> 00:10:29,460
In this case for classification I should have one neuron per class so that will be a dense layer with

145
00:10:29,460 --> 00:10:30,740
10 neurons.

146
00:10:30,840 --> 00:10:36,210
And in this case I also have to think of my activation function which should be for a multi class classification

147
00:10:36,210 --> 00:10:42,330
problem not a binary class but a multi class should be the soft Max activation function.

148
00:10:42,390 --> 00:10:53,920
So again it's going to be soft Max because this is a multi class problem then finally I'm going to compile

149
00:10:53,920 --> 00:11:05,590
this will say model compile loss is equal to categorical cross entropy categorical cross entry because

150
00:11:05,590 --> 00:11:12,520
it's a multi class problem the optimizer will go ahead and choose atom for optimizer and here if I want

151
00:11:12,700 --> 00:11:17,650
I can specify additional metrics which is actually something we haven't seen before but I could say

152
00:11:18,700 --> 00:11:21,240
go ahead and add in some additional metrics.

153
00:11:21,250 --> 00:11:24,980
Typically what we do is we use loss as our metric.

154
00:11:25,180 --> 00:11:30,370
Essentially the lost calculation from our loss function which is categorical cross entropy.

155
00:11:30,370 --> 00:11:31,130
That's something I could do.

156
00:11:31,150 --> 00:11:36,820
I could also keep track of something like accuracy and if you want to check out what string codes are

157
00:11:36,820 --> 00:11:43,900
available to you or what metrics are available to you can go to Kerry's the I O slash metrics.

158
00:11:43,900 --> 00:11:51,280
So if I go ahead and copy this and then paste it here to the curious documentation it'll actually show

159
00:11:51,280 --> 00:11:52,480
you the available metrics.

160
00:11:52,480 --> 00:11:59,350
There's accuracy binary actually categorical accuracy top K etc. clone club metrics and you can even

161
00:11:59,530 --> 00:12:06,020
create your own custom metrics so there's lots of options here that we can keep taking a look at so

162
00:12:06,020 --> 00:12:11,960
we'll go ahead and just choose accuracy essentially actually across all categories in our case and we'll

163
00:12:11,960 --> 00:12:12,620
leave it as such.

164
00:12:12,620 --> 00:12:17,150
We'll still be able to calculate loss but this is just another metric that we can keep recording during

165
00:12:17,150 --> 00:12:18,060
training.

166
00:12:18,140 --> 00:12:22,830
We'll go ahead and compile the model make sure we don't commit any typos and we're good to go.

167
00:12:22,880 --> 00:12:23,110
All right.

168
00:12:23,540 --> 00:12:28,760
So I want to quickly highlight what can you play around with and what has to be said.

169
00:12:28,790 --> 00:12:35,300
Let's start off by discussing the parameters that are fixed and should be determined by your actual

170
00:12:35,300 --> 00:12:41,780
data set those parameters are your input shape the input shape should essentially match what an image

171
00:12:41,840 --> 00:12:46,940
is going to look like in our case it's a 28 by twenty eight one color channel image.

172
00:12:46,940 --> 00:12:52,710
This input shape parameter is determined by your data after your compositional layers and you're pulling

173
00:12:52,710 --> 00:12:53,390
layers.

174
00:12:53,430 --> 00:12:56,280
You will eventually have to flatten out your data.

175
00:12:56,310 --> 00:13:01,440
So this is another parameter essentially a layer that should be somewhere in your network.

176
00:13:01,440 --> 00:13:07,170
Then the last couple of parameters that you will edit and should be set based off your data.

177
00:13:07,170 --> 00:13:15,630
Is this final dense layer this dense layer should be equal to the number of neurons to your classes.

178
00:13:15,630 --> 00:13:19,750
So we have 10 possible classes the numbers 0 1 2 3 all the way to 9.

179
00:13:19,890 --> 00:13:24,290
So I should have 10 year ons here and the activation function should then be soft to Max.

180
00:13:24,510 --> 00:13:29,820
If you were dealing with a binary classification problem such as just an image of a cat versus a dog

181
00:13:30,180 --> 00:13:36,450
then this would be a binary classification with just one neuron output with an activation of sigmoid

182
00:13:37,050 --> 00:13:39,840
and the other thing that's defined by your problem is the type of loss.

183
00:13:39,870 --> 00:13:44,180
And then here in our case it's categorical cross entropy.

184
00:13:44,210 --> 00:13:49,920
OK now the things can play around with are several here you can add as many compositional and pulling

185
00:13:49,920 --> 00:13:55,140
layers as you want and then within those you can play around the number of filters the kernel sizes

186
00:13:55,200 --> 00:13:58,750
as well as the pool size and you can also play around with the padding.

187
00:13:58,860 --> 00:14:00,960
Then after that after you flatten it out.

188
00:14:00,960 --> 00:14:06,060
You can play around with the number of dense layers as well as the number of neurons in those layers.

189
00:14:06,060 --> 00:14:10,800
And typically people just use kind of one dense layer maybe two after they flatten it out.

190
00:14:10,860 --> 00:14:15,360
They don't have that many dense layers after flattening out most of the work for image data should be

191
00:14:15,360 --> 00:14:17,760
done by the convolution and pulling layers.

192
00:14:17,760 --> 00:14:22,560
OK so I just wanted to have that brief discussion highlighting what is available to you to play around

193
00:14:22,560 --> 00:14:25,400
with and what should be set by your data.

194
00:14:25,430 --> 00:14:29,840
All right now the last thing we want to set up is training the model to make sure we don't need to worry

195
00:14:29,840 --> 00:14:31,640
about choosing the number of epochs.

196
00:14:31,640 --> 00:14:34,850
Let's go ahead and set up an early stopping callback.

197
00:14:34,960 --> 00:14:45,390
We'll say from tensor flow that carries the callbacks go ahead and import early stopping and then the

198
00:14:45,390 --> 00:14:50,050
early stop will be equal to early stopping.

199
00:14:50,100 --> 00:14:54,920
We decide what we want to monitor by default we monitor validation loss.

200
00:14:54,950 --> 00:15:00,830
But keep in mind the other metric we could be monitoring is validation accuracy because I added metrics

201
00:15:01,100 --> 00:15:02,130
accuracy here.

202
00:15:02,210 --> 00:15:09,950
I could say Val underscore accuracy as my monitor device but we'll go ahead to keep it to the lost that's

203
00:15:10,010 --> 00:15:17,900
output by categorical cross entropy and then we specify some patients so we can specify something like

204
00:15:17,900 --> 00:15:23,780
patients want or patients to we're going to set it to patients once so wait 1 epoch run that and now

205
00:15:23,810 --> 00:15:32,320
we'll say model that fit passin our training data and then for y recall we want to pass on the categorical

206
00:15:32,320 --> 00:15:39,760
version of these labels we'll set epochs to something relatively high 10 and then we need to make sure

207
00:15:39,760 --> 00:15:46,090
we also pass in our validation dataset so it's going to be x test and also this should also be categorical

208
00:15:46,290 --> 00:15:52,990
why cat test and then finally to make sure we actually have early stopping we'll say callbacks is equal

209
00:15:52,990 --> 00:15:55,770
to early stop.

210
00:15:55,820 --> 00:15:58,220
Okay go ahead and fit that model.

211
00:15:58,240 --> 00:16:02,320
Make sure we didn't make any typos above and it looks like it's working out for us you can really see

212
00:16:02,320 --> 00:16:06,480
we get a very high accuracy right off the bat this is a pretty easy dataset to work with.

213
00:16:06,880 --> 00:16:12,190
Okay so coming up in the next lecture after with on training the model we will evaluate the model's

214
00:16:12,190 --> 00:16:13,080
performance.

215
00:16:13,240 --> 00:16:13,840
I will see you there.
