1
00:00:05,440 --> 00:00:06,810
Welcome back everyone.

2
00:00:06,820 --> 00:00:09,720
In part three of the caris syntax basics.

3
00:00:09,790 --> 00:00:16,210
We're gonna focus on the evaluation of our model recall that we have this test set that we can compare

4
00:00:16,300 --> 00:00:21,280
our models to predictions to to evaluate how well our model is actually performing.

5
00:00:21,280 --> 00:00:24,750
Let's head back to notebook and continue where we left off OK.

6
00:00:24,760 --> 00:00:26,770
Here we are where we left off last time.

7
00:00:26,770 --> 00:00:33,250
Now with this plot I can see my losses on the training set but what I really want to know is how well

8
00:00:33,250 --> 00:00:39,280
will this model perform on data that it's never seen before and that data is our test data.

9
00:00:39,460 --> 00:00:41,100
There's lots different ways we can evaluate.

10
00:00:41,140 --> 00:00:45,010
So we're going to walk through a bunch of different methods and a lot of these will return back the

11
00:00:45,010 --> 00:00:45,860
same results.

12
00:00:45,880 --> 00:00:50,330
Some means caught error so we're going to go through the various methods of doing this.

13
00:00:50,530 --> 00:00:56,170
One way to do this is by calling model dot evaluates and the weight model that evaluate works as you

14
00:00:56,170 --> 00:00:58,930
pass in your test set X and Y.

15
00:00:58,930 --> 00:01:06,660
So what I'm going to say is X test and Y test and I will say verbose is equal to zero.

16
00:01:06,660 --> 00:01:14,010
So I don't see a bunch of output and if I run this will happens is it returns back your models loss

17
00:01:14,460 --> 00:01:16,770
on the test set and why test.

18
00:01:16,800 --> 00:01:21,260
So what this number actually represents is the metric loss that you decided on.

19
00:01:21,650 --> 00:01:26,190
And if we take a look back at our model in our case that's mean squared error.

20
00:01:26,250 --> 00:01:30,900
So what this means is on the test set that is data it's never seen before.

21
00:01:30,900 --> 00:01:35,770
It's getting back to a mean squared error of twenty four point nine seven.

22
00:01:35,790 --> 00:01:45,410
So we could do the same thing for our training set so we could say model that evaluate X train versus

23
00:01:45,980 --> 00:01:52,290
Y train run that and we see the loss on our training set.

24
00:01:52,350 --> 00:01:57,840
Keep in mind your values may look slightly different just because of the way the neural network works.

25
00:01:57,870 --> 00:02:00,010
It starts off of random initialization.

26
00:02:00,330 --> 00:02:03,490
So you may get numbers that are slightly different.

27
00:02:03,540 --> 00:02:09,570
However after training on about 250 epochs you shouldn't be hovering somewhere between twenty four and

28
00:02:09,570 --> 00:02:12,560
twenty six as your means squared error.

29
00:02:12,630 --> 00:02:15,180
So what does this actually mean.

30
00:02:15,180 --> 00:02:20,100
Well this is a way we can interpret our results to see how well the predictions are actually performing

31
00:02:20,490 --> 00:02:25,090
and we'll show you and also grab root means squared error and mean absolute error.

32
00:02:25,170 --> 00:02:32,250
So the way we can do that is get our actual true predictions and we do that by saying models that predict

33
00:02:33,480 --> 00:02:42,120
now we're going to pass in our test to get test underscore predictions.

34
00:02:42,130 --> 00:02:48,070
So what this does is we pass in our test features and have the model predict just based off those features

35
00:02:48,670 --> 00:02:51,440
what it thinks the price should be.

36
00:02:51,440 --> 00:02:57,870
So now here's a list of the prices that are predicted based off our next test set.

37
00:02:57,940 --> 00:03:03,070
And in fact let's bring these together along with the true values for that test set.

38
00:03:03,080 --> 00:03:04,490
That is the why test.

39
00:03:04,490 --> 00:03:07,750
And then we can plot them out compare them against each other.

40
00:03:07,760 --> 00:03:13,730
So what I'll do is the following I will create a data frame called pred underscored the F so my prediction

41
00:03:13,730 --> 00:03:22,750
data frame and it's going to be equal to and in this case I will say that my test predictions are this

42
00:03:22,840 --> 00:03:30,160
model that predict and I will turn those into a panda series by saying test predictions is equal to

43
00:03:30,160 --> 00:03:36,340
PD that series Test underscore predictions.

44
00:03:36,370 --> 00:03:43,720
And in this case I will need to reshape this to be 300 karma and that's just what matches up with the

45
00:03:43,720 --> 00:03:47,230
dimensions that a pan this serious call expects.

46
00:03:47,230 --> 00:03:53,890
So essentially after running this I still have those same test predictions but it's a pan this series

47
00:03:53,890 --> 00:04:00,050
now instead of a nut pyrite which will allow me to do the following.

48
00:04:00,280 --> 00:04:10,970
I can say my prediction data frame is equal to PD that data frame based off white test let's say the

49
00:04:10,970 --> 00:04:15,910
columns here are just test true why.

50
00:04:16,230 --> 00:04:23,130
So right now my prediction data frame just has the true value of y and what I'm going to do is say go

51
00:04:23,130 --> 00:04:30,760
ahead and concatenate that with the true value of y comma with my test predictions.

52
00:04:30,950 --> 00:04:35,270
And I know there's a lot of code here as well as a lot of braces brackets and parentheses.

53
00:04:35,270 --> 00:04:36,710
So if you get an error somewhere.

54
00:04:36,740 --> 00:04:42,140
Go ahead and check out our notebook and just run that directly and hear what I'm going to do is also

55
00:04:42,140 --> 00:04:44,480
make sure that I'm joining these along axis equal to 1.

56
00:04:44,510 --> 00:04:50,210
So along the columns after running that you should be able to see your prediction data frame which is

57
00:04:50,210 --> 00:04:52,670
essentially looking like this we have test true y.

58
00:04:52,760 --> 00:04:55,740
And here we get zero because we don't actually have a name for that.

59
00:04:55,760 --> 00:05:05,960
So go ahead and say my columns are test true y and then my model predictions.

60
00:05:05,990 --> 00:05:09,290
So now when I take a look at my predicted data frame I get this result.

61
00:05:09,770 --> 00:05:17,700
So here I can directly see based off my test set what the true price value was and what my model predicted.

62
00:05:17,870 --> 00:05:20,830
OK so what I can do is lots of things now.

63
00:05:20,870 --> 00:05:23,200
I can actually plot these against each other.

64
00:05:23,240 --> 00:05:31,880
So what I could do is say create a scatter plot based off this data and my prediction data frame and

65
00:05:31,880 --> 00:05:41,850
then I'll also do the following I'll say X is equal to test true y and I plotted against these model

66
00:05:41,850 --> 00:05:44,280
predictions.

67
00:05:44,280 --> 00:05:46,530
So run that and we see this result.

68
00:05:46,710 --> 00:05:48,300
So what does this actually mean.

69
00:05:48,300 --> 00:05:55,170
Well let's imagine that my predictions were a perfect match for the true y prices.

70
00:05:55,200 --> 00:06:00,840
That means I would expect a perfect straight line here because if my price was three hundred then my

71
00:06:00,840 --> 00:06:02,930
prediction should also be three hundred.

72
00:06:02,940 --> 00:06:10,170
Now notice we actually are quite close to a very straight fitting line which means this model is performing

73
00:06:10,260 --> 00:06:17,400
very well and we can also grab metrics to essentially show that not just qualitatively through a plot

74
00:06:17,670 --> 00:06:21,950
but quantitatively through the various regression methods that we talked about.

75
00:06:22,110 --> 00:06:27,550
Recall back in the machinery lectures we had a whole discussion on regression evaluation.

76
00:06:27,630 --> 00:06:32,480
So we talked about mean absolute error means squared error and then root mean square error.

77
00:06:32,550 --> 00:06:36,730
So let's show you how you can actually grab those to do that.

78
00:06:36,750 --> 00:06:48,660
I can say from S.K. learn that metrics import mean absolute error and mean squared error.

79
00:06:49,020 --> 00:06:54,690
And if I want my mean absolute error then I just need to if I take a look at this compare my y true

80
00:06:54,870 --> 00:07:00,750
to my Y predicted and luckily I've already organized that for myself in this data frame where I have

81
00:07:00,900 --> 00:07:09,090
my test true y and I also have my model predictions.

82
00:07:09,090 --> 00:07:14,150
So I run that and I get a mean absolute error of about 4 which is something you should begin initially

83
00:07:14,220 --> 00:07:17,920
beginning or somewhere around 4 4 a mean absolute error.

84
00:07:17,970 --> 00:07:23,440
So this means on average I'm about four dollars off from my price point.

85
00:07:23,640 --> 00:07:28,050
Now the most common stupid question I get is how do I know if this is good or bad.

86
00:07:28,590 --> 00:07:31,510
Well it really depends on your original data.

87
00:07:31,560 --> 00:07:38,190
We take a look at our original data frame recall we have this price column let's go ahead and call dot

88
00:07:38,190 --> 00:07:45,930
describe on this and we can see that the average price is around five hundred dollars with a minimum

89
00:07:45,930 --> 00:07:49,950
of two hundred twenty three and a maximum of seven hundred and seventy four.

90
00:07:50,220 --> 00:07:57,430
In our mean absolute error that is how on average how far off we are we are on average off by four dollars.

91
00:07:57,630 --> 00:08:01,790
So if I take a look at the mean price that's less than 1 percent.

92
00:08:01,890 --> 00:08:05,820
So that would mean that this is actually a pretty good mean absolute error.

93
00:08:05,820 --> 00:08:10,740
Something indicated again by this plot right here that's almost a perfect straight line.

94
00:08:10,770 --> 00:08:16,800
So this indicates that our model is performing very well at predicting the price of let's say this gemstone

95
00:08:17,130 --> 00:08:19,760
based off these two features.

96
00:08:19,770 --> 00:08:25,590
Now again the mean absolute error doesn't mean anything without the context of the label you're trying

97
00:08:25,590 --> 00:08:32,130
to predict if the average price was one dollar in our mean absolute error was four dollars.

98
00:08:32,130 --> 00:08:35,860
That means we're off by 400 percent and that's a very different story.

99
00:08:35,880 --> 00:08:42,990
So you always have to take into account the mean values as well as the actual distribution of your label

100
00:08:43,350 --> 00:08:48,540
when comparing it to your error such as mean absolute error and we can also calculate our mean square

101
00:08:48,570 --> 00:08:52,780
error by performing the exact same thing.

102
00:08:52,790 --> 00:08:54,740
So I can say it means great error.

103
00:08:54,740 --> 00:09:01,040
Go ahead and copy and paste this and notice it's twenty four point nine seven which is essentially the

104
00:09:01,040 --> 00:09:06,830
same thing we got at the very bottom here when we said model to evaluate on X test versus Y test which

105
00:09:06,830 --> 00:09:12,140
makes sense because the original loss for the model was mean squared error.

106
00:09:12,230 --> 00:09:17,910
So essentially what this model evaluate line does is exactly what this line does.

107
00:09:17,930 --> 00:09:23,980
It just calculates the mean squared error for whatever you pass in the test set or the training set.

108
00:09:24,200 --> 00:09:28,610
And if we wanted to get the root mean square there then all I would need to do is essentially take the

109
00:09:28,730 --> 00:09:33,500
square root of this which is the same as taking something to the power of zero point five.

110
00:09:33,500 --> 00:09:38,840
You could also say NDP thought rescue party if you imported some pie and then we get back the root mean

111
00:09:38,840 --> 00:09:40,870
square error which is four point ninety nine.

112
00:09:41,060 --> 00:09:44,900
So you can use that mean absolute error means squared error and root mean square.

113
00:09:44,960 --> 00:09:51,290
However you see fit to evaluate your model's performance and finally I want to go over two last things

114
00:09:51,290 --> 00:09:53,960
which is predicting on brand new data.

115
00:09:53,960 --> 00:10:00,080
So let's imagine that we go out into the field and I pick out this gemstone from the ground and it has

116
00:10:01,160 --> 00:10:01,840
these features.

117
00:10:01,850 --> 00:10:06,460
Let's say I pick up this new Gemstone and pay attention to my dimensions here.

118
00:10:06,470 --> 00:10:13,130
I have double braces so that it matches up with the original data and feature one is equal to 998 and

119
00:10:13,130 --> 00:10:14,570
feature two is equal to a thousand.

120
00:10:14,570 --> 00:10:16,070
And these are just made up features.

121
00:10:16,250 --> 00:10:21,510
So I pick this new gem out of the ground and I want to ask my model which I prices at.

122
00:10:21,520 --> 00:10:27,740
Well the one thing I have to remember is that my model is trained on these scaled features.

123
00:10:27,740 --> 00:10:35,880
So what I have to first do is take my original scalar and transform new gem.

124
00:10:35,970 --> 00:10:38,970
So now I have the scaled version of these features.

125
00:10:39,060 --> 00:10:45,210
So let's go ahead and set new gem equal to the scaled version of new gem.

126
00:10:45,750 --> 00:10:53,680
And now what I can do is simply take my model and predict the price of that new gem which in this case

127
00:10:53,710 --> 00:10:56,420
should be somewhere around 420 dollars.

128
00:10:56,470 --> 00:10:59,890
So that's how you would predict on a brand new set of data.

129
00:10:59,890 --> 00:11:05,850
Keep in mind that's the exact same process you just ran on your test data set since your test data set

130
00:11:06,190 --> 00:11:08,150
according to the model is essentially brand new data.

131
00:11:08,170 --> 00:11:09,640
It's never seen before.

132
00:11:09,640 --> 00:11:16,750
So the way you evaluate your test set is basically the exact same thing you would do for brand new data.

133
00:11:16,750 --> 00:11:21,670
And finally if you're running a very complex model that took a lot of time to train you want to make

134
00:11:21,670 --> 00:11:25,130
sure that you save that model and Caris makes it quite easy.

135
00:11:25,150 --> 00:11:31,210
We simply say from tensor flow that carries that models import

136
00:11:33,930 --> 00:11:46,280
Load model and then I take my current existing model and they save it as a HD F5 file so I can say some

137
00:11:46,280 --> 00:11:51,180
string my gem model the H5 run that.

138
00:11:51,200 --> 00:11:58,820
And now what I can do is use the Load model come in so later on I can say OK I'm in a new notebook and

139
00:11:58,820 --> 00:12:00,350
I want to load up this model.

140
00:12:00,350 --> 00:12:06,830
I SIMPLY RUN THIS import command of load model and I say later models equal to load model and then I

141
00:12:06,830 --> 00:12:14,240
read in that model I saved my gem model that H5 and then you make it some morning there based off the

142
00:12:14,240 --> 00:12:19,940
input shape you can totally ignore that warning it's OK but notice now I can treat this later model

143
00:12:19,970 --> 00:12:27,370
just as I would any other model and then predict on new gem just as I did before and notice we get back

144
00:12:27,430 --> 00:12:29,170
the exact same results.

145
00:12:29,200 --> 00:12:33,720
So that's how you can both save a model and then load it later in the new file.

146
00:12:33,730 --> 00:12:34,380
OK.

147
00:12:34,660 --> 00:12:37,420
So we went over the very basics of terrorists.

148
00:12:37,450 --> 00:12:41,070
Now we did this on a fake generated data.

149
00:12:41,110 --> 00:12:47,020
Coming up next let's focus on a much more realistic dataset and really focus on the full workflow including

150
00:12:47,020 --> 00:12:52,690
exploratory data analysis and feature engineering which is very crucial to becoming a good machine learning

151
00:12:52,690 --> 00:12:53,930
practitioner.

152
00:12:53,990 --> 00:12:55,900
Thanks and I'll see you at the next lecture.
