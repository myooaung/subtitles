1
00:00:05,380 --> 00:00:09,770
Welcome back everyone to part two on competition on your own that works on custom images.

2
00:00:09,850 --> 00:00:16,240
In part two really we're going to focus on is this special object from tensor flow cares which is called

3
00:00:16,240 --> 00:00:18,160
the image data generator.

4
00:00:18,190 --> 00:00:22,930
What you're going to be able to do of this class is feed it in the directory over your actual image

5
00:00:22,930 --> 00:00:28,240
files are and you'll be able to perform a bunch of manipulations on your images and then feed those

6
00:00:28,480 --> 00:00:30,820
new images to your model.

7
00:00:30,820 --> 00:00:35,920
Let's go ahead and explore this idea of manipulating images as well as flowing from a directory.

8
00:00:35,920 --> 00:00:37,550
These new batches of files.

9
00:00:37,630 --> 00:00:40,390
Let's head back to notebook where we left off last time.

10
00:00:40,390 --> 00:00:40,640
All right.

11
00:00:40,640 --> 00:00:45,850
Recall last time we basically read in the data and we figured out what are the average dimensions of

12
00:00:45,850 --> 00:00:46,680
our images.

13
00:00:46,720 --> 00:00:51,010
Because when we feed these images to the model we need to make sure they all have the same size.

14
00:00:51,010 --> 00:00:55,960
So picking out the average dimensions is probably a good idea in our case it was conveniently around

15
00:00:55,960 --> 00:00:57,580
130 by 130.

16
00:00:57,640 --> 00:01:00,140
Next is image manipulation.

17
00:01:00,220 --> 00:01:06,170
So keep in mind there's really just too much data for us to read in all this data at once.

18
00:01:06,340 --> 00:01:09,780
These files are much much larger than the files we've been dealing with.

19
00:01:09,940 --> 00:01:13,630
Recall Em this was on was basically twenty eight by twenty eight.

20
00:01:13,640 --> 00:01:16,220
The Safa was 32 by 32.

21
00:01:16,300 --> 00:01:23,170
And even that small expansion from twenty eight to twenty two color images a 32 by 32 was a huge expansion

22
00:01:23,230 --> 00:01:24,660
in the amount of data.

23
00:01:24,700 --> 00:01:25,700
So that's 28 times.

24
00:01:25,700 --> 00:01:29,280
Twenty eight was seven hundred eighty four data points.

25
00:01:29,410 --> 00:01:35,330
And when we went to Safa That was thirty two by thirty two times three one for each color channel.

26
00:01:35,500 --> 00:01:41,620
That was three thousand seventy two our files are going to be even larger as we read them in they're

27
00:01:41,620 --> 00:01:43,750
gonna be 130 times 130 times three.

28
00:01:43,870 --> 00:01:48,880
So now we're dealing with fifty thousand seven hundred data points because of that we're not going to

29
00:01:48,880 --> 00:01:51,060
be able to just feed in everything at once.

30
00:01:51,070 --> 00:01:55,120
Instead we'll have to select batches of our images.

31
00:01:55,180 --> 00:02:02,500
The other idea that we want the model to be able to overcome is the fact that it should be robust enough

32
00:02:02,530 --> 00:02:06,820
to deal of images that are pretty different from images that it's seen before.

33
00:02:06,820 --> 00:02:12,160
And when we can do that is by manipulating and performing transformations on our images things like

34
00:02:12,160 --> 00:02:20,160
rotation resizing and scaling to begin this entire process we'll say from tensor flow that carries the

35
00:02:20,260 --> 00:02:30,120
pre processing the image import and we're going to use the image data generator.

36
00:02:30,440 --> 00:02:37,790
Go ahead and run that and then once that's imported I would encourage you to actually call help on this

37
00:02:37,820 --> 00:02:43,330
object and take a low or just take a look at the documentation for this class.

38
00:02:43,370 --> 00:02:44,980
There's definitely a lot going on here.

39
00:02:44,990 --> 00:02:49,030
This is a huge class even has kind of full examples of how to do this.

40
00:02:49,130 --> 00:02:53,670
But what I want you to do is just take a time to kind of read through this and see the different examples.

41
00:02:53,690 --> 00:02:57,060
You can also read up about this on its online documentation page.

42
00:02:57,200 --> 00:03:02,300
But what we're going to do is basically show you the main idea of what image that data generator is

43
00:03:02,360 --> 00:03:03,120
doing.

44
00:03:03,140 --> 00:03:10,250
So what I'll do is I'm going to create an instance of an image generator we'll say image Jen is equal

45
00:03:10,250 --> 00:03:15,180
to and we will call our image data generator object.

46
00:03:15,320 --> 00:03:20,870
If you do shift type here you can begin to see the various parameters and there are a ton of parameters

47
00:03:20,900 --> 00:03:22,260
they can pass in here.

48
00:03:22,370 --> 00:03:28,670
Everything from feature wise centering sample wise centering brightness range horizontal flipping vertical

49
00:03:28,670 --> 00:03:31,100
flipping pre processing et cetera.

50
00:03:31,130 --> 00:03:33,540
So there's lots of different things we can do here.

51
00:03:33,560 --> 00:03:39,320
You should also recall that when we're dealing with the m this dataset we had sixty thousand images

52
00:03:39,740 --> 00:03:42,280
and sixty thousand images is a ton of images.

53
00:03:42,320 --> 00:03:46,340
And that was for a very simple file type essentially a very simple image.

54
00:03:46,340 --> 00:03:48,080
It was only 28 by 28.

55
00:03:48,110 --> 00:03:56,500
Right now we have half of that size over our entire dataset our entire dataset is less than 30000 images.

56
00:03:56,540 --> 00:04:02,560
So we want to be able to do is to expand the amount of images without having to gather more data.

57
00:04:02,570 --> 00:04:05,530
We can't just keep grabbing blood cells from people.

58
00:04:05,570 --> 00:04:12,950
So what we can do instead is do things like take our current images and randomly rotate them so something

59
00:04:12,950 --> 00:04:19,580
we can do say rotation underscore range and set this equal to the amount of degrees that we can randomly

60
00:04:19,580 --> 00:04:26,090
rotate our images so we can do something like 20 degrees and for something like the blood cell which

61
00:04:26,090 --> 00:04:29,980
is circular in nature you can possibly choose a lot larger than 20 degrees.

62
00:04:30,100 --> 00:04:35,990
But here I'm just showing you examples the other things we can begin to edit are things like the width

63
00:04:36,890 --> 00:04:44,750
shift range and this will shift the actual width of the picture by some maximum percentage.

64
00:04:44,810 --> 00:04:52,070
So if we say zero point one that stands for randomly choose a value between 0 and 10 percent or 010

65
00:04:52,120 --> 00:04:56,810
zero point one to shift the width of the image and we can do the same thing for the height.

66
00:04:56,840 --> 00:05:03,780
We can randomly kind of stretch these out so we can say something like zero point one.

67
00:05:03,830 --> 00:05:09,080
Now you may be wondering what are good values to choose here for things like rotation and shifting.

68
00:05:09,080 --> 00:05:12,170
It all depends on the kind of images you're dealing with.

69
00:05:12,170 --> 00:05:15,790
We're very lucky in our case that we're dealing with what are essentially blobs.

70
00:05:15,890 --> 00:05:21,500
So we can expect that future images of red blood cells will kind of look like these blobs will be circular

71
00:05:21,560 --> 00:05:26,690
in nature and they can kind of be stretched or squished in feature images.

72
00:05:26,690 --> 00:05:34,160
So what we can do is pray choose a pretty larger values here for things like rotation with and shift.

73
00:05:34,160 --> 00:05:40,820
If you're dealing something like facial data you don't want to be squeezing or rotating faces so much

74
00:05:41,150 --> 00:05:43,220
that they're in unrealistic positions.

75
00:05:43,220 --> 00:05:48,980
For example let's imagine you're making software for a video camera that will be trying its best to

76
00:05:48,980 --> 00:05:52,400
detect whether or not the face of a person is in that image.

77
00:05:52,400 --> 00:05:57,230
You probably don't want to rotate something 180 degrees because it's not useful for the camera to be

78
00:05:57,230 --> 00:06:02,030
able to detect upside down faces unless someone is going to be walking upside down in that camera's

79
00:06:02,030 --> 00:06:02,740
view.

80
00:06:02,750 --> 00:06:09,260
So those kind of ideas can help you choose reasonable values for these random transformations.

81
00:06:09,270 --> 00:06:10,520
OK.

82
00:06:10,520 --> 00:06:16,910
The other thing we want to do is we want to reskill the image so we can reskill it by simply normalizing

83
00:06:16,910 --> 00:06:17,310
it.

84
00:06:17,420 --> 00:06:20,870
If we take a look at one of the sample images we have.

85
00:06:20,870 --> 00:06:23,220
So let's take a look at let's say parasail.

86
00:06:23,300 --> 00:06:25,120
So that was our image file there.

87
00:06:25,130 --> 00:06:27,930
Let's take a look at the image.

88
00:06:28,060 --> 00:06:32,770
Read of it and let's take a look at the max values here.

89
00:06:32,770 --> 00:06:37,750
So in our case they're actually already standard and normalized for us.

90
00:06:37,750 --> 00:06:44,230
But if they were not let's say they went from 0 to 255 then I'd have to reskill by saying one divided

91
00:06:44,230 --> 00:06:46,220
by two fifty five.

92
00:06:46,240 --> 00:06:49,840
In our case it looks like these images are already scaled for us.

93
00:06:49,990 --> 00:06:53,130
So we don't need to normalize anything by the scale factor.

94
00:06:53,170 --> 00:06:56,830
We can also check this on the uninfected cell that we had earlier.

95
00:06:56,950 --> 00:07:02,770
So the uninfected cell let's make sure that's actually I believe this already in array from before.

96
00:07:02,770 --> 00:07:04,370
So we already have the uninfected cell.

97
00:07:04,390 --> 00:07:05,730
Let's take a look at it.

98
00:07:05,860 --> 00:07:07,420
Check out its max value.

99
00:07:07,450 --> 00:07:09,140
It also looks to be normalized.

100
00:07:09,160 --> 00:07:13,720
So it looks like all the values fall between zero and something less than one which is exactly what

101
00:07:13,720 --> 00:07:14,960
we want in our case.

102
00:07:14,980 --> 00:07:17,300
So the reskill factor we don't need to worry about that.

103
00:07:17,380 --> 00:07:25,500
But if you did want to reskill you would do something like 1 over 255 OK so in our case where we normalized

104
00:07:25,510 --> 00:07:27,050
we didn't worry about that.

105
00:07:27,050 --> 00:07:30,080
We can also do things like have a sheer range.

106
00:07:30,080 --> 00:07:35,680
So sheer means cutting away part of the image and we can set that to maybe a maximum of 10 percent.

107
00:07:35,720 --> 00:07:37,000
We can also zoom in on the image.

108
00:07:37,010 --> 00:07:41,790
We have the option to randomly zoom in so we can say zoom range.

109
00:07:41,840 --> 00:07:43,310
Zero point one.

110
00:07:43,310 --> 00:07:45,530
We can also do horizontal and vertical flipping.

111
00:07:45,530 --> 00:07:50,030
So for example I can say horizontal flip is equal to true.

112
00:07:50,030 --> 00:07:55,310
So it will randomly allow for horizontal flipping and then I have to figure out Well how am I going

113
00:07:55,310 --> 00:07:56,720
to fill in the missing data.

114
00:07:57,500 --> 00:08:01,970
So one way of doing this is Phil mode of nearest.

115
00:08:01,970 --> 00:08:06,500
So what I mean by that is if you're doing a transformation that essentially stretches out the image

116
00:08:06,770 --> 00:08:08,530
how are you going to fill in that space.

117
00:08:08,570 --> 00:08:14,300
Are you going to leave it blank through some just padding of zeros or are you going to take the nearest

118
00:08:14,300 --> 00:08:17,750
pixel values to it and then stretch it out with those pixel values.

119
00:08:17,780 --> 00:08:19,350
I would recommend choosing nearest.

120
00:08:19,740 --> 00:08:20,610
OK.

121
00:08:20,870 --> 00:08:22,820
So we have this image data generator.

122
00:08:22,820 --> 00:08:27,320
And let's take a look at this uninfected cell again.

123
00:08:27,490 --> 00:08:38,680
So recall uninfected cell is this array so I can say Pulte image show and I have this uninfected cell.

124
00:08:38,740 --> 00:08:45,970
Let's see what happens if I take a look at randomly transforming this uninfected cell and it may not

125
00:08:45,970 --> 00:08:49,300
be so obvious here because there's no point in the center.

126
00:08:49,300 --> 00:08:53,190
So actually let's do this with the parrot image or the parasite cell.

127
00:08:53,550 --> 00:08:59,810
So we come back up here make sure we grab the right object so we'll say PDT M. Reed parasol.

128
00:09:00,040 --> 00:09:00,700
So scroll up.

129
00:09:00,700 --> 00:09:02,530
Let's choose one actually has this point.

130
00:09:02,740 --> 00:09:10,550
We'll make it a little easier to see the transformations so we're going to go ahead and say Keelty and

131
00:09:10,570 --> 00:09:12,280
show em read parasol.

132
00:09:12,640 --> 00:09:15,300
OK so I have this parasol in read.

133
00:09:16,270 --> 00:09:23,780
Let's go ahead and set that to just be para underscore image is equal to m read parasol.

134
00:09:23,810 --> 00:09:27,860
That way I can just simply display parasite image.

135
00:09:28,040 --> 00:09:30,690
So I run that is basically the same idea.

136
00:09:30,740 --> 00:09:34,050
So what I'm going to do it's take this poor image.

137
00:09:34,060 --> 00:09:37,990
That's my array and I'm going to say the following.

138
00:09:37,990 --> 00:09:43,960
Take my image generator object that I defined above and call a single random transformation.

139
00:09:43,990 --> 00:09:49,710
So essentially do a bunch of random transformations on it based off the restrictions that I set up here.

140
00:09:50,500 --> 00:09:54,340
So we already know this is what it normally looks like when we're actually feeding in the data to the

141
00:09:54,340 --> 00:09:54,880
model.

142
00:09:54,910 --> 00:09:57,080
We're not going to feed it this raw image.

143
00:09:57,100 --> 00:09:59,820
Instead it will randomly transform the image.

144
00:10:00,540 --> 00:10:05,910
So let's actually see the random transformation by St. peel team show.

145
00:10:06,010 --> 00:10:06,710
Run that.

146
00:10:06,990 --> 00:10:11,460
OK so here is now the randomize version of the image.

147
00:10:11,470 --> 00:10:13,090
Notice that we got some stretch.

148
00:10:13,090 --> 00:10:15,480
Kind of like columns sticking out of the cell.

149
00:10:15,700 --> 00:10:20,020
And that's because through this random transformation it looks like it got stretched out and it filled

150
00:10:20,020 --> 00:10:22,750
in those values with the nearest pixel value.

151
00:10:22,930 --> 00:10:29,260
And then note it was also rotated makes a lot of sense to randomly rotate images here because their

152
00:10:29,260 --> 00:10:32,320
cells that can be in any sort of rotational axis that they want.

153
00:10:32,320 --> 00:10:37,960
They can be floating around in their sample so depending again on the actual type of images you're looking

154
00:10:37,960 --> 00:10:46,320
at you're going to be playing around if these actual range values OK so now with the fact that we can

155
00:10:46,320 --> 00:10:51,600
randomly transform these images I can essentially augment my dataset.

156
00:10:51,780 --> 00:10:57,660
I'm no longer restricted to just this single image from the cell I can randomly transform this many

157
00:10:57,660 --> 00:10:58,320
times over.

158
00:10:58,320 --> 00:11:02,030
So if you keep running this you'll see more and more random transformations.

159
00:11:02,190 --> 00:11:06,360
And this is a way of artificially expanding your image dataset.

160
00:11:06,450 --> 00:11:11,970
Recall we had less than 30000 images but now I could do a random transformation on all those images

161
00:11:12,330 --> 00:11:14,790
and immediately double the size of my dataset.

162
00:11:14,970 --> 00:11:20,240
Maybe I could do five random transformations and I've gone from something like 20000 images to 100000

163
00:11:20,250 --> 00:11:20,790
images.

164
00:11:21,060 --> 00:11:26,940
So this is a really powerful tool that you have to keep in mind when you're dealing with kind of smaller

165
00:11:26,950 --> 00:11:31,950
datasets and when it comes to compositional neural networks it takes thousands thousands images to get

166
00:11:31,950 --> 00:11:33,800
something that performs really well.

167
00:11:33,810 --> 00:11:38,160
That's why the m this dataset and that so far 10 data set were actually very large.

168
00:11:38,160 --> 00:11:45,510
OK so how do we actually set up our directories to flow batches from a directory the way we do that

169
00:11:46,080 --> 00:11:59,060
is we say image underscore gem that flow from directory and then you provide the path to your training

170
00:11:59,060 --> 00:12:00,200
folder.

171
00:12:00,200 --> 00:12:08,430
So recall that this train path variable if we come up here was the file path to sell images train.

172
00:12:08,720 --> 00:12:12,670
So we'll say image can flow from directory train path.

173
00:12:12,920 --> 00:12:17,990
And when you run that you'll notice it says OK I found this many images belonging to two classes.

174
00:12:18,080 --> 00:12:19,580
How does it actually know that.

175
00:12:19,580 --> 00:12:25,100
Well it's because in order to use flow from directory your files have to actually be organized in a

176
00:12:25,100 --> 00:12:26,450
very specific way.

177
00:12:26,480 --> 00:12:30,500
And we've laid that out for you in the notebook that corresponds with this lecture working of custom

178
00:12:30,500 --> 00:12:31,400
images.

179
00:12:31,400 --> 00:12:38,860
If you scroll down basically you'll see everything we've been doing so far keep going down until you

180
00:12:38,860 --> 00:12:39,480
see this.

181
00:12:39,490 --> 00:12:44,960
So in order to use Flo from directory you must organize the images in sub directories.

182
00:12:45,010 --> 00:12:46,620
So this is an absolute requirement.

183
00:12:46,630 --> 00:12:48,280
Otherwise the method won't work.

184
00:12:48,280 --> 00:12:53,740
So when you're following along these instructions on your own data sets the directories have to be basically

185
00:12:53,740 --> 00:12:54,700
like this.

186
00:12:54,700 --> 00:12:57,240
You have to have your overall image data folder.

187
00:12:57,310 --> 00:13:02,590
So recall that was our cell images folder and then you need for every class here.

188
00:13:02,650 --> 00:13:07,540
So you have class 1 you'll go ahead and have an image.

189
00:13:07,630 --> 00:13:11,090
Another image in that image of representations of class 1.

190
00:13:11,350 --> 00:13:15,790
Then for class 2 you'll need another image in other image etc..

191
00:13:15,880 --> 00:13:21,760
So essentially what happens is if we take a look at our original training paths so we can come back

192
00:13:21,760 --> 00:13:24,030
to our notebook to play around with this.

193
00:13:24,070 --> 00:13:29,530
Recall that our training path is right here.

194
00:13:29,540 --> 00:13:32,750
Cell images train and inside of that.

195
00:13:32,750 --> 00:13:40,190
If I say OS list directories I have one folder per class.

196
00:13:40,190 --> 00:13:44,750
If we were dealing with a multi class classification problem for example let's say we were trying to

197
00:13:44,750 --> 00:13:49,460
distinguish between images of birds dogs and cats.

198
00:13:49,460 --> 00:13:53,780
Then I would need three folders here one for all the bird images one for all the dog images and then

199
00:13:53,780 --> 00:13:55,360
one for all a cat images.

200
00:13:55,370 --> 00:13:58,220
So you need a folder per class.

201
00:13:58,220 --> 00:14:04,100
That is how this flow from directory immediately understood that there was two classes because there's

202
00:14:04,100 --> 00:14:05,020
two folders here.

203
00:14:05,120 --> 00:14:07,310
There's the parasite folder and the uninfected folder.

204
00:14:07,850 --> 00:14:08,960
So that's how this works.

205
00:14:08,960 --> 00:14:14,950
It must be in this sort of format and you would then have one folder for your training data and then

206
00:14:14,950 --> 00:14:16,920
one folder for your test data.

207
00:14:16,940 --> 00:14:19,310
Okay so in other we understand that.

208
00:14:19,480 --> 00:14:24,910
Let's go ahead and see what it looks like for the image generation flow from the tests it would just

209
00:14:24,910 --> 00:14:29,960
say image Gen flow from directory.

210
00:14:29,990 --> 00:14:35,300
Check out the test path run that and you'll notice it found two thousand six hundred images belong to

211
00:14:35,300 --> 00:14:39,960
two classes which makes sense because it was thirteen hundred images per class.

212
00:14:40,070 --> 00:14:42,590
And again the test path has the exact same formatting.

213
00:14:42,740 --> 00:14:44,190
It has two folders beneath it.

214
00:14:44,300 --> 00:14:45,850
One for each class.

215
00:14:45,860 --> 00:14:53,690
Okay so that's it for this lecture on being able to generate images from this image data generator class

216
00:14:53,690 --> 00:14:54,480
object.

217
00:14:54,500 --> 00:14:59,340
This is a super useful class and it basically does all the heavy lifting for you.

218
00:14:59,360 --> 00:15:03,860
I would encourage you to spend time reading the online documentation for it to see what other options

219
00:15:03,860 --> 00:15:04,400
there are.

220
00:15:04,550 --> 00:15:09,350
But the main thing to note here and again a big part of this is understanding your file parts is making

221
00:15:09,350 --> 00:15:16,190
sure your data is organized into this particular format of one folder per class or then every class

222
00:15:16,190 --> 00:15:23,330
folder has many instances of that particular class so this would for example be all dogs all birds etc.

223
00:15:23,660 --> 00:15:25,560
for each of those animal classes.

224
00:15:25,850 --> 00:15:29,450
In our case we're just dealing with two classes coming up next.

225
00:15:29,450 --> 00:15:35,180
We will create a model and then after that we'll talk about evaluating the model's performance.

226
00:15:35,180 --> 00:15:36,740
Thanks and I'll see you at the next lecture.
