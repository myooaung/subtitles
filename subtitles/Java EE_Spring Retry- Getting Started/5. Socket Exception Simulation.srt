1
00:00:00,945 --> 00:00:03,091
Now that we've implemented custom policies,

2
00:00:03,091 --> 00:00:07,663
let's examine which of SaaS Bass's pain points are alleviated by retry.

3
00:00:07,663 --> 00:00:11,142
We'll start by simulating socket exceptions.

4
00:00:11,142 --> 00:00:16,816
In SaaS Bass's case, socket exceptions are caused by a temporary server overload.

5
00:00:16,816 --> 00:00:19,590
To follow along with this demo, for the Bass Tracker Service,

6
00:00:19,590 --> 00:00:24,379
check out the adding-custom-retry-policies-socket-exception branch.

7
00:00:24,379 --> 00:00:25,936
For the Lake Profile Service,

8
00:00:25,936 --> 00:00:31,156
also check out the adding-custom-retry-policies-socket-exception branch.

9
00:00:31,156 --> 00:00:33,456
Here in the Lake Profile Service's Endpoint class,

10
00:00:33,456 --> 00:00:38,111
we've simulated a temporary server overload by throwing a socket exception

11
00:00:38,111 --> 00:00:41,816
the first two times each POST and GET request are made.

12
00:00:41,816 --> 00:00:43,945
After the first two attempts,

13
00:00:43,945 --> 00:00:47,811
the GET and POST endpoints can proceed handling their requests.

14
00:00:47,811 --> 00:00:50,576
Let's run the lake-profile-service.

15
00:00:50,576 --> 00:00:54,095
Now, let's switch over to the bass-tracker-service.

16
00:00:54,095 --> 00:00:56,005
We haven't made any modifications for this simulation,

17
00:00:56,005 --> 00:00:59,658
so we should expect that the CommandLineRunner will attempt to

18
00:00:59,658 --> 00:01:02,225
create the Lake Profile in a separate thread,

19
00:01:02,225 --> 00:01:05,756
wait for 3 seconds, and then try to get the newly created profile.

20
00:01:05,756 --> 00:01:08,820
If either request fails, it should retry up to three times.

21
00:01:08,820 --> 00:01:11,136
Let's run it and see what happens.

22
00:01:11,136 --> 00:01:11,641
Sure enough,

23
00:01:11,641 --> 00:01:14,993
we see that each request is attempted three times and we are able

24
00:01:14,993 --> 00:01:18,356
to create and get the lake profile successfully.

25
00:01:18,356 --> 00:01:21,767
The interesting thing to note here is that we saved ourselves about

26
00:01:21,767 --> 00:01:26,438
6000 ms using an exponential back off policy compared to a fixed back

27
00:01:26,438 --> 00:01:29,561
off policy with a 1000 ms back off period.

28
00:01:29,561 --> 00:01:38,000
Six hundred milliseconds may not sound like much, but that's a significant time savings in the context of an API call stack.

