WEBVTT
1
1

00:00:00.210  -->  00:00:01.650
<v Instructor>So here is a short lecture</v>
2

2

00:00:01.650  -->  00:00:04.890
on KMS API calls limits, and data key caching.
3

3

00:00:04.890  -->  00:00:08.130
So when your application is making API calls to KMS,
4

4

00:00:08.130  -->  00:00:10.710
you have a service limit that you can hit.
5

5

00:00:10.710  -->  00:00:12.630
And KMS is an expensive service.
6

6

00:00:12.630  -->  00:00:15.030
So there's a number of requests per second limit
7

7

00:00:15.030  -->  00:00:18.420
and if you use KMS too much, you will be throttled.
8

8

00:00:18.420  -->  00:00:19.470
So how can you go around it?
9

9

00:00:19.470  -->  00:00:21.750
Well, number one, you can increase this service limit,
10

10

00:00:21.750  -->  00:00:25.020
of course, but number two, you can do data key caching
11

11

00:00:25.020  -->  00:00:27.810
and data key caching is to reuse the data keys
12

12

00:00:27.810  -->  00:00:31.230
that you've created out of KMS to protect your data.
13

13

00:00:31.230  -->  00:00:33.990
So instead of generating a new key every time,
14

14

00:00:33.990  -->  00:00:35.670
you are going to reuse the data key
15

15

00:00:35.670  -->  00:00:37.800
for encryption operations.
16

16

00:00:37.800  -->  00:00:40.110
So let's turn and understand a use case.
17

17

00:00:40.110  -->  00:00:43.110
So we have a user, we're using something that already
18

18

00:00:43.110  -->  00:00:45.960
has the data key catching mechanism implemented
19

19

00:00:45.960  -->  00:00:47.100
but we could write it ourselves.
20

20

00:00:47.100  -->  00:00:50.880
But the AWS encryption SDK has this for us.
21

21

00:00:50.880  -->  00:00:54.870
The user makes one API call into KMS to get a data key.
22

22

00:00:54.870  -->  00:00:57.570
So it's a generate data key API call
23

23

00:00:57.570  -->  00:00:59.100
and we're going to cache it.
24

24

00:00:59.100  -->  00:01:00.840
That means we're going to keep it for a while
25

25

00:01:00.840  -->  00:01:03.510
so we can encrypt several files with it.
26

26

00:01:03.510  -->  00:01:06.390
And then we can also use it to decrypt the files
27

27

00:01:06.390  -->  00:01:09.090
that were encrypted with the same data key.
28

28

00:01:09.090  -->  00:01:12.120
So instead of doing three or four API calls to KMS,
29

29

00:01:12.120  -->  00:01:13.650
we are doing one API call
30

30

00:01:13.650  -->  00:01:15.690
because we're reusing the data key.
31

31

00:01:15.690  -->  00:01:19.020
So the goal of this, of course, is to, for example,
32

32

00:01:19.020  -->  00:01:20.867
reduce latency because we don't do API calls
33

33

00:01:20.867  -->  00:01:22.530
to KMS all the time.
34

34

00:01:22.530  -->  00:01:24.870
We improve the throughput, we reduce the cost
35

35

00:01:24.870  -->  00:01:27.150
because we call KMS less and less
36

36

00:01:27.150  -->  00:01:29.400
and we stay within service limits.
37

37

00:01:29.400  -->  00:01:31.890
So this is implemented in some SDK,
38

38

00:01:31.890  -->  00:01:35.130
such as the AWS encryption SDK.
39

39

00:01:35.130  -->  00:01:39.420
But using this data key caching has a trade off, of course.
40

40

00:01:39.420  -->  00:01:42.188
It's discouraged to use it too much because, well,
41

41

00:01:42.188  -->  00:01:44.940
the whole principle behind encryption
42

42

00:01:44.940  -->  00:01:47.130
is the unicity of data keys.
43

43

00:01:47.130  -->  00:01:51.240
So this is definitely a trade off of cost versus security
44

44

00:01:51.240  -->  00:01:53.310
but an option you need to know about.
45

45

00:01:53.310  -->  00:01:54.270
All right, that's it.
46

46

00:01:54.270  -->  00:01:55.410
I hope you like this lecture
47

47

00:01:55.410  -->  00:01:57.483
and I will see you in the next lecture.
