1
00:00:05,240 --> 00:00:12,200
Hello everyone and welcome to the section on Skala and Sparke on AWOS EMR or Amazon Web Services elastic

2
00:00:12,200 --> 00:00:17,510
map readers in this section of the course we're going to be showing you how to set up Skala and Spahr

3
00:00:17,660 --> 00:00:23,680
to run on a cluster that you specify on Amazon Web Services elastic map reduce or AWOS EMR.

4
00:00:23,750 --> 00:00:27,980
We've already shown you data Brick's notebook system and now we're going to show you the Open Source

5
00:00:28,070 --> 00:00:30,850
zipline notebook system.

6
00:00:30,900 --> 00:00:36,300
Keep in mind that we're now going to be doing tasks that are beyond any free tier of service following

7
00:00:36,300 --> 00:00:41,890
along with this video is going to cost you money in Amazon Web Services is going to charge you what

8
00:00:41,900 --> 00:00:46,990
we show in this section of the course costs really only a few dollars per hour of runtime.

9
00:00:47,040 --> 00:00:50,240
So at most you should be paying $10 maximum.

10
00:00:50,490 --> 00:00:54,960
But if you forget to terminate your instance you're going to be continually charged so please keep that

11
00:00:54,960 --> 00:00:56,270
in mind.

12
00:00:56,460 --> 00:01:01,290
Only follow along if you feel comfortable spending some money on Amazon Web Services and you know you're

13
00:01:01,290 --> 00:01:06,300
going to remember to terminate your cluster if you feel uncomfortable with this or tend to be forgetful

14
00:01:06,450 --> 00:01:09,580
than just watched his lectures and don't follow along.

15
00:01:09,660 --> 00:01:15,270
So please keep in mind I'm not personally responsible for any costs you may incur when Amazon Web Services

16
00:01:15,300 --> 00:01:16,130
charges you.

17
00:01:16,260 --> 00:01:20,640
There's lots of horror stories online of people forgetting to turn off their cluster and leave it running

18
00:01:20,640 --> 00:01:21,330
for a month.

19
00:01:21,420 --> 00:01:25,380
And at the end of the month they get charged hundreds or thousands of dollars so really keep that in

20
00:01:25,380 --> 00:01:25,740
mind.

21
00:01:25,740 --> 00:01:30,660
It's really easy to forget things and have those charges stack up.

22
00:01:30,730 --> 00:01:33,830
Now with that being said let's go ahead and get started.

23
00:01:33,850 --> 00:01:37,660
Go to AWOS thought Amazon Dot Com and set up an account there.

24
00:01:37,720 --> 00:01:41,830
You're going to need to provide some sort of debit card or credit card for billing information.

25
00:01:41,830 --> 00:01:45,080
But other than that should be a pretty straightforward set up process.

26
00:01:45,160 --> 00:01:49,870
And then once you set up that account go ahead and log into the main W-S con..

27
00:01:49,960 --> 00:01:51,940
You can also check out zipline patch.

28
00:01:51,940 --> 00:01:57,130
The word we're going to be talking that zipline open documentation for just a little bit before we actually

29
00:01:57,160 --> 00:01:57,850
get started.

30
00:01:57,880 --> 00:01:58,910
Cluster.

31
00:01:58,930 --> 00:01:59,520
All right.

32
00:01:59,530 --> 00:02:03,910
Want to jump to my browser have those two links open and explore them a little more with you.

33
00:02:03,910 --> 00:02:07,900
All right so here I am at my browser I've logged into my AWOS console.

34
00:02:07,930 --> 00:02:12,340
I have my services ready to go and I also have another tab open.

35
00:02:12,370 --> 00:02:17,620
Zipline Apache the org which is the official documentation page or official Web site for the Apache

36
00:02:17,620 --> 00:02:19,630
zipline open source project.

37
00:02:19,630 --> 00:02:24,160
Now before we get started actually creating a cluster I want to just give you a quick tour of zipline

38
00:02:24,160 --> 00:02:28,750
not a patch or scribe just a little more detail what Apache's applet is.

39
00:02:28,750 --> 00:02:32,380
It's basically just the web based notebook that enables interactive data analytics.

40
00:02:32,380 --> 00:02:37,690
You can almost think of it as an open source version of data Briggs's notebook now data Brick's does

41
00:02:37,690 --> 00:02:43,030
offer a lot of convenience things such as uploading other tables or setting up clusters or just couple

42
00:02:43,030 --> 00:02:48,700
of clicks but you get an additional charge for that convenience so keep in mind you can think of Zeppelin

43
00:02:48,700 --> 00:02:53,080
as just an alternative option where you're trading off a little bit of convenience for the fact that

44
00:02:53,470 --> 00:02:56,840
it's free on top of AWOS you start to pay for AWOS.

45
00:02:56,860 --> 00:02:59,950
But zipline is open source.

46
00:02:59,990 --> 00:03:04,390
It's also a multipurpose notebook so it supports multiple language beckons.

47
00:03:04,400 --> 00:03:10,600
Not just the Patchi spark of Skala but it supports things such as Cassandra our post-career sequel Hadoop

48
00:03:10,950 --> 00:03:12,170
DFS cetera.

49
00:03:12,200 --> 00:03:16,130
You can check out more information here as Epling that a patch that org.

50
00:03:16,130 --> 00:03:20,630
There are other types of notebooks if you're familiar of other programming languages you can think of

51
00:03:20,630 --> 00:03:23,500
this as almost like a Jupiter notebook type interface.

52
00:03:23,510 --> 00:03:29,450
But keep in mind that Apache Zeppelin in particular was really designed for big data type notebooks

53
00:03:29,450 --> 00:03:33,620
and it was especially designed for Apache spark integration.

54
00:03:33,620 --> 00:03:36,660
So you don't need to build a separate module plug into a library for it.

55
00:03:36,750 --> 00:03:41,990
Apache's Zeppelin of SPARC integration provides a lot of those dependencies already loaded up for you

56
00:03:42,950 --> 00:03:46,520
and it also has the capability to do some sort of basic chart visualization.

57
00:03:46,880 --> 00:03:52,250
So you can explore this documentation page a little more has a nice community link you can just click

58
00:03:52,250 --> 00:03:56,080
here on docs and you'll notice that currently at the filming of this video the current release.

59
00:03:56,120 --> 00:04:01,460
Is there a point six point to Amazon Web Services does a really good job of keeping up with the latest

60
00:04:01,460 --> 00:04:08,150
releases of not just pacis Zetlin but also Skala and Spark's usually have no problems getting the latest

61
00:04:08,150 --> 00:04:10,520
releases to Amazon Web Services.

62
00:04:10,670 --> 00:04:14,360
You won't usually get the development just because there may be bugs in that.

63
00:04:14,510 --> 00:04:20,540
But as far as the latest release in our case 0.6 point 6.2 that will be available to you on Amazon Web

64
00:04:20,540 --> 00:04:23,640
Services so you can click here go to the quick star.

65
00:04:23,680 --> 00:04:28,130
It'll tell you how to install stuff exploring the UI gives you a little tutorial basic feature guides

66
00:04:28,140 --> 00:04:31,750
etc. but right now let's go back to our AWOS cons..

67
00:04:31,760 --> 00:04:37,060
You can explore the rest of this documentation on your own and actually set up a cluster OK.

68
00:04:37,080 --> 00:04:39,800
So coming back to this AWOS Amazon Dot com.

69
00:04:40,060 --> 00:04:42,380
Well we want to do is actually find EMR.

70
00:04:42,420 --> 00:04:50,010
Now if you want there's usually a search box here we can just type in EMR and find the Minnich framework

71
00:04:50,010 --> 00:04:53,760
or classic map reading service if for some reason the UI has changed.

72
00:04:53,760 --> 00:04:57,720
You can usually just click here on this icon and it will take you there excuse me.

73
00:04:57,720 --> 00:05:00,480
Click here on services and you can search services here.

74
00:05:00,490 --> 00:05:06,210
Then again it should be under analytics EMR or you can just type in EMR and it should show up.

75
00:05:06,240 --> 00:05:09,960
So just find the lasting map read his page and you'll see something that looks like this.

76
00:05:09,960 --> 00:05:12,920
Let me zoom out a little bit so we can see the whole picture.

77
00:05:12,990 --> 00:05:19,290
And basically this is Amazon's elastic map reduce and it's a web service that allows you to create clusters

78
00:05:19,350 --> 00:05:20,410
very easily.

79
00:05:20,640 --> 00:05:26,000
So click here and create cluster and we will have some quick options.

80
00:05:26,290 --> 00:05:30,540
Now in the past used to have to go to advance options to make sure everything was set up properly.

81
00:05:30,640 --> 00:05:37,720
But actually a classic map reduce Amazon Web Services has a really good job of including Sparc and zipline

82
00:05:37,870 --> 00:05:39,730
as some sort of base configuration.

83
00:05:40,000 --> 00:05:43,660
So call your cluster whatever you want to call it my cluster.

84
00:05:43,810 --> 00:05:45,900
You can turn logging off if you want.

85
00:05:45,910 --> 00:05:51,820
It's basically just going to copy the cluster's log files automatically to some S-3 which is just Amazon

86
00:05:51,820 --> 00:05:53,260
Web Services storage.

87
00:05:53,260 --> 00:05:58,480
When it turned that off we're not going to be necessary and we're going to go to launch mode have clustered

88
00:05:58,480 --> 00:06:00,870
there and then software configuration.

89
00:06:00,880 --> 00:06:06,490
We're going to choose Amazon as our vendor have this latest release that's fine whatever the default

90
00:06:06,490 --> 00:06:12,760
he is here that should be fine and if we come down we should see Sparke on Hadoop with Zeppelin here.

91
00:06:12,790 --> 00:06:18,160
And you'll notice that it's actually the latest version SPARC 2.0 point two ends up Blin 0.6 point two

92
00:06:18,160 --> 00:06:19,210
which is nice.

93
00:06:19,240 --> 00:06:24,730
Now for some reason you don't see anything here with SPARC and zipline you can always come here to go

94
00:06:24,730 --> 00:06:26,370
to advanced options.

95
00:06:26,710 --> 00:06:33,430
And if you go here then you can actually click on Hadoop pig hide et cetera and you should see options

96
00:06:33,430 --> 00:06:36,950
here to then click on things such as zipline and Sparke.

97
00:06:36,950 --> 00:06:42,340
Now I'm going to go back to quick options more likely than not under quick options you should see something

98
00:06:42,340 --> 00:06:46,310
pre-configured has Sparc and zipline ready to go for you.

99
00:06:46,330 --> 00:06:50,860
So that's what we'll be choosing and I'm going to turn logging back off since I came back too quick.

100
00:06:50,860 --> 00:06:52,770
So I'm calling it my cluster logging is off.

101
00:06:52,780 --> 00:06:57,670
Have that looked at cluster vendors Amazon and their other applications and their quick options just

102
00:06:57,670 --> 00:07:03,640
using this one to spark Hadoop and Zetland that they have my hardware configuration and basically here

103
00:07:03,880 --> 00:07:08,110
this is where are you going to manually choose how big you want your cluster to be.

104
00:07:08,110 --> 00:07:13,920
So I'm going to choose just the default which is M3 x large with number of instances equal to 3.

105
00:07:14,020 --> 00:07:17,890
And basically that's going to be what is your master node and how many core nodes do you have on top

106
00:07:17,890 --> 00:07:20,830
of that the Pentagon what instance you use.

107
00:07:20,830 --> 00:07:22,870
You're going to be charged more or less.

108
00:07:22,900 --> 00:07:23,780
So keep that in mind.

109
00:07:23,800 --> 00:07:28,380
There's also different generation so there's the previous generation and the current gen generation.

110
00:07:28,390 --> 00:07:33,450
But right now we're going to just use the default N3 that x large number of instances just to be in

111
00:07:33,450 --> 00:07:35,170
one master in two core nodes.

112
00:07:35,380 --> 00:07:39,600
Obviously if you go a larger or more expensive hardware you're going to be charged more than you're

113
00:07:39,610 --> 00:07:42,110
charged per instance hour.

114
00:07:42,130 --> 00:07:47,770
So that means if you choose a more expensive instance every hour you going to get charged more.

115
00:07:47,900 --> 00:07:48,200
All right.

116
00:07:48,230 --> 00:07:55,550
Now security and access you're going to need to log in to this Amazon Web Services EMR by using what's

117
00:07:55,550 --> 00:08:03,200
known as an easy to keep hair this easy to keep perience going to make sure that you're able to actually

118
00:08:03,230 --> 00:08:06,470
log on and connect to your cluster through your command prompt.

119
00:08:06,470 --> 00:08:11,090
Now if you've never created an ISA to keep there you can click here and learn how to create an easy

120
00:08:11,090 --> 00:08:16,280
to keep here and you just come over here follow these instructions to actually create an easy to keep

121
00:08:16,280 --> 00:08:16,790
here.

122
00:08:16,820 --> 00:08:17,870
It's pretty straightforward.

123
00:08:17,870 --> 00:08:20,300
Just come here to the Amazon easy to con..

124
00:08:20,300 --> 00:08:26,870
Go to click keep peers create a key pair click create and save the resulting file in a safe location

125
00:08:27,560 --> 00:08:31,160
and then you're going to need to modify your pen file.

126
00:08:31,160 --> 00:08:36,190
If you are on a Windows or Mac so there's instructions here on how to do this on Windows.

127
00:08:36,320 --> 00:08:40,980
And if you click here on this tab there's instructions on how to do it on a Mac since you may or may

128
00:08:40,980 --> 00:08:42,200
not have done this before.

129
00:08:42,210 --> 00:08:46,830
I'm going to briefly create a new key pair that you can actually see how this works.

130
00:08:46,830 --> 00:08:54,150
I'm going to open my Amazon easy to con. In a new window and click on key pairs in the navigation pane.

131
00:08:54,150 --> 00:09:01,640
So if I come here to my console I'm going to see Pierce here I've already created some but let's just

132
00:09:01,640 --> 00:09:08,620
make another one point click here on create key pair and type in your create keep your name.

133
00:09:08,630 --> 00:09:16,060
So for instance we'll call this my sparkie click on Create.

134
00:09:16,310 --> 00:09:18,210
Once you created that new key pair.

135
00:09:18,230 --> 00:09:21,870
It should automatically have downloaded that PMS file.

136
00:09:21,890 --> 00:09:24,710
It's really important that you remember where this PTM file is.

137
00:09:24,710 --> 00:09:27,900
You basically don't get another chance to download another one.

138
00:09:28,100 --> 00:09:33,080
So make sure you know the location of this PTM file you just created and downloaded.

139
00:09:33,080 --> 00:09:38,720
All right so once you have that file make sure you save it to a location that you remember I back here

140
00:09:39,260 --> 00:09:45,530
to our set up keep there once you have that pgm or pen file in a safe location you're probably going

141
00:09:45,530 --> 00:09:52,390
to need to modify your pen file in order to S-sh or securely connect to your cluster.

142
00:09:52,400 --> 00:09:57,590
Now modifying this pen files a little different depending on whether you're on a Mac or Linux or Windows

143
00:09:57,590 --> 00:09:58,300
computer.

144
00:09:58,460 --> 00:10:03,290
Amazon Web Services actually has really nice instructions for either version but basically if you're

145
00:10:03,290 --> 00:10:08,210
on a Mac or Linux you're just going to open up your terminal and type this command you're going to say

146
00:10:08,230 --> 00:10:16,060
S.H. maade space O.G. dash RW x and then Mikee pair that PM or whatever you're called your key pair.

147
00:10:16,070 --> 00:10:22,540
Now remember you have to be at the same directory directory location where you saved your PMS file.

148
00:10:22,550 --> 00:10:25,710
Now if you're on Windows it's going to be a little more involved.

149
00:10:25,760 --> 00:10:28,670
You have to download Agent X to your computer.

150
00:10:28,670 --> 00:10:30,590
There's a link right here to download it.

151
00:10:30,590 --> 00:10:33,540
You're going to launch the gen click load.

152
00:10:33,620 --> 00:10:39,200
Select the PM file you created earlier click open then click OK on the page and notice telling you your

153
00:10:39,200 --> 00:10:44,030
key has successfully imported enter a passphrase in the key passphrase field.

154
00:10:44,120 --> 00:10:52,840
Click Save private key save it in a PPK format the format Windows needs for S-sh into a cluster and

155
00:10:52,850 --> 00:10:58,610
then you're going to name your petty private key such as my key pair that PPK click save and then exit

156
00:10:58,610 --> 00:11:00,170
the PATTI-JANE application.

157
00:11:00,380 --> 00:11:04,160
OK so go ahead and do that whether you're on a Windows or Mac.

158
00:11:04,160 --> 00:11:06,190
Take care of this M-file.

159
00:11:06,330 --> 00:11:07,030
I'm on Windows.

160
00:11:07,040 --> 00:11:09,350
I'll be using this putty generate now.

161
00:11:09,440 --> 00:11:14,230
Windows is a little more involved but again Amazon Web Services is really good documentation on this.

162
00:11:14,240 --> 00:11:19,070
If you ever get stuck you can either just look at the steps it's pretty straightforward or just google

163
00:11:19,070 --> 00:11:22,790
search AWOS S-sh easy to keep there.

164
00:11:22,810 --> 00:11:24,030
Or something similar.

165
00:11:24,110 --> 00:11:28,980
And Amazon EMR has a whole management guide on how to do this step by step.

166
00:11:29,090 --> 00:11:30,840
So I'm going to close this.

167
00:11:30,920 --> 00:11:32,470
Again the instructions are always here for you.

168
00:11:32,480 --> 00:11:34,980
Just learn how to create an easy to keep there.

169
00:11:35,210 --> 00:11:40,380
I'm going to choose the one easy to keep.

170
00:11:40,390 --> 00:11:47,960
I just made which was my spark key and then I'm going to come down here and click on Create cluster

171
00:11:50,320 --> 00:11:52,720
and that's going to be creating your cluster right now.

172
00:11:52,720 --> 00:11:56,690
Now it usually takes a couple of minutes to actually fully create the cluster.

173
00:11:56,740 --> 00:12:01,690
So you may need to just wait a little while it's going to say starting for a little bit but it's actually

174
00:12:01,690 --> 00:12:07,410
creating a cluster right now and it has the my spare key for security and access.

175
00:12:07,790 --> 00:12:12,670
OK while you're waiting for your cluster to actually initialize what you want to do is make sure that

176
00:12:12,670 --> 00:12:16,910
you're going to be able to s s h into your Zeppelin notebook.

177
00:12:17,100 --> 00:12:21,910
And for that you may need to change the security settings so what are you going to do under security

178
00:12:21,910 --> 00:12:23,010
and access.

179
00:12:23,020 --> 00:12:30,790
Come here and click on security groups for Master that we'll take you to this de-link on security groups.

180
00:12:30,790 --> 00:12:31,120
All right.

181
00:12:31,120 --> 00:12:37,550
Once you're on this security group page where you're going to do is select the map reduce M..

182
00:12:37,660 --> 00:12:41,320
Click here and you should see the security groups.

183
00:12:41,320 --> 00:12:45,560
And if you click on inbound tab where you want to do is click here on edit.

184
00:12:45,580 --> 00:12:52,550
Now we're going to open up some ports here so click on edit and then click here where it says add rule

185
00:12:53,090 --> 00:12:55,440
and you'll get a new little rule pop up.

186
00:12:55,470 --> 00:13:05,090
And we want to select SS h and then make sure that the port is 22 and over here on Kustom we can either

187
00:13:05,090 --> 00:13:07,760
select any where or my IP.

188
00:13:07,760 --> 00:13:13,520
Now if you select my IP that means you can only connect to this cluster from your actual IP address

189
00:13:13,520 --> 00:13:14,540
location.

190
00:13:14,540 --> 00:13:16,910
That's probably the most secure way of going about this.

191
00:13:16,940 --> 00:13:18,230
You want to click anywhere.

192
00:13:18,350 --> 00:13:23,990
That means anyone will be able to connect to this cluster which could be dangerous for the most secure

193
00:13:23,990 --> 00:13:24,230
thing.

194
00:13:24,230 --> 00:13:32,210
Just click on my IP and then we want to do is open up one more rule so say add rule and then have this

195
00:13:32,210 --> 00:13:34,610
be a custom TCAP rule.

196
00:13:34,610 --> 00:13:42,230
And then what I want to do is open up the poor 8 8 9 0 and I get I'm just going to say my IP.

197
00:13:42,410 --> 00:13:48,320
So if those two things selected click save.

198
00:13:48,340 --> 00:13:53,530
All right so now that we have our security groups for it to go or we needed to just wait for the actual

199
00:13:53,530 --> 00:13:55,420
cluster to start.

200
00:13:55,630 --> 00:14:01,200
So come back here to the AWOS cluster in probably still waiting right now may take a couple of minutes.

201
00:14:01,210 --> 00:14:03,800
But basically we have everything set up.

202
00:14:04,240 --> 00:14:04,560
OK.

203
00:14:04,560 --> 00:14:08,810
Coming back to the Amazon AWOS counsel for your cluster.

204
00:14:08,860 --> 00:14:13,120
Once you see the masters running and the Corps is running you should see something like waiting here

205
00:14:13,330 --> 00:14:17,560
and that means your cluster is waiting for you to actually do something with it which is good to know

206
00:14:18,280 --> 00:14:24,820
what we can do here is you have basically two options depending on how strict you want your security

207
00:14:24,820 --> 00:14:26,150
settings to be.

208
00:14:26,200 --> 00:14:27,720
You could S-sh.

209
00:14:27,760 --> 00:14:34,420
And that has to do all the stuff I was talking about earlier using that dot PM A Your key or yours PPK

210
00:14:34,420 --> 00:14:38,240
if you're on Windows and setting up the actual S-sh connection.

211
00:14:38,380 --> 00:14:43,330
But if you did the security settings that I showed you here you can actually access your zipline notebook

212
00:14:43,360 --> 00:14:46,880
directly through this public your Airlink.

213
00:14:46,880 --> 00:14:51,130
Now keep in mind this is a pretty open way of accessing a cluster.

214
00:14:51,140 --> 00:14:56,090
So this may not be the right setting for you or your organization that pending on how important security

215
00:14:56,090 --> 00:14:57,030
is for you.

216
00:14:57,050 --> 00:15:04,400
But I can just copy and paste this public DNS into my browser and then write Colan 8 8 9 0 remember

217
00:15:04,400 --> 00:15:09,190
that was the port we left open for Zeppelin enter and you should see something that looks like this

218
00:15:09,210 --> 00:15:11,000
the Zeppelin notebook page.

219
00:15:11,000 --> 00:15:15,350
And now you're ready to actually create your own notebooks and run whatever you want on your cluster

220
00:15:15,440 --> 00:15:17,330
on a W-S.

221
00:15:17,540 --> 00:15:19,870
You can hear it create a new notes.

222
00:15:19,910 --> 00:15:23,700
We'll call this my first notebook.

223
00:15:23,810 --> 00:15:28,870
It entered create notes and in here we can actually type in Scurlock code.

224
00:15:28,870 --> 00:15:35,190
So for instance I can say print's Ellen and I will say something like Hello world.

225
00:15:35,200 --> 00:15:39,000
Now if it's your very first note book you can do shift and try to run the cell.

226
00:15:39,280 --> 00:15:41,680
And it may take a little while to actually run.

227
00:15:41,680 --> 00:15:44,410
Here it took one second for me.

228
00:15:44,650 --> 00:15:49,690
If you're just running this note book for the very first time it's probably going to take about 30 seconds

229
00:15:49,690 --> 00:15:53,710
to a minute just to connect your cluster and load up Skala.

230
00:15:53,950 --> 00:15:57,470
But after that every other cell should take very little time.

231
00:15:57,480 --> 00:15:59,220
The Peniel what Operation doing.

232
00:15:59,350 --> 00:16:03,640
Your very first cell even if it's a simple command will probably take around 30 seconds to actually

233
00:16:03,640 --> 00:16:04,080
run.

234
00:16:04,300 --> 00:16:06,510
But I already ran a note book on this previously.

235
00:16:06,550 --> 00:16:07,800
So I'm ready to go.

236
00:16:08,110 --> 00:16:14,490
And now I'm going to just show you an example of how you would maybe access and S3 bucket.

237
00:16:14,500 --> 00:16:14,820
All right.

238
00:16:14,830 --> 00:16:19,720
So let me just walk through the generic settings you would probably use to connect your clusters to

239
00:16:19,720 --> 00:16:27,030
some data you were hosting on Amazon Web Services S3 storage you would just say something like Sparc

240
00:16:27,420 --> 00:16:37,430
or Apache that spark the sequel spark session then you would create your values spark just as we've

241
00:16:37,430 --> 00:16:38,500
done before.

242
00:16:38,750 --> 00:16:49,440
Sparks session it we can say builder or creates and then offer this Sparke session that we're running

243
00:16:49,440 --> 00:16:53,260
right now you would actually read in from your S-3 data.

244
00:16:53,280 --> 00:16:59,120
So for example let's say you have a publicly available bucket Well that makes things pretty easy you

245
00:16:59,120 --> 00:17:07,160
would just say something like that all for your data frame is equal to spark read maybe you set up a

246
00:17:07,160 --> 00:17:08,860
couple of options et cetera.

247
00:17:09,140 --> 00:17:17,600
But at the end for instance working for CSP file you would just type in your path here S-3 your bucket.

248
00:17:17,600 --> 00:17:21,240
You know your file CXXVI etc..

249
00:17:21,350 --> 00:17:26,970
Now if you're using something that's privately hosted and you need a key access to it it would look

250
00:17:26,970 --> 00:17:28,750
something more like this.

251
00:17:28,800 --> 00:17:38,190
You would still start off with S-3 but you may need to do S-3 and colon slash slash and then your access

252
00:17:38,190 --> 00:17:49,890
key colon and then your secret key atts and then you type in your bucket and whatever your file was

253
00:17:49,900 --> 00:17:52,220
or you have to your files CSP.

254
00:17:52,450 --> 00:17:56,500
And then once you're able to read that you'd have your data frame loaded to your cluster.

255
00:17:56,500 --> 00:18:01,840
Now keep in mind every and a have to match up to your limitations so if your cluster is too small to

256
00:18:01,840 --> 00:18:07,270
hold in your data it's not going to work and you're going to be charged depending on how big your data

257
00:18:07,270 --> 00:18:09,850
is or how big your cluster is so keep that in mind.

258
00:18:10,060 --> 00:18:12,730
If money is an issue for you you really want to keep a handle on that.

259
00:18:12,760 --> 00:18:15,790
Otherwise your prices will skyrocket.

260
00:18:15,790 --> 00:18:17,910
Now if you're looking for a more concrete example.

261
00:18:18,010 --> 00:18:19,780
Zipline actually comes with one.

262
00:18:20,050 --> 00:18:26,760
You can click here and go to Leppla tutorial and it actually has an example of reading in from S-3 you

263
00:18:26,760 --> 00:18:31,080
are l not for you or I'll link you have to do a little bit of a different aspect to it.

264
00:18:31,100 --> 00:18:35,960
But you have to call in New York L because you can't read it as a fill is just a direct three bucket

265
00:18:35,960 --> 00:18:36,530
link.

266
00:18:36,590 --> 00:18:40,230
But basically here they have loaded data into a table and you can check this out.

267
00:18:40,370 --> 00:18:42,270
If you're looking for another example.

268
00:18:42,270 --> 00:18:47,010
Now this uses the R D D techniques for actually reading in the data.

269
00:18:47,020 --> 00:18:51,360
But it's essentially the same thing as far as connecting a cluster to S3.

270
00:18:51,380 --> 00:18:55,140
And here they actually show you examples of how to use the visualizations as well.

271
00:18:55,400 --> 00:18:56,630
All right.

272
00:18:56,630 --> 00:19:01,580
So that's basically it as far as the basics of using the zipline notebook on your own cluster.

273
00:19:01,580 --> 00:19:06,410
And as I mentioned many times already but keep in mind you will be charged for every hour that this

274
00:19:06,410 --> 00:19:07,480
notebook is running.

275
00:19:07,670 --> 00:19:12,660
So the most important step out of everything is to remember how to actually terminate your cluster.

276
00:19:12,680 --> 00:19:17,540
So you just go back to your AWOS consul and click here on terminate.

277
00:19:17,540 --> 00:19:20,680
It's going to ask you Are you sure you want to terminate this cluster.

278
00:19:20,840 --> 00:19:24,150
All the data stored on this cluster is going to be lost.

279
00:19:24,190 --> 00:19:26,140
You can go ahead and click terminate.

280
00:19:26,140 --> 00:19:29,530
And now it's going to be terminated and you're not going to be charged for it anymore so.

281
00:19:29,620 --> 00:19:30,970
Remember to do that.

282
00:19:31,090 --> 00:19:35,590
And if you want to verify that it's being terminated you can visit that your Allegan and make sure nothing

283
00:19:35,590 --> 00:19:36,670
pops up.

284
00:19:36,670 --> 00:19:37,450
All right.

285
00:19:37,450 --> 00:19:38,890
Hope you enjoyed the lecture.

286
00:19:38,890 --> 00:19:43,060
Basically you have all the tools you need to analyze big data.

287
00:19:43,060 --> 00:19:48,280
You can check out Amazon Web Services public data sets if you're interested in uploading and analyzing

288
00:19:48,280 --> 00:19:49,780
very large data sets.

289
00:19:49,910 --> 00:19:52,110
Remember the larger it gets the more you have to pay.

290
00:19:52,120 --> 00:19:53,580
So keep that in mind.

291
00:19:53,590 --> 00:19:56,570
All right thanks everyone and I'll see you at the next lecture.
