1
00:00:05,000 --> 00:00:08,290
Hello everyone and welcome to the solutions lecture for the project.

2
00:00:08,300 --> 00:00:13,940
Exercise for the classification for machine learning of Sparke section of the course.

3
00:00:14,000 --> 00:00:17,330
Let's jump straight to the project exercise to get started.

4
00:00:17,330 --> 00:00:17,590
All right.

5
00:00:17,600 --> 00:00:21,060
Here I am at the project Skala scripts.

6
00:00:21,230 --> 00:00:23,080
Let's scroll down and get started.

7
00:00:23,090 --> 00:00:25,680
I want to complete the comment to tasks below.

8
00:00:25,950 --> 00:00:27,800
Just scroll to left a little more.

9
00:00:27,830 --> 00:00:32,920
First thing we need to do is import a spark session and logistic regression.

10
00:00:32,930 --> 00:00:33,980
Let's start off of that.

11
00:00:34,070 --> 00:00:39,470
Hopefully by now you're beginning to memorize some of these common import commands so you'll say import

12
00:00:39,470 --> 00:00:43,560
or that Apache that spark M-L classification.

13
00:00:45,170 --> 00:00:47,520
Logistic Regression.

14
00:00:47,690 --> 00:00:56,720
And then I want to say import or Apache that sparked that sequel spark session then optional.

15
00:00:56,740 --> 00:01:01,890
We can use the following code that will be available to you but Scheck's just from the solutions.

16
00:01:01,960 --> 00:01:08,020
If you want to have this error reporting totally optional up to you next you want to create a spark

17
00:01:08,020 --> 00:01:17,610
session will save Val spark is equal to spark session and then we want to say builder and then get or

18
00:01:17,650 --> 00:01:19,400
create.

19
00:01:20,020 --> 00:01:25,290
Then you want to use Sparke to read in the advertising see file so this advertising see as we file if

20
00:01:25,300 --> 00:01:28,780
you open it should look something like this to see if we file.

21
00:01:28,780 --> 00:01:31,870
So let's use Sparke don't read that option.

22
00:01:31,870 --> 00:01:39,880
It will save Velle data is equal to spark read option and you notice that when I look at the CC file

23
00:01:39,880 --> 00:01:41,150
it has a header to it.

24
00:01:41,320 --> 00:01:51,350
So I will say header true as one of my options and then as another option I'm also going to ask to infer

25
00:01:51,350 --> 00:01:55,290
the schema since I have mixed data types in my CSP file.

26
00:01:55,310 --> 00:02:00,400
I will say for schema to be true.

27
00:02:01,250 --> 00:02:11,300
And then I want to save formats is CSFB and then I want to say load and passen advertising C is free.

28
00:02:11,400 --> 00:02:19,060
This should actually be lower case a then I want to print the scheme of the data frame so will say data.

29
00:02:19,710 --> 00:02:27,920
Print schema is often H me save this and run it just to make sure everything's working so far.

30
00:02:27,940 --> 00:02:37,870
I've already started a spark cell so will say load and then log Reg project Skala and hit enter OK.

31
00:02:37,870 --> 00:02:39,950
Perfec we have the schema printed out.

32
00:02:39,990 --> 00:02:41,620
I can expand that to explore it.

33
00:02:41,820 --> 00:02:43,660
We have the daily time spent on that site.

34
00:02:43,680 --> 00:02:48,360
The age area income daily Internet usage ad topic city male country.

35
00:02:48,380 --> 00:02:52,990
A time stamp call on which will work with later and then clicked on ADD yes or no.

36
00:02:53,820 --> 00:02:56,210
Next we want to actually display that data.

37
00:02:56,250 --> 00:02:57,440
Lots of ways to do this.

38
00:02:57,450 --> 00:03:04,520
You can use a for loop as shown on the solutions or really easy ways to say they are ahead hit enter

39
00:03:04,700 --> 00:03:09,140
and you will get printed out a row of the data frame.

40
00:03:09,140 --> 00:03:12,800
Now keep in mind if you're putting this all into an object you won't be able to play around of stuff

41
00:03:13,100 --> 00:03:14,390
as we do here in Sparke shell.

42
00:03:14,420 --> 00:03:17,470
Which is why we don't use the object notation yet.

43
00:03:17,570 --> 00:03:20,410
Then we want to set up the data frame for machine learning.

44
00:03:20,450 --> 00:03:22,500
There's a couple of things we need to do here.

45
00:03:22,610 --> 00:03:25,840
We need to rename the clicked on add column to label.

46
00:03:25,910 --> 00:03:27,530
We want to ground the following columns.

47
00:03:27,560 --> 00:03:33,230
Are listed here for us and then we want to create a new column called Our from the time stamp containing

48
00:03:33,230 --> 00:03:38,660
the hour of the click and to keep in mind that we don't actually need to do all of this in this exact

49
00:03:38,720 --> 00:03:39,620
order.

50
00:03:39,620 --> 00:03:43,300
You just need to come out with the same result at the end.

51
00:03:43,310 --> 00:03:44,860
Let me show you what I mean by that.

52
00:03:45,050 --> 00:03:48,400
By starting off creating this our column.

53
00:03:48,410 --> 00:03:50,880
So create a new column called our.

54
00:03:50,880 --> 00:04:00,980
I'll say all time data is equal to data with column and hopefully a member from the previous lectures

55
00:04:00,980 --> 00:04:02,950
and spark data frame dates and time stamps.

56
00:04:02,960 --> 00:04:07,700
You can just say our and then passen the column itself.

57
00:04:07,700 --> 00:04:09,410
In this case it's called time stamp.

58
00:04:09,410 --> 00:04:10,070
Capital-T

59
00:04:13,650 --> 00:04:16,710
and then off of that I'm going to say Velle log.

60
00:04:16,740 --> 00:04:29,900
Reg data is equal to this time data and I want to select the clicked on ADD clicked on add a column

61
00:04:31,570 --> 00:04:38,170
as label and the next the other things I want to selects are all the columns.

62
00:04:38,190 --> 00:04:45,420
So in this case to put this on multiple lines I'm going to reprint sees an open print cease here so

63
00:04:45,420 --> 00:04:48,030
I can type on multiple lines here.

64
00:04:48,950 --> 00:04:55,370
So I will also close this off print sees may do a tab here and now.

65
00:04:55,390 --> 00:05:00,410
Let's start off by putting in the actual columns who want I want.

66
00:05:00,420 --> 00:05:05,340
And they're actually all listed here and the directions daily time spent on site h cetera.

67
00:05:05,370 --> 00:05:12,670
So daily time spent on sites that I want h.

68
00:05:12,890 --> 00:05:15,900
Let's make sure that's in double quotes.

69
00:05:15,900 --> 00:05:20,690
Then I also want the area income.

70
00:05:20,980 --> 00:05:24,800
And then I also want the daily

71
00:05:27,470 --> 00:05:31,780
Internet usage.

72
00:05:31,980 --> 00:05:36,740
And then finally I want our column we just created.

73
00:05:36,890 --> 00:05:43,430
I also want that mail column indicating whether or not this person was a male and we can actually just

74
00:05:44,510 --> 00:05:46,510
close this off right here.

75
00:05:47,840 --> 00:05:56,320
So I will take this print seas close it put it right here we can actually put this on the next line

76
00:05:56,860 --> 00:05:59,280
and close that office just for formatting purposes.

77
00:05:59,500 --> 00:06:05,860
So we've done so far we selected clicked on ADD as label and then daily time spent on site age area

78
00:06:05,860 --> 00:06:09,760
income daily Internet usage our and then mail.

79
00:06:09,820 --> 00:06:11,610
Let me make sure everything's right.

80
00:06:11,620 --> 00:06:15,890
One thing to note is that here in the directions it says Select time stamp.

81
00:06:16,090 --> 00:06:17,560
But what it wants you to do.

82
00:06:17,560 --> 00:06:20,980
Select time stamp and then convert that into a column called our.

83
00:06:21,070 --> 00:06:26,250
Make sure you don't have that time stamp column here on your final logistic regression data.

84
00:06:26,320 --> 00:06:31,390
Otherwise you may get an error because time stamped information is not going to be compatible with the

85
00:06:31,390 --> 00:06:33,690
logistic regression algorithm.

86
00:06:33,700 --> 00:06:40,810
Instead we want just our which is going to end up being a digit from somewhere 0.24 OK.

87
00:06:41,100 --> 00:06:45,450
So next we want to import vector assembler in vectors.

88
00:06:45,450 --> 00:06:55,470
So I will say imports or Patchi sparked the of feature and then I want vector assembler.

89
00:06:55,680 --> 00:06:58,100
Next they will say import or Apache.

90
00:06:58,100 --> 00:07:00,420
That sparked the animal.

91
00:07:00,430 --> 00:07:01,730
Ouch.

92
00:07:02,160 --> 00:07:06,470
And I will import vector's we save this.

93
00:07:06,710 --> 00:07:11,150
Next we want to create a new vector a similar object called the Sembler for the feature columns as the

94
00:07:11,150 --> 00:07:16,340
input set and the output columns to be called the features just like we've done multiple times before

95
00:07:16,640 --> 00:07:19,360
we need to make sure that our data frame is in the correct format.

96
00:07:19,640 --> 00:07:25,740
So I will say this Velle assembler is equal to open and close.

97
00:07:25,740 --> 00:07:33,860
Prince is here to work on multiple lines O.S. new vector assembler code parentheses and then it will

98
00:07:33,860 --> 00:07:40,450
say Dot set in put calls to.

99
00:07:40,650 --> 00:07:47,520
And this is going to contain an array and it's just an array of all the columns we just typed out.

100
00:07:47,520 --> 00:07:54,480
So let me go ahead and just grab them here and then it will deletes the actual dollar signs so grab

101
00:07:54,480 --> 00:07:58,520
that going to us right click copy.

102
00:07:58,740 --> 00:07:59,760
Scroll down.

103
00:08:00,710 --> 00:08:02,860
Right click paste.

104
00:08:02,870 --> 00:08:04,990
So that's my array of columns.

105
00:08:04,990 --> 00:08:08,920
Let me make sure to delete these dollar signs because we just want them as strings.

106
00:08:10,730 --> 00:08:13,050
And then make sure my princes are balanced here.

107
00:08:14,430 --> 00:08:14,720
OK.

108
00:08:14,740 --> 00:08:16,310
So those are my input columns.

109
00:08:16,320 --> 00:08:26,760
And then finally I want to set my output call ups Peetie call and that's just going to be called features

110
00:08:26,880 --> 00:08:28,170
as always.

111
00:08:28,170 --> 00:08:30,020
All lowercase.

112
00:08:30,080 --> 00:08:34,370
Let me save that and let me run this to make sure all my princes are balanced.

113
00:08:34,380 --> 00:08:36,250
I'm doing a lot of stuff on multiple lines.

114
00:08:37,380 --> 00:08:40,530
Running that looks like we're good to go.

115
00:08:40,550 --> 00:08:41,420
Perfect.

116
00:08:42,210 --> 00:08:45,550
And I can actually just close that princes off here.

117
00:08:45,650 --> 00:08:50,780
So so far we have our vector assembler ready to go next we want to use random split to create a train

118
00:08:50,780 --> 00:08:52,890
to split 30.

119
00:08:52,970 --> 00:09:05,950
So I will say that all array training test is equal to log Regg data dot random splits.

120
00:09:06,200 --> 00:09:08,030
And then we pass in an array.

121
00:09:08,510 --> 00:09:12,290
We want training to be 0.7 and the test to be 0.3.

122
00:09:12,290 --> 00:09:17,210
Basically the way this works is this point seven lines up with the first item in the story which is

123
00:09:17,210 --> 00:09:21,940
training the 0.3 lines up with the second item in that area which is test.

124
00:09:22,070 --> 00:09:24,920
And if you want you can also add a seed to this.

125
00:09:24,930 --> 00:09:29,880
I had a seat in just so if you're following along you can make sure your results match up to mine.

126
00:09:30,060 --> 00:09:32,510
Common see is just one two three four five.

127
00:09:32,650 --> 00:09:34,810
How will you get the same random split that I do.

128
00:09:35,560 --> 00:09:40,420
Next we want to set up the pipeline and this is going to make our life a lot easier using pipelines

129
00:09:40,990 --> 00:09:43,980
instead of just putting everything onto an actual model.

130
00:09:43,980 --> 00:09:53,100
I will say import or puckey the spark the M-L the pipeline and then I will create a new pipeline with

131
00:09:53,100 --> 00:09:58,590
the stages assembler and L R but whoops I forgot I skipped the step.

132
00:09:58,600 --> 00:10:01,230
I want to create a new logistic regression object called L-R.

133
00:10:01,420 --> 00:10:04,650
Let me cut this and paste it here.

134
00:10:05,800 --> 00:10:07,920
Now I want to create an eulogistic Russian soci.

135
00:10:07,930 --> 00:10:13,220
Well L-R is new logistic regression close parentheses.

136
00:10:13,270 --> 00:10:16,310
Then I can create a pipeline well pipeline.

137
00:10:16,340 --> 00:10:21,340
This is going to be a simpler pipeline than what we used in the example walkthrough lecture of course

138
00:10:21,460 --> 00:10:25,690
just a pipeline with essentially just two stages here.

139
00:10:25,780 --> 00:10:32,140
The stages are passes an array and the stage is just an assembler and then the logistic regression model

140
00:10:32,140 --> 00:10:35,680
itself that we want to fit the pipeline into the training.

141
00:10:35,710 --> 00:10:40,490
So we'll say well model is equal to Pipeline.

142
00:10:40,840 --> 00:10:43,700
Fit as in training.

143
00:10:43,720 --> 00:10:47,440
And then we want to get the results on the test set with transform.

144
00:10:47,440 --> 00:10:58,900
So I will say that all results equals modeled transform test save this we will run this make sure we

145
00:10:58,900 --> 00:11:04,900
don't need to debug any mistakes but we should see everything clear out and then we will be able to

146
00:11:04,900 --> 00:11:10,180
actually call the results and see what they look like and this may take a little bit of time depending

147
00:11:10,180 --> 00:11:13,350
on how fast the computer is as far as running everything.

148
00:11:13,360 --> 00:11:16,210
If you run this on a cluster it would be much much faster.

149
00:11:17,820 --> 00:11:23,110
All right ends up it was actually already done it just needed to expand this command prompt here.

150
00:11:23,120 --> 00:11:28,890
All right we have our actual results if we say results that show actually that print schema

151
00:11:31,760 --> 00:11:35,550
we can see we have a prediction and a probability and also a what's known as a prediction.

152
00:11:35,600 --> 00:11:38,020
And then the label it's the integer.

153
00:11:38,040 --> 00:11:43,880
Now we can evaluate how well our results did for this right now we're going to use this semi outdated

154
00:11:43,910 --> 00:11:45,220
multiclass metrics.

155
00:11:45,380 --> 00:11:50,240
Again make sure you check the lectures surrounding this one in case there's an extra notes and check

156
00:11:50,250 --> 00:11:51,910
the Q&amp;A forums.

157
00:11:51,920 --> 00:11:56,960
I will make sure to post there if anything's changed but we'll just say import orgullo Apache that spark

158
00:11:57,230 --> 00:12:02,380
M-L lib evaluation evaluation.

159
00:12:02,380 --> 00:12:08,780
And they will say multiclass metrics and I earlier noted that the newer machine learning is sometimes

160
00:12:08,780 --> 00:12:12,250
just called M-L and the older oddity is called Emsellem.

161
00:12:12,280 --> 00:12:17,740
The reason for that is this because ardy the stuff you imported from sparked the M-L lib you were stuff

162
00:12:17,740 --> 00:12:19,540
you import it from SPARC that came out.

163
00:12:19,570 --> 00:12:25,180
So keep that in mind if you ever hear someone say Sparke MLS that a spark at Bell lib.

164
00:12:25,180 --> 00:12:33,250
Next I want to say well I will just call this prediction and all labels as we've done in previous lectures

165
00:12:33,910 --> 00:12:45,230
will say results selects and then you'll select the prediction column and we'll select the label column

166
00:12:46,190 --> 00:12:47,990
and I need to convert this to an R D D.

167
00:12:47,990 --> 00:12:57,950
You can reference lecture notes for this but you just say double double and then RTD lowercase.

168
00:12:58,270 --> 00:13:04,260
They want to instantiate a new multiclass metrics object so I will say yvel metrics is equal to New

169
00:13:05,250 --> 00:13:06,550
multiclass metrics.

170
00:13:06,600 --> 00:13:10,870
And then pasand those predictions and labels.

171
00:13:11,000 --> 00:13:13,740
Next I want to actually print out that confusion matrix.

172
00:13:13,740 --> 00:13:24,700
I will simply just say Prince L.N. confusion matrix and then I will say Prince Elen actually off the

173
00:13:24,710 --> 00:13:25,720
metric subject.

174
00:13:26,630 --> 00:13:29,710
Grab the confusion matrix.

175
00:13:29,720 --> 00:13:33,000
Capital M their matrix.

176
00:13:33,020 --> 00:13:37,620
OK save all that and let's make sure this thing actually works.

177
00:13:37,640 --> 00:13:39,810
Hopefully it runs with no errors.

178
00:13:41,200 --> 00:13:45,140
It's funny Dr. Sembler pipelined classification is looking good.

179
00:13:45,140 --> 00:13:50,670
Got a results and there is a confusion matrix and I spell confusion wrong.

180
00:13:50,810 --> 00:13:52,610
But other than that no errors.

181
00:13:52,740 --> 00:13:54,120
OK perfect.

182
00:13:54,160 --> 00:13:56,180
If you evaluate this model looks like that pretty good.

183
00:13:56,190 --> 00:14:03,410
It only mislabelled 8 points makes sense because the state is actually pretty well separated.

184
00:14:03,410 --> 00:14:05,300
Let me quickly review everything we did here.

185
00:14:05,300 --> 00:14:09,530
This should have been a pretty straightforward assignment especially if you went through the walk through

186
00:14:09,530 --> 00:14:12,100
example earlier in the section of the course.

187
00:14:12,110 --> 00:14:15,440
But as a quick final run through let me just tell you everything we did.

188
00:14:15,470 --> 00:14:21,980
We got our data imported logistic regression and SPARC session set the error reporting created a spark

189
00:14:21,980 --> 00:14:23,090
session.

190
00:14:23,090 --> 00:14:29,100
You Spark's read in the advertising file printed the schema splayed some of the data using head.

191
00:14:29,240 --> 00:14:35,030
We grab the time stamp and set it to be our cause we can't use just time stamp information.

192
00:14:35,030 --> 00:14:39,150
So a little bit of feature engineering here then grabbed the actual features we wanted.

193
00:14:39,990 --> 00:14:42,870
Make sure that the clicked on ADD was set as label.

194
00:14:42,990 --> 00:14:47,790
Then after that we need to import vector Sembler and vectors to actually put all these feature columns

195
00:14:47,790 --> 00:14:52,020
to an array called features actually set up vector assembler.

196
00:14:52,260 --> 00:14:54,620
Split the data into a training and test set.

197
00:14:54,690 --> 00:14:59,370
Then we imported the pipeline create a new logistic regression object actually set the pipeline if it

198
00:14:59,370 --> 00:15:05,370
stages fit to the training data then transform the test data and then violate the results.

199
00:15:05,430 --> 00:15:09,280
Using this kind of older multiclass metrics All right.

200
00:15:09,320 --> 00:15:11,520
That is for the solutions here.

201
00:15:11,520 --> 00:15:14,370
If you have any questions feel free to post them to the Kewney forums.

202
00:15:14,370 --> 00:15:16,170
Thanks everyone and I'll see at the next lecture.
