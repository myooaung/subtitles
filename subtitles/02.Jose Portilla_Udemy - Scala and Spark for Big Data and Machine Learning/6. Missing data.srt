1
00:00:05,280 --> 00:00:09,210
Hello everyone and welcome to the missing data lecture in this lecture.

2
00:00:09,240 --> 00:00:14,160
We're going to discuss various ways you can use spark data frames to actually deal with data that is

3
00:00:14,160 --> 00:00:15,890
missing from your data set.

4
00:00:16,080 --> 00:00:19,280
Let's go ahead and jump to the text editor to get started.

5
00:00:19,290 --> 00:00:19,620
All right.

6
00:00:19,620 --> 00:00:21,440
Here I am at the text editor.

7
00:00:21,480 --> 00:00:27,450
I've created the new Skala script files called Elly's see for lecture and the Scala a script that goes

8
00:00:27,450 --> 00:00:33,120
along with this lecture is the missing data that Skala And you're also going to read this contains no

9
00:00:33,150 --> 00:00:38,610
but see the file you take a look at this contains no you'll notice that say CACP file that it's actually

10
00:00:38,610 --> 00:00:39,880
missing some information.

11
00:00:39,900 --> 00:00:45,510
So only this last row is complete where you have an employee ID a name and then a particular sales number

12
00:00:45,600 --> 00:00:47,130
or sales figure.

13
00:00:47,130 --> 00:00:49,490
Go ahead and copy these first three lines of code.

14
00:00:49,680 --> 00:00:55,960
Or we started Sparke session get create and set up our import of this CSC file.

15
00:00:55,990 --> 00:00:58,660
Again it's the contains no CACP file.

16
00:00:58,660 --> 00:01:01,920
All right let's go ahead and discuss missing data.

17
00:01:02,170 --> 00:01:07,830
Before we do that I'm going to just show you what happens when we actually print the schema of this

18
00:01:07,830 --> 00:01:09,490
particular data frame.

19
00:01:09,760 --> 00:01:14,010
And what happens when we show the schema member it's missing some data in it.

20
00:01:14,020 --> 00:01:18,790
So let's go ahead and load really see that Skala here.

21
00:01:20,060 --> 00:01:22,870
Run it and then I'm going to expand this to show you.

22
00:01:23,570 --> 00:01:24,070
OK.

23
00:01:24,260 --> 00:01:29,250
So as I mentioned and as we saw contains nulled out CAC is actually missing some data.

24
00:01:29,360 --> 00:01:35,100
And what happens is SPARC is actually going to show that by inputting and you L-L for NULL.

25
00:01:35,150 --> 00:01:40,220
So we can see here that we have all the employee ID information but we only have two names and two numbers

26
00:01:40,520 --> 00:01:44,950
and we have a particular employee ID with neither name nor a sales number.

27
00:01:45,380 --> 00:01:48,610
And basically we have three options when we deal with no values.

28
00:01:48,800 --> 00:01:53,730
Either you can just keep them in and maybe only a certain percentage of no values exist.

29
00:01:53,900 --> 00:01:57,390
So maybe you're OK with missing one or the other.

30
00:01:57,470 --> 00:02:03,110
In this case names or sales but you're not ok with missing both of these information points.

31
00:02:03,110 --> 00:02:04,250
So that's option 1.

32
00:02:04,250 --> 00:02:07,790
Just keep them and maybe limit them to a certain percentage.

33
00:02:07,790 --> 00:02:09,950
The other option is to just drop them completely.

34
00:02:10,100 --> 00:02:14,030
So maybe you just drop anywhere where you don't have an employee name or drop any rows where you don't

35
00:02:14,030 --> 00:02:15,240
have the sales data.

36
00:02:15,380 --> 00:02:19,010
And then the third option which is really common when you're done of machine learning is to actually

37
00:02:19,010 --> 00:02:21,350
try to fill them in with some other value.

38
00:02:21,350 --> 00:02:25,220
And I want you to know there is no perfectly correct answer here.

39
00:02:25,250 --> 00:02:29,020
There is no correct answer where you'll have to drop them or have to fill them in.

40
00:02:29,180 --> 00:02:34,370
It's basically up to you as either the data engineer or a data scientist or whoever you're talking with

41
00:02:34,640 --> 00:02:38,010
on the particular project and what your particular data set looks like.

42
00:02:38,120 --> 00:02:42,050
So again there's no correct answer you're going to have to adjust the way you think about the problem

43
00:02:42,280 --> 00:02:44,470
to the actual data that you have.

44
00:02:44,480 --> 00:02:49,950
Let's go ahead and get started by showing you how you can drop values.

45
00:02:50,050 --> 00:02:57,250
Now if we take a look at this idea if there is a thought and a method and then there's methods we can

46
00:02:57,250 --> 00:03:01,660
call off of this if you want to explore these methods you can actually see them in the terminal.

47
00:03:01,660 --> 00:03:09,730
So after running this in this terminal and the Skoll determined can say DMF any dots and then TEB and

48
00:03:09,730 --> 00:03:12,910
you'll see that you have drop fill and replace.

49
00:03:12,910 --> 00:03:17,830
Now at this point in time these are still technically experimental but they should be off experimental

50
00:03:17,830 --> 00:03:20,150
in the next update release of SPARC.

51
00:03:20,350 --> 00:03:21,310
So keep that in mind.

52
00:03:21,310 --> 00:03:23,570
But from my experience they do work well.

53
00:03:23,870 --> 00:03:24,400
Okay.

54
00:03:24,640 --> 00:03:31,330
So the very first option is to drop our data if we want to drop any rows with any amount of any values.

55
00:03:31,450 --> 00:03:37,860
We just say DFA any that drop and then I'm going to say that show to actually see the state of frame

56
00:03:37,950 --> 00:03:43,740
as an output and I'm going to show the original data frame just so we can see the difference here.

57
00:03:43,770 --> 00:03:50,400
So let's go ahead and load L.E. see that Skala and we can see the original data frame and then what

58
00:03:50,400 --> 00:03:52,360
happens when we say that drop.

59
00:03:52,380 --> 00:03:59,250
So in this original data frame we can see that we have the null values and when we say any drop it will

60
00:03:59,250 --> 00:04:03,570
drop any rows to have any null values for any columns.

61
00:04:03,570 --> 00:04:09,630
Now you can actually pasan a number arguments into this any draw and you can draw any rows that have

62
00:04:09,630 --> 00:04:15,900
less than a minimum number of non null values and that's going to be an integer that you put in there.

63
00:04:15,900 --> 00:04:22,400
So for example if we go ahead and put two go ahead and save that and run this again.

64
00:04:24,330 --> 00:04:27,510
And let's compare the results we have now.

65
00:04:27,520 --> 00:04:34,480
So here we can see that we have the original data frame in by inputting the value to we go in and scroll

66
00:04:34,480 --> 00:04:36,390
down here into any that drop.

67
00:04:36,400 --> 00:04:41,480
All right so how does this actually work with this and a that drop the two as the argument.

68
00:04:41,530 --> 00:04:48,100
Remember this is going to drop any rows that have less than the minimum number of non null values.

69
00:04:48,100 --> 00:04:55,810
So less than that integer amount which in this case we're looking for any row that has less than 2 non-null

70
00:04:55,810 --> 00:04:56,800
values.

71
00:04:56,830 --> 00:05:04,210
So unfortunately we can see here that employee number two had two non or 2 no values and we want to

72
00:05:04,270 --> 00:05:09,990
drop any rows that have less than the minimum number amount of non-null values.

73
00:05:10,040 --> 00:05:17,500
In this case we're left with any rows that has at least one or more non-null values.

74
00:05:17,530 --> 00:05:21,670
This is sometimes a little tricky to understand because it's kind of warding it backwards it's almost

75
00:05:21,670 --> 00:05:24,840
like a double negative when you're thinking about nulls.

76
00:05:24,880 --> 00:05:29,650
So go ahead and check out the missing data that Skala in case you need written out for you.

77
00:05:30,010 --> 00:05:35,050
So if you scroll down here you'll see here that there's drop any rows to have less than a minimum number

78
00:05:35,050 --> 00:05:36,660
of non-null values.

79
00:05:36,670 --> 00:05:40,770
So a couple of tricky points for beginners sometimes is this use of kind of a double negative.

80
00:05:40,930 --> 00:05:46,150
Dropping any rows with the non-null values and the other confusion points sometimes it's that this is

81
00:05:46,150 --> 00:05:49,170
a less than not a less than or equal to.

82
00:05:49,180 --> 00:05:55,150
So keep that in mind if you're still a little confused by this what I would recommend doing is actually

83
00:05:55,210 --> 00:06:01,000
open up this contains no doubt see a c file maybe add in some more columns and more empty value slots

84
00:06:01,270 --> 00:06:03,510
so you can truly understand what's going on here.

85
00:06:03,520 --> 00:06:09,160
Again sometimes some beaners have issues with this as far as understanding it but it's pretty straightforward

86
00:06:09,160 --> 00:06:13,930
once you are able to get that click in your mind where it says drop any rows they have less than a minimum

87
00:06:13,930 --> 00:06:17,070
number of the double negative non null values.

88
00:06:17,190 --> 00:06:17,770
OK.

89
00:06:18,040 --> 00:06:21,360
So that's basically it for dropping rows.

90
00:06:21,370 --> 00:06:28,690
Either you drop any rows of any amount of null or any values or you actually specify a threshold number

91
00:06:29,080 --> 00:06:33,380
where you drop any rows that have less than the minimum number of non-null values.

92
00:06:33,390 --> 00:06:33,720
All right.

93
00:06:33,730 --> 00:06:41,200
Now that we discussed how to drop any values either drop any rows that have any null values or drop

94
00:06:41,320 --> 00:06:45,990
rows if a certain amount of non-null values that meet some sort of minimum threshold.

95
00:06:46,150 --> 00:06:50,130
We can do is discuss how to actually fill in no values.

96
00:06:50,140 --> 00:06:55,450
Sometimes you have a particular singular value some sort of based value that you actually want to fill

97
00:06:55,450 --> 00:06:56,330
in.

98
00:06:56,510 --> 00:06:58,360
Let me go ahead and show you how you can do that.

99
00:06:58,420 --> 00:07:03,500
And there's some really interesting behavior as far as inferring schema.

100
00:07:03,610 --> 00:07:10,540
So we're going to go to say DFA N.A. Phil and I'm just going to pass any number one hundred and then

101
00:07:10,540 --> 00:07:14,340
I'm going to go ahead and show this and we'll see some interesting behavior.

102
00:07:14,440 --> 00:07:18,850
Go ahead and just to remind you show you what this data frame looks like.

103
00:07:18,850 --> 00:07:26,110
Our data from right now has a string column of ID's a string column of names and a double column of

104
00:07:26,110 --> 00:07:27,850
sales numbers here.

105
00:07:27,850 --> 00:07:30,750
Now I'm going to say fill 100.

106
00:07:30,990 --> 00:07:34,130
Let's see what happens when I run this code.

107
00:07:34,170 --> 00:07:40,270
So I go ahead and whips load see that Skala will see something interesting happen.

108
00:07:40,530 --> 00:07:40,900
OK.

109
00:07:40,950 --> 00:07:45,990
And this is what's interesting and a lot of languages that deal with data frames won't actually do this.

110
00:07:45,990 --> 00:07:52,110
What Sparke is able to do is based off we go ahead and scroll down here based on the data type of what

111
00:07:52,110 --> 00:07:53,490
you put in for fill.

112
00:07:53,670 --> 00:07:58,120
It will look for all the columns that match that data type and fill it in.

113
00:07:58,140 --> 00:08:03,990
In this case we put in a 100 which has a numerical value or a number and it went ahead and looked at

114
00:08:03,990 --> 00:08:09,270
the columns and said OK look at the data types and tell me what columns have a data type that is a number

115
00:08:09,490 --> 00:08:14,400
that's going to be either a integer or that will and then it says OK Will the sales column has that

116
00:08:14,400 --> 00:08:20,370
sort of data type and it goes ahead and fills in 100 only for the missing values in that sales column

117
00:08:20,670 --> 00:08:24,160
and then it goes ahead and leaves name as null values.

118
00:08:24,390 --> 00:08:28,790
Let's go ahead and see what happens when we fill in a string here.

119
00:08:28,890 --> 00:08:36,710
So I'm going to fill in missing name save this and run this.

120
00:08:36,730 --> 00:08:42,600
Now think for a second what you expect and how this is going to infer the schema for the fill job.

121
00:08:42,700 --> 00:08:44,350
We go ahead and run this.

122
00:08:44,590 --> 00:08:46,690
Notice we get back these results.

123
00:08:46,690 --> 00:08:52,540
So now instead of filling in the sales which was a double type it's going to fill in any missing values

124
00:08:52,540 --> 00:08:54,780
that were the same data type here in Phil..

125
00:08:54,940 --> 00:08:57,120
In this case that is the name column.

126
00:08:57,130 --> 00:09:03,070
Keep in mind that if we had other columns that had strings in them that were also missing it would also

127
00:09:03,070 --> 00:09:05,290
put in missing name into those columns.

128
00:09:05,290 --> 00:09:11,710
So a lot of times you're going to want to be more specific and specify what columns you actually want

129
00:09:11,710 --> 00:09:12,800
to fill in.

130
00:09:12,880 --> 00:09:18,030
You usually won't just use a fill command like this unless you have a pretty small data set.

131
00:09:18,070 --> 00:09:19,670
As far as columns concern.

132
00:09:19,740 --> 00:09:25,000
So if you have a few columns and you only expect to fill in one column you could use that thought fill

133
00:09:25,210 --> 00:09:29,170
with no specification as far as what column you want to pass.

134
00:09:29,230 --> 00:09:33,420
But in this case let's go ahead and specify what column we want to do.

135
00:09:33,760 --> 00:09:37,490
So I'm going to specify that I want to fill in the name column.

136
00:09:37,500 --> 00:09:43,660
So I'm going to say specific as my string and you can name the string whatever you want.

137
00:09:43,660 --> 00:09:46,050
So let's go ahead just to make that clear.

138
00:09:46,120 --> 00:09:51,190
We'll say new name though don't confuse anybody.

139
00:09:51,220 --> 00:09:58,040
And the second argument you passen is an array of the column names you want in this case.

140
00:09:58,150 --> 00:10:01,020
I just want to fill in the name column.

141
00:10:01,080 --> 00:10:04,990
Go ahead and save that I'll clear the terminal and let's run this again.

142
00:10:07,200 --> 00:10:07,690
OK.

143
00:10:07,810 --> 00:10:10,460
And now we can see that we basically got the same result.

144
00:10:10,540 --> 00:10:15,790
But in this case instead of just specifying to fill any columns with missing values of the same data

145
00:10:15,790 --> 00:10:23,260
type I was able to specify that I want to specifically fill in only the column that has this name column

146
00:10:23,650 --> 00:10:25,420
or this name column name.

147
00:10:26,970 --> 00:10:30,710
Let me go ahead and show you the same thing for the sales column.

148
00:10:30,720 --> 00:10:40,010
So for instance let's go ahead and say 200 dollars and instead of saying array name I'm going to say

149
00:10:40,100 --> 00:10:43,490
arraying sales.

150
00:10:43,980 --> 00:10:52,990
Save this and run it in now I can see I only filled in sales because I specified it not that it actually

151
00:10:52,990 --> 00:10:54,730
inferred the data type here.

152
00:10:56,260 --> 00:11:03,910
Let me go ahead and clear this terminal and before we finish off this lecture I just want to do a simple

153
00:11:03,910 --> 00:11:09,450
exercise which is going to be filling in the sales with the average sales data.

154
00:11:09,460 --> 00:11:11,700
So how do we actually get that average sale data.

155
00:11:11,740 --> 00:11:17,020
Well he could use an aggregate function but I'll show you a very simple method to do this in two steps.

156
00:11:17,020 --> 00:11:20,830
Usually you want to do this in one single step but you could say something like this.

157
00:11:20,870 --> 00:11:28,180
DFI thought describe and remember the scribe shows you that statistical information often numerical

158
00:11:28,180 --> 00:11:28,670
columns.

159
00:11:28,680 --> 00:11:34,570
If IDF taught the scribe sales I can see that my mean or average sale is 400 point five.

160
00:11:34,570 --> 00:11:43,900
So then I would say fill four hundred point five to the sales column save that heaps and load my lecture

161
00:11:43,930 --> 00:11:49,990
Skala and I've gone ahead and then filled in my sales data with that average and if I wanted to I could

162
00:11:49,990 --> 00:11:53,390
also copy this.

163
00:11:53,550 --> 00:11:56,700
And let's go ahead and fill in the name data as well and see what happens.

164
00:11:56,700 --> 00:12:06,100
So if I say something like missing name and specify that I want the name column here let's see what

165
00:12:06,100 --> 00:12:10,070
happens when I do that.

166
00:12:10,100 --> 00:12:15,530
You'll notice that I end up getting two results here one with the sales filled in but the name missing

167
00:12:15,920 --> 00:12:17,520
and the other with the name filled in.

168
00:12:17,530 --> 00:12:19,720
But the sale still missing.

169
00:12:19,960 --> 00:12:25,990
If I wanted to actually affect both of these columns what I could end up doing is setting a value here.

170
00:12:26,060 --> 00:12:36,150
What's in my script for Val DFI to equal to that data frame and take off show and then I could say here

171
00:12:36,380 --> 00:12:41,300
DFI to that N.A. that Phil. Let's go in and run this and see how it works.

172
00:12:42,570 --> 00:12:47,520
And at the very end they see now that I have both my name column filled in and my sales column filled

173
00:12:47,520 --> 00:12:48,400
in.

174
00:12:48,420 --> 00:12:49,010
All right.

175
00:12:49,110 --> 00:12:49,950
Great.

176
00:12:50,040 --> 00:12:54,280
Go ahead and check out the Skala script for this lecture.

177
00:12:54,360 --> 00:12:59,070
And keep in mind these are still technically experimental at these times but they've been around since

178
00:12:59,070 --> 00:13:00,360
1.3.

179
00:13:00,690 --> 00:13:02,300
So they should work pretty well.

180
00:13:02,300 --> 00:13:04,180
I've never had an issue with them at all.

181
00:13:04,540 --> 00:13:05,940
Okay thanks everyone.

182
00:13:05,940 --> 00:13:09,040
Make sure you go ahead and kind of reclean look for this missing data.

183
00:13:09,090 --> 00:13:14,430
That's called a script in case you want to see any more comments or any more code.

184
00:13:14,430 --> 00:13:16,380
Thanks everyone and I'll see you at the next lecture.
