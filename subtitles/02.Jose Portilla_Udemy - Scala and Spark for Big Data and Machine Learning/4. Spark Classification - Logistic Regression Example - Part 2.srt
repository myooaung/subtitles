1
00:00:05,550 --> 00:00:10,410
Hello everyone and welcome to part two of the walk through example of a logistic regression problem

2
00:00:10,410 --> 00:00:12,200
for classification with SPARK.

3
00:00:12,450 --> 00:00:16,120
Let's jump right back in where we left off last time OK.

4
00:00:16,130 --> 00:00:22,100
Here we are right back where we left off when we left off we talked about using vectors vector assembler's

5
00:00:22,130 --> 00:00:27,560
string indexers and one hot encoders to actually deal for categorical columns.

6
00:00:27,590 --> 00:00:31,150
Let's actually use those in this case.

7
00:00:31,210 --> 00:00:35,520
We are going to import what we need to start off with.

8
00:00:35,720 --> 00:00:39,950
And as I mentioned all the time you usually put these imports at the top but I'm separating out in this

9
00:00:39,950 --> 00:00:43,050
format so you can see what goes with what.

10
00:00:43,070 --> 00:00:50,840
So I'm going to import org that Apache that spark that emal that feature and then to import multiple

11
00:00:50,840 --> 00:00:53,100
things you can just put it in brackets here.

12
00:00:53,420 --> 00:01:02,650
I want to import a vector assembler the string indexer and then the vector indexer.

13
00:01:02,650 --> 00:01:05,990
And that's going to allow me to actually deal with these categorical columns.

14
00:01:06,020 --> 00:01:13,010
And then the last thing I want to do here also from feature is one hot encoder OK.

15
00:01:13,120 --> 00:01:25,380
And then finally I want to import Orrick Apache spark M-L Lin alge vector's sometimes you know import

16
00:01:25,380 --> 00:01:27,290
that you may get some errors.

17
00:01:27,660 --> 00:01:33,420
Ok moving along we want to first deal for categorial categorical columns that are in string forms by

18
00:01:33,420 --> 00:01:35,080
using the string indexer.

19
00:01:35,910 --> 00:01:47,000
So I'm going to say Val create an object called gender indexer is equal to a new string indexer and

20
00:01:47,000 --> 00:01:52,810
then very similar to what we're using vector assembler's we set an input call.

21
00:01:52,880 --> 00:02:03,280
In this case it's going to be sex and then use sets up McCollum's so set output call and I would just

22
00:02:03,280 --> 00:02:08,390
call this sex index OK.

23
00:02:08,680 --> 00:02:13,600
Once we have that we also need to do the same for the embarked column.

24
00:02:13,720 --> 00:02:27,400
So we can say Val Embarq indexer is equal to New Street indexer input call to.

25
00:02:27,400 --> 00:02:28,960
In this case it's Embarq

26
00:02:32,030 --> 00:02:33,860
and then I also output call

27
00:02:37,060 --> 00:02:44,590
to something like Embarq index.

28
00:02:44,710 --> 00:02:45,090
All right.

29
00:02:45,130 --> 00:02:57,330
So just to label this this is converting strings into numerical values.

30
00:02:58,410 --> 00:03:03,220
And then after that we need to convert numerical values.

31
00:03:06,120 --> 00:03:16,970
Into some sort of one hot encoding and basically what that means is 0 or ones in order for a logistic

32
00:03:16,970 --> 00:03:29,630
regression function to actually deal with this we will say Val gender gender in KOTOR is equal to new.

33
00:03:29,880 --> 00:03:36,810
And then I'm going to actually task one Hutten Khoder I will set the input call to be equal to what

34
00:03:36,810 --> 00:03:38,160
we outputted last time.

35
00:03:38,220 --> 00:03:42,880
In this case sex index.

36
00:03:43,120 --> 00:03:50,000
And then I will set the output call to be called something like encoded or something.

37
00:03:50,010 --> 00:03:52,650
Or we can actually just say.

38
00:03:52,840 --> 00:03:56,490
It's going to be a vector we'll say sex we see.

39
00:03:56,520 --> 00:04:08,070
So that sex vector and then we'll say well Embarq encoder is equal to new lips.

40
00:04:08,200 --> 00:04:18,640
One ha encoder in very similarly we will say set the input to embark index and then we will set the

41
00:04:18,700 --> 00:04:23,770
output call to embark vector.

42
00:04:23,810 --> 00:04:29,010
So severely Embarq we will just say VTC OK.

43
00:04:29,180 --> 00:04:32,720
So so far what we've done is we've taken in that string column.

44
00:04:32,720 --> 00:04:39,320
If we check this out we have these two string columns sex's which is male and female and then disembarks

45
00:04:39,350 --> 00:04:40,750
which is letters.

46
00:04:41,000 --> 00:04:47,510
We want to take those using the string indexer create and a new column called either sex index or Embarq

47
00:04:47,510 --> 00:04:50,660
index that converts these into actual numbers.

48
00:04:50,720 --> 00:04:52,880
So something like mail is one.

49
00:04:52,890 --> 00:04:58,440
A female is to offer these locations as one cue is to see is three.

50
00:04:58,660 --> 00:05:05,570
And we want to take those singular columns and use one one in coding to actually create some dummy variables.

51
00:05:05,570 --> 00:05:11,510
So we will take as input these sex index and embark index and then set some output columns.

52
00:05:11,510 --> 00:05:15,650
Now it doesn't really matter what you call this but hopefully this sort of naming convention is a little

53
00:05:15,650 --> 00:05:17,390
more clear for you.

54
00:05:17,390 --> 00:05:22,430
All right after that we want to put everything together into the classic form that we have been dealing

55
00:05:22,430 --> 00:05:29,310
with that label features form so we need to put everything into label features.

56
00:05:30,450 --> 00:05:41,000
And as we've done before we will create a value called the Sembler and create a new vector assembler.

57
00:05:41,200 --> 00:05:45,420
And then I want to set my input columns.

58
00:05:45,450 --> 00:05:51,790
This is actually pleural to be in train of all the columns are going to be working with.

59
00:05:51,810 --> 00:06:00,180
And in this case these are going to be my passenger class the sex column that output at the end of that

60
00:06:00,180 --> 00:06:01,240
gendering coater.

61
00:06:01,560 --> 00:06:08,600
And later on we'll show you how to actually implement the indexers and encoders then is the age column.

62
00:06:08,610 --> 00:06:10,440
And I'm just passing on strings here.

63
00:06:10,480 --> 00:06:18,320
The sibling spouse column the parent child column or parch and then let me check what else we have.

64
00:06:18,340 --> 00:06:22,200
We also need the Fair column and then the Embarq vector column.

65
00:06:22,450 --> 00:06:23,750
Make sure it's a comma there.

66
00:06:26,230 --> 00:06:27,460
So the Fair column

67
00:06:30,240 --> 00:06:35,540
and then Embarq the PC.

68
00:06:35,570 --> 00:06:35,780
All right.

69
00:06:35,790 --> 00:06:41,490
So we have those input columns and then as we always do with a vector assembler we need to set these

70
00:06:41,550 --> 00:06:42,430
as an output.

71
00:06:42,450 --> 00:06:46,510
And in this case the output will be just features.

72
00:06:46,630 --> 00:06:51,510
So I will do is put a print C's here so I can write this in multiple lines.

73
00:06:52,630 --> 00:06:56,800
And as long as this is all on under that group of parentheses should be fine.

74
00:06:58,620 --> 00:07:03,290
So then I will say that set output call.

75
00:07:03,520 --> 00:07:08,780
In this case features they make sure that princes are balanced and you can see the highlighting here.

76
00:07:08,820 --> 00:07:10,830
Looks like we're good to go.

77
00:07:10,830 --> 00:07:11,130
All right.

78
00:07:11,130 --> 00:07:12,460
Now I have my assembler.

79
00:07:12,720 --> 00:07:16,530
Let me just run this and make sure everything actually worked.

80
00:07:16,530 --> 00:07:27,330
So I'm going to save this and then say load log Rick X scholar enter and make sure everything's working

81
00:07:27,330 --> 00:07:28,010
all right.

82
00:07:31,420 --> 00:07:37,030
OK print out that example row my feature in coder's and stree indexers are OK.

83
00:07:37,060 --> 00:07:40,540
Dr. assembler's Okay so it looks like we are good to go.

84
00:07:40,540 --> 00:07:43,120
Keep in mind I haven't actually done anything yet.

85
00:07:43,300 --> 00:07:45,490
I need to call these indexers and encoders.

86
00:07:45,490 --> 00:07:47,630
Right now we're just creating them.

87
00:07:47,770 --> 00:07:52,190
Up next I want to split the data into a training set and a test set.

88
00:07:53,000 --> 00:08:05,000
So I will say Val Auray training test equal to my log Regg data.

89
00:08:05,030 --> 00:08:05,840
Not all of it.

90
00:08:05,890 --> 00:08:13,670
Remember we want to drop the missing values and then I can call random split and this takes in an array

91
00:08:14,680 --> 00:08:16,440
where you decide the ratio.

92
00:08:16,510 --> 00:08:25,210
So I want 0.7 to be so 70 percent of this logarithmic data is going to be this object training and then

93
00:08:25,210 --> 00:08:26,010
everything else.

94
00:08:26,020 --> 00:08:34,690
Or 0.3 30 percent will be test and you can actually add in a seat value here if you want to follow along

95
00:08:34,690 --> 00:08:35,560
exactly with me.

96
00:08:35,560 --> 00:08:37,270
I recommend you do so.

97
00:08:37,270 --> 00:08:38,440
Put in a seed of.

98
00:08:38,440 --> 00:08:43,660
In this case I'm just going to put one two three four five and just make sure that the random split

99
00:08:43,660 --> 00:08:45,190
is the same as mine.

100
00:08:45,910 --> 00:08:47,480
So remember this is a random split.

101
00:08:47,490 --> 00:08:52,620
So if you don't put in the seat value your split may be different than mine which means your confusion

102
00:08:52,620 --> 00:08:54,820
matrix at the end of everything will be different.

103
00:08:54,840 --> 00:08:59,160
But if you want to make sure you get all the same results if you run this one two three four five you

104
00:08:59,160 --> 00:09:02,500
should get the same result as I do or at least extremely similar.

105
00:09:02,520 --> 00:09:05,250
Next up is to actually set up the pipeline.

106
00:09:05,250 --> 00:09:11,220
The pipeline is going to allow us to put all these encoders assemblers and indexers into a pipeline

107
00:09:11,580 --> 00:09:16,420
so we can just feed in our raw data into the pipeline and take care of everything.

108
00:09:17,340 --> 00:09:23,960
So I will see import or that Apache that sparked the M-L pipeline.

109
00:09:24,030 --> 00:09:26,410
You've noticed that we're importing a lot of stuff from m-L.

110
00:09:26,490 --> 00:09:31,680
So probably if you're putting this all in one object script you are just at the very top say M-L and

111
00:09:31,680 --> 00:09:36,960
then in brackets have a bunch of imports they're coming from that machine learning library but this

112
00:09:36,960 --> 00:09:39,610
will allow us to play around often spark a little more.

113
00:09:39,730 --> 00:09:45,940
I will say well L-R is equal to new logistic regression.

114
00:09:47,140 --> 00:09:51,130
So I create this logistic regression object and then this is something we haven't seen before.

115
00:09:51,140 --> 00:09:52,700
The pipeline.

116
00:09:53,020 --> 00:09:56,520
So I will AUPs create this value pipeline.

117
00:09:56,710 --> 00:10:05,120
Call it new pipeline and the next part of the pipeline is to set the stages and the stages is just going

118
00:10:05,120 --> 00:10:09,350
to be an array of all these indexers encoders assemblers.

119
00:10:09,410 --> 00:10:11,180
And then finally the model.

120
00:10:11,960 --> 00:10:19,990
So I will say new pipeline set stages and then passen an array of all the stages I want in this case.

121
00:10:20,010 --> 00:10:26,220
I'm going to basically be doing everything I wrote here in order it will do the gender indexer roomer

122
00:10:26,240 --> 00:10:27,650
that's a string indexer.

123
00:10:27,720 --> 00:10:32,610
It grabs the input column called sex and then sets an output column called sex index.

124
00:10:32,610 --> 00:10:38,220
The next thing I have is the embark indexer grabs a string column called embarked sets the output to

125
00:10:38,220 --> 00:10:39,540
embark index.

126
00:10:39,540 --> 00:10:45,360
The next thing I have over here is the gender and coater those these very similar things up in this

127
00:10:45,360 --> 00:10:50,420
case it takes in the output of those indexers and outputs those vectors.

128
00:10:50,430 --> 00:10:52,500
Now we have Embarq and coater does the same thing.

129
00:10:52,530 --> 00:10:57,690
And then I finally have my assembler that takes in all those feature columns sets a single output column

130
00:10:57,690 --> 00:10:59,400
called features.

131
00:10:59,400 --> 00:11:01,770
Then I go ahead and I put that array.

132
00:11:01,770 --> 00:11:04,100
So let's put that all in in here.

133
00:11:04,170 --> 00:11:13,360
First thing I want to do is put in the Jinder indexer then the Embarq indexer then the gender in coater

134
00:11:14,690 --> 00:11:20,900
then the embark and coater And then once we have the indexing and the encoding set up we just need to

135
00:11:20,900 --> 00:11:21,680
assemble it.

136
00:11:21,740 --> 00:11:27,400
So I will say assembler and then you can actually just passing your model here as well.

137
00:11:27,600 --> 00:11:30,060
So LR for logistic regression model.

138
00:11:30,060 --> 00:11:31,240
And that's your whole pipeline.

139
00:11:31,260 --> 00:11:35,500
You've set up all the stages that you're actually going to do for your data.

140
00:11:35,730 --> 00:11:41,360
Then you can fit the pipeline just as if it was a normal machine learning model.

141
00:11:41,850 --> 00:11:50,550
So you'll say Val model is equal to pipeline that fit and this case will just fit it to the training

142
00:11:50,550 --> 00:11:54,930
data and we can later on test it against the test data.

143
00:11:55,880 --> 00:12:00,370
So that fits it to the training data to get results in my test data.

144
00:12:00,370 --> 00:12:07,730
I just say Velle results take that model I just trained from that pipeline and transform my test set

145
00:12:09,050 --> 00:12:12,530
OK let's run this and make sure it all works.

146
00:12:13,880 --> 00:12:19,220
So I will load that script and while this is running it shouldn't take that long the machine learning

147
00:12:19,220 --> 00:12:20,820
part may take a little while.

148
00:12:21,850 --> 00:12:24,640
But let's actually review what we've done so far.

149
00:12:25,000 --> 00:12:31,660
We've taken in our data as a CSP file printed out an example of what it looks like grabbed all the data

150
00:12:32,410 --> 00:12:38,890
then dropped the missing values imported What we need to import create the indexers the deal of string

151
00:12:39,010 --> 00:12:45,340
objects then convert the string objects into numerical objects convert those numerical columns into

152
00:12:45,340 --> 00:12:51,520
one hot coded columns basically dummy variables take that get label and features in the right order

153
00:12:51,610 --> 00:12:57,880
with assembler and then split the data into training and test called the pipeline create a model and

154
00:12:57,880 --> 00:13:04,290
then set the stage for the pipeline fit it to the actual training data and get some results off of that.

155
00:13:04,300 --> 00:13:04,560
All right.

156
00:13:04,570 --> 00:13:06,360
Looks like that all ran just fine.

157
00:13:06,370 --> 00:13:08,800
Have results here as a data frame.

158
00:13:08,800 --> 00:13:14,350
Now it's time to actually evaluate how well our model performed on the test data going to start a little

159
00:13:14,350 --> 00:13:19,000
bit of a new section here called Model evaluation.

160
00:13:20,880 --> 00:13:26,610
And basically this is where we're going to have to pay a price for dealing with the latest and greatest

161
00:13:26,640 --> 00:13:29,370
of Sparke the absolute newest stuff.

162
00:13:29,400 --> 00:13:35,960
The reason for that is a lot of this metrics and evaluation stuff is still only available for our D.

163
00:13:36,110 --> 00:13:37,760
Make sure you check the documentation.

164
00:13:37,770 --> 00:13:44,430
After viewing this lecture to actually check if what I showing you here has been updated to data frames

165
00:13:44,730 --> 00:13:50,640
I will make a note somewhere either before this lecture or after this lecture to links to the documentation

166
00:13:50,910 --> 00:13:53,390
in case this ever gets updated for data frames.

167
00:13:53,610 --> 00:13:59,460
Right now unfortunately it's still an art form so we will have to do is select our prediction column

168
00:13:59,460 --> 00:14:03,840
in our label column off of our results and transform that to an R D.

169
00:14:04,200 --> 00:14:07,680
First I want to actually import what I'm going to be using in this case.

170
00:14:07,680 --> 00:14:14,530
It's going to be Org the Apache that spark that M-L lib.

171
00:14:14,530 --> 00:14:17,570
Note the difference there not a male but a male lib.

172
00:14:17,920 --> 00:14:22,700
And then call evaluation and call multiclass metrics

173
00:14:25,290 --> 00:14:26,910
and then north to use this.

174
00:14:26,910 --> 00:14:30,210
I need to convert our prediction results into an R D.

175
00:14:30,480 --> 00:14:38,730
So I will create an object called prediction and labels and set equal to results select and I just want

176
00:14:38,730 --> 00:14:44,280
to select the prediction column and the label column

177
00:14:47,800 --> 00:14:54,200
and then set that as and this is where we can actually type it in as a data frame.

178
00:14:54,390 --> 00:15:03,030
In this case I want to say as passen a tuple here double comma double and hopefully in the future once

179
00:15:03,030 --> 00:15:10,350
this has been moved to M-L you will have to do this kind of tedious process and then say Dot r d d.

180
00:15:10,470 --> 00:15:18,990
Basically what this is doing is if you look at results right now the results the print schema and hit

181
00:15:19,190 --> 00:15:20,420
enter.

182
00:15:20,420 --> 00:15:26,840
We have this probability this prediction and scrolling up here we have the label.

183
00:15:26,840 --> 00:15:32,130
You also note that we have some of the original columns such as sex and embarked.

184
00:15:32,150 --> 00:15:38,310
Those were actually not used during the model being trained because of the assembler only accepting

185
00:15:38,330 --> 00:15:43,820
the scroll back up here the sex VEC and the embark thick and setting it out two features.

186
00:15:43,820 --> 00:15:49,450
So the model only looked for a label and features it didn't actually look for the rest of these columns.

187
00:15:49,520 --> 00:15:55,910
Essentially you could have just selected features and label before doing the train test split over here.

188
00:15:56,110 --> 00:16:00,770
But kind of optional to you the machine learning algorithms are smart enough to understand that you

189
00:16:00,770 --> 00:16:07,910
really only care about the label and the features column the ones that are actually called that.

190
00:16:07,920 --> 00:16:14,520
All right moving along because of that we want to select just a prediction and just the label select

191
00:16:14,520 --> 00:16:17,130
them as double double because that's the data type.

192
00:16:17,130 --> 00:16:18,950
These are zeros and ones.

193
00:16:18,990 --> 00:16:24,570
And then we want to set that as an r d d in order to use this multiclass MIT metrics because it's still

194
00:16:24,570 --> 00:16:28,100
limited to ARDE these unfortunately.

195
00:16:28,350 --> 00:16:38,410
Then I will say avowe metrics is equal to a new multiclass metrics and then passen the object they I

196
00:16:38,410 --> 00:16:45,100
just made in this case prediction and labels and this allows me to actually create a confusion matrix

197
00:16:45,100 --> 00:16:45,380
print.

198
00:16:45,400 --> 00:16:54,590
Ellen confusion matrix prints Ellen and right off of this metrics.

199
00:16:54,600 --> 00:17:01,490
Objects that I've just created I can say metrics dots confusion matrix.

200
00:17:01,820 --> 00:17:02,840
Let's save this.

201
00:17:02,870 --> 00:17:04,500
And then I want to walk you through a couple of things.

202
00:17:04,500 --> 00:17:08,720
Be careful when using this semi outdated evaluation.

203
00:17:09,710 --> 00:17:14,690
Going to load this and hopefully at the end of this we should see a confusion matrix printed out for

204
00:17:14,690 --> 00:17:17,760
people who survived that people who didn't survive.

205
00:17:17,880 --> 00:17:21,930
And you can review the theory lecture on logistic regression to understand what the confusion matrix

206
00:17:21,930 --> 00:17:24,080
look like OK great.

207
00:17:24,110 --> 00:17:26,300
Here's the confusion matrix we wanted.

208
00:17:26,300 --> 00:17:31,100
Using these values you can actually calculate things such as precision recall and accuracy.

209
00:17:31,190 --> 00:17:32,600
Type 1 error type 2 error.

210
00:17:32,600 --> 00:17:38,750
Well we just discussed in the theory lecture now there's a caveat to this because it's under the older

211
00:17:38,880 --> 00:17:40,700
male lib RTD.

212
00:17:40,790 --> 00:17:50,760
If you say metrics dot and then hit tab here you should see a bunch of objects come up or methods.

213
00:17:50,840 --> 00:17:56,470
Theoretically you should be able to call accuracy precision and recall a true positive rate etc..

214
00:17:56,520 --> 00:18:02,150
Often this metrics object unfortunately because it's the older RBD.

215
00:18:02,210 --> 00:18:10,320
If you say metrics that accuracy enter you will get an accuracy here but you have to notice something.

216
00:18:10,320 --> 00:18:18,190
If I say metrics the recall I also get the exact same number for recall.

217
00:18:18,390 --> 00:18:24,420
And then if I call metrics stop precision I will get the exact same number for precision.

218
00:18:24,550 --> 00:18:29,850
Unfortunately recall and precision are actually just showing the accuracy as well.

219
00:18:29,920 --> 00:18:34,510
And you notice that there's actually a warning here and you can rerun it to actually check what the

220
00:18:34,510 --> 00:18:35,360
details are.

221
00:18:35,560 --> 00:18:38,890
Basically multiclass metrics right now is broken.

222
00:18:39,160 --> 00:18:44,560
And in the future probably won't be updated because it's under the old ardy method.

223
00:18:44,560 --> 00:18:50,380
So if you want to calculate things such as precision and recall you should do that straight off the

224
00:18:50,380 --> 00:18:55,870
confusion matrix the confusion matrix itself still works but always keep in mind that when you're dealing

225
00:18:55,870 --> 00:19:01,120
with something that's basically on the edge of the newest available technology you're going to have

226
00:19:01,120 --> 00:19:05,740
to be dealing with this sort of stuff often and check the documentation to make sure everything is still

227
00:19:05,740 --> 00:19:08,300
working and always double check your answers.

228
00:19:08,320 --> 00:19:12,730
So I apologize that that can be really annoying especially as you're just beginning to learn how to

229
00:19:12,730 --> 00:19:14,110
use all these tools.

230
00:19:14,110 --> 00:19:17,270
But that's the state of the language at this point in time.

231
00:19:17,530 --> 00:19:22,840
And keep in mind I will try to make announcements in this course or set up extra notes or extra lectures

232
00:19:23,110 --> 00:19:25,860
when I find stuff like this has been updated.

233
00:19:25,870 --> 00:19:26,170
All right.

234
00:19:26,170 --> 00:19:32,370
With that all being said that's basically all there is to performing a logistic regression in Sparke.

235
00:19:32,560 --> 00:19:37,090
I'm going to minimize this terminal and just walk through everything we did because we did do quite

236
00:19:37,090 --> 00:19:38,610
a bit of stuff.

237
00:19:38,620 --> 00:19:44,230
First off we imported logistic regression as our chosen classification algorithm which started a spark

238
00:19:44,230 --> 00:19:51,010
session set the logging level to not see so many outputs and the errors read in our CXXVI data explored

239
00:19:51,100 --> 00:19:52,210
a little bit.

240
00:19:52,390 --> 00:19:57,970
Then we grabbed all the data that we were going to use dropped all of the missing values that we didn't

241
00:19:57,970 --> 00:20:04,270
want to deal with imported the features we were going to be using including Lin algebra vectors then

242
00:20:04,270 --> 00:20:10,420
we used to separate string index or objects to deal to categorical columns that were strings so we converted

243
00:20:10,420 --> 00:20:16,170
these strings into a single column and then these single index calls we convert using one hot encoding

244
00:20:16,510 --> 00:20:19,120
to actual vector or array columns.

245
00:20:19,330 --> 00:20:25,410
Then we want to use an assembler to grab all those features and set the output column as features.

246
00:20:25,570 --> 00:20:30,400
You can go ahead and then split that array into training and test data or that data frame I should say

247
00:20:31,080 --> 00:20:36,700
create a pipeline create a new logistic regression object and you can add parameters if you want.

248
00:20:36,700 --> 00:20:41,050
Right now we're just keeping it simple but I encourage you to play around these parameters if you want

249
00:20:41,050 --> 00:20:44,110
to then create a new pipeline object.

250
00:20:44,140 --> 00:20:49,330
Set the stage is an array including your indexing your encoding your assembler and the actual model

251
00:20:49,330 --> 00:20:50,320
you're working with.

252
00:20:50,530 --> 00:20:56,020
Fit this pipeline as if it was just a normal model on your training data and then use the model to transform

253
00:20:56,020 --> 00:20:57,280
your test data.

254
00:20:57,280 --> 00:21:02,620
And right now you can use this semi outdated model evaluation technique.

255
00:21:02,620 --> 00:21:07,450
If you're concerned about using these older evaluation techniques you can just get everything yourself

256
00:21:07,480 --> 00:21:09,250
manually off the results.

257
00:21:09,280 --> 00:21:17,090
So if you ever see the results and say that show these last columns here we say results stop print schema

258
00:21:19,480 --> 00:21:20,330
are available to you.

259
00:21:20,350 --> 00:21:26,530
So you have the probability and predictions including the label column all to yourself in case you ever

260
00:21:26,530 --> 00:21:32,530
want to do any of the maps of type 1 or Type 2 errors yourself to make sure everything is correct.

261
00:21:32,800 --> 00:21:33,490
All right.

262
00:21:33,490 --> 00:21:38,020
If you have any questions feel free to post them to the Q&amp;A forums and I'll be happy to help you out.

263
00:21:38,020 --> 00:21:40,130
Thanks everyone and I will see you at the next lecture.
