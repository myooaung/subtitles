1
00:00:05,510 --> 00:00:11,300
Hello everyone and welcome to the school and Sparke overview lecture and this lecture will give an overview

2
00:00:11,300 --> 00:00:16,310
of the scholar programming language then we will discuss the general big data ecosystem and afterwards

3
00:00:16,310 --> 00:00:18,970
we'll show how Petchey spark fits into all of this.

4
00:00:18,980 --> 00:00:21,780
This is going to be just a non-technical overview lecture.

5
00:00:21,860 --> 00:00:26,630
Just to give you some context of how all the topics we learn in this course actually fit in with each

6
00:00:26,630 --> 00:00:27,110
other.

7
00:00:28,390 --> 00:00:32,800
Scala is a general purpose programming language and it was designed by Mark know their ske in the early

8
00:00:32,800 --> 00:00:33,510
2000s.

9
00:00:33,510 --> 00:00:34,030
EPA.

10
00:00:34,030 --> 00:00:41,530
Fell a technical university in Switzerland and it was designed to overcome criticism of Java's shortcomings.

11
00:00:41,790 --> 00:00:46,760
Source code is intended to be compiled to Java bytecode to run on a Java virtual machine.

12
00:00:46,760 --> 00:00:52,450
So when we install Skala will also need to install Java Java libraries may be used directly in Scala

13
00:00:52,640 --> 00:00:53,330
which is nice.

14
00:00:53,330 --> 00:00:58,310
That way if you have understanding of Java and Java libraries you can leverage that knowledge in Scala

15
00:00:58,880 --> 00:00:59,810
unlike Java.

16
00:00:59,840 --> 00:01:03,340
Scala has many features of functional programming.

17
00:01:03,680 --> 00:01:08,570
A large reason skald the man has dramatically risen in recent years is because of Apache's SPARC which

18
00:01:08,570 --> 00:01:09,950
is written in Scala.

19
00:01:09,950 --> 00:01:13,650
So let's go ahead and discuss what spark is in the context of Big Data.

20
00:01:13,820 --> 00:01:17,940
We'll begin with a general explanation of what big data is and related technologies.

21
00:01:18,170 --> 00:01:22,670
So for this big data Overview section of this lecture we're going to go ahead and give an explanation

22
00:01:22,670 --> 00:01:24,740
of Hadoop map reduce and sparrer.

23
00:01:24,770 --> 00:01:27,440
We'll talk about local versus distributed systems.

24
00:01:27,470 --> 00:01:32,300
We'll give an overview of the Hadoop ecosystem and then an overview of SPARC itself.

25
00:01:33,800 --> 00:01:36,050
Let's talk about big data in general.

26
00:01:36,050 --> 00:01:41,900
There's data that can fit on a local computer and that's usually in the scale of 0 to 32 gigabytes depending

27
00:01:41,900 --> 00:01:43,760
on how much ram your computer has.

28
00:01:43,760 --> 00:01:47,390
So this is just data that can actually fit onto your RAM.

29
00:01:47,660 --> 00:01:53,210
But what do you do if you have larger data sets which are bigger than what you can actually hold in

30
00:01:53,210 --> 00:01:54,840
memory on RAM.

31
00:01:54,890 --> 00:02:00,770
Well you can try using a sequel database to move storage onto a hard drive instead of a ram or onto

32
00:02:00,770 --> 00:02:03,130
a cloud database using sequel.

33
00:02:03,380 --> 00:02:09,960
Or you can use a distributed system that distributes the data to multiple machines or computers and

34
00:02:09,960 --> 00:02:14,730
this discussion of a local system versus a distributed system comes into play.

35
00:02:14,760 --> 00:02:20,900
You're usually using a local system for just that home using a single computer with a distributed system

36
00:02:20,910 --> 00:02:26,400
you can actually have a master computer controlling more course.

37
00:02:26,400 --> 00:02:30,570
So instead of actually thinking of these as computers you should actually think of this distributed

38
00:02:30,570 --> 00:02:36,960
system as controlling servers which in combination of each other can actually leverage the power of

39
00:02:36,960 --> 00:02:41,450
smaller computers to have more cores than just a single local computer.

40
00:02:42,520 --> 00:02:48,220
So a local process will use the computation resources of a single machine in a distributed process has

41
00:02:48,220 --> 00:02:53,170
access to the computational resources across a number of machines connected through some sort of network

42
00:02:53,860 --> 00:02:54,960
after a certain point.

43
00:02:54,970 --> 00:03:00,580
It's a lot easier to scale out to many lower CPM machines that try to scale up to a single machine with

44
00:03:00,580 --> 00:03:07,010
a high CPQ distributed machines also have the advantage of easily scaling.

45
00:03:07,010 --> 00:03:10,940
You can just add more machines and they also include things such as fault tolerance.

46
00:03:10,940 --> 00:03:16,160
So if one machine fails the whole network can still go on unlike your local computer where if it goes

47
00:03:16,160 --> 00:03:18,320
down that's it you're out.

48
00:03:18,320 --> 00:03:22,970
So let's go ahead and discuss the typical format of a distributed architecture that uses Hadoop and

49
00:03:22,970 --> 00:03:29,840
then we'll discuss how we can use distributed computing with SPARC Hadoop is a way to distribute very

50
00:03:29,840 --> 00:03:34,520
large files across multiple machines and it uses what's known as the Hadoop distributed file system

51
00:03:34,700 --> 00:03:42,890
or HFS DFS allows a user to work with large data sets and HFS also duplicates blocks of data for fault

52
00:03:42,920 --> 00:03:43,990
tolerance.

53
00:03:44,000 --> 00:03:50,400
It also then uses map reduce and map Redus allows computations on that data.

54
00:03:50,470 --> 00:03:54,690
So let's go ahead and look at a simple example of what distributed storage looks like.

55
00:03:54,760 --> 00:03:59,550
This is just a general overview of what a Hadoop distributed file system may look like.

56
00:03:59,600 --> 00:04:05,740
You'll have a name node with some C-p in RAM and then you'll have your data nodes which contain your

57
00:04:05,740 --> 00:04:07,670
data in a distributed format.

58
00:04:09,160 --> 00:04:14,090
So DFS will use blocks of data for the size of 128 megabytes by default.

59
00:04:14,290 --> 00:04:19,180
And each of these blocks is replicated three times and then those replications are distributed in a

60
00:04:19,180 --> 00:04:24,430
way across those distributed servers or computers in order to support fault tolerance.

61
00:04:24,430 --> 00:04:29,650
So if one of these servers goes down you'll also have copies or replications of that data.

62
00:04:30,960 --> 00:04:36,840
Smaller blocks provide more paralyzation during processing and multiple copies of a block prevent loss

63
00:04:36,840 --> 00:04:43,880
of data due to some sort of failure of a node map reduce is a way of splitting computation tasks to

64
00:04:43,880 --> 00:04:50,720
a distributed set of files such as HFS and it consists of a job tracker and multiple task trackers.

65
00:04:50,800 --> 00:04:56,410
The job tracker is going to send code to run on the task trackers and then the task tracker will allocate

66
00:04:56,420 --> 00:05:03,600
CPQ and memory for the tasks and monitor the tasks on these worker nodes so that we cover it can be

67
00:05:03,600 --> 00:05:05,000
thought of into distinct parts.

68
00:05:05,010 --> 00:05:10,520
You're using HFS that Hadoop distributed file system to distribute large data sets and you're using

69
00:05:10,520 --> 00:05:14,250
that produce to distribute computational tasks to distributed data set.

70
00:05:14,250 --> 00:05:19,500
So you have the storage and formatting versus the actual distribution of the computational task.

71
00:05:19,500 --> 00:05:23,870
So next let's go ahead and learn about the latest technology in the space known as SPARK what we cover

72
00:05:23,870 --> 00:05:29,090
in this course spark improves on the concepts of using distribution.

73
00:05:29,090 --> 00:05:34,700
So this lecture is going to now be an abstract overview of spark spark versus map reduce spark already

74
00:05:34,700 --> 00:05:40,920
does and then spark data frame's so Sparke is one of the latest technologies being used to quickly and

75
00:05:40,920 --> 00:05:42,480
easily handle big data.

76
00:05:42,480 --> 00:05:45,360
And it's an open source project hosted on Apache.

77
00:05:45,390 --> 00:05:51,510
It was first released in February 2013 and has exploded in popularity due to its ease of use and its

78
00:05:51,510 --> 00:05:52,300
speed.

79
00:05:52,350 --> 00:05:56,830
It was created at the amp lab at UC Berkeley in California.

80
00:05:56,880 --> 00:06:02,550
You can think of Sparke as a flexible alternative to map reuse and spark can use data stored in a variety

81
00:06:02,550 --> 00:06:03,110
of formats.

82
00:06:03,120 --> 00:06:11,960
Cassandra AWOS S3 HD effects and much more so map redos requires files to be stored in the FS while

83
00:06:11,960 --> 00:06:13,190
SPARC does not.

84
00:06:13,190 --> 00:06:19,520
It can use those multiple file formats Sparke can also perform operations up to 100 times faster than

85
00:06:19,550 --> 00:06:20,300
map reduce.

86
00:06:20,420 --> 00:06:22,030
And this is its main selling point.

87
00:06:22,040 --> 00:06:24,310
Its speed overmastered does.

88
00:06:24,350 --> 00:06:29,890
So now we want to know how does it actually achieve this huge speed increase will map reduce writes

89
00:06:29,900 --> 00:06:36,320
most of its data to disk after each map and reduce operation spark however keeps most of the data in

90
00:06:36,320 --> 00:06:41,760
memory after each transformation and spark can spill over to disk if the memory is filled.

91
00:06:41,960 --> 00:06:44,220
So the simplified the difference a little bit.

92
00:06:44,270 --> 00:06:50,330
You can basically think of SPARC as keeping all its operations in memory as much as it can versus map

93
00:06:50,330 --> 00:06:54,440
reduce having to write the disk after each mapping reduce operation.

94
00:06:54,440 --> 00:07:00,060
So as you may imagine SPARC can do these operations much faster since it's keeping everything in memory

95
00:07:01,920 --> 00:07:03,070
at the core of SPARC.

96
00:07:03,090 --> 00:07:05,810
Is the idea of a resilient distributed dataset.

97
00:07:05,820 --> 00:07:11,520
Or are you going to be hearing that term a lot when you have discussions about SPARC resilient distributed

98
00:07:11,560 --> 00:07:14,960
datasets or are does have four main features.

99
00:07:15,000 --> 00:07:16,960
It's a distributed collection of data.

100
00:07:17,220 --> 00:07:18,900
It's fault tolerant.

101
00:07:18,960 --> 00:07:26,010
It has parallel operations that are partitioned and it has the ability to use many data sources.

102
00:07:26,040 --> 00:07:28,400
So what does this actually look like in a general sense.

103
00:07:28,410 --> 00:07:30,450
Well it's actually going to look pretty familiar.

104
00:07:30,450 --> 00:07:35,710
Based on what we discussed about Hadoop Smet produce but already these are slightly different.

105
00:07:35,730 --> 00:07:40,590
You have a driver program which has a spark context or a spark session.

106
00:07:40,800 --> 00:07:46,260
Then you have a cluster manager which is going to manage the different worker nodes that are executing

107
00:07:46,260 --> 00:07:48,990
the tasks that are being held in memory.

108
00:07:49,080 --> 00:07:51,800
So what does this actually look like in a more physical sense.

109
00:07:51,810 --> 00:07:56,930
We'll usually have what are known as Master nodes and then these slave nodes or these worker nodes.

110
00:07:57,210 --> 00:08:02,640
The master controls how the data is partitioned across these worker nodes and then it takes advantage

111
00:08:02,640 --> 00:08:06,650
of data locality while keeping track of all the stream data computation.

112
00:08:06,840 --> 00:08:12,570
All these worker machines if a certain machine is unavailable then the data on that machine just gets

113
00:08:12,570 --> 00:08:18,510
reconstructed on another available machine and that allows for this fault tolerance and the distribution

114
00:08:18,960 --> 00:08:25,200
of the data set allowing it to be resilient distributed datasets or Arti these are Didi's are immutable

115
00:08:25,290 --> 00:08:30,120
lazily evaluated and then cashable and there's two types of art to the operations.

116
00:08:30,120 --> 00:08:35,190
There's transformations and actions and this is a critical point to truly understanding.

117
00:08:35,220 --> 00:08:42,600
These transformations are basically just a recipe to follow you give instructions as a recipe to your

118
00:08:42,600 --> 00:08:48,150
actual RTT that set of data that's distributed across these worker nodes.

119
00:08:48,150 --> 00:08:54,090
Then once you actually want to perform an action you call some sort of action operation that will perform

120
00:08:54,330 --> 00:08:58,140
what the transformations say to do and then return something back.

121
00:08:58,140 --> 00:09:04,590
The reason for this split of operations transformations vs actions is because if you're working of spark

122
00:09:04,710 --> 00:09:07,320
it means you're working with a very large dataset.

123
00:09:07,500 --> 00:09:12,780
So you want to make sure that every time you adjust a transformation you're not actually recomputing

124
00:09:12,780 --> 00:09:14,950
everything across your entire cluster.

125
00:09:14,970 --> 00:09:19,770
It's only when you call that action that the transformations actually get computed and that's why it's

126
00:09:19,770 --> 00:09:21,360
called lazily evaluated.

127
00:09:21,510 --> 00:09:25,810
It's lazily waiting for you to actually call the action.

128
00:09:25,970 --> 00:09:31,910
Now when discussing Spark's syntax you're going to see RTD vs data frame Syntec show up especially as

129
00:09:31,910 --> 00:09:36,390
you start to browse the documentation with the release of SPARC 2.0.

130
00:09:36,560 --> 00:09:40,110
SPARC is moving towards a data frame based syntax.

131
00:09:40,190 --> 00:09:46,040
But keep in mind that the way files are being distributed physically across the cluster can actually

132
00:09:46,040 --> 00:09:48,230
still be thought of as the DS.

133
00:09:48,320 --> 00:09:53,540
It's just the actual typed out syntax that is changing and we're going to discuss this a lot further

134
00:09:53,540 --> 00:09:59,800
detail when we actually learn more about Sparc and how to actually type out Sparke commands in Scala.

135
00:09:59,930 --> 00:10:04,490
But in this course we're going to be focusing on the future of SPARC which is this data frame based

136
00:10:04,550 --> 00:10:05,340
syntax.

137
00:10:05,540 --> 00:10:07,000
But don't let that confuse you.

138
00:10:07,040 --> 00:10:11,700
As if already these are suddenly disappearing from your physical cluster management.

139
00:10:11,720 --> 00:10:18,300
It's just a cleaner syntax for working with data so I know we've covered a lot.

140
00:10:18,320 --> 00:10:23,330
And don't worry if you didn't memorize all these details a lot of this will be covered again as we learn

141
00:10:23,330 --> 00:10:27,470
more about how to actually code in Scala and utilize all these ideas.

142
00:10:27,470 --> 00:10:33,020
This is just a basic high level overview for you to understand the context of everything you're about

143
00:10:33,020 --> 00:10:34,580
to learn in this course.

144
00:10:34,580 --> 00:10:36,410
OK thanks everyone.

145
00:10:36,500 --> 00:10:39,710
I'm super excited to get off the course and I'll see you at the next lecture.
