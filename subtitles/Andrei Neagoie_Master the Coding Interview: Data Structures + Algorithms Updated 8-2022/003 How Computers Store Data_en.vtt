WEBVTT
1
00:00:01.380 --> 00:00:08.250
In order to truly understand the value of data structures, we have to go deep down into the way computer

2
00:00:08.250 --> 00:00:08.910
works.

3
00:00:09.030 --> 00:00:10.290
The fundamental level.

4
00:00:11.420 --> 00:00:18.350
In order for a computer to run code, it needs to keep track of things like variables, like numbers,

5
00:00:18.350 --> 00:00:19.610
strings, array.

6
00:00:20.210 --> 00:00:27.740
These variables are stored in what we call random access, memory or RAM for short.

7
00:00:28.390 --> 00:00:30.280
That's how programs run.

8
00:00:30.400 --> 00:00:34.900
We remember this from Space Complexity video, right?

9
00:00:35.260 --> 00:00:43.450
On top of that, we also have storage where we store things like our video files, music files, documents.

10
00:00:44.240 --> 00:00:51.440
And the storage can be a disk drive, a flash drive, or a solid state drive.

11
00:00:52.140 --> 00:00:55.980
Data on storage is permanent or what we call persistent.

12
00:00:55.980 --> 00:01:01.680
So when you turn off your laptop or computer, it's still going to be there when you turn it back on.

13
00:01:02.040 --> 00:01:06.300
In RAM, you lose the memory when the computer turns off.

14
00:01:07.200 --> 00:01:12.060
So why wouldn't we just always use storage so we don't lose any data?

15
00:01:12.660 --> 00:01:16.440
Well, the problem is that persistent storage is slow.

16
00:01:17.410 --> 00:01:21.550
Because you see a computer is run by its CPU.

17
00:01:21.940 --> 00:01:26.740
You can think of the CPU as the little worker that does all the calculations that we need.

18
00:01:26.770 --> 00:01:29.290
It does the actual work inside our computer.

19
00:01:29.650 --> 00:01:39.910
And this CPU needs access to the RAM and the storage, but it can access the RAM and the information

20
00:01:39.910 --> 00:01:41.770
in the RAM a lot faster.

21
00:01:42.450 --> 00:01:45.660
But let me give you an example as if we're using Google.

22
00:01:46.620 --> 00:01:50.070
When we run Google Chrome, for example, a browser.

23
00:01:51.180 --> 00:01:54.210
That Google Chrome browser has a piece of code.

24
00:01:54.240 --> 00:01:58.690
Now here I've simplified it and we just have a variable A equals one.

25
00:01:58.710 --> 00:02:01.870
We're just assigning this variable one.

26
00:02:01.890 --> 00:02:07.740
But we can imagine how we have hundreds, thousands of lines of code of Google Chrome.

27
00:02:08.130 --> 00:02:14.670
Now, in order for our computer to run Google Chrome, we run the CPU for it to do so.

28
00:02:15.960 --> 00:02:23.610
Now when a variable is declared in, let's say, a script to run Google Chrome, it's going to hold

29
00:02:23.610 --> 00:02:27.480
that in memory in our random access memory.

30
00:02:28.500 --> 00:02:35.790
But once we turn off or close Google Chrome, we want to be able to reopen it, right?

31
00:02:36.300 --> 00:02:43.650
Well, that's what we do when we save an application on our computer, we save it to storage so that

32
00:02:43.650 --> 00:02:46.080
next time we open up Google Chrome.

33
00:02:47.420 --> 00:02:54.920
The CPU is going to grab the program from the storage so that it can use it again.

34
00:02:54.920 --> 00:03:01.730
And for Google Chrome to run fast and run smaller scripts, it's going to keep that information and

35
00:03:01.730 --> 00:03:03.260
random access memory.

36
00:03:03.590 --> 00:03:06.440
We can see this on our computers as well.

37
00:03:07.940 --> 00:03:14.660
If I go to about this, Mac, my computer, we can see here that we have the processor, which is my

38
00:03:14.690 --> 00:03:18.650
CPU, we have my memory, which is my RAM.

39
00:03:18.650 --> 00:03:26.120
And if I go to storage, this is my flash storage, my persistent storage on my computer.

40
00:03:28.190 --> 00:03:36.170
So you can think of RAM in the computer as a massive storage area, kind of like a data structure,

41
00:03:36.170 --> 00:03:36.620
right?

42
00:03:37.420 --> 00:03:43.510
Well, this massive storage area has shelves that are numbered.

43
00:03:44.290 --> 00:03:53.230
We call these address or addresses, and it's a really, really big shelf that holds a lot of information

44
00:03:53.650 --> 00:03:57.430
and it allows us to run programs.

45
00:03:58.150 --> 00:03:59.080
On our computer.

46
00:03:59.440 --> 00:04:06.970
Now, each of these shelves holds what we call eight bits or numbers.

47
00:04:07.000 --> 00:04:12.100
If you see here, one, two, three, four, five, six, seven, eight.

48
00:04:12.490 --> 00:04:15.520
Each one of these numbers is a bit.

49
00:04:16.540 --> 00:04:21.690
And a bit is a tiny electrical switch that can be turned on or off.

50
00:04:21.700 --> 00:04:29.890
But instead of calling it on or off, we call it one or zero and eight bits is called a byte.

51
00:04:30.430 --> 00:04:34.420
Each shelf has one byte.

52
00:04:35.380 --> 00:04:36.610
Of storage.

53
00:04:37.300 --> 00:04:45.220
And the CPU is connected to something called a memory controller and a memory controller does the actual

54
00:04:45.220 --> 00:04:53.830
reading of this memory as well as writing this memory, because sometimes the shelf might be blank and

55
00:04:53.830 --> 00:04:54.940
doesn't have anything.

56
00:04:55.640 --> 00:05:05.660
Now this direct connection to the CPU is important because the CPU asks the RAM, Hey, what's in shelf

57
00:05:05.660 --> 00:05:06.650
number zero?

58
00:05:06.860 --> 00:05:13.880
And the memory controller actually has connections individually to all of these shelves.

59
00:05:14.480 --> 00:05:21.710
Again, that's really important because it means that we can access the zero shelf and immediately access

60
00:05:21.710 --> 00:05:30.950
the seven shelf or 10,781 shelf without having to climb down or step down.

61
00:05:32.020 --> 00:05:35.050
That's what the name random access memory means.

62
00:05:35.050 --> 00:05:40.520
We can access memory really fast because we have these connections any shelf we want.

63
00:05:40.540 --> 00:05:43.210
We just need to know which shelf we're looking for.

64
00:05:43.690 --> 00:05:48.100
We can access the bits at any random address in memory right away.

65
00:05:48.520 --> 00:05:54.970
Even though this memory controller can jump between far apart memory addresses, really fast programs

66
00:05:54.970 --> 00:05:57.670
tend to access memory that is nearby.

67
00:05:57.700 --> 00:06:06.580
The closer the information is to the CPU and the less it has to travel, the faster a program can run.

68
00:06:07.370 --> 00:06:13.070
So computers are actually tuned to get extra speed boosts when reading memory dresses.

69
00:06:13.760 --> 00:06:18.650
That are close to each other for a computer to access zero.

70
00:06:18.650 --> 00:06:26.000
And one is a lot faster than a computer for it to access zero and 1000.

71
00:06:26.930 --> 00:06:29.090
Because these are a lot closer together.

72
00:06:29.510 --> 00:06:37.970
And to further optimize this, our computers also have what we call a CPU cache, where the CPU has

73
00:06:37.970 --> 00:06:44.000
a tiny, tiny memory, where it stores a copy of stuff that is really, really recent.

74
00:06:44.630 --> 00:06:47.690
And this is called a cache.

75
00:06:49.150 --> 00:06:52.480
A common one that you might hear is something called LRU cash.

76
00:06:53.110 --> 00:06:59.410
So again, if we use Google Chrome as an example, we turn on Google Chrome with let's say we have the

77
00:06:59.410 --> 00:07:08.140
application downloaded on our storage, the CPU loads it up and because we've visited Hacker News.com,

78
00:07:08.140 --> 00:07:16.150
it's going to load up the information for that Hacker News and put it into memory or maybe even cache

79
00:07:16.150 --> 00:07:17.140
if it can hold it.

80
00:07:19.130 --> 00:07:22.400
So why is this important for data structures?

81
00:07:23.290 --> 00:07:24.010
Well.

82
00:07:25.130 --> 00:07:30.230
Data structures are remember ways for us to store information.

83
00:07:30.620 --> 00:07:37.820
For example, if we want to store a variable A equals one, well, in our modern computers, usually

84
00:07:37.820 --> 00:07:39.760
we represent integers.

85
00:07:39.770 --> 00:07:43.460
That is the number one in 32 bits.

86
00:07:43.460 --> 00:07:47.210
That is this block size of RAM.

87
00:07:47.240 --> 00:07:53.570
And by the way, this is now can be 64 bits with more and more recent upgrades.

88
00:07:54.740 --> 00:07:55.400
But.

89
00:07:56.080 --> 00:08:03.030
This way we can store the number one within this blocks of 32 bits.

90
00:08:03.040 --> 00:08:04.360
Why 32 bits?

91
00:08:04.570 --> 00:08:10.060
Because eight bits, which is one byte times one, two, three, four.

92
00:08:10.060 --> 00:08:13.780
So eight times four is 32 bits.

93
00:08:13.780 --> 00:08:16.180
We can store 32 bits of information.

94
00:08:16.790 --> 00:08:20.220
And this bit of one you can see here.

95
00:08:20.240 --> 00:08:28.280
000000 or zero zero and one is stored now in memory 0123 or the address zero one, two, three.

96
00:08:28.310 --> 00:08:36.049
If we have another variable B equals to seven, we would store it in the next block over here in our

97
00:08:36.049 --> 00:08:36.590
RAM.

98
00:08:37.450 --> 00:08:38.710
In doing this.

99
00:08:39.419 --> 00:08:48.480
You can now think about how systems that are eight bit can hold 255 bits of information.

100
00:08:50.190 --> 00:08:54.300
Things that are 16 bit well, they can hold a lot more information.

101
00:08:54.720 --> 00:08:57.390
And now we have systems that are 32 bits.

102
00:08:58.050 --> 00:09:01.350
You can see here that we can hold a ton of information.

103
00:09:01.350 --> 00:09:11.130
And then if we had 64 bits, that is, instead of having four little shells over here, we have eight

104
00:09:11.220 --> 00:09:14.820
shelves shelf times, eight bits.

105
00:09:14.850 --> 00:09:18.720
Well, that's a lot of information that we can store.

106
00:09:19.170 --> 00:09:23.670
And the bigger this is, the more diverse that information is.

107
00:09:23.700 --> 00:09:25.530
If we had an eight bit system.

108
00:09:25.620 --> 00:09:29.940
Well, the number 256, we can't really store that.

109
00:09:29.940 --> 00:09:31.260
That's really hard to do.

110
00:09:31.800 --> 00:09:34.380
And I can demonstrate this to you with JavaScript.

111
00:09:35.430 --> 00:09:38.190
You see, there's something called integer overflow.

112
00:09:38.220 --> 00:09:41.260
Now, JavaScript technically doesn't have integers.

113
00:09:41.280 --> 00:09:44.280
It only has what we call a 64 bit floats.

114
00:09:44.700 --> 00:09:50.310
But the idea is that a computer can only store a certain number of information.

115
00:09:51.170 --> 00:09:59.150
So using this syntax in JavaScript, we have Math Pao, which is a function that returns the base to

116
00:09:59.150 --> 00:10:00.240
the exponent power.

117
00:10:00.260 --> 00:10:05.850
That is the first parameter is the base to the power of the second parameter.

118
00:10:05.870 --> 00:10:09.650
So we can create really large numbers like math dot pow.

119
00:10:09.650 --> 00:10:11.580
So five to the power of 100.

120
00:10:11.600 --> 00:10:14.290
If I run this, we see the number over here.

121
00:10:14.300 --> 00:10:19.450
If I increase this to let's say six again, another large number.

122
00:10:19.460 --> 00:10:23.360
Now, what if I keep going and change this to six to the power of 1000?

123
00:10:24.410 --> 00:10:26.120
We get infinity.

124
00:10:27.920 --> 00:10:28.340
Hmm.

125
00:10:28.430 --> 00:10:29.090
What?

126
00:10:29.090 --> 00:10:29.990
What is that?

127
00:10:30.080 --> 00:10:38.840
Well, as the number becomes too large to store in our RAM, then we need to represent this number that

128
00:10:38.840 --> 00:10:42.050
we cannot store into something that is tangible.

129
00:10:42.050 --> 00:10:44.770
In JavaScript case, it is infinity.

130
00:10:44.780 --> 00:10:51.830
We can only store this much information and no matter how big I make this, any number above a certain

131
00:10:51.830 --> 00:10:54.980
threshold is going to just say infinity.

132
00:10:55.890 --> 00:10:56.870
How cool is that?

133
00:10:58.420 --> 00:10:59.920
Now let's go back to the slides.

134
00:11:00.810 --> 00:11:06.000
I showed you all of this because other data types other than numbers work the same way.

135
00:11:06.210 --> 00:11:13.800
Each data type has a number of bits associated with it, and that needs to get stored in the system.

136
00:11:14.420 --> 00:11:21.230
And the system allocates that storage and then the CPU reads from that storage.

137
00:11:22.550 --> 00:11:23.090
Now.

138
00:11:23.090 --> 00:11:28.010
I'll leave a link for you after this video so that you can get more information if you want.

139
00:11:28.040 --> 00:11:32.570
We don't want to get too deep in this, but a data structure is this.

140
00:11:33.480 --> 00:11:36.150
A data structure is an arrangement of data.

141
00:11:36.450 --> 00:11:42.050
You can define the way you interact with this data and how it is arranged in RAM.

142
00:11:42.060 --> 00:11:48.810
So some data structures in RAM are organized right next to each other, some are organized apart from

143
00:11:48.810 --> 00:11:54.390
each other and they have different pros and cons on access and right.

144
00:11:55.190 --> 00:12:02.360
Our goal is to minimize the operation that we need to do for the CPU to get the information for the

145
00:12:02.360 --> 00:12:04.310
CPU to write information.

146
00:12:05.330 --> 00:12:07.970
And that is why data structures are so powerful.

147
00:12:08.540 --> 00:12:15.350
We're thinking about the low level and I don't know about you, but this to me when I learned about

148
00:12:15.350 --> 00:12:22.580
this was really, really exciting because we have a way now to think how data structures actually affect

149
00:12:22.580 --> 00:12:29.930
the process of our computers and how we can use what we know about computers now to write great code.

150
00:12:30.530 --> 00:12:31.790
I'll see you in the next video.

