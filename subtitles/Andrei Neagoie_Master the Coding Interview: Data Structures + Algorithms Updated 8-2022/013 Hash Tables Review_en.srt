1
00:00:01,710 --> 00:00:04,980
Another data structure down hash tables.

2
00:00:05,040 --> 00:00:11,520
By now, you should absolutely love them because, well, they're very useful.

3
00:00:11,700 --> 00:00:13,110
They're used everywhere.

4
00:00:13,500 --> 00:00:22,020
And the funny thing is that it's probably the most common interview question where you use a hash table

5
00:00:22,020 --> 00:00:27,990
to optimize something kind of like we saw in our interview question.

6
00:00:28,380 --> 00:00:34,230
By using hash tables, we optimize those nested loops that are own squared.

7
00:00:35,070 --> 00:00:38,730
Two o of n linear time.

8
00:00:39,240 --> 00:00:45,030
This is a question that comes up again and again that I promise you, if you notice this pattern, it

9
00:00:45,030 --> 00:00:51,690
will be extremely useful for you in an interview, and undoubtedly you'll have an instance where you

10
00:00:51,690 --> 00:00:55,410
have to use it and follow this exact same step.

11
00:00:55,890 --> 00:01:03,660
In this section, we learn that hash tables have really fast lookups, but remember, we need a good

12
00:01:03,660 --> 00:01:05,340
collision resolution needed.

13
00:01:05,790 --> 00:01:11,940
Usually we don't need to worry about this because our language and computer underneath the hood take

14
00:01:11,940 --> 00:01:13,050
care of that for us.

15
00:01:13,680 --> 00:01:22,110
It allows us to do fast inserts and depending on the type of hash tables such as maps and JavaScript,

16
00:01:22,110 --> 00:01:30,690
we can have flexible keys instead of an array that has zero one, two, three, just numbered indexes.

17
00:01:31,730 --> 00:01:35,810
The downside with hash tables is that it is unordered.

18
00:01:35,840 --> 00:01:39,380
It's hard to really go through everything in order.

19
00:01:39,380 --> 00:01:42,500
And also it has slow key iteration.

20
00:01:42,500 --> 00:01:49,130
That is, if I want to grab all the keys from a hash table, I'll have to go through the entire memory

21
00:01:49,130 --> 00:01:52,250
space as we saw when we built our own hash table.

22
00:01:52,860 --> 00:01:54,810
Looking at the big cheat sheet.

23
00:01:55,700 --> 00:01:56,510
We can see that.

24
00:01:56,540 --> 00:02:04,790
Hash tables has a search insertion deletion of all of one, but in worst case due to collision there

25
00:02:04,790 --> 00:02:08,780
are some o of MN operations that could happen.

26
00:02:09,229 --> 00:02:11,090
And if we go to our.

27
00:02:11,810 --> 00:02:12,710
Mind map.

28
00:02:13,500 --> 00:02:16,440
We can now cross off hash tables off our list.

29
00:02:16,470 --> 00:02:18,930
We understand the big complexity.

30
00:02:19,770 --> 00:02:26,550
We also understand that with collisions, we might want to use something like link lists, which we'll

31
00:02:26,550 --> 00:02:28,080
talk about very shortly.

32
00:02:28,380 --> 00:02:31,170
In our exercise, we just simply used arrays.

33
00:02:32,010 --> 00:02:40,680
We also learned the idea that hash tables and interviews are usually useful for improving time complexity,

34
00:02:40,710 --> 00:02:42,840
especially of nested loops.

35
00:02:43,480 --> 00:02:49,810
The trade off being that we can have fast access but more memory.

36
00:02:51,210 --> 00:03:00,150
Going back to our question that we had a few lessons ago where we had to find the common item of two

37
00:03:00,150 --> 00:03:00,570
arrays.

38
00:03:00,570 --> 00:03:08,490
We had array one and array two, and we had to see if any of these arrays contain similar items.

39
00:03:08,760 --> 00:03:16,380
We had one that didn't, and the second version where X and X both arrays contained X, it would return.

40
00:03:16,380 --> 00:03:24,180
True, our first iteration of that exercise we had to use two for loops that were nested.

41
00:03:25,300 --> 00:03:30,370
So that created a times B complexity.

42
00:03:31,670 --> 00:03:40,910
However, using hash maps, we were able to just do one for loop and optimize this function.

43
00:03:41,720 --> 00:03:49,160
Like I said before, this is such a common pattern that we'll be talking about it later on in the course

44
00:03:49,160 --> 00:03:51,500
as well when we talk about dynamic programming.

45
00:03:52,920 --> 00:03:59,280
If we go back to our cheat sheet that I shared with you at the beginning of this course, we can now

46
00:03:59,280 --> 00:04:05,790
cross off a few things off the list that we haven't talked about in the good code checklist.

47
00:04:06,270 --> 00:04:13,230
We talked about the good use of data structures, when to use hash tables over perhaps arrays.

48
00:04:14,390 --> 00:04:21,230
The idea of code reuse and not repeating yourself is something we've been following and should be familiar

49
00:04:21,230 --> 00:04:22,100
to all of us.

50
00:04:23,200 --> 00:04:29,500
We also talked about modular code and making code more readable, which allows code to be more maintainable

51
00:04:29,500 --> 00:04:30,250
and testable.

52
00:04:30,550 --> 00:04:39,940
We talked about how usually in an interview we want to avoid the O and squared operations and we saw

53
00:04:39,940 --> 00:04:42,010
that we're able to do that with hash tables.

54
00:04:44,490 --> 00:04:48,720
But we did see that with a hash table.

55
00:04:48,720 --> 00:04:57,240
We had to increase our space complexity to o of MN because we created this new variable that keeps track

56
00:04:57,330 --> 00:04:59,860
of all the items in the array.

57
00:04:59,880 --> 00:05:01,440
So that is the trade off.

58
00:05:03,060 --> 00:05:05,580
And then we can cross off a few heuristics.

59
00:05:05,580 --> 00:05:13,110
For those who don't know, heuristics are kind of like rules or simple tricks that are going to come

60
00:05:13,110 --> 00:05:16,620
up over and over and over that you can use in an interview.

61
00:05:16,950 --> 00:05:19,290
Hash maps or hash tables.

62
00:05:20,090 --> 00:05:23,060
Are usually the answer to improve time complexity.

63
00:05:23,360 --> 00:05:24,860
Again, hash tables.

64
00:05:25,690 --> 00:05:28,060
Are some of the best way to optimize your code.

65
00:05:28,780 --> 00:05:35,230
And looking at time versus space trade off, sometimes storing extra state and memory like we did with

66
00:05:35,230 --> 00:05:38,440
hash tables can help the time or the runtime.

67
00:05:39,100 --> 00:05:41,720
And then finally, space time trade offs.

68
00:05:41,740 --> 00:05:44,830
Hash tables usually solve this a lot of the time.

69
00:05:45,970 --> 00:05:50,710
You use more space, but you can get a time optimization to the process.

70
00:05:52,160 --> 00:05:57,800
I know we've only talked about two data structures, but I think these two are the most important.

71
00:05:58,430 --> 00:06:02,000
Moving forward, we're going to use them to learn about others.

72
00:06:02,240 --> 00:06:03,620
Good job getting this far.

73
00:06:03,650 --> 00:06:04,970
Take a nice little break.

74
00:06:04,970 --> 00:06:07,820
Have some coffee and I'll see you in the next video.

75
00:06:08,300 --> 00:06:08,870
Bye bye.

