WEBVTT
1
00:00:00.730 --> 00:00:07.930
Big O says which function, algorithm or code is best.

2
00:00:07.960 --> 00:00:14.740
We learn that when it comes to good code, we're concerned about readability and scalability and Big

3
00:00:14.740 --> 00:00:19.090
O allows us to measure the idea of scalable code.

4
00:00:19.920 --> 00:00:21.810
And why do we care?

5
00:00:22.020 --> 00:00:26.820
It's because there is no such thing as a free lunch.

6
00:00:26.850 --> 00:00:29.950
You save time and money for a company.

7
00:00:29.970 --> 00:00:31.290
You're a superstar.

8
00:00:31.500 --> 00:00:38.070
Knowing how much time your code takes, how much memory it uses, is very, very critical.

9
00:00:38.100 --> 00:00:42.420
Those are expensive things for a company or a product.

10
00:00:42.510 --> 00:00:47.820
Now, Big O is a very important concept that you won't find in your day to day job.

11
00:00:47.910 --> 00:00:51.660
But it's something that should always be in the back of your mind.

12
00:00:51.690 --> 00:00:56.820
And good developers and engineers always have this knowledge.

13
00:00:57.270 --> 00:01:00.840
That is why it is such a popular topic during interviews.

14
00:01:01.230 --> 00:01:06.480
Big O is used to describe how efficient we can run our code.

15
00:01:06.510 --> 00:01:13.230
It saves companies a lot of money if people they hire know how to write efficient code.

16
00:01:13.230 --> 00:01:22.470
And in this section we learned about the idea of time complexity and space complexity, how we can use

17
00:01:22.470 --> 00:01:29.790
Big O to measure both things, but each one is a trade off between the other and big O describes the

18
00:01:29.790 --> 00:01:32.340
upper bound of our estimates.

19
00:01:32.640 --> 00:01:36.300
We're always looking at the worst case scenario.

20
00:01:36.450 --> 00:01:43.110
We want to be pessimistic and say, what is the worst case scenario here with our code so we can be

21
00:01:43.110 --> 00:01:44.610
prepared when the time comes.

22
00:01:44.640 --> 00:01:47.970
Now, time, complexity and space complexity.

23
00:01:48.090 --> 00:01:57.730
Time is how long it takes the algorithm to run, and space is the memory that is required by the algorithm.

24
00:01:57.750 --> 00:02:04.080
The important thing that we learned here is that big go is about how you can scale.

25
00:02:04.410 --> 00:02:14.490
It doesn't necessarily mean that o n is better than zero and squared because scalability wasn't the

26
00:02:14.490 --> 00:02:15.170
only factor.

27
00:02:15.180 --> 00:02:15.660
Right?

28
00:02:15.690 --> 00:02:19.950
Readability is something that we are concerned with as well.

29
00:02:20.070 --> 00:02:24.720
Sometimes readability may be matters more than scalability.

30
00:02:25.530 --> 00:02:30.960
Maybe time complexity is less important than space complexity.

31
00:02:31.680 --> 00:02:35.340
And that's something that you want to be careful of now with this newfound knowledge.

32
00:02:35.370 --> 00:02:40.010
Premature optimization can be the root of all evil.

33
00:02:40.020 --> 00:02:42.540
It's a famous quote that a lot of developers know.

34
00:02:42.660 --> 00:02:51.300
Sometimes optimizing for time or space can negatively impact the readability of code.

35
00:02:51.810 --> 00:02:57.150
So if you're working at a young startup, for example, it might be more important for you to write

36
00:02:57.150 --> 00:03:02.250
code that's easy to ship and perhaps easy to understand later.

37
00:03:02.250 --> 00:03:08.760
Perhaps not take as much time to write the code and think about the code and its implications for long

38
00:03:08.760 --> 00:03:14.490
term, because maybe the startup has limited budget and needs things done fast.

39
00:03:15.060 --> 00:03:18.690
That doesn't mean startups don't care about Big O analysis.

40
00:03:18.900 --> 00:03:26.820
A great engineer at a startup or at a big company knows how to strike the right balance between runtime

41
00:03:26.820 --> 00:03:29.530
space and, of course, readability.

42
00:03:29.550 --> 00:03:36.540
The thing to keep in mind is that data needs to be sufficiently big to talk about big O.

43
00:03:36.540 --> 00:03:37.800
It's about scaling.

44
00:03:38.070 --> 00:03:46.440
If your function is linear time, but the input is always, let's say, seven items, then the linear

45
00:03:46.440 --> 00:03:52.080
time algorithm might be better than the constant time algorithm.

46
00:03:53.180 --> 00:03:56.210
So it really, really depends on your situation.

47
00:03:57.330 --> 00:04:01.830
I introduced Big O here because we're going to be using it throughout this course.

48
00:04:01.830 --> 00:04:07.710
And as we learn more about data structures and algorithms, we're going to learn more about Big O and

49
00:04:07.710 --> 00:04:11.520
some other things we saw in this graph that we haven't talked about.

50
00:04:11.790 --> 00:04:18.630
But I hope you now look at a code differently and you had a few aha moments throughout this section.

51
00:04:19.310 --> 00:04:26.150
It's certainly my favorite section and a great topic that really made me a better engineer once I learned

52
00:04:26.150 --> 00:04:26.750
this topic.

53
00:04:26.750 --> 00:04:28.580
So I hope it did for you as well.

54
00:04:28.760 --> 00:04:32.270
At the end of this all, you have a way to look at code differently.

55
00:04:32.270 --> 00:04:35.510
And when someone says, Hey, how good is my code?

56
00:04:35.540 --> 00:04:39.800
You have a nice new way of looking at things and measuring things.

57
00:04:40.610 --> 00:04:41.750
I'll see you in the next one.

