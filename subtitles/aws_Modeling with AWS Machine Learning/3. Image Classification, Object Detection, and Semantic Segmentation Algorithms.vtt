WEBVTT
1
00:00:00.940 --> 00:00:04.220
[Autogenerated] Image Classifications algorithm is a super ways

2
00:00:04.220 --> 00:00:08.540
learning algorithm that uses convolution neural network,

3
00:00:08.540 --> 00:00:14.340
and it can be used both for binary on multi class classification.

4
00:00:14.340 --> 00:00:20.560
Image classifications supports both record eyeball on image formats like JPEG

5
00:00:20.560 --> 00:00:25.820
and PNG types in file more and only recordable in pipe.

6
00:00:25.820 --> 00:00:31.650
More Amazon sage maker recommends using GPU like API to or

7
00:00:31.650 --> 00:00:37.040
Petri during the training face on CPU, such as a C four.

8
00:00:37.040 --> 00:00:40.980
During the inference face image classifications can

9
00:00:40.980 --> 00:00:43.140
be run in two different modes.

10
00:00:43.140 --> 00:00:46.740
First one is a full training mode in full training,

11
00:00:46.740 --> 00:00:51.040
more random weights error used during the training process.

12
00:00:51.040 --> 00:00:55.230
Second one is a transfer learning more where the network is

13
00:00:55.230 --> 00:00:59.820
initialized with pre trained weights on the final,

14
00:00:59.820 --> 00:01:04.540
fully connected layer is initialized with random mates.

15
00:01:04.540 --> 00:01:06.660
Since its uses a pre trained data,

16
00:01:06.660 --> 00:01:11.940
even a smaller dataset is enough for the training process.

17
00:01:11.940 --> 00:01:18.340
Image classifications reports accuracy as metric during the training process.

18
00:01:18.340 --> 00:01:21.910
The number off output classes on the number of training samples in

19
00:01:21.910 --> 00:01:26.440
the input dataset are two require hyper parameters.

20
00:01:26.440 --> 00:01:29.240
Let's jump into the demo and see how to implement

21
00:01:29.240 --> 00:01:32.640
image classifications algorithm.

22
00:01:32.640 --> 00:01:38.450
In this algorithm, we will be using Caltech to 56 dataset to begin with.

23
00:01:38.450 --> 00:01:42.260
Let's get the Docker image from the PCR using get image.

24
00:01:42.260 --> 00:01:46.940
You are a matter in the data preparation phase.

25
00:01:46.940 --> 00:01:52.680
Training on validation data are downloaded and uploaded to

26
00:01:52.680 --> 00:01:59.150
correspondent S3 buckets for the initial training we're using.

27
00:01:59.150 --> 00:02:07.710
API, to instance, on file mode, is being used to read the data.

28
00:02:07.710 --> 00:02:12.250
Let's look at the hyper parameters on the depth off the network,

29
00:02:12.250 --> 00:02:19.940
they said to 18 on the number of training epochs is said to 10.

30
00:02:19.940 --> 00:02:26.540
Then the input channels error set up that I've needed for the training purposes.

31
00:02:26.540 --> 00:02:28.340
For incremental training,

32
00:02:28.340 --> 00:02:33.440
we need to use the pre trained model as we discussed before.

33
00:02:33.440 --> 00:02:37.440
So, along with the train on Validation Channel,

34
00:02:37.440 --> 00:02:42.640
a new model input channel needs to be included.

35
00:02:42.640 --> 00:02:47.250
Then an estimator object is created and required.

36
00:02:47.250 --> 00:02:54.240
Hyper parameters is sick like we did in the initial training.

37
00:02:54.240 --> 00:02:58.040
The training process is restarted.

38
00:02:58.040 --> 00:03:05.540
Once the training is completed, the trained model is ready for deployment.

39
00:03:05.540 --> 00:03:11.040
During in front stage, you need to download a test image,

40
00:03:11.040 --> 00:03:17.340
convert that into a bike array before using it for production.

41
00:03:17.340 --> 00:03:20.940
Object detection is a supervised learning algorithm,

42
00:03:20.940 --> 00:03:25.140
and it uses a single deep neural network.

43
00:03:25.140 --> 00:03:32.140
It takes images as input on identifies all the objects in that image.

44
00:03:32.140 --> 00:03:34.830
The object is then categorized into one off the

45
00:03:34.830 --> 00:03:37.440
classes in a specified collection,

46
00:03:37.440 --> 00:03:43.340
along with a confidence score that it belongs to that specific category,

47
00:03:43.340 --> 00:03:45.540
just like image classification.

48
00:03:45.540 --> 00:03:51.080
Object Detection algorithm uses both record iOS on image format like JPEG

49
00:03:51.080 --> 00:03:57.140
and PNG in file mode on record arrival in pipe more.

50
00:03:57.140 --> 00:04:03.700
Each image needs a corresponding JSON file for an addition purposes on one off.

51
00:04:03.700 --> 00:04:07.640
The important requirement is that the JSON file name needs to

52
00:04:07.640 --> 00:04:12.240
be the same name as its corresponding image.

53
00:04:12.240 --> 00:04:17.370
Amazon Sage Maker recommends using GPU like API to our API.

54
00:04:17.370 --> 00:04:23.340
Three instances for training on CPU, such as Psi Phi on M fi.

55
00:04:23.340 --> 00:04:26.180
I'll GPU instance, at a speed to R P.

56
00:04:26.180 --> 00:04:30.140
Three for the inference purpose.

57
00:04:30.140 --> 00:04:33.340
The training can be performed on full training mode,

58
00:04:33.340 --> 00:04:37.470
our transfer learning more in full training mode.

59
00:04:37.470 --> 00:04:42.890
Random weights are used and pre trained data will be used in transfer.

60
00:04:42.890 --> 00:04:47.410
Learning more object detection uses main average position as

61
00:04:47.410 --> 00:04:50.240
the metric during the training process.

62
00:04:50.240 --> 00:04:51.780
Number of output classes,

63
00:04:51.780 --> 00:04:57.540
a number of training samples in the input dataset the required hyper parameters.

64
00:04:57.540 --> 00:05:02.640
Let's quickly see how to implement object detection algorithm.

65
00:05:02.640 --> 00:05:06.200
The sample notebook shows how to leverage previously

66
00:05:06.200 --> 00:05:10.140
claimed model to improve the model quality,

67
00:05:10.140 --> 00:05:15.240
and Paschal walked dataset is being used for this purpose.

68
00:05:15.240 --> 00:05:21.740
To begin with, let's get their Docker image off object detection from PCR.

69
00:05:21.740 --> 00:05:27.530
In the data preparation face, the data is downloaded unconverted to the record I.

70
00:05:27.530 --> 00:05:30.340
WilPharma.

71
00:05:30.340 --> 00:05:36.040
The data is then uploaded to training on valuation channels, respectively.

72
00:05:36.040 --> 00:05:37.940
For the initial training,

73
00:05:37.940 --> 00:05:42.720
the training is performed on API three Instance On file.

74
00:05:42.720 --> 00:05:48.980
More operation is being used on a resonant 50 is used

75
00:05:48.980 --> 00:05:53.140
as a base network with five a box.

76
00:05:53.140 --> 00:05:58.740
The input channels are set up for training a new validation

77
00:05:58.740 --> 00:06:01.940
to start a new in criminal training job.

78
00:06:01.940 --> 00:06:06.030
Another estimated job is created on the requirement is that we

79
00:06:06.030 --> 00:06:11.240
need to use the same based network algorithm.

80
00:06:11.240 --> 00:06:16.140
They use the pre trained model along with the train on Validation Channel.

81
00:06:16.140 --> 00:06:22.840
A new model channel needs to be added by setting the right content IT please pay

82
00:06:22.840 --> 00:06:27.940
attention that the content type is set to sage maker model.

83
00:06:27.940 --> 00:06:30.040
The model can then be deployed.

84
00:06:30.040 --> 00:06:33.940
Once this incremental training completes,

85
00:06:33.940 --> 00:06:37.270
you can then download the image that the Al Qaeda hasn't seen

86
00:06:37.270 --> 00:06:43.640
before and use it to check the prediction reasons.

87
00:06:43.640 --> 00:06:48.120
Semantic segmentation algorithm is primarily used in computer vision

88
00:06:48.120 --> 00:06:55.340
applications like self driving cars on medical imaging diagnostics.

89
00:06:55.340 --> 00:07:01.440
This is a progression from chorus object detection to fine grained detection.

90
00:07:01.440 --> 00:07:03.750
Though the origins are in classifications,

91
00:07:03.750 --> 00:07:09.740
this algorithm goes one more level deeper into fine grained detection.

92
00:07:09.740 --> 00:07:13.740
Unlike image classifications that classifies an image,

93
00:07:13.740 --> 00:07:17.710
our object detection that was able to detect and classify and object in an

94
00:07:17.710 --> 00:07:24.200
image semantic segmentation provides a fine grain pixel level approach to solve

95
00:07:24.200 --> 00:07:28.240
business problems in the field of a computer vision.

96
00:07:28.240 --> 00:07:33.440
It accomplishes this by using a fundamental technique called tagging,

97
00:07:33.440 --> 00:07:37.590
where every pixel in an image with a class level is

98
00:07:37.590 --> 00:07:41.740
tagged against a pre defensive of classes.

99
00:07:41.740 --> 00:07:44.110
Since this algorithm works with a pixel level,

100
00:07:44.110 --> 00:07:47.620
it not only can identify the object but also can

101
00:07:47.620 --> 00:07:50.920
identify the shapes off the option.

102
00:07:50.920 --> 00:07:54.940
This is built using Apache mxnet framework,

103
00:07:54.940 --> 00:07:59.940
and it provides you with a choice off three built in algorithms.

104
00:07:59.940 --> 00:08:03.940
You can use fully convolution URL network algorithm,

105
00:08:03.940 --> 00:08:11.040
pyramid seen parsing algorithm, our deep lab Vetri al got to.

106
00:08:11.040 --> 00:08:14.460
It supports recordable on augmented manifest image

107
00:08:14.460 --> 00:08:18.140
farmer by the training in pipe more.

108
00:08:18.140 --> 00:08:22.080
The recommendation is to use GPU instances only,

109
00:08:22.080 --> 00:08:27.660
like P two or P three during training on CPU instances such as Psi Phi and M

110
00:08:27.660 --> 00:08:34.440
Fi on GPU Instances such speed to are Petri for inference.

111
00:08:34.440 --> 00:08:38.900
Intersection Over Union, also called us Jaccard Index is what,

112
00:08:38.900 --> 00:08:44.340
after commonly used metric in the field of semantic segmentation.

113
00:08:44.340 --> 00:08:48.190
Number of outward classes on the number of training samples in the

114
00:08:48.190 --> 00:08:52.340
input dataset I'll required hyper parameters.

115
00:08:52.340 --> 00:08:56.700
Let's jump into a Jupyter notebook and learn how to TrainSignal tae shin

116
00:08:56.700 --> 00:09:02.330
algorithm in sage maker using the F c an algorithm on using the Paschal

117
00:09:02.330 --> 00:09:09.080
walk dataset once again get image you are I is used to fetch this

118
00:09:09.080 --> 00:09:16.220
algorithm from the container registry w get is being used to download the

119
00:09:16.220 --> 00:09:23.110
error a source This algorithm will need four input channels two input

120
00:09:23.110 --> 00:09:27.860
channels for train on validation on to more to include their

121
00:09:27.860 --> 00:09:31.240
corresponding annotation.

122
00:09:31.240 --> 00:09:36.580
This data is then uploaded to the S3 buckets and output location is

123
00:09:36.580 --> 00:09:42.440
set up in S3 that will hold the model output.

124
00:09:42.440 --> 00:09:47.450
Next an estimator object is created and Petri instantiate

125
00:09:47.450 --> 00:09:51.640
is being used for the training process.

126
00:09:51.640 --> 00:09:55.220
Then quarter are the backbone is a CNN using

127
00:09:55.220 --> 00:10:01.840
resonant 50 and algorithm is FC error.

128
00:10:01.840 --> 00:10:04.940
Once all the required hyper parameters is said,

129
00:10:04.940 --> 00:10:09.390
you can call the fit method to begin the training process on.

130
00:10:09.390 --> 00:10:10.940
Once it is completed,

131
00:10:10.940 --> 00:10:18.440
you can deploy the trained model on this can be used for in France purposes.

132
00:10:18.440 --> 00:10:20.740
During the influence face,

133
00:10:20.740 --> 00:10:31.000
you can download the image that is not used in the training face, and this needs to be converted to a bi tary before passing it to the predictor.

