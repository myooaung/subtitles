WEBVTT
1
00:00:01.310 --> 00:00:07.140
[Autogenerated] let me click Run to kickstart the automated tuning job.

2
00:00:07.140 --> 00:00:11.840
Let me switch back to Sage maker console.

3
00:00:11.840 --> 00:00:17.340
Let me click the tuning job that is currently in progress.

4
00:00:17.340 --> 00:00:23.140
You can see there are currently two jobs that are in progress State

5
00:00:23.140 --> 00:00:30.970
Let me select the first one Click on view history and you can see

6
00:00:30.970 --> 00:00:35.170
the instances are already prepared and it is currently downloading

7
00:00:35.170 --> 00:00:39.700
the data under algorithm.

8
00:00:39.700 --> 00:00:42.260
The instants type count on the input.

9
00:00:42.260 --> 00:00:45.540
More are specified.

10
00:00:45.540 --> 00:00:50.680
The S3 bucket You are a for training on validation data are under input Data

11
00:00:50.680 --> 00:00:57.740
configuration metrics list all the training on valuation metrics that this

12
00:00:57.740 --> 00:01:04.930
algorithm emits output data configuration list the output path after S3 bucket

13
00:01:04.930 --> 00:01:09.940
where the model will be uploaded eventually.

14
00:01:09.940 --> 00:01:11.320
Hyper parameter section.

15
00:01:11.320 --> 00:01:16.440
Let's all the hyper parameters that are specific to this run.

16
00:01:16.440 --> 00:01:22.870
I would like you to pay close attention to OData Alfa Men Child,

17
00:01:22.870 --> 00:01:27.300
wait on max Depth That error selected by the

18
00:01:27.300 --> 00:01:31.440
automated tuning process For this run,

19
00:01:31.440 --> 00:01:36.080
I clicked the history again at the top and looks like this run is

20
00:01:36.080 --> 00:01:42.440
completed and can see an explicit link to the model file.

21
00:01:42.440 --> 00:01:46.260
There is an option as well to create a model directly from

22
00:01:46.260 --> 00:01:50.750
this training job and right underneath the training time

23
00:01:50.750 --> 00:01:55.240
unavailable time are listed as well.

24
00:01:55.240 --> 00:01:57.930
Now that the two training jobs error completed,

25
00:01:57.930 --> 00:02:02.740
you can see the two more jobs have started.

26
00:02:02.740 --> 00:02:07.540
Let me click on the tab training job definition,

27
00:02:07.540 --> 00:02:12.140
this list, all the input data output data,

28
00:02:12.140 --> 00:02:17.040
the resource conflict that we defined in the notebook,

29
00:02:17.040 --> 00:02:21.790
a tab tuning job configuration lists all the concurrent job

30
00:02:21.790 --> 00:02:26.040
settings that we define in the notebook.

31
00:02:26.040 --> 00:02:27.770
I'm going to pass this on.

32
00:02:27.770 --> 00:02:28.510
Come back.

33
00:02:28.510 --> 00:02:33.240
Once all the 10 training jobs are completed,

34
00:02:33.240 --> 00:02:39.540
you can see it took totally 14 minutes to complete all the 10 runs.

35
00:02:39.540 --> 00:02:43.240
Let me select the tuning job.

36
00:02:43.240 --> 00:02:48.640
Click on Best training job and you can see the A U C.

37
00:02:48.640 --> 00:02:52.290
Value off the best training job that is selected by

38
00:02:52.290 --> 00:02:55.740
the automated tuning process.

39
00:02:55.740 --> 00:02:59.150
Right underneath is the display off all the hyper parameter

40
00:02:59.150 --> 00:03:03.040
values that are part of this training job.

41
00:03:03.040 --> 00:03:05.040
Let me select the training job,

42
00:03:05.040 --> 00:03:08.750
and it lists all the 10 training jobs under corresponding

43
00:03:08.750 --> 00:03:13.330
metric value on the training duration.

44
00:03:13.330 --> 00:03:20.310
Let me go to CloudWatch console to view the algorithm on instance metrics,

45
00:03:20.310 --> 00:03:26.770
let me enter the training job name you can see that each cleaning job

46
00:03:26.770 --> 00:03:29.710
is the name off the hyper parameter tuning job.

47
00:03:29.710 --> 00:03:33.740
Suffolk S3 by its run number.

48
00:03:33.740 --> 00:03:39.740
I would like to filter it to display one Lee The validation metric.

49
00:03:39.740 --> 00:03:43.520
Let me select all the jobs and can see a visual

50
00:03:43.520 --> 00:03:45.730
representation off all the A U C.

51
00:03:45.730 --> 00:03:49.340
Values off each training job,

52
00:03:49.340 --> 00:03:53.360
you can see the one of the top that had better a you see value,

53
00:03:53.360 --> 00:03:57.540
which was selected as the best training job.

54
00:03:57.540 --> 00:04:03.140
Now I would like to see all the instance metrics for all these 10 jobs,

55
00:04:03.140 --> 00:04:10.110
let me filter once again by the tuning jobs name on the CB utilization.

56
00:04:10.110 --> 00:04:13.340
Let me select all the jobs.

57
00:04:13.340 --> 00:04:19.840
Looks like one off the job took a higher CPU compared to all the other jobs.

58
00:04:19.840 --> 00:04:25.010
Let me repeat the same for memory utilization and I can see a visual

59
00:04:25.010 --> 00:04:32.530
chart off all the values I'm going to attach the entire notebook that

60
00:04:32.530 --> 00:04:37.140
they built together under Exercise File section.

61
00:04:37.140 --> 00:04:42.340
You will see the notebook on the CSV file that we used in the demo.

62
00:04:42.340 --> 00:04:46.330
If you're planning to use the CSV from your local instance,

63
00:04:46.330 --> 00:04:50.840
you need to change the download location accordingly.

64
00:04:50.840 --> 00:04:54.450
Let me also show you how to upload this notebook to your sage maker.

65
00:04:54.450 --> 00:05:00.640
Instance, I just logged into my notebook instance.

66
00:05:00.640 --> 00:05:06.560
Click upload and select the notebook file to upload the

67
00:05:06.560 --> 00:05:10.640
notebook to your specific instance.

68
00:05:10.640 --> 00:05:13.480
We covered a lot of ground in this course.

69
00:05:13.480 --> 00:05:16.840
Let's quickly recap what we learned.

70
00:05:16.840 --> 00:05:20.210
They started this course by learning about the business case that

71
00:05:20.210 --> 00:05:24.950
are best suited for machine learning and understood how to map a

72
00:05:24.950 --> 00:05:26.840
business problem to your mission.

73
00:05:26.840 --> 00:05:28.640
Learning problem.

74
00:05:28.640 --> 00:05:32.740
We saw various built in algorithms offered by sage maker,

75
00:05:32.740 --> 00:05:36.330
its implementation details that addresses both

76
00:05:36.330 --> 00:05:40.640
supervised on unsupervised problems.

77
00:05:40.640 --> 00:05:43.440
Later, we launched a sage maker notebook.

78
00:05:43.440 --> 00:05:47.540
Instance, downloaded a banking dataset,

79
00:05:47.540 --> 00:05:51.640
used extra boost algorithm and train the model.

80
00:05:51.640 --> 00:05:53.020
And finally, you, sir,

81
00:05:53.020 --> 00:05:58.230
how to use sage makers automated hyper parameter tuning to identify the

82
00:05:58.230 --> 00:06:09.000
training job that provides the best object in metric and use CloudWatch console to monitor algorithm on instants metrics

