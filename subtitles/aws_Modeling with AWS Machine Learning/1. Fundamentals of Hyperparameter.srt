1
00:00:01,840 --> 00:00:07,080
[Autogenerated] Welcome to this module on tune ML models In this module,

2
00:00:07,080 --> 00:00:11,440
we get a detailed look at how sage maker automated hyper parameter

3
00:00:11,440 --> 00:00:15,740
tuning works before looking at the tuning process.

4
00:00:15,740 --> 00:00:22,740
Let's clear the basics on understand parameters and hyper parameters.

5
00:00:22,740 --> 00:00:26,080
A model parameter is internal to the model on.

6
00:00:26,080 --> 00:00:28,610
It can be visualized as a conflagration.

7
00:00:28,610 --> 00:00:31,720
Variable whose value can be estimated,

8
00:00:31,720 --> 00:00:36,670
are derived from the data that we feed in these values.

9
00:00:36,670 --> 00:00:39,940
Error not set manually by the model developer,

10
00:00:39,940 --> 00:00:44,740
but they're required by the model while making predictions.

11
00:00:44,740 --> 00:00:49,850
The predicted value is saved along with a trained model on the accuracy off.

12
00:00:49,850 --> 00:00:55,640
The predicted value determines the optimal prediction off your model.

13
00:00:55,640 --> 00:00:59,340
The weights in an artificial neural network.

14
00:00:59,340 --> 00:01:04,940
The support letters in SPM, the coefficients in a linear regression,

15
00:01:04,940 --> 00:01:09,340
are some of the examples off a model parameter.

16
00:01:09,340 --> 00:01:13,820
Hyper parameters are external to the model on the values of hyper

17
00:01:13,820 --> 00:01:18,950
parameters are set before starting the training process they error

18
00:01:18,950 --> 00:01:21,420
independent to the data that is being trained on.

19
00:01:21,420 --> 00:01:26,440
These values do not change during the training process,

20
00:01:26,440 --> 00:01:29,890
since his values are not part of the final model.

21
00:01:29,890 --> 00:01:34,540
These values are not saved along with the model.

22
00:01:34,540 --> 00:01:38,340
The K values in Kenya's neighbors,

23
00:01:38,340 --> 00:01:42,440
the Learning rate for Training and URL network,

24
00:01:42,440 --> 00:01:47,220
the value off Lambda in lasso regression are some of the examples

25
00:01:47,220 --> 00:01:52,850
off model hyper parameter Tuning a hyper parameter is a process of

26
00:01:52,850 --> 00:01:57,530
finding the right combination of hyper parameters that delivers

27
00:01:57,530 --> 00:02:01,140
high position on accuracy.

28
00:02:01,140 --> 00:02:05,440
There are multiple strategies used in hyper parameter tuning,

29
00:02:05,440 --> 00:02:12,540
but grid search on random search are two popularly used methods.

30
00:02:12,540 --> 00:02:17,790
Another common strategy that is gaining more traction now is beige.

31
00:02:17,790 --> 00:02:21,040
In search in grid search,

32
00:02:21,040 --> 00:02:25,600
all the hyper parameter values are set up in a great fashion on.

33
00:02:25,600 --> 00:02:29,230
The model is strained for each combination on the

34
00:02:29,230 --> 00:02:33,040
accuracy of the model is direct.

35
00:02:33,040 --> 00:02:36,190
This is a resource intensive process on all the

36
00:02:36,190 --> 00:02:37,790
combinations of hyper parameters.

37
00:02:37,790 --> 00:02:43,540
Error evaluated before the model that performs the best is determined.

38
00:02:43,540 --> 00:02:47,820
The complexity of great searching increases as the number of hyper

39
00:02:47,820 --> 00:02:53,540
parameters increases in number in random search methods.

40
00:02:53,540 --> 00:02:57,940
The hyper parameters values are set up in a great fashion,

41
00:02:57,940 --> 00:03:04,640
but random combinations off hyper parameters are used to find the best solution.

42
00:03:04,640 --> 00:03:09,090
The number of iterations is set based on time on resource

43
00:03:09,090 --> 00:03:13,900
availability on this method has shown best results when the

44
00:03:13,900 --> 00:03:16,920
hyper parameters are fewer in number on,

45
00:03:16,920 --> 00:03:20,550
The underlying assumption is that not all hyper

46
00:03:20,550 --> 00:03:24,540
parameters are considered equally important.

47
00:03:24,540 --> 00:03:28,380
The problem with great on random searches are they're

48
00:03:28,380 --> 00:03:31,570
completely unaware off the results from the past.

49
00:03:31,570 --> 00:03:36,690
Evaluations on might end up spending valuable time on resource in

50
00:03:36,690 --> 00:03:41,940
searching for optimal hyper parameter values in wrong ranges.

51
00:03:41,940 --> 00:03:46,690
Base in Search, in contrast, keeps track of the past results,

52
00:03:46,690 --> 00:03:52,040
and it treats hyper parameter tuning like a regression problem.

53
00:03:52,040 --> 00:03:57,740
After testing the first set off randomly chosen hyper parameter values,

54
00:03:57,740 --> 00:04:02,040
the tuning process uses regression to test the next set off

55
00:04:02,040 --> 00:04:05,940
values while choosing the next set off values,

56
00:04:05,940 --> 00:04:10,820
The tuning job chooses a combination that resulted in the previously

57
00:04:10,820 --> 00:04:16,340
best trained job to improve performance incrementally.

58
00:04:16,340 --> 00:04:19,330
Let's look at the automated model tuning resource

59
00:04:19,330 --> 00:04:23,840
limits enforced by the sage maker.

60
00:04:23,840 --> 00:04:26,780
The number of hyper parameter tuning jobs that can be

61
00:04:26,780 --> 00:04:31,340
run parallel E is limited to 100.

62
00:04:31,340 --> 00:04:33,550
The maximum number off training jobs.

63
00:04:33,550 --> 00:04:38,490
Perl hyper parameter tuning job is 500 on the

64
00:04:38,490 --> 00:04:40,760
number off concurrent training jobs.

65
00:04:40,760 --> 00:04:46,340
Perl hyper parameter tuning job is limited to 10.

66
00:04:46,340 --> 00:04:50,140
The maximum number of hyper parameters that can be searched

67
00:04:50,140 --> 00:04:55,970
during a specific job is limited to 20 the maximum number

68
00:04:55,970 --> 00:04:58,080
off metrics that are defined.

69
00:04:58,080 --> 00:05:03,920
Perl hyper parameter tuning job cannot exceed 20 I'm.

70
00:05:03,920 --> 00:05:06,920
Finally, the maximum runtime off.

71
00:05:06,920 --> 00:05:13,240
A hyper parameter tuning job cannot exceed 30 days.

72
00:05:13,240 --> 00:05:19,640
Sage Maker recommends few best practices to follow during the tuning process.

73
00:05:19,640 --> 00:05:25,240
Those sage maker a loves you to use up to 20 hyper parameters in a tuning job.

74
00:05:25,240 --> 00:05:31,840
The recommendation is to use a much smaller number of hyper parameters.

75
00:05:31,840 --> 00:05:36,330
The range off the hyper parameters that you choose will also have a

76
00:05:36,330 --> 00:05:40,540
significant impact on the resource consumption.

77
00:05:40,540 --> 00:05:47,440
So it's recommended to use a much smaller range than a larger one.

78
00:05:47,440 --> 00:05:51,280
Converting a parameter scale from a linear to a log rhythm

79
00:05:51,280 --> 00:05:55,240
IQ is a very time consuming process.

80
00:05:55,240 --> 00:05:59,840
So if you know that hyper parameters should use log rhythmic scaling,

81
00:05:59,840 --> 00:06:03,090
you can convert it to yourself on mention it.

82
00:06:03,090 --> 00:06:06,140
During the configuration set up,

83
00:06:06,140 --> 00:06:12,540
a curing job improves one Lee after every successive rounds off experiments,

84
00:06:12,540 --> 00:06:15,410
so it's recommended to limit the number of training

85
00:06:15,410 --> 00:06:20,040
jobs that can be run concurrently.

86
00:06:20,040 --> 00:06:24,180
Sage maker also recommends enabling distributed training by

87
00:06:24,180 --> 00:06:29,530
training the jobs in multiple instances early,

88
00:06:29,530 --> 00:06:34,070
stopping is a process off terminating a training job when the

89
00:06:34,070 --> 00:06:38,970
object to metric computed by this job is significantly lawyer

90
00:06:38,970 --> 00:06:41,840
than the best training job.

91
00:06:41,840 --> 00:06:46,570
It helps reduce the compute time and helps you avoid the over

92
00:06:46,570 --> 00:06:51,640
fitting off the model to configure early stopping.

93
00:06:51,640 --> 00:06:55,660
You need to set the variable early stopping type to

94
00:06:55,660 --> 00:07:00,440
are two to during the conflagration process.

95
00:07:00,440 --> 00:07:05,180
After each epoch off training, sage maker gets the value off.

96
00:07:05,180 --> 00:07:10,890
The object to metric computes the median off the objective metric for

97
00:07:10,890 --> 00:07:15,540
all the previous training jobs up to the same epoch.

98
00:07:15,540 --> 00:07:20,540
And if the value off the object to metric is higher than the previous job,

99
00:07:20,540 --> 00:07:26,340
sage maker stops the current job to conserve computing resources.

100
00:07:26,340 --> 00:07:33,140
Some of the algorithms that support early stopping our linear learner x g boost.

101
00:07:33,140 --> 00:07:39,670
He made declassification object detection sequence to sequence on i p.

102
00:07:39,670 --> 00:07:42,440
Insights.

103
00:07:42,440 --> 00:07:47,030
Warm start to hyper parameter tuning job is a process off.

104
00:07:47,030 --> 00:07:52,740
Leveraging are reusing previously controlled training jobs.

105
00:07:52,740 --> 00:07:58,000
The results off the previous jobs are used to inform which combinations off

106
00:07:58,000 --> 00:08:03,140
hyper parameters are effective in the newly starting job.

107
00:08:03,140 --> 00:08:06,040
With the knowledge off previously tuned jobs,

108
00:08:06,040 --> 00:08:09,640
every current job don't need to start from the scratch,

109
00:08:09,640 --> 00:08:13,890
and it helps fast in the time it takes to identify the

110
00:08:13,890 --> 00:08:18,240
best hyper parameter combination.

111
00:08:18,240 --> 00:08:25,240
One starting help save significant time effort on computing resources and

112
00:08:25,240 --> 00:08:32,490
eventually save cost tuning jobs with Warm Start usually takes longer to

113
00:08:32,490 --> 00:08:41,000
start than standard tuning jobs because the results from the parent jobs needs to be loaded unstudied.

