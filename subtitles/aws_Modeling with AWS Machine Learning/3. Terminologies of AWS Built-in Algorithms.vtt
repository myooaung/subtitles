WEBVTT
1
00:00:00.840 --> 00:00:03.860
[Autogenerated] before we get into the specifics off Amazon Sage

2
00:00:03.860 --> 00:00:09.240
Maker Built in algorithms Let's build our foundation and understand

3
00:00:09.240 --> 00:00:13.640
common parameters used by these algorithms.

4
00:00:13.640 --> 00:00:20.240
A channel name is a named input source that a training algorithm can consume.

5
00:00:20.240 --> 00:00:23.330
Usually it's the string that represents the path to the

6
00:00:23.330 --> 00:00:26.940
directory that contains the input data.

7
00:00:26.940 --> 00:00:30.180
You can specify more than one input channels to specify.

8
00:00:30.180 --> 00:00:34.580
Both train and tested a source registry,

9
00:00:34.580 --> 00:00:38.940
part Amazon uses elastic container registry,

10
00:00:38.940 --> 00:00:40.230
also called E C.

11
00:00:40.230 --> 00:00:44.740
R, to actively maintain the built in algorithms.

12
00:00:44.740 --> 00:00:49.500
This is a fully managed Docker container where sage maker team actively

13
00:00:49.500 --> 00:00:55.240
updates the latest version off that specific algorithms.

14
00:00:55.240 --> 00:00:56.910
Input more.

15
00:00:56.910 --> 00:00:57.790
This is a reading.

16
00:00:57.790 --> 00:01:02.840
More to read the input data finally type.

17
00:01:02.840 --> 00:01:07.190
This is a file type off input data instantiate

18
00:01:07.190 --> 00:01:10.000
class instantiate Lasses specified.

19
00:01:10.000 --> 00:01:18.340
If the training more can use CPU are GPU are both distributed.

20
00:01:18.340 --> 00:01:23.940
If the algorithms can be Padley, run in a distributed in grandma.

21
00:01:23.940 --> 00:01:26.440
Let's take a look at the different file types that

22
00:01:26.440 --> 00:01:29.540
are supported by sage maker Text.

23
00:01:29.540 --> 00:01:30.440
Fine.

24
00:01:30.440 --> 00:01:34.760
A simple text file with one sentence per line that is

25
00:01:34.760 --> 00:01:40.890
separated by space CSV comma separated values.

26
00:01:40.890 --> 00:01:45.160
This is a simple file format to store tabular data on the

27
00:01:45.160 --> 00:01:50.040
requirement is that the first column must always be the labor

28
00:01:50.040 --> 00:01:53.090
JSON JavaScript Object rotation,

29
00:01:53.090 --> 00:01:57.950
which is a lightweight data exchange farmer record.

30
00:01:57.950 --> 00:01:59.440
Aibel.

31
00:01:59.440 --> 00:02:03.740
This is primarily used to exchange binary data formats.

32
00:02:03.740 --> 00:02:04.240
Here.

33
00:02:04.240 --> 00:02:08.160
The data is diverted into multiple chunks, called records.

34
00:02:08.160 --> 00:02:08.830
On each.

35
00:02:08.830 --> 00:02:16.040
A chunk is prevented by its length in bytes Parky.

36
00:02:16.040 --> 00:02:17.920
It's open source file format,

37
00:02:17.920 --> 00:02:23.940
where the data is stored in a column format instead off a typical roof format.

38
00:02:23.940 --> 00:02:27.920
This is highly preferred while processing larger quantities of

39
00:02:27.920 --> 00:02:33.240
data because off its storage on performance,

40
00:02:33.240 --> 00:02:37.840
there are two supported modes of operation to read the input data.

41
00:02:37.840 --> 00:02:41.660
First one is file mode in file mode.

42
00:02:41.660 --> 00:02:47.270
All the data is frustrated from your Amazon S3 storage to your training.

43
00:02:47.270 --> 00:02:48.340
Instance.

44
00:02:48.340 --> 00:02:52.690
Before the actual training is perform in, fight more.

45
00:02:52.690 --> 00:03:03.000
The data is streamed directly from the storage volume. Streaming data offers better performance compared to the file more operation

