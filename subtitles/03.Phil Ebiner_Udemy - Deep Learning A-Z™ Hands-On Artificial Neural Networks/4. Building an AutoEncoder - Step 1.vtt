WEBVTT
1
1

00:00:00.000  -->  00:00:02.720
<v Instructor>Hello, and welcome to the final round</v>
2

2

00:00:02.720  -->  00:00:06.310
of this deep learning journey, part 6, AutoEncoders.
3

3

00:00:06.310  -->  00:00:08.562
I'm super excited to get to this part because
4

4

00:00:08.562  -->  00:00:11.580
AutoEncoders are my personal favorites.
5

5

00:00:11.580  -->  00:00:14.207
And the reason is that there is this amazing contrast
6

6

00:00:14.207  -->  00:00:18.390
between their simplicity and what they're capable of.
7

7

00:00:18.390  -->  00:00:20.930
Because you're gonna see that we will solve
8

8

00:00:20.930  -->  00:00:24.360
this recommended system problem in a rather simple way
9

9

00:00:24.360  -->  00:00:27.040
and besides we will get excellent results.
10

10

00:00:27.040  -->  00:00:30.030
We will implement these AutoEncoders with PyTorch
11

11

00:00:30.030  -->  00:00:32.163
and you're gonna' see how it's going to be so easy
12

12

00:00:32.163  -->  00:00:35.288
to change the architecture of our AutoEncoders.
13

13

00:00:35.288  -->  00:00:37.673
This will be all very intuitive, we will implement
14

14

00:00:37.673  -->  00:00:39.590
these AutoEncoders from scratch
15

15

00:00:39.590  -->  00:00:41.740
but of course by using PyTorch.
16

16

00:00:41.740  -->  00:00:44.110
And I promise you at the end of these tutorials
17

17

00:00:44.110  -->  00:00:44.943
for the challenge,
18

18

00:00:44.943  -->  00:00:47.150
because there's going to be a challenge as usual,
19

19

00:00:47.150  -->  00:00:49.600
it is going to be kids stuff for you to try
20

20

00:00:49.600  -->  00:00:52.115
different architectures than the one we're going to use now
21

21

00:00:52.115  -->  00:00:54.085
and to try and improve your moral.
22

22

00:00:54.085  -->  00:00:58.520
Okay so let's do it, let's implement our AutoEncoders
23

23

00:00:58.520  -->  00:01:01.440
and let's try to beat our restricted Boltzmann machines
24

24

00:01:01.440  -->  00:01:03.610
that we made in the previous part.
25

25

00:01:03.610  -->  00:01:06.310
So the first we are gonna' do of course is set
26

26

00:01:06.310  -->  00:01:08.260
the right folder as working directory.
27

27

00:01:08.260  -->  00:01:10.327
So we'll go to file explorer and
28

28

00:01:10.327  -->  00:01:12.417
to our Deep Learning A-Z folder.
29

29

00:01:12.417  -->  00:01:16.200
Now we're still in volume 2 - Unsupervised Deep Learning
30

30

00:01:16.200  -->  00:01:19.220
and so now we have to go Part 6 - Auto Encoders
31

31

00:01:19.220  -->  00:01:23.086
here we go, and section 23 - Building an Auto Encoder.
32

32

00:01:23.086  -->  00:01:24.112
Perfect.
33

33

00:01:24.112  -->  00:01:25.810
And that's the right folder that
34

34

00:01:25.810  -->  00:01:27.640
we need to set as working directory.
35

35

00:01:27.640  -->  00:01:30.457
This folder contains the AutoEncoders Python File
36

36

00:01:30.457  -->  00:01:33.094
which is this one here so make sure to save it
37

37

00:01:33.094  -->  00:01:36.189
in this folder if you're making your own Python file.
38

38

00:01:36.189  -->  00:01:38.584
And then we have these two folders,
39

39

00:01:38.584  -->  00:01:42.984
each one corresponding to one data set of movie ratings.
40

40

00:01:42.984  -->  00:01:44.680
The first data set is the
41

41

00:01:44.680  -->  00:01:46.970
data set of one million movie ratings,
42

42

00:01:46.970  -->  00:01:50.430
which are all contained in this ratings.dat file
43

43

00:01:50.430  -->  00:01:52.460
and then we have the list of all the movies,
44

44

00:01:52.460  -->  00:01:55.010
the list of all the users, the training set
45

45

00:01:55.010  -->  00:01:58.190
and the test set so exactly like the previous part.
46

46

00:01:58.190  -->  00:02:00.310
And then we have this second folder
47

47

00:02:00.310  -->  00:02:03.191
which is actually the subset of ratings of this folder
48

48

00:02:03.191  -->  00:02:05.550
because it contains not one million ratings
49

49

00:02:05.550  -->  00:02:07.670
but one hundred thousand ratings.
50

50

00:02:07.670  -->  00:02:09.823
And so as in the previous part we will train
51

51

00:02:09.823  -->  00:02:13.620
our AutoEncoders with this data set.
52

52

00:02:13.620  -->  00:02:15.550
I'm choosing this data set to do the training
53

53

00:02:15.550  -->  00:02:17.810
because this one is a huge data set and
54

54

00:02:17.810  -->  00:02:21.490
might not work on certain machines due to memory problems.
55

55

00:02:21.490  -->  00:02:23.990
So I want to make sure everybody manages to train
56

56

00:02:23.990  -->  00:02:25.616
the AutoEncoders and therefore
57

57

00:02:25.616  -->  00:02:28.244
we're gonna take this data set.
58

58

00:02:28.244  -->  00:02:31.810
Alright now let's set this folder as working directory
59

59

00:02:31.810  -->  00:02:34.060
so we click on this tool button here
60

60

00:02:34.060  -->  00:02:37.380
and then set console working directory.
61

61

00:02:37.380  -->  00:02:40.000
Perfect. Alright first step done.
62

62

00:02:40.000  -->  00:02:41.990
Now we're going to import the libraries
63

63

00:02:41.990  -->  00:02:44.900
we will be using to implement our AutoEncoders
64

64

00:02:44.900  -->  00:02:47.890
and actually I've listed all these libraries here
65

65

00:02:47.890  -->  00:02:50.560
so that all the required imports are done
66

66

00:02:50.560  -->  00:02:52.570
and so that we don't have to worry about this.
67

67

00:02:52.570  -->  00:02:54.810
So there is numpy because of course
68

68

00:02:54.810  -->  00:02:56.470
we will be working with arrays.
69

69

00:02:56.470  -->  00:02:58.770
There is pandas to import the data set
70

70

00:02:58.770  -->  00:03:01.320
and create the train set and the test set.
71

71

00:03:01.320  -->  00:03:03.730
And then we have all the torch libraries
72

72

00:03:03.730  -->  00:03:07.054
so for example this nn is the module of torch
73

73

00:03:07.054  -->  00:03:09.640
to implement neural networks.
74

74

00:03:09.640  -->  00:03:11.550
This is for the parallel computations.
75

75

00:03:11.550  -->  00:03:13.170
This is for the optimizers.
76

76

00:03:13.170  -->  00:03:14.900
These are the tools that we will use.
77

77

00:03:14.900  -->  00:03:17.700
And this is for stochastic rate in the set.
78

78

00:03:17.700  -->  00:03:21.200
So let's import them all, so I'm going to select all of them
79

79

00:03:21.200  -->  00:03:23.842
and let's press command or control plus enter to execute.
80

80

00:03:23.842  -->  00:03:27.125
Here we go, now all the libraries, classes and functions
81

81

00:03:27.125  -->  00:03:30.820
are well imported and so we are ready to start.
82

82

00:03:30.820  -->  00:03:33.700
So now what we are going to do is import the data set
83

83

00:03:33.700  -->  00:03:37.260
and so if you followed part five on Boltzmann machines
84

84

00:03:37.260  -->  00:03:40.220
well feel free to skip this tutorial now and go to the next
85

85

00:03:40.220  -->  00:03:43.170
one because basically now we will importing the same
86

86

00:03:43.170  -->  00:03:45.854
data set as in the previous part.
87

87

00:03:45.854  -->  00:03:47.876
Okay so let's start with the first one.
88

88

00:03:47.876  -->  00:03:49.510
The first data set we are going
89

89

00:03:49.510  -->  00:03:51.686
to import is all our movies.
90

90

00:03:51.686  -->  00:03:54.794
So let's do it, all our movies are in this file
91

91

00:03:54.794  -->  00:03:58.640
movies.dat and so let's create a new variable
92

92

00:03:58.640  -->  00:04:00.750
that will contain all our movies.
93

93

00:04:00.750  -->  00:04:04.020
So I'm calling it movies, then equal, and then
94

94

00:04:04.020  -->  00:04:06.330
we're gonna' use pandas of course which has
95

95

00:04:06.330  -->  00:04:10.682
the shortcut pd then the read underscore csv function.
96

96

00:04:10.682  -->  00:04:13.240
Here we go, and now there is gonna'
97

97

00:04:13.240  -->  00:04:15.420
be quite some adventure because the data set
98

98

00:04:15.420  -->  00:04:17.710
is not that simple and we will need to use
99

99

00:04:17.710  -->  00:04:20.670
some of the arguments here to import it well.
100

100

00:04:20.670  -->  00:04:24.160
So first what we need to do is to find the path
101

101

00:04:24.160  -->  00:04:26.493
that contains the data set and so this
102

102

00:04:26.493  -->  00:04:29.589
whole folder here is the working directory
103

103

00:04:29.589  -->  00:04:32.970
but then we need to access this folder because
104

104

00:04:32.970  -->  00:04:36.070
this is a folder that contains this movies.file
105

105

00:04:36.070  -->  00:04:40.660
and so the first element of the path is ML-1M.
106

106

00:04:40.660  -->  00:04:42.670
So that's what we need to specify first
107

107

00:04:42.670  -->  00:04:47.670
so ML-1M and then slash and then we just
108

108

00:04:48.620  -->  00:04:53.027
need to type the name of the file which is Movies.dat.
109

109

00:04:54.710  -->  00:04:58.430
Okay perfect that's the first argument now second one.
110

110

00:04:58.430  -->  00:05:00.340
So the second one is the separator
111

111

00:05:00.340  -->  00:05:02.920
the default separator is a comma and that works
112

112

00:05:02.920  -->  00:05:05.233
for csv file you know simple csv files where
113

113

00:05:05.233  -->  00:05:08.620
the features are separated by commas
114

114

00:05:08.620  -->  00:05:10.560
but here that's not the case because you know
115

115

00:05:10.560  -->  00:05:12.840
we have the titles of the movies and some of them
116

116

00:05:12.840  -->  00:05:15.460
contain commas inside the title
117

117

00:05:15.460  -->  00:05:18.410
so we can not use commas to separate the movies
118

118

00:05:18.410  -->  00:05:20.670
because then we could have a same movie in
119

119

00:05:20.670  -->  00:05:23.230
two different columns and therefore the separator
120

120

00:05:23.230  -->  00:05:26.559
is not a comma but a double colon, like this.
121

121

00:05:26.559  -->  00:05:29.810
If you open the movies.dat file you will see
122

122

00:05:29.810  -->  00:05:32.300
that the movies are separated by their ratings
123

123

00:05:32.300  -->  00:05:35.860
and their other features by a double colon like this.
124

124

00:05:35.860  -->  00:05:38.210
So that is the separator and therefore we need to add
125

125

00:05:38.210  -->  00:05:42.826
sep = and we have to input these double colons in quotes.
126

126

00:05:42.826  -->  00:05:44.570
Like this.
127

127

00:05:44.570  -->  00:05:46.330
Then comma and third parameter.
128

128

00:05:46.330  -->  00:05:48.750
The third parameter is the header because
129

129

00:05:48.750  -->  00:05:51.977
actually the file movies.dat doesn't contain
130

130

00:05:51.977  -->  00:05:54.740
headers, that is names of columns.
131

131

00:05:54.740  -->  00:05:57.010
And therefore we need to specify this because
132

132

00:05:57.010  -->  00:05:59.111
the default value of header is not none
133

133

00:05:59.111  -->  00:06:01.620
that is the case where there is no column names
134

134

00:06:01.620  -->  00:06:04.310
but infer and therefore we need to specify
135

135

00:06:04.310  -->  00:06:06.870
that there is no column names and
136

136

00:06:06.870  -->  00:06:11.772
to do this we put header = None, alright.
137

137

00:06:11.772  -->  00:06:15.100
The next parameter is going to be engine and this
138

138

00:06:15.100  -->  00:06:18.110
is it to make sure the data set gets imported correctly.
139

139

00:06:18.110  -->  00:06:22.372
And we will use the Python engine, Python here in quotes
140

140

00:06:22.372  -->  00:06:23.894
to make it efficient.
141

141

00:06:23.894  -->  00:06:27.570
And finally we need to input a last argument
142

142

00:06:27.570  -->  00:06:29.800
which is the encoding and we need to input
143

143

00:06:29.800  -->  00:06:31.710
a different encoding than usual because
144

144

00:06:31.710  -->  00:06:34.990
some of the movie titles contain special characters that
145

145

00:06:34.990  -->  00:06:38.320
cannot be treated properly with the classic encoding UTF8.
146

146

00:06:38.320  -->  00:06:42.360
So we're just adding this encoding argument because of
147

147

00:06:42.360  -->  00:06:45.200
some of the special characters in the movie titles.
148

148

00:06:45.200  -->  00:06:50.200
So in quotes we input latin-1 and quote again
149

149

00:06:53.130  -->  00:06:55.000
and that's the end of the parenthesis.
150

150

00:06:55.000  -->  00:06:57.560
Perfect, I think now we have everything
151

151

00:06:57.560  -->  00:07:00.320
let's make sure it's the case so I'm going
152

152

00:07:00.320  -->  00:07:03.580
to select this line and execute.
153

153

00:07:03.580  -->  00:07:05.450
Perfect, that works.
154

154

00:07:05.450  -->  00:07:08.290
So let's check it out in variable explorer
155

155

00:07:08.290  -->  00:07:11.521
and here are all our movies, here we go.
156

156

00:07:11.521  -->  00:07:14.870
So that's the list of all our movies in this
157

157

00:07:14.870  -->  00:07:17.240
movie lance database, so feel free to have
158

158

00:07:17.240  -->  00:07:19.990
a look at this we have thousands of movies
159

159

00:07:19.990  -->  00:07:21.850
and for each of these movies we have this
160

160

00:07:21.850  -->  00:07:24.150
first column which is the movie ID and that
161

161

00:07:24.150  -->  00:07:25.710
is the most important information
162

162

00:07:25.710  -->  00:07:27.610
because this is the information we will use
163

163

00:07:27.610  -->  00:07:30.230
to make a recommended system you know
164

164

00:07:30.230  -->  00:07:32.250
we will not be using the titles it will
165

165

00:07:32.250  -->  00:07:34.458
be much more simple with the movie's IDs.
166

166

00:07:34.458  -->  00:07:36.906
Okay so this is the first data set
167

167

00:07:36.906  -->  00:07:39.820
and in fact this is just to show you the movies
168

168

00:07:39.820  -->  00:07:42.010
we will not be using this data set to make
169

169

00:07:42.010  -->  00:07:43.650
the training set or the test set.
170

170

00:07:43.650  -->  00:07:46.690
It is just to show you what is going on with all the movies.
171

171

00:07:46.690  -->  00:07:51.430
So okay, and now we're gonna' do the same for our users.
172

172

00:07:51.430  -->  00:07:53.380
Same that's just for you to see where they are
173

173

00:07:53.380  -->  00:07:55.110
and so we're going to create a new variable that
174

174

00:07:55.110  -->  00:07:57.682
we are going to call users and equals.
175

175

00:07:57.682  -->  00:08:00.960
Good news we're going to copy this line
176

176

00:08:00.960  -->  00:08:02.812
because it is going to be almost the same,
177

177

00:08:02.812  -->  00:08:05.206
so copy, and paste that here.
178

178

00:08:05.206  -->  00:08:07.850
And actually we need to use the exact same
179

179

00:08:07.850  -->  00:08:12.160
arguments here for the header, the engine and the encoding,
180

180

00:08:12.160  -->  00:08:14.270
but then of course we need to change the path
181

181

00:08:14.270  -->  00:08:16.702
because we are now importing our users
182

182

00:08:16.702  -->  00:08:20.266
that are contained in users.dat and therefore
183

183

00:08:20.266  -->  00:08:25.266
I'm replacing movies here by users and that should be all.
184

184

00:08:25.530  -->  00:08:27.720
They use the same separator, the double colon
185

185

00:08:27.720  -->  00:08:30.280
to separate the features and therefore that's done.
186

186

00:08:30.280  -->  00:08:33.170
We can select this line and execute.
187

187

00:08:33.170  -->  00:08:36.640
There we go, perfect, our users are well imported.
188

188

00:08:36.640  -->  00:08:39.287
Here they are, users and that all the
189

189

00:08:39.287  -->  00:08:41.951
information is about the different users.
190

190

00:08:41.951  -->  00:08:44.070
So the first column is the user ID
191

191

00:08:44.070  -->  00:08:45.940
the second column is the gender
192

192

00:08:45.940  -->  00:08:48.242
the third column is the age, the fourth column
193

193

00:08:48.242  -->  00:08:51.740
is some code that corresponds to the users job
194

194

00:08:51.740  -->  00:08:54.432
and the last column is the zip code.
195

195

00:08:54.432  -->  00:08:58.257
Okay, and now let's import our ratings
196

196

00:08:58.257  -->  00:09:00.800
so the one million ratings and in fact
197

197

00:09:00.800  -->  00:09:02.670
this is going to be exactly the same
198

198

00:09:02.670  -->  00:09:04.130
we are going to create it a new variable
199

199

00:09:04.130  -->  00:09:06.452
that we are going to call ratings and here
200

200

00:09:06.452  -->  00:09:09.470
we just paste the same line and that's
201

201

00:09:09.470  -->  00:09:10.330
the same, we are going to use
202

202

00:09:10.330  -->  00:09:12.380
the same separator, the same header,
203

203

00:09:12.380  -->  00:09:14.490
the same engine, the same encoding,
204

204

00:09:14.490  -->  00:09:17.350
and therefore we only need to replace movies
205

205

00:09:17.350  -->  00:09:21.150
by the name of the file that contains all the ratings.
206

206

00:09:21.150  -->  00:09:24.610
This is ratings.dat, so here I am just replacing movies
207

207

00:09:24.610  -->  00:09:27.240
by ratings, alright.
208

208

00:09:27.240  -->  00:09:30.829
And now let's take this line and execute
209

209

00:09:30.829  -->  00:09:33.480
here we go it's taking a little time because
210

210

00:09:33.480  -->  00:09:35.570
there is one million ratings and
211

211

00:09:35.570  -->  00:09:39.550
if we go to variable explorer this is our ratings.
212

212

00:09:39.550  -->  00:09:43.480
So here that are important to understand the structure
213

213

00:09:43.480  -->  00:09:46.087
because we are getting closer to the training set
214

214

00:09:46.087  -->  00:09:49.990
and the test set we will make to train our AutoEncoders.
215

215

00:09:49.990  -->  00:09:54.090
So, the first column corresponds to the users so this
216

216

00:09:54.090  -->  00:09:57.049
one here that we see corresponds to the first user
217

217

00:09:57.049  -->  00:09:58.640
of the data base.
218

218

00:09:58.640  -->  00:10:01.700
So all these ones here correspond to the same user
219

219

00:10:01.700  -->  00:10:04.660
then the second column corresponds to the movies
220

220

00:10:04.660  -->  00:10:08.224
and the numbers that we see here are the movie IDs.
221

221

00:10:08.224  -->  00:10:10.690
So this corresponds to our first movie,
222

222

00:10:10.690  -->  00:10:12.467
this corresponds to our second movie,
223

223

00:10:12.467  -->  00:10:14.550
our third movie, our fourth movie,
224

224

00:10:14.550  -->  00:10:18.023
well these are the movie IDs that are contained
225

225

00:10:18.023  -->  00:10:21.328
in this movies data frame so that's why we
226

226

00:10:21.328  -->  00:10:24.540
imported this data frame it's for you to see
227

227

00:10:24.540  -->  00:10:27.500
which movie IDs corresponds to which movie
228

228

00:10:27.500  -->  00:10:29.160
just if you want to play or test
229

229

00:10:29.160  -->  00:10:31.040
the recommended system in the end.
230

230

00:10:31.040  -->  00:10:33.750
Let's open that again, okay so that's the second column
231

231

00:10:33.750  -->  00:10:36.530
corresponding to the movies and then the third
232

232

00:10:36.530  -->  00:10:39.660
column corresponds of course to the ratings.
233

233

00:10:39.660  -->  00:10:41.820
So the ratings go from one to five,
234

234

00:10:41.820  -->  00:10:43.960
one means the user didn't like the movie
235

235

00:10:43.960  -->  00:10:47.287
and five means the user absolutely loved the movie.
236

236

00:10:47.287  -->  00:10:50.380
So let's give two examples, this second line
237

237

00:10:50.380  -->  00:10:53.747
here of index 2 means that user number 1 rated
238

238

00:10:53.747  -->  00:10:58.747
the movie number 914 and gave it three stars.
239

239

00:11:00.080  -->  00:11:03.007
And then let's give another example
240

240

00:11:03.007  -->  00:11:05.858
if I'm scrolling down well for example
241

241

00:11:05.858  -->  00:11:10.340
let's take this observation, 1589.
242

242

00:11:10.340  -->  00:11:13.013
Well this corresponds to the user number 15
243

243

00:11:13.013  -->  00:11:18.013
that rated the movie number 357 and gave it 1 star.
244

244

00:11:19.650  -->  00:11:22.040
So this user absolutely hated this movie.
245

245

00:11:22.040  -->  00:11:24.560
So now for example if you're curious you can have fun
246

246

00:11:24.560  -->  00:11:28.850
and see what this 357 movie ID corresponds to.
247

247

00:11:28.850  -->  00:11:31.873
The answer is in this movie data set.
248

248

00:11:31.873  -->  00:11:34.040
Alright that's the third column
249

249

00:11:34.040  -->  00:11:36.640
and the fourth column we absolutely don't care
250

250

00:11:36.640  -->  00:11:38.890
these are just the time stamps that basically
251

251

00:11:38.890  -->  00:11:42.900
specifies when each user rated the movie.
252

252

00:11:42.900  -->  00:11:44.730
So that's all so we don't care and we will
253

253

00:11:44.730  -->  00:11:47.160
remove this data afterwards when
254

254

00:11:47.160  -->  00:11:49.780
creating the training set and the test set.
255

255

00:11:49.780  -->  00:11:53.019
Alright perfect so that's it for this first tutorial,
256

256

00:11:53.019  -->  00:11:55.660
the data set is now imported correctly
257

257

00:11:55.660  -->  00:11:57.570
and so we will move on to the next step
258

258

00:11:57.570  -->  00:12:00.950
which will be to create the training set and the test set.
259

259

00:12:00.950  -->  00:12:02.640
So I will see you in the next tutorial
260

260

00:12:02.640  -->  00:12:04.453
and until then enjoy Deep Learning!
