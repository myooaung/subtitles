1
1

00:00:00,140  -->  00:00:02,550
<v Instructor>Hello and welcome to this Python tutorial.</v>
2

2

00:00:02,550  -->  00:00:04,160
Alright, so today we're gonna train
3

3

00:00:04,160  -->  00:00:06,020
our stacked autoencoders.
4

4

00:00:06,020  -->  00:00:08,440
And this is going to be quite technical,
5

5

00:00:08,440  -->  00:00:10,010
but that's for the good reason,
6

6

00:00:10,010  -->  00:00:12,880
because this is only to optimize our code
7

7

00:00:12,880  -->  00:00:15,500
so that you can use it on high dimensional datasets,
8

8

00:00:15,500  -->  00:00:17,960
on higher datasets because we are gonna do this
9

9

00:00:17,960  -->  00:00:19,850
with the 200,000 ratings,
10

10

00:00:19,850  -->  00:00:23,110
but if you wanna use it for the 1 million ratings dataset
11

11

00:00:23,110  -->  00:00:25,040
or even a larger dataset,
12

12

00:00:25,040  -->  00:00:26,970
you need an optimized code
13

13

00:00:26,970  -->  00:00:29,350
that saves up the memory as much as possible.
14

14

00:00:29,350  -->  00:00:32,080
So we won't go in too much details about the technique
15

15

00:00:32,080  -->  00:00:34,830
and besides this is some technique related to PyTorch.
16

16

00:00:34,830  -->  00:00:36,760
So you just need to understand what the lines of code
17

17

00:00:36,760  -->  00:00:39,410
will do and that I will make sure to explain.
18

18

00:00:39,410  -->  00:00:41,350
Because then, the most important thing that matters
19

19

00:00:41,350  -->  00:00:43,730
is that you understand how the architecture
20

20

00:00:43,730  -->  00:00:45,370
of the neuron network works
21

21

00:00:45,370  -->  00:00:48,070
and that you know how to manipulate this architecture
22

22

00:00:48,070  -->  00:00:50,180
by changing the number of layers
23

23

00:00:50,180  -->  00:00:52,320
and the number of neurons in the hidden layers.
24

24

00:00:52,320  -->  00:00:55,430
With this structure here, that's very simple to do.
25

25

00:00:55,430  -->  00:00:57,653
And after this section I'll give you a little homework
26

26

00:00:57,653  -->  00:01:00,640
to teach you how to manipulate objects.
27

27

00:01:00,640  -->  00:01:02,700
And this homework will consist of
28

28

00:01:02,700  -->  00:01:06,390
manipulating the objects related to the activation functions
29

29

00:01:06,390  -->  00:01:08,360
so that you can try different combinations
30

30

00:01:08,360  -->  00:01:09,970
of the activation functions.
31

31

00:01:09,970  -->  00:01:13,040
So the most important part of the code is here
32

32

00:01:13,040  -->  00:01:15,070
and now we're gonna train the SAE
33

33

00:01:15,070  -->  00:01:17,090
and we're gonna use some pretty advanced techniques
34

34

00:01:17,090  -->  00:01:20,150
in PyTorch that are only PyTorch related.
35

35

00:01:20,150  -->  00:01:21,230
So let's do this.
36

36

00:01:21,230  -->  00:01:23,920
It's gonna take a little more than 10 lines of code,
37

37

00:01:23,920  -->  00:01:24,900
but no worries.
38

38

00:01:24,900  -->  00:01:26,730
We will do it step by step.
39

39

00:01:26,730  -->  00:01:28,100
So let's start with the first step.
40

40

00:01:28,100  -->  00:01:31,530
The first step is to defined a number of EPOCH,
41

41

00:01:31,530  -->  00:01:34,550
because you know we're training our stacked autoencoders
42

42

00:01:34,550  -->  00:01:37,460
on several EPOCHs, so that at each EPOCH
43

43

00:01:37,460  -->  00:01:38,950
the weights can be updated.
44

44

00:01:38,950  -->  00:01:41,290
And so we need to choose a number of EPOCH.
45

45

00:01:41,290  -->  00:01:45,850
And the number I chose is based of course on experimenting.
46

46

00:01:45,850  -->  00:01:49,500
And by doing that I ended up choosing a number of EPOCH.
47

47

00:01:49,500  -->  00:01:53,650
So that's the name of the variable I'm creating to 200.
48

48

00:01:53,650  -->  00:01:57,980
So we're gonna train our stacked autoencoders on 200 EPOCHs.
49

49

00:01:57,980  -->  00:01:59,480
Alright, second step.
50

50

00:01:59,480  -->  00:02:02,540
Second step is to make a four loop, of course,
51

51

00:02:02,540  -->  00:02:05,370
because in each EPOCH we will loop over
52

52

00:02:05,370  -->  00:02:06,980
all our observations.
53

53

00:02:06,980  -->  00:02:08,890
That is all our users because
54

54

00:02:08,890  -->  00:02:12,060
each observation corresponds to the ratings of a user.
55

55

00:02:12,060  -->  00:02:13,980
So we're gonna loop over all our users,
56

56

00:02:13,980  -->  00:02:15,200
all our observations,
57

57

00:02:15,200  -->  00:02:17,580
but we're gonna make this loop in each EPOCH.
58

58

00:02:17,580  -->  00:02:19,000
So we will have two loops,
59

59

00:02:19,000  -->  00:02:22,130
one loop to loop over all the EPOCHs and another loop,
60

60

00:02:22,130  -->  00:02:24,700
inside this loop, to loop over all the observations,
61

61

00:02:24,700  -->  00:02:26,240
that is the users.
62

62

00:02:26,240  -->  00:02:29,120
So we start of course with the four loop for the EPOCH.
63

63

00:02:29,120  -->  00:02:30,730
And so we do four,
64

64

00:02:30,730  -->  00:02:32,520
then we introduced the variable for the loop,
65

65

00:02:32,520  -->  00:02:34,530
which I'm gonna call EPOCH.
66

66

00:02:34,530  -->  00:02:38,780
Alright, in range, and now we define the start
67

67

00:02:38,780  -->  00:02:40,930
and the stop of the EPOCH variable.
68

68

00:02:40,930  -->  00:02:44,570
So the start will be one, we will start at the first EPOCH
69

69

00:02:44,570  -->  00:02:48,320
and we stop at number of EPOCH.
70

70

00:02:48,320  -->  00:02:50,230
Of course we stop at 200.
71

71

00:02:50,230  -->  00:02:53,070
But remember the upper bound in a range in Python
72

72

00:02:53,070  -->  00:02:55,900
is excluded, so we have to add here
73

73

00:02:55,900  -->  00:02:59,280
plus one so that that includes 200.
74

74

00:02:59,280  -->  00:03:00,920
Alright, exactly as before.
75

75

00:03:00,920  -->  00:03:03,780
And then colon and now we go inside the loop
76

76

00:03:03,780  -->  00:03:06,970
and now this is inside this loop that this other loop
77

77

00:03:06,970  -->  00:03:08,910
over all the users that we are gonna make
78

78

00:03:08,910  -->  00:03:10,220
is gonna take place.
79

79

00:03:10,220  -->  00:03:12,213
But before we introduced that second loop,
80

80

00:03:12,213  -->  00:03:15,630
what we need to do is initialized two variables
81

81

00:03:15,630  -->  00:03:18,720
that we will need to keep the information over the EPOCH.
82

82

00:03:18,720  -->  00:03:19,870
And so what is it?
83

83

00:03:19,870  -->  00:03:22,696
That's of course the loss, the loss error.
84

84

00:03:22,696  -->  00:03:24,834
So we're gonna introduce a new variable
85

85

00:03:24,834  -->  00:03:26,730
that will be this loss error.
86

86

00:03:26,730  -->  00:03:31,040
And so I'm gonna call it train underscore loss.
87

87

00:03:31,040  -->  00:03:32,850
Because then we will make the test loss
88

88

00:03:32,850  -->  00:03:34,690
for the loss of the test set.
89

89

00:03:34,690  -->  00:03:38,610
So train loss equals, and so right now we just want to
90

90

00:03:38,610  -->  00:03:42,010
initialize it because it will be modified at each EPOCH.
91

91

00:03:42,010  -->  00:03:45,040
And so we initialize it to zero because of course
92

92

00:03:45,040  -->  00:03:47,090
at the very beginning of our training,
93

93

00:03:47,090  -->  00:03:48,220
there is no loss yet.
94

94

00:03:48,220  -->  00:03:50,530
And therefore, train loss equal zero.
95

95

00:03:50,530  -->  00:03:53,100
Alright, we're not ready yet to start the second loop.
96

96

00:03:53,100  -->  00:03:55,270
Before I'd like to introduce another variable
97

97

00:03:55,270  -->  00:03:57,260
and initialize it to zero as well,
98

98

00:03:57,260  -->  00:04:00,470
which will be a variable that will count the number of users
99

99

00:04:00,470  -->  00:04:02,560
that rated at least one movie.
100

100

00:04:02,560  -->  00:04:05,270
And that's for the exact purpose I've just mentioned.
101

101

00:04:05,270  -->  00:04:07,040
That is to optimize the memory
102

102

00:04:07,040  -->  00:04:09,380
because we won't do the computations for the users
103

103

00:04:09,380  -->  00:04:11,110
who didn't rate any movies.
104

104

00:04:11,110  -->  00:04:13,490
That could have happened, and so we want to exclude
105

105

00:04:13,490  -->  00:04:16,760
these observations, these users from the computations.
106

106

00:04:16,760  -->  00:04:19,590
And to do this we need to keep track of the number of users
107

107

00:04:19,590  -->  00:04:21,230
who rated at least one movie
108

108

00:04:21,230  -->  00:04:23,180
and so that's why we're introducing this new variable
109

109

00:04:23,180  -->  00:04:26,460
right now, which I'm going to call s and
110

110

00:04:26,460  -->  00:04:29,390
which I'm going to initialize to zero.
111

111

00:04:29,390  -->  00:04:31,080
And I'm even going to do more.
112

112

00:04:31,080  -->  00:04:35,120
I'm gonna introduce it to 0. To make it a float
113

113

00:04:35,120  -->  00:04:37,710
and that's because I'm gonna use s to compute
114

114

00:04:37,710  -->  00:04:39,150
the RMSE in the end.
115

115

00:04:39,150  -->  00:04:40,800
That is the root-mean-squared error.
116

116

00:04:40,800  -->  00:04:43,570
And since the root-mean-squared error is a float,
117

117

00:04:43,570  -->  00:04:46,670
then all the elements to compute the root-mean-squared error
118

118

00:04:46,670  -->  00:04:47,610
should be a float.
119

119

00:04:47,610  -->  00:04:49,900
And since s is part of the computations,
120

120

00:04:49,900  -->  00:04:51,690
s should rather be a float.
121

121

00:04:51,690  -->  00:04:53,000
It's not compulsory,
122

122

00:04:53,000  -->  00:04:54,723
but that's just to avoid a warning.
123

123

00:04:54,723  -->  00:04:56,950
Alright, then next step.
124

124

00:04:56,950  -->  00:05:00,200
And the next step is of course to start the second loop.
125

125

00:05:00,200  -->  00:05:03,860
That is the loop that will loop over all the observations,
126

126

00:05:03,860  -->  00:05:05,410
that is all the users.
127

127

00:05:05,410  -->  00:05:08,250
So this loop will introduce all the actions
128

128

00:05:08,250  -->  00:05:10,750
that will take place in one EPOCH.
129

129

00:05:10,750  -->  00:05:13,320
So right now what we're gonna do inside this loop
130

130

00:05:13,320  -->  00:05:15,730
is everything that is, you know, we're gonna get
131

131

00:05:15,730  -->  00:05:18,720
our predicted rating using our SAE class
132

132

00:05:18,720  -->  00:05:20,440
with this object we created.
133

133

00:05:20,440  -->  00:05:22,590
We're gonna also compute the loss error.
134

134

00:05:22,590  -->  00:05:25,710
But this will be the loss error on one EPOCH.
135

135

00:05:25,710  -->  00:05:28,640
And that's what we wanna see evolve in the training.
136

136

00:05:28,640  -->  00:05:30,110
You know we want to optimize this loss,
137

137

00:05:30,110  -->  00:05:32,340
so we want to compute this loss at each EPOCH
138

138

00:05:32,340  -->  00:05:35,050
and see if it's decreasing over the EPOCHs.
139

139

00:05:35,050  -->  00:05:38,353
So we will do that and we will apply our optimizer
140

140

00:05:38,353  -->  00:05:40,650
that we created here and that we'll apply to
141

141

00:05:40,650  -->  00:05:43,010
casting gradient and descent to update the weights
142

142

00:05:43,010  -->  00:05:44,770
and lead to the convergence.
143

143

00:05:44,770  -->  00:05:47,500
And as an optimizer we chose RMSProp.
144

144

00:05:47,500  -->  00:05:50,060
Okay, so now let's make the second loop
145

145

00:05:50,060  -->  00:05:53,640
which is four and so now we introduce the loop variable
146

146

00:05:53,640  -->  00:05:55,430
that will loop over all the users
147

147

00:05:55,430  -->  00:05:59,300
and we're gonna call it ID underscore user.
148

148

00:05:59,300  -->  00:06:02,923
Alright and then same in range.
149

149

00:06:03,880  -->  00:06:06,720
And inside this range we need to put all our users.
150

150

00:06:06,720  -->  00:06:09,430
So this time we actually don't have to choose
151

151

00:06:09,430  -->  00:06:13,020
a sort of one and a step of NB users plus one
152

152

00:06:13,020  -->  00:06:15,011
because actually it needs to be the indexes
153

153

00:06:15,011  -->  00:06:17,330
of the observations of our training set
154

154

00:06:17,330  -->  00:06:19,960
and the indexes of the observations of our training set
155

155

00:06:19,960  -->  00:06:23,530
don't go from one to 943.
156

156

00:06:23,530  -->  00:06:27,160
They go from zero to 942.
157

157

00:06:27,160  -->  00:06:29,720
So what we simply need to do is add here
158

158

00:06:29,720  -->  00:06:34,720
just NB underscore users, which we created right here,
159

159

00:06:35,450  -->  00:06:38,720
NB users that is equal to 943
160

160

00:06:38,720  -->  00:06:41,060
but only putting NB users here,
161

161

00:06:41,060  -->  00:06:45,690
Will make this range from zero to 943 excluded.
162

162

00:06:45,690  -->  00:06:48,730
That is 942 which is exactly what we want
163

163

00:06:48,730  -->  00:06:50,610
for the indexes of our training set.
164

164

00:06:50,610  -->  00:06:52,000
So that's perfect.
165

165

00:06:52,000  -->  00:06:56,180
And now colon and we go inside the second loop.
166

166

00:06:56,180  -->  00:06:58,010
Alright, and so now basically we need to
167

167

00:06:58,010  -->  00:07:00,960
make the action take place for each observation.
168

168

00:07:00,960  -->  00:07:02,890
That is for each user.
169

169

00:07:02,890  -->  00:07:04,720
So, what do we have to start with?
170

170

00:07:04,720  -->  00:07:07,740
Well, we can start by getting the input.
171

171

00:07:07,740  -->  00:07:09,640
The input vector, that is basically
172

172

00:07:09,640  -->  00:07:11,370
the input vector features
173

173

00:07:11,370  -->  00:07:14,100
that contains all the ratings of all the movies
174

174

00:07:14,100  -->  00:07:17,660
given by this particular user inside the loop.
175

175

00:07:17,660  -->  00:07:18,700
Okay, so let's do this.
176

176

00:07:18,700  -->  00:07:21,020
How can we get this input vector features
177

177

00:07:21,020  -->  00:07:22,470
containing all the ratings?
178

178

00:07:22,470  -->  00:07:25,000
Well first, let's give a name to this variable.
179

179

00:07:25,000  -->  00:07:28,400
We're gonna call it input equals.
180

180

00:07:28,400  -->  00:07:30,950
And so now basically what we would be tempted to do
181

181

00:07:30,950  -->  00:07:35,050
is to take our training set, alright.
182

182

00:07:35,050  -->  00:07:36,410
Because right now we're in the training set,
183

183

00:07:36,410  -->  00:07:39,090
you know, we're training our stacked autoencoders,
184

184

00:07:39,090  -->  00:07:40,380
and then brackets.
185

185

00:07:40,380  -->  00:07:44,860
And then inside these brackets we input our ID user
186

186

00:07:44,860  -->  00:07:48,070
because this ID user corresponds to the index
187

187

00:07:48,070  -->  00:07:51,000
of the observation corresponding to the user
188

188

00:07:51,000  -->  00:07:53,900
with which we are dealing right now in the loop.
189

189

00:07:53,900  -->  00:07:55,060
Okay, fair enough.
190

190

00:07:55,060  -->  00:07:56,450
But as you might've guessed,
191

191

00:07:56,450  -->  00:07:58,270
this is not only what we have to do.
192

192

00:07:58,270  -->  00:08:02,580
And the reason is that training set ID user is a vector
193

193

00:08:02,580  -->  00:08:06,390
and a network in PyTorch or even on Charisse
194

194

00:08:06,390  -->  00:08:09,760
generally can not accept a single vector of one dimension.
195

195

00:08:09,760  -->  00:08:13,430
What it rather accepts is a batch of input vectors.
196

196

00:08:13,430  -->  00:08:15,960
That is that when we applied the different functions
197

197

00:08:15,960  -->  00:08:17,170
of the network, like for example,
198

198

00:08:17,170  -->  00:08:20,580
the forward function, while the functions will not take
199

199

00:08:20,580  -->  00:08:23,920
simple vectors of one dimension as input.
200

200

00:08:23,920  -->  00:08:26,160
Remember we already crossed that situation.
201

201

00:08:26,160  -->  00:08:28,480
That was when we used the predict function
202

202

00:08:28,480  -->  00:08:31,560
to predict if the image contains a cat or a dog.
203

203

00:08:31,560  -->  00:08:33,910
Remember we had to add one dimension
204

204

00:08:33,910  -->  00:08:36,580
and that additional dimension was for the batch.
205

205

00:08:36,580  -->  00:08:40,150
We put our input image of a cat or a dog into a batch
206

206

00:08:40,150  -->  00:08:42,670
and that added one dimension that then would make
207

207

00:08:42,670  -->  00:08:45,350
the whole thing accepted by the predict method.
208

208

00:08:45,350  -->  00:08:47,050
And here that's gonna be the same.
209

209

00:08:47,050  -->  00:08:48,400
This is the input.
210

210

00:08:48,400  -->  00:08:51,390
We're gonna use some functions on this input
211

211

00:08:51,390  -->  00:08:55,270
and as in Charisse, the PyTorch network and its functions
212

212

00:08:55,270  -->  00:08:59,200
don't accept a single vector of one dimension as input.
213

213

00:08:59,200  -->  00:09:01,440
And so what we need to do is do exactly the same
214

214

00:09:01,440  -->  00:09:02,690
as we did in Charisse.
215

215

00:09:02,690  -->  00:09:07,260
We need to add an additional dimension like a fake dimension
216

216

00:09:07,260  -->  00:09:09,120
which will correspond to a batch.
217

217

00:09:09,120  -->  00:09:10,410
So we'll create a batch.
218

218

00:09:10,410  -->  00:09:12,610
This batch will contain one vector,
219

219

00:09:12,610  -->  00:09:14,740
but we will be into a new dimension
220

220

00:09:14,740  -->  00:09:16,160
corresponding to the batches.
221

221

00:09:16,160  -->  00:09:17,680
And so now the question is,
222

222

00:09:17,680  -->  00:09:20,410
how do we create this new dimension?
223

223

00:09:20,410  -->  00:09:22,540
Well, that's just a PyTorch technique.
224

224

00:09:22,540  -->  00:09:25,880
What we have to do is use the variable function.
225

225

00:09:25,880  -->  00:09:27,350
So I'm putting that first
226

226

00:09:27,350  -->  00:09:30,270
because it will take training set ID user as input,
227

227

00:09:30,270  -->  00:09:34,190
so variable then parenthesis, we put
228

228

00:09:34,190  -->  00:09:36,200
training set ID user inside.
229

229

00:09:36,200  -->  00:09:37,320
But that's still not enough.
230

230

00:09:37,320  -->  00:09:41,090
To create this additional dimension, we add here a dot.
231

231

00:09:41,090  -->  00:09:45,060
And then we're gonna use the function unsqueeze, like this.
232

232

00:09:45,060  -->  00:09:47,150
And now the last thing that we need to do is
233

233

00:09:47,150  -->  00:09:49,950
specify the index of this new dimension.
234

234

00:09:49,950  -->  00:09:52,380
And that's exactly the same as in Charisse.
235

235

00:09:52,380  -->  00:09:55,210
We are gonna put this new dimension in first position.
236

236

00:09:55,210  -->  00:09:57,780
And so this dimension will have index zero.
237

237

00:09:57,780  -->  00:10:01,520
So the zero here is the index of this new dimension.
238

238

00:10:01,520  -->  00:10:05,640
And this, all this, will create a batch of,
239

239

00:10:05,640  -->  00:10:07,600
okay, a single input vector.
240

240

00:10:07,600  -->  00:10:09,700
The batch can have several input vectors.
241

241

00:10:09,700  -->  00:10:11,770
Remember we called this batch learning.
242

242

00:10:11,770  -->  00:10:13,350
But here we're gonna do online learning.
243

243

00:10:13,350  -->  00:10:16,060
That means that we're going to update the weights
244

244

00:10:16,060  -->  00:10:18,540
after each observation going to the network.
245

245

00:10:18,540  -->  00:10:21,610
And therefore, we are creating a batch of one input vector.
246

246

00:10:21,610  -->  00:10:23,210
But we have to create this batch,
247

247

00:10:23,210  -->  00:10:25,070
otherwise it won't work.
248

248

00:10:25,070  -->  00:10:27,580
Alright, so now next step.
249

249

00:10:27,580  -->  00:10:30,480
The next step now is to take care of the target.
250

250

00:10:30,480  -->  00:10:32,220
We have the input vector,
251

251

00:10:32,220  -->  00:10:34,160
but we would like some separate variables
252

252

00:10:34,160  -->  00:10:37,290
between the input vector and the target.
253

253

00:10:37,290  -->  00:10:40,130
So basically the target is the same as the input vector,
254

254

00:10:40,130  -->  00:10:42,120
but since we're going to modify the input,
255

255

00:10:42,120  -->  00:10:44,740
we would like to get the original input
256

256

00:10:44,740  -->  00:10:45,920
before the modifications.
257

257

00:10:45,920  -->  00:10:50,410
And therefore, I'm gonna create this target variable.
258

258

00:10:50,410  -->  00:10:52,750
And this will be a clone of the inputs.
259

259

00:10:52,750  -->  00:10:54,250
Like a copy of the inputs.
260

260

00:10:54,250  -->  00:10:55,630
But I'm using the word clone because
261

261

00:10:55,630  -->  00:10:57,770
we're gonna use the clone function.
262

262

00:10:57,770  -->  00:11:00,100
Okay and so to clone our input,
263

263

00:11:00,100  -->  00:11:02,370
we simply need to take our input.
264

264

00:11:02,370  -->  00:11:05,100
So input here and then add a dot.
265

265

00:11:05,100  -->  00:11:09,950
And then use this clone function to copy our input.
266

266

00:11:09,950  -->  00:11:13,090
So right now the input and the target are the same.
267

267

00:11:13,090  -->  00:11:14,640
That's the input vector features
268

268

00:11:14,640  -->  00:11:17,040
containing all the ratings of the different movies
269

269

00:11:17,040  -->  00:11:19,421
by this ID user at the loop right now.
270

270

00:11:19,421  -->  00:11:21,367
But then we will modify target.
271

271

00:11:21,367  -->  00:11:23,840
Okay, then next step.
272

272

00:11:23,840  -->  00:11:27,130
So in this next step we're gonna introduce an if condition.
273

273

00:11:27,130  -->  00:11:29,150
And the only purpose of doing this
274

274

00:11:29,150  -->  00:11:31,090
is to optimize the memory.
275

275

00:11:31,090  -->  00:11:33,470
To save as much memory as possible
276

276

00:11:33,470  -->  00:11:36,890
because this if condition will consist of
277

277

00:11:36,890  -->  00:11:40,740
only looking at the users who rated at least one movie.
278

278

00:11:40,740  -->  00:11:43,510
So if an observation contains only zeros,
279

279

00:11:43,510  -->  00:11:46,070
which means that the user didn't rate any movies,
280

280

00:11:46,070  -->  00:11:48,350
then we won't care of this observation.
281

281

00:11:48,350  -->  00:11:51,210
This will not be part of what's gonna follow.
282

282

00:11:51,210  -->  00:11:53,150
Okay, so let's make this if condition.
283

283

00:11:53,150  -->  00:11:55,960
We start with if, then we add the condition.
284

284

00:11:55,960  -->  00:11:57,730
And this condition is going to be,
285

285

00:11:57,730  -->  00:12:02,730
torch.some parenthesis, and inside the parenthesis,
286

286

00:12:03,060  -->  00:12:06,730
we're gonna input target.data.
287

287

00:12:06,730  -->  00:12:10,160
So target.data will take all the values of target,
288

288

00:12:10,160  -->  00:12:11,800
which is our input vector.
289

289

00:12:11,800  -->  00:12:13,790
And therefore, target.data will be
290

290

00:12:13,790  -->  00:12:17,380
older ratings of this user here at the loop right now.
291

291

00:12:17,380  -->  00:12:20,410
So, target.data is just all the ratings.
292

292

00:12:20,410  -->  00:12:22,740
But we wanna consider all the ratings
293

293

00:12:22,740  -->  00:12:26,080
that are larger than zero, because what we wanna do
294

294

00:12:26,080  -->  00:12:30,420
is check to see if this sum of the ratings
295

295

00:12:30,420  -->  00:12:32,780
that are larger than zero, that is either
296

296

00:12:32,780  -->  00:12:34,700
one, two, three, four or five.
297

297

00:12:34,700  -->  00:12:38,640
We wanna check if this sum is larger than zero.
298

298

00:12:38,640  -->  00:12:40,030
And if that's the case,
299

299

00:12:40,030  -->  00:12:44,290
that means that the observation contains at least
300

300

00:12:44,290  -->  00:12:46,330
one rating that is not zero.
301

301

00:12:46,330  -->  00:12:47,410
Because then if that's the case,
302

302

00:12:47,410  -->  00:12:50,060
this sum will be larger than zero.
303

303

00:12:50,060  -->  00:12:52,050
And so in that way we consider the users
304

304

00:12:52,050  -->  00:12:54,120
that rated at least one movie.
305

305

00:12:54,120  -->  00:12:54,953
So perfect.
306

306

00:12:54,953  -->  00:12:56,040
That's what we want.
307

307

00:12:56,040  -->  00:12:58,740
And now we can start the computations.
308

308

00:12:58,740  -->  00:13:00,560
So the first thing we're gonna do now,
309

309

00:13:00,560  -->  00:13:02,550
so that's the real first step of the action,
310

310

00:13:02,550  -->  00:13:05,520
is to get our vector of predicted ratings.
311

311

00:13:05,520  -->  00:13:09,170
That is our output at the very right of the network
312

312

00:13:09,170  -->  00:13:11,470
after the input, that is the observation
313

313

00:13:11,470  -->  00:13:13,390
went into the network.
314

314

00:13:13,390  -->  00:13:14,740
So basically that's nothing else
315

315

00:13:14,740  -->  00:13:17,050
than a vector of predicted ratings.
316

316

00:13:17,050  -->  00:13:19,100
Okay, so we're gonna introduce a new variable
317

317

00:13:19,100  -->  00:13:22,770
to get this output vector of predicted ratings
318

318

00:13:22,770  -->  00:13:25,720
and we're gonna call it of course, output.
319

319

00:13:25,720  -->  00:13:26,700
Here we go.
320

320

00:13:26,700  -->  00:13:30,390
And now how can we get this vector of predicted ratings?
321

321

00:13:30,390  -->  00:13:31,720
That is our predictions.
322

322

00:13:31,720  -->  00:13:34,220
Well try to pause the video and guess it.
323

323

00:13:34,220  -->  00:13:36,120
Because that's important to understand
324

324

00:13:36,120  -->  00:13:36,953
what it's gonna be.
325

325

00:13:36,953  -->  00:13:38,610
It's actually very simple.
326

326

00:13:38,610  -->  00:13:40,070
I'm gonna tell you right now.
327

327

00:13:40,070  -->  00:13:43,060
We have to use our SAE object.
328

328

00:13:43,060  -->  00:13:46,570
Because this object is an object of the SAE class.
329

329

00:13:46,570  -->  00:13:50,730
And in this SAE class, the action of forwarding
330

330

00:13:50,730  -->  00:13:53,570
the input vector into the network takes place.
331

331

00:13:53,570  -->  00:13:55,750
And we besides, this function returns
332

332

00:13:55,750  -->  00:13:57,560
the output of the network,
333

333

00:13:57,560  -->  00:13:59,920
that is the vector of predicted ratings.
334

334

00:13:59,920  -->  00:14:03,380
So since this forward function is part of the class,
335

335

00:14:03,380  -->  00:14:07,140
then by applying our object SAE to the input
336

336

00:14:07,140  -->  00:14:10,270
of real ratings, well the forward function will be applied
337

337

00:14:10,270  -->  00:14:11,850
and will return x.
338

338

00:14:11,850  -->  00:14:13,750
That is the vector of predicted ratings.
339

339

00:14:13,750  -->  00:14:15,510
So basically that's very simple.
340

340

00:14:15,510  -->  00:14:18,410
We just need to take our object SAE,
341

341

00:14:18,410  -->  00:14:21,460
and then in the parenthesis we add our input.
342

342

00:14:21,460  -->  00:14:23,584
That is our input vector of real ratings.
343

343

00:14:23,584  -->  00:14:27,650
This input is going to be this x here.
344

344

00:14:27,650  -->  00:14:31,230
So the forward function will take place with the input
345

345

00:14:31,230  -->  00:14:32,080
right here.
346

346

00:14:32,080  -->  00:14:34,900
It will do the action and return x,
347

347

00:14:34,900  -->  00:14:36,870
the vector of predicted ratings,
348

348

00:14:36,870  -->  00:14:38,940
which is going to be output.
349

349

00:14:38,940  -->  00:14:39,960
So that's how it works.
350

350

00:14:39,960  -->  00:14:41,950
It's very important to understand this.
351

351

00:14:41,950  -->  00:14:43,660
You just need to take your object
352

352

00:14:43,660  -->  00:14:46,390
and by inputting the input vector of real ratings here,
353

353

00:14:46,390  -->  00:14:48,230
the forward function will take action.
354

354

00:14:48,230  -->  00:14:50,260
The encodings and decoding will happen.
355

355

00:14:50,260  -->  00:14:51,770
And this will return eventually
356

356

00:14:51,770  -->  00:14:54,060
to the vector of predicted ratings.
357

357

00:14:54,060  -->  00:14:56,120
Alright, so we have our real ratings
358

358

00:14:56,120  -->  00:14:57,660
and our Predicted ratings.
359

359

00:14:57,660  -->  00:14:59,070
That's the first step done.
360

360

00:14:59,070  -->  00:15:00,500
Now let's take a short break
361

361

00:15:00,500  -->  00:15:02,220
and we'll take care of the rest of the training
362

362

00:15:02,220  -->  00:15:03,590
in the next tutorial.
363

363

00:15:03,590  -->  00:15:05,353
Until then, enjoy deep learning.
