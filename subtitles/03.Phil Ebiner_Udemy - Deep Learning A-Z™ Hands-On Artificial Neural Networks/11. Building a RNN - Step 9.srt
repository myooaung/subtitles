1
1

00:00:00,350  -->  00:00:02,270
<v Tutor>Hello and welcome to</v>
2

2

00:00:02,270  -->  00:00:05,470
the almost last step of this part two building the RNN,
3

3

00:00:05,470  -->  00:00:07,980
well at least this is the last step of
4

4

00:00:07,980  -->  00:00:10,060
the architecture of the neural network.
5

5

00:00:10,060  -->  00:00:12,890
What's left to do is just to add the outward layer
6

6

00:00:12,890  -->  00:00:15,380
and that's exactly what we'll do in this tutorial.
7

7

00:00:15,380  -->  00:00:16,810
And it's going to be very efficient,
8

8

00:00:16,810  -->  00:00:18,740
it's actually very simple.
9

9

00:00:18,740  -->  00:00:20,435
We just need to take our regressor,
10

10

00:00:20,435  -->  00:00:23,030
it's actually exactly the same as for
11

11

00:00:23,030  -->  00:00:25,380
the ANN and the CNN.
12

12

00:00:25,380  -->  00:00:27,478
We take our regressor, or classifier,
13

13

00:00:27,478  -->  00:00:29,420
then dot, then we add,
14

14

00:00:29,420  -->  00:00:33,070
again the add method from sequential class,
15

15

00:00:33,070  -->  00:00:37,180
to add this final outward layer of our neural network.
16

16

00:00:37,180  -->  00:00:39,110
And now the important question is
17

17

00:00:39,110  -->  00:00:43,320
which class are we gonna use to add this outward layer?
18

18

00:00:43,320  -->  00:00:46,500
Well since this time we're not adding an LSTM layer,
19

19

00:00:46,500  -->  00:00:48,960
but a classic fully connected layer,
20

20

00:00:48,960  -->  00:00:50,942
you know because the outward layer is fully connected
21

21

00:00:50,942  -->  00:00:53,070
to the previous LSTM layer,
22

22

00:00:53,070  -->  00:00:55,420
the fourth one that we added here,
23

23

00:00:55,420  -->  00:00:57,641
well in that case to make a full connection
24

24

00:00:57,641  -->  00:01:00,750
we need to use the dense class
25

25

00:01:00,750  -->  00:01:03,550
exactly as we did for ANN and CNN.
26

26

00:01:03,550  -->  00:01:04,750
So let's do this.
27

27

00:01:04,750  -->  00:01:08,341
Let's specify in the add method here dense,
28

28

00:01:08,341  -->  00:01:09,757
the dense class,
29

29

00:01:09,757  -->  00:01:13,520
and now we have to input one argument,
30

30

00:01:13,520  -->  00:01:15,950
only one which will correspond to
31

31

00:01:15,950  -->  00:01:18,910
the number of neurons there needs to be,
32

32

00:01:18,910  -->  00:01:21,540
you must not choose it there is only one possibility,
33

33

00:01:21,540  -->  00:01:23,540
there needs to be in this outward layer.
34

34

00:01:23,540  -->  00:01:26,710
And so since we're predicting a real value
35

35

00:01:26,710  -->  00:01:28,360
corresponding to the stock price,
36

36

00:01:28,360  -->  00:01:31,078
well the output has only one dimension
37

37

00:01:31,078  -->  00:01:34,640
and this one dimension is exactly what we need to input.
38

38

00:01:34,640  -->  00:01:37,170
And the argument for that is units,
39

39

00:01:37,170  -->  00:01:39,100
basically units corresponds to
40

40

00:01:39,100  -->  00:01:42,490
the number of neurons there should be in this outward layer,
41

41

00:01:42,490  -->  00:01:44,210
and that corresponds exactly to
42

42

00:01:44,210  -->  00:01:47,195
the dimension of the outward layer, which is one.
43

43

00:01:47,195  -->  00:01:52,040
Alright, so lets add units equals one,
44

44

00:01:52,040  -->  00:01:53,210
our stock price,
45

45

00:01:53,210  -->  00:01:54,690
at time T plus one
46

46

00:01:54,690  -->  00:01:57,313
which is exactly what we have to predict.
47

47

00:01:58,650  -->  00:02:01,610
Lets select this line and execute
48

48

00:02:01,610  -->  00:02:04,600
and there we go, we have our final layer,
49

49

00:02:04,600  -->  00:02:08,055
the outward layer, of our recurrent neural network.
50

50

00:02:08,055  -->  00:02:11,250
So congratulations, you are now done
51

51

00:02:11,250  -->  00:02:13,930
with the architecture of our super robust
52

52

00:02:13,930  -->  00:02:15,780
LSTM recurrent neural network,
53

53

00:02:15,780  -->  00:02:17,750
and now we have two remaining steps.
54

54

00:02:17,750  -->  00:02:19,850
The first one is compiling the RNN
55

55

00:02:19,850  -->  00:02:23,330
with a powerful optimizer and the right loss,
56

56

00:02:23,330  -->  00:02:24,690
which will be the mean squared error
57

57

00:02:24,690  -->  00:02:26,084
because we're doing some regression
58

58

00:02:26,084  -->  00:02:27,390
and the second step,
59

59

00:02:27,390  -->  00:02:30,648
and the last step of this part two building the RNN,
60

60

00:02:30,648  -->  00:02:34,923
is of course to fit this neural network that we make
61

61

00:02:34,923  -->  00:02:37,410
to our training set.
62

62

00:02:37,410  -->  00:02:40,560
And our training set is composed of x train,
63

63

00:02:40,560  -->  00:02:42,142
that's the right data structure
64

64

00:02:42,142  -->  00:02:44,260
that is expected by the neural networks
65

65

00:02:44,260  -->  00:02:47,210
so we need to take x train and not training set,
66

66

00:02:47,210  -->  00:02:48,043
or training set scaled,
67

67

00:02:48,043  -->  00:02:51,440
and of course we will need to specify the output
68

68

00:02:51,440  -->  00:02:53,405
when fitting the regressor to our training sets
69

69

00:02:53,405  -->  00:02:56,380
because the output contains the ground truth
70

70

00:02:56,380  -->  00:02:58,687
that is the stock price at time T plus one.
71

71

00:02:58,687  -->  00:03:01,430
We're training the RNN on the truth,
72

72

00:03:01,430  -->  00:03:05,150
the true stock price that is happening at time T plus one
73

73

00:03:05,150  -->  00:03:07,390
after the 60 produced stock prices
74

74

00:03:07,390  -->  00:03:09,560
during the 60 produced financial days
75

75

00:03:09,560  -->  00:03:12,760
and so that's why we also need to include the ground truth
76

76

00:03:12,760  -->  00:03:14,560
and therefore y train.
77

77

00:03:14,560  -->  00:03:16,610
So we will do these last two steps
78

78

00:03:16,610  -->  00:03:19,300
in the next two tutorials and until then,
79

79

00:03:19,300  -->  00:03:20,300
enjoy deep learning.
