1
1

00:00:00,260  -->  00:00:02,670
<v Instructor>Hello and welcome this Python tutorial.</v>
2

2

00:00:02,670  -->  00:00:05,740
Okay, so far we've got our input of real ratings,
3

3

00:00:05,740  -->  00:00:08,420
our target, which is the clone of the input
4

4

00:00:08,420  -->  00:00:12,050
and we also got our output of predicted ratings.
5

5

00:00:12,050  -->  00:00:15,230
And now the next step will be, again, about optimization.
6

6

00:00:15,230  -->  00:00:18,780
That is optimizing the memory and the computations.
7

7

00:00:18,780  -->  00:00:20,750
As you notice we have two variables
8

8

00:00:20,750  -->  00:00:22,150
representing the same thing.
9

9

00:00:22,150  -->  00:00:23,940
The input and the target,
10

10

00:00:23,940  -->  00:00:26,200
because the target is a clone of the input.
11

11

00:00:26,200  -->  00:00:29,080
And so, when we apply stochastic gradient descent,
12

12

00:00:29,080  -->  00:00:31,770
we want to make sure the gradient is computed
13

13

00:00:31,770  -->  00:00:35,454
only with respect to the input and not the target.
14

14

00:00:35,454  -->  00:00:38,120
To do this, we will use this trick,
15

15

00:00:38,120  -->  00:00:39,930
which will reduce the computations
16

16

00:00:39,930  -->  00:00:41,630
and save up again some memory,
17

17

00:00:41,630  -->  00:00:43,420
and that is target.
18

18

00:00:43,420  -->  00:00:46,890
We take our target vector, then we add a dot,
19

19

00:00:46,890  -->  00:00:48,890
and then we're gonna use require_grad
20

20

00:00:51,006  -->  00:00:54,110 line:15% 
and we will set it equal to False.
21

21

00:00:54,110  -->  00:00:58,180
This will make sure that we don't compute the gradient
22

22

00:00:58,180  -->  00:01:00,500
with respect to the target and that will save
23

23

00:01:00,500  -->  00:01:03,440
a lot of computations and that optimizes the code.
24

24

00:01:03,440  -->  00:01:04,480
Alright, perfect.
25

25

00:01:04,480  -->  00:01:06,410
And now, let's move on to the next step.
26

26

00:01:06,410  -->  00:01:08,750
The next step is also about optimization.
27

27

00:01:08,750  -->  00:01:11,080
That is, that's in the future computations
28

28

00:01:11,080  -->  00:01:13,450
of the gradient and stochastic gradient descent,
29

29

00:01:13,450  -->  00:01:15,810
we only want to include in the computations,
30

30

00:01:15,810  -->  00:01:17,490
the non-zero values.
31

31

00:01:17,490  -->  00:01:19,050
We don't wanna deal with the movies
32

32

00:01:19,050  -->  00:01:20,610
that the user didn't rate,
33

33

00:01:20,610  -->  00:01:22,420
where the ratings are equal to zero,
34

34

00:01:22,420  -->  00:01:25,240
but that is only for the output vector.
35

35

00:01:25,240  -->  00:01:26,720
The vector of predicted ratings.
36

36

00:01:26,720  -->  00:01:29,793
What we're gonna add now is output,
37

37

00:01:30,750  -->  00:01:33,170
that's our output vector of predicted ratings,
38

38

00:01:33,170  -->  00:01:36,450
and now, remember we're gonna add this such as
39

39

00:01:36,450  -->  00:01:39,290
which adds a condition exactly as we did here,
40

40

00:01:39,290  -->  00:01:41,340
where we wanted to take our movies
41

41

00:01:41,340  -->  00:01:45,060
such as the movies were rated by the user.
42

42

00:01:45,060  -->  00:01:49,150
Now, the condition that we'll add is such as the target
43

43

00:01:50,450  -->  00:01:53,010
is equal to zero.
44

44

00:01:53,010  -->  00:01:54,750
That's exactly the same as in here.
45

45

00:01:54,750  -->  00:01:57,630
We wanna take the values of our output vector
46

46

00:01:57,630  -->  00:02:00,750
that is the predicted ratings in our output vector,
47

47

00:02:00,750  -->  00:02:02,909
such as the corresponding ratings
48

48

00:02:02,909  -->  00:02:06,550
in the target vector are equal to zero.
49

49

00:02:06,550  -->  00:02:09,180
We're just taking the same indexes of the ratings
50

50

00:02:09,180  -->  00:02:12,120
that were equal to zero in the input vector.
51

51

00:02:12,120  -->  00:02:15,260
And for these indexes of the output vector,
52

52

00:02:15,260  -->  00:02:17,070
we will set the values corresponding
53

53

00:02:17,070  -->  00:02:20,070
to these indexes to zero.
54

54

00:02:20,070  -->  00:02:22,790
Now question is, why are we allowed to do this?
55

55

00:02:22,790  -->  00:02:26,100
Well, that's because these values will not count
56

56

00:02:26,100  -->  00:02:28,150
in the computations of the error,
57

57

00:02:28,150  -->  00:02:29,650
and so they won't have impact
58

58

00:02:29,650  -->  00:02:31,770
on the updates of the different weights
59

59

00:02:31,770  -->  00:02:34,160
right after having measured the error.
60

60

00:02:34,160  -->  00:02:36,870
After we've measured the error, the weights are updated
61

61

00:02:36,870  -->  00:02:40,900
by the RMSprop Optimizer and updating these weights require
62

62

00:02:40,900  -->  00:02:43,875
some computations and in these computations,
63

63

00:02:43,875  -->  00:02:46,270
these values here don't count.
64

64

00:02:46,270  -->  00:02:47,940
Even if they're not equal to zero,
65

65

00:02:47,940  -->  00:02:49,740
they don't count, and so,
66

66

00:02:49,740  -->  00:02:53,770
to save up some memory, again, we set them to zero.
67

67

00:02:53,770  -->  00:02:54,820
Okay, so perfect.
68

68

00:02:54,820  -->  00:02:56,980
We have an even more optimized code,
69

69

00:02:56,980  -->  00:02:59,770
so you will perfectly be able to use it
70

70

00:02:59,770  -->  00:03:01,470
on larger data sets.
71

71

00:03:01,470  -->  00:03:03,490
Okay, and now, next step.
72

72

00:03:03,490  -->  00:03:04,820
In this next step we will eventually
73

73

00:03:04,820  -->  00:03:06,690
compute the loss error.
74

74

00:03:06,690  -->  00:03:08,050
We're gonna compute the loss,
75

75

00:03:08,050  -->  00:03:09,990
and, actually this is going to be very easy,
76

76

00:03:09,990  -->  00:03:13,440
because we already created a criterion object,
77

77

00:03:13,440  -->  00:03:16,100
which we will use, of course, to compute the loss
78

78

00:03:16,100  -->  00:03:17,670
and we will use it this way.
79

79

00:03:17,670  -->  00:03:20,540
We first introduce a variable for the loss
80

80

00:03:20,540  -->  00:03:22,227
that I'm calling loss and now we use
81

81

00:03:22,227  -->  00:03:25,770
the subject criterion and this subject
82

82

00:03:25,770  -->  00:03:28,240
takes two arguments that are very intuitive,
83

83

00:03:28,240  -->  00:03:29,180
you can guess them.
84

84

00:03:29,180  -->  00:03:32,690
It's basically the arguments you need to compute a loss.
85

85

00:03:32,690  -->  00:03:35,050
So, that's, of course, the vector of real ratings,
86

86

00:03:35,050  -->  00:03:38,470
that is the truth, and the vector of predicted ratings,
87

87

00:03:38,470  -->  00:03:39,650
that is our predictions.
88

88

00:03:39,650  -->  00:03:43,460
First argument, we're gonna input our vector
89

89

00:03:43,460  -->  00:03:46,400
of predicted ratings, which is output,
90

90

00:03:46,400  -->  00:03:49,250
and second argument is the vector of real ratings,
91

91

00:03:49,250  -->  00:03:52,103
that is the truth, which is our target.
92

92

00:03:53,200  -->  00:03:54,033
And that's all,
93

93

00:03:54,033  -->  00:03:55,630
the loss is ready.
94

94

00:03:55,630  -->  00:03:56,463
Next step.
95

95

00:03:56,463  -->  00:03:58,130
In the next step, we're gonna introduce
96

96

00:03:58,130  -->  00:04:03,130
a new variable that we're gonna call mean_corrector,
97

97

00:04:03,130  -->  00:04:07,210
and this new variable will be equal to the number of movies
98

98

00:04:07,210  -->  00:04:10,920
over the number of movies that have positive ratings.
99

99

00:04:10,920  -->  00:04:12,960
Let's get this and then I'm going to explain.
100

100

00:04:12,960  -->  00:04:15,600
The number of movies that have non-zero ratings,
101

101

00:04:15,600  -->  00:04:17,120
we can get them this way.
102

102

00:04:17,120  -->  00:04:19,390
We're gonna use first the float function
103

103

00:04:19,390  -->  00:04:20,960
to make sure it's a float
104

104

00:04:20,960  -->  00:04:22,380
and then inside this float function
105

105

00:04:22,380  -->  00:04:25,770
we're gonna use torch, the module, then dot,
106

106

00:04:25,770  -->  00:04:28,430
and to get a number of movies that
107

107

00:04:28,430  -->  00:04:31,870
verifies a certain condition, we can use the sum function
108

108

00:04:31,870  -->  00:04:34,820
that will count the movies that have non-zero ratings.
109

109

00:04:34,820  -->  00:04:37,490
We're gonna use the sum here and inside the sum,
110

110

00:04:37,490  -->  00:04:41,680
we're gonna input target.data,
111

111

00:04:41,680  -->  00:04:43,750
larger than zero,
112

112

00:04:43,750  -->  00:04:47,376
And that, exactly as here, we're considering all the movies
113

113

00:04:47,376  -->  00:04:49,420
that have non-zero ratings.
114

114

00:04:49,420  -->  00:04:51,060
And then I'm just going to add
115

115

00:04:51,060  -->  00:04:55,110
a plus one times ten at the power of -10,
116

116

00:04:55,110  -->  00:04:57,810
and according to you, why do we need to do that?
117

117

00:04:57,810  -->  00:05:00,770
That's for a mathematical reason, it's very important.
118

118

00:05:00,770  -->  00:05:03,940
This is a denominator, so we need to make sure
119

119

00:05:03,940  -->  00:05:06,230
that this denominator is non-nil.
120

120

00:05:06,230  -->  00:05:09,130
And that, even if we have this condition here.
121

121

00:05:09,130  -->  00:05:11,680
That's very important to make it, any way,
122

122

00:05:11,680  -->  00:05:13,830
never equal to zero and with this,
123

123

00:05:13,830  -->  00:05:14,980
this will always be the case,
124

124

00:05:14,980  -->  00:05:19,300
because this is always positive, because if by any chance
125

125

00:05:19,300  -->  00:05:21,930
the denominator is equal to zero, well that will lead
126

126

00:05:21,930  -->  00:05:23,660
to a pretty important error that has
127

127

00:05:23,660  -->  00:05:26,783
an infinite computations that we really want to avoid.
128

128

00:05:26,783  -->  00:05:30,213
I'm just adding this very, very small number here
129

129

00:05:30,213  -->  00:05:33,470
that will not create any bias into this computation,
130

130

00:05:33,470  -->  00:05:35,510
but that will make sure the denominator
131

131

00:05:35,510  -->  00:05:36,990
is different than zero.
132

132

00:05:36,990  -->  00:05:41,610
Okay, and now, why do we need to create this mean corrector?
133

133

00:05:41,610  -->  00:05:45,090
Basically, try to think what this represents.
134

134

00:05:45,090  -->  00:05:46,500
I'm gonna tell you right now.
135

135

00:05:46,500  -->  00:05:50,460
This actually represents the average of the error,
136

136

00:05:50,460  -->  00:05:53,820
but by only considering the movies that were rated,
137

137

00:05:53,820  -->  00:05:56,780
the movies that at least got one to five ratings.
138

138

00:05:56,780  -->  00:05:59,691
And that, we need to do this because we only considered here
139

139

00:05:59,691  -->  00:06:02,451
the movies that have non-zero ratings.
140

140

00:06:02,451  -->  00:06:05,460
Since then we will compute some mean,
141

141

00:06:05,460  -->  00:06:07,124
this mean has to be computed
142

142

00:06:07,124  -->  00:06:09,610
only on the movies that we consider.
143

143

00:06:09,610  -->  00:06:12,430
That is, the movies that got non-zero ratings.
144

144

00:06:12,430  -->  00:06:14,440
This mean correcter variable is just
145

145

00:06:14,440  -->  00:06:17,110
to adapt to this consideration of the movies
146

146

00:06:17,110  -->  00:06:18,920
that got non-zero ratings.
147

147

00:06:18,920  -->  00:06:20,560
We need to do this because this will then be
148

148

00:06:20,560  -->  00:06:24,010
mathematically relevant to compute the mean of the errors.
149

149

00:06:24,010  -->  00:06:25,790
Okay, then, next step.
150

150

00:06:25,790  -->  00:06:27,390
In this next step, we're gonna call
151

151

00:06:27,390  -->  00:06:30,120
the backward method for the loss.
152

152

00:06:30,120  -->  00:06:33,000
This call of the backward method will just tell
153

153

00:06:33,000  -->  00:06:35,750
in which direction we need to update the different weights.
154

154

00:06:35,750  -->  00:06:38,630
Do we need to increase the weight or decrease the weight?
155

155

00:06:38,630  -->  00:06:39,720
That's what the backward method
156

156

00:06:39,720  -->  00:06:42,070
will make sure of doing properly.
157

157

00:06:42,070  -->  00:06:45,810
So, to use it we take our loss, then dot,
158

158

00:06:45,810  -->  00:06:49,763
and then we use backward and then we just add backward.
159

159

00:06:52,000  -->  00:06:54,720
Alright, so we're almost reaching the end.
160

160

00:06:54,720  -->  00:06:56,250
We have a few steps left.
161

161

00:06:56,250  -->  00:06:59,400
The next step is to compute the RMSE.
162

162

00:06:59,400  -->  00:07:01,960
The next step is to update the train loss
163

163

00:07:01,960  -->  00:07:04,280
that we initialized to zero here,
164

164

00:07:04,280  -->  00:07:06,770
but you know after each observation going to the network,
165

165

00:07:06,770  -->  00:07:08,930
this train loss is modified and therefore,
166

166

00:07:08,930  -->  00:07:11,360
we need to update its value right now.
167

167

00:07:11,360  -->  00:07:13,290
We're gonna update it, train loss
168

168

00:07:14,440  -->  00:07:15,910
and I'm going to update it this way.
169

169

00:07:15,910  -->  00:07:19,250
I'm gonna add a +, then an =, and that means
170

170

00:07:19,250  -->  00:07:21,070
that we're incrementing it by something.
171

171

00:07:21,070  -->  00:07:24,110
We're adding something to the original value of train loss,
172

172

00:07:24,110  -->  00:07:25,520
which, so far, is zero.
173

173

00:07:25,520  -->  00:07:27,660
So, basically what I'm adding here
174

174

00:07:27,660  -->  00:07:29,850
will be the new value of train loss.
175

175

00:07:29,850  -->  00:07:30,980
And then at the next round,
176

176

00:07:30,980  -->  00:07:33,540
that is for the next user, the new value of train loss
177

177

00:07:33,540  -->  00:07:35,380
will be the old value of train loss
178

178

00:07:35,380  -->  00:07:37,350
plus what we're gonna add here.
179

179

00:07:37,350  -->  00:07:39,750
So, what are we going to add here?
180

180

00:07:39,750  -->  00:07:41,820
We're gonna take the loss that is generated
181

181

00:07:41,820  -->  00:07:43,310
after the prediction was done.
182

182

00:07:43,310  -->  00:07:45,330
That is basically the difference between
183

183

00:07:45,330  -->  00:07:47,460
the real rating and the predicted rating.
184

184

00:07:47,460  -->  00:07:51,340
And so to get this, we need to take our loss object,
185

185

00:07:51,340  -->  00:07:53,300
then add a dot and now we're gonna get
186

186

00:07:53,300  -->  00:07:56,620
the part of this loss object that contains the error.
187

187

00:07:56,620  -->  00:08:00,130
We excess to the data in the loss object
188

188

00:08:00,130  -->  00:08:02,510
and then we need to take the index of the data
189

189

00:08:02,510  -->  00:08:04,470
that contains this train loss,
190

190

00:08:04,470  -->  00:08:07,063
and this index is actually zero.
191

191

00:08:07,063  -->  00:08:10,300
That's when we're gonna use our mean corrector,
192

192

00:08:10,300  -->  00:08:13,980
because in order to get this adjusted mean over the movies
193

193

00:08:13,980  -->  00:08:16,760
that got non-zero ratings by the user,
194

194

00:08:16,760  -->  00:08:21,760
we need to multiply our loss here, by this adjustment factor
195

195

00:08:21,810  -->  00:08:23,520
which is our mean corrector.
196

196

00:08:23,520  -->  00:08:25,260
So, we're just adjusting this loss
197

197

00:08:25,260  -->  00:08:28,750
with this mean corrector factor
198

198

00:08:28,750  -->  00:08:30,810
to compute this relevant mean,
199

199

00:08:30,810  -->  00:08:34,610
and then since this loss data is the squared error
200

200

00:08:34,610  -->  00:08:37,030
and we want to get the state of the art error,
201

201

00:08:37,030  -->  00:08:39,420
that is the one degree loss, we will take
202

202

00:08:39,420  -->  00:08:42,670
the root of this loss.data.mean_corrector.
203

203

00:08:42,670  -->  00:08:44,780
That is this adjusted square loss.
204

204

00:08:44,780  -->  00:08:46,800
And so we're gonna use here NumPy.
205

205

00:08:46,800  -->  00:08:49,440
It's been a while, but we still need NumPy
206

206

00:08:49,440  -->  00:08:50,850
and that's because we wanna take
207

207

00:08:50,850  -->  00:08:54,300
the square root function, which is S-Q-R-T.
208

208

00:08:54,300  -->  00:08:56,260
Remember, we already used it,
209

209

00:08:56,260  -->  00:08:58,530
so we're gonna put that in parentheses.
210

210

00:08:58,530  -->  00:09:01,370
And that is just to get the state of the art error,
211

211

00:09:01,370  -->  00:09:03,490
including that adjustment here.
212

212

00:09:03,490  -->  00:09:05,670
Okay, and then that's almost over.
213

213

00:09:05,670  -->  00:09:08,060
We now need to increment this s here
214

214

00:09:08,060  -->  00:09:10,300
that corresponds to the number of users
215

215

00:09:10,300  -->  00:09:12,470
who rated at least one movie,
216

216

00:09:12,470  -->  00:09:13,700
and so if that's the case,
217

217

00:09:13,700  -->  00:09:16,050
if this is the case for this user here,
218

218

00:09:16,050  -->  00:09:18,270
that is if this user here rated one movie,
219

219

00:09:18,270  -->  00:09:20,250
we need to increment s because we need
220

220

00:09:20,250  -->  00:09:22,740
to keep track of the number of such users.
221

221

00:09:22,740  -->  00:09:25,750
So, s and then to increment it by one that's the same,
222

222

00:09:25,750  -->  00:09:29,980
we use += and then one point,
223

223

00:09:29,980  -->  00:09:32,980
because remember we want s to be a float.
224

224

00:09:32,980  -->  00:09:34,910
Okay then, almost the next step.
225

225

00:09:34,910  -->  00:09:37,150
Sorry about that, it's quite long and technical,
226

226

00:09:37,150  -->  00:09:38,720
but we're almost getting to the end.
227

227

00:09:38,720  -->  00:09:42,440
This almost last step is to use the optimizer.
228

228

00:09:42,440  -->  00:09:44,040
The optimizer that we created here,
229

229

00:09:44,040  -->  00:09:46,740
because as you notice, we haven't used it yet
230

230

00:09:46,740  -->  00:09:49,730
and, of course, we need it to update the weight.
231

231

00:09:49,730  -->  00:09:51,210
I'm gonna explain right now the difference
232

232

00:09:51,210  -->  00:09:53,650
between backward and optimizer.
233

233

00:09:53,650  -->  00:09:55,710
You're gonna understand, it will be very clear.
234

234

00:09:55,710  -->  00:09:58,150
First, let's use our optimizer.
235

235

00:09:58,150  -->  00:09:59,597
We add optimizer,
236

236

00:10:00,700  -->  00:10:02,740
then dot, and then to apply it,
237

237

00:10:02,740  -->  00:10:05,820
we just need to use this method of the optimizer object
238

238

00:10:05,820  -->  00:10:09,360
from the RMSprop clause, which is step.
239

239

00:10:09,360  -->  00:10:12,500
That will just apply the optimizer to update the weights.
240

240

00:10:12,500  -->  00:10:14,030
And now, what is the difference
241

241

00:10:14,030  -->  00:10:16,820
between backward and optimizer step?
242

242

00:10:16,820  -->  00:10:19,614
Well, backward decides the direction
243

243

00:10:19,614  -->  00:10:22,150
to which the weight will be updated.
244

244

00:10:22,150  -->  00:10:24,440
That is, will they be increased or decreased?
245

245

00:10:24,440  -->  00:10:29,390
And optimizer step decides intensity of the updates.
246

246

00:10:29,390  -->  00:10:32,700
That is, the amount by which the weights will be updated.
247

247

00:10:32,700  -->  00:10:34,420
So, that decides the direction
248

248

00:10:34,420  -->  00:10:36,893
and that decides the intensity, the amount.
249

249

00:10:37,850  -->  00:10:40,690
Alright, and now, finally, the next step.
250

250

00:10:40,690  -->  00:10:43,620
Actually, optimizer.step was the last step
251

251

00:10:43,620  -->  00:10:47,650
of both the if condition and the first for loop,
252

252

00:10:47,650  -->  00:10:50,400
so we're done with dealing with our observation,
253

253

00:10:50,400  -->  00:10:51,690
taking care of all the actions
254

254

00:10:51,690  -->  00:10:53,730
that happened into the network.
255

255

00:10:53,730  -->  00:10:56,710
Now, we're getting back to this first loop here,
256

256

00:10:56,710  -->  00:11:00,660
and so I'm back here to here, because here I'm outside
257

257

00:11:00,660  -->  00:11:03,383
of this for loop and inside of this one.
258

258

00:11:03,383  -->  00:11:06,630
Now, that's the last line of code of this training
259

259

00:11:06,630  -->  00:11:10,410
and this last step consists of printing what's gonna happen
260

260

00:11:10,410  -->  00:11:13,230
at each epoch, that is what we wanna see,
261

261

00:11:13,230  -->  00:11:15,610
when the action will take place here in the console.
262

262

00:11:15,610  -->  00:11:18,280
We wanna see the loss at each error,
263

263

00:11:18,280  -->  00:11:21,190
and of course this epoch where we're at.
264

264

00:11:21,190  -->  00:11:22,023
So, let's do this.
265

265

00:11:22,023  -->  00:11:24,646
We're gonna use the print function.
266

266

00:11:24,646  -->  00:11:29,646
Let's say that we first want this train epoch,
267

267

00:11:29,900  -->  00:11:31,720
colon, space.
268

268

00:11:31,720  -->  00:11:34,100
That's just a string that will appear all the time.
269

269

00:11:34,100  -->  00:11:35,750
And then, after this epoch and string,
270

270

00:11:35,750  -->  00:11:38,740
we add the number of the epoch where we're at,
271

271

00:11:38,740  -->  00:11:40,773
and this, we get this with +str.
272

272

00:11:41,770  -->  00:11:45,070
So, str is a function to make the epoch a string.
273

273

00:11:45,070  -->  00:11:47,210
Now, we need to get the epoch where we're at,
274

274

00:11:47,210  -->  00:11:50,931
which is given by this epoch variable in the loop.
275

275

00:11:50,931  -->  00:11:52,640
Since we're still in the for loop,
276

276

00:11:52,640  -->  00:11:55,320
we can add this and that epoch.
277

277

00:11:55,320  -->  00:11:56,170
Alright.
278

278

00:11:56,170  -->  00:11:59,230
And then + and then we add some new quotes,
279

279

00:11:59,230  -->  00:12:01,460
because then we would like the loss,
280

280

00:12:01,460  -->  00:12:03,623
with colon and space again.
281

281

00:12:03,623  -->  00:12:07,160
After this loss we'll add the value of the train loss.
282

282

00:12:07,160  -->  00:12:09,710
And that is +, so we're gonna convert that
283

283

00:12:09,710  -->  00:12:12,380
into a string again and inside the parentheses,
284

284

00:12:12,380  -->  00:12:16,280
we input the value of the train loss, which is train_loss.
285

285

00:12:16,280  -->  00:12:20,950
Since we want the average, we divide this train loss by s,
286

286

00:12:20,950  -->  00:12:24,330
the number of observations that we considered in all this.
287

287

00:12:24,330  -->  00:12:26,200
That is in all these computations,
288

288

00:12:26,200  -->  00:12:27,960
and these are the number of movies
289

289

00:12:27,960  -->  00:12:30,930
that got at least one non-zero rating.
290

290

00:12:30,930  -->  00:12:33,330
That is given, of course, by s,
291

291

00:12:33,330  -->  00:12:35,440
that we made sure to increment here.
292

292

00:12:35,440  -->  00:12:37,580
So, we add here s.
293

293

00:12:37,580  -->  00:12:40,090
And here we go, that's ready!
294

294

00:12:40,090  -->  00:12:41,360
Alright, congratulations,
295

295

00:12:41,360  -->  00:12:44,580
because this was actually pretty technical.
296

296

00:12:44,580  -->  00:12:47,070
But the good news is that now you don't even
297

297

00:12:47,070  -->  00:12:48,360
have to take care about this,
298

298

00:12:48,360  -->  00:12:51,250
and if you wanna build an autoencoder model
299

299

00:12:51,250  -->  00:12:54,400
for one of your problem, whether it is a recommended system,
300

300

00:12:54,400  -->  00:12:56,430
or anything else, well you just
301

301

00:12:56,430  -->  00:12:59,270
have to change the architecture here.
302

302

00:12:59,270  -->  00:13:00,390
And maybe if you wanna try
303

303

00:13:00,390  -->  00:13:03,330
some other combinations of activation functions.
304

304

00:13:03,330  -->  00:13:04,170
That's all.
305

305

00:13:04,170  -->  00:13:05,580
You don't have to worry about this,
306

306

00:13:05,580  -->  00:13:09,090
except maybe trying different number of epochs,
307

307

00:13:09,090  -->  00:13:10,300
but in that case you just need
308

308

00:13:10,300  -->  00:13:12,650
to change the number of epochs here.
309

309

00:13:12,650  -->  00:13:14,980
Since we're getting close to the 20 minutes
310

310

00:13:14,980  -->  00:13:18,590
where we will see action taking place in the next tutorial.
311

311

00:13:18,590  -->  00:13:21,260
That is, we're gonna see the 200 epoch going on,
312

312

00:13:21,260  -->  00:13:23,390
and we will see how the RMSE evolves,
313

313

00:13:23,390  -->  00:13:26,000
and mostly what we'll get in the end.
314

314

00:13:26,000  -->  00:13:28,470
So, this is definitely going to be the exciting tutorial
315

315

00:13:28,470  -->  00:13:30,940
of this section, and I can't wait to see you there.
316

316

00:13:30,940  -->  00:13:32,553
Until then, enjoy deep learning.
