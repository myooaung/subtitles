1
00:00:02,719 --> 00:00:05,825
If you've been using Node since before containers,

2
00:00:06,320 --> 00:00:09,260
you've probably done something in production like PM2, or

3
00:00:10,010 --> 00:00:13,670
Forever, or Nodemon to manage your Node processes,

4
00:00:13,850 --> 00:00:16,730
as well as scale those processes for multi

5
00:00:16,800 --> 00:00:18,260
CPU servers.

6
00:00:18,830 --> 00:00:21,084
What that really means is Node, by default, is

7
00:00:21,830 --> 00:00:23,060
not multithreaded.

8
00:00:23,600 --> 00:00:26,518
On most servers, you're going to have multiple CPUs.

9
00:00:26,690 --> 00:00:29,651
Node won't take advantage of more than one of those CPUs by

10
00:00:30,230 --> 00:00:33,410
default. In most Node apps,

11
00:00:33,470 --> 00:00:35,959
you need to consider how you're going to run it across

12
00:00:35,960 --> 00:00:38,570
multiple CPUs on a server,

13
00:00:39,260 --> 00:00:41,610
and across multiple servers in a lot of cases.

14
00:00:42,200 --> 00:00:44,503
Traditionally, before containers, we had things

15
00:00:45,170 --> 00:00:47,642
like PM2, Forever Nodemon

16
00:00:48,380 --> 00:00:51,560
and other tools that would spin up one or more

17
00:00:51,590 --> 00:00:53,746
Node processes, running the same code, to be

18
00:00:54,890 --> 00:00:57,529
able to run on multiple CPUs concurrently, and then it

19
00:00:57,530 --> 00:01:00,199
would manage incoming connections and distribute it across

20
00:01:00,200 --> 00:01:02,870
all those. Well, Docker does that for us.

21
00:01:03,050 --> 00:01:05,285
So, whether you're using Docker, or Docker Compose,

22
00:01:06,230 --> 00:01:08,650
or maybe Swarm, or Kubernetes, or ECS,

23
00:01:09,410 --> 00:01:12,260
or some sort of container solution,

24
00:01:12,650 --> 00:01:14,572
that solution is going to take into account how

25
00:01:15,920 --> 00:01:19,250
you manage incoming connections, rather than these

26
00:01:19,340 --> 00:01:22,310
older tools that we used before containers in

27
00:01:22,370 --> 00:01:23,450
Node world.

28
00:01:23,960 --> 00:01:26,459
So, think about it from the container manager point

29
00:01:26,930 --> 00:01:28,645
of view. Realize that it's designed

30
00:01:30,200 --> 00:01:32,929
to spin up multiple containers, and most solutions, they

31
00:01:32,930 --> 00:01:33,956
call it replicas.

32
00:01:34,520 --> 00:01:37,490
You're spinning up multiple replicas, which is copies

33
00:01:37,550 --> 00:01:40,000
of that image, in multiple containers, all running

34
00:01:40,250 --> 00:01:41,250
together.

35
00:01:41,330 --> 00:01:44,420
A lot of solutions create some sort of load balancer for

36
00:01:44,450 --> 00:01:46,010
talking about incoming connections.

37
00:01:46,340 --> 00:01:48,830
They create load balancers in front of that to distribute

38
00:01:48,860 --> 00:01:51,555
incoming connections. So, you don't need to worry about

39
00:01:51,800 --> 00:01:54,409
those older tools. That's why throughout this course, I

40
00:01:54,410 --> 00:01:57,007
have asked you to run Node directly in your container

41
00:01:57,350 --> 00:02:00,400
images so that when your containers launch, there's

42
00:02:00,410 --> 00:02:03,470
not this middle layer managing different

43
00:02:03,500 --> 00:02:05,530
Node executables.

44
00:02:06,170 --> 00:02:08,990
My general guideline for production systems

45
00:02:09,440 --> 00:02:12,109
is to look at your Node apps, and of course you've got to

46
00:02:12,110 --> 00:02:14,540
consider what kind of load you want to have, and you're

47
00:02:14,550 --> 00:02:17,392
going to have to probably test some load stuff in order to

48
00:02:17,480 --> 00:02:19,490
understand how your Node app is going to work.

49
00:02:19,760 --> 00:02:22,510
But in general, in terms of CPU and consuming

50
00:02:23,120 --> 00:02:26,120
all the CPU resources, you'll want to start one

51
00:02:26,300 --> 00:02:28,865
to two containers per CPU,

52
00:02:29,570 --> 00:02:32,600
assuming that you wanted to use all of the CPU resources

53
00:02:32,780 --> 00:02:35,279
on that machine. If you had a cloud server, or some

54
00:02:35,780 --> 00:02:37,640
data center server that had

55
00:02:39,080 --> 00:02:41,360
two CPUs, then you would probably launch between four to

56
00:02:41,450 --> 00:02:44,150
eight Node containers of that image

57
00:02:44,600 --> 00:02:46,820
out-of-the-box. You may not need that many.

58
00:02:46,880 --> 00:02:50,570
Maybe you only need a couple just to provide redundancy,

59
00:02:50,690 --> 00:02:53,389
but you don't necessarily need more than that for capacity.

60
00:02:53,390 --> 00:02:56,085
And that's fine. But, realize that when you're starting

61
00:02:56,420 --> 00:02:59,036
up things in Docker, just because you have one or two Node

62
00:02:59,270 --> 00:03:01,429
containers running, doesn't mean it's going to use all

63
00:03:01,430 --> 00:03:02,813
those CPUs.

64
00:03:02,836 --> 00:03:05,629
That Node limitation still exists in Docker, which is why

65
00:03:05,720 --> 00:03:07,220
we want to start up replicas.

66
00:03:07,460 --> 00:03:09,470
Swarm does this. Kubernetes does this.

67
00:03:09,920 --> 00:03:11,750
Other orchestrators have this concept.

68
00:03:12,020 --> 00:03:14,568
If you're using Docker Compose or Docker run, you're

69
00:03:15,110 --> 00:03:17,168
going to use aliases and replicas in those

70
00:03:18,080 --> 00:03:19,080
features as well.

71
00:03:19,724 --> 00:03:21,826
When it comes to these containers inside of your CI,

72
00:03:22,850 --> 00:03:25,349
be a little bit careful about when you run multiple

73
00:03:25,580 --> 00:03:27,736
replicas, or containers, of your code inside

74
00:03:28,790 --> 00:03:31,681
of CI. You want to know specifically why you're going to do

75
00:03:31,910 --> 00:03:34,429
that because it's much harder to test when you've got

76
00:03:34,430 --> 00:03:36,830
multiple copies of your app running there.

77
00:03:37,040 --> 00:03:39,829
So, usually when you're doing unit testing, or other very

78
00:03:39,830 --> 00:03:42,440
basic testing of your code, you're going to want to run

79
00:03:42,470 --> 00:03:45,980
just one replica and have that single container output

80
00:03:46,340 --> 00:03:48,839
all the things. If you get advanced in the CI, just

81
00:03:49,310 --> 00:03:52,201
like any other solution, you could always spin up different

82
00:03:52,340 --> 00:03:54,440
containers to run different tests.

83
00:03:54,710 --> 00:03:57,111
That way, you could spread out your workloads and

84
00:03:57,710 --> 00:04:00,258
distribute them so that your testing would go faster

85
00:04:00,260 --> 00:04:03,320
instead of in a linear, synchronous fashion.

86
00:04:03,500 --> 00:04:05,080
But, that doesn't really have anything to do with Node.

87
00:04:05,480 --> 00:04:07,490
That's just how you design your CI system.

88
00:04:08,060 --> 00:04:10,951
In general, for integration testing, I might consider using

89
00:04:11,330 --> 00:04:14,025
multiple replicas if I have something that's like maybe

90
00:04:14,480 --> 00:04:17,077
a Node API, or some middle layer of Node,

91
00:04:17,690 --> 00:04:20,899
where I want to make sure that across different

92
00:04:21,019 --> 00:04:24,350
containers running, that I still get the expected output

93
00:04:24,410 --> 00:04:26,780
of my full integration and functional testing.

94
00:04:27,140 --> 00:04:29,930
You might consider that as a part of your testing workflow.

95
00:04:30,170 --> 00:04:32,914
Again, that part isn't really Node specific, but when it

96
00:04:32,930 --> 00:04:36,080
comes to containers, it's so easy for us to spin up

97
00:04:36,110 --> 00:04:38,658
multiple copies of these images into many containers

98
00:04:39,620 --> 00:04:43,130
that we sometimes forget that there are design limitations

99
00:04:43,280 --> 00:04:46,970
inherent in our application, that we may not realize

100
00:04:47,030 --> 00:04:50,330
until we're running multiple copies of that same thing,

101
00:04:50,360 --> 00:04:51,250
all at the same time.

