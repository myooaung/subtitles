WEBVTT
1
00:00:00.811 --> 00:00:04.360
We can enable CloudFront to create log files that contain detailed

2
00:00:04.360 --> 00:00:08.389
information about every user request that CloudFront receives.

3
00:00:08.389 --> 00:00:14.162
These access logs are available for both web and streaming distribution types.

4
00:00:14.162 --> 00:00:15.416
If you enable logging,

5
00:00:15.416 --> 00:00:20.034
you also specify the S3 bucket that you want CloudFront to save files in.

6
00:00:20.034 --> 00:00:23.955
This is all done while you're creating a distribution or from

7
00:00:23.955 --> 00:00:27.933
the Distribution Settings tab later on.

8
00:00:27.933 --> 00:00:30.368
Since we already have our distribution for our website,

9
00:00:30.368 --> 00:00:33.549
let's go ahead and add logging now.

10
00:00:33.549 --> 00:00:38.999
From within the CloudFront service console, open up our distribution settings.

11
00:00:38.999 --> 00:00:43.816
While on the General tab, click Edit.

12
00:00:43.816 --> 00:00:45.927
Please scroll to the end of the configuration options,

13
00:00:45.927 --> 00:00:48.467
there you will find Logging.

14
00:00:48.467 --> 00:00:51.104
Click the On option.

15
00:00:51.104 --> 00:00:52.230
After clicking on,

16
00:00:52.230 --> 00:00:57.952
the bucket for logs and log prefix options just became available for editing.

17
00:00:57.952 --> 00:00:59.681
In bucket for logs,

18
00:00:59.681 --> 00:01:04.899
enter the bucket name which you would like to store your logs in.

19
00:01:04.899 --> 00:01:07.704
I've already created an S3 bucket for this purpose,

20
00:01:07.704 --> 00:01:11.242
which is called the event-logs.

21
00:01:11.242 --> 00:01:14.126
I like to separate my logs by including prefixes for each

22
00:01:14.126 --> 00:01:17.324
service I have logging to my S3 bucket.

23
00:01:17.324 --> 00:01:25.094
So in the bucket for logs field, I'll add the event-logs bucket,

24
00:01:25.094 --> 00:01:32.339
and for log prefix, I'll use CloudFront/distribution id/.

25
00:01:32.339 --> 00:01:35.609
That way my logs are logically organized.

26
00:01:35.609 --> 00:01:38.410
So if I look in the bucket for CloudFront logs,

27
00:01:38.410 --> 00:01:43.071
then look in the CloudFront prefix,

28
00:01:43.071 --> 00:01:47.667
there I'll find a folder that matches my distributions ID.

29
00:01:47.667 --> 00:01:52.353
Within that folder, that's where I can find all my logs.

30
00:01:52.353 --> 00:01:59.391
So now click Yes, Edit to deploy this config to CloudFront.

31
00:01:59.391 --> 00:02:00.773
Once this is deployed,

32
00:02:00.773 --> 00:02:04.037
CloudFront will start delivering access logs in the W3C

33
00:02:04.037 --> 00:02:08.864
extended log file format to my bucket.

34
00:02:08.864 --> 00:02:11.961
Logging works in the following way.

35
00:02:11.961 --> 00:02:17.228
A viewer request content using the URLs associated with the distribution.

36
00:02:17.228 --> 00:02:22.381
CloudFront routes each request to the appropriate edge location.

37
00:02:22.381 --> 00:02:26.181
CloudFront writes data about each request to a log

38
00:02:26.181 --> 00:02:28.742
file specific to that distribution.

39
00:02:28.742 --> 00:02:32.222
CloudFront periodically saves the log file for that distribution

40
00:02:32.222 --> 00:02:36.511
into the S3 bucket specified when enabling logging.

41
00:02:36.511 --> 00:02:38.893
CloudFront then starts saving information about

42
00:02:38.893 --> 00:02:43.495
subsequent requests in a new log file.

43
00:02:43.495 --> 00:02:49.316
And each entry in a log file gives detail about a single request.

44
00:02:49.316 --> 00:02:52.985
So a few things to know about the logs,

45
00:02:52.985 --> 00:02:57.420
they are written in W3C extended log file format,

46
00:02:57.420 --> 00:03:02.025
they contain tab-separated values,

47
00:03:02.025 --> 00:03:06.541
and records are not necessarily in chronological order.

48
00:03:06.541 --> 00:03:12.586
All spaces and non-standard characters are substituted with URL encoded

49
00:03:12.586 --> 00:03:18.557
equivalents and every file begins with two header lines.

50
00:03:18.557 --> 00:03:22.333
The first one is file format version,

51
00:03:22.333 --> 00:03:30.050
the second one lists all of the fields included in each record.

52
00:03:30.050 --> 00:03:35.020
Every log entry contains the following 26 fields.

53
00:03:35.020 --> 00:03:40.846
Every record begins with the date that the request occurred.

54
00:03:40.846 --> 00:03:44.116
Next is the time that the request occurred and both

55
00:03:44.116 --> 00:03:47.604
the date and time are in UTC.

56
00:03:47.604 --> 00:03:50.464
Edge location is a three-letter plus random number identifier

57
00:03:50.464 --> 00:03:54.857
of the edge cache that handled the request.

58
00:03:54.857 --> 00:03:58.303
Bytes refers to the total number of bytes that CloudFront

59
00:03:58.303 --> 00:04:03.095
served to the viewer including headers.

60
00:04:03.095 --> 00:04:08.609
IP is the real IP of the requester.

61
00:04:08.609 --> 00:04:12.575
This field is the verb that was used during the request,

62
00:04:12.575 --> 00:04:16.531
which is get, post, put, delete.

63
00:04:16.531 --> 00:04:20.633
This host field is the domain name of the distribution.

64
00:04:20.633 --> 00:04:23.486
This could be the domain name that's generated by

65
00:04:23.486 --> 00:04:27.896
CloudFront when it was created or a CNAME or alias that

66
00:04:27.896 --> 00:04:32.583
you've attached to the distribution.

67
00:04:32.583 --> 00:04:38.033
URI stem matches the path that was included in the request.

68
00:04:38.033 --> 00:04:47.244
The status is the status response code, so 200, 300, 400, 500s.

69
00:04:47.244 --> 00:04:51.945
Refer refers to the domain name that originated the request.

70
00:04:51.945 --> 00:04:57.514
So if somebody clicked on the link from a Google search engine result page,

71
00:04:57.514 --> 00:05:01.324
that would probably be from Google or somebody's Facebook

72
00:05:01.324 --> 00:05:05.989
feed or Twitter that would show up as that.

73
00:05:05.989 --> 00:05:12.056
CloudFront reads the URI stem and query strings as two different items.

74
00:05:12.056 --> 00:05:15.175
The query string is what is stored here in this field,

75
00:05:15.175 --> 00:05:20.446
and if you enable cookie logging from your distribution settings,

76
00:05:20.446 --> 00:05:24.352
then the full value of the cookie is stored in this value.

77
00:05:24.352 --> 00:05:27.909
When your request hits the edge cache,

78
00:05:27.909 --> 00:05:32.603
CloudFront has to decide whether it has it in its local cache,

79
00:05:32.603 --> 00:05:34.441
which would mean hit.

80
00:05:34.441 --> 00:05:37.086
If it doesn't have it and it has to reach out to origin,

81
00:05:37.086 --> 00:05:38.893
then that would be a miss.

82
00:05:38.893 --> 00:05:43.048
Those values are stored under edge result type.

83
00:05:43.048 --> 00:05:48.341
Every single request that hits the edge cache is given a unique identifier,

84
00:05:48.341 --> 00:05:52.083
that's your edge request id.

85
00:05:52.083 --> 00:05:57.348
Host-header stores the value of any host header sent with the request.

86
00:05:57.348 --> 00:06:05.298
Protocol lets us know whether the request was an HTTP or an HTTPS request.

87
00:06:05.298 --> 00:06:07.644
This bytes field is different from the earlier one because

88
00:06:07.644 --> 00:06:11.415
this is the total bytes of the request received by the

89
00:06:11.415 --> 00:06:15.996
edge cache from the requester.

90
00:06:15.996 --> 00:06:20.197
CloudFront measures the time between when an edge cache receives the request

91
00:06:20.197 --> 00:06:26.722
and when CloudFront has fully responded to the requester.

92
00:06:26.722 --> 00:06:32.274
Forwarded-for stores the IP address if the request came through a proxy.

93
00:06:32.274 --> 00:06:37.162
This protocol field stores the version of the SSL or

94
00:06:37.162 --> 00:06:40.181
TLS that was used during the request.

95
00:06:40.181 --> 00:06:46.497
And cipher lists the cipher set used to negotiate the request.

96
00:06:46.497 --> 00:06:49.832
This is how CloudFront classified the response

97
00:06:49.832 --> 00:06:52.936
before returning it to the viewer.

98
00:06:52.936 --> 00:07:02.493
Protocol-version refers to the version of HTTP used so HTTP 1.1, 2.0.

99
00:07:02.493 --> 00:07:06.907
Status shows status performance of any encrypted fields.

100
00:07:06.907 --> 00:07:08.581
And last, but not least,

101
00:07:08.581 --> 00:07:15.869
encrypted-fields list the total number of encrypted fields sent to the origin.

102
00:07:15.869 --> 00:07:17.810
Once logs have been flowing into your S3 bucket,

103
00:07:17.810 --> 00:07:21.845
you can download the log file in order to review it.

104
00:07:21.845 --> 00:07:25.311
Logs use the following naming convention.

105
00:07:25.311 --> 00:07:29.307
There are two sides to this name, the elements defined by the admin,

106
00:07:29.307 --> 00:07:32.488
which are the bucket name and the prefix,

107
00:07:32.488 --> 00:07:37.376
the rest are defined by AWS.

108
00:07:37.376 --> 00:07:39.137
Okay, so when reviewing log files,

109
00:07:39.137 --> 00:07:42.266
it can become quite tedious to review them one by one.

110
00:07:42.266 --> 00:07:46.270
It's better to ship these files into some sort of tool which you can use

111
00:07:46.270 --> 00:07:49.757
to query all or a subset of these logs all at once.

112
00:07:49.757 --> 00:07:55.699
You can keep your logs within S3 and use a service like Amazon Athena.

113
00:07:55.699 --> 00:07:59.335
Athena is an interactive query service that makes it easy to analyze

114
00:07:59.335 --> 00:08:04.588
data from your S3 bucket using standard SQL queries.

115
00:08:04.588 --> 00:08:08.353
It's serverless so there is no infrastructure to manage and you

116
00:08:08.353 --> 00:08:13.017
really you only pay for the queries that you run.

117
00:08:13.017 --> 00:08:14.843
If you already have an Elasticsearch database,

118
00:08:14.843 --> 00:08:17.343
you can ship your logs to that as well.

119
00:08:17.343 --> 00:08:20.647
The only difference is that Elasticsearch can adjust directly from S3,

120
00:08:20.647 --> 00:08:24.933
so you would need to set up a lambda function to get your files,

121
00:08:24.933 --> 00:08:31.720
unzip them, and transform them to just to send them into Elasticsearch.

122
00:08:31.720 --> 00:08:34.483
Well, I think we have a good handle on logging now.

123
00:08:34.483 --> 00:08:38.403
CloudFront is configured to log to our S3 bucket and you should have

124
00:08:38.403 --> 00:08:40.485
a decent understanding of how logs are delivered,

125
00:08:40.485 --> 00:08:50.000
plus after ready through a log entry, you can see how much detail is provided. Let's move on to monitoring and alerting.

