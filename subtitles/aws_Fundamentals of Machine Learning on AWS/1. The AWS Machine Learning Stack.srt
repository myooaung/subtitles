1
00:00:01,040 --> 00:00:03,330
[Autogenerated] hi there, and welcome to this next module.

2
00:00:03,330 --> 00:00:04,750
I'm still Amber Israel sent,

3
00:00:04,750 --> 00:00:08,180
and thanks for sticking with me over the last few modules,

4
00:00:08,180 --> 00:00:11,470
we've gone through the process of fetching and preparing data training and

5
00:00:11,470 --> 00:00:15,140
evaluating the model and then deploying and monitoring it.

6
00:00:15,140 --> 00:00:15,680
To do this.

7
00:00:15,680 --> 00:00:18,230
We've been using various capabilities of sage maker,

8
00:00:18,230 --> 00:00:24,440
but there's a lot more to the overall a i M l ecosystem in Amazon Web Services.

9
00:00:24,440 --> 00:00:26,240
Like all of this,

10
00:00:26,240 --> 00:00:29,450
we've seen a few of the things in the middle there under ML services,

11
00:00:29,450 --> 00:00:32,370
things like notebooks, algorithms, training,

12
00:00:32,370 --> 00:00:35,240
some optimization deployment and hosting.

13
00:00:35,240 --> 00:00:37,740
But let's look at the rest of the stack.

14
00:00:37,740 --> 00:00:38,470
Generally speaking,

15
00:00:38,470 --> 00:00:41,720
it goes from higher level and abstracted at the top of the diagram,

16
00:00:41,720 --> 00:00:43,690
where you really don't want to deal with the details

17
00:00:43,690 --> 00:00:46,040
of building and training the model.

18
00:00:46,040 --> 00:00:48,950
Then in the middle with sage maker, there's a little bit more control,

19
00:00:48,950 --> 00:00:52,710
but sage maker still doing a lot of the heavy lifting and then the bottom

20
00:00:52,710 --> 00:00:55,940
layer where your more comfortable working at the framework level and having

21
00:00:55,940 --> 00:01:04,000
more control over the underlying infrastructure. Let's take a little bit deeper on the top level AI services

