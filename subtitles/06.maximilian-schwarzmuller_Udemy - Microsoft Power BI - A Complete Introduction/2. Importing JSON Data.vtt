WEBVTT

00:02.060 --> 00:07.310
I prepared this data.json file which you can find attached to this video and you may download it and if

00:07.310 --> 00:09.680
you open it like this, it's pretty hard to read.

00:09.830 --> 00:11.670
It's in the json format obviously

00:11.810 --> 00:17.230
and here what we will have some sales and then it's an array of sales or a list of sales with structured

00:17.230 --> 00:18.490
data in that array

00:18.680 --> 00:24.650
and that is also what makes up json, this structured data approach with nested objects.

00:24.740 --> 00:29.550
We will see in a second why that is tricky or special when importing it.

00:29.900 --> 00:32.570
So that's the data, you can find it attached as mentioned,

00:32.750 --> 00:37.330
now I'm in a brand new Power BI project and of course I want to get some data

00:37.430 --> 00:43.490
and now if we click on more, we obviously see a lot of import data sources and you saw that before.

00:43.490 --> 00:49.640
Now as mentioned, we'll have a look at JSON, MySQL and the web here in this module and I want to

00:49.640 --> 00:50.970
start with JSON

00:50.990 --> 00:54.200
since we just saw that we have some data in the JSON format.

00:54.410 --> 00:59.310
So let's double-click JSON and pick that data.json file we find attached

00:59.570 --> 01:03.880
and now it looks something like that and that of course is data which is pretty hard to work with,

01:03.920 --> 01:08.300
it's just sales and a list. We can click on list actually

01:08.370 --> 01:10.570
and now we have a list of records,

01:10.580 --> 01:13.000
still not that useful.

01:13.040 --> 01:19.670
Now you can click on one of these records and you see a single item in this sales array.

01:19.670 --> 01:27.020
So here that's for India, we have a volume of 120 and then we have even more nested data, the transactions which

01:27.020 --> 01:29.530
is again a list of records,

01:29.620 --> 01:33.000
if we open that, now we get the individual transactions.

01:33.260 --> 01:36.680
Now it would be nice to have one single table with all the data

01:36.980 --> 01:43.450
than having, well these kind of nested data source here which makes it really hard to work with and is not

01:43.450 --> 01:45.800
really in the format we want to work with.

01:45.860 --> 01:53.270
So let's not drill down into that and let's instead simply convert this into a table on the top left

01:53.270 --> 01:54.040
here.

01:54.200 --> 01:58.770
If you click this, now you see it converts this in a table

01:58.790 --> 02:06.320
so far that it created a column name with our sales and a value which is still a list. Here

02:06.330 --> 02:10.210
however we get a new button and that actually is the same button

02:10.310 --> 02:17.610
you can find on transform and then it's here, expand.

02:18.040 --> 02:23.980
If you select this column, you can click expand or again, this button and you are asked to expand

02:24.010 --> 02:27.150
this in new rows or extract the values.

02:27.550 --> 02:29.040
Let's start with the values

02:29.050 --> 02:37.450
and if we click OK here, take a few seconds, you see that didn't really work because extracted values

02:37.570 --> 02:40.990
would only work if we had a list of values in there we could use.

02:41.140 --> 02:42.070
We don't however,

02:42.100 --> 02:44.450
we have more structured data in there,

02:44.710 --> 02:49.840
so instead what I will do is I will choose the first option and expand to new rows and

02:49.870 --> 02:55.380
now we have a couple of sales records where we have the individual records.

02:55.420 --> 03:00.820
So the list has been mapped into our main table which is what we want because we want to work with one

03:00.820 --> 03:01.900
single table in the end,

03:01.900 --> 03:05.250
right? Now however that is still not that useful,

03:05.260 --> 03:07.600
so why don't we expand this one more time

03:07.630 --> 03:11.360
and keep in mind, you can always do this here on the right structured column expand

03:11.820 --> 03:15.640
and now you were actually asked which fields do you want to expand

03:15.700 --> 03:20.620
because if I close this and we drill into one of these records, you see these are the three fields we

03:20.620 --> 03:21.630
have, region,

03:21.700 --> 03:27.690
volume and transactions. Now with that, we can remove that and

03:27.760 --> 03:29.570
let's pick OK now.

03:29.710 --> 03:35.140
Now we're extracting the values because we don't need to add new rows, we don't have structured data

03:35.140 --> 03:35.890
on that level,

03:35.890 --> 03:38.620
we had three value fields instead

03:38.980 --> 03:42.190
and here we have the three values, we have our regions,

03:42.490 --> 03:48.940
our volumes for the regions and then again, a list. Now inside the list, we again have structured data

03:48.990 --> 03:49.380
though.

03:49.510 --> 03:51.970
So if you choose extract values here again,

03:52.360 --> 03:57.600
well guess what? We get an error again because if we have a look at a list item, it's a record,

03:57.640 --> 03:58.780
it's a structured data,

03:58.840 --> 04:01.200
we can't see any values there.

04:01.210 --> 04:08.300
So instead, let's remove that step here and I click expand again, expand to new rows,

04:08.560 --> 04:15.220
now that looks better. Now we have sales for the different regions with the volumes and we have multiple rows

04:15.220 --> 04:20.180
for each region because we have the different individual records, the transactions.

04:20.560 --> 04:25.470
So now if we click this one more time and we extract the values. date and volume,

04:25.600 --> 04:30.340
now we have the finished table with our sales for regions, with the total volume

04:30.340 --> 04:32.880
and then individual transactions.

04:32.980 --> 04:35.520
Now of course it depends on what you want to analyze,

04:35.650 --> 04:40.750
maybe you were only interested in the total volume, then you could have stopped way earlier. If you are

04:40.750 --> 04:42.470
interested in individual transactions,

04:42.610 --> 04:49.960
this is how you drill down and create a table of the structured data in a unstructured data here, in a

04:50.290 --> 04:52.490
table, in a two dimensional table

04:52.660 --> 04:57.420
by expanding the different datasets you had in your data source.

04:57.780 --> 05:00.610
So that's now the finished table I want to work with,

05:00.730 --> 05:05.230
the last thing I want to do is I want to assign some types here.

05:05.350 --> 05:11.650
So what I do want to do is I want to right-click on my volumes, change the type to a whole number and

05:11.650 --> 05:13.550
do the same for the value volume

05:13.540 --> 05:17.950
here, whole number and that here should clearly be a date,

05:18.010 --> 05:23.640
so let's pick date. With all that, we can click close and apply to apply the data

05:23.890 --> 05:26.320
and we're now ready to analyze that.

05:26.320 --> 05:33.880
So for example, we could create a column chart here which is a bit bigger, then pull our transaction values

05:33.880 --> 05:34.300
in there,

05:34.300 --> 05:36.890
so let me resize that

05:37.180 --> 05:47.420
and now let's take the volume of our transactions into the value field, maybe date as an axis and finally,

05:47.480 --> 05:50.290
the value region as legend.

05:50.320 --> 05:57.170
Finally let me increase this a bit more, so that we not only see it on a per year basis, we could drill down

05:57.170 --> 06:05.910
do quarterly or monthly data and now we see for the different regions, our different values. That

06:05.930 --> 06:07.730
would be the finished analysis,

06:07.730 --> 06:09.830
the chart is not that interesting here,

06:09.830 --> 06:15.350
the key part was to understand how you can import JSON and I hope this became a bit clearer. How you

06:15.350 --> 06:22.250
drill down and how you expand these columns which hold the structured data or the lists of values

06:22.760 --> 06:25.870
and how to then get this into a two dimensional table.
