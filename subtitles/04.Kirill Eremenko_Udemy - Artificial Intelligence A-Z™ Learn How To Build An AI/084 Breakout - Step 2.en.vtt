WEBVTT
1
00:00:00.490 --> 00:00:02.550
Hello and welcome to this tutorial.

2
00:00:02.560 --> 00:00:07.550
All right so we're going to start with the first fellow of our moral and the most important fowl that's

3
00:00:07.630 --> 00:00:08.410
muddled up.

4
00:00:08.440 --> 00:00:09.020
Why.

5
00:00:09.180 --> 00:00:14.590
And this is in this file that we will implement the brain of the homo you know the brain at the heart

6
00:00:14.650 --> 00:00:20.290
of the 8:3 Simmo that's in this file that will make the neural network which will of course contain

7
00:00:20.290 --> 00:00:25.030
some convolutional will know when that works because of course we're still doing some deep reinforcement

8
00:00:25.030 --> 00:00:25.570
learning.

9
00:00:25.690 --> 00:00:31.690
So are able to have eyes and inside this neural network will integrate everything that is related to

10
00:00:31.870 --> 00:00:34.600
the active Craigmile and there is a bonus.

11
00:00:34.630 --> 00:00:39.550
As I told you we are implementing one of the most powerful A-3 morals and what makes it that powerful

12
00:00:39.550 --> 00:00:45.910
is that it will contain a record a new network and more precisely in LCN long term memory so that we

13
00:00:45.910 --> 00:00:48.660
can learn the temporal properties of what's going on.

14
00:00:48.670 --> 00:00:54.710
Again that is actually the temporal properties of the input so that the predictions can be even better.

15
00:00:55.270 --> 00:00:56.050
So there we go.

16
00:00:56.050 --> 00:01:01.330
We are implementing a very powerful model that combines basically all the neural networks that we saw

17
00:01:01.420 --> 00:01:02.590
in the deepening course.

18
00:01:02.680 --> 00:01:08.070
That is an artificial neural network a convolutional neural network and a record new network.

19
00:01:08.260 --> 00:01:13.240
And at the heart of all these networks there is of course the A-380 model that will make the AI AI very

20
00:01:13.240 --> 00:01:14.040
powerful.

21
00:01:14.410 --> 00:01:18.300
So let's do this let's attack this model and implemented.

22
00:01:18.430 --> 00:01:21.760
So we're going to start by making two functions.

23
00:01:21.850 --> 00:01:26.410
There are just some functions that will take care of how we can initialize the weights because you know

24
00:01:26.410 --> 00:01:30.460
we're going to have some new networks and therefore we're going to have weights and we just want to

25
00:01:30.460 --> 00:01:36.740
make these two functions for us so that we already have a tool to integrate very easily inside the home

26
00:01:36.750 --> 00:01:38.090
so the neural network.

27
00:01:38.290 --> 00:01:41.600
So these two functions are going to be normalized columns.

28
00:01:41.600 --> 00:01:48.730
Initialiser that is basically a function that can not only initialize some weights but sets a specific

29
00:01:48.730 --> 00:01:50.370
variance of tensor weights.

30
00:01:50.380 --> 00:01:52.770
So that's exactly what we're about to implement right now.

31
00:01:53.020 --> 00:01:57.700
And then we will implement the second function which will be the weights in that function and that will

32
00:01:57.700 --> 00:02:01.840
basically initialize the weights in enough time a way for the learning.

33
00:02:01.840 --> 00:02:02.330
All right.

34
00:02:02.350 --> 00:02:08.070
And then once we're done with these two functions we will start implementing the neural network.

35
00:02:08.330 --> 00:02:14.770
So let's do it let's quickly make these two functions so I'm starting with a def here then I'm going

36
00:02:14.770 --> 00:02:24.420
to give the name of this function which is normalized and these core columns underscore initialiser.

37
00:02:24.720 --> 00:02:25.550
There we go.

38
00:02:25.650 --> 00:02:28.780
And this function is going to take just two inputs.

39
00:02:29.010 --> 00:02:35.790
First it's going to be the weights we want to initialize and the standard deviation because as I just

40
00:02:35.790 --> 00:02:40.200
said we want to set a specific variance for our tensor of weights.

41
00:02:40.230 --> 00:02:45.300
And if you want to understand why we have to do this it's because you know when we make the neural network

42
00:02:45.620 --> 00:02:50.490
that will be the actor and the critic according to the through tomorrow and we'll make two separate

43
00:02:50.490 --> 00:02:53.670
fully connected layers one for the actor and one for the critic.

44
00:02:53.880 --> 00:02:59.970
And these two fully connected layers will have weights and we will set a standard deviation for each

45
00:02:59.970 --> 00:03:01.810
of these two groups of weights.

46
00:03:01.860 --> 00:03:05.650
And so what we'll do is we will set a small standard deviation for the actor.

47
00:03:05.700 --> 00:03:12.570
It will be around 0.01 and a big standard deviation for the critic which will be around 1 I think.

48
00:03:12.750 --> 00:03:18.690
So that's why we're making this function so that we can very easily set the standard deviation for the

49
00:03:18.690 --> 00:03:21.900
weights we will initialize later for the actor and the craic.

50
00:03:21.930 --> 00:03:23.560
That's why we're doing this.

51
00:03:23.560 --> 00:03:28.860
So now we're just going to set a default value but this will change afterwards when we initialize the

52
00:03:28.860 --> 00:03:29.500
weights.

53
00:03:29.520 --> 00:03:32.100
So let's use so for 1.0.

54
00:03:32.240 --> 00:03:32.920
All right.

55
00:03:33.000 --> 00:03:37.340
And now we're ready to define what's inside this function.

56
00:03:37.410 --> 00:03:41.960
So what will first prepare is the output that we're going to call out.

57
00:03:42.000 --> 00:03:46.310
So this out for all is what will be returned by this function.

58
00:03:46.380 --> 00:03:50.210
And so at first what we're going to do is it.

59
00:03:50.330 --> 00:03:56.750
So as you understood this output will be a tensor of weights that will have a specific standard deviation.

60
00:03:56.850 --> 00:04:01.970
But before we take care of setting the standard deviation we just want to initialize it and then we'll

61
00:04:02.010 --> 00:04:06.550
set the standard deviation here which is the argument which is the input of this function.

62
00:04:06.870 --> 00:04:10.670
So out into initialize tensor weights you might know how to do it.

63
00:04:10.680 --> 00:04:12.150
We already did it.

64
00:04:12.180 --> 00:04:20.250
We're going to use our torche library and from this torche library we will take the round and function

65
00:04:21.180 --> 00:04:27.540
which will initialize the torched answer with random weights that follow a normal distribution.

66
00:04:27.540 --> 00:04:29.630
So that's why it is called rant.

67
00:04:29.820 --> 00:04:31.100
And as for normal.

68
00:04:31.230 --> 00:04:36.380
And so now what we simply need to input is the number of elements that distention will contain.

69
00:04:36.510 --> 00:04:41.510
And this number of elements is of course the number of weights because we were actually initializing

70
00:04:41.500 --> 00:04:43.140
a tensor for these weights here.

71
00:04:43.350 --> 00:04:53.410
And so to get this number of elements we can simply take our weights and add dot to get size with parenthesis.

72
00:04:53.410 --> 00:05:00.280
And this will give the number of elements and weights so that it will create the torch tensor of the

73
00:05:00.280 --> 00:05:05.320
same number of elements of our weights and it will be initialized with random weights following a normal

74
00:05:05.320 --> 00:05:06.860
distribution.

75
00:05:06.860 --> 00:05:07.330
All right.

76
00:05:07.360 --> 00:05:13.390
And now it is time to set the standard deviation we want to have that is the standard deviation here.

77
00:05:13.510 --> 00:05:16.960
So we're going to do now is a simple normalization.

78
00:05:16.960 --> 00:05:21.400
We have a tortured sense of weights and now we want to normalize it.

79
00:05:21.600 --> 00:05:25.810
And so to normalize it will simply write the explicit computation.

80
00:05:25.840 --> 00:05:34.960
And so what we simply need to do here is take our output then update it by multiplying it by the standard

81
00:05:34.960 --> 00:05:41.140
deviation we want to have divided by the sum I have just mentioned.

82
00:05:41.140 --> 00:05:44.960
And so to get the sum we're going to use the square root function by torch.

83
00:05:45.010 --> 00:05:48.700
And so that's when taken here torche that s q r t.

84
00:05:48.820 --> 00:05:50.710
That's the square root function.

85
00:05:50.830 --> 00:05:55.980
And inside we are going to input the square some of the weights of a vector.

86
00:05:56.160 --> 00:05:58.000
And so we take our outputs.

87
00:05:58.210 --> 00:06:06.040
Then we use the power function to which we input to because we want to take the square of the sum and

88
00:06:06.040 --> 00:06:08.950
then we take therefore the sun.

89
00:06:09.000 --> 00:06:15.300
And inside we are going to specify the index of the cone that contains the weight.

90
00:06:15.310 --> 00:06:23.990
Want to some and then to get these weights separately because you want to sum them well we usually expand

91
00:06:24.490 --> 00:06:29.440
on the school as a function of our output out.

92
00:06:29.470 --> 00:06:29.820
All right.

93
00:06:29.820 --> 00:06:37.280
So this will get the weights out which so far was initialized as a Torchin sort of weights that gets

94
00:06:37.340 --> 00:06:38.320
all these weights.

95
00:06:38.330 --> 00:06:43.850
We take the sum of square and then we take the square root to apply the normalization.

96
00:06:44.030 --> 00:06:50.230
And the fact that we have this standard deviation at the numerator we'll make sure that we can write

97
00:06:50.230 --> 00:06:50.900
it here.

98
00:06:51.960 --> 00:06:58.890
Variants out will be equal to the square of the standard deviation.

99
00:06:58.890 --> 00:07:05.940
This formula here will make sure that this tensor of weights that we initialized will have a variance

100
00:07:06.030 --> 00:07:10.860
that will be equal to the square of the standard deviation that we put as arguments.

101
00:07:11.190 --> 00:07:17.940
And that is how we can set a specific standard deviation for the future actually and critic that will

102
00:07:17.940 --> 00:07:24.150
make soon and we will choose a small standard deviation for the actor and a larger one for the critic

103
00:07:24.340 --> 00:07:27.780
and we will do this very easily since this function.

104
00:07:27.780 --> 00:07:28.150
All right.

105
00:07:28.170 --> 00:07:31.120
And so now we have only one thing to do left.

106
00:07:31.200 --> 00:07:38.940
It's of course to return the output that is now normalized with this specific standard deviation.

107
00:07:38.940 --> 00:07:40.340
All right so perfect.

108
00:07:40.350 --> 00:07:42.680
That's the first function we had to make.

109
00:07:42.870 --> 00:07:46.220
That's the first tool we will be very happy to use tonight.

110
00:07:46.250 --> 00:07:47.290
H-3 sea brain.

111
00:07:47.370 --> 00:07:49.250
We have one more function to make now.

112
00:07:49.350 --> 00:07:51.130
It's going to be the weight function.

113
00:07:51.360 --> 00:07:57.160
And that's just a function that will remind initialize the weights to make the learning optimal.

114
00:07:57.570 --> 00:08:01.110
So let's do this in the next tutorial and until then I.
