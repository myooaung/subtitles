WEBVTT
1
00:00:00.420 --> 00:00:04.730
Hello and welcome to the very last step of this part one building the.

2
00:00:04.860 --> 00:00:10.500
Now the only thing that we have to do left is to make this the Ford function that will propagate the

3
00:00:10.500 --> 00:00:16.650
signal from the very beginning when the brain is getting the image to the very end when I place the

4
00:00:16.650 --> 00:00:22.260
action so we're going to make this whole function and that's going to be our last step before we move

5
00:00:22.260 --> 00:00:26.710
on to part to training our AI with deep convolutional kulang.

6
00:00:26.890 --> 00:00:28.080
So let's do this.

7
00:00:28.080 --> 00:00:34.470
We are going to take the function call which actually is similar to the init function that is it's an

8
00:00:34.470 --> 00:00:38.760
existing function but this time we use it to call some other functions.

9
00:00:38.790 --> 00:00:43.170
The ones that we made before because you know we're going to use the forward function from the brain

10
00:00:43.290 --> 00:00:45.490
and the port function from the body.

11
00:00:45.630 --> 00:00:50.270
And so we're using this function now to basically call these functions.

12
00:00:50.550 --> 00:00:53.160
So call is going to take two arguments.

13
00:00:53.160 --> 00:00:54.330
The first one is self.

14
00:00:54.330 --> 00:01:00.220
Of course the object and the second argument which according to you what is it going to be.

15
00:01:00.360 --> 00:01:02.910
Well we are doing the whole propagation this time.

16
00:01:02.910 --> 00:01:08.460
So what we want to take as input is of course the input images because of course that's the starting

17
00:01:08.460 --> 00:01:10.860
point when the AI is playing the game.

18
00:01:10.860 --> 00:01:16.080
It is first visualizing the images of the game then propagates the signals in the brain and then plays

19
00:01:16.080 --> 00:01:17.180
the action.

20
00:01:17.190 --> 00:01:20.130
Therefore the second argument is going to be inputs.

21
00:01:20.610 --> 00:01:24.740
And now we are ready to make this whole propagation.

22
00:01:24.810 --> 00:01:26.220
So let's do this again.

23
00:01:26.220 --> 00:01:31.900
So the first step where is it the first step is receiving the input images from the game.

24
00:01:32.190 --> 00:01:38.010
And since these images are going to enter the neural network Well you can imagine that we have to format

25
00:01:38.010 --> 00:01:42.840
them in a special structure and the structure is of course a torch structure.

26
00:01:42.840 --> 00:01:48.420
So the first thing that will happen is that we will convert these images into an umpire array then we

27
00:01:48.420 --> 00:01:55.320
will convert it into a torch tensor and then finally we will put the torch tensor inside a torch variable

28
00:01:55.500 --> 00:01:58.260
that will contain both the tensor and a gradient.

29
00:01:58.350 --> 00:02:03.780
That's for our dynamic graphs to compute very efficiently the gradients later faster Kattie great in

30
00:02:03.780 --> 00:02:04.460
the sense.

31
00:02:04.620 --> 00:02:06.200
So that's our first step.

32
00:02:06.270 --> 00:02:12.130
And then once we get the right format of our images well they will be able to enter the neural network

33
00:02:12.360 --> 00:02:16.320
and then that's where we'll do the whole propagation of the signals.

34
00:02:16.380 --> 00:02:20.340
So let's do this first that converting the image into the right format.

35
00:02:20.430 --> 00:02:23.050
So our images are so for inputs.

36
00:02:23.220 --> 00:02:26.780
Now we're going to create a new variable which I'm calling input.

37
00:02:26.820 --> 00:02:30.470
So that's the real input of the neural network and this input.

38
00:02:30.510 --> 00:02:31.760
Where is it going to be.

39
00:02:31.920 --> 00:02:34.490
Well first we need to take our inputs.

40
00:02:34.530 --> 00:02:36.650
That is our original images.

41
00:02:36.870 --> 00:02:42.190
Then as we said we want to convert these images into Nampa arrays.

42
00:02:42.330 --> 00:02:49.260
So to do this we can simply take none by which has a shortcut and then the function array.

43
00:02:49.500 --> 00:02:52.850
So we put in put in the parentheses of the function array.

44
00:02:52.890 --> 00:02:53.340
There we go.

45
00:02:53.340 --> 00:02:55.940
Now it is converted into something and by arrays.

46
00:02:56.190 --> 00:03:02.790
But then since the cells of the numpad arrays will contain the pixels it is actually safer to specify

47
00:03:02.790 --> 00:03:04.230
the type float.

48
00:03:04.310 --> 00:03:11.040
It's better to make sure we have some floats right now to make sure that we can use that float.

49
00:03:11.090 --> 00:03:12.690
Sorry to hear.

50
00:03:12.720 --> 00:03:15.390
All right so now we still have an umpire.

51
00:03:15.540 --> 00:03:17.330
But with the tablet.

52
00:03:17.720 --> 00:03:24.150
All right and that's also another reason it's that tensors are by definition arrays of a single type.

53
00:03:24.270 --> 00:03:28.060
And so we choose the single type to be a float float 32.

54
00:03:28.060 --> 00:03:28.350
All right.

55
00:03:28.350 --> 00:03:34.440
Now that we have our non-bio raise the next step is to convert that into a tortoise sensor and to do

56
00:03:34.440 --> 00:03:37.990
this we can use for example torch.

57
00:03:38.070 --> 00:03:45.380
And then from underscore non-pilot function that will convert that into a torch sensor.

58
00:03:45.420 --> 00:03:46.200
There we go.

59
00:03:46.210 --> 00:03:52.320
And now the last step is to put these torch sensors into a torch variable containing both the tensor

60
00:03:52.320 --> 00:03:53.230
and the agreement.

61
00:03:53.400 --> 00:04:02.010
And you know how to do it of course we take our variable class because actually everything that is inside

62
00:04:02.010 --> 00:04:05.530
this variable is actually the input of the variable class.

63
00:04:05.760 --> 00:04:11.400
But I wanted to show that to you this way because you know we start with our input images then we convert

64
00:04:11.400 --> 00:04:15.890
them into numbered arrays then to torch tensors and then tomorrow.

65
00:04:16.170 --> 00:04:17.220
And now we're good.

66
00:04:17.220 --> 00:04:23.370
They are allowed to enter the neural network that is first the eyes of the eye and then the fully connected

67
00:04:23.370 --> 00:04:25.770
layers to lead to the predictions.

68
00:04:26.220 --> 00:04:30.340
So speaking of the eyes of the eyes that's exactly what we're going to do now.

69
00:04:30.480 --> 00:04:37.280
We're going to propagate these allowed images now into the eyes of the eyes that is through the three

70
00:04:37.290 --> 00:04:38.720
convolutional layers.

71
00:04:38.850 --> 00:04:41.620
And to do this you're going to see now how it's so simple.

72
00:04:41.640 --> 00:04:46.290
That's because we already have our brain in our body from the init function.

73
00:04:46.320 --> 00:04:56.190
We simply need to take our brain self that brain and apply this brain to the input images and that will

74
00:04:56.190 --> 00:04:59.830
propagate things to the food function here from the brain.

75
00:05:00.430 --> 00:05:06.190
That will propagate the signals inside the brain and since the forward function of the brain returns

76
00:05:06.520 --> 00:05:13.600
the output signals that the neurons of the output layer containing Q values Well this self the brain

77
00:05:13.610 --> 00:05:19.030
input here will return this output signal and therefore we're going to put here whether it be turned

78
00:05:19.090 --> 00:05:26.120
into a variable and we're going to call it very simply outwits this output is the output signal of the

79
00:05:26.120 --> 00:05:26.690
brain.

80
00:05:26.930 --> 00:05:31.970
And now now that we have the output signal of the brain Well we have to propagate this output signal

81
00:05:31.970 --> 00:05:37.990
to the body and to do this we're going to use the second forward function from the body and to do this.

82
00:05:38.030 --> 00:05:46.370
We simply need to take our body and apply it to of course the output because the Ford function of the

83
00:05:46.370 --> 00:05:50.600
body takes as input the output signals of the brain.

84
00:05:50.660 --> 00:05:55.880
So that's exactly what output is right now and returns the actions.

85
00:05:56.000 --> 00:05:58.080
And therefore since it returns the actions.

86
00:05:58.380 --> 00:06:03.530
Well here we are going to add actions to cause self that very output.

87
00:06:03.920 --> 00:06:09.380
All right so now you can see that very simply we propagated the signals inside the brain and then from

88
00:06:09.380 --> 00:06:15.410
the brain to the very first by using the form function from the brain which takes us and put the input

89
00:06:15.410 --> 00:06:19.830
images and then propagate them into the brain to retain the key values.

90
00:06:20.240 --> 00:06:25.400
And then we propagate this output signal into the body where the forward function of our body to get

91
00:06:25.520 --> 00:06:26.900
the action to play.

92
00:06:26.900 --> 00:06:32.300
And so now the only remaining thing that we have to do and that's the very last line of code of this

93
00:06:32.300 --> 00:06:34.510
part one building the.

94
00:06:34.760 --> 00:06:39.370
We have to return the action to play and that is actions.

95
00:06:39.530 --> 00:06:45.020
However right now the actions have to torch format and we need to convert them back into them by right

96
00:06:45.260 --> 00:06:51.660
and to do this we're going to take the data structure of these actions and then add here the non-pilot

97
00:06:51.890 --> 00:06:53.840
function and then we go.

98
00:06:53.840 --> 00:06:56.780
Now we have the actions we turned in the right format.

99
00:06:56.780 --> 00:06:58.040
So congratulations.

100
00:06:58.040 --> 00:07:00.660
We are now done with this first part 1.

101
00:07:00.770 --> 00:07:03.410
We build the AI in three steps.

102
00:07:03.410 --> 00:07:06.860
First we made the brain second we made the body.

103
00:07:06.860 --> 00:07:13.430
And third we assembles the brain in the body and we propagated the whole signal from the eyes to the

104
00:07:13.430 --> 00:07:15.130
moment we play the action.

105
00:07:15.560 --> 00:07:17.100
So that's a first step done.

106
00:07:17.120 --> 00:07:22.200
That was a huge step but now as you understood we built an AI AI but it is still stupid.

107
00:07:22.220 --> 00:07:24.110
We need to train it to be intelligent.

108
00:07:24.170 --> 00:07:29.030
So we need to train it to do what we wanted to do and to do this we're going to use the word have to

109
00:07:29.030 --> 00:07:34.100
do environments you know because it's learning from the world by being reinforced when it gets a good

110
00:07:34.100 --> 00:07:34.690
reward.

111
00:07:34.760 --> 00:07:40.610
And by being punished or weakened when it's getting a bad word that's where the cue learning will come

112
00:07:40.610 --> 00:07:41.670
into play.

113
00:07:41.690 --> 00:07:47.510
And so that's exactly what we'll do in this part to train in the eye with deep convolutional Q learning.

114
00:07:47.510 --> 00:07:50.270
I can't wait to start and until then I.
