WEBVTT
1
00:00:00.270 --> 00:00:02.250
Hello and welcome to the store.

2
00:00:02.430 --> 00:00:05.810
I'm super excited because we're about to make the A-3 see brain.

3
00:00:05.810 --> 00:00:07.430
That is the brain of our AI.

4
00:00:07.590 --> 00:00:10.800
And speaking about brains I would like to highlight something.

5
00:00:10.870 --> 00:00:15.750
Remember in the first module we made a simple brain with only fully connected layers.

6
00:00:15.840 --> 00:00:22.260
Then in the second module for Dhoom we made a brain that not only had fully connected layers but also

7
00:00:22.350 --> 00:00:29.070
eyes because we added the convolutional layers which gave eyes to the eye because it could observe the

8
00:00:29.070 --> 00:00:31.550
images and understand what's going on inside.

9
00:00:31.830 --> 00:00:37.590
And now we're going to say that even at a high level because we're going to make a brain that not only

10
00:00:37.590 --> 00:00:41.310
will have eyes and fully connect layers but also memory.

11
00:00:41.430 --> 00:00:46.710
Because as I said in the previous tutorial we're going to add a record on that work inside this big

12
00:00:46.710 --> 00:00:53.490
brain and that will give a long memory to our brain so that it can understand the temporal relationships

13
00:00:53.580 --> 00:00:57.010
the temporal properties of the input images.

14
00:00:57.120 --> 00:01:02.400
So there we go and even more powerful brain I can tell you that the Dymo we're about Intiman right now

15
00:01:02.640 --> 00:01:09.930
is really really powerful and we can see how building AI's and doing deeper and deeper and Forsman learning

16
00:01:10.260 --> 00:01:14.820
is all about getting closer and closer to how human brain works.

17
00:01:14.820 --> 00:01:19.560
You know we started with the basic relationships of the brain with the linear connections.

18
00:01:19.560 --> 00:01:22.230
Then we added eyes and we added the memory.

19
00:01:22.230 --> 00:01:24.900
Who knows what we're going to add in the future models.

20
00:01:24.990 --> 00:01:30.780
You know in 2018 maybe they will add something that will make the brain look like even more like a human

21
00:01:30.780 --> 00:01:31.330
brain.

22
00:01:31.680 --> 00:01:37.590
But already with fully connected lasers eyes and memory we have already a really good and functional

23
00:01:37.590 --> 00:01:38.280
brain.

24
00:01:38.790 --> 00:01:39.690
So let's do it.

25
00:01:39.750 --> 00:01:41.140
Let's make this brain.

26
00:01:41.310 --> 00:01:46.470
So as usual we're going to make a class for that because it's going to have a lot of properties with

27
00:01:46.470 --> 00:01:48.780
the convolutions and science.

28
00:01:48.870 --> 00:01:53.770
So we're going to make it function to initialize all this create all these connections.

29
00:01:54.090 --> 00:01:59.220
And then of course we'll have the Ford function that will of course propagate the signal inside the

30
00:01:59.220 --> 00:02:02.580
brain so that we can get eventually the output.

31
00:02:02.580 --> 00:02:03.200
All right.

32
00:02:03.240 --> 00:02:04.020
Are you ready.

33
00:02:04.140 --> 00:02:05.400
Let's do this.

34
00:02:05.400 --> 00:02:13.470
So class we introduce in class which we call actor credit because of course I'm talking about brains

35
00:02:13.470 --> 00:02:13.700
here.

36
00:02:13.710 --> 00:02:19.440
But let's not forget that we're making with the model which is based on the active critic principle

37
00:02:19.650 --> 00:02:24.810
with separately the actor and the critic so will make actually one of the near-full connections for

38
00:02:24.810 --> 00:02:27.770
the actor and one meaningful connection for the critic.

39
00:02:27.810 --> 00:02:30.880
You'll see how well we'll do that will be actually quite simple.

40
00:02:30.900 --> 00:02:39.060
So active critic and this actor class is going to inherit from the end and that Maggio so that we can

41
00:02:39.060 --> 00:02:40.780
use all the Pitre which tools.

42
00:02:40.860 --> 00:02:44.130
So let's do this to inherit from the end in that module.

43
00:02:44.190 --> 00:02:53.000
Well we need to take first the torch library then that then and then and that and Mudgal.

44
00:02:53.090 --> 00:02:54.100
All right.

45
00:02:54.110 --> 00:02:55.600
That way we inherit from it.

46
00:02:56.990 --> 00:02:57.240
All right.

47
00:02:57.260 --> 00:03:01.630
So there we go with our first function which will be of course in its function.

48
00:03:01.640 --> 00:03:10.400
So we start with in its in its double underscore then this function is going to take as argument self

49
00:03:10.850 --> 00:03:17.970
with the object then the input shape that is the dominations of our input images and we call it non

50
00:03:18.050 --> 00:03:25.820
inputs and the actions phase which is basically the space that contains all the actions.

51
00:03:26.000 --> 00:03:31.340
We also know from this action space we can get a number of actions that is a number of possible actions

52
00:03:31.700 --> 00:03:33.870
which will actually get very soon.

53
00:03:33.870 --> 00:03:38.290
So that's why we also needed that for the arguments.

54
00:03:38.290 --> 00:03:39.390
That's all we need.

55
00:03:39.650 --> 00:03:45.450
And then let's go inside the function and let's create all the variables proper to our brain.

56
00:03:45.830 --> 00:03:51.740
But before we do that remember what we have to do to activate in some way the inheritance that we can

57
00:03:52.040 --> 00:03:59.450
use all the tools from the end of Maggio we have to use the superfunction this way inside of which we

58
00:03:59.450 --> 00:04:00.180
input.

59
00:04:00.440 --> 00:04:10.740
Actor critic that is our class and then come up self with the object All right then and there we go

60
00:04:10.740 --> 00:04:14.840
again with the function.

61
00:04:14.940 --> 00:04:15.560
There we go.

62
00:04:15.600 --> 00:04:20.100
That gives us all the tools that we all need from torch to build our brain.

63
00:04:20.400 --> 00:04:21.940
All right then.

64
00:04:22.170 --> 00:04:24.690
Well it's time to make the eyes of the eye.

65
00:04:24.780 --> 00:04:26.210
That is the convolutions.

66
00:04:26.460 --> 00:04:31.770
So we're going to do it very quickly because we already explained this in details for doom.

67
00:04:31.800 --> 00:04:34.210
Because I remember the day I had ice.

68
00:04:34.260 --> 00:04:39.240
So it's exactly the same we're going to make some conclusions and we will use a very simple architecture

69
00:04:39.510 --> 00:04:45.240
with 32 feature detectors of size three by three stride of two and a padding of one.

70
00:04:45.450 --> 00:04:50.460
So that's a pretty classic architecture but that will actually be enough to you know make sure that

71
00:04:50.690 --> 00:04:53.010
I understand what's going on in the break.

72
00:04:53.010 --> 00:04:54.090
OK.

73
00:04:54.480 --> 00:04:56.750
All right so let's make those convolutions.

74
00:04:56.790 --> 00:05:03.900
So we start with self because the convolutions will be variables of the objects so self that can we

75
00:05:03.900 --> 00:05:09.210
can call it come and there's going to be four convolution so and can this one can one.

76
00:05:09.540 --> 00:05:11.040
And there we go.

77
00:05:11.040 --> 00:05:18.900
We take the N and Maggio dot and then we take the cone to the class because actually convenant will

78
00:05:18.930 --> 00:05:20.670
be an object of disgust.

79
00:05:21.540 --> 00:05:25.870
And then inside first we put the input shape of the images.

80
00:05:25.920 --> 00:05:32.780
So that exactly what we have here so we can copy this and enter it as the first input.

81
00:05:33.090 --> 00:05:38.600
Then the second argument is the number of feature detectors are also the number of kernels.

82
00:05:38.640 --> 00:05:45.060
So we're going to take 32 as we just said classic choice then we need to choose the size of the kernel

83
00:05:45.060 --> 00:05:50.130
that is the number of cells that will slide over the input image.

84
00:05:50.190 --> 00:05:55.170
And so remember we can either take three four or five that's come in choices and we're going to choose

85
00:05:55.290 --> 00:05:58.460
three and then we're going to choose.

86
00:05:58.550 --> 00:06:01.100
Tried to.

87
00:06:01.340 --> 00:06:11.350
And a padding of one that we go that's for the first convolution that goes from the input image to the

88
00:06:11.350 --> 00:06:16.210
first convolutional layer is composed of 32 convoluted images.

89
00:06:16.360 --> 00:06:18.850
So now we are ready to make the second convolution.

90
00:06:18.850 --> 00:06:27.290
So it's actually going to be almost the same so I'm copying this line and basing that below pasted below

91
00:06:27.310 --> 00:06:33.490
again and pasting it one last time because we're going to have four convolutions with almost nothing

92
00:06:33.490 --> 00:06:42.640
to change so we can already replace Here comes one by comes to one by three and comes one by come four.

93
00:06:42.670 --> 00:06:45.160
That will be our four convolutions.

94
00:06:45.160 --> 00:06:49.330
And now of course we need to change some things here but not much because we're going to keep track

95
00:06:49.370 --> 00:06:52.280
of two for each and a pattern of one.

96
00:06:52.420 --> 00:06:58.620
They will all have 32 feature detectors that has 32 outputs convoluted images.

97
00:06:58.780 --> 00:07:04.040
But then here remember this corresponds to the left part of the convolution.

98
00:07:04.180 --> 00:07:09.610
So actually that corresponds to what was at the right part of the previous conclusion you know it's

99
00:07:09.610 --> 00:07:10.370
like a dominoes.

100
00:07:10.390 --> 00:07:11.440
It's really easy.

101
00:07:11.560 --> 00:07:22.390
And therefore here we have to put 32 and here's where we're going to see very easily 32 and 32.

102
00:07:22.390 --> 00:07:27.790
All right so to sum up we start with our input images that has none.

103
00:07:27.810 --> 00:07:35.350
Simon Jones was the first convolution we get 32 convoluted images each one detecting a specific feature

104
00:07:35.800 --> 00:07:43.120
then from these 32 convoluted images we apply the second convolution to get 32 new convoluted images

105
00:07:43.420 --> 00:07:46.510
then same from these 32 new convoluted images.

106
00:07:46.510 --> 00:07:52.430
We apply the third convolution to get 32 new convoluted images again and then eventually from the three

107
00:07:52.450 --> 00:07:57.470
to convoluted images we apply the fourth convolution to get features.

108
00:07:57.490 --> 00:07:57.910
All right.

109
00:07:57.910 --> 00:08:03.700
And this will be enough with this or I will have a supervision it will take the ball very well.

110
00:08:03.700 --> 00:08:07.250
All right so that's it for the convolution So that's it for the eyes.

111
00:08:07.420 --> 00:08:09.490
And now let's take care of the memory.

112
00:08:09.640 --> 00:08:15.520
This new feature of this brain we're implementing as opposed before with to not only it will have a

113
00:08:15.680 --> 00:08:23.140
supervision but also it will have a super memory long memory because we going to see Long short term

114
00:08:23.170 --> 00:08:29.230
memory which is this kind of record or a neural network that gives to your model some kind of a long

115
00:08:29.230 --> 00:08:36.580
memory so that it can learn some long temporal relationships from the past so saying we're going to

116
00:08:36.580 --> 00:08:43.180
create new variables from time with self and this new variable we're going to call it simply because

117
00:08:43.180 --> 00:08:47.260
this will correspond to the LACMA network inside the brain.

118
00:08:47.290 --> 00:08:55.240
So SVM and out before we write the code for the LCN let's make sure we understand what this LACMA part

119
00:08:55.240 --> 00:08:56.270
of the brain will do.

120
00:08:56.530 --> 00:09:03.980
So as we understood this LCN is used to learn the temporal properties of the input input images.

121
00:09:04.090 --> 00:09:09.730
So for example if the ball hits a the LACMA will encode the balance.

122
00:09:09.730 --> 00:09:11.410
So that's the first thing to understand.

123
00:09:11.410 --> 00:09:15.070
It will kind of encode what's happening in the game.

124
00:09:15.070 --> 00:09:20.080
Then the next important thing to understand when we implemented that ISTM is that we need to choose

125
00:09:20.170 --> 00:09:26.680
in-order of the temporal dependencies and here since we're going to feed our neural network with a sequence

126
00:09:26.680 --> 00:09:33.740
of four images then that means that we can already learn some temporal dependencies of order for that

127
00:09:33.740 --> 00:09:40.310
is some temporal dependencies where what happens at 1:20 depends on what happens at time T.

128
00:09:40.360 --> 00:09:45.500
T minus 1 T minus 2 and T minus 3 so that we can definitely do that.

129
00:09:45.730 --> 00:09:51.040
But the good news is that we're going to use analysis YEM and therefore we will be able to learn some

130
00:09:51.160 --> 00:09:54.560
even more complex temporal relationships.

131
00:09:54.650 --> 00:10:00.430
For example we can learn some simple properties where what happens at 1:20 will depend on what happens

132
00:10:00.430 --> 00:10:01.370
at time T.

133
00:10:01.370 --> 00:10:05.510
T minus 20 minutes to do minus three down to T minus.

134
00:10:05.940 --> 00:10:13.360
And that's the long part in the long short term memory with this assay and we can learn some very complex

135
00:10:13.360 --> 00:10:15.490
temporal relationships.

136
00:10:15.490 --> 00:10:18.080
All right so let's add our LCN.

137
00:10:18.160 --> 00:10:25.030
So to do this we're going to use the N in module and then we're going to add the class as T.N. cell

138
00:10:25.600 --> 00:10:31.960
which will create this as an object which will represent DST and part of the new network because right

139
00:10:31.960 --> 00:10:38.570
now what's also important to understand is that we're making a C R and then you know convolutional record

140
00:10:38.590 --> 00:10:45.520
a new network and the arland part comes after the CNN part and therefore right now what we need to input

141
00:10:45.610 --> 00:10:51.350
in this LACMA cell is first the size of the output after the convolution.

142
00:10:51.400 --> 00:10:56.060
So that is 32 times three times three.

143
00:10:56.230 --> 00:11:02.670
So this 32 times three times three is actually the output after the four convolutions here.

144
00:11:02.830 --> 00:11:07.600
But that becomes the input of the RNA the LSD and that work.

145
00:11:07.870 --> 00:11:13.710
And now why is the output of the four convolutions half the size three two times three times three.

146
00:11:13.870 --> 00:11:16.030
Well don't worry it's not that direct.

147
00:11:16.060 --> 00:11:22.140
It's actually not a simple formula but there is a formula to compute this number of output neurons.

148
00:11:22.210 --> 00:11:26.490
After flattening the pooled and convoluted images of deconvolution.

149
00:11:26.710 --> 00:11:32.050
But if we gathered the terms of this big formula Well we get 32 times three times three.

150
00:11:32.200 --> 00:11:36.060
I didn't want to spend too much time on this because we have a lot to do more.

151
00:11:36.190 --> 00:11:39.470
And besides we already made a function to compute this number.

152
00:11:39.520 --> 00:11:43.710
Remember it was for doom when we made this count neurons function.

153
00:11:43.870 --> 00:11:45.750
So you can reuse it if you want.

154
00:11:45.760 --> 00:11:51.610
You're not convinced but that is just what we get after gathering the terms of this big formula like

155
00:11:51.610 --> 00:11:53.490
computing the number of outputs.

156
00:11:53.530 --> 00:11:59.380
So that's for the first argument and then the second argument is going to be the number of output neurons

157
00:11:59.380 --> 00:12:00.370
of the.

158
00:12:00.610 --> 00:12:05.220
And we're going to go for 256 OK.

159
00:12:05.220 --> 00:12:12.180
And so what does that mean now that means that now we have a vector that encodes each event of the game

160
00:12:12.540 --> 00:12:19.260
or in other words we have an encoded state and so that is now that we can make the separation between

161
00:12:19.620 --> 00:12:25.470
the actor and the critic because you know we're going to make actually two separate new networks one

162
00:12:25.470 --> 00:12:31.410
for the actor and one for the critic but they will be the same encoding of the images and the temporal

163
00:12:31.410 --> 00:12:33.990
relationships for these two neural networks.

164
00:12:33.990 --> 00:12:37.740
So this is the common part that we do for these two new networks.

165
00:12:37.740 --> 00:12:43.650
This will be the same beginning for the two new networks but now things are going to change for the

166
00:12:43.650 --> 00:12:49.710
actor and the creek because we're going to make one in the full connection for the actor and one different

167
00:12:49.710 --> 00:12:52.200
than near-full connection for the craic.

168
00:12:52.230 --> 00:12:56.320
So let's take a quick break and let's do that in the next little.

169
00:12:56.400 --> 00:12:57.860
Until then enjoy AI.
