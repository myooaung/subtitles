WEBVTT
1
00:00:00.000 --> 00:00:02.131
Hello, I'm Michael Hoffman.

2
00:00:02.131 --> 00:00:06.920
Welcome to this course on Getting Started with Spring Batch.

3
00:00:06.920 --> 00:00:07.981
To begin with,

4
00:00:07.981 --> 00:00:11.185
I'll explain why you might need batch processing and

5
00:00:11.185 --> 00:00:13.709
how Spring Batch can meet your needs.

6
00:00:13.709 --> 00:00:17.324
I'll also cover what you'll learn from watching the course.

7
00:00:17.324 --> 00:00:19.885
Let's get started with some background.

8
00:00:19.885 --> 00:00:23.457
The concept of processing data in batch goes back to

9
00:00:23.457 --> 00:00:25.243
the earliest days of computing.

10
00:00:25.243 --> 00:00:29.837
It evokes images of men and women sitting in very uncomfortable chairs

11
00:00:29.837 --> 00:00:34.103
entering batches of punch cards into tabulation machines.

12
00:00:34.103 --> 00:00:37.991
Over time, large mainframe computers dominated the landscape.

13
00:00:37.991 --> 00:00:41.357
This greatly increased the demand for batch processing.

14
00:00:41.357 --> 00:00:46.051
Today, enterprises have evolved into a mixture of servers in the cloud.

15
00:00:46.051 --> 00:00:49.044
Enterprises have a variety of web applications and back-end

16
00:00:49.044 --> 00:00:51.570
systems that support their supply chain.

17
00:00:51.570 --> 00:00:55.527
Enterprises execute business on these systems at a global scale,

18
00:00:55.527 --> 00:01:00.071
requiring 24 x 7 uptime and minimal system impact from internal processes.

19
00:01:00.071 --> 00:01:01.255
As a result,

20
00:01:01.255 --> 00:01:05.038
there's been a shift from batch processing to stream processing

21
00:01:05.038 --> 00:01:07.712
for real-time updates of these systems; however,

22
00:01:07.712 --> 00:01:12.181
batch is certainly still a relevant tool for the enterprise.

23
00:01:12.181 --> 00:01:14.019
With that history as context,

24
00:01:14.019 --> 00:01:16.960
let's formulate a simple definition of batch processing.

25
00:01:16.960 --> 00:01:20.041
Batch processing takes data as an input.

26
00:01:20.041 --> 00:01:22.904
In general, input datasets are large in value,

27
00:01:22.904 --> 00:01:26.704
which drives the need for the various batching features that are available.

28
00:01:26.704 --> 00:01:28.300
The dataset is structured,

29
00:01:28.300 --> 00:01:32.784
oftentimes in a file with a delimiter such as a comma or tab.

30
00:01:32.784 --> 00:01:37.903
The dataset is also finite, such as having a set number of rows in the file.

31
00:01:37.903 --> 00:01:41.615
This input data is then processed by one or more jobs.

32
00:01:41.615 --> 00:01:46.085
These jobs run periodically, often overnight, to process data.

33
00:01:46.085 --> 00:01:47.419
As part of processing,

34
00:01:47.419 --> 00:01:51.419
jobs will apply one or more rules to each input data record.

35
00:01:51.419 --> 00:01:54.841
Rarely does the process update the source input directly.

36
00:01:54.841 --> 00:01:58.404
Jobs gain efficiency by taking advantage of features such as

37
00:01:58.404 --> 00:02:00.749
chunking of data and parallel processing.

38
00:02:00.749 --> 00:02:05.499
Once the job is finished processing a data record, it gets output.

39
00:02:05.499 --> 00:02:09.044
Jobs will often write process data to a database.

40
00:02:09.044 --> 00:02:13.635
Jobs can also write out data to be used for input to the next job in a chain.

41
00:02:13.635 --> 00:02:16.797
Again, jobs will take advantage of batching features for output,

42
00:02:16.797 --> 00:02:19.949
such as batching commits to the destination endpoint.

43
00:02:19.949 --> 00:02:20.000
Next, let's look at how you would use batch processing.

44
00:02:20.000 --> 00:02:23.550
While there are certainly many usage scenarios,

45
00:02:23.550 --> 00:02:28.763
let's look at the two most common ones for batch processing.

46
00:02:28.763 --> 00:02:31.440
The first scenario is data transformation.

47
00:02:31.440 --> 00:02:33.745
Oftentimes this is at a large scale.

48
00:02:33.745 --> 00:02:34.404
For example,

49
00:02:34.404 --> 00:02:38.022
I may have an end of month accounting process where I

50
00:02:38.022 --> 00:02:40.729
retrieve all of the transactions for the month,

51
00:02:40.729 --> 00:02:42.147
process each one individually,

52
00:02:42.147 --> 00:02:45.077
and produce other structures of data for reporting.

53
00:02:45.077 --> 00:02:47.380
Returning to our definition of batch,

54
00:02:47.380 --> 00:02:51.309
this type of processing likely happens on a scheduled

55
00:02:51.309 --> 00:02:54.195
basis when some business need arises.

56
00:02:54.195 --> 00:02:58.230
As this processing usually requires completion within a window of time,

57
00:02:58.230 --> 00:03:00.195
such as before month's end for accounting,

58
00:03:00.195 --> 00:03:03.629
we need to take advantage of features like parallel

59
00:03:03.629 --> 00:03:06.661
processing and chunking of input data.

60
00:03:06.661 --> 00:03:09.694
The second scenario is system integration.

61
00:03:09.694 --> 00:03:15.314
Commonly, this is used to ingest or export large amounts of data between systems.

62
00:03:15.314 --> 00:03:15.940
For example,

63
00:03:15.940 --> 00:03:19.382
a retail system may bulk load all of the new merchandise

64
00:03:19.382 --> 00:03:23.067
available from external vendors on a nightly basis so that it's

65
00:03:23.067 --> 00:03:26.090
available the next day on the website.

66
00:03:26.090 --> 00:03:30.893
Oftentimes this scenario requires batch processing to happen more frequently.

67
00:03:30.893 --> 00:03:33.921
The batch system will pull more frequently for inputs to

68
00:03:33.921 --> 00:03:36.450
keep data fresh in a near real-time manner.

69
00:03:36.450 --> 00:03:37.091
Given this,

70
00:03:37.091 --> 00:03:40.465
it's often a shorter window for processing time and may

71
00:03:40.465 --> 00:03:43.391
require different features of batch processing over

72
00:03:43.391 --> 00:03:45.758
larger scale data transformation.

73
00:03:45.758 --> 00:03:51.033
Now let's briefly look at another approach for data processing.

74
00:03:51.033 --> 00:03:53.454
Stream processing is an approach that actually builds

75
00:03:53.454 --> 00:03:55.538
on the concept of batch processing.

76
00:03:55.538 --> 00:04:00.341
Instead of a fixed input from a file or other data source,

77
00:04:00.341 --> 00:04:05.200
stream processing takes a stream of data change events as input.

78
00:04:05.200 --> 00:04:10.117
Oftentimes these change events are sourced from a message queue.

79
00:04:10.117 --> 00:04:15.216
The input data is often formatted in a structure such as JSON or XML.

80
00:04:15.216 --> 00:04:18.274
Each input event contains either a document with a full

81
00:04:18.274 --> 00:04:22.001
dataset that's changed or the bare minimum of details to allow

82
00:04:22.001 --> 00:04:26.595
the processor to retrieve the data, such as a unique identifier.

83
00:04:26.595 --> 00:04:29.953
Instead of running on a periodic or scheduled basis,

84
00:04:29.953 --> 00:04:33.765
the stream processing job is always running in a near real-time pace,

85
00:04:33.765 --> 00:04:36.512
processing events as they come in.

86
00:04:36.512 --> 00:04:38.344
Similar to batch processing,

87
00:04:38.344 --> 00:04:42.089
there's also the application of business rules to the input event data,

88
00:04:42.089 --> 00:04:44.076
such as domain transformation.

89
00:04:44.076 --> 00:04:47.824
There are challenges that emerge for stream processing,

90
00:04:47.824 --> 00:04:49.931
which are different than batch.

91
00:04:49.931 --> 00:04:50.511
For example,

92
00:04:50.511 --> 00:04:53.693
stream processors need to be concerned with the availability of components,

93
00:04:53.693 --> 00:04:56.776
such as the message queue and the destination in order

94
00:04:56.776 --> 00:04:59.273
to assure that data is not lost,

95
00:04:59.273 --> 00:05:03.548
where batch processing can always rely on the original input.

96
00:05:03.548 --> 00:05:06.200
Challenges with stream processing means different types

97
00:05:06.200 --> 00:05:08.963
of features are needed for support.

98
00:05:08.963 --> 00:05:14.119
This includes redundancy of processors, message replay, and message routing.

99
00:05:14.119 --> 00:05:19.209
Stream processing often results in written outputs similar to batch processing.

100
00:05:19.209 --> 00:05:22.818
Oftentimes this data is written to a database in a similar fashion to

101
00:05:22.818 --> 00:05:26.507
the system integration scenario mentioned for batch.

102
00:05:26.507 --> 00:05:29.727
Data could also be written to another queue for a variety of

103
00:05:29.727 --> 00:05:33.558
reasons such as grouping similar messages or fanning out to

104
00:05:33.558 --> 00:05:35.538
other jobs for parallel processing.

105
00:05:35.538 --> 00:05:38.886
As a final step to understanding the background of batch processing,

106
00:05:38.886 --> 00:05:42.581
let's look at some of its benefits and challenges.

107
00:05:42.581 --> 00:05:45.936
I'm going to focus on three key benefits and three

108
00:05:45.936 --> 00:05:47.614
key challenges of batch processing.

109
00:05:47.614 --> 00:05:52.636
First, batch processing is best for processing high volumes of data at a time.

110
00:05:52.636 --> 00:05:55.403
As you know the dataset from the start of processing,

111
00:05:55.403 --> 00:05:59.687
it's possible to read an entire input set and optimize the

112
00:05:59.687 --> 00:06:02.277
processing of data prior to execution.

113
00:06:02.277 --> 00:06:05.911
Stream processing can be slower for large volumes as events will need

114
00:06:05.911 --> 00:06:09.350
to be queued and require additional processing to determine the best

115
00:06:09.350 --> 00:06:11.332
approach for grouping data processing.

116
00:06:11.332 --> 00:06:16.525
Another key benefit is the ability to stop and restart a job at any time.

117
00:06:16.525 --> 00:06:18.248
As the input data is finite,

118
00:06:18.248 --> 00:06:22.070
we can count the number of records processed prior to a failure,

119
00:06:22.070 --> 00:06:25.920
then we can fix an offending record and restart the

120
00:06:25.920 --> 00:06:29.255
processing at or after the failing record.

121
00:06:29.255 --> 00:06:32.893
As stream processing is a continual ingestion of events,

122
00:06:32.893 --> 00:06:36.841
we could cause significant upstream issues by stopping processing,

123
00:06:36.841 --> 00:06:39.972
such as backing up the input queue to the point of

124
00:06:39.972 --> 00:06:41.395
overloading it or crashing it.

125
00:06:41.395 --> 00:06:45.974
Finally, batch processing has matured over a large span of time.

126
00:06:45.974 --> 00:06:47.230
There are many tools available,

127
00:06:47.230 --> 00:06:50.288
including the framework we will focus on in this course.

128
00:06:50.288 --> 00:06:53.461
There are also many examples available describing the

129
00:06:53.461 --> 00:06:56.675
right and wrong ways to implement batch.

130
00:06:56.675 --> 00:07:01.518
Along with these benefits, batch processing also faces several challenges.

131
00:07:01.518 --> 00:07:04.146
Fist, because batch works with a finite dataset,

132
00:07:04.146 --> 00:07:09.272
it often means that it can't meet the business need for data availability.

133
00:07:09.272 --> 00:07:13.725
Today, many systems need data to be as fresh as possible.

134
00:07:13.725 --> 00:07:14.378
For example,

135
00:07:14.378 --> 00:07:17.850
a retail company may want to maximize availability of their product

136
00:07:17.850 --> 00:07:22.052
and want to assure that as soon as inventory is available the product

137
00:07:22.052 --> 00:07:25.091
is also available for customer purchase.

138
00:07:25.091 --> 00:07:28.660
It would not make sense to run a batch job every 5

139
00:07:28.660 --> 00:07:30.147
minutes to handle this scenario.

140
00:07:30.147 --> 00:07:32.429
If you need real-time availability,

141
00:07:32.429 --> 00:07:36.079
you may want to consider stream processing instead.

142
00:07:36.079 --> 00:07:40.446
Next, batch processing tends to be a resource intensive process.

143
00:07:40.446 --> 00:07:44.011
Given the 24 x 7 requirements for many of today's systems,

144
00:07:44.011 --> 00:07:46.686
running a long batch process can have significant impact

145
00:07:46.686 --> 00:07:48.687
on the real-time usage of systems.

146
00:07:48.687 --> 00:07:52.001
If you have these types of uptime processing requirements,

147
00:07:52.001 --> 00:07:56.675
you may want to look at an alternative approach including stream processing.

148
00:07:56.675 --> 00:07:57.160
Finally,

149
00:07:57.160 --> 00:08:01.314
many times the integration and transformation requirements for data

150
00:08:01.314 --> 00:08:04.698
require simple computations or a business rule application.

151
00:08:04.698 --> 00:08:05.514
For example,

152
00:08:05.514 --> 00:08:10.164
you may just need to convert a few attributes of the input data

153
00:08:10.164 --> 00:08:12.679
to massage it into the required output format.

154
00:08:12.679 --> 00:08:17.868
Leveraging a batch system in these cases can be overkill.

155
00:08:17.868 --> 00:08:19.382
As this is a Getting Started course,

156
00:08:19.382 --> 00:08:22.269
I'm not going to dive much deeper into batch processing concepts.

157
00:08:22.269 --> 00:08:25.335
If you would like more information on the approaches

158
00:08:25.335 --> 00:08:26.992
for batch and stream processing,

159
00:08:26.992 --> 00:08:31.359
I would recommend checking out Martin Kleppmann's book,

160
00:08:31.359 --> 00:08:33.383
Designing Data-Intensive Applications.

161
00:08:33.383 --> 00:08:35.436
With our high-level understanding of batch processing,

162
00:08:35.436 --> 00:08:43.000
let's look at one of the most popular frameworks for supporting batch process implementation.

