WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:02.460
Next we'll take the pickled files to

00:00:02.460 --> 00:00:05.640
the Google collab environment and try to predict their.

00:00:05.640 --> 00:00:10.170
Google collab is like a Jupiter environment with some visual customization.

00:00:10.170 --> 00:00:14.625
And it has lot of pre-built libraries for machine learning and deep learning.

00:00:14.625 --> 00:00:18.780
You can just login using your jimmy lady or

00:00:18.780 --> 00:00:23.385
Google lady and then create a new notebook and start coding.

00:00:23.385 --> 00:00:26.310
Let's create a new notebook I've already logged in.

00:00:26.310 --> 00:00:29.260
Will give this file a name.

00:00:33.110 --> 00:00:40.245
We can go to tool setting and change the theme to dark or adaptive.

00:00:40.245 --> 00:00:43.090
Let's send it to dark.

00:00:43.380 --> 00:00:46.750
Colombia is like a Jupiter notebook environment.

00:00:46.750 --> 00:00:50.455
You can simply type code NDA, hit Shift Enter.

00:00:50.455 --> 00:00:57.310
You'll see the output. Or you can click on the Run icon here and run the program.

00:00:57.310 --> 00:01:03.470
And you can right-click Delete sin or you can simply click here and delete sale.

00:01:03.600 --> 00:01:06.700
In Kuulab will find most of the machine learning

00:01:06.700 --> 00:01:09.980
and deep learning libraries pre-installed.

00:01:10.320 --> 00:01:13.090
If something is not installed,

00:01:13.090 --> 00:01:17.830
you can do pip install here and install it.

00:01:17.830 --> 00:01:20.605
Wallabies like Linux environment.

00:01:20.605 --> 00:01:26.980
You can do exclamation mark Ellis and see all the files that are present here.

00:01:26.980 --> 00:01:31.855
Currently, there is nothing that is a sample data folder within your Columbian moment.

00:01:31.855 --> 00:01:35.830
And all the files get saved to the Google Drive.

00:01:35.830 --> 00:01:40.400
Will transfer this to pick your files to the Colombian moment.

00:01:40.950 --> 00:01:44.840
We'll go to our GitHub repository.

00:01:45.750 --> 00:01:51.835
And we've already uploaded the pickle files to this repository on GitHub,

00:01:51.835 --> 00:01:54.670
futurist skilled ML model deployment.

00:01:54.670 --> 00:01:57.950
Select the classified or typical.

00:01:59.880 --> 00:02:05.995
Greatly can download and copy the link address,

00:02:05.995 --> 00:02:10.600
go to the Colombian Robert and do a Linux W get.

00:02:10.600 --> 00:02:16.480
And the path makes sure the file path is row.

00:02:16.480 --> 00:02:21.580
Get the file, do ls to see if the file has been copied or not.

00:02:21.580 --> 00:02:24.925
Next, let's get the standard scaler.

00:02:24.925 --> 00:02:27.580
Click on a CDO pickle, right?

00:02:27.580 --> 00:02:30.265
T can download, copy link address,

00:02:30.265 --> 00:02:34.720
not do a W GET and get the standard scaler pickle file.

00:02:34.720 --> 00:02:38.665
Now we can see both the pickled files are available in the Colombian moment.

00:02:38.665 --> 00:02:41.545
We've uploaded the morals to the Colombian moment.

00:02:41.545 --> 00:02:42.940
Here in this notebook.

00:02:42.940 --> 00:02:45.805
We don't know how the models were built are trained,

00:02:45.805 --> 00:02:51.220
but we can use these models to do similar prediction as you have done earlier.

00:02:51.220 --> 00:02:53.590
Create a classifier object.

00:02:53.590 --> 00:02:56.600
We'll call it classifier collapse.

00:03:00.270 --> 00:03:03.740
Create a scalar object.

00:03:05.910 --> 00:03:10.195
And we'll use that classifier and scholar to predict.

00:03:10.195 --> 00:03:14.095
Simply type the variable name and hit Enter.

00:03:14.095 --> 00:03:17.530
We'll see the output. So the prediction is 0.

00:03:17.530 --> 00:03:22.540
It is same as what we got earlier

00:03:22.540 --> 00:03:28.820
for a customer with age 40 and suddenly 20 thousand will get go probability also.

00:03:30.570 --> 00:03:33.925
You can print it the same cell also.

00:03:33.925 --> 00:03:36.565
The last land gets printed.

00:03:36.565 --> 00:03:42.280
So we're seeing 20% probability of somebody with age 40 and solid 20 thousand buying

00:03:42.280 --> 00:03:49.390
the product will do the same for age 42 and san-serif 50 thousand.

00:03:49.390 --> 00:03:57.505
Prediction is one. Probability is 0.6 because we did not put the right edge.

00:03:57.505 --> 00:04:00.580
Let's run it again. This time we're getting 80.

00:04:00.580 --> 00:04:03.910
This is how we can train models in one environment and

00:04:03.910 --> 00:04:07.450
take them to a completely new environment and run them dead.

00:04:07.450 --> 00:04:10.120
You are giving the model to another team or third-party.

00:04:10.120 --> 00:04:14.230
They did not know how you built enter into your model all the noise.

00:04:14.230 --> 00:04:17.410
It's a classifier, it takes value in certain format.

00:04:17.410 --> 00:04:19.790
And Gibbs doubt.
