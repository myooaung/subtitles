1
00:00:00,180 --> 00:00:00,720
Hi guys.

2
00:00:00,720 --> 00:00:07,290
And welcome back to this email because we are finally at the last parts of the CNN implementation which

3
00:00:07,290 --> 00:00:08,520
is the evaluation parts.

4
00:00:08,790 --> 00:00:13,050
So let's just see you right now how our model performs on new data.

5
00:00:13,080 --> 00:00:23,330
So we will get results as being the outputs of D.C. and then that's evaluates.

6
00:00:23,400 --> 00:00:28,040
And we will give these methods the test inputs this time.

7
00:00:28,270 --> 00:00:36,960
So this inputs tests labels and we would give him the budget size the same we used for the training

8
00:00:36,960 --> 00:00:50,780
so much batch size and we will simply print results to see the accuracy that we can get with new data

9
00:00:50,810 --> 00:00:53,580
that haven't been seen before.

10
00:00:54,050 --> 00:00:54,470
OK.

11
00:00:54,530 --> 00:00:55,310
Perfect.

12
00:00:55,310 --> 00:01:00,500
It's it's data that has not been used for the training but we still have the same kind of accuracy which

13
00:01:00,500 --> 00:01:07,460
is 0 point 8 which is pretty good knowing that we can still improve the model by making an optimization

14
00:01:07,610 --> 00:01:09,300
of the hyper parameters.

15
00:01:09,300 --> 00:01:15,920
So that's pretty good but let's let's have a little bit more fun and try to well together sentimental

16
00:01:15,920 --> 00:01:20,440
analysis on homemade sentences on own sentences.

17
00:01:20,450 --> 00:01:28,860
So let's do that by calling our model on an A and B.

18
00:01:29,150 --> 00:01:38,640
That's a great we will talk a nice sentence and input sentence and let's start with the really simple

19
00:01:38,640 --> 00:01:49,080
one just to to try it like I love you for instance which of course for most of us should convey a positive

20
00:01:49,940 --> 00:01:51,360
or positive sentiments.

21
00:01:52,050 --> 00:01:54,320
So training equals false.

22
00:01:54,330 --> 00:02:01,320
So we don't apply the drop outs and let's make it an end by so we don't get to tensor that is hard to

23
00:02:01,320 --> 00:02:02,420
read.

24
00:02:02,520 --> 00:02:03,370
Yeah.

25
00:02:03,510 --> 00:02:13,340
All right of course let's run it again and we get s yet O point seventy three so that's of course positive.

26
00:02:13,340 --> 00:02:17,540
So that's normal.

27
00:02:17,580 --> 00:02:19,480
Let's try the the opposite.

28
00:02:19,500 --> 00:02:19,870
Okay.

29
00:02:19,910 --> 00:02:21,000
Very negative sentiment.

30
00:02:21,000 --> 00:02:24,010
So that's that's also a good point.

31
00:02:24,420 --> 00:02:34,170
Let's try with something a little bit more maybe complicated like I wish we'll never have to do that

32
00:02:34,230 --> 00:02:41,580
again so we don't have of use words like like or love or hate in this one so let's see if you'd understand

33
00:02:41,580 --> 00:02:43,130
that it's OK.

34
00:02:43,260 --> 00:02:49,940
He definitely understand that it's a really bad thing that we don't want to to do something again in

35
00:02:49,930 --> 00:02:50,710
the in the future.

36
00:02:50,720 --> 00:02:53,340
So that's pretty good.

37
00:02:54,810 --> 00:02:57,360
Let's try it last one.

38
00:02:57,540 --> 00:03:00,610
You also funny OK.

39
00:03:00,630 --> 00:03:01,950
That's actually really positive.

40
00:03:01,950 --> 00:03:08,610
So I guess if if someone tells you that you are self funny it would mean that they are more into you

41
00:03:08,620 --> 00:03:10,510
than say I love you.

42
00:03:10,530 --> 00:03:11,610
That's interesting.

43
00:03:11,610 --> 00:03:19,610
But anyway we had good results on the on the test data and it seems to work pretty pretty well on our

44
00:03:19,650 --> 00:03:24,630
own sentences of course the data that we used is far from perfect.

45
00:03:24,630 --> 00:03:27,800
It's just some tweets we don't have a lot of them.

46
00:03:27,840 --> 00:03:31,550
It's a certain kind of language in a certain way.

47
00:03:31,740 --> 00:03:37,440
As always for data sets and depends on what you want to apply your model to you have to get data that

48
00:03:37,680 --> 00:03:39,630
fits your task or your purpose.

49
00:03:39,670 --> 00:03:41,590
So be careful that that's.

50
00:03:41,610 --> 00:03:45,810
But for just this example and just to show that our model works perfectly well.

51
00:03:45,930 --> 00:03:47,830
This was a good data sets.

52
00:03:47,910 --> 00:03:53,760
So anyway I hope you liked it and hope that you will have some fun with the model train with the data

53
00:03:53,770 --> 00:03:59,420
all even the classification task that was it for CNN applies to MLP.

54
00:03:59,430 --> 00:03:59,910
See you soon.
