WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:05.870
everybody and welcome this lesson are looking at how we can create a lambda function and

00:00:05.870 --> 00:00:07.760
the psychic learn reference.

00:00:07.760 --> 00:00:12.140
So for those who that don't know what is serverless so serverless computing basically

00:00:12.140 --> 00:00:15.900
enables you to build and run applications without thinking about the servers and other

00:00:15.900 --> 00:00:17.050
network infrastructure.

00:00:17.050 --> 00:00:20.880
So it's relieving a developer from the burden off bootstrapping,

00:00:20.880 --> 00:00:21.590
configuring,

00:00:21.590 --> 00:00:22.170
networking,

00:00:22.170 --> 00:00:22.920
clustering,

00:00:22.920 --> 00:00:27.840
updating and all the other aspects off a physical server management and the enormous

00:00:27.840 --> 00:00:28.430
benefits.

00:00:28.430 --> 00:00:29.920
If not being able to do that.

00:00:29.920 --> 00:00:35.060
Not having to do that so enables you to focus on tasks at hand without sacrificing the

00:00:35.060 --> 00:00:36.790
access or scalability.

00:00:36.790 --> 00:00:39.660
So a few things that need to keep in mind.

00:00:39.660 --> 00:00:39.990
Obviously,

00:00:39.990 --> 00:00:43.540
we need to make sure that we have our AWS account on.

00:00:43.540 --> 00:00:45.870
You can also use the free tier for this.

00:00:45.870 --> 00:00:47.310
It's not going to make a difference.

00:00:47.310 --> 00:00:49.990
As most as none of the things here are chargeable,

00:00:49.990 --> 00:00:54.840
So first thing I'm going to do is we need to create a sage maker lifecycle configuration.

00:00:54.840 --> 00:00:57.180
We're gonna go ahead and log and tour console.

00:00:57.180 --> 00:00:59.500
We're gonna go to navigate to our sage maker,

00:00:59.500 --> 00:01:04.570
and you can find that out of the machine learning or you can use the search box and the

00:01:04.570 --> 00:01:09.510
dashboard contains links to all of the major components notebook training in front and so

00:01:09.510 --> 00:01:09.790
on.

00:01:09.790 --> 00:01:12.110
So the notebook,

00:01:12.110 --> 00:01:14.580
we have the option off lifecycle configurations.

00:01:14.580 --> 00:01:16.150
We're gonna go and click on that.

00:01:16.150 --> 00:01:22.020
The life cycle configurations are startup scripts that initialized the Jupiter nor book

00:01:22.020 --> 00:01:22.700
environments.

00:01:22.700 --> 00:01:28.150
And they can be run once on creation or or one every notebook startup.

00:01:28.150 --> 00:01:30.450
I want you to click on that.

00:01:30.450 --> 00:01:32.190
We're gonna under scripts,

00:01:32.190 --> 00:01:34.150
going to click on create Notebook,

00:01:34.150 --> 00:01:38.890
and we're gonna go ahead and paste in this code.

00:01:38.890 --> 00:01:41.520
So this above code,

00:01:41.520 --> 00:01:46.450
it does the following when instances created is going to download the code and necessary

00:01:46.450 --> 00:01:49.500
files from the get hub repository.

00:01:49.500 --> 00:01:54.450
It's going to organize the folder structure in place files in session folders is going to

00:01:54.450 --> 00:01:58.430
set right permission to the folder and is going to install seven zip,

00:01:58.430 --> 00:02:02.680
which is required to compress Lambda packages to their smallest size.

00:02:02.680 --> 00:02:04.360
So after we do that,

00:02:04.360 --> 00:02:06.750
we're gonna go ahead and create our notebook.

00:02:06.750 --> 00:02:07.270
Instance,

00:02:07.270 --> 00:02:11.960
we're gonna click on notebook instances and created instance that's gonna creator Jupiter

00:02:11.960 --> 00:02:17.960
notebook using the lifecycle configuration we just created in the last step we're gonna go

00:02:17.960 --> 00:02:22.000
ahead and pride the deep regular information in terms of the notebook name,

00:02:22.000 --> 00:02:24.950
we're going to keep the instance the smallest one that's available,

00:02:24.950 --> 00:02:30.820
we're gonna use the S three bucket and I am role to make sure that has access to all of the

00:02:30.820 --> 00:02:31.880
S three buckets.

00:02:31.880 --> 00:02:33.540
And more importantly,

00:02:33.540 --> 00:02:37.550
we're going to choose the life cycle configuration that we just specified.

00:02:37.550 --> 00:02:41.490
And we're gonna go ahead and create our notebook.

00:02:41.490 --> 00:02:42.080
Instance,

00:02:42.080 --> 00:02:46.160
I was gonna take several minutes to go ahead and get that up and running.

00:02:46.160 --> 00:02:47.710
And in the meantime,

00:02:47.710 --> 00:02:52.720
we're gonna go and navigate to our S three console and create our bucket while waiting for

00:02:52.720 --> 00:02:53.270
the notebook.

00:02:53.270 --> 00:02:53.730
Instance.

00:02:53.730 --> 00:02:54.500
Tow launch.

00:02:54.500 --> 00:02:59.550
So we're gonna go ahead and create a bucket that's going to be that's going to host all of

00:02:59.550 --> 00:03:00.580
our data for us,

00:03:00.580 --> 00:03:04.830
and the bucket is necessary to store the training data and models that were going to be

00:03:04.830 --> 00:03:06.450
creating in this workshop.

00:03:06.450 --> 00:03:09.780
After we create the bucket we need to set up,

00:03:09.780 --> 00:03:13.790
I am rolls and attached the necessary Polly's policies to it.

00:03:13.790 --> 00:03:18.890
So we need to add rights to our newly created sagemaker role and create a new role for the

00:03:18.890 --> 00:03:20.350
serverless inference.

00:03:20.350 --> 00:03:25.500
So we're gonna be using to policies were going to use the Lambda full access and the S

00:03:25.500 --> 00:03:27.050
three full access policies.

00:03:27.050 --> 00:03:29.470
And these permissions are required in the notebook.

00:03:29.470 --> 00:03:35.330
As as since we're gonna be uploading objects to the S three and creating Lambda Functions,

00:03:35.330 --> 00:03:39.040
we're gonna go ahead and go into our I am dashboard.

00:03:39.040 --> 00:03:40.850
You're gonna go and click on roles.

00:03:40.850 --> 00:03:41.900
We're gonna go ahead,

00:03:41.900 --> 00:03:46.930
type out sage maker as one of the role that we want to search for and the summers page.

00:03:46.930 --> 00:03:49.250
We're going to click on attach policies.

00:03:49.250 --> 00:03:50.780
And then again,

00:03:50.780 --> 00:03:55.540
we're going to use the search box to add to policies the Lambda full access and the S three

00:03:55.540 --> 00:04:01.940
full access and the next we're going to create a serverless inference execution role for

00:04:01.940 --> 00:04:02.620
the Lambda.

00:04:02.620 --> 00:04:04.540
So this senses for the Lambda.

00:04:04.540 --> 00:04:11.340
We're gonna go ahead and click on the Lambda to create a new role ever gonna sign this one

00:04:11.340 --> 00:04:16.160
full access to the S three bucket and the sagemaker also.

00:04:16.160 --> 00:04:21.730
So now we have both those roles created and done to make sure that we have access for the

00:04:21.730 --> 00:04:26.560
Lambda functions and for the stage maker to the s three buckets and vice versa.

00:04:26.560 --> 00:04:27.870
So if that's done,

00:04:27.870 --> 00:04:32.450
we're gonna go ahead and go back into our sage maker dashboard and has received the

00:04:32.450 --> 00:04:33.900
notebook instances up and ready.

00:04:33.900 --> 00:04:36.350
We're gonna go ahead and open up Jupiter tow.

00:04:36.350 --> 00:04:37.630
Launch our duper of notebook.

00:04:37.630 --> 00:04:38.350
Instance.

00:04:38.350 --> 00:04:42.000
Once we're in there,

00:04:42.000 --> 00:04:45.600
let's go ahead and navigate to the serverless.

00:04:45.600 --> 00:04:46.750
A workshop,

00:04:46.750 --> 00:04:49.580
the Lambda Psych it learn in France.

00:04:49.580 --> 00:04:52.290
And you wanna open up that psychics?

00:04:52.290 --> 00:04:52.980
Sentiment,

00:04:52.980 --> 00:04:53.670
analysis,

00:04:53.670 --> 00:04:56.670
tweet a couple of things that you guys want to do.

00:04:56.670 --> 00:05:00.970
Make sure you replace where it says your bucket name with the bucket name that you created

00:05:00.970 --> 00:05:03.270
in the S three when we created the buckets.

00:05:03.270 --> 00:05:05.050
Enough of that work.

00:05:05.050 --> 00:05:12.250
We're going to go ahead and run all of those steps and will train the psych it learns built

00:05:12.250 --> 00:05:12.850
in a logger.

00:05:12.850 --> 00:05:19.190
Them logistic regression using the tweets data set and in the last lines off the cord.

00:05:19.190 --> 00:05:24.640
There is basically uploading the train model and the validation and test data said back

00:05:24.640 --> 00:05:28.550
into our three buckets that we previously created.

00:05:28.550 --> 00:05:31.250
So after we do that,

00:05:31.250 --> 00:05:36.680
we're gonna go and go back into our Jupiter notebook file browser and launch a terminal

00:05:36.680 --> 00:05:42.820
into our instance from the Jupiter notebook How to set up the Lambda and enable inference

00:05:42.820 --> 00:05:44.180
on our newly created model.

00:05:44.180 --> 00:05:48.330
We're gonna use the AWS command line interface and again we're able to do that right from

00:05:48.330 --> 00:05:53.850
the Jupiter notebook instance on the sea Ally is basically preinstalled in the bash cell

00:05:53.850 --> 00:05:56.060
provided in every sagemaker.

00:05:56.060 --> 00:05:56.510
Instance.

00:05:56.510 --> 00:05:58.710
So on the right hand side of Jupiter notebook,

00:05:58.710 --> 00:05:59.160
we're gonna click.

00:05:59.160 --> 00:06:03.770
I knew I And at the bottom we're gonna click on Terminal and it's gonna go ahead and launch

00:06:03.770 --> 00:06:05.950
our new terminal instance in a new tab.

00:06:05.950 --> 00:06:14.060
So next we're going to create a Lambda Leer on the notebook instance through issuing a few

00:06:14.060 --> 00:06:14.790
commands.

00:06:14.790 --> 00:06:15.940
And then,

00:06:15.940 --> 00:06:16.900
after doing that,

00:06:16.900 --> 00:06:19.350
we're going to publish the Lambda Lear.

00:06:19.350 --> 00:06:22.150
So after that's done,

00:06:22.150 --> 00:06:27.050
we're going to create a lambda function using just our lambda function.

00:06:27.050 --> 00:06:32.400
That pie file and all the dependencies have been bundled in the layer that we previously

00:06:32.400 --> 00:06:34.000
published in the last step.

00:06:34.000 --> 00:06:40.470
So we need to do is we need the full Aaron or Amazon resource name to run this command,

00:06:40.470 --> 00:06:41.730
and we can get that air.

00:06:41.730 --> 00:06:47.680
And by going back into our I am console going into the role and just copying it from there

00:06:47.680 --> 00:06:47.680
.

00:06:47.680 --> 00:06:51.500
So after that,

00:06:51.500 --> 00:06:56.360
now let's go ahead and update the lander to use the layer we just published.

00:06:56.360 --> 00:06:57.840
So after you do that,

00:06:57.840 --> 00:07:03.250
I'm gonna go ahead and ever get back into our console and navigate to the Lambda dashboard

00:07:03.250 --> 00:07:03.250
.

00:07:03.250 --> 00:07:06.130
And the package has been uploaded,

00:07:06.130 --> 00:07:07.440
and in this instance,

00:07:07.440 --> 00:07:07.830
she ate it.

00:07:07.830 --> 00:07:13.090
So now we can call it on demand and will use the Lambda as testing feature to call the

00:07:13.090 --> 00:07:16.790
model Lambda is in the compute section of the console.

00:07:16.790 --> 00:07:18.970
If you're not familiar with where it is,

00:07:18.970 --> 00:07:23.510
we're gonna go ahead and click on functions and select sentiment analysis.

00:07:23.510 --> 00:07:25.830
And in the upper right hand corner,

00:07:25.830 --> 00:07:27.340
you guys see the test option,

00:07:27.340 --> 00:07:28.750
We're gonna go and click on that.

00:07:28.750 --> 00:07:35.650
It's going to pop up a new window and we're gonna just call it a test event.

00:07:35.650 --> 00:07:41.250
We're going to give it again the bucket we're gonna put in our bucket name.

00:07:41.250 --> 00:07:43.080
As soon as they're done,

00:07:43.080 --> 00:07:48.660
we're going to click on the test button and after a couple of seconds,

00:07:48.660 --> 00:07:54.780
we're going to see the following result in terms of the execution result as being succeeded

00:07:54.780 --> 00:07:54.780
.

00:07:54.780 --> 00:07:58.580
So there you have it fairly simple is that I should say,

00:07:58.580 --> 00:08:01.970
are creating a model using the psych it learn,

00:08:01.970 --> 00:08:03.120
built a lambda lair,

00:08:03.120 --> 00:08:08.730
published it and used the Lambda function to use that layer and got a successful test from

00:08:08.730 --> 00:08:14.840
the console so now essentially can use this same model and scale it out.

00:08:14.840 --> 00:08:19.260
You can choose to call the function from a P a gateway and put it into production.

00:08:19.260 --> 00:08:23.530
So essentially it's this model can be put into production production,

00:08:23.530 --> 00:08:25.760
as is the few minor tweaks here and there.

00:08:25.760 --> 00:08:26.490
But essentially,

00:08:26.490 --> 00:08:31.590
it is as simple as that in terms of building a server less ai environment.

