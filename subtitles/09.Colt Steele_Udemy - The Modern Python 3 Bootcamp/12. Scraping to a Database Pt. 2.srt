1
00:00:00,180 --> 00:00:01,220
All right welcome back.

2
00:00:01,220 --> 00:00:05,070
So now that we've scraped all of our data we get it in a list at the very end.

3
00:00:05,370 --> 00:00:09,070
All we have to do is inserted and we have a couple of options.

4
00:00:09,090 --> 00:00:13,350
I mean we have to connect to the database do all that stuff create that table but then we can either

5
00:00:13,350 --> 00:00:20,280
do a bulk insert and conveniently we have it as tuples which is what we want inside of a list.

6
00:00:20,310 --> 00:00:21,580
So that's nice and easy.

7
00:00:21,630 --> 00:00:24,560
Or we can iterate over the list and insert one at a time.

8
00:00:24,720 --> 00:00:32,310
But I think it's better and it's actually faster and sequel prefers it if you feel let me say that if

9
00:00:32,310 --> 00:00:37,110
you do some research it's generally faster to do an insert with 10 items instead of 10 in search of

10
00:00:37,110 --> 00:00:37,920
one item.

11
00:00:37,920 --> 00:00:46,710
So I head over here and we already have our import for Sequel 3 so I'm going to make a new method called

12
00:00:47,040 --> 00:00:56,190
I don't know save data or save books and it's going to take a list of all of our books as an argument

13
00:00:57,360 --> 00:01:02,100
and the first thing that will do is just initialize the sequel side of things.

14
00:01:02,160 --> 00:01:08,260
So we need to make our connection equals sequel light three connect.

15
00:01:08,370 --> 00:01:14,670
We don't have a database I've created yet so I'm going just make a database called bookstand DB and

16
00:01:14,670 --> 00:01:23,100
then I need to do our cursor connection cursor and then from there we have a couple of queries.

17
00:01:23,100 --> 00:01:33,930
First we want to create our table so seacock execute and the query is create table books and then we

18
00:01:33,930 --> 00:01:35,660
have a couple of pieces.

19
00:01:36,180 --> 00:01:41,090
And this is going to be a long one so I'm going to do it on three lines on three lines.

20
00:01:41,190 --> 00:01:44,000
I mean on multiple lines using three quotes.

21
00:01:44,240 --> 00:01:50,490
So create table books and then I think from there I'm just going to spot this up so this will go on

22
00:01:50,490 --> 00:01:52,330
the next line indented.

23
00:01:52,650 --> 00:01:56,760
And the things that we want are a title which is text.

24
00:01:56,910 --> 00:02:01,890
We want a rating which is an integer and then we want a price.

25
00:02:01,890 --> 00:02:06,840
And actually if we look at the order and building the tuple and right now it's title price rating which

26
00:02:06,840 --> 00:02:07,520
is totally fine.

27
00:02:07,530 --> 00:02:12,080
We just it's best it will make our lives easier if we put them in the same order.

28
00:02:12,330 --> 00:02:13,660
But it really doesn't matter.

29
00:02:13,710 --> 00:02:16,160
So we'll do.

30
00:02:16,200 --> 00:02:16,680
Sure.

31
00:02:16,710 --> 00:02:17,240
Rating.

32
00:02:17,250 --> 00:02:17,790
And then.

33
00:02:17,820 --> 00:02:21,190
Well I think price is slightly more important than rating maybe.

34
00:02:21,420 --> 00:02:23,460
So let's just go this way.

35
00:02:23,520 --> 00:02:34,120
So we have title then price and then rating so price is going to be real which is basically a float

36
00:02:34,680 --> 00:02:36,210
and rating is an integer.

37
00:02:36,240 --> 00:02:40,730
So we have title text price real rating integer and that should create the table for us.

38
00:02:40,730 --> 00:02:41,600
That's all we need.

39
00:02:41,690 --> 00:02:43,260
See that execute that.

40
00:02:43,260 --> 00:02:50,690
Then afterwards we want to go and insert all of our books which we'll assume are in this all books list.

41
00:02:50,760 --> 00:02:57,300
So if we have all of this data like this we have access to it all that we need to do is do a bulk insert

42
00:02:57,900 --> 00:03:01,640
multiple insert of this data and it would look something like this.

43
00:03:01,710 --> 00:03:08,590
The actual query is just insert into books and then values.

44
00:03:08,820 --> 00:03:14,310
We're going to have those three placeholder question marks and then we just would pass in after that

45
00:03:15,240 --> 00:03:23,040
our list of tuples of books which are coming from here again would be called all books.

46
00:03:23,040 --> 00:03:29,370
So then the method that we need is not up execute It's actually secret executes many.

47
00:03:29,610 --> 00:03:31,670
And that will allow us to insert them all at once.

48
00:03:31,680 --> 00:03:34,430
We don't have to write the loop ourself.

49
00:03:34,500 --> 00:03:37,350
So this is a big test.

50
00:03:37,350 --> 00:03:41,100
We're going to create that table and insert all those books in.

51
00:03:41,100 --> 00:03:44,590
Now we're not calling Save books yet so we would need to call that here.

52
00:03:44,640 --> 00:03:45,830
So let's do that now.

53
00:03:45,930 --> 00:03:51,480
At the end so after our loop we have this or this list of all books that contains all of our data we're

54
00:03:51,480 --> 00:03:57,340
just going to call save books with all books like that.

55
00:03:57,350 --> 00:03:58,160
All right.

56
00:03:58,160 --> 00:04:00,760
So start scraping books from that euro.

57
00:04:00,960 --> 00:04:06,970
Re-initialize everything and then we go and find all articles that would create this list.

58
00:04:07,190 --> 00:04:12,530
And for each article that came back recalling a book we're compiling three pieces of data as a pull

59
00:04:12,860 --> 00:04:18,410
we're spending that into our list all books passing that list into saved books which should then go

60
00:04:18,410 --> 00:04:19,270
insert at all.

61
00:04:19,280 --> 00:04:22,530
So it connects the database creates a new cursor.

62
00:04:22,670 --> 00:04:26,290
It creates a table so we'll comment this line out after the first time.

63
00:04:26,360 --> 00:04:31,370
If you're running this over and over you probably would want a separate method or Honestly you only

64
00:04:31,370 --> 00:04:32,180
create a table once.

65
00:04:32,180 --> 00:04:34,420
So I would just do that without Python.

66
00:04:34,550 --> 00:04:38,490
Just go into the sequel and do that and then insert it into books.

67
00:04:38,510 --> 00:04:40,450
We'll see if this is correct.

68
00:04:41,000 --> 00:04:46,140
Always room for error when you're dealing with sequel and python.

69
00:04:46,280 --> 00:04:55,520
Oh and we need to make sure we do our connection commit and then connection close and now oh fingers

70
00:04:55,520 --> 00:05:00,990
crossed let's see if it works on three books scraper.

71
00:05:01,830 --> 00:05:04,300
OK that's a good sign that we don't see anything.

72
00:05:04,490 --> 00:05:07,620
So we should now have a file books D-B sequel.

73
00:05:07,670 --> 00:05:13,180
Three books D.B and first we have a Books table.

74
00:05:13,480 --> 00:05:17,040
Now is there anything in it.

75
00:05:17,530 --> 00:05:18,630
Yes there is.

76
00:05:18,820 --> 00:05:20,250
All of our data is in there.

77
00:05:20,470 --> 00:05:21,730
So now I have access.

78
00:05:21,740 --> 00:05:28,690
Imagine that you're scraping this like let's say we were scraping a famous bookseller that starts with

79
00:05:28,690 --> 00:05:36,520
an A and you were running this like all the time and getting all new books has her added or I don't

80
00:05:36,520 --> 00:05:39,490
know daily you are scraping all fantasy books or whatever genre.

81
00:05:39,490 --> 00:05:42,210
And we had like hundreds of thousands or maybe more.

82
00:05:42,340 --> 00:05:47,230
And you want to then be able to figure out what are the actual highest rated books or what.

83
00:05:47,230 --> 00:05:51,790
I mean we could scrape a lot more information reviews if we could take those reviews and run them through

84
00:05:52,420 --> 00:05:56,770
certain API so it would tell us how positive or negative the language actually was or which ones are

85
00:05:56,770 --> 00:05:58,090
fake versus real.

86
00:05:58,150 --> 00:06:02,490
And then we could store that in our database and then we could go through and do all sorts of queries.

87
00:06:02,500 --> 00:06:10,060
So like this is this is silly but let's just select all books let's say like book titles from books

88
00:06:10,870 --> 00:06:19,350
where rating is greater than 4 or greater than equal to four.

89
00:06:19,390 --> 00:06:24,910
And this gives us the highest rated books Sapiens A short history of nearly everything that went pretty

90
00:06:24,910 --> 00:06:26,030
good for that.

91
00:06:26,200 --> 00:06:27,710
And then I haven't read the others.

92
00:06:28,060 --> 00:06:31,660
And also they're all just randomly generated ratings on that Web site.

93
00:06:31,690 --> 00:06:37,190
They have a disclaimer that says they're not real they don't reflect the quality of the books anyway.

94
00:06:37,210 --> 00:06:38,830
So now we have data here.

95
00:06:38,880 --> 00:06:43,710
It's sort of a trivial example but we went through the steps of scraping and then saving it to a database.

96
00:06:43,750 --> 00:06:49,480
And you could apply that to scraping any other web site and then saving into your database usually with

97
00:06:49,480 --> 00:06:52,380
some reason in mind you're not just going to save it for no reason.

98
00:06:52,600 --> 00:06:56,540
But if you're trying to figure something out with sequel and you totally could do that.

99
00:06:56,620 --> 00:06:57,310
All right.

100
00:06:57,310 --> 00:06:58,510
So that wraps up sequel.
