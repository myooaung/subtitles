WEBVTT
1
00:00:00.210 --> 00:00:00.910
Welcome back.

2
00:00:01.080 --> 00:00:06.090
So in this video I'm going to begin the solution to the quotes game and what we're going to focus on

3
00:00:06.090 --> 00:00:09.340
is the scraping portion the game logical comes second.

4
00:00:09.510 --> 00:00:15.510
So by the end of the video we want to have a list containing data from all the quotes on this Web site

5
00:00:15.930 --> 00:00:20.970
and we just want the text of the quote the name of the author of the quote and then the link.

6
00:00:20.970 --> 00:00:23.590
The ATF the link to the author's bio.

7
00:00:23.810 --> 00:00:28.680
So we should have a big list by the end and we're going to run it on every page of the Web site.

8
00:00:28.710 --> 00:00:32.400
So here's a site and we already kind of took a look.

9
00:00:32.420 --> 00:00:37.410
I will come back to this but it's always a good idea to start by identifying the information we want

10
00:00:37.410 --> 00:00:38.880
and where it is.

11
00:00:38.880 --> 00:00:43.770
So what we want is just all of these quotes on any given page where class is quote.

12
00:00:43.860 --> 00:00:46.650
And fortunately we know how to do that using beautiful soup.

13
00:00:46.890 --> 00:00:53.130
But before we even do that we have to make our request so let's go to our terminal and I'll make a new

14
00:00:53.130 --> 00:00:59.680
file here and I'll call this one scraper dot P Y and I'll add that you are all we need up there just

15
00:00:59.760 --> 00:01:02.940
so I have it and we need to import a couple of things.

16
00:01:02.940 --> 00:01:12.370
The first is going to be requests and we'll also import from B-S for let's do it that way.

17
00:01:12.620 --> 00:01:16.240
Import beautiful soup.

18
00:01:16.350 --> 00:01:22.410
There we go and we'll just start simply by making our first request to this Web site and we can just

19
00:01:22.410 --> 00:01:23.800
do it one time.

20
00:01:23.820 --> 00:01:24.860
It started easy.

21
00:01:24.870 --> 00:01:27.700
So that's going to be requests to get.

22
00:01:27.840 --> 00:01:35.920
And then you also get rid of that in quotes and then we want to just pass the response text.

23
00:01:36.140 --> 00:01:41.400
So when you just save this to a variable just call it raise it calls requests get and then we'll do

24
00:01:41.400 --> 00:01:49.380
a red dot text for beautiful soup and save that and just call it soup and let's just make sure we're

25
00:01:49.380 --> 00:01:50.130
getting anything.

26
00:01:50.130 --> 00:01:56.100
So we'll do print soup dot body and let's see if it works.

27
00:01:56.100 --> 00:01:57.820
Do we have any problems.

28
00:02:00.250 --> 00:02:00.620
All right.

29
00:02:00.640 --> 00:02:02.510
So we are getting the body next.

30
00:02:02.530 --> 00:02:05.440
Let's focus on actually getting a list of quotes.

31
00:02:05.600 --> 00:02:08.820
So we want to get all of the items that have a nice quote.

32
00:02:08.830 --> 00:02:12.530
All elements were classes quote and there's a couple of ways we can do that.

33
00:02:12.580 --> 00:02:17.260
You could use select and then use the CSSA style selector.

34
00:02:17.260 --> 00:02:19.270
Or we can do find all.

35
00:02:19.780 --> 00:02:24.560
And let me do this in a separate variable or actually so souped up find all.

36
00:02:24.940 --> 00:02:30.200
And we want to find where class and we have to use that underscore.

37
00:02:30.850 --> 00:02:33.190
So we don't avoid using a keyword class.

38
00:02:33.190 --> 00:02:34.290
Class equals.

39
00:02:34.450 --> 00:02:38.380
And it was called quote and save that to a variable.

40
00:02:38.380 --> 00:02:43.570
So call it quotes and let's just print that variable now.

41
00:02:43.600 --> 00:02:44.700
All right.

42
00:02:44.940 --> 00:02:47.100
Clear some space here.

43
00:02:48.700 --> 00:02:54.100
And looks like it's hard to tell because there's all this metal stuff in here as well but you can see

44
00:02:54.310 --> 00:02:55.300
here's a quote.

45
00:02:55.390 --> 00:02:57.010
Imperfection is beauty.

46
00:02:57.010 --> 00:02:57.980
Blah blah blah blah blah.

47
00:02:57.970 --> 00:02:59.530
Then we can see the author.

48
00:02:59.590 --> 00:03:04.480
There's a class author Marilyn Monroe and then the draft to her bio.

49
00:03:04.820 --> 00:03:05.810
Ok cool.

50
00:03:06.040 --> 00:03:09.440
So next we're going to loop through all of the quotes.

51
00:03:09.820 --> 00:03:13.330
So just a for quote in quotes.

52
00:03:13.330 --> 00:03:19.030
We're going to want to let's just focus on the quote text first and if we look at an individual quote

53
00:03:19.450 --> 00:03:26.410
the text is actually located instead of a span with the class text so we can just use on each quote

54
00:03:26.770 --> 00:03:28.700
which is here we have a list of these.

55
00:03:28.930 --> 00:03:35.560
We'll just call DOT find the class of text and then that should give us the text of the quote and if

56
00:03:35.560 --> 00:03:36.720
we try that now.

57
00:03:36.890 --> 00:03:44.190
So we do find and then we want class underscore equals and then text.

58
00:03:44.230 --> 00:03:47.150
Well let's let's start by just printing that.

59
00:03:47.830 --> 00:03:53.590
And if all goes well we should get a whole bunch of quotes and it looks good we're getting all of these

60
00:03:53.590 --> 00:03:54.650
bands.

61
00:03:54.760 --> 00:03:57.270
Now we just want to grab the text out of them.

62
00:03:57.580 --> 00:04:00.610
So that's just another thing we don't get text.

63
00:04:00.610 --> 00:04:03.580
We only want the inner texts we don't actually want the span's.

64
00:04:04.090 --> 00:04:05.350
And there we go.

65
00:04:05.350 --> 00:04:10.040
We get all of these quotes here a day without sunshine is like you know night.

66
00:04:10.060 --> 00:04:10.610
Great quote.

67
00:04:10.630 --> 00:04:11.650
Whoever said that.

68
00:04:11.650 --> 00:04:14.500
So at this point we could now make a list just called.

69
00:04:14.680 --> 00:04:17.320
I don't know all quotes and have it be empty.

70
00:04:17.710 --> 00:04:28.030
And then we'll append to all quotes a dictionary and in that dictionary We'll start by what we call

71
00:04:28.030 --> 00:04:29.010
this text.

72
00:04:29.290 --> 00:04:34.660
That's a sign text to be this right here.

73
00:04:36.040 --> 00:04:45.190
And then next let's assign the author name and to get that data inside the quote.

74
00:04:45.590 --> 00:04:49.580
Let's see there's this span here with by perfect.

75
00:04:49.590 --> 00:04:55.680
There's this small element with class author and the inner text that is the author's name.

76
00:04:55.720 --> 00:05:03.190
We can just do another find to quote of find class underscore equals instead of text its author and

77
00:05:03.190 --> 00:05:04.920
then don't get text.

78
00:05:05.500 --> 00:05:12.040
And at the end this time must just print all quotes and see if we now have text and author in there

79
00:05:12.040 --> 00:05:14.810
together and we don't get any syntax errors.

80
00:05:16.160 --> 00:05:17.100
It looks good.

81
00:05:17.150 --> 00:05:23.130
If things like text a day without sunshine is like you know night and then author Steve Martin.

82
00:05:23.580 --> 00:05:25.850
OK finally we need to grab this.

83
00:05:25.850 --> 00:05:31.930
You are el So what you can do is just in the developer tools on Chrome which if you don't remember how

84
00:05:31.930 --> 00:05:38.870
to open them on a Mac it's command option J or you can right click and then go to inspect.

85
00:05:39.400 --> 00:05:39.800
OK.

86
00:05:39.880 --> 00:05:46.690
So you click on an element after selecting this and it's highlighted here and you see that there isn't

87
00:05:46.690 --> 00:05:53.290
a class that we can select automatically just to give us what we want but inside the div is the only

88
00:05:53.290 --> 00:05:54.670
anchor tag in here.

89
00:05:54.760 --> 00:05:57.470
No there are other Angerer tags here.

90
00:05:58.030 --> 00:06:03.130
So what we can do is just find the first anchor tag because there aren't any.

91
00:06:03.130 --> 00:06:07.530
So if we go through one quote first element Are there any anchor text in here.

92
00:06:07.570 --> 00:06:08.230
Nope.

93
00:06:08.800 --> 00:06:11.950
OK so then next element down.

94
00:06:11.950 --> 00:06:13.940
This is indeed the first anchor tag.

95
00:06:14.080 --> 00:06:19.660
So we can take advantage of that what we want is we don't want the inner text that says about we actually

96
00:06:19.660 --> 00:06:21.260
want that Tref here.

97
00:06:21.340 --> 00:06:24.510
Slash author slash Albert Einstein.

98
00:06:24.550 --> 00:06:28.990
So to get the attribute we can use the square brackets syntax.

99
00:06:29.110 --> 00:06:30.180
So we begin.

100
00:06:30.340 --> 00:06:31.250
Let's make.

101
00:06:31.420 --> 00:06:34.670
I don't know what we call this bio link or something like that.

102
00:06:34.830 --> 00:06:37.750
And that should be quote find.

103
00:06:38.050 --> 00:06:40.730
And then we're just going to find the first anchor tag.

104
00:06:41.410 --> 00:06:47.810
So not find all but find otherwise find out gives us a list and then we just want to f on that.

105
00:06:47.920 --> 00:06:50.790
And this is the syntax we use to get a single attribute.

106
00:06:51.350 --> 00:06:51.840
OK.

107
00:06:52.670 --> 00:06:58.000
And make sure know that's intended properly if you print it all now.

108
00:06:58.270 --> 00:06:59.500
I think I'm missing a comma.

109
00:06:59.690 --> 00:07:00.540
Yes I am.

110
00:07:00.770 --> 00:07:01.010
OK.

111
00:07:01.010 --> 00:07:01.950
Try again.

112
00:07:02.030 --> 00:07:05.330
Now we get all this data in a list text.

113
00:07:05.450 --> 00:07:08.020
The world as we have created bubble up of law.

114
00:07:08.180 --> 00:07:10.880
Author Albert Einstein bio link.

115
00:07:10.910 --> 00:07:11.810
There we go.

116
00:07:12.230 --> 00:07:12.470
OK.

117
00:07:12.470 --> 00:07:14.300
So that's one page.

118
00:07:14.300 --> 00:07:16.750
All of these results are coming from a single page.

119
00:07:16.760 --> 00:07:21.790
Now we face the tricky task of automating this so that it happens on every page.

120
00:07:21.950 --> 00:07:27.220
And the solution that I think is best is to use if we scroll down.

121
00:07:27.410 --> 00:07:27.800
There we go.

122
00:07:27.800 --> 00:07:34.970
This next link to find this on each page if it exists and if it does exist grab that you are well and

123
00:07:34.970 --> 00:07:40.490
scrape that you around and then keep going and try and find the next button and extract the you and

124
00:07:40.490 --> 00:07:42.140
scrape that Intel.

125
00:07:42.140 --> 00:07:46.510
Like I showed in the last video eventually there isn't a next button.

126
00:07:46.620 --> 00:07:48.480
And if that's the case we'll stop.

127
00:07:48.500 --> 00:07:48.810
OK.

128
00:07:48.830 --> 00:07:51.300
So we need to know how to find that next button.

129
00:07:51.330 --> 00:07:58.250
There's an ally with class equals next so we can use that and then find the anchor tag inside of the

130
00:07:58.300 --> 00:07:59.980
fly with class equals next.

131
00:08:00.170 --> 00:08:00.620
OK.

132
00:08:00.740 --> 00:08:04.080
So down here after we go through all the quotes.

133
00:08:04.280 --> 00:08:14.570
Let's also do a soup of find and then the class was called next and we can just save that to variable

134
00:08:14.600 --> 00:08:21.710
cut next button and then we'll do print next DTN dot find.

135
00:08:21.710 --> 00:08:25.600
And we want to find the first anchor tag dot X and not dot.

136
00:08:25.640 --> 00:08:32.670
We just want the H ref the link in that first anchor tag and we'll just print that and that's it.

137
00:08:32.690 --> 00:08:36.840
Let's just only print that actually so we won't print all quotes.

138
00:08:37.340 --> 00:08:40.760
And if you look down here we get page slash too.

139
00:08:40.880 --> 00:08:45.800
You also might notice that I'm getting this warning and it's telling me I'm 9:6.

140
00:08:45.980 --> 00:08:49.140
I'm not specifying what type of markup I'm using.

141
00:08:49.490 --> 00:08:52.170
So it still works but we just need to add this.

142
00:08:52.190 --> 00:08:53.450
And where are you.

143
00:08:53.450 --> 00:08:54.510
Here we go.

144
00:08:54.770 --> 00:08:58.630
This Each symbol that parser line I forgot that tells beautiful soup.

145
00:08:58.700 --> 00:09:00.960
We are indeed parsing HMO.

146
00:09:01.130 --> 00:09:01.580
All right.

147
00:09:01.610 --> 00:09:04.350
So this is giving us the next you are out to scrape.

148
00:09:04.490 --> 00:09:05.990
Well it's not the fool you are.

149
00:09:06.080 --> 00:09:08.670
But we could append this onto the base.

150
00:09:08.670 --> 00:09:09.430
You are ill.

151
00:09:09.560 --> 00:09:10.590
So let's do that.

152
00:09:10.670 --> 00:09:13.040
Let's make a variable called base.

153
00:09:13.040 --> 00:09:13.520
You are all

154
00:09:16.550 --> 00:09:23.210
equal to that string and then set a variable equal to you or row and are row is going to start as Page

155
00:09:23.270 --> 00:09:27.070
slash 1 and then we're going to combine these two.

156
00:09:27.140 --> 00:09:29.520
But this is going to change every time.

157
00:09:29.570 --> 00:09:32.650
This will be the result of what we find in the next button.

158
00:09:32.690 --> 00:09:34.730
But the first time around it has to start here.

159
00:09:34.790 --> 00:09:36.420
Serena do requests get.

160
00:09:36.500 --> 00:09:39.990
And then I don't know how about an F string.

161
00:09:40.920 --> 00:09:50.370
And what do you base your L and then no space immediately after are you or.

162
00:09:51.320 --> 00:09:55.370
And then the other thing is we want to move this code into here.

163
00:09:55.550 --> 00:09:59.290
Well not into there but we're going to move it down and then we're going to add a loop.

164
00:09:59.420 --> 00:10:02.990
And this is a big step but I'm going to do a set of wild true.

165
00:10:03.040 --> 00:10:09.640
I to do a while you Arel and at the beginning that's going to run forever.

166
00:10:09.680 --> 00:10:10.460
So that's not good.

167
00:10:10.460 --> 00:10:17.630
So don't run this just yet while you go make a request to base you or else with the you are appended

168
00:10:17.630 --> 00:10:18.020
at the end.

169
00:10:18.020 --> 00:10:19.510
So make a request to here.

170
00:10:19.940 --> 00:10:23.280
So if we're doing a while then we need to update the value of your l.

171
00:10:23.390 --> 00:10:26.330
I'm going to set instead of printing this here.

172
00:10:26.840 --> 00:10:32.120
I'm going to set you r l equals next PTEN dot find.

173
00:10:32.510 --> 00:10:35.330
So this will be that you are all that we find on the next page.

174
00:10:35.600 --> 00:10:43.340
So the next time around you l will now be page slash to page 3 but we solve the problem of Eventually

175
00:10:43.340 --> 00:10:45.960
there isn't going to be a next button find.

176
00:10:46.080 --> 00:10:50.070
And just to be safe we can just add some conditional logic in here.

177
00:10:50.120 --> 00:10:53.010
So you are out equals next button Fabo blah.

178
00:10:53.180 --> 00:10:56.210
If Next button exists in the first place.

179
00:10:56.240 --> 00:11:02.840
So if we can find that next button but if there is no next button on that page then we're going to set

180
00:11:02.840 --> 00:11:03.640
it to be.

181
00:11:03.860 --> 00:11:09.320
We could do none we could do false even an empty string but not as a kind of a standard thing to do.

182
00:11:09.680 --> 00:11:12.090
And I'm not going to do it on one line like this.

183
00:11:12.140 --> 00:11:15.600
So if we find the next button we're going to look for the next button on each page.

184
00:11:15.680 --> 00:11:21.620
If we find it set you RL to whatever that you are inside if that next button is and then that will restart

185
00:11:21.620 --> 00:11:22.890
the scraping process.

186
00:11:23.060 --> 00:11:27.740
If there isn't an X button so this should only happen one time at the end we get to the last page there's

187
00:11:27.770 --> 00:11:29.000
no next button set.

188
00:11:29.000 --> 00:11:30.470
You are out to be none.

189
00:11:30.650 --> 00:11:32.750
And then this will stop.

190
00:11:32.750 --> 00:11:40.070
So finally here let's do a print let's just print all quotes and then I also like to have some feedback

191
00:11:40.070 --> 00:11:41.230
as we go through this.

192
00:11:41.300 --> 00:11:44.030
So I'll do something like printing.

193
00:11:44.150 --> 00:11:45.610
Let me grab this string.

194
00:11:45.840 --> 00:11:50.240
You print scraping or paste that string.

195
00:11:50.390 --> 00:11:51.170
OK.

196
00:11:54.190 --> 00:11:56.900
Now scraping that you throw.

197
00:11:57.480 --> 00:12:00.460
So we have an idea what's happening because it will take a while.

198
00:12:00.730 --> 00:12:03.100
Not that long but a couple of seconds.

199
00:12:03.100 --> 00:12:03.330
All right.

200
00:12:03.340 --> 00:12:05.320
Let's see if I have any syntax errors.

201
00:12:05.320 --> 00:12:07.210
Moment of Truth here.

202
00:12:07.210 --> 00:12:07.890
All right.

203
00:12:07.960 --> 00:12:10.230
See if it works.

204
00:12:10.840 --> 00:12:14.120
And when you look at that it's going so fast.

205
00:12:14.180 --> 00:12:18.430
OK a couple of points I'd like to make one we can celebrate it works.

206
00:12:18.660 --> 00:12:20.230
We have all of this data.

207
00:12:20.230 --> 00:12:21.450
There's a lot of quotes now.

208
00:12:21.520 --> 00:12:22.530
So our game.

209
00:12:22.690 --> 00:12:24.120
I don't know how many quotes.

210
00:12:24.110 --> 00:12:27.490
There's like 10 or more in a page to at least 100 quotes.

211
00:12:27.490 --> 00:12:32.500
But the thing I want to point out is that this went really quickly and this site is intended for people

212
00:12:32.500 --> 00:12:33.020
to scrape.

213
00:12:33.030 --> 00:12:34.170
So that's OK.

214
00:12:34.300 --> 00:12:36.110
They're not going to freak out.

215
00:12:36.280 --> 00:12:42.360
But still it's polite to actually take a bit of time in between especially if you're scraping a site

216
00:12:42.370 --> 00:12:44.430
that maybe they don't want you to scrape.

217
00:12:44.440 --> 00:12:46.480
Then you definitely it's not a matter of being polite.

218
00:12:46.480 --> 00:12:48.430
It's a matter of not being caught.

219
00:12:48.430 --> 00:12:56.800
So what you want to do is space your requests out so we can import from time import sleep.

220
00:12:56.800 --> 00:12:59.250
And this is a way just to halt our code.

221
00:12:59.260 --> 00:13:06.960
So in this loop wherever we want just at the end we can do is sleep and then a number of seconds like

222
00:13:06.970 --> 00:13:13.390
one second or two seconds and now each time through the loop it will wait two seconds before requesting

223
00:13:13.390 --> 00:13:13.880
again.

224
00:13:14.080 --> 00:13:15.160
And that's a good idea.

225
00:13:15.160 --> 00:13:17.790
One because you don't want to overload the server in too.

226
00:13:17.800 --> 00:13:22.160
You don't want to attract attention if you're sending a bunch of requests in one second.

227
00:13:22.360 --> 00:13:24.900
And this is only happening 10 or so times.

228
00:13:24.970 --> 00:13:28.600
But if you're scraping a site that has tons of data you could be scraping.

229
00:13:28.600 --> 00:13:32.200
I don't know making ten thousand requests or more than you really would.

230
00:13:32.250 --> 00:13:36.420
You really want to be polite and you don't want to overload the server.

231
00:13:36.460 --> 00:13:42.400
So now I do it it's slowed down and I will speed this up so I'll be back in a second.

232
00:13:42.840 --> 00:13:43.480
OK.

233
00:13:43.650 --> 00:13:45.800
And now we get the exact same result.

234
00:13:45.910 --> 00:13:46.870
So I'm going to remove.

235
00:13:46.900 --> 00:13:51.940
We're going to comment out the sleep just so that you know I don't have to edit around it constantly

236
00:13:52.030 --> 00:13:53.160
in the next video.

237
00:13:53.180 --> 00:13:58.090
Just keep in mind that this is kind of standard protocol when you are scraping but it doesn't really

238
00:13:58.090 --> 00:14:01.140
matter for this exercise because we're not scraping that much data.

239
00:14:01.180 --> 00:14:01.610
All right.

240
00:14:01.660 --> 00:14:05.530
So so far we have successfully scraped all the quotes data.

241
00:14:05.590 --> 00:14:09.940
Now we're ready to go forth and actually create a game using the quotes data.

242
00:14:10.210 --> 00:14:16.390
One thing I would mention is if you were really doing this for real it would be better to save the quotes

243
00:14:16.390 --> 00:14:17.490
to a file.

244
00:14:17.800 --> 00:14:19.640
So you only scrape one time.

245
00:14:19.750 --> 00:14:25.510
Or maybe once every week or something and then when you actually run the game it would just call that

246
00:14:25.600 --> 00:14:31.930
CXXVI file or whatever file you created Jaison or CFE or in a pickle file and your game would just start

247
00:14:31.930 --> 00:14:33.650
by loading that file.

248
00:14:33.670 --> 00:14:38.650
It would be a lot faster than having to request you know this you Arel 10 times but it wasn't part of

249
00:14:38.650 --> 00:14:39.260
the requirement.

250
00:14:39.260 --> 00:14:44.470
So if you do want to do that good on you it would be it would make for a better experience for a user

251
00:14:44.470 --> 00:14:47.650
to not have to wait for all the scraping to happen.

252
00:14:47.800 --> 00:14:50.360
But this will work just as well for this little exercise.

253
00:14:50.380 --> 00:14:50.690
OK.

254
00:14:50.690 --> 00:14:52.780
In the next video we will build the game logic.
