1
00:00:00,640 --> 00:00:03,250
[Autogenerated] Okay, let's dive in to Sqs now.

2
00:00:03,250 --> 00:00:07,410
Amazon Simple Cue Service allows us to use a hosted

3
00:00:07,410 --> 00:00:12,740
platform for queueing messages, which allows for a D coupled architecture.

4
00:00:12,740 --> 00:00:13,440
Er.

5
00:00:13,440 --> 00:00:15,050
So let me click on Get Started now,

6
00:00:15,050 --> 00:00:19,880
and we'll walk through this and this brings us to our create a new Q screen,

7
00:00:19,880 --> 00:00:20,870
so we'll give it a name.

8
00:00:20,870 --> 00:00:22,540
Let me call it Pluralsight.

9
00:00:22,540 --> 00:00:26,340
And that brings us to what type of Q do we need now?

10
00:00:26,340 --> 00:00:30,670
A standard que allows for unlimited throughput,

11
00:00:30,670 --> 00:00:34,020
the transactions per second with an API action.

12
00:00:34,020 --> 00:00:38,580
Now, the difference between these two types of queues are pretty significant,

13
00:00:38,580 --> 00:00:43,540
so it's very important that you understand them for the exam.

14
00:00:43,540 --> 00:00:47,090
Now a standard Q on the left has unlimited throughput,

15
00:00:47,090 --> 00:00:48,940
which is important to know,

16
00:00:48,940 --> 00:00:54,490
But the two big pieces are that the messages are only guaranteed at least once.

17
00:00:54,490 --> 00:00:58,080
But that does not prevent duplication in the system,

18
00:00:58,080 --> 00:01:03,540
so messages can be processed more than once off of the queue.

19
00:01:03,540 --> 00:01:07,170
And that's a very important point to keep in mind when designing

20
00:01:07,170 --> 00:01:12,090
an architecture for sqs and then just as important is that is we

21
00:01:12,090 --> 00:01:14,190
have best effort ordering now.

22
00:01:14,190 --> 00:01:18,880
What this means is that Sqs is going to do its best to deliver

23
00:01:18,880 --> 00:01:21,640
messages in order from which they were sent.

24
00:01:21,640 --> 00:01:25,190
But there's no guarantee that they will be received in order.

25
00:01:25,190 --> 00:01:27,400
And you can see the graphic here at the bottom.

26
00:01:27,400 --> 00:01:31,300
You can see we have message one and then we have message three on the right.

27
00:01:31,300 --> 00:01:36,130
So Message three is getting delivered twice and before

28
00:01:36,130 --> 00:01:39,160
one and two and then we have a FIFA Q.

29
00:01:39,160 --> 00:01:42,610
Now a 50 que has a very specific purpose,

30
00:01:42,610 --> 00:01:43,940
and you'll see when we choose it,

31
00:01:43,940 --> 00:01:48,340
you have to have .NET Python at the end of your cue name as well.

32
00:01:48,340 --> 00:01:49,320
I'm not going to create a fight.

33
00:01:49,320 --> 00:01:50,910
Folk UI just want to read through this,

34
00:01:50,910 --> 00:01:54,890
but you can see that it has high throughput but not unlimited.

35
00:01:54,890 --> 00:01:58,790
So you can only go up to 300 messages per second.

36
00:01:58,790 --> 00:02:01,270
And what that means is that you can only have a

37
00:02:01,270 --> 00:02:06,650
total of 300 API calls per second, so that includes descends,

38
00:02:06,650 --> 00:02:09,240
the receives and the deletes.

39
00:02:09,240 --> 00:02:13,160
Now A W S suggests a best practice here,

40
00:02:13,160 --> 00:02:19,040
and they really preach about batch ing messages together into groups of 10.

41
00:02:19,040 --> 00:02:20,400
If that's possible,

42
00:02:20,400 --> 00:02:24,940
what this does is it allows our consumers are workers that error polling the

43
00:02:24,940 --> 00:02:29,010
queues for the messages to pull up to 3000 per second?

44
00:02:29,010 --> 00:02:34,550
Because there's many messages in one single API call and batch ING messages,

45
00:02:34,550 --> 00:02:36,170
either in Standard or Fife.

46
00:02:36,170 --> 00:02:39,600
Oh, allow for a cost optimization.

47
00:02:39,600 --> 00:02:43,840
Since you're making less API calls to sqs.

48
00:02:43,840 --> 00:02:48,600
Now, the two biggest parts of a 50 que is its first in first out.

49
00:02:48,600 --> 00:02:50,840
That's what FIFA stands for.

50
00:02:50,840 --> 00:02:56,350
So whichever order messages error sent their received in the exact same order.

51
00:02:56,350 --> 00:03:01,300
So you can see in the graph that it's 12345 And that differs

52
00:03:01,300 --> 00:03:05,670
from our standard Q on the left and then another major benefit

53
00:03:05,670 --> 00:03:07,910
is the exactly once processing,

54
00:03:07,910 --> 00:03:13,400
so a messages only going to be delivered once until it's consumed and deleted.

55
00:03:13,400 --> 00:03:16,890
There's no duplicates that error introduced into the queue.

56
00:03:16,890 --> 00:03:18,690
So with a standard Q,

57
00:03:18,690 --> 00:03:23,420
you have to build in some type of D duplication process that can

58
00:03:23,420 --> 00:03:27,490
handle duplicate messages coming in as opposed to FIFA,

59
00:03:27,490 --> 00:03:31,770
where you know your only going to get one message and the order

60
00:03:31,770 --> 00:03:35,870
is going to be preserved so I'll go into a standard queue here

61
00:03:35,870 --> 00:03:39,450
for this demo will configure our Q and let's walk through these

62
00:03:39,450 --> 00:03:41,640
attributes and settings now.

63
00:03:41,640 --> 00:03:44,740
The first is the default visibility time out,

64
00:03:44,740 --> 00:03:50,640
and what this is specifying is the amount of seconds or hours or

65
00:03:50,640 --> 00:03:54,620
minutes that we want a message to be hidden on the Q.

66
00:03:54,620 --> 00:03:55,980
Once it's received,

67
00:03:55,980 --> 00:04:00,600
it's important to note the difference between receiving and deleting a message.

68
00:04:00,600 --> 00:04:06,540
Receiving a message simply hides it based on this visibility time out.

69
00:04:06,540 --> 00:04:10,590
So when a worker pulls a message down, it doesn't delete it from the queue.

70
00:04:10,590 --> 00:04:13,990
You have to make a separate call for deleting that message.

71
00:04:13,990 --> 00:04:16,990
Otherwise it'll get populated back onto the Q.

72
00:04:16,990 --> 00:04:19,470
And you can see we could go between zero seconds.

73
00:04:19,470 --> 00:04:22,410
So don't hide any of them, and 12 hours.

74
00:04:22,410 --> 00:04:24,840
It's just dependent on your use case.

75
00:04:24,840 --> 00:04:27,680
The next thing we have is our message retention period.

76
00:04:27,680 --> 00:04:33,120
So how long do we want to store this message on our cue for resiliency?

77
00:04:33,120 --> 00:04:36,810
So these messages currently with these settings can live for

78
00:04:36,810 --> 00:04:39,940
four days on the queue before they're deleted,

79
00:04:39,940 --> 00:04:42,660
so this allows for some downtime in between,

80
00:04:42,660 --> 00:04:47,140
so you don't lose your messages and you can see the maximum is 14 days,

81
00:04:47,140 --> 00:04:50,100
and that builds into maximum message size.

82
00:04:50,100 --> 00:04:56,540
Now, messages in sqs can only be up to 256 kilobytes,

83
00:04:56,540 --> 00:05:00,940
and a common exam scenario is having to send larger

84
00:05:00,940 --> 00:05:03,800
messages than that on to Sqs.

85
00:05:03,800 --> 00:05:07,200
And then they ask you what kind of architecture you could use?

86
00:05:07,200 --> 00:05:10,120
Well, a very common architecture er.

87
00:05:10,120 --> 00:05:15,740
To solve that problem is to store the large objects and S3 and then

88
00:05:15,740 --> 00:05:21,370
passing metadata as the messages in sqs pointing at those objects

89
00:05:21,370 --> 00:05:24,010
similar to the graphic you see on the screen here.

90
00:05:24,010 --> 00:05:27,860
So this is sort of a bypass in a way to get around

91
00:05:27,860 --> 00:05:32,610
that size limit that Sqs holds, and this is a hard limit,

92
00:05:32,610 --> 00:05:34,040
so keep that in mind.

93
00:05:34,040 --> 00:05:36,630
The next thing we have is a delivery delay.

94
00:05:36,630 --> 00:05:40,740
So how long do we want to wait to deliver a message?

95
00:05:40,740 --> 00:05:44,510
So how long do we want to wait to deliver the message?

96
00:05:44,510 --> 00:05:49,190
Once it's on the Q on we can, hold it from 0 to 15 minutes.

97
00:05:49,190 --> 00:05:55,110
So if we wanted to we can go ahead and hold on to that message and wait to

98
00:05:55,110 --> 00:05:59,050
deliver it and building off of that we have our received message.

99
00:05:59,050 --> 00:06:04,440
Wait time now this is where we talk about short polling and long polling.

100
00:06:04,440 --> 00:06:07,500
So zero seconds is considered short polling.

101
00:06:07,500 --> 00:06:11,970
And that means you have to constantly check the queue for new messages,

102
00:06:11,970 --> 00:06:15,430
since there's no wait time messages, error not gonna build up.

103
00:06:15,430 --> 00:06:19,660
But if we wanted to we can specify up to 20 seconds,

104
00:06:19,660 --> 00:06:22,340
and that's now in the long polling range.

105
00:06:22,340 --> 00:06:26,840
Anything more than zero is considered long polling in sqs,

106
00:06:26,840 --> 00:06:28,680
and this allows for two things.

107
00:06:28,680 --> 00:06:34,390
It allows sqs to gather all of the messages so we can almost guarantee

108
00:06:34,390 --> 00:06:36,840
that we're gonna have at least one message in there,

109
00:06:36,840 --> 00:06:40,870
which, if we didn't, would be a waste of an API call which you pay for.

110
00:06:40,870 --> 00:06:44,170
So this allows messages to build up so we have a better

111
00:06:44,170 --> 00:06:46,640
chance of pulling them off the queue.

112
00:06:46,640 --> 00:06:46,750
Now.

113
00:06:46,750 --> 00:06:49,500
This provides a few main benefits,

114
00:06:49,500 --> 00:06:55,430
the first being it allows us to wait for messages to be cute onto a rescue

115
00:06:55,430 --> 00:06:59,750
sq in order for processing and building off of that,

116
00:06:59,750 --> 00:07:03,320
it allows for less API calls to the Q.

117
00:07:03,320 --> 00:07:07,270
Because now we're waiting 20 seconds in between calls,

118
00:07:07,270 --> 00:07:12,140
as opposed to having to check the Q constantly with a set of zero,

119
00:07:12,140 --> 00:07:13,870
so we'll go ahead and leave this at zero.

120
00:07:13,870 --> 00:07:17,080
But this is an important architecture question that comes up

121
00:07:17,080 --> 00:07:19,270
quite frequently on the professional level.

122
00:07:19,270 --> 00:07:23,080
Exams understand that zero is short polling,

123
00:07:23,080 --> 00:07:27,340
and then anything from 1 to 20 seconds is considered long polling.

124
00:07:27,340 --> 00:07:29,550
And then we have our dead letter Q settings.

125
00:07:29,550 --> 00:07:33,720
Now, this is where we can specify a re Docker policy,

126
00:07:33,720 --> 00:07:37,940
and what this does is it allows us to store messages that fail

127
00:07:37,940 --> 00:07:42,240
processing onto a separate queue for longer retention.

128
00:07:42,240 --> 00:07:42,500
Now,

129
00:07:42,500 --> 00:07:46,520
this is a best practice to use dead letter cues because it will

130
00:07:46,520 --> 00:07:50,660
allow you to go ahead and view the message that was failing and

131
00:07:50,660 --> 00:07:54,000
then do some type of diagnosis to solve.

132
00:07:54,000 --> 00:07:55,540
Why it error it out.

133
00:07:55,540 --> 00:07:57,600
Now you'll see we have to have an existing Q.

134
00:07:57,600 --> 00:08:00,280
I don't have one, so I'm gonna diesel ect this.

135
00:08:00,280 --> 00:08:03,820
But this is a very critical component of SQs,

136
00:08:03,820 --> 00:08:06,590
a dead letter Q, which is also known as D E.

137
00:08:06,590 --> 00:08:06,740
L.

138
00:08:06,740 --> 00:08:07,640
Q.

139
00:08:07,640 --> 00:08:10,460
And finally, we have our server site encryption.

140
00:08:10,460 --> 00:08:15,180
So if we wanted to we can use server site encryption and this is going to

141
00:08:15,180 --> 00:08:20,020
encrypt our messages when they go into the Q And what's neat about this

142
00:08:20,020 --> 00:08:26,860
is that we can specify how long we can allow sqs to reuse a data key that

143
00:08:26,860 --> 00:08:29,320
it generates from our kms key.

144
00:08:29,320 --> 00:08:31,870
So we can say, hey, every five minutes,

145
00:08:31,870 --> 00:08:34,950
I want you to generate a new data key and start

146
00:08:34,950 --> 00:08:37,440
encrypting and decrypting with that.

147
00:08:37,440 --> 00:08:41,380
And then it continually cycles based on our re use period.

148
00:08:41,380 --> 00:08:43,440
So I'm not going to encrypt.

149
00:08:43,440 --> 00:08:46,500
I'm gonna go ahead and click on Create Que and there we go.

150
00:08:46,500 --> 00:08:48,120
We now have our Q.

151
00:08:48,120 --> 00:08:49,410
So what can we do with this?

152
00:08:49,410 --> 00:08:54,290
Well, some architectural examples would be similar to this graphic.

153
00:08:54,290 --> 00:08:57,380
Here we have a decoupled architecture er,

154
00:08:57,380 --> 00:08:58,430
as you can see,

155
00:08:58,430 --> 00:09:01,050
where we have our workers which are pushing

156
00:09:01,050 --> 00:09:03,910
messages or sending messages to our Q.

157
00:09:03,910 --> 00:09:09,300
We have the Q itself, which allows for the decoupling and data retention.

158
00:09:09,300 --> 00:09:12,380
And then we have the polar or the worker on the back end

159
00:09:12,380 --> 00:09:14,840
that's pulling the messages off the queue.

160
00:09:14,840 --> 00:09:19,930
So what this does is it allows us to separate our application components and

161
00:09:19,930 --> 00:09:24,640
allows us to break away from a traditional monolithic approach.

162
00:09:24,640 --> 00:09:26,840
We can have separate components that error

163
00:09:26,840 --> 00:09:29,840
independently operating and being updated.

164
00:09:29,840 --> 00:09:32,300
All right, this is a pretty good breaking point,

165
00:09:32,300 --> 00:09:41,000
the clips getting a little long, so let's go ahead. We'll break here and then we'll pick back up where we left off in the next clip.

