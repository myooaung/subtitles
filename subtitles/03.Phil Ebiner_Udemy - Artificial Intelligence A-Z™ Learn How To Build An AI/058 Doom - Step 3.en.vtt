WEBVTT
1
00:00:00.360 --> 00:00:06.030
Hello and welcome to the first part of this AI implementation part one building the AI.

2
00:00:06.120 --> 00:00:12.570
And as you can see I already added dimension in the structure of this indentation with these three sections

3
00:00:12.660 --> 00:00:16.620
composing Part 1 which clearly show how we are going to build this AI.

4
00:00:16.620 --> 00:00:18.750
First we're going to make the brain.

5
00:00:18.840 --> 00:00:23.760
There is nothing else than the neural network then we're going to make the body which will define how

6
00:00:23.760 --> 00:00:25.400
the actions are going to be played.

7
00:00:25.590 --> 00:00:31.620
And then once we have the brain and the body we will assemble them to make the AI which will be in the

8
00:00:31.620 --> 00:00:33.840
last section of this first part.

9
00:00:33.840 --> 00:00:37.890
So now you can already have a good vision of the structure of this implementation.

10
00:00:37.890 --> 00:00:42.760
First we make the brain then we make the body and then we assemble the two to make the AI.

11
00:00:43.050 --> 00:00:48.520
And then this is all we're going to start with the first section that is about making the brain.

12
00:00:48.810 --> 00:00:51.330
And this is going to take us for tutorials.

13
00:00:51.360 --> 00:00:54.810
You can imagine that making a brain is not like making a cake.

14
00:00:54.900 --> 00:00:57.100
So this will require more than one tutorial.

15
00:00:57.270 --> 00:01:03.690
And of course as usual we are going to represent that brain with a class because we will need several

16
00:01:03.690 --> 00:01:10.200
functions and in order to have a structure of several functions that will be organized in some kind

17
00:01:10.200 --> 00:01:11.160
of instructions.

18
00:01:11.310 --> 00:01:16.010
Well of course we need a class and that's Berkeley because once we made that class.

19
00:01:16.080 --> 00:01:22.080
Well we will be able to create as many brains as we want by just creating some objects of this class.

20
00:01:22.080 --> 00:01:28.050
So again classes in Python and in general an object oriented programming languages are very practical

21
00:01:28.200 --> 00:01:33.510
because you make a model of something you want to build and then you're able to create as many object

22
00:01:33.510 --> 00:01:37.820
as you want and they will have all the features that you define in the class.

23
00:01:38.010 --> 00:01:40.470
And for our brain the features will be of course.

24
00:01:40.500 --> 00:01:45.930
Well first of all the architecture of the neural network which I remind will be of CNN and of course

25
00:01:45.930 --> 00:01:51.780
two different functions like for example passing on the signals from the input neurons to the output

26
00:01:51.780 --> 00:01:55.520
neurons that will be of course the Ford function that will make.

27
00:01:55.920 --> 00:01:58.940
So let's do this let's start making the brain.

28
00:01:58.950 --> 00:02:00.600
This is going to be pretty exciting.

29
00:02:00.650 --> 00:02:02.380
It is one of my favorite parts.

30
00:02:02.520 --> 00:02:04.860
And therefore let's get straight into it.

31
00:02:04.890 --> 00:02:10.880
So we're going to start by introducing the class of course and we're going to call this class.

32
00:02:10.950 --> 00:02:18.570
Well I hesitated to call it brain but let's be more direct and let's call it CNN because actually the

33
00:02:18.570 --> 00:02:20.570
brain is a CNN network.

34
00:02:20.580 --> 00:02:22.510
Convolutional neural network.

35
00:02:22.530 --> 00:02:27.440
So as you watch you can call brain if you want but at least now we know what we're building.

36
00:02:28.710 --> 00:02:35.040
And CNN As for the network of the self-driving car is going to inherit from the end of Mudgal.

37
00:02:35.220 --> 00:02:42.870
So remember the end of module is what we put it here and we want to be able to use all the tools of

38
00:02:42.870 --> 00:02:49.050
this and a module and therefore we want to use this technique in object oriented programming which is

39
00:02:49.050 --> 00:02:55.870
inheritance and which allows us to you know well use all the tools from a parent class and this very

40
00:02:55.900 --> 00:02:59.970
class is going to be on that module.

41
00:02:59.970 --> 00:03:00.830
There we go.

42
00:03:00.930 --> 00:03:05.510
And now we can use all the tools and objects at the end of that module.

43
00:03:05.510 --> 00:03:12.100
All right so now that we have our inheritance we can go into the class to make our first function.

44
00:03:12.150 --> 00:03:18.360
And as you probably guess the first function is the end function that will define all the variables

45
00:03:18.720 --> 00:03:20.330
of the future brain objects.

46
00:03:20.370 --> 00:03:23.440
You know the future and objects that will be created.

47
00:03:23.700 --> 00:03:24.890
All right so let's do this.

48
00:03:24.900 --> 00:03:29.800
Def then two underscores in it to the scores again.

49
00:03:29.910 --> 00:03:31.910
And now we need to put some variables.

50
00:03:32.100 --> 00:03:37.460
So first of all I was going to be self that's of course to refer to the object.

51
00:03:37.490 --> 00:03:42.380
Now I guess you're pretty comfortable with this then we we're going to add another variable which will

52
00:03:42.380 --> 00:03:45.310
be the number of actions in the Dumah environment.

53
00:03:45.500 --> 00:03:48.900
So we're going to call that number actions.

54
00:03:49.010 --> 00:03:50.380
Number of actions.

55
00:03:50.570 --> 00:03:54.390
And actually this variable is not compulsory for the function.

56
00:03:54.500 --> 00:03:59.360
It's just that if you want to test the idea we're going to build on other environments.

57
00:03:59.540 --> 00:04:06.100
Well this will be very practical because we will import this number of actions horrible from the doom

58
00:04:06.120 --> 00:04:12.290
and Varman wrappers with two discrete and when doing that we will you know input the name of the environment

59
00:04:12.510 --> 00:04:13.980
do the zero.

60
00:04:14.180 --> 00:04:21.050
And so if you want to you know experiment with this on other environments and play other games well

61
00:04:21.050 --> 00:04:26.300
you won't have anything to do because this number of actions will directly get the number of actions

62
00:04:26.300 --> 00:04:27.470
in the Dumor environment.

63
00:04:27.470 --> 00:04:28.650
You'll be playing with.

64
00:04:29.110 --> 00:04:32.710
OK so that's it for the two arguments of this function.

65
00:04:32.780 --> 00:04:36.500
So now we can go inside and now remember what we have to do.

66
00:04:36.530 --> 00:04:41.560
The first thing we have to do is activate the inheritance with the superfunction.

67
00:04:41.570 --> 00:04:43.840
So that's exactly like for the self-driving car.

68
00:04:43.970 --> 00:04:50.940
We take the superfunction then inside we start by inputting the class that will define the neural network

69
00:04:51.470 --> 00:04:53.330
and that is CNN.

70
00:04:53.690 --> 00:04:56.950
Then we have to input self to refer to the object.

71
00:04:57.190 --> 00:05:05.230
But then remember that's not all we need to add here at DOT and then the init function with some parenthesis.

72
00:05:05.270 --> 00:05:07.880
And by doing that we activate the inheritance.

73
00:05:07.950 --> 00:05:11.470
And now we can use all the tools from the end and the module.

74
00:05:11.510 --> 00:05:17.070
All right so now I think it's time to build the architecture of the neural network.

75
00:05:17.270 --> 00:05:23.330
And so as you remember we are going to build a CNN convolutional neural network simply because this

76
00:05:23.330 --> 00:05:30.290
time the AI will have eyes and the eyes of the eye will be the convolutional layers of this convolutional

77
00:05:30.290 --> 00:05:31.220
neural network.

78
00:05:31.520 --> 00:05:38.240
And then after the ai ai visualizes the images with the convolutional layers it will pass on the signals

79
00:05:38.330 --> 00:05:41.040
into a classic our visual neural network.

80
00:05:41.180 --> 00:05:44.510
So that is the one that we had before with fully connected layers.

81
00:05:44.660 --> 00:05:50.730
And that's where it will try to predict the cube values for each possible actions that we can play.

82
00:05:51.290 --> 00:05:56.930
So you have the architecture in mind first we're going to have some convolutional layers and then some

83
00:05:56.930 --> 00:06:01.270
fully connected layers and this will be the brain of our AI.

84
00:06:01.550 --> 00:06:07.530
So what we're going to do to be able to have a step back at what we're making.

85
00:06:07.670 --> 00:06:11.840
Well let's just make this architecture with the variables we want to create.

86
00:06:11.840 --> 00:06:18.890
So actually speaking of this architecture we are going to build a CNN with three convolutional layers.

87
00:06:18.920 --> 00:06:24.530
And then after that one hidden layer that means that we will need three convolutional connections and

88
00:06:24.530 --> 00:06:26.020
two full connections.

89
00:06:26.180 --> 00:06:31.340
And speaking of connections that's exactly what we're about to define that will be the variables for

90
00:06:31.370 --> 00:06:35.030
CNN class and therefore Right now I'm going to define five variables.

91
00:06:35.150 --> 00:06:39.100
Three for the convolutional connections and two political connections.

92
00:06:39.350 --> 00:06:40.100
So let's do this.

93
00:06:40.100 --> 00:06:42.570
We're going to start with the convolution connections.

94
00:06:42.770 --> 00:06:47.250
So I'm going to call them self-taught convolution.

95
00:06:47.540 --> 00:06:53.620
One going to copy that and based on the low.

96
00:06:54.020 --> 00:07:01.640
And then we go self-conviction to and self-conviction three that are convolution connections to this

97
00:07:01.640 --> 00:07:08.450
first conclusion one here we'll apply some convolution to the input images to get a first convolutional

98
00:07:08.460 --> 00:07:15.860
layer then the second contribution to here will take the first convolutional layer as input and by applying

99
00:07:15.860 --> 00:07:21.180
again some convolution it will create a second convolutional there and then this convolutional there

100
00:07:21.180 --> 00:07:25.920
will get some new images each of them detecting one specific feature.

101
00:07:26.030 --> 00:07:32.840
So we'll get these new images in a convolutional there then we will apply this convolution to here to

102
00:07:32.870 --> 00:07:39.740
connect these new images from this first convolutional layer to some new images of a second convolution

103
00:07:39.740 --> 00:07:40.300
layer.

104
00:07:40.430 --> 00:07:46.120
And these new images again will detect some features in the images of the first convolutional there.

105
00:07:46.220 --> 00:07:52.100
So it's just to reinforce the future detection and then to the emergence of the second convolutional

106
00:07:52.100 --> 00:07:52.650
there.

107
00:07:52.790 --> 00:07:57.000
We applied the third convolutional here to get it for each of them.

108
00:07:57.050 --> 00:08:01.900
Some more images that detect even more features inside the input images.

109
00:08:02.050 --> 00:08:07.300
And so the more we do this the more we apply some convolutions to the different layers of images.

110
00:08:07.520 --> 00:08:13.580
Well the more we are able to detect some features and that's how by detecting features the eye will

111
00:08:13.580 --> 00:08:18.360
understand where the monsters are where it has to shoot to kill them and where it should go to.

112
00:08:18.500 --> 00:08:21.290
It will also detect the walls the obstacles.

113
00:08:21.440 --> 00:08:28.100
Well literally where it has to go and that is thanks to what all these convolutional layers detect in

114
00:08:28.130 --> 00:08:29.680
the original images.

115
00:08:30.450 --> 00:08:34.980
All right so that's for the convolution part of the CNN.

116
00:08:35.100 --> 00:08:42.720
But then remember after the convolutional layers we have to flatten all the pixels obtained by the different

117
00:08:42.720 --> 00:08:48.660
series of convolutions that were applied and by flattening all the arrays of pixels we get this huge

118
00:08:48.810 --> 00:08:53.260
vector that will become the input of a classic artificial neural network.

119
00:08:53.490 --> 00:08:58.600
And that's where we get our fully connected letters and therefore our connections.

120
00:08:58.710 --> 00:09:04.560
And so now what we have to do is create two new variables because we're going to have one here and there

121
00:09:04.810 --> 00:09:09.330
in this classic artificial neural network that comes next and therefore we need one full connection

122
00:09:09.330 --> 00:09:16.260
from this huge Flaten vector to this one here and there and a second full connection between this one

123
00:09:16.260 --> 00:09:21.620
here and there and the output layer composed of the output neurons that are the key values.

124
00:09:21.960 --> 00:09:27.090
So let's make these two first connections and then we will define all these connections.

125
00:09:27.240 --> 00:09:36.200
So ask for the soundtrack in code we're going to call them self that one and then self taught C too.

126
00:09:36.240 --> 00:09:41.010
All right so now we have all our valuables and to know what we have to do is of course defined then

127
00:09:41.250 --> 00:09:44.300
with the classes of the engine module.

128
00:09:44.310 --> 00:09:49.110
So that means we'll basically create the architecture of the neural network and that's what we'll do

129
00:09:49.190 --> 00:09:50.340
in the next tomorrow.

130
00:09:50.490 --> 00:09:51.920
Until then I.
