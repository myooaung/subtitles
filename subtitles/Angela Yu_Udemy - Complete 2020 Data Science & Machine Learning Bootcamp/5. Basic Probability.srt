1
00:00:00,540 --> 00:00:06,900
Now that we've discussed a final step on how our need based classifier makes decisions we should talk

2
00:00:06,900 --> 00:00:12,840
about where the probabilities that feed into this decision making actually come from.

3
00:00:12,840 --> 00:00:20,730
And this means backing up a bit and talking about statistics how this is the part that no one gets excited

4
00:00:20,730 --> 00:00:21,610
about.

5
00:00:21,630 --> 00:00:24,170
I've yet to hear somebody say yes statistics.

6
00:00:24,180 --> 00:00:31,620
My favorite topic but the thing is statistics is everything in machine learning and this project will

7
00:00:31,620 --> 00:00:34,770
give us a chance to get some exposure.

8
00:00:34,770 --> 00:00:35,100
All right.

9
00:00:35,190 --> 00:00:39,030
So we're interested in calculating the probability that an email is spam.

10
00:00:39,630 --> 00:00:45,960
However it's not like we can simply work out the probability the same way we would work out the probability

11
00:00:46,020 --> 00:00:53,610
of safe flipping heads on a coin flip or rolling a six with a die with coins and dice working out the

12
00:00:53,610 --> 00:00:56,640
probabilities is fairly straightforward.

13
00:00:56,640 --> 00:01:02,620
But let's review some of these concepts nonetheless because they're gonna come in handy later.

14
00:01:02,880 --> 00:01:12,300
How with coins we know that there's two sides and a flip has a 50/50 chance of showing heads with this

15
00:01:12,300 --> 00:01:13,140
dice here.

16
00:01:13,170 --> 00:01:20,550
We know that there are six sides and we've got a one in six or roughly 17 percent chance of rolling

17
00:01:20,610 --> 00:01:23,470
a six or any particular number.

18
00:01:23,490 --> 00:01:29,490
Now let me ask you a question outside of the realm of flipping coins and rolling dice.

19
00:01:29,550 --> 00:01:33,690
How would you work out your probability of getting hit by lightning.

20
00:01:35,220 --> 00:01:41,490
Yeah I know you could probably ask Google and get the answer but if you had to calculate it yourself

21
00:01:41,940 --> 00:01:45,090
how would you do it well.

22
00:01:45,220 --> 00:01:51,940
The simplest way to do this is by dividing two numbers the total number of times people get hit by lightning

23
00:01:53,080 --> 00:01:55,820
and the total number of lightning strikes.

24
00:01:55,900 --> 00:02:04,990
Now I trawled through the key PDA for you and I've dug out these figures about 240000 people are injured

25
00:02:05,140 --> 00:02:07,220
by lightning every year.

26
00:02:07,360 --> 00:02:16,420
Now at 24000 actually sounds like quite a lot of people but there are an order of magnitude more lightning

27
00:02:16,420 --> 00:02:24,250
strikes every year around 350 million lightning bolts actually strike the ground.

28
00:02:24,250 --> 00:02:30,320
So then just given these two numbers what's the chance of your AI being hurt by lightning.

29
00:02:30,970 --> 00:02:39,600
Well it'll be 240000 divided by 350 million or zero point zero seven percent.

30
00:02:39,640 --> 00:02:44,550
The point I'm trying to get across here is how to use basic probability.

31
00:02:44,650 --> 00:02:51,010
We took some observations like the number of times a lightning struck a person and the total number

32
00:02:51,010 --> 00:02:54,130
of times we observed lightning in a year.

33
00:02:54,130 --> 00:02:56,290
To calculate this figure.

34
00:02:56,290 --> 00:03:02,430
Now suppose we had to work out the chance of an email being spam.

35
00:03:02,440 --> 00:03:09,940
Any email that is right any email in the whole world we can apply the same technique as in the lightning

36
00:03:09,940 --> 00:03:19,660
example the chance of an email being spam should also depend on two things namely one how many spam

37
00:03:19,690 --> 00:03:29,140
emails were sent and 2 how many emails were sent and total with these two quantities in hand.

38
00:03:29,200 --> 00:03:36,940
We can work it out so trawled the internet and here's what I pulled up in 2017.

39
00:03:36,940 --> 00:03:42,910
There were an estimated one hundred and forty eight billion spam emails sent.

40
00:03:42,910 --> 00:03:52,330
That's right billion and the total number of emails being sent was approximately two hundred and sixty

41
00:03:52,330 --> 00:03:53,670
nine billion.

42
00:03:53,890 --> 00:04:02,740
So that means if a new email comes into your inbox the probability of that email being spam or having

43
00:04:02,740 --> 00:04:08,460
pin spam in 2017 was 55 percent.

44
00:04:08,470 --> 00:04:15,580
And this is simply based on the observation of the frequencies namely the total number of spam emails

45
00:04:15,700 --> 00:04:19,840
divided by the total number of all email traffic.

46
00:04:19,840 --> 00:04:24,110
So you can think of calculating the basic probability as step one.

47
00:04:24,400 --> 00:04:31,510
We figured out the overall probability of spam but we can't build a classifier with this alone.

48
00:04:31,510 --> 00:04:32,320
So what's step two.
