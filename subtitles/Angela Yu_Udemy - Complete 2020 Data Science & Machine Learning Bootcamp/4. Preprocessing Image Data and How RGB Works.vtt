WEBVTT
1
00:00:00.800 --> 00:00:01.270
All right.

2
00:00:01.300 --> 00:00:07.420
So in this lesson we're gonna start working with images we're going to start a brand new Google collab

3
00:00:07.420 --> 00:00:08.470
notebook.

4
00:00:08.560 --> 00:00:16.360
And in that notebook we're gonna be using something called tensor flow tensor flow is an open source

5
00:00:16.420 --> 00:00:18.130
machine learning framework.

6
00:00:18.170 --> 00:00:25.290
It was developed originally by Google but was subsequently open sourced in 2015 and ever since then

7
00:00:25.290 --> 00:00:31.780
it's become incredibly popular and widely used tensor flow is the technology that's going to be running

8
00:00:31.810 --> 00:00:34.990
in the background powering our neural network.

9
00:00:34.990 --> 00:00:40.180
But on top of tense afloat we're gonna be using something called Charisse.

10
00:00:40.570 --> 00:00:44.750
You can think of carrots as a bolt on to tensor flow.

11
00:00:44.800 --> 00:00:52.060
It's a neural network library and it's probably one of the easiest most user friendly ways to get started

12
00:00:52.360 --> 00:00:54.190
working with neural networks.

13
00:00:54.580 --> 00:01:00.300
Charisse is essentially a module that will use tensor flow in the background to do the calculations.

14
00:01:00.430 --> 00:01:06.270
So let's jump right in and fire up your chrome browser and follow along with me.

15
00:01:06.350 --> 00:01:06.860
How.

16
00:01:06.870 --> 00:01:11.350
In this case I really do recommend the Google Chrome browser because I've seen some strange bugs with

17
00:01:12.040 --> 00:01:15.950
other browsers like Firefox when it comes to things like file upload.

18
00:01:16.420 --> 00:01:19.310
So go to drive dot google dot com.

19
00:01:19.570 --> 00:01:29.530
You'll need a Google account to do this of course and then go to new more collaboratively.

20
00:01:29.890 --> 00:01:39.870
So just click on that and Google Drive will create a new file namely their version of a Jupiter notebook.

21
00:01:39.870 --> 00:01:46.230
The interface is actually very very similar to Jupiter which is not really a surprise considering it's

22
00:01:46.230 --> 00:01:48.610
all based on Jupiter notebook.

23
00:01:48.600 --> 00:01:52.050
There's only a few minor differences which you'll see shortly.

24
00:01:52.050 --> 00:01:57.290
Once your page is loaded click up here and let's rename this notebook.

25
00:01:57.570 --> 00:02:10.230
Let's call it 0 9 neural nets hyphen pre trained image classification.

26
00:02:10.230 --> 00:02:18.690
Now let's add a markdown cell so you just click on text and him will create a market on cell that reads

27
00:02:18.780 --> 00:02:19.380
inputs.

28
00:02:20.220 --> 00:02:25.590
So one difference you'll see is you'll get a little preview of what your markdown will actually look

29
00:02:25.590 --> 00:02:29.130
like here on the right shift enter.

30
00:02:29.130 --> 00:02:30.380
And so it's a cell below.

31
00:02:31.230 --> 00:02:34.190
And here we can add our input statements.

32
00:02:34.710 --> 00:02:39.110
So I'll say import num pi adds and P.

33
00:02:39.300 --> 00:02:41.350
We always need num Pi.

34
00:02:41.370 --> 00:02:50.940
And then I'll import tens of low as T F and then I'll import Charisse.

35
00:02:50.940 --> 00:02:55.770
Now one other thing I might actually do is click on this little arrow sign here and toggle the header

36
00:02:55.770 --> 00:02:59.830
visibility that way we get a bit more screen real estate.

37
00:02:59.880 --> 00:03:02.880
Next I want to import the I Python display.

38
00:03:03.360 --> 00:03:10.950
But before I do that I'm going to hit connect up here which connects a runtime to this notebook.

39
00:03:10.950 --> 00:03:13.680
Meaning our code could actually get executed.

40
00:03:13.980 --> 00:03:20.870
And in addition it means that we can use the autocomplete in the collab notebook which you can't otherwise.

41
00:03:20.890 --> 00:03:28.320
So I'll see from I python and I'll hit tab on my keyboard and you might notice a slight delay until

42
00:03:28.320 --> 00:03:40.140
the suggestion pops up I'll hit enter their dot see tab on my keyboard core dot D tab on my keyboard

43
00:03:40.500 --> 00:03:45.960
display import display.

44
00:03:45.960 --> 00:03:47.230
There we go.

45
00:03:47.230 --> 00:03:51.570
Now let me hit shift enter here and the cell will run.

46
00:03:51.840 --> 00:03:56.160
And down here you'll get a message using tense of low back end.

47
00:03:56.160 --> 00:04:01.920
This is a message from carers because carers can be bolted on to a number of other technologies as well

48
00:04:02.340 --> 00:04:03.760
doesn't have to be tens of flow.

49
00:04:04.080 --> 00:04:08.640
But here is just confirming it's kind of using tensor flow as a back end.

50
00:04:08.640 --> 00:04:09.920
Great.

51
00:04:09.930 --> 00:04:16.380
Now what I'd like you to do is go to the course resources page and download our sample images that we're

52
00:04:16.380 --> 00:04:18.250
gonna be using for this project.

53
00:04:18.510 --> 00:04:26.310
On that page under this modules resources you should find a zip file that you can download and this

54
00:04:26.310 --> 00:04:29.110
file will contain our sample images.

55
00:04:29.340 --> 00:04:37.770
And once I unzip this file and open the folder I can see that I've got eleven images here I've actually

56
00:04:37.770 --> 00:04:41.420
pulled these images from on Splash dot com.

57
00:04:41.490 --> 00:04:48.510
This is a fantastic resource for high resolution photos from professional photographers but what I've

58
00:04:48.510 --> 00:04:54.530
done is I've downloaded these images and I've resized them I've made him a lot smaller.

59
00:04:54.630 --> 00:05:00.450
This will help us when it comes to feeding data to our neural nets and how after you've unzipped this

60
00:05:00.450 --> 00:05:08.310
file click on this little arrow here and upload the files that you funds it upload these jpeg images

61
00:05:09.420 --> 00:05:16.760
click on upload and then in your Downloads folder open the folder that you've unzipped.

62
00:05:16.830 --> 00:05:24.450
Select the images therein and click upload will instantly get a reminder from Google telling us that

63
00:05:24.450 --> 00:05:28.880
these files will only exist while we're working with this notebook.

64
00:05:28.980 --> 00:05:31.730
They won't actually stay there permanently.

65
00:05:31.860 --> 00:05:38.040
The way they phrase this is files will get deleted when this runtime is recycled.

66
00:05:38.040 --> 00:05:45.270
What this means is that eventually this runtime that we've got will be shut down and the computing resource

67
00:05:45.420 --> 00:05:48.890
on Google servers will be given to someone else.

68
00:05:48.960 --> 00:05:52.490
So that's just one of the trade offs of using a free resource.

69
00:05:52.500 --> 00:05:59.260
There's some limitations in place but after your files have been uploaded they should all come up here.

70
00:05:59.460 --> 00:06:00.860
Next I want to take this cell.

71
00:06:01.190 --> 00:06:10.380
I'll move it down here to be a bit more organized and I'll add another markdown cell that reads constants

72
00:06:11.430 --> 00:06:21.490
and there I will add a few file names so I'll see file underscore one is equal to single quotes 0 1

73
00:06:22.490 --> 00:06:31.080
reload and JPEG and then I'll see a file on the score two is equal to single quotes.

74
00:06:31.220 --> 00:06:38.220
02 coupled up JPEG I'm just picking out a couple of the file names that I can use then later on in my

75
00:06:38.220 --> 00:06:49.550
code file underscore three is equal to single quotes zero three ocean dot J Peg shift into.

76
00:06:49.560 --> 00:06:50.970
There we go.

77
00:06:51.010 --> 00:07:00.840
Now we can add another markdown cell and we'll call this one pre processing images.

78
00:07:00.840 --> 00:07:07.530
This is where we're gonna write our code that will take these images and format the data in such a way

79
00:07:07.860 --> 00:07:11.340
that we can feed it into our neural networks.

80
00:07:11.520 --> 00:07:16.590
And I do say neural networks because we're going to be trying out more than one of them in this module

81
00:07:18.420 --> 00:07:24.090
so how we're going to process our data how we're gonna process these images for the code that will follow.

82
00:07:24.870 --> 00:07:31.260
Well the thing with working with images is that we need to convert these images to an array of numbers.

83
00:07:31.260 --> 00:07:32.340
Why.

84
00:07:32.340 --> 00:07:37.260
Well our neural network will need to work with columns and rows of values.

85
00:07:37.380 --> 00:07:37.690
Right.

86
00:07:38.320 --> 00:07:42.840
But what kind of values make up an image.

87
00:07:42.840 --> 00:07:49.620
We can actually express every single pixel in an image as a number or a set of numbers with a color

88
00:07:49.620 --> 00:07:50.630
image like this.

89
00:07:50.670 --> 00:07:53.730
We'll need three numbers to describe a pixel.

90
00:07:54.000 --> 00:08:00.300
And that's because we can express every single color in terms of the amount of red the amount of green

91
00:08:00.990 --> 00:08:03.120
and the amount of blue.

92
00:08:03.120 --> 00:08:06.220
This is the very famous RG B format.

93
00:08:06.540 --> 00:08:07.620
You can actually see this.

94
00:08:07.680 --> 00:08:14.430
When I bring up my color selector in my keynote program so if I click on this thing there not only do

95
00:08:14.430 --> 00:08:20.280
I have like a little color wheel but I've also got this option of using these RG B sliders to select

96
00:08:20.280 --> 00:08:20.720
a color.

97
00:08:21.570 --> 00:08:24.340
And what you see here is that there are three sliders.

98
00:08:24.390 --> 00:08:26.590
This one governs the amount of red.

99
00:08:27.060 --> 00:08:30.720
So this is a number between zero and two hundred and fifty five.

100
00:08:31.350 --> 00:08:33.900
So 2055 has lots of red.

101
00:08:33.990 --> 00:08:36.480
Zero is very little red.

102
00:08:36.480 --> 00:08:40.520
I've got a slider for the amount of blue and I've got the slider for the amount of green.

103
00:08:40.680 --> 00:08:46.620
And as I play around with these sliders I get different colors because every single color out there

104
00:08:46.810 --> 00:08:50.830
is actually just a mix between red green and blue.

105
00:08:50.850 --> 00:08:55.800
Now if I had a black and white image instead then I actually wouldn't need three sliders.

106
00:08:55.800 --> 00:09:00.620
I wouldn't need three different values to express the value of a pixel.

107
00:09:00.780 --> 00:09:07.230
I would actually just use this grayscale slider and this would give me a value between zero and two

108
00:09:07.220 --> 00:09:11.860
hundred and fifty five and accomplish exactly the same thing.

109
00:09:11.880 --> 00:09:17.560
So once we know the values for each individual color we can turn our image into an array.

110
00:09:17.700 --> 00:09:22.680
But the question is what are the dimensions going to be of this array.

111
00:09:22.680 --> 00:09:31.030
Well it's gonna be the height and pixels times the width and pixels times the number of channels.

112
00:09:31.070 --> 00:09:33.450
So that's three dimensions really.

113
00:09:33.710 --> 00:09:36.300
What I mean by number of channels.

114
00:09:36.620 --> 00:09:41.900
Well for our G.B. we have three channels red green and blue.

115
00:09:41.900 --> 00:09:48.170
The array that you'd actually get after doing this conversion from a picture to a set of numbers will

116
00:09:48.260 --> 00:09:54.110
actually look something a bit like a set of spreadsheets each channel in this case will have its own

117
00:09:54.110 --> 00:09:55.130
spreadsheet.

118
00:09:55.130 --> 00:10:01.160
And if you stack all of these spreadsheets up then each individual pixel will correspond to the three

119
00:10:01.160 --> 00:10:09.320
values of these colors to the top left pixel will have the value 0 for red the value 1 2 7 for green

120
00:10:09.650 --> 00:10:15.620
and the value 0 for blue that's the information that we're gonna be piping over into our neural net

121
00:10:16.790 --> 00:10:18.730
back in our core lab notebook.

122
00:10:18.740 --> 00:10:26.030
Let's go to the very top and under our import statements let's import a few pre processing functions

123
00:10:26.180 --> 00:10:32.900
from Caris carries will not only help us work with neural networks cares will also help us pretty process

124
00:10:32.990 --> 00:10:36.900
some of our data I think this is very very handy.

125
00:10:36.960 --> 00:10:45.450
So let's write from Chris dot pre processing dot image import.

126
00:10:45.950 --> 00:10:54.440
I m g underscore to underscore array come and then load on a score.

127
00:10:54.690 --> 00:10:57.660
I m g load image.

128
00:10:57.660 --> 00:11:00.040
Let me hit shift and sure on this.

129
00:11:00.090 --> 00:11:05.040
This is a helper function that we can try out right here.

130
00:11:05.040 --> 00:11:11.020
And the way we're going to do this is we're going to pull up our first image in our collab notebook.

131
00:11:11.060 --> 00:11:11.940
Let's try it out.

132
00:11:11.940 --> 00:11:20.810
So I'll say pick is equal to load on a school image ethanol take file at a school one.

133
00:11:21.020 --> 00:11:26.460
One thing you'll find notice is that in contrast to running all the stuff locally on your machine there's

134
00:11:26.460 --> 00:11:28.130
that slight delay.

135
00:11:28.170 --> 00:11:33.720
When you hit tab on your keyboard to use autocomplete it drives me absolutely crazy.

136
00:11:33.720 --> 00:11:40.810
And this is why I really really prefer working locally rather than with the Google collab notebook.

137
00:11:41.190 --> 00:11:46.350
But the big advantage working with the core lab notebook is that we don't have to do any setup right.

138
00:11:46.350 --> 00:11:52.480
We can jump straight in into Charisse and tensor flow without having to do any installation.

139
00:11:52.710 --> 00:11:54.120
So it's a give and take.

140
00:11:54.120 --> 00:11:56.200
You win some you lose some.

141
00:11:56.430 --> 00:11:59.630
So now that I've loaded my image I can actually display it right.

142
00:11:59.640 --> 00:12:08.670
Using the I Python display so I'll say display parentheses pick and headings shift enter and I'll actually

143
00:12:08.670 --> 00:12:15.430
show the image right here as an output under my cell.

144
00:12:15.510 --> 00:12:20.790
So this is the image for us humans but our neural network will want that array of numbers.

145
00:12:20.790 --> 00:12:30.120
So how do we get that pick on a score array shall be equal to the output of the image.

146
00:12:30.240 --> 00:12:34.670
Underscore to underscore array function from Caris.

147
00:12:34.860 --> 00:12:38.390
Here we can feed in the picture that we loaded earlier.

148
00:12:39.390 --> 00:12:40.520
And then we can see.

149
00:12:40.560 --> 00:12:48.630
Pick the score array don't shape to take a look at what the output for this function actually is.

150
00:12:48.630 --> 00:12:55.950
It's indeed an array and you can see that I've downscaled these images from unsurpassed quite dramatically.

151
00:12:55.950 --> 00:13:01.680
This one here is 2 5 6 by 2 5 6 and it's got 3 channels.

152
00:13:01.710 --> 00:13:05.110
This is how to interpret this information.

153
00:13:05.640 --> 00:13:13.850
So with very few lines of code we've just loaded our images and we've converted them into an array in

154
00:13:13.850 --> 00:13:14.710
the next lesson.

155
00:13:14.780 --> 00:13:20.640
We're going to start looking at our neural network models that are available in Caris.

156
00:13:20.900 --> 00:13:22.040
I'll see you there.

157
00:13:22.070 --> 00:13:22.570
Take her.
