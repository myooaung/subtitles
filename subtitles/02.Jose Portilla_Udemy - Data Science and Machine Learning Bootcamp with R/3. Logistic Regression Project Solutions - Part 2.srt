1

00:00:00,990  -->  00:00:07,170
Hello everyone and welcome to the logistic regression project solutions part to lecture in part one

2

00:00:07,170  -->  00:00:12,360
the previous lecture we went ahead and got the data and then we also transformed feature variables with

3

00:00:12,690  -->  00:00:18,210
a lot of factor levels and we reduced the number of levels in those factor variables.

4

00:00:18,210  -->  00:00:24,530
Let's go ahead now and explore the missing data using the Amelia package do worked with previously and

5

00:00:24,540  -->  00:00:26,870
to jump to our studio to get started.

6

00:00:26,910  -->  00:00:31,220
OK here we are our studio and I'm going to go ahead and clear the console.

7

00:00:31,320  -->  00:00:33,750
Here we have our script with all the transformations.

8

00:00:33,750  -->  00:00:41,190
Let's go ahead and clear this structure print statement out and start a new section or code.

9

00:00:41,190  -->  00:00:46,590
We'll go ahead and call it missing data.

10

00:00:49,100  -->  00:00:53,900
OK first thing going to do is call the Amulya package.

11

00:00:54,240  -->  00:00:57,610
Go ahead and install the Amulya package if you haven't done so already.

12

00:00:57,840  -->  00:01:01,350
That's basically a package that allows us to create missing maps.

13

00:01:01,350  -->  00:01:07,070
The next step you had to do was convert any cell with a question mark to an end a value.

14

00:01:07,080  -->  00:01:13,050
There's lots of ways to do this but one of the simplest ways is just to do this transformation by saying

15

00:01:14,250  -->  00:01:22,140
adults and you'll say it we're adult is equal to the character question mark.

16

00:01:22,140  -->  00:01:25,180
Go ahead and transform that to an end a value.

17

00:01:25,290  -->  00:01:27,860
That's the easiest way to do this.

18

00:01:27,870  -->  00:01:33,020
You can also do like an is and a check or apply that to a data frame.

19

00:01:33,030  -->  00:01:34,880
But this is probably the easiest way to do that.

20

00:01:34,920  -->  00:01:39,840
That's just going to cover all the question mark or that character question marks in the data set to

21

00:01:39,960  -->  00:01:40,510
any value.

22

00:01:40,510  -->  00:01:45,270
So we actually get missing data instead of just a question mark character.

23

00:01:45,270  -->  00:01:52,160
Then what we're going to do is use table on a column and a values should now display not those any values

24

00:01:52,200  -->  00:01:55,500
but just see a zero for question mark levels.

25

00:01:55,620  -->  00:01:57,210
Let me go ahead and show you what I mean by that.

26

00:01:57,240  -->  00:02:03,170
I'm going to say print's the table let's go and explore type employer.

27

00:02:03,270  -->  00:02:08,970
If you remember from part one when we explore a type employer we went ahead and grouped the type of

28

00:02:08,970  -->  00:02:11,330
employment's to self-employed.

29

00:02:11,490  -->  00:02:15,530
Federal government state and local government and then private and unemployed.

30

00:02:15,630  -->  00:02:23,730
And I will say that question mark call him let's go and explore this by running this after running this

31

00:02:23,730  -->  00:02:25,050
line.

32

00:02:25,230  -->  00:02:30,710
I have a few other print statements that are running Here's our table print statement.

33

00:02:30,720  -->  00:02:37,620
Notice that now I have a question mark as to zero which means what we want to do is actually refactor

34

00:02:37,740  -->  00:02:41,470
or apply that factor to all those columns again.

35

00:02:41,730  -->  00:02:46,830
I'm going to go ahead and grab this factor code.

36

00:02:48,150  -->  00:02:56,490
Let's go ahead and grab the label as well and do it after we do this transformation going to go ahead

37

00:02:56,490  -->  00:02:57,780
and paste it here.

38

00:02:57,990  -->  00:03:01,510
That way we don't have these questionmark levels anymore.

39

00:03:02,130  -->  00:03:06,220
OK something else that is going to delete this print statement.

40

00:03:08,130  -->  00:03:11,200
And like I mentioned earlier you can actually just supply factor.

41

00:03:11,280  -->  00:03:18,420
You say the factor of this column instead of saying a supply but that's totally up to you than what

42

00:03:18,420  -->  00:03:20,660
we're going to do is go ahead and just to make sure it works.

43

00:03:20,730  -->  00:03:22,460
Check table of adults.

44

00:03:22,710  -->  00:03:24,810
We'll go ahead and say type employer.

45

00:03:25,410  -->  00:03:27,120
Run this code.

46

00:03:28,560  -->  00:03:29,460
And there you have it.

47

00:03:29,460  -->  00:03:35,190
We no longer have this questionmark level notice that any values just won't show up.

48

00:03:35,190  -->  00:03:36,040
Perfect.

49

00:03:36,090  -->  00:03:36,870
That's our table.

50

00:03:36,870  -->  00:03:42,030
We want to do now is play around with the mismatched function from the Amelia package.

51

00:03:42,030  -->  00:03:45,600
Hopefully you can kind of play with it and start to figure it out.

52

00:03:45,630  -->  00:03:52,620
If you just say mismatched adults after calling the Amulya package what you want to do is expand your

53

00:03:52,620  -->  00:03:58,230
plot's window called mismeasure adults and you'll notice you'll get a missing map or a missing this

54

00:03:58,230  -->  00:04:00,010
map but it looks kind of ugly.

55

00:04:00,120  -->  00:04:05,130
It will show you lines the missing values and the observed values but then you also have a bunch of

56

00:04:05,130  -->  00:04:08,530
crap there for the labels.

57

00:04:08,910  -->  00:04:13,260
What you want to do is note that this is basically a heat map pointing out missing values and it gives

58

00:04:13,260  -->  00:04:15,360
you a quick glance at how much data is missing.

59

00:04:15,360  -->  00:04:16,820
In this case it's not a whole lot.

60

00:04:16,830  -->  00:04:21,720
Relatively speaking you probably also notice that there's a bunch of white labels and you can get rid

61

00:04:21,720  -->  00:04:23,490
of them through the following command.

62

00:04:23,530  -->  00:04:25,470
And this one is actually in the notebook.

63

00:04:25,890  -->  00:04:28,580
And we go out and copy and paste it.

64

00:04:30,360  -->  00:04:38,190
If you run this code instead where you say Why Dot labels is equal to a vector of a single empty string

65

00:04:38,200  -->  00:04:38,460
.

66

00:04:38,850  -->  00:04:46,740
And you also say why x is equal to this vector of 1 and you can set the colors for a missing versus

67

00:04:46,740  -->  00:04:47,700
observe.

68

00:04:47,700  -->  00:04:54,200
This will actually produce a cleaner looking Messina's map perfect this is a lot cleaner.

69

00:04:54,220  -->  00:05:00,190
It won't actually show the white label data points of who is missing data from those actual index values

70

00:05:00,210  -->  00:05:00,420
.

71

00:05:00,610  -->  00:05:05,550
It's a lot easier to interpret than the kind of previous uglier plot.

72

00:05:06,160  -->  00:05:06,770
OK.

73

00:05:06,910  -->  00:05:09,150
Hopefully you're able to create that plot.

74

00:05:09,190  -->  00:05:13,740
Now we want to do is think about how we can deal with this missing data.

75

00:05:13,780  -->  00:05:19,130
We could just pass an average values we did something like that for the Titanic dataset.

76

00:05:19,180  -->  00:05:26,400
However no occupation and type employer both of them are not numeric values so we can't just say OK

77

00:05:26,560  -->  00:05:32,780
impute the average employer type or we're going to go ahead and do is it's not so much of our data.

78

00:05:32,980  -->  00:05:34,770
We're just going to drop it.

79

00:05:34,930  -->  00:05:41,680
And the way you can drop it is by using an 8. omits.

80

00:05:42,050  -->  00:05:46,860
Now let's go ahead and start a new section called Drop missing data

81

00:05:49,480  -->  00:06:01,120
and the command that just any omits adults or Belisa adults to get rid of its missing data going to

82

00:06:01,120  -->  00:06:02,260
go out and run this

83

00:06:05,670  -->  00:06:10,750
nation is quickly note that this line depending on how fast your computer is it may take a little longer

84

00:06:10,750  -->  00:06:12,730
to actually compute.

85

00:06:12,730  -->  00:06:13,630
Looks like it's done.

86

00:06:13,630  -->  00:06:18,520
Let's go ahead and copy this line and redo our missing this map.

87

00:06:18,520  -->  00:06:24,320
Hopefully now we won't see any actual yellow lines here.

88

00:06:24,370  -->  00:06:24,730
Perfect.

89

00:06:24,730  -->  00:06:29,900
That means we observe every value and we have no missing values and everything is black.

90

00:06:29,980  -->  00:06:31,210
Looks like that works.

91

00:06:31,360  -->  00:06:34,150
Now that we've cleaned the data dropped any any values.

92

00:06:34,150  -->  00:06:38,680
We are ready to actually explore this data through visualization.

93

00:06:38,680  -->  00:06:45,970
Let's go ahead and call G-G plot to called the plier library and mess around with the data actually

94

00:06:45,970  -->  00:06:48,570
plotted out and visualize it.

95

00:06:48,590  -->  00:06:52,630
I'm going to go ahead and call library cheesy plot too.

96

00:06:53,320  -->  00:06:55,950
And I'm also going to call the deployer library just in case.

97

00:06:56,020  -->  00:06:58,850
I haven't actually imported it yet.

98

00:06:59,170  -->  00:07:05,110
Going to clear the plots is missing the maps and get started.

99

00:07:05,110  -->  00:07:08,970
Let me push this over a little bit so you get a nice balance here.

100

00:07:09,010  -->  00:07:15,220
First thing we want you to do is create a histogram of ages colored by income and we're under the FDA

101

00:07:15,250  -->  00:07:20,800
section of the project now the exploratory data analysis.

102

00:07:20,800  -->  00:07:25,490
I'm going to pass in my adult data frame that's already been cleaned and had the missing data or Moogs

103

00:07:25,500  -->  00:07:26,360
.

104

00:07:27,130  -->  00:07:33,200
I'm going to put in the aesthetic of age and that's my XT histogram and then I'm going to say geometer

105

00:07:33,200  -->  00:07:44,500
score histogram and I want the fill color to be by the income and also what I'm going to do is say color

106

00:07:44,950  -->  00:07:46,400
is equal to black.

107

00:07:46,420  -->  00:07:47,680
This is my personal preference.

108

00:07:47,680  -->  00:07:49,960
I like having that borderline of black.

109

00:07:50,020  -->  00:07:52,080
You don't have to do it if you don't want to.

110

00:07:52,540  -->  00:07:56,600
And then I'm also going to say been with is equal to one.

111

00:07:57,280  -->  00:08:05,260
And finally I'm going to add my favorite thing which is just a simple theme underscore B.W. and there

112

00:08:05,260  -->  00:08:06,990
we have let's go and zoom in.

113

00:08:07,300  -->  00:08:07,540
OK.

114

00:08:07,540  -->  00:08:11,500
So here's a histogram of the ages colored by income.

115

00:08:11,530  -->  00:08:17,190
You'll notice that basically if you're younger than 25 remember this state is from like around 1996

116

00:08:17,200  -->  00:08:17,240
.

117

00:08:17,260  -->  00:08:20,620
But according to this data set they were younger than 25.

118

00:08:20,800  -->  00:08:25,770
There's very few people that are making more than 50 K when they're below 25 years of age.

119

00:08:25,840  -->  00:08:30,820
And as you get older the amount with people percentage wise for that particular age group that are making

120

00:08:30,820  -->  00:08:32,830
more than the 50 case starts to grow.

121

00:08:33,070  -->  00:08:38,590
But then after a certain age people start retiring they receive less income both just the actual data

122

00:08:38,590  -->  00:08:43,870
points begins to decrease but also the amount of people making 50 proportional to their age group begins

123

00:08:43,870  -->  00:08:45,790
to decrease.

124

00:08:45,790  -->  00:08:46,160
All right.

125

00:08:46,270  -->  00:08:51,730
Hopefully that's pretty useful information as far as from an exploratory data analysis framework.

126

00:08:51,730  -->  00:08:56,030
Let's go ahead and plot a histogram of the hours worked per week.

127

00:08:56,210  -->  00:09:04,160
Osages you adults will go ahead and say our underscore her underscore week.

128

00:09:04,320  -->  00:09:09,700
It was just H.R. underscore and then I'm going to say history.

129

00:09:10,660  -->  00:09:14,040
Let me go ahead and finally add that theme.

130

00:09:15,890  -->  00:09:17,140
Let's play that out.

131

00:09:17,380  -->  00:09:18,980
And here we go.

132

00:09:19,630  -->  00:09:19,960
All right.

133

00:09:19,960  -->  00:09:22,990
Since the United States 40 hours per week is the standard.

134

00:09:22,990  -->  00:09:29,140
We notice that there is such a high it counts of 40 hours per week as far as the occurrences go that

135

00:09:29,140  -->  00:09:35,530
you may want to consider creating a nother right feature by feature engineering saying something like

136

00:09:35,590  -->  00:09:39,360
less than 40 hours per week 40 hours per week or above 40 hours per week.

137

00:09:39,400  -->  00:09:44,730
Right now we'll go ahead and leave it as is and continue on through the project assignment.

138

00:09:44,800  -->  00:09:50,560
The next task you have to do is rename the country column to region column to better reflect the factor

139

00:09:50,620  -->  00:09:51,810
levels.

140

00:09:51,900  -->  00:09:56,410
Take a look at the head of the adult data frame right now.

141

00:09:56,530  -->  00:10:01,150
Those we still have a country column but the country column These aren't really countries North America

142

00:10:01,150  -->  00:10:03,640
is an a country and South America isn't a country.

143

00:10:03,640  -->  00:10:05,470
They're more actually regions.

144

00:10:05,470  -->  00:10:09,680
Let's go ahead and rename that country to regt. column.

145

00:10:09,700  -->  00:10:11,900
There's lots of ways to do this.

146

00:10:12,070  -->  00:10:18,720
I like to use the plier to do this sort of operation because as a really simple rename function and

147

00:10:18,720  -->  00:10:25,460
we go out and see adults and then I'm going to say rename and rename is really easy just pass in the

148

00:10:25,550  -->  00:10:26,930
data.

149

00:10:26,920  -->  00:10:33,000
So you say rename the adult data frame and then you Pessin your new column name equals and then the

150

00:10:33,000  -->  00:10:38,110
old column name and that's all you have to do.

151

00:10:38,270  -->  00:10:42,620
And I want to go ahead and just put a print statement here to make sure it works.

152

00:10:42,620  -->  00:10:45,540
So print head of adults.

153

00:10:45,750  -->  00:10:49,650
Once you've done that we're going to go ahead and create a bar plot of the region with the fill color

154

00:10:50,030  -->  00:10:52,920
line by income class.

155

00:10:52,930  -->  00:10:53,570
Okay perfect.

156

00:10:53,580  -->  00:10:58,950
If we take a look at this head we have region as the output versus previously we had country has the

157

00:10:58,950  -->  00:11:04,350
output on the go ahead and clear that print statement clear the consul and get working on this marplot

158

00:11:04,370  -->  00:11:05,020
.

159

00:11:05,150  -->  00:11:10,980
Again I want to create a bar plot of region with full color defined by income class.

160

00:11:11,720  -->  00:11:19,320
I'm going to go ahead and say G-G plot pass in my adult data frame and say the aesthetic is region and

161

00:11:19,320  -->  00:11:21,070
I want this to be a bar plot.

162

00:11:21,120  -->  00:11:24,180
We're actually going to be doing quite a few additional layers to this.

163

00:11:24,410  -->  00:11:32,580
So I want to go ahead and sign this to P.L. and then I'm going to say geometers score bar and static

164

00:11:34,080  -->  00:11:37,840
feel equal to income.

165

00:11:38,850  -->  00:11:40,890
Color is equal to black

166

00:11:43,450  -->  00:11:46,050
plus theme.

167

00:11:46,110  -->  00:11:48,130
Underscore B.-W.

168

00:11:49,200  -->  00:11:53,280
And if we just show what looks like for right now we'll get this result.

169

00:11:53,770  -->  00:11:55,600
We go ahead and zoom in on it.

170

00:11:55,620  -->  00:12:02,890
We get this nice output of the income levels for coloring and then the actual bar plots.

171

00:12:02,900  -->  00:12:09,320
Notice most of our data is actually from North America and North America seems to have quite the highest

172

00:12:09,330  -->  00:12:16,980
amount of people making over $50000 even if you look at it proportionally it's still a much higher percentage

173

00:12:16,980  -->  00:12:18,950
in North America than other countries.

174

00:12:19,010  -->  00:12:22,520
Maybe Asia's a little competitive there.

175

00:12:24,220  -->  00:12:24,620
OK.

176

00:12:24,620  -->  00:12:29,160
So that concludes our exploratory data analysis in our data cleaning.

177

00:12:29,390  -->  00:12:34,120
Let's go ahead and just briefly get an overview of everything we've done in part 1 and Part 2.

178

00:12:34,330  -->  00:12:39,210
And in the final part 3 of this lecture series we're going to build a logistic regression model and

179

00:12:39,210  -->  00:12:42,700
split it into a training a test set for data etc..

180

00:12:42,750  -->  00:12:48,950
Let's just review quickly what we've done so far the things we've done so far is we read in our data

181

00:12:48,970  -->  00:12:49,280
.

182

00:12:49,470  -->  00:12:56,090
We called the player library to quickly unselect that extra index column and then we spent a lot of

183

00:12:56,100  -->  00:12:58,140
time cleaning our data.

184

00:12:58,470  -->  00:13:04,680
Here's a saying in data science where 80 to 90 percent of your time is going to be spent cleaning data

185

00:13:04,940  -->  00:13:09,600
and then 20 to 10 percent of time is going to be spent actually creating models.

186

00:13:09,600  -->  00:13:11,200
And that's definitely true in real life.

187

00:13:11,550  -->  00:13:14,190
So it's good to practice data cleaning in general.

188

00:13:14,180  -->  00:13:18,950
Here we practice data cleaning by combining features that had a lot of factor levels.

189

00:13:18,960  -->  00:13:23,900
We went ahead and did this for the job or any type of employer feature.

190

00:13:23,900  -->  00:13:26,920
We grouped them by self-employed state and local government.

191

00:13:27,090  -->  00:13:31,040
We also did this for the marital status not married never married married.

192

00:13:31,230  -->  00:13:34,510
And we just do this by creating a function and then applying a function.

193

00:13:34,510  -->  00:13:38,240
This is the easiest way to do it and it give you the most control.

194

00:13:38,250  -->  00:13:44,190
Then we went ahead and did the same for the country column data by splitting it up into regions and

195

00:13:44,180  -->  00:13:51,260
later on we went ahead and use the operator as a little trick with these vectors to do that.

196

00:13:51,260  -->  00:13:53,300
And again we just apply it.

197

00:13:53,750  -->  00:13:56,590
Then we took care of missing data by exploring it a little bit.

198

00:13:56,610  -->  00:14:01,520
We use the Amulya library a great library for working with and trying to visualize or missing data.

199

00:14:01,520  -->  00:14:06,040
We went ahead and put a question of Mark data to add a values.

200

00:14:06,330  -->  00:14:12,440
Then we used factor to apply a new factor level in order to make sure the old factory levels that it

201

00:14:12,440  -->  00:14:14,640
have that question mark inside of it.

202

00:14:14,630  -->  00:14:19,320
We checked out the missing data dropped all the missing data since it wasn't that much checking out

203

00:14:19,320  -->  00:14:20,630
the missing this maps.

204

00:14:20,730  -->  00:14:30,030
Then we explored our data through a few visualization plots such as bar plots histograms such as hours

205

00:14:30,020  -->  00:14:31,940
per week.

206

00:14:32,070  -->  00:14:37,670
Then we also did this age for counts are plot and you can check or a histogram excuse me and you could

207

00:14:37,660  -->  00:14:40,530
check out your own visualizations if you want to.

208

00:14:40,640  -->  00:14:45,900
Then the final thing we did was just rename the country column to the region column using the plyers

209

00:14:45,990  -->  00:14:48,690
rename function.

210

00:14:48,680  -->  00:14:51,740
Ok that's it for part 2 and part 3.

211

00:14:51,770  -->  00:14:56,640
We will end the fire exploratory data analysis and move on to building the logistic regression model

212

00:14:56,840  -->  00:15:01,950
to try to classify people into two groups above or below 50 k in salary.

213

00:15:01,940  -->  00:15:03,750
Thanks everyone and I'll see at the next lecture
