1

00:00:01,830  -->  00:00:08,550
Hello everyone else can support vector machines project solutions part 2 video lecture in part one of

2

00:00:08,550  -->  00:00:09,790
this lecture series.

3

00:00:09,810  -->  00:00:16,140
We went ahead and got the data turned the features that were categorical into categorical data features

4

00:00:16,140  -->  00:00:20,670
using the factor function and then we went ahead and explored the data of G-G plot 2.

5

00:00:20,880  -->  00:00:26,460
Let's go ahead and move on to part 2 where we actually train and build our model ship to our studio

6

00:00:26,460  -->  00:00:26,550
.

7

00:00:26,610  -->  00:00:27,570
To get started.

8

00:00:27,840  -->  00:00:30,160
OK here we are at our studio.

9

00:00:30,300  -->  00:00:37,290
Let's go ahead and see that we've read the CAC data and that actually converted the columns into categorical

10

00:00:37,290  -->  00:00:37,830
data.

11

00:00:37,830  -->  00:00:39,960
The ones that needed to be categorical.

12

00:00:39,960  -->  00:00:43,710
Now we can actually start building our support vector machine model.

13

00:00:43,710  -->  00:00:48,280
The first step in doing this is to split our data to training and testing sets.

14

00:00:48,330  -->  00:00:52,780
I'm going to go ahead and call the CAA tools library to do this.

15

00:00:52,890  -->  00:00:55,680
I will set the seed to 101.

16

00:00:55,680  -->  00:00:59,790
You don't have to do this but if you want your results to be just like mine you should go ahead and

17

00:00:59,790  -->  00:01:09,880
do that then we will create the sample split you passin a column of your data frame.

18

00:01:09,930  -->  00:01:13,410
I always like passing in the column or trying to predict.

19

00:01:13,800  -->  00:01:20,530
And then you pass in your split ratio which in this case is going to be 0.7.

20

00:01:20,670  -->  00:01:27,120
And then let's go ahead and make 70 percent of our data training data by taking the subset of loans

21

00:01:27,660  -->  00:01:34,880
or sample is equal to true.

22

00:01:35,670  -->  00:01:45,150
And then the tests will be the subset of loans where the sample is equal to false.

23

00:01:45,150  -->  00:01:52,110
That's our train test split then we're actually going to train the support vector machine.

24

00:01:52,110  -->  00:02:01,530
We do that by calling the e 1 0 7 1 library and then we just say model is going to be support vector

25

00:02:01,530  -->  00:02:03,710
machine we pass in the formula.

26

00:02:03,960  -->  00:02:11,340
We're trying to predict the not fully paid column based off of every other feature.

27

00:02:11,850  -->  00:02:16,050
And then we'll indicate that we want this data to be our training data.

28

00:02:16,110  -->  00:02:20,540
Then after that we'll go ahead and print a summary of the model.

29

00:02:20,730  -->  00:02:23,370
Let's go ahead and run this.

30

00:02:23,970  -->  00:02:24,770
Just a quick note.

31

00:02:24,780  -->  00:02:30,600
Depending on the how fast you computer how much RAM you have and your CPQ these support vector machines

32

00:02:30,600  -->  00:02:33,760
steps may take a while especially in the tuning phase.

33

00:02:33,780  -->  00:02:36,710
So just keep that in mind here.

34

00:02:36,720  -->  00:02:42,390
We've ran our model and it looks like we're using a cost of one and a gamma of zero point zero or 1

35

00:02:42,390  -->  00:02:43,280
7.

36

00:02:43,620  -->  00:02:49,960
Let's go ahead and see how well our model did by actually getting predicted values off of it.

37

00:02:50,040  -->  00:03:00,990
We're going to clear the cons. I'm going to say predicted values I will call my predict function I pass

38

00:03:00,990  -->  00:03:07,140
in my model and then I pass in my test data and I'm only going to pass in the test data that doesn't

39

00:03:07,140  -->  00:03:14,560
have a label and that's going to be the columns one through 13 of your test data.

40

00:03:15,480  -->  00:03:19,560
Then I just call a table on my predictive values

41

00:03:23,010  -->  00:03:28,370
comma and then the actual not fully paid column.

42

00:03:28,380  -->  00:03:30,650
The thing I was trying to predict.

43

00:03:30,720  -->  00:03:37,140
All right if you did your same sample split with set seed 101 you got a table that looks something like

44

00:03:37,140  -->  00:03:37,920
this.

45

00:03:38,340  -->  00:03:40,680
And that's actually just really bad results.

46

00:03:40,680  -->  00:03:47,010
Basically your model is predicting that everything was 0 for not fully paid meaning everyone fully paid

47

00:03:47,010  -->  00:03:48,220
off their loan.

48

00:03:48,660  -->  00:03:54,710
What we having an issue with here is that we're using the wrong cost and gamma parameter values.

49

00:03:54,720  -->  00:03:57,930
This is where tuning the model is going to come into play.

50

00:03:57,960  -->  00:04:04,230
We're going to need to use the tune function to test out different cost and gamma values in the previous

51

00:04:04,380  -->  00:04:10,530
lecture not part one but the lecture for SVM with our we went ahead and showed you how to tune the model

52

00:04:10,530  -->  00:04:10,820
.

53

00:04:10,830  -->  00:04:12,660
Let's go ahead and do that.

54

00:04:13,020  -->  00:04:13,400
All right.

55

00:04:13,400  -->  00:04:17,090
To begin tuning our model we're going to go ahead and use the tune function.

56

00:04:17,460  -->  00:04:24,630
I'm going to make a variable called tuned results called the tune function and I'll show you another

57

00:04:24,640  -->  00:04:31,260
way you can actually use the tune function in the previous lecture with our and how do you support vector

58

00:04:31,260  -->  00:04:32,020
machines.

59

00:04:32,040  -->  00:04:36,990
We saw that we could put in train the X put in the features and that person train that y and put in

60

00:04:36,990  -->  00:04:38,120
the labels.

61

00:04:38,130  -->  00:04:43,260
You can also put in train the X and just person a formula.

62

00:04:43,620  -->  00:04:50,550
That means I can say not fully paid cild dot and that's the formula for prediction and if you do that

63

00:04:50,580  -->  00:04:52,780
then you know after actually passing training.

64

00:04:52,790  -->  00:04:53,250
Why.

65

00:04:53,280  -->  00:04:56,730
Which is kind of nice use whatever method you prefer.

66

00:04:56,790  -->  00:05:02,130
I prefer the formula method since it's similar to how we actually train our models and the passenger

67

00:05:02,130  -->  00:05:03,510
training data.

68

00:05:03,510  -->  00:05:08,250
When we go in the case that I want the kernel to be the radio kernel

69

00:05:10,990  -->  00:05:17,680
it then I will go ahead and search for ranges and then ranges is going to take a list of vector values

70

00:05:17,680  -->  00:05:18,960
for the other parameters.

71

00:05:18,970  -->  00:05:23,830
In this case we're looking at cost and gamma says this can take such a long time.

72

00:05:23,830  -->  00:05:25,750
The pending on the speed of your computer.

73

00:05:25,900  -->  00:05:28,870
I'm going to go ahead and just test two different costs values.

74

00:05:28,870  -->  00:05:37,010
We'll go ahead and say 100 and 200 or something like that you can actually just put a good range.

75

00:05:37,120  -->  00:05:42,850
We'll go ahead and just test this against gamma values and in this case I'm actually just going to test

76

00:05:42,850  -->  00:05:45,290
against one game of values or point one.

77

00:05:45,810  -->  00:05:48,510
You can go ahead and put in as many values here as you want.

78

00:05:48,500  -->  00:05:53,470
Just keep in mind the more values you put in for this grid search of tuning the longer it will take

79

00:05:53,590  -->  00:05:55,860
especially if you have a slower computer.

80

00:05:56,230  -->  00:06:05,530
Then we will go ahead and print the summary of our tuned results.

81

00:06:05,530  -->  00:06:10,460
Let's go ahead and run this.

82

00:06:10,720  -->  00:06:19,460
I'm going to go ahead and jump to this tuned results and tune function grid search completing.

83

00:06:20,010  -->  00:06:20,380
All right.

84

00:06:20,380  -->  00:06:23,200
Looks like our tuning is done and went ahead and jumped.

85

00:06:23,200  -->  00:06:30,100
This took a like about five to 10 minutes on my computer and I have a pretty fast computer so keep that

86

00:06:30,100  -->  00:06:30,360
in mind.

87

00:06:30,370  -->  00:06:34,790
If you have a slower one and you put in more values here it would still take a while.

88

00:06:34,840  -->  00:06:39,450
Looks like our best performers were cost of 100 and a gamma of 0.1.

89

00:06:39,490  -->  00:06:42,390
We're still getting about a 20 percent error rate which isn't so great.

90

00:06:42,500  -->  00:06:46,400
Well let's go ahead and do a new tune into model with this cost.

91

00:06:46,420  -->  00:06:55,090
And this gamma value is going to go ahead and copy these results so I can reference them you know put

92

00:06:55,090  -->  00:06:57,140
them here in our script.

93

00:06:57,460  -->  00:07:06,280
Let's go ahead and clear the council now and go ahead and say tune's model SVM going to go ahead and

94

00:07:06,280  -->  00:07:07,590
pass in my formula.

95

00:07:08,010  -->  00:07:10,870
Not fully paid.

96

00:07:11,980  -->  00:07:14,220
Say that my data is equal to my training data.

97

00:07:14,410  -->  00:07:20,190
And then I'm going to set my costs equal to 100 and my gamma equal to zero point 1

98

00:07:23,200  -->  00:07:28,180
want to run that support vector machine and train it on my training data with those specific costs and

99

00:07:28,180  -->  00:07:29,670
gamma parameters.

100

00:07:29,710  -->  00:07:35,530
Once that's done you can go ahead and call a summary of our SVM and we can also start predicting new

101

00:07:35,520  -->  00:07:38,960
values with this tune into model.

102

00:07:39,700  -->  00:07:39,960
Right.

103

00:07:39,970  -->  00:07:44,900
So let's go ahead and actually try to predict new values using this model.

104

00:07:45,270  -->  00:07:54,530
We're going to go ahead and say tuned predictions is equal to predict where a person might tune's model

105

00:07:54,540  -->  00:07:57,330
.

106

00:07:59,110  -->  00:08:00,720
And then my test data.

107

00:08:00,750  -->  00:08:06,580
And in this case I just want the actual feature columns not the label column.

108

00:08:06,580  -->  00:08:13,180
And then once that's done I can call it table off my tune predictions versus the actual label which

109

00:08:13,180  -->  00:08:18,670
was not fully paid column.

110

00:08:18,670  -->  00:08:19,130
All right.

111

00:08:19,140  -->  00:08:25,230
And it looks like we are now no longer classifying everyone as the 0 for the not fully paid column.

112

00:08:25,260  -->  00:08:29,820
We're actually beginning to classify some of the ones correctly.

113

00:08:29,920  -->  00:08:35,610
This still isn't such a great model but you can go ahead and calculate accuracy recant precision for

114

00:08:35,710  -->  00:08:37,700
this model here that's been tuned.

115

00:08:37,870  -->  00:08:42,400
If you really want to start getting a much better model support vector machines you'd have to tune for

116

00:08:42,390  -->  00:08:45,750
a much larger array of cost and gamma combinations.

117

00:08:45,750  -->  00:08:51,040
However that comes at the cost of just waiting a long time to test those various combinations through

118

00:08:51,040  -->  00:08:52,800
your grid search.

119

00:08:52,810  -->  00:08:56,690
All right let's go ahead and quickly review everything we've done and the second part.

120

00:08:57,250  -->  00:09:02,040
We went ahead and did a train test split using C-8 tools.

121

00:09:02,160  -->  00:09:05,760
We just said sample that split on the not fully paid column.

122

00:09:05,950  -->  00:09:09,830
Took 70 percent of it said it as a training data 30 percent as our test data.

123

00:09:09,990  -->  00:09:12,720
We called the e 1 0 7 1 library.

124

00:09:12,730  -->  00:09:19,420
We went ahead and we first just trained the model without specifying the gamma and cause we just use

125

00:09:19,410  -->  00:09:20,110
the default.

126

00:09:20,130  -->  00:09:23,400
And when we reprinted that original summary of our model it was quite bad.

127

00:09:23,590  -->  00:09:27,810
We were basically labeling everything in the not fully paid column as zero.

128

00:09:28,120  -->  00:09:36,390
Then we used to we are a grid search to actually search and combine various values for cost and gamma

129

00:09:36,390  -->  00:09:36,780
.

130

00:09:36,790  -->  00:09:41,590
Once we did that we took the summary of the tuned results and reported back that out of the various

131

00:09:41,590  -->  00:09:42,630
combinations we tried.

132

00:09:42,630  -->  00:09:49,410
We basically tried to combos one hundred and 0.1 200 and 0.1 that the cost of one hundred and Gamme

133

00:09:49,400  -->  00:09:51,940
of 0.1 were the best out of those two.

134

00:09:51,930  -->  00:09:57,240
And then they went ahead and created a new model with those specific parameters that can take a while

135

00:09:57,250  -->  00:10:01,330
depending on how many costs and gamma values you put in.

136

00:10:01,380  -->  00:10:06,720
This is usually something you want to try to sync with going out to lunch or taking a coffee break though

137

00:10:06,790  -->  00:10:11,310
where you set your tuning and grid search ready to go and you go out have lunch and come back an hour

138

00:10:11,320  -->  00:10:13,340
later and the results are done for you.

139

00:10:13,810  -->  00:10:14,390
All right.

140

00:10:14,620  -->  00:10:16,210
I hope you enjoyed that project.

141

00:10:16,210  -->  00:10:17,320
I will see it next lecture
