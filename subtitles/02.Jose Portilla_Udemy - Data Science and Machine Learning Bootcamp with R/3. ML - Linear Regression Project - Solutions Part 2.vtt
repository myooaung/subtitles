WEBVTT
1

00:00:00.780  -->  00:00:06.090
Hello everyone and welcome to the second part of the solution lecture for the linear regression project

2

00:00:06.090  -->  00:00:06.390
.

3

00:00:06.480  -->  00:00:11.540
In part one we got went ahead and got the data explored the data a lot through G-G plot too.

4

00:00:11.760  -->  00:00:16.200
And then we actually went ahead and featured engineered a our data column.

5

00:00:16.230  -->  00:00:21.600
Let's go ahead and start building a linear regression model using L.M. in our studio.

6

00:00:21.600  -->  00:00:23.360
Let's shift our studio and get started.

7

00:00:23.700  -->  00:00:24.020
OK.

8

00:00:24.030  -->  00:00:25.600
Here we are back in our studio.

9

00:00:25.610  -->  00:00:28.490
The very last plot we did that we did talk about a whole lot.

10

00:00:28.490  -->  00:00:31.080
But just briefly went over was this weekend plot.

11

00:00:31.260  -->  00:00:35.310
You should have noticed that the working days have picquet activity during the morning or on Adium and

12

00:00:35.310  -->  00:00:41.430
then right after work at around 5 p.m. and the not not work days where were they working day is equal

13

00:00:41.430  -->  00:00:42.390
to zero.

14

00:00:42.390  -->  00:00:46.660
We have a steady rise and fall for the afternoon which just intuitively makes sense.

15

00:00:46.770  -->  00:00:52.570
Let's go ahead and not worry about these visualizations anymore and start building our model.

16

00:00:52.680  -->  00:00:59.310
We're going to use L-M function to build a model that linear model to try to predict count based solely

17

00:00:59.370  -->  00:01:03.870
on the temperature feature we'll name it temp model.

18

00:01:03.870  -->  00:01:05.520
So as I said in same

19

00:01:08.010  -->  00:01:16.530
builds model and I'm going to start off by saying Tim got model

20

00:01:20.930  -->  00:01:27.810
L.M. and I'm going to try to predict count based off of the temp feature and I own a pass in my bike

21

00:01:28.050  -->  00:01:35.010
data you may be wondering why aren't we splitting the data into a training set and a testing set like

22

00:01:35.010  -->  00:01:37.130
you mentioned in the previous lecture.

23

00:01:37.170  -->  00:01:43.050
The reason for that is because eventually we'll see that because this data has a seasonality to it and

24

00:01:43.050  -->  00:01:48.730
a growing trend a linear regression model isn't actually going to be very helpful here.

25

00:01:48.840  -->  00:01:57.090
And also because it's a time series version of data it doesn't help to randomly select sections of the

26

00:01:57.090  -->  00:02:01.350
data is missing test points and try to predict those missing test points.

27

00:02:01.360  -->  00:02:03.540
We're going to show you what I mean by that.

28

00:02:03.600  -->  00:02:09.930
Imagine that this was our testing data if we're to randomly select points as missing we would grab them

29

00:02:09.930  -->  00:02:14.860
at all random hours of the day and to show you a better example of this.

30

00:02:14.970  -->  00:02:21.510
Let's go back to one of our previous plots where we plotted out all the data based off of that time

31

00:02:23.370  -->  00:02:29.040
which was this one right here for go to zoom in on this since this is time series data.

32

00:02:29.040  -->  00:02:33.360
What we are eventually going to learn is that the linear regression model isn't going to be super use

33

00:02:33.360  -->  00:02:40.230
for this because it has a growing trend and has a seasonality aspect to it and split it up into a training

34

00:02:40.230  -->  00:02:41.640
set and a testing set.

35

00:02:41.670  -->  00:02:46.830
Would it be very helpful because you'll be predicting at points squeezed in between two time points

36

00:02:47.120  -->  00:02:52.330
that you already have training data for which you would really want to do is try to predict future trends

37

00:02:52.710  -->  00:02:57.340
and that doesn't really work well for what we know about linear regression so far.

38

00:02:57.510  -->  00:03:02.400
Later on we'll learn about various other methods that we can use for time series data.

39

00:03:02.400  -->  00:03:03.830
They'll perform a lot better.

40

00:03:04.050  -->  00:03:08.430
For now go ahead and do is just train on everything.

41

00:03:08.430  -->  00:03:12.150
So we're go in and say build the model counts on temp.

42

00:03:12.240  -->  00:03:17.610
So try to count based off of the temperature off of the bike and that's the reason we're not splitting

43

00:03:17.610  -->  00:03:25.380
right now for a training and test and then we're going to go ahead and do is print the summary of the

44

00:03:25.380  -->  00:03:26.860
temp model.

45

00:03:27.220  -->  00:03:29.870
Let's go ahead and run that.

46

00:03:31.590  -->  00:03:33.150
OK we got our summary out.

47

00:03:33.330  -->  00:03:37.400
Let's expand this window a bit to check it out.

48

00:03:37.470  -->  00:03:40.450
Notice we get some residuals here and some coefficients.

49

00:03:40.470  -->  00:03:48.210
What you should have gotten is somewhere around 6 point 0 4 6 2 as the intercept and nine point 7 as

50

00:03:48.210  -->  00:03:52.870
the temperature coefficient and you should have gotten those results because we're not randomly splitting

51

00:03:52.870  -->  00:03:55.480
or anything you're using all the data I'm using.

52

00:03:55.740  -->  00:03:57.530
How can we actually interpret these values.

53

00:03:57.540  -->  00:04:02.750
Well you can do some Wikipedia research reread Eissler or revisit the linear regression electron notebook

54

00:04:02.770  -->  00:04:05.150
for more on how to actually do this interpretation.

55

00:04:05.430  -->  00:04:12.780
But as far as interpreting the intercept that data not just of y value when x is equal to zero thus

56

00:04:12.870  -->  00:04:19.110
it is the estimated number of rentals when the temperature is zero degrees Celsius when the temperatures

57

00:04:19.170  -->  00:04:19.980
zero degrees.

58

00:04:19.980  -->  00:04:25.000
We estimate only 6 count rentals at that temperature.

59

00:04:25.020  -->  00:04:29.340
However we should know it doesn't always make sense to just interpret the intercepts by itself in the

60

00:04:29.340  -->  00:04:31.270
manner just described.

61

00:04:31.290  -->  00:04:35.390
However what makes a little more sense is interpret seeing the temp coefficient.

62

00:04:35.440  -->  00:04:38.170
Beta 1 which is the number eight here.

63

00:04:38.160  -->  00:04:39.470
Nine point one seven.

64

00:04:39.600  -->  00:04:44.340
And that's basically saying it's the change in y divided by the change in x or the slope.

65

00:04:44.490  -->  00:04:51.060
Thus a temperature increase of 1 degree Celsius holding all things equal is associated with a rental

66

00:04:51.090  -->  00:04:56.160
increase in about 9.1 seven bikes as far as our model goes.

67

00:04:56.160  -->  00:05:01.950
However I should note this is not a statement of causation and Beta 1 would be negative if an increase

68

00:05:01.950  -->  00:05:05.670
in temperature was associated with a decrease in rentals.

69

00:05:05.740  -->  00:05:11.250
We want to know now is how many bike rentals would we predict if the temperature was 25 degrees Celsius

70

00:05:11.250  -->  00:05:11.730
.

71

00:05:11.730  -->  00:05:16.980
And we can calculate this in two ways using the values we just got above or using the predictive function

72

00:05:16.980  -->  00:05:17.520
.

73

00:05:17.520  -->  00:05:21.610
Let me show you how to do this manually with the values above.

74

00:05:21.660  -->  00:05:27.330
Again the question is how many bike rental counts

75

00:05:31.080  -->  00:05:45.290
at 25 degrees C Celsius what we can do is go ahead and say our base intercept six 0.4 six to plus nine

76

00:05:45.290  -->  00:05:54.060
point one seven times the temperature 25 degrees and so we would expect at 25 degrees Celsius somewhere

77

00:05:54.060  -->  00:05:57.590
around the range of 235 bike rental counts.

78

00:05:57.720  -->  00:06:04.260
Given our model that was only trained on temperature the other way to do this would be using the predicts

79

00:06:04.310  -->  00:06:05.180
method.

80

00:06:05.340  -->  00:06:09.330
So I could say something like this I'll say temp test

81

00:06:12.660  -->  00:06:17.770
and set that equal to a data frame.

82

00:06:19.210  -->  00:06:24.180
We'll go in and say temp as just a single value 25 degrees.

83

00:06:24.690  -->  00:06:32.390
So notice if I call temp test loops all it is just a simple data frame one temperature point twenty

84

00:06:32.400  -->  00:06:38.790
five and then I could actually as predict pass in my model the temp model

85

00:06:41.750  -->  00:06:47.610
and then pasand the temp test and it gives you a very similar result.

86

00:06:47.610  -->  00:06:52.650
Two hundred thirty five point three 0 9 7.

87

00:06:52.650  -->  00:06:59.010
Let's go ahead and move along to the final tasks we had to do which was use as apply and as numeric

88

00:06:59.000  -->  00:07:03.450
to change the hour column to a column of numeric values.

89

00:07:03.460  -->  00:07:04.520
Let's go ahead and do that.

90

00:07:04.560  -->  00:07:10.580
We'll say like our air supply

91

00:07:13.010  -->  00:07:16.000
bike hour and then we'll say as gnumeric.

92

00:07:16.130  -->  00:07:18.390
And that just changes that tune as numeric.

93

00:07:18.480  -->  00:07:21.300
I'm going to go ahead and actually put this into my scripts

94

00:07:24.930  -->  00:07:26.190
and this will go under.

95

00:07:26.190  -->  00:07:29.760
Feature engineering as well.

96

00:07:29.750  -->  00:07:30.260
All right.

97

00:07:30.420  -->  00:07:35.520
So we have our bike our fully ready to go and we're going to do is finally build a model that attempts

98

00:07:35.510  -->  00:07:43.260
to predict count based off of the following features season holiday working day weather temp humidity

99

00:07:43.250  -->  00:07:53.520
wind speed and the factor of the hour in order to do this you could either add up all the features or

100

00:07:53.510  -->  00:07:57.410
you can just subtract the ones you don't want from everything else.

101

00:07:57.420  -->  00:08:03.860
Let me show you an example of what I mean we could have either said predict counts from let me go in

102

00:08:03.860  -->  00:08:05.140
and label this just model.

103

00:08:05.130  -->  00:08:15.540
This is not the temperature modeling more but we could have said season plus holiday plus whoops Plus

104

00:08:15.540  -->  00:08:23.730
the holiday Collomb Plus the working day Collomb etc. etc. all the way in so we would have had to fill

105

00:08:23.730  -->  00:08:25.230
in all the columns that we wanted.

106

00:08:25.230  -->  00:08:31.200
Or the faster way to do this is you can say dot for everything and then subtract the columns you don't

107

00:08:31.200  -->  00:08:32.650
want to use this case.

108

00:08:32.660  -->  00:08:36.270
I don't want to use casuals so mindless casual minus.

109

00:08:36.260  -->  00:08:44.070
Registered minus date time minus 8 temp.

110

00:08:45.030  -->  00:08:49.470
Let's go ahead and make sure that works by calling for a summary of the model.

111

00:08:49.670  -->  00:08:53.180
And there we have our model of the summary based off of those values.

112

00:08:53.420  -->  00:08:58.810
Hopefully you're able to figure this out if not the notes had the answer in them.

113

00:08:58.860  -->  00:09:00.930
You can always check those out as well.

114

00:09:00.970  -->  00:09:01.910
We push this up

115

00:09:04.740  -->  00:09:07.440
and check out the summary of our model.

116

00:09:07.440  -->  00:09:11.080
QUESTION Was did the model perform well on this training data.

117

00:09:11.100  -->  00:09:14.140
What do you think about using a linear model on this data.

118

00:09:14.700  -->  00:09:20.400
Well the answer is a linear model like this one we chose which uses less won't be able to take into

119

00:09:20.390  -->  00:09:26.430
account the seasonality of our data it will get thrown off by the growth in our dataset accidentally

120

00:09:26.420  -->  00:09:31.700
attributing it towards the winter season instead of realizing it's just overall demand growing.

121

00:09:31.910  -->  00:09:37.220
Later on we're going to explore other models that will be better fit for this sort of time series data

122

00:09:37.230  -->  00:09:38.580
.

123

00:09:38.580  -->  00:09:42.510
So you should notice that this sort of model doesn't work well given our seasonal and time series data

124

00:09:42.500  -->  00:09:42.800
.

125

00:09:43.010  -->  00:09:48.140
And if we need a model that can keep this kind of trends into account we'll learn about regression for

126

00:09:48.130  -->  00:09:48.970
us.

127

00:09:48.990  -->  00:09:54.360
Let's go ahead and move along with our understanding of machine learning and start learning about logistic

128

00:09:54.360  -->  00:10:01.480
regression what you can go ahead and do now is check out the train test split methods on this data.

129

00:10:01.620  -->  00:10:07.700
But instead of randomly training and testing splits try to split for future test data and previous data

130

00:10:07.710  -->  00:10:08.610
for training.

131

00:10:08.610  -->  00:10:14.730
And what you mean by that to be take a look at this plot manually split this data into training at test

132

00:10:14.730  -->  00:10:17.660
sets based off some time point.

133

00:10:17.880  -->  00:10:24.460
That means take everything beyond for instance 2012 and set that as test data.

134

00:10:24.500  -->  00:10:26.780
Never seen before that said it as training data.

135

00:10:27.030  -->  00:10:29.110
And check out how that works for you.

136

00:10:29.850  -->  00:10:30.430
OK.

137

00:10:30.650  -->  00:10:31.580
Thanks everyone.

138

00:10:31.620  -->  00:10:33.870
I hope you found this project enjoyable.

139

00:10:33.870  -->  00:10:38.480
It was definitely focused more on exploratory data analysis and actual model building because we're

140

00:10:38.490  -->  00:10:42.960
going to get a lot more practice with building models in our later on through subsequent lectures and

141

00:10:42.960  -->  00:10:48.210
projects hopefully by now you've noticed that the actual building of the model is usually just one line

142

00:10:48.330  -->  00:10:52.520
and is kind of the easiest part of the entire machine learning process.

143

00:10:52.940  -->  00:10:55.010
Okay thanks and I'll see you at the next lecture
