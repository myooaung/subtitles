WEBVTT
1
00:00:00.000 --> 00:00:02.007
- [Instructor] As an API gains adoption

2
00:00:02.007 --> 00:00:04.005
and its usage increases,

3
00:00:04.005 --> 00:00:07.000
it's important to maintain the experience

4
00:00:07.000 --> 00:00:10.002
and to meet the performance demands of its clients.

5
00:00:10.002 --> 00:00:14.001
Often, the operations found on an API are composed

6
00:00:14.001 --> 00:00:18.005
from those made available in a cluster of microservices.

7
00:00:18.005 --> 00:00:23.005
These microservices must remain stable as traffic increases.

8
00:00:23.005 --> 00:00:27.009
Scaling is the first strategy to consider when demand

9
00:00:27.009 --> 00:00:31.006
for a micro-service begins to exceed its capacity.

10
00:00:31.006 --> 00:00:34.005
By design, microservices are intended

11
00:00:34.005 --> 00:00:38.002
to scale easily through features like auto-scaling

12
00:00:38.002 --> 00:00:42.002
that are provided by container orchestrators.

13
00:00:42.002 --> 00:00:45.000
However, auto scaling has its limitations

14
00:00:45.000 --> 00:00:49.006
because constraints such as costs or available resources

15
00:00:49.006 --> 00:00:53.006
may limit the number of microservice instances that are able

16
00:00:53.006 --> 00:00:55.002
to be spun up.

17
00:00:55.002 --> 00:00:58.007
Underlying each container orchestrator is a plane

18
00:00:58.007 --> 00:01:01.000
of host VMs.

19
00:01:01.000 --> 00:01:03.004
Once their capacity is exhausted,

20
00:01:03.004 --> 00:01:06.008
there's nowhere for another container to be deployed.

21
00:01:06.008 --> 00:01:10.006
In some cases, such as a denial of service attack,

22
00:01:10.006 --> 00:01:12.007
you may not even want to scale.

23
00:01:12.007 --> 00:01:17.002
Seeing an increased demand for your API is great,

24
00:01:17.002 --> 00:01:18.007
but it may not be feasible

25
00:01:18.007 --> 00:01:22.003
to allow every client unrestricted consumption of it

26
00:01:22.003 --> 00:01:26.000
because it could bring down the API for all clients.

27
00:01:26.000 --> 00:01:30.008
Throttling the number of requests is one strategy used

28
00:01:30.008 --> 00:01:34.007
to control the amount of API usage by clients.

29
00:01:34.007 --> 00:01:37.003
It is based on the principle that it is better

30
00:01:37.003 --> 00:01:41.000
to deny some traffic to preserve the existing usage,

31
00:01:41.000 --> 00:01:45.004
than to crash the system and have no traffic at all.

32
00:01:45.004 --> 00:01:47.008
At a high level, you can think of throttling

33
00:01:47.008 --> 00:01:50.002
like a speed limit for APIs.

34
00:01:50.002 --> 00:01:53.007
The most basic strategy for throttling an API

35
00:01:53.007 --> 00:01:57.005
is to apply a universal cap on the concurrent number

36
00:01:57.005 --> 00:02:01.007
of requests made to a service for all clients.

37
00:02:01.007 --> 00:02:06.003
This cap is typically placed just below the maximum capacity

38
00:02:06.003 --> 00:02:07.008
for the service.

39
00:02:07.008 --> 00:02:11.007
There's problems with using a universal cap.

40
00:02:11.007 --> 00:02:15.004
It can allow one client to unfairly consume the majority

41
00:02:15.004 --> 00:02:18.002
of the capacity of the microservices.

42
00:02:18.002 --> 00:02:22.003
A better strategy is to create a quota and a rate limit

43
00:02:22.003 --> 00:02:24.004
for each API client.

44
00:02:24.004 --> 00:02:28.008
The quota defines the number of calls permitted by a client

45
00:02:28.008 --> 00:02:32.008
over a long period of time, like a day or a month.

46
00:02:32.008 --> 00:02:35.006
A rate limit focuses on preventing bursts

47
00:02:35.006 --> 00:02:38.006
of concurrent calls over a much shorter timeframe

48
00:02:38.006 --> 00:02:41.008
that could take down the microservice.

49
00:02:41.008 --> 00:02:46.003
In some cases, certain clients may have higher rate limits

50
00:02:46.003 --> 00:02:48.007
and quotas than other clients.

51
00:02:48.007 --> 00:02:50.008
For instance, a first party client

52
00:02:50.008 --> 00:02:54.001
may have a higher rate limit than a third party.

53
00:02:54.001 --> 00:02:56.008
For things like admin tools, we may not want

54
00:02:56.008 --> 00:02:59.008
to apply a throttle at all, since they're used

55
00:02:59.008 --> 00:03:01.003
to resolve issues.

56
00:03:01.003 --> 00:03:03.009
For APIs that are monetized,

57
00:03:03.009 --> 00:03:07.002
you'll see different tiers that are available,

58
00:03:07.002 --> 00:03:11.004
via an API plan that allows consumers to purchase more quota

59
00:03:11.004 --> 00:03:14.000
or an increased rate limit.

60
00:03:14.000 --> 00:03:17.008
Rate limits and quota can also be tracked and enforced

61
00:03:17.008 --> 00:03:20.007
at more granular levels.

62
00:03:20.007 --> 00:03:24.000
Restricting quota by end user can prevent a particular user

63
00:03:24.000 --> 00:03:28.003
from consuming the entirety of a client's quota.

64
00:03:28.003 --> 00:03:32.000
This allows available resources to be fairly assigned

65
00:03:32.000 --> 00:03:34.006
across all users of a client.

66
00:03:34.006 --> 00:03:39.000
When applying this strategy, the claims on a jot can be used

67
00:03:39.000 --> 00:03:43.003
to determine the identity of the end user and the client.

68
00:03:43.003 --> 00:03:45.007
Another effective throttling strategy

69
00:03:45.007 --> 00:03:48.007
is to apply a rate limit and quota

70
00:03:48.007 --> 00:03:52.001
for each particular operation on an API.

71
00:03:52.001 --> 00:03:56.004
API operations normally span multiple microservices.

72
00:03:56.004 --> 00:03:58.006
Each of these microservices

73
00:03:58.006 --> 00:04:01.004
may have their own resource profile

74
00:04:01.004 --> 00:04:06.002
with some consuming more memory and CPU than others.

75
00:04:06.002 --> 00:04:08.009
By having separate throttling limits applied

76
00:04:08.009 --> 00:04:10.000
for each operation,

77
00:04:10.000 --> 00:04:14.002
clients consume less resource intensive operations

78
00:04:14.002 --> 00:04:17.000
more frequently while heavier operations

79
00:04:17.000 --> 00:04:20.005
are made less available to prevent downtime.

80
00:04:20.005 --> 00:04:23.009
Availability often gets overlooked when it comes

81
00:04:23.009 --> 00:04:27.002
to security, especially when it's valid end users

82
00:04:27.002 --> 00:04:29.003
that bring down a service.

83
00:04:29.003 --> 00:04:32.006
Luckily, there are many techniques for throttling your API

84
00:04:32.006 --> 00:04:34.006
that you can choose from

85
00:04:34.006 --> 00:04:37.000
to keep your microservices available.

