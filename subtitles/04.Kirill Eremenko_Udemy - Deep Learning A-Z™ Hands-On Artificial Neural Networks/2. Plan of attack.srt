1
1

00:00:00,320  -->  00:00:01,310
<v Instructor>Hello and welcome back</v>
2

2

00:00:01,310  -->  00:00:03,100
to the course on Deep Learning.
3

3

00:00:03,100  -->  00:00:05,750
I hope you're as excited about this section
4

4

00:00:05,750  -->  00:00:08,630
of the course on recurrent neural networks as I am.
5

5

00:00:08,630  -->  00:00:12,820
We're slowly venturing into the very complex,
6

6

00:00:12,820  -->  00:00:17,820
very forward-looking and cutting-edge areas of deep learning
7

7

00:00:17,930  -->  00:00:20,210
and this is going to be very, very fun.
8

8

00:00:20,210  -->  00:00:22,320
So today we're going to talk about how we're going
9

9

00:00:22,320  -->  00:00:24,130
to approach this section, which contains
10

10

00:00:24,130  -->  00:00:28,290
so many different complex topics, so many concepts
11

11

00:00:28,290  -->  00:00:30,100
that we need to get our head around.
12

12

00:00:30,100  -->  00:00:32,240
Alright, so in this section we will learn
13

13

00:00:32,240  -->  00:00:35,650
first of all, the idea behind Recurrent Neural Networks.
14

14

00:00:35,650  -->  00:00:38,240
We'll see how they compare to the human brain,
15

15

00:00:38,240  -->  00:00:41,650
we'll understand what makes them unique and special
16

16

00:00:41,650  -->  00:00:45,350
as compared to regular artificial neural networks.
17

17

00:00:45,350  -->  00:00:47,580
Then we'll talk about the Vanishing Gradient Problem,
18

18

00:00:47,580  -->  00:00:52,580
something that has been a major road block in,
19

19

00:00:52,810  -->  00:00:56,400
or had been a major road block in the development
20

20

00:00:56,400  -->  00:00:58,450
and utilization of recurrent neural networks,
21

21

00:00:58,450  -->  00:01:00,670
something that prevented them from being
22

22

00:01:00,670  -->  00:01:04,020
what they are now and then
23

23

00:01:04,020  -->  00:01:05,823
we will move on to the solution,
24

24

00:01:05,823  -->  00:01:07,860
one of the most popular solutions
25

25

00:01:07,860  -->  00:01:09,100
to the Vanishing Gradient Problem,
26

26

00:01:09,100  -->  00:01:13,210
the Long Short-Term Memory or LSTM neural networks
27

27

00:01:13,210  -->  00:01:15,000
and we'll talk about their architecture,
28

28

00:01:15,000  -->  00:01:16,120
will be a very exciting tutorial,
29

29

00:01:16,120  -->  00:01:19,470
it's one of my favorite topics and we will find out
30

30

00:01:19,470  -->  00:01:23,840
exactly how they work and what that complex structure
31

31

00:01:23,840  -->  00:01:26,367
is inside them, we'll break it down into simple terms
32

32

00:01:26,367  -->  00:01:29,920
and you will be able to walk away with a
33

33

00:01:29,920  -->  00:01:33,840
pretty solid understanding of LSTMs.
34

34

00:01:33,840  -->  00:01:35,840
Then we'll talk about the practical intuition.
35

35

00:01:35,840  -->  00:01:38,080
So in that previous tutorial, we will have
36

36

00:01:38,080  -->  00:01:40,320
a practical example of using LSTMs,
37

37

00:01:40,320  -->  00:01:42,080
but in this practical intuition tutorial,
38

38

00:01:42,080  -->  00:01:45,340
we'll look at some great examples posted
39

39

00:01:45,340  -->  00:01:49,010
by one of the researchers, one of the most well-known
40

40

00:01:49,010  -->  00:01:51,470
researchers in the space, and we'll understand
41

41

00:01:51,470  -->  00:01:53,750
even better on an intuitive level
42

42

00:01:53,750  -->  00:01:56,370
how LSTMs actually work, how they think,
43

43

00:01:56,370  -->  00:01:59,070
we'll be like neuroscientists trying to understand
44

44

00:01:59,070  -->  00:02:01,610
what's going on in the brain of an LSTM,
45

45

00:02:01,610  -->  00:02:03,410
it's going to be very exciting as well.
46

46

00:02:03,410  -->  00:02:06,460
And then at the end, we'll have an extra tutorial
47

47

00:02:06,460  -->  00:02:10,060
on LSTM variations, something special, something,
48

48

00:02:10,060  -->  00:02:12,130
you don't really have to take this tutorial
49

49

00:02:12,130  -->  00:02:15,080
but it's very quick, just to get you up to speed
50

50

00:02:15,080  -->  00:02:18,740
on what other options of LSTMs exist out there
51

51

00:02:18,740  -->  00:02:20,800
in the world, what other architectures
52

52

00:02:21,710  -->  00:02:23,810
you might come across in your work.
53

53

00:02:23,810  -->  00:02:27,390
So hopefully, you're excited and ready to get started
54

54

00:02:27,390  -->  00:02:29,640
and I can't wait to see you in the next tutorial.
55

55

00:02:29,640  -->  00:02:31,763
Until then, enjoy deep learning.
