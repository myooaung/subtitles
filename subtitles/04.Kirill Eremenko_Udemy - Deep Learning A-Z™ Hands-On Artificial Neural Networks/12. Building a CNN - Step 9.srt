1
1

00:00:00,360  -->  00:00:03,250
<v Instructor>Hello and welcome to this Python tutorial.</v>
2

2

00:00:03,250  -->  00:00:06,190
So we just completed part one, building the CNN,
3

3

00:00:06,190  -->  00:00:08,180
that is we designed the architecture
4

4

00:00:08,180  -->  00:00:10,050
of our Convolutional Neural Network,
5

5

00:00:10,050  -->  00:00:11,680
and now we're beginning part two,
6

6

00:00:11,680  -->  00:00:14,860
in which we will fit our CNN to our images.
7

7

00:00:14,860  -->  00:00:16,980
So we will actually do it in one step
8

8

00:00:16,980  -->  00:00:18,730
because we're gonna use a shortcut,
9

9

00:00:18,730  -->  00:00:20,720
which is going to be very practical.
10

10

00:00:20,720  -->  00:00:22,940
It is the Keras Documentation,
11

11

00:00:22,940  -->  00:00:24,830
and what we will use it for, well,
12

12

00:00:24,830  -->  00:00:27,760
it's for a process called image augmentation,
13

13

00:00:27,760  -->  00:00:30,860
that basically consists of preprocessing
14

14

00:00:30,860  -->  00:00:33,460
your images to prevent overfitting,
15

15

00:00:33,460  -->  00:00:35,030
because what will happen then,
16

16

00:00:35,030  -->  00:00:37,160
we will get the results in this tutorial,
17

17

00:00:37,160  -->  00:00:39,470
but if we don't do this image augmentation,
18

18

00:00:39,470  -->  00:00:43,240
well what we might get is a great accuracy result
19

19

00:00:43,240  -->  00:00:44,410
on the training set,
20

20

00:00:44,410  -->  00:00:47,110
but a much lower accuracy on the test set,
21

21

00:00:47,110  -->  00:00:49,700
so that is exactly overfitting that corresponds
22

22

00:00:49,700  -->  00:00:52,820
to this particular situation where you get great results
23

23

00:00:52,820  -->  00:00:54,480
on your training set and poor results
24

24

00:00:54,480  -->  00:00:58,830
on your test set due to an overfit on the training set.
25

25

00:00:58,830  -->  00:01:01,580
So before fitting our CNN to our images,
26

26

00:01:01,580  -->  00:01:05,020
let's precede to this image augmentation process.
27

27

00:01:05,020  -->  00:01:07,060
So right now, we're gonna take a browser,
28

28

00:01:07,060  -->  00:01:08,280
because as I just told you,
29

29

00:01:08,280  -->  00:01:11,370
we're gonna use this Keras Documentation shortcut.
30

30

00:01:11,370  -->  00:01:15,153
And so in your browser, you can type Keras Documentation,
31

31

00:01:16,610  -->  00:01:18,910
all right, you can press enter, here it is.
32

32

00:01:18,910  -->  00:01:22,080
You just take the first link, Keras Documentation.
33

33

00:01:22,080  -->  00:01:24,580
Here we go, and that's the page we want.
34

34

00:01:24,580  -->  00:01:25,950
So basically on this page
35

35

00:01:25,950  -->  00:01:27,330
you get a lot of informations
36

36

00:01:27,330  -->  00:01:29,740
about Keras and ready-to-use codes
37

37

00:01:29,740  -->  00:01:32,060
that you can take for your deep learning project.
38

38

00:01:32,060  -->  00:01:34,580
So right now what we need is some info, or code,
39

39

00:01:34,580  -->  00:01:37,220
for image augmentation, image preprocessing.
40

40

00:01:37,220  -->  00:01:38,830
So in these windows on the left,
41

41

00:01:38,830  -->  00:01:42,110
we're gonna look for Preprocessing, here it is.
42

42

00:01:42,110  -->  00:01:44,070
That's the section we're interested in,
43

43

00:01:44,070  -->  00:01:45,860
and inside this section as you can see,
44

44

00:01:45,860  -->  00:01:48,920
there are some info about sequence preprocessing,
45

45

00:01:48,920  -->  00:01:51,280
text preprocessing, yes indeed, deep learning
46

46

00:01:51,280  -->  00:01:54,440
can also be applied to text in a very powerful way.
47

47

00:01:54,440  -->  00:01:56,400
And, of course, image preprocessing,
48

48

00:01:56,400  -->  00:01:58,610
and that's what we are interested in right now.
49

49

00:01:58,610  -->  00:02:01,320
So let's click on it, and let's see what we get.
50

50

00:02:01,320  -->  00:02:02,630
All right, and the first thing interesting
51

51

00:02:02,630  -->  00:02:05,090
to see is this ImageDataGenerator.
52

52

00:02:05,090  -->  00:02:07,370
That's the first function that we're gonna use
53

53

00:02:07,370  -->  00:02:10,350
to generate this image augmentation.
54

54

00:02:10,350  -->  00:02:12,000
So what is image augmentation,
55

55

00:02:12,000  -->  00:02:14,460
and how will it prevent overfitting?
56

56

00:02:14,460  -->  00:02:16,990
Well, we know that one of the situations that lead
57

57

00:02:16,990  -->  00:02:20,970
to overfitting is when we have few data to train our model.
58

58

00:02:20,970  -->  00:02:24,040
In that situation, our model finds some correlations
59

59

00:02:24,040  -->  00:02:26,400
in the few observations of the training set,
60

60

00:02:26,400  -->  00:02:28,810
but fails to generalize this correlations
61

61

00:02:28,810  -->  00:02:30,630
on some new observations.
62

62

00:02:30,630  -->  00:02:33,290
And when it comes to images, we actually need
63

63

00:02:33,290  -->  00:02:37,140
a lot of images to find and generalize some correlations,
64

64

00:02:37,140  -->  00:02:38,580
because in computer vision,
65

65

00:02:38,580  -->  00:02:40,330
our machine learning model doesn't seem to need
66

66

00:02:40,330  -->  00:02:41,640
to find some correlations
67

67

00:02:41,640  -->  00:02:43,400
between some independent variable
68

68

00:02:43,400  -->  00:02:44,840
and some dependent variables.
69

69

00:02:44,840  -->  00:02:47,470
It needs to find some patterns in the pixels,
70

70

00:02:47,470  -->  00:02:50,720
and to do this it requires a lot of images.
71

71

00:02:50,720  -->  00:02:53,740
Right now, we are working with 10,000 images,
72

72

00:02:53,740  -->  00:02:56,160
8,000 images on the training set,
73

73

00:02:56,160  -->  00:02:57,810
and that is actually not much
74

74

00:02:57,810  -->  00:03:00,100
to get some great performance results.
75

75

00:03:00,100  -->  00:03:02,210
We either need some more images,
76

76

00:03:02,210  -->  00:03:03,750
or we can use a trick,
77

77

00:03:03,750  -->  00:03:06,720
and that is where data augmentation comes into play.
78

78

00:03:06,720  -->  00:03:09,240
That is the trick, because what it will do,
79

79

00:03:09,240  -->  00:03:12,800
is it will create many batches of our images,
80

80

00:03:12,800  -->  00:03:16,260
and in each batch it will apply some random transformations
81

81

00:03:16,260  -->  00:03:18,560
on a random selection of our images,
82

82

00:03:18,560  -->  00:03:21,950
like rotating them, flipping them, shifting them,
83

83

00:03:21,950  -->  00:03:25,470
or even shearing them, and eventually what we'll get during
84

84

00:03:25,470  -->  00:03:28,180
the training is many more diverse images
85

85

00:03:28,180  -->  00:03:30,320
inside these batches, and therefore
86

86

00:03:30,320  -->  00:03:32,720
a lot more material to train.
87

87

00:03:32,720  -->  00:03:36,090
And now we understand why it is called image augmentation.
88

88

00:03:36,090  -->  00:03:37,460
That's because the amount
89

89

00:03:37,460  -->  00:03:40,560
of our training images is augmented.
90

90

00:03:40,560  -->  00:03:42,560
Besides, because the transformations
91

91

00:03:42,560  -->  00:03:44,170
are random transformations,
92

92

00:03:44,170  -->  00:03:45,720
well our model will never find
93

93

00:03:45,720  -->  00:03:48,040
the same picture across the batches.
94

94

00:03:48,040  -->  00:03:50,780
So all this image augmentation trick
95

95

00:03:50,780  -->  00:03:53,760
can only reduce overfitting.
96

96

00:03:53,760  -->  00:03:56,590
So in summary, image augmentation is a technique
97

97

00:03:56,590  -->  00:04:00,040
that allows us to enrich our data set, our data set,
98

98

00:04:00,040  -->  00:04:02,930
without adding more images and therefore that allows
99

99

00:04:02,930  -->  00:04:05,070
us to get good performance results with little
100

100

00:04:05,070  -->  00:04:08,730
or not overfitting, even with a small amount of images.
101

101

00:04:08,730  -->  00:04:13,070
So now, let's apply this image augmentation on our images.
102

102

00:04:13,070  -->  00:04:15,280
And to do this, we are gonna use this shortcut
103

103

00:04:15,280  -->  00:04:18,960
I was tell you about, which is to take ready-to-use code
104

104

00:04:18,960  -->  00:04:20,950
that we can find on this page,
105

105

00:04:20,950  -->  00:04:22,350
and that corresponds very well
106

106

00:04:22,350  -->  00:04:25,140
to how we structured our data set,
107

107

00:04:25,140  -->  00:04:27,050
because as you can see there's two ways
108

108

00:04:27,050  -->  00:04:28,560
to preprocess our images
109

109

00:04:28,560  -->  00:04:30,840
by applying image augmentation on them.
110

110

00:04:30,840  -->  00:04:33,040
It's either by using this code that is based
111

111

00:04:33,040  -->  00:04:35,880
on the flow method, or this code that is based
112

112

00:04:35,880  -->  00:04:38,200
on the flow from directory method.
113

113

00:04:38,200  -->  00:04:39,380
And as you might've guessed,
114

114

00:04:39,380  -->  00:04:41,850
we are gonna use this code section here
115

115

00:04:41,850  -->  00:04:45,210
because we are gonna take out data from this dataset
116

116

00:04:45,210  -->  00:04:47,080
that we built, and that we structured
117

117

00:04:47,080  -->  00:04:49,340
this specific way so that our classes
118

118

00:04:49,340  -->  00:04:52,000
can be well identified in the separate folders,
119

119

00:04:52,000  -->  00:04:54,570
cat or dogs, and since this dataset
120

120

00:04:54,570  -->  00:04:57,080
is now working directory, well that's why we used
121

121

00:04:57,080  -->  00:04:59,890
this function here, flow_from_directory.
122

122

00:04:59,890  -->  00:05:02,940
So inside this function here, instead of having directory,
123

123

00:05:02,940  -->  00:05:04,830
we'll put our dataset.
124

124

00:05:04,830  -->  00:05:06,850
And so why did I call it a shortcut?
125

125

00:05:06,850  -->  00:05:09,260
Well, that's because with this code section here,
126

126

00:05:09,260  -->  00:05:12,780
we have everything we need to preprocess our images,
127

127

00:05:12,780  -->  00:05:14,740
augment them, and even fitting
128

128

00:05:14,740  -->  00:05:16,340
our Convolutional Neural Network
129

129

00:05:16,340  -->  00:05:18,910
that we just built on our images.
130

130

00:05:18,910  -->  00:05:21,170
So basically, that's the end of the code,
131

131

00:05:21,170  -->  00:05:24,140
because this fit generator method
132

132

00:05:24,140  -->  00:05:27,060
will not only fit our CNN to the training set,
133

133

00:05:27,060  -->  00:05:29,410
but it will also test at the same time
134

134

00:05:29,410  -->  00:05:31,690
its performance on some new operations,
135

135

00:05:31,690  -->  00:05:33,070
which are gonna be the observations
136

136

00:05:33,070  -->  00:05:35,060
of our test set, that is the images
137

137

00:05:35,060  -->  00:05:36,550
of our test set folder.
138

138

00:05:36,550  -->  00:05:38,320
So that's perfect, we have everything we need.
139

139

00:05:38,320  -->  00:05:41,710
So this part is the image augmentation part,
140

140

00:05:41,710  -->  00:05:45,160
where we apply several transformations like the rescale.
141

141

00:05:45,160  -->  00:05:47,290
Well, the rescale is always compulsory
142

142

00:05:47,290  -->  00:05:49,560
and it corresponds to the feature scanning part
143

143

00:05:49,560  -->  00:05:51,980
of the data preprocessing phase that we know.
144

144

00:05:51,980  -->  00:05:55,000
And then we have other transformations like shear range,
145

145

00:05:55,000  -->  00:05:56,890
so that corresponds to shearing.
146

146

00:05:56,890  -->  00:05:59,720
You know, sharing is a geometrical transformation
147

147

00:05:59,720  -->  00:06:01,610
that is also called transvection.
148

148

00:06:01,610  -->  00:06:05,380
And where the pixels are moved to a fixed direction
149

149

00:06:05,380  -->  00:06:07,540
over a proportional distance from a line
150

150

00:06:07,540  -->  00:06:10,520
that is parallel to the direction they're moving to.
151

151

00:06:10,520  -->  00:06:13,570
So basically that is just a geometrical transformation
152

152

00:06:13,570  -->  00:06:16,380
for that same purpose of augmenting our images.
153

153

00:06:16,380  -->  00:06:18,280
And then we also have some other kinds
154

154

00:06:18,280  -->  00:06:20,600
of transformations, like zoom range,
155

155

00:06:20,600  -->  00:06:22,780
so this is some sort of random zoom
156

156

00:06:22,780  -->  00:06:24,710
that we apply on our images.
157

157

00:06:24,710  -->  00:06:27,060
Ad we also also this horizontal flip
158

158

00:06:27,060  -->  00:06:29,820
that flips horizontally the images.
159

159

00:06:29,820  -->  00:06:33,890
And we also have vertical flip, but that is not used here.
160

160

00:06:33,890  -->  00:06:37,270
We can have fun and apply all the image transformations
161

161

00:06:37,270  -->  00:06:39,888
that there are in this Keras Documentation,
162

162

00:06:39,888  -->  00:06:43,030
but for now we will just use what we have in this example.
163

163

00:06:43,030  -->  00:06:44,400
That will be way enough
164

164

00:06:44,400  -->  00:06:47,110
and you'll see that we get good results.
165

165

00:06:47,110  -->  00:06:50,050
All right, so that is the image augmentation part.
166

166

00:06:50,050  -->  00:06:52,820
Now this image augmentation part is applied
167

167

00:06:52,820  -->  00:06:55,320
on the training set, and then we use again
168

168

00:06:55,320  -->  00:06:57,550
this ImageDataGenerator function
169

169

00:06:57,550  -->  00:07:01,300
to this time only rescale the images of our test set.
170

170

00:07:01,300  -->  00:07:03,250
And then we have these two sections,
171

171

00:07:03,250  -->  00:07:05,580
trans_generator and validation_generator.
172

172

00:07:05,580  -->  00:07:08,210
Well, these two sections actually create
173

173

00:07:08,210  -->  00:07:10,220
the training set and the test set,
174

174

00:07:10,220  -->  00:07:12,710
so what we'll do then when we are back to Spyder,
175

175

00:07:12,710  -->  00:07:16,050
well we will call it training set and this test set,
176

176

00:07:16,050  -->  00:07:17,770
so that we clearly see what's happening.
177

177

00:07:17,770  -->  00:07:19,610
And basically this is in this section
178

178

00:07:19,610  -->  00:07:22,510
that we will create this training set composed
179

179

00:07:22,510  -->  00:07:25,290
of all these augmented images extracted
180

180

00:07:25,290  -->  00:07:27,300
from our ImageDataGenerator,
181

181

00:07:27,300  -->  00:07:30,090
and same, this section will create our test set
182

182

00:07:30,090  -->  00:07:32,670
that will be used to evaluate the model performance
183

183

00:07:32,670  -->  00:07:34,170
in this part of the code.
184

184

00:07:34,170  -->  00:07:36,870
And same, the images of the test set are extracted
185

185

00:07:36,870  -->  00:07:39,080
from our ImageDataGenerator
186

186

00:07:39,080  -->  00:07:41,440
that was applied on our test set.
187

187

00:07:41,440  -->  00:07:44,560
And then we have this code section here that will fit
188

188

00:07:44,560  -->  00:07:47,940
our Convolutional Neural Network model on the training set,
189

189

00:07:47,940  -->  00:07:50,970
as well as testing its performance on the test set.
190

190

00:07:50,970  -->  00:07:54,260
So let's do it, let's take all this section here.
191

191

00:07:54,260  -->  00:07:57,050
We are gonna make a few changes, but very few.
192

192

00:07:57,050  -->  00:07:59,170
And now let's go back to Spyder
193

193

00:07:59,170  -->  00:08:04,070
to paste this whole code section into our editor.
194

194

00:08:04,070  -->  00:08:06,050
All right, and now we need to change a few things.
195

195

00:08:06,050  -->  00:08:07,700
The first thing that we need to do first,
196

196

00:08:07,700  -->  00:08:09,890
is to import the class that will allow
197

197

00:08:09,890  -->  00:08:12,750
us to use this ImageDataGenerator function.
198

198

00:08:12,750  -->  00:08:16,130
And this class is called ImageDataGenerator,
199

199

00:08:16,130  -->  00:08:20,900
and we import this class from Keras.preprocessing.image,
200

200

00:08:24,580  -->  00:08:29,400
and import and eventually, ImageDataGenerator.
201

201

00:08:31,290  -->  00:08:34,020
All right, so now we have our class.
202

202

00:08:34,020  -->  00:08:36,060
Now, next section.
203

203

00:08:36,060  -->  00:08:38,620
All right, so in this section we won't change anything.
204

204

00:08:38,620  -->  00:08:41,918
We will rescale all our pixel values
205

205

00:08:41,918  -->  00:08:44,210
between zero and ones, because you know,
206

206

00:08:44,210  -->  00:08:47,360
pixel's state value between zero and 255
207

207

00:08:47,360  -->  00:08:52,360
and by rescaling them using this rescale = 1 / 255,
208

208

00:08:52,690  -->  00:08:56,060
then all our pixel values will be between zero and one.
209

209

00:08:56,060  -->  00:08:58,950
Then shear_range, that's to apply random transvections,
210

210

00:08:58,950  -->  00:09:01,070
and we will keep this open two value.
211

211

00:09:01,070  -->  00:09:03,540
Zoom_range, that's to apply some random zooms,
212

212

00:09:03,540  -->  00:09:05,370
and we will keep this open two value.
213

213

00:09:05,370  -->  00:09:08,420
So this open two values here are just some parameters
214

214

00:09:08,420  -->  00:09:12,110
of how much you wanna apply these random transformations,
215

215

00:09:12,110  -->  00:09:14,620
and here we will take what Keras suggests.
216

216

00:09:14,620  -->  00:09:17,660
And then, horizontal_flip, that means that our images
217

217

00:09:17,660  -->  00:09:21,170
will be flipped horizontally, so that's fine.
218

218

00:09:21,170  -->  00:09:24,030
That will generate enough transformations
219

219

00:09:24,030  -->  00:09:26,260
so that we don't find the same image
220

220

00:09:26,260  -->  00:09:27,610
in the different batches.
221

221

00:09:27,610  -->  00:09:29,910
So basically we don't have anything to change here
222

222

00:09:29,910  -->  00:09:32,140
in this code section here, and we can move
223

223

00:09:32,140  -->  00:09:32,973
on to the next one.
224

224

00:09:32,973  -->  00:09:36,480
Test_datagen, well same, here we only need to rescale
225

225

00:09:36,480  -->  00:09:39,040
the pixels of the images of the test set,
226

226

00:09:39,040  -->  00:09:41,370
so that they have values between zero and one,
227

227

00:09:41,370  -->  00:09:42,960
so that's all fine here as well.
228

228

00:09:42,960  -->  00:09:44,750
We don't need to change anything.
229

229

00:09:44,750  -->  00:09:46,500
But then we have this code section here
230

230

00:09:46,500  -->  00:09:48,800
that created the training set,
231

231

00:09:48,800  -->  00:09:50,680
and here we have a few things to change.
232

232

00:09:50,680  -->  00:09:52,380
So first, let's give another name
233

233

00:09:52,380  -->  00:09:55,387
for train_generator, and call it training_set,
234

234

00:09:56,420  -->  00:10:01,100
and let's press Alt + Shift to align everything well.
235

235

00:10:01,100  -->  00:10:02,970
And so here, what do we need to change?
236

236

00:10:02,970  -->  00:10:04,640
Well first, the first parameter
237

237

00:10:04,640  -->  00:10:07,330
is where we extract the images from.
238

238

00:10:07,330  -->  00:10:09,020
From which directory?
239

239

00:10:09,020  -->  00:10:12,320
So it's not from the data/training directory.
240

240

00:10:12,320  -->  00:10:13,870
Let's see where it is from.
241

241

00:10:13,870  -->  00:10:16,980
Well, remember we have here our dataset
242

242

00:10:16,980  -->  00:10:20,200
that is composed of two set folders, the training_set
243

243

00:10:20,200  -->  00:10:22,540
and the test_set, and so since here
244

244

00:10:22,540  -->  00:10:25,390
the section corresponds to the creation of the training set,
245

245

00:10:25,390  -->  00:10:28,050
well we need to specify what this training set is,
246

246

00:10:28,050  -->  00:10:29,930
and therefore we need to specify the paths,
247

247

00:10:29,930  -->  00:10:33,553
that is, dataset/training_set.
248

248

00:10:34,560  -->  00:10:36,570
And we don't have to specify the whole path
249

249

00:10:36,570  -->  00:10:39,300
that leads to this dataset because this dataset
250

250

00:10:39,300  -->  00:10:42,070
is already in the working directory folder.
251

251

00:10:42,070  -->  00:10:44,590
Perfect, then, target_size.
252

252

00:10:44,590  -->  00:10:47,750
So target_size is the size of your images
253

253

00:10:47,750  -->  00:10:50,840
that is expected in your CNN model.
254

254

00:10:50,840  -->  00:10:55,640
So as you can see here we chose a 64 by 64 dimension
255

255

00:10:55,640  -->  00:10:57,610
for our images, and therefore here
256

256

00:10:57,610  -->  00:11:01,720
we cannot keep this 150 and 150.
257

257

00:11:01,720  -->  00:11:05,100
We need to put the dimensions expected by our CNN.
258

258

00:11:05,100  -->  00:11:10,100
That is, 64 and 64.
259

259

00:11:10,330  -->  00:11:12,670
Great, then the batch_size.
260

260

00:11:12,670  -->  00:11:14,550
So that is the size of the batches
261

261

00:11:14,550  -->  00:11:17,730
in which some random samples of our images will be included,
262

262

00:11:17,730  -->  00:11:19,700
and that contains the number of images
263

263

00:11:19,700  -->  00:11:21,450
that will go through the CNN,
264

264

00:11:21,450  -->  00:11:23,570
after which the weight will be updated.
265

265

00:11:23,570  -->  00:11:25,480
So we will keep 32 here.
266

266

00:11:25,480  -->  00:11:28,510
This actually looks fine to train our CNN.
267

267

00:11:28,510  -->  00:11:30,060
And finally, class_mode,
268

268

00:11:30,060  -->  00:11:31,910
well that's the parameter indicating
269

269

00:11:31,910  -->  00:11:34,550
if your class, your dependent variable,
270

270

00:11:34,550  -->  00:11:37,450
is binary or has more than two categories,
271

271

00:11:37,450  -->  00:11:39,610
and therefore since we have two classes here,
272

272

00:11:39,610  -->  00:11:42,650
cats and dogs, well the class_mode is binary.
273

273

00:11:42,650  -->  00:11:45,290
So great, this section is now ready.
274

274

00:11:45,290  -->  00:11:46,910
Now let's move on to the next section.
275

275

00:11:46,910  -->  00:11:50,510
Validation_generator, so let's actually call
276

276

00:11:50,510  -->  00:11:53,390
it test_set, because this code section
277

277

00:11:53,390  -->  00:11:57,470
will create the test set, and now let's align everything.
278

278

00:11:57,470  -->  00:11:59,590
I'm going to press Alt + Shift,
279

279

00:11:59,590  -->  00:12:01,300
and now let's see what we need to change.
280

280

00:12:01,300  -->  00:12:03,900
So first, we need to input here the path
281

281

00:12:03,900  -->  00:12:06,570
that lead to the test set, and that's exactly
282

282

00:12:06,570  -->  00:12:08,450
the same as for the training set.
283

283

00:12:08,450  -->  00:12:11,320
We need to input here dataset first,
284

284

00:12:11,320  -->  00:12:15,353
and then test_set instead of validation.
285

285

00:12:15,353  -->  00:12:18,080
Test_set, here we go.
286

286

00:12:18,080  -->  00:12:20,470
Then, target_size, well that's the same.
287

287

00:12:20,470  -->  00:12:23,080
The images of our test set will be expected
288

288

00:12:23,080  -->  00:12:27,070
to have the 64 by 64 dimensions by our CNN,
289

289

00:12:27,070  -->  00:12:29,413
and therefore here we also need to replace
290

290

00:12:29,413  -->  00:12:33,917
a 150 by 64, and same here, 64.
291

291

00:12:35,040  -->  00:12:38,500
All right, then we will also keep this batch_size of 32,
292

292

00:12:38,500  -->  00:12:40,200
and same class mode binary,
293

293

00:12:40,200  -->  00:12:42,570
because we have our binary outcome.
294

294

00:12:42,570  -->  00:12:45,010
Great, and now finally last code section,
295

295

00:12:45,010  -->  00:12:48,240
the model fit generator, where we fit our CNN
296

296

00:12:48,240  -->  00:12:50,330
to the training set, while also testing
297

297

00:12:50,330  -->  00:12:53,340
its performance on the test set, and therefore,
298

298

00:12:53,340  -->  00:12:56,343
well first let's align everything again.
299

299

00:12:57,720  -->  00:13:00,110
Here we go, and now let's change the last things.
300

300

00:13:00,110  -->  00:13:01,570
Well the first argument that we need
301

301

00:13:01,570  -->  00:13:03,700
to input here is out training set,
302

302

00:13:03,700  -->  00:13:08,420
so we will replace train_generator by training_set.
303

303

00:13:08,420  -->  00:13:11,410
Then the second arguments is the samples_per_epoch.
304

304

00:13:11,410  -->  00:13:13,730
Well that's simply the number of images we have
305

305

00:13:13,730  -->  00:13:15,970
in our training set, because remember
306

306

00:13:15,970  -->  00:13:18,530
all the observations of the training set pass
307

307

00:13:18,530  -->  00:13:21,910
through the Convolutional Neural Network during each epoch,
308

308

00:13:21,910  -->  00:13:25,510
and since we have 8,000 images in our training set,
309

309

00:13:25,510  -->  00:13:30,370
well here we need to replace 2,000 by 8,000, all right?
310

310

00:13:30,370  -->  00:13:32,440
The number of epoch, well that's the number
311

311

00:13:32,440  -->  00:13:35,060
of epochs we wanna choose to train our CNN.
312

312

00:13:35,060  -->  00:13:36,860
And here, 50 might be a little too much,
313

313

00:13:36,860  -->  00:13:39,320
so we will take 25 so that we don't have
314

314

00:13:39,320  -->  00:13:42,090
to wait for too long to get our results.
315

315

00:13:42,090  -->  00:13:43,910
Then, validation data.
316

316

00:13:43,910  -->  00:13:45,610
So that corresponds to the test set
317

317

00:13:45,610  -->  00:13:48,900
on which we want to evaluate the performance of our CNN,
318

318

00:13:48,900  -->  00:13:50,600
and that is of course the test set.
319

319

00:13:50,600  -->  00:13:54,553
So we will replace validation generator by test_set.
320

320

00:13:55,496  -->  00:13:59,540
Almost good, the last parameter is nb_val_samples,
321

321

00:13:59,540  -->  00:14:01,850
and that corresponds to the number of images
322

322

00:14:01,850  -->  00:14:06,180
in our test set, and that is 2,000.
323

323

00:14:06,180  -->  00:14:08,910
Perfect, and now we just need to change one last thing.
324

324

00:14:08,910  -->  00:14:10,220
Can you guess what it is?
325

325

00:14:10,220  -->  00:14:12,760
Well, we are using this fit generator method
326

326

00:14:12,760  -->  00:14:14,870
to fit our CNN to our training set
327

327

00:14:14,870  -->  00:14:16,770
and test its performance on the test set
328

328

00:14:16,770  -->  00:14:19,550
at the same time, and this fit generator method
329

329

00:14:19,550  -->  00:14:22,400
is applied onto our CNN model.
330

330

00:14:22,400  -->  00:14:24,880
But our CNN model is not called model,
331

331

00:14:24,880  -->  00:14:26,800
it is called classifier.
332

332

00:14:26,800  -->  00:14:30,863
So we just need to replace model here by classifier.
333

333

00:14:31,740  -->  00:14:34,900
And let's align this again, Alt + Shift,
334

334

00:14:34,900  -->  00:14:37,820
so that now we apply this fit generator method
335

335

00:14:37,820  -->  00:14:41,000
onto our classifier to fit it to the training set
336

336

00:14:41,000  -->  00:14:42,870
and test it on the test set.
337

337

00:14:42,870  -->  00:14:45,070
So great, now everything is ready,
338

338

00:14:45,070  -->  00:14:48,730
we are ready to execute each of these last sections one
339

339

00:14:48,730  -->  00:14:52,370
by one, and eventually we will get to our final results.
340

340

00:14:52,370  -->  00:14:55,150
So let's execute them one by one.
341

341

00:14:55,150  -->  00:14:57,150
We're gonna start by importing
342

342

00:14:57,150  -->  00:15:01,480
the ImageDataGenerator class, here we go, well imported.
343

343

00:15:01,480  -->  00:15:05,250
And now let's proceed to this next section to,
344

344

00:15:05,250  -->  00:15:08,630
well actually, prepare the image augmentation
345

345

00:15:08,630  -->  00:15:11,640
with this train_data_gen, which is an object
346

346

00:15:11,640  -->  00:15:14,050
of the ImageDataGenerator class.
347

347

00:15:14,050  -->  00:15:16,570
So in this section we are creating this object,
348

348

00:15:16,570  -->  00:15:19,060
so I'm gonna press Command + Enter to execute,
349

349

00:15:19,060  -->  00:15:20,420
and now our object
350

350

00:15:20,420  -->  00:15:23,560
of the ImageDataGenerator class is created.
351

351

00:15:23,560  -->  00:15:24,903
And this object is the object
352

352

00:15:24,903  -->  00:15:26,990
that we're gonna use to augment
353

353

00:15:26,990  -->  00:15:29,210
the images of the training set.
354

354

00:15:29,210  -->  00:15:31,530
And now we're gonna do the same for our test set.
355

355

00:15:31,530  -->  00:15:33,390
We are gonna create another object
356

356

00:15:33,390  -->  00:15:35,570
of the ImageDataGenerator class,
357

357

00:15:35,570  -->  00:15:39,340
and this object will be used to preprocess
358

358

00:15:39,340  -->  00:15:41,700
the images of the test set.
359

359

00:15:41,700  -->  00:15:43,390
And then, next code section.
360

360

00:15:43,390  -->  00:15:46,260
In this code section we apply the image augmentation
361

361

00:15:46,260  -->  00:15:49,070
itself on the images of our training set
362

362

00:15:49,070  -->  00:15:51,910
by at the same time resizing all our images
363

363

00:15:51,910  -->  00:15:55,680
of the training set into this 64 times 64 dimensions,
364

364

00:15:55,680  -->  00:15:59,247
and by creating some batches of 32 images,
365

365

00:15:59,247  -->  00:16:01,180
and then our CNN will be trained
366

366

00:16:01,180  -->  00:16:04,060
on these images in all the different batches.
367

367

00:16:04,060  -->  00:16:06,570
Okay, so let's execute this section.
368

368

00:16:06,570  -->  00:16:09,700
And as you can see, that's actually very interesting to see.
369

369

00:16:09,700  -->  00:16:14,610
Well, Keras found 8,000 images belonging to two classes,
370

370

00:16:14,610  -->  00:16:16,740
and that is specifically thanks to the way
371

371

00:16:16,740  -->  00:16:19,569
we organized our images into our dataset folder,
372

372

00:16:19,569  -->  00:16:21,710
you know, splitting this dataset folder
373

373

00:16:21,710  -->  00:16:25,538
into a test_set folder, composed of 2,000 test images,
374

374

00:16:25,538  -->  00:16:26,670
and the training_set folder,
375

375

00:16:26,670  -->  00:16:29,210
composed of 8,000 training images.
376

376

00:16:29,210  -->  00:16:30,700
So that's why I was telling you
377

377

00:16:30,700  -->  00:16:32,730
this is a great and simple way
378

378

00:16:32,730  -->  00:16:36,200
to preprocess our dataset when we work with images.
379

379

00:16:36,200  -->  00:16:39,580
And then, next section is the same but for the test set.
380

380

00:16:39,580  -->  00:16:41,900
In this section we are creating the test set
381

381

00:16:41,900  -->  00:16:44,610
and we are resizing all the images of the test set
382

382

00:16:44,610  -->  00:16:47,230
into this 64 by 64 dimensions,
383

383

00:16:47,230  -->  00:16:51,400
and at the same time creating some batches of 32 images.
384

384

00:16:51,400  -->  00:16:53,660
So now let's execute this section,
385

385

00:16:53,660  -->  00:16:55,780
and we can guess what we're gonna get now.
386

386

00:16:55,780  -->  00:16:58,670
We should have found 2,000 images belonging
387

387

00:16:58,670  -->  00:17:01,040
to two classes, let's check it out.
388

388

00:17:01,040  -->  00:17:03,040
And we're going to execute, and here we go.
389

389

00:17:03,040  -->  00:17:06,110
Found 2,000 images belonging to two classes,
390

390

00:17:06,110  -->  00:17:10,460
so of course that's the 2,000 images of our test set.
391

391

00:17:10,460  -->  00:17:12,770
And now finally, last section,
392

392

00:17:12,770  -->  00:17:14,380
but I have to warn you,
393

393

00:17:14,380  -->  00:17:16,180
now this is going to take some time.
394

394

00:17:16,180  -->  00:17:19,270
So a good idea right now would be to run this code
395

395

00:17:19,270  -->  00:17:21,300
just before you have some lunch or dinner,
396

396

00:17:21,300  -->  00:17:22,530
or even take a nap.
397

397

00:17:22,530  -->  00:17:25,030
I'm going to take a nap right now, but what I mean
398

398

00:17:25,030  -->  00:17:27,740
is that it's not gonna take 10 seconds to execute.
399

399

00:17:27,740  -->  00:17:29,900
It'll be rather 10 or 20 minutes,
400

400

00:17:29,900  -->  00:17:32,590
but anyway now we are ready to execute
401

401

00:17:32,590  -->  00:17:35,570
and find out about the final results.
402

402

00:17:35,570  -->  00:17:36,780
So let's check it out.
403

403

00:17:36,780  -->  00:17:38,470
I'm going to execute right now.
404

404

00:17:38,470  -->  00:17:39,590
Are you ready?
405

405

00:17:39,590  -->  00:17:41,440
And, go.
406

406

00:17:41,440  -->  00:17:44,060
Here we go, first epoch, one of 25.
407

407

00:17:44,060  -->  00:17:46,770
So as you can see, it's going to take a while
408

408

00:17:46,770  -->  00:17:50,010
because right now it's training on the 8,000 images
409

409

00:17:50,010  -->  00:17:54,050
of the training set, and it will do this over 25 epochs.
410

410

00:17:54,050  -->  00:17:56,240
So let's take a break, let's get a coffee,
411

411

00:17:56,240  -->  00:17:57,920
and lets this run on its own.
412

412

00:17:57,920  -->  00:17:59,310
I'm gonna take a quick nap,
413

413

00:17:59,310  -->  00:18:01,310
and I'll see you in a couple of minutes.
414

414

00:18:03,090  -->  00:18:05,830
And here we go, the training is over.
415

415

00:18:05,830  -->  00:18:10,250
We obtained an accuracy of 84% for the training set,
416

416

00:18:10,250  -->  00:18:13,050
and 75% for the test set.
417

417

00:18:13,050  -->  00:18:14,940
So what do you think of these results?
418

418

00:18:14,940  -->  00:18:18,360
Well, not too bad, but not too good either.
419

419

00:18:18,360  -->  00:18:19,730
Okay so first we obtained
420

420

00:18:19,730  -->  00:18:23,010
this 84.5% accuracy on the training set.
421

421

00:18:23,010  -->  00:18:24,070
That is not bad,
422

422

00:18:24,070  -->  00:18:27,143
but that is not what we are mostly interested in.
423

423

00:18:27,143  -->  00:18:29,810
What we are mostly interested in is the accuracy
424

424

00:18:29,810  -->  00:18:33,050
of the test set, which is equal to 75%,
425

425

00:18:33,050  -->  00:18:35,160
and the difference between the accuracy
426

426

00:18:35,160  -->  00:18:36,980
of the training set and the accuracy
427

427

00:18:36,980  -->  00:18:38,690
of the test set to access
428

428

00:18:38,690  -->  00:18:41,050
whether there's overfitting or not.
429

429

00:18:41,050  -->  00:18:44,690
So 75% accuracy on the test set is not bad.
430

430

00:18:44,690  -->  00:18:47,130
That means that we get three correct predictions
431

431

00:18:47,130  -->  00:18:49,490
out of four, so that's actually not too bad,
432

432

00:18:49,490  -->  00:18:51,120
but then we get quite a large difference
433

433

00:18:51,120  -->  00:18:53,530
between the accuracy on the training set
434

434

00:18:53,530  -->  00:18:55,170
and the accuracy on test set.
435

435

00:18:55,170  -->  00:18:57,930
So it's not like there is important overfitting,
436

436

00:18:57,930  -->  00:19:00,410
but still there is a lot of room for improvement.
437

437

00:19:00,410  -->  00:19:03,490
Not only can we improve the accuracy of the test set,
438

438

00:19:03,490  -->  00:19:05,840
and you know a good goal that we can set ourselves
439

439

00:19:05,840  -->  00:19:09,900
would be to make this accuracy reach an accuracy over 80%.
440

440

00:19:09,900  -->  00:19:11,740
And besides, which we would like to get,
441

441

00:19:11,740  -->  00:19:14,200
is a smaller difference between the accuracy
442

442

00:19:14,200  -->  00:19:16,810
of the training set and the one of the set test.
443

443

00:19:16,810  -->  00:19:18,080
So that's our challenge.
444

444

00:19:18,080  -->  00:19:20,630
Let's try to increase this accuracy
445

445

00:19:20,630  -->  00:19:23,210
of the test set over 80%, and decrease
446

446

00:19:23,210  -->  00:19:25,470
this difference between the training set accuracy
447

447

00:19:25,470  -->  00:19:26,810
and the test set accuracy.
448

448

00:19:26,810  -->  00:19:28,700
This is what we'll do in the next tutorial,
449

449

00:19:28,700  -->  00:19:31,150
but because you get to this next tutorial,
450

450

00:19:31,150  -->  00:19:32,500
try to figure out some ideas
451

451

00:19:32,500  -->  00:19:34,910
to improve that and reach these goals.
452

452

00:19:34,910  -->  00:19:36,080
And I'll give you a hint.
453

453

00:19:36,080  -->  00:19:37,990
The answer to this improvement
454

454

00:19:37,990  -->  00:19:40,120
is in the title of this course.
455

455

00:19:40,120  -->  00:19:43,260
So good luck, and I'll see you in the next tutorial.
456

456

00:19:43,260  -->  00:19:44,953
Until then, enjoy Deep Learning.
