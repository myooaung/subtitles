1
1

00:00:00,380  -->  00:00:03,060
<v ->Hello and welcome to this Python tutorial.</v>
2

2

00:00:03,060  -->  00:00:05,310
Alright, we completed two steps out of four,
3

3

00:00:05,310  -->  00:00:08,390
and today is about the third step, Flattening.
4

4

00:00:08,390  -->  00:00:10,870
So this step is a crucial step to understand,
5

5

00:00:10,870  -->  00:00:13,140
because basically this step consists
6

6

00:00:13,140  -->  00:00:15,760
of taking all our Pooled Feature Maps
7

7

00:00:15,760  -->  00:00:18,660
and put them into one single vector.
8

8

00:00:18,660  -->  00:00:20,490
This is going to be a huge vector of course
9

9

00:00:20,490  -->  00:00:23,490
because even if we reduced the size of the Feature Maps
10

10

00:00:23,490  -->  00:00:24,980
and divided them by two,
11

11

00:00:24,980  -->  00:00:27,510
well we still have many Pooled Feature Maps.
12

12

00:00:27,510  -->  00:00:29,650
So to summarize, we have all our Feature Maps
13

13

00:00:29,650  -->  00:00:32,900
in the Pooling Layer, we apply the Flattening Step
14

14

00:00:32,900  -->  00:00:35,830
and we get this huge single vector
15

15

00:00:35,830  -->  00:00:37,410
that contains all different cells
16

16

00:00:37,410  -->  00:00:39,380
of of all the different Feature Maps.
17

17

00:00:39,380  -->  00:00:40,850
And this single vector is going to be
18

18

00:00:40,850  -->  00:00:43,760
the Input Layer of a future ANN,
19

19

00:00:43,760  -->  00:00:46,340
the ANN that we know from the previous section
20

20

00:00:46,340  -->  00:00:50,080
that is a classic ANN with Fully Connected Layers.
21

21

00:00:50,080  -->  00:00:53,810
Now we can ask ourselves to very important questions.
22

22

00:00:53,810  -->  00:00:56,490
The first question is, why don't we lose
23

23

00:00:56,490  -->  00:00:58,910
the spacial structure by Flattening
24

24

00:00:58,910  -->  00:01:02,070
all these Feature Maps into one same, single vector.
25

25

00:01:02,070  -->  00:01:03,110
And the answer is,
26

26

00:01:03,110  -->  00:01:05,680
that's because by creating our Feature Maps,
27

27

00:01:05,680  -->  00:01:08,740
we extracted the spatial structure informations,
28

28

00:01:08,740  -->  00:01:10,800
by, you know, by getting these high numbers
29

29

00:01:10,800  -->  00:01:13,140
in the Feature Maps, thanks to the Feature Detector
30

30

00:01:13,140  -->  00:01:15,280
that we applied on the Input Image
31

31

00:01:15,280  -->  00:01:17,000
through the Convolution Step.
32

32

00:01:17,000  -->  00:01:19,500
So basically these high numbers represent
33

33

00:01:19,500  -->  00:01:21,810
the spatial structure of our images
34

34

00:01:21,810  -->  00:01:24,300
because these high numbers in the Feature Maps
35

35

00:01:24,300  -->  00:01:28,230
are associated to a specific feature in the input image.
36

36

00:01:28,230  -->  00:01:30,210
And since then, we apply the Max Pooling Step,
37

37

00:01:30,210  -->  00:01:33,380
we keep these high numbers because we take the Max.
38

38

00:01:33,380  -->  00:01:35,400
And then the Flattening Step just consists
39

39

00:01:35,400  -->  00:01:37,350
of putting all the numbers in the cells
40

40

00:01:37,350  -->  00:01:39,950
of the Feature Maps into one, same, single vector.
41

41

00:01:39,950  -->  00:01:42,060
Well we still keep these high numbers
42

42

00:01:42,060  -->  00:01:44,760
in this one, single vector and since these high numbers
43

43

00:01:44,760  -->  00:01:47,830
represent the spatial structure of the Input Image
44

44

00:01:47,830  -->  00:01:50,090
and are associated to one specific feature
45

45

00:01:50,090  -->  00:01:51,550
of this spatial structure,
46

46

00:01:51,550  -->  00:01:54,600
well, we keep this spatial structure information,
47

47

00:01:54,600  -->  00:01:57,520
even in this one, huge, single vector.
48

48

00:01:57,520  -->  00:01:59,160
And now the second question is,
49

49

00:01:59,160  -->  00:02:01,580
why didn't we directly take all the pixels
50

50

00:02:01,580  -->  00:02:03,660
of the Input Image and Flatten them
51

51

00:02:03,660  -->  00:02:05,970
into this one, same, single vector, you know,
52

52

00:02:05,970  -->  00:02:07,700
without applying the previous steps,
53

53

00:02:07,700  -->  00:02:10,140
the Convolution Step and Max Pooling Step?
54

54

00:02:10,140  -->  00:02:12,460
Well, that's because if we directly Flatten
55

55

00:02:12,460  -->  00:02:13,850
the Input Image pixels
56

56

00:02:13,850  -->  00:02:16,300
into this huge, single, one-dimensional vector,
57

57

00:02:16,300  -->  00:02:18,070
then each node of this huge vector
58

58

00:02:18,070  -->  00:02:20,350
will represent one pixel of the Image,
59

59

00:02:20,350  -->  00:02:23,010
independently of the pixels that are around it.
60

60

00:02:23,010  -->  00:02:25,800
So we only get informations of the pixel itself,
61

61

00:02:25,800  -->  00:02:28,513
and we don't get informations of how this pixel
62

62

00:02:28,513  -->  00:02:31,642
is spatially connected to the other pixels around it.
63

63

00:02:31,642  -->  00:02:34,155
So basically, we don't get any information
64

64

00:02:34,155  -->  00:02:37,310
of the spatial structure around this pixel.
65

65

00:02:37,310  -->  00:02:40,330
However, if we apply the Convolution Step
66

66

00:02:40,330  -->  00:02:42,320
and the Max Pooling Step to create
67

67

00:02:42,320  -->  00:02:44,620
all the reduced size Feature Maps,
68

68

00:02:44,620  -->  00:02:46,800
and Flatten all these Feature Maps into this
69

69

00:02:46,800  -->  00:02:49,130
huge, single, one-dimensional vector,
70

70

00:02:49,130  -->  00:02:51,500
then since each Feature Map corresponds
71

71

00:02:51,500  -->  00:02:53,870
to one specific feature of the image,
72

72

00:02:53,870  -->  00:02:55,780
then each node of this huge vector
73

73

00:02:55,780  -->  00:02:58,210
that contains a high number, will represent
74

74

00:02:58,210  -->  00:03:00,440
the information of a specific feature,
75

75

00:03:00,440  -->  00:03:03,020
a specific detail of the Input Image,
76

76

00:03:03,020  -->  00:03:06,280
like for example, the upper left border of a dog nose.
77

77

00:03:06,280  -->  00:03:07,880
And that is because this high number
78

78

00:03:07,880  -->  00:03:10,560
doesn't represent a unique pixel by itself.
79

79

00:03:10,560  -->  00:03:13,040
It represents the study specific feature,
80

80

00:03:13,040  -->  00:03:14,890
that the Feature Detector could extract
81

81

00:03:14,890  -->  00:03:18,260
from the Input Image, through the Convolution Operation.
82

82

00:03:18,260  -->  00:03:20,090
And therefore eventually, we keep
83

83

00:03:20,090  -->  00:03:23,600
the spatial structure information of the Input Image.
84

84

00:03:23,600  -->  00:03:25,140
So now, let's go back to Spyder
85

85

00:03:25,140  -->  00:03:28,060
and let's take care of this Flattening Step.
86

86

00:03:28,060  -->  00:03:30,810
So as usual, we're gonna take our classifier,
87

87

00:03:30,810  -->  00:03:33,880
and copy it and paste it here
88

88

00:03:33,880  -->  00:03:37,060
and then dot to introduce the add method,
89

89

00:03:37,060  -->  00:03:40,530
that we still use to create this new layer,
90

90

00:03:40,530  -->  00:03:42,770
well this huge, single vector.
91

91

00:03:42,770  -->  00:03:45,850
And so parentheses and inside these parentheses,
92

92

00:03:45,850  -->  00:03:48,590
we're gonna use a new function that we haven't used before.
93

93

00:03:48,590  -->  00:03:52,070
And that is as you might have guessed, the Flatten Function.
94

94

00:03:52,070  -->  00:03:55,410
This is the function that will flatten all the Feature Maps
95

95

00:03:55,410  -->  00:03:58,560
in the Pooling Layer into this huge, single vector.
96

96

00:03:58,560  -->  00:04:03,010
So let's input this function, Flatten, spell this way,
97

97

00:04:03,010  -->  00:04:05,930
and then some parentheses of course because it's a function.
98

98

00:04:05,930  -->  00:04:08,210
But then the good news is, that we don't need to input
99

99

00:04:08,210  -->  00:04:11,480
any parameters here because Keras will understand that,
100

100

00:04:11,480  -->  00:04:13,860
you know, since we're taking a classifier object,
101

101

00:04:13,860  -->  00:04:16,253
that it needs to Flatten the previous layer
102

102

00:04:16,253  -->  00:04:19,230
that we obtain here, after the Convolution Step
103

103

00:04:19,230  -->  00:04:20,700
and the Max Pooling Step.
104

104

00:04:20,700  -->  00:04:22,440
So we're all good, we just need
105

105

00:04:22,440  -->  00:04:25,230
to select this line and execute,
106

106

00:04:25,230  -->  00:04:29,620
to complete the Flattening Step and everything is all good.
107

107

00:04:29,620  -->  00:04:31,800
Now this huge, single vector is created
108

108

00:04:31,800  -->  00:04:33,500
and basically it contains all the informations
109

109

00:04:33,500  -->  00:04:36,300
of the spatial structure of your images.
110

110

00:04:36,300  -->  00:04:38,300
And so now what we only have to do left,
111

111

00:04:38,300  -->  00:04:42,870
is to create a classic ANN, that will classify the images,
112

112

00:04:42,870  -->  00:04:45,900
and it will classify them well thanks to this Input Vector,
113

113

00:04:45,900  -->  00:04:48,960
that contains the informations of the spatial structure.
114

114

00:04:48,960  -->  00:04:51,140
So three steps down, one more to go
115

115

00:04:51,140  -->  00:04:54,020
and we will be done with our Convolutional Neural Network,
116

116

00:04:54,020  -->  00:04:56,000
all ready in the the next tutorial.
117

117

00:04:56,000  -->  00:04:57,660
So I look forward to seeing you there,
118

118

00:04:57,660  -->  00:04:59,543
and until then, enjoy Deep Learning.
