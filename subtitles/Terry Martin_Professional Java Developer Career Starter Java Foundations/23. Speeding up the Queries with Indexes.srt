1
00:00:00,480 --> 00:00:01,410
Hey, welcome back.

2
00:00:01,740 --> 00:00:09,270
So in the last lesson, we loaded up all five million records of our test data file into a real database,

3
00:00:09,270 --> 00:00:13,170
and we allowed them to persist by committing them via a test.

4
00:00:13,410 --> 00:00:18,480
Now that test method that we wrote wasn't a real test because we made no assertions.

5
00:00:18,570 --> 00:00:25,020
We were really just using the mechanisms of a test class as a convenient place for us to execute some

6
00:00:25,020 --> 00:00:28,230
code that is basically meant to only be run probably once.

7
00:00:28,800 --> 00:00:34,470
So now that we've got those five million records loaded into the database, I want to focus on a topic

8
00:00:34,470 --> 00:00:40,950
that I don't think enough beginner and maybe even intermediate developers focus on, and that is database

9
00:00:40,950 --> 00:00:41,970
optimization.

10
00:00:42,270 --> 00:00:44,820
Now, don't worry, we're not going to go very deep into this.

11
00:00:44,980 --> 00:00:50,940
They're really just one or two really basic things that we can do when working with a database to vastly

12
00:00:50,940 --> 00:00:53,550
improve the performance of that database.

13
00:00:53,730 --> 00:00:55,920
So let's take a look at some of those options now.

14
00:00:56,280 --> 00:00:56,560
All right.

15
00:00:56,580 --> 00:01:03,450
So turning back into Squirrel, I'm going to go back in to our people test database and connect to it.

16
00:01:04,410 --> 00:01:04,860
All right.

17
00:01:05,190 --> 00:01:10,350
So the first thing I want to do is to find some records in this database that are kind of towards the

18
00:01:10,350 --> 00:01:11,730
end of the database.

19
00:01:11,730 --> 00:01:17,250
OK, so we loaded five million records in and we already had like 11 records in there before.

20
00:01:17,430 --> 00:01:20,610
So I want to query the database for at least one record.

21
00:01:20,610 --> 00:01:23,490
That's kind of towards the end of those five million records.

22
00:01:23,790 --> 00:01:30,960
And the way that we can do that is with a select query, so we can do select star from people.

23
00:01:31,620 --> 00:01:36,630
But now what we want to do is we want to skip past a lot of records.

24
00:01:36,750 --> 00:01:40,740
In fact, I'm thinking basically, we want to skip past around five million records or so.

25
00:01:40,920 --> 00:01:48,030
So just as in Java, where we can use the skip function of the streams, API databases have a similar

26
00:01:48,030 --> 00:01:49,260
capability as well.

27
00:01:49,410 --> 00:01:56,130
Now again, each database engine may have a slightly different version of sequel that they used to be

28
00:01:56,130 --> 00:02:00,420
able to specify this, so you'll have to consult whatever database you're using.

29
00:02:00,600 --> 00:02:05,360
But with H2 database, we can use the offset keyword.

30
00:02:05,430 --> 00:02:05,850
OK.

31
00:02:06,060 --> 00:02:11,520
And then we can just provided a number to tell it how many records we want it to offset or skip over,

32
00:02:11,520 --> 00:02:12,210
essentially.

33
00:02:12,420 --> 00:02:15,270
So I'm going to tell it to skip over five million records.

34
00:02:17,220 --> 00:02:18,150
Six zeros.

35
00:02:18,180 --> 00:02:18,630
OK.

36
00:02:19,260 --> 00:02:22,710
And then from here, we can tell it once you get to that point.

37
00:02:22,920 --> 00:02:25,020
Just fetch like one record.

38
00:02:25,320 --> 00:02:30,150
So then we can say fetch first one row only.

39
00:02:30,180 --> 00:02:35,310
OK, so let me jump into the idea real quick, because I just want you to understand that a lot of these

40
00:02:35,310 --> 00:02:42,210
concepts that we're going to see in the database have analogs to the streams API or various other things

41
00:02:42,210 --> 00:02:44,220
that we do in Java in general, OK?

42
00:02:44,490 --> 00:02:54,650
So this offset five million here would be equivalent to us here in Java code doing skip five million

43
00:02:54,660 --> 00:02:55,830
like so OK.

44
00:02:56,250 --> 00:03:05,220
And then this fetch first one row is equivalent to saying limit one.

45
00:03:06,060 --> 00:03:06,370
Right?

46
00:03:06,390 --> 00:03:09,420
So there are analogs to a lot of these concepts.

47
00:03:09,570 --> 00:03:09,930
All right.

48
00:03:10,080 --> 00:03:11,170
Let me on do that, though.

49
00:03:11,190 --> 00:03:13,590
I'm just showing you that for illustrative purposes.

50
00:03:14,310 --> 00:03:17,800
OK, so let's go ahead and run this and see what we get.

51
00:03:17,820 --> 00:03:21,930
And I want you to pay attention to how long it takes for this to execute as well.

52
00:03:22,170 --> 00:03:23,250
And I'm going to go now.

53
00:03:28,160 --> 00:03:30,620
OK, so now that we found this record.

54
00:03:30,980 --> 00:03:37,610
The reason I had to do this is because I really wanted to get at one of the IDs of a record that's toward

55
00:03:37,610 --> 00:03:39,230
the bottom of this table.

56
00:03:39,260 --> 00:03:42,890
OK, so now I want to do something very similar to this.

57
00:03:43,130 --> 00:03:52,910
Let's query for this record by its I.D. So we'll do a select star from people where ID equals, and

58
00:03:52,910 --> 00:03:59,240
then I can come down here and click on that ID value and copy and then I can paste it.

59
00:04:00,340 --> 00:04:00,700
OK.

60
00:04:01,120 --> 00:04:06,520
And let's run that with a control return, or don't forget, you can also click the little thing there,

61
00:04:06,520 --> 00:04:08,690
but keyboard shortcuts are your friend.

62
00:04:08,710 --> 00:04:09,940
They make you go faster.

63
00:04:10,390 --> 00:04:10,750
All right.

64
00:04:10,780 --> 00:04:11,980
So let's run that.

65
00:04:13,380 --> 00:04:16,020
And again, let's note how long that took.

66
00:04:16,050 --> 00:04:19,290
OK, so that took two and a half seconds.

67
00:04:19,380 --> 00:04:23,370
So pretty much the same, in fact, took a little bit longer in this particular case.

68
00:04:23,790 --> 00:04:24,030
All right.

69
00:04:24,060 --> 00:04:27,840
So basically the same amount of time as the previous query.

70
00:04:28,230 --> 00:04:29,310
So here's the problem.

71
00:04:29,490 --> 00:04:34,650
Two and a half seconds might seem like it's pretty fast considering that we're iterating over five million

72
00:04:34,650 --> 00:04:35,160
rows.

73
00:04:35,460 --> 00:04:39,850
But in actuality, that is really quite slow for a database.

74
00:04:39,870 --> 00:04:45,510
If this database with these five million records were being used in an application or on the web or

75
00:04:45,510 --> 00:04:51,030
something like that, and we had lots of users who were all trying to do the equivalent of this more

76
00:04:51,030 --> 00:04:55,710
or less simultaneously, those two and a half second start to add up pretty quickly.

77
00:04:55,890 --> 00:05:01,890
And keep in mind every time the computer has to take two and a half seconds to go find one record,

78
00:05:02,040 --> 00:05:07,110
that's time that the processor in that computer isn't available to do other things right.

79
00:05:07,560 --> 00:05:09,120
So this is actually pretty bad.

80
00:05:09,480 --> 00:05:12,900
Now let me help you to get an understanding of why this is so slow.

81
00:05:13,230 --> 00:05:20,610
We've got a sample of our rows here, and when we tell the database to go find a record with some ID,

82
00:05:20,730 --> 00:05:24,090
let's pretend like this employee ID is our ID card.

83
00:05:24,090 --> 00:05:28,020
Even though it's not, we didn't actually bring that data over, but let's pretend like we did.

84
00:05:28,410 --> 00:05:34,110
And until we tell the computer, go find record four one eight three nine zero.

85
00:05:34,560 --> 00:05:42,480
In this particular case, the database had to actually scan over every single row checking to see if

86
00:05:42,480 --> 00:05:46,860
the ID matched what we passed in as a parameter until it finds a match.

87
00:05:47,190 --> 00:05:54,150
And because we chose a record that's almost near the very bottom of the table, the database essentially

88
00:05:54,150 --> 00:05:59,580
had to perform what's called a full table scan, meaning just that it had to scan through every single

89
00:05:59,580 --> 00:06:02,580
record in the table in order to find that record.

90
00:06:02,970 --> 00:06:06,870
Now, some of you may be thinking, Well, isn't that what a database would have to do anyway?

91
00:06:06,900 --> 00:06:12,600
How else could it find that record other than to scan through the entire table looking for it?

92
00:06:13,380 --> 00:06:19,710
Well, we actually learned some techniques back in our collections module that would help us to understand

93
00:06:19,710 --> 00:06:25,020
how a database could potentially find that record a lot faster than what it just did now.

94
00:06:25,500 --> 00:06:31,530
If you recall, back in the collections module, we learned about hashes and sets and hash maps.

95
00:06:31,890 --> 00:06:37,230
And one of the things that we learned about the hash map or even just maps in general, is the fact

96
00:06:37,230 --> 00:06:44,820
that when we store a key and a value pair in a map, the hash map implementation of the map interface

97
00:06:45,060 --> 00:06:51,540
has the ability to analyze the key that we're inserting into that key value pair entry and generate

98
00:06:51,540 --> 00:06:53,610
a hash code for that key.

99
00:06:53,640 --> 00:07:01,680
The hash map will then use that hash code to determine where in a table that entry should go.

100
00:07:01,920 --> 00:07:07,770
So the next time you try to retrieve a value out of the hash map using that key, the hash map doesn't

101
00:07:07,770 --> 00:07:11,520
have to iterate over every single entry in that map.

102
00:07:11,760 --> 00:07:14,610
Instead, it takes your key that you provided.

103
00:07:14,730 --> 00:07:21,960
It regenerates a hash code for it, and then it uses that hash code to determine an index into a table

104
00:07:21,960 --> 00:07:25,200
where your record exists or where your entry exists.

105
00:07:25,380 --> 00:07:28,290
And then it can much more efficiently go straight to that entry.

106
00:07:28,290 --> 00:07:34,560
Or at least it can get super super close if there happened to be collisions where other entries yield

107
00:07:34,560 --> 00:07:35,790
the same index.

108
00:07:36,060 --> 00:07:41,700
But it can cut down a lot on the amount of scanning that has to be done to find your entry.

109
00:07:41,880 --> 00:07:45,630
And in this example, entry and record are essentially the same thing.

110
00:07:46,140 --> 00:07:52,530
Well, it just so happens that databases can use very similar types of tricks, and they are optimized

111
00:07:52,530 --> 00:07:55,020
to do so if you help them out.

112
00:07:55,350 --> 00:08:01,830
So databases have an ability to generate what is called an index, and you can basically just think

113
00:08:01,830 --> 00:08:04,020
of the creation of an index on a table.

114
00:08:04,170 --> 00:08:10,590
Very similarly to a hash map generating hash codes that lead to indexes for records and a hash maps

115
00:08:10,590 --> 00:08:13,560
internal table very similar concepts.

116
00:08:13,560 --> 00:08:18,690
I wouldn't be surprised if a lot of databases essentially use almost the exact same mechanisms, in

117
00:08:18,690 --> 00:08:19,110
fact.

118
00:08:19,230 --> 00:08:26,220
So the key here is that if you want to be able to look up records in a database more quickly, you need

119
00:08:26,220 --> 00:08:32,940
to consider generating what is called an index for the particular column that you're going to be searching

120
00:08:32,940 --> 00:08:33,300
by.

121
00:08:33,390 --> 00:08:37,950
So in our case, we just searched for one record by ID.

122
00:08:38,550 --> 00:08:43,350
But the problem is that currently we do not have an index on the ID column.

123
00:08:43,440 --> 00:08:47,700
And in fact, in this people table, we don't have any indexes defined at all.

124
00:08:47,730 --> 00:08:53,760
Now, when we created this table, I intentionally left out any possibility for an index to be generated

125
00:08:54,000 --> 00:08:55,290
for a couple of reasons.

126
00:08:55,620 --> 00:09:00,630
Number one, I wanted to be able to teach this concept and show you what happens when you don't have

127
00:09:00,630 --> 00:09:01,280
indexes.

128
00:09:01,290 --> 00:09:02,220
Things are slow.

129
00:09:02,550 --> 00:09:05,910
And there's another reason that I'll get to a little bit later in this lesson.

130
00:09:06,300 --> 00:09:06,630
OK.

131
00:09:06,780 --> 00:09:11,370
So first off, I want to just show you the lack of index on this people table.

132
00:09:11,610 --> 00:09:12,590
So if we jump over here?

133
00:09:12,740 --> 00:09:19,670
Who the objects tab and then jump into the people test icon here, I'm just double clicking on that

134
00:09:19,670 --> 00:09:26,120
and then double clicking on public and then double clicking on table and then clicking on people here.

135
00:09:26,150 --> 00:09:31,520
So this represents the people table, and then we can click on this Indexes tab here.

136
00:09:31,940 --> 00:09:35,240
And what you'll see is there are no rows in here at all.

137
00:09:35,240 --> 00:09:40,640
So that's just letting us know that the people table currently has no index as defined on it.

138
00:09:40,670 --> 00:09:41,050
OK.

139
00:09:41,300 --> 00:09:41,540
All right.

140
00:09:41,540 --> 00:09:44,270
So now we'll jump back over to the school tab.

141
00:09:44,540 --> 00:09:52,640
So let's go ahead now and actually create an index for the ID column and see if that has any effect

142
00:09:52,640 --> 00:09:55,490
on how the database is performing some of our queries.

143
00:09:55,940 --> 00:09:56,240
All right.

144
00:09:56,250 --> 00:10:04,490
So to create an index, I will go down to a new line and we can use this command, create index and

145
00:10:04,490 --> 00:10:09,340
then we need to provide a name for the index and I'm inclined to call this index.

146
00:10:09,350 --> 00:10:14,510
I'd underscore index, meaning it's the index for the ID column.

147
00:10:14,810 --> 00:10:18,830
Then we have to specify what column we are applying this index to.

148
00:10:19,220 --> 00:10:25,280
So we'll say on people table idea column like that.

149
00:10:26,710 --> 00:10:28,150
And then we'll execute this.

150
00:10:30,320 --> 00:10:32,450
Now, notice this is taking a little while.

151
00:10:33,620 --> 00:10:34,070
All right.

152
00:10:34,220 --> 00:10:37,280
So that actually took six point six seconds.

153
00:10:37,820 --> 00:10:41,270
I want you to make note of the fact that that took six point six seconds.

154
00:10:41,540 --> 00:10:47,960
The reason that took so long is because when we create an index on a column and a database with five

155
00:10:47,960 --> 00:10:54,080
million records, what's happening is that the database is having to go through the ID column values

156
00:10:54,080 --> 00:10:57,990
on all five million of those records to generate its index.

157
00:10:58,020 --> 00:11:01,340
OK, so it has to do some analysis in order to be able to do this.

158
00:11:01,640 --> 00:11:07,820
So you can imagine again going back to the hash map example where the hash map itself has to generate

159
00:11:07,820 --> 00:11:14,690
a hash code and then figure out what index to generate from that hash code so that subsequent lookups

160
00:11:14,690 --> 00:11:17,450
into the hash table will be fast, right?

161
00:11:17,450 --> 00:11:23,180
Because it can just jump straight from a key to a hash map to an index and then go straight to that

162
00:11:23,180 --> 00:11:23,840
row, right?

163
00:11:24,110 --> 00:11:29,510
The database, again, is doing very similar types of things here, but that does take a little while

164
00:11:29,510 --> 00:11:32,660
to generate on five million records initially.

165
00:11:32,900 --> 00:11:33,220
All right.

166
00:11:33,230 --> 00:11:37,880
So now that we've created this index, let's jump back over to the Objects tab.

167
00:11:37,910 --> 00:11:38,250
All right.

168
00:11:38,270 --> 00:11:44,000
And then if we right click on this people table and we can refresh item?

169
00:11:44,930 --> 00:11:45,680
There we go.

170
00:11:46,220 --> 00:11:49,580
And so now we have one record under the Indexes tab.

171
00:11:49,850 --> 00:11:57,380
And you may have to put your cursor in between these headers here to make room if you can't see everything

172
00:11:57,380 --> 00:11:57,620
there.

173
00:11:57,620 --> 00:12:03,830
But we're in the people test database, and it's just saying that we created an index that is called

174
00:12:03,860 --> 00:12:08,960
ID underscore ADX, and it is for the first column.

175
00:12:09,410 --> 00:12:12,170
Column one, which is the ID column.

176
00:12:12,170 --> 00:12:13,400
That's the column name.

177
00:12:13,430 --> 00:12:19,700
OK, so the main point I want to show here is that now we have an index created for the people table.

178
00:12:20,090 --> 00:12:20,360
All right.

179
00:12:20,360 --> 00:12:26,420
So now going back over to the sequel tab, let's try querying for this record now.

180
00:12:26,540 --> 00:12:30,410
OK, so I'm going to just put my cursor right back here and then just rerun this.

181
00:12:32,720 --> 00:12:38,360
And now you might have noticed that that came back pretty much instantaneously, and in fact, if we

182
00:12:38,360 --> 00:12:42,260
come down here, we see that that took point zero zero one seconds, right?

183
00:12:42,410 --> 00:12:48,380
What is that 10, 100 hundred one one thousandth of a second, which I think is one millisecond now

184
00:12:48,410 --> 00:12:54,200
to make sure that this is really working and not just like some kind of cached data caching means once

185
00:12:54,200 --> 00:12:58,820
you've retrieved one record, it's kind of stored for faster retrieval than the next time.

186
00:12:58,820 --> 00:13:02,810
So let's make sure we're not just benefiting from that type of caching trick.

187
00:13:03,140 --> 00:13:09,930
So we can actually just increase this number on here from from ending in a seven to ending in an eight.

188
00:13:09,950 --> 00:13:10,610
Like so.

189
00:13:10,790 --> 00:13:14,000
So we'll get a fresh new record and then let's run that.

190
00:13:15,020 --> 00:13:17,930
And that also took one one thousandth of a second.

191
00:13:18,140 --> 00:13:23,600
And we're going to find now that in general, everything is going to be really, really fast.

192
00:13:24,410 --> 00:13:28,010
In fact, that one showed up as only having taken zero seconds.

193
00:13:28,010 --> 00:13:31,670
So I guess it was so fast that it didn't even register as a millisecond.

194
00:13:31,760 --> 00:13:39,740
So just by creating that index on the ID column, we were able to vastly increase the speed at which

195
00:13:39,740 --> 00:13:42,950
we're able to query for a specific row by ID.

196
00:13:43,580 --> 00:13:45,260
Now, having shown you that?

197
00:13:45,380 --> 00:13:46,610
Let me show you this, though.

198
00:13:46,700 --> 00:13:53,810
So down here in the data, we have retrieved a record with that ID and the last name of Durkee.

199
00:13:54,020 --> 00:14:00,260
Let's try selecting the same record, but instead of searching by ID, let's search by the email address

200
00:14:00,260 --> 00:14:01,730
and see how that performs.

201
00:14:01,850 --> 00:14:10,640
So I'll do a select everything from people where email equals, and then I'll come down here and right

202
00:14:10,640 --> 00:14:15,590
click and copy that and then come up here and paste that.

203
00:14:16,010 --> 00:14:22,360
And remember, now in most databases, we surround strings with single ticks, not double ticks.

204
00:14:22,400 --> 00:14:22,790
OK.

205
00:14:23,000 --> 00:14:23,420
All right.

206
00:14:23,540 --> 00:14:24,920
So now let's run this.

207
00:14:26,400 --> 00:14:27,330
Oh, look at that.

208
00:14:27,360 --> 00:14:29,280
We're back to it being slow again.

209
00:14:29,520 --> 00:14:34,440
How long did that take two and a half seconds, just like it was before we created an index?

210
00:14:35,040 --> 00:14:36,720
Are any of you confused about this?

211
00:14:36,730 --> 00:14:37,540
You shouldn't be.

212
00:14:37,560 --> 00:14:39,860
But, but it's OK if you are all right.

213
00:14:39,870 --> 00:14:44,130
So why did that take so much longer, even though we've created this index?

214
00:14:44,670 --> 00:14:52,500
The reason is because our index is specifically for the ID column, and now we're not querying by ID

215
00:14:52,710 --> 00:14:53,230
anymore.

216
00:14:53,250 --> 00:14:55,770
Now we just queried by email address.

217
00:14:56,040 --> 00:15:02,010
So this is an important point for you to understand when we create an index on a table.

218
00:15:02,310 --> 00:15:05,910
That index is typically specific for a column.

219
00:15:06,060 --> 00:15:11,670
Now, some databases may support complex indexes that are based on a combination of columns.

220
00:15:11,910 --> 00:15:16,590
We won't be getting into that, but here we are no longer querying by ID.

221
00:15:16,920 --> 00:15:19,100
We're querying by email address.

222
00:15:19,110 --> 00:15:26,400
And so if we want this to perform fast, we need to create another index specifically for the email

223
00:15:26,400 --> 00:15:26,970
column.

224
00:15:27,150 --> 00:15:29,820
So let's go ahead and do that just to prove it.

225
00:15:30,360 --> 00:15:38,070
So create index, and I will call this one email underscore IDEX on people.

226
00:15:39,320 --> 00:15:45,500
Parentheses, email, close parentheses and then return, and let's pay attention to how long this may

227
00:15:45,500 --> 00:15:45,890
take.

228
00:15:49,770 --> 00:15:56,700
Wow, look at that that took almost 15 seconds to generate the index on the email column.

229
00:15:57,000 --> 00:15:58,800
Why did that take so much longer, by the way?

230
00:15:59,160 --> 00:16:03,840
Now I'm not a database expert, but I'm pretty sure it has a lot to do with the fact that the email

231
00:16:03,840 --> 00:16:10,950
addresses are somewhat complex strings with more characters in them than an ID column that is really

232
00:16:10,950 --> 00:16:11,790
just numbers.

233
00:16:11,820 --> 00:16:12,240
OK.

234
00:16:12,630 --> 00:16:19,560
So I think you may find in many database engines that the more complex the data of a column is, the

235
00:16:19,560 --> 00:16:23,580
longer it may take to initially create the index on that column.

236
00:16:23,670 --> 00:16:28,020
OK, but now that we've got that, let's go try this again.

237
00:16:28,410 --> 00:16:34,470
So I'm putting my cursor back here on this query and I'm on a search and I'm going to execute this.

238
00:16:35,280 --> 00:16:38,550
And now that came back in one one thousandth of a second.

239
00:16:38,760 --> 00:16:43,800
And again, now, just to make sure that's not some fluke of caching, let's query the database for

240
00:16:43,800 --> 00:16:48,060
a few records so that we can get a few unique email addresses for them.

241
00:16:48,090 --> 00:16:54,750
OK, so I'm going to go back up here to this first line, and instead of retrieving just one row, let's

242
00:16:54,750 --> 00:16:56,760
retrieve 10 rows.

243
00:16:57,090 --> 00:16:58,230
So let's run that.

244
00:16:59,460 --> 00:17:06,350
OK, so now we've got our ten rows here, and we've got lots of e-mail addresses to work with, right?

245
00:17:06,360 --> 00:17:09,510
And there's Jeff Durkee there, so we will avoid him.

246
00:17:09,750 --> 00:17:12,960
So let's try this second to last one, Merl Rufus.

247
00:17:13,470 --> 00:17:15,930
Someone to grab that copy.

248
00:17:16,590 --> 00:17:19,890
Come up here and replace Jeff with Merle.

249
00:17:22,330 --> 00:17:23,080
All right.

250
00:17:23,320 --> 00:17:28,540
And now let's run that look at that essentially instantaneous.

251
00:17:28,960 --> 00:17:31,330
So these indexes are invaluable.

252
00:17:31,360 --> 00:17:37,660
Now you may be thinking, OK, well then we should probably just generate indexes on every single column,

253
00:17:37,660 --> 00:17:40,310
in every database table every time.

254
00:17:40,330 --> 00:17:40,600
Right?

255
00:17:41,260 --> 00:17:42,580
Well, not so quick.

256
00:17:44,340 --> 00:17:47,040
With great power comes great responsibility.

257
00:17:47,670 --> 00:17:50,520
And these indexes come at a cost.

258
00:17:50,700 --> 00:17:56,460
So we don't necessarily just want to automatically generate indexes on every single column in every

259
00:17:56,460 --> 00:17:57,180
single table.

260
00:17:57,660 --> 00:18:03,330
The key to figuring this out is to understand how our database applications will be utilized.

261
00:18:03,600 --> 00:18:10,470
So we have to ask ourselves questions like in what ways are our users most likely to search for and

262
00:18:10,470 --> 00:18:11,340
query data?

263
00:18:11,760 --> 00:18:19,050
For example, if we have an application that allows people to enter an ID to look up some kind of data

264
00:18:19,050 --> 00:18:24,030
or record, well, then you know, you're certainly going to have to be querying the database by ID

265
00:18:24,270 --> 00:18:25,920
for those particular records.

266
00:18:26,100 --> 00:18:31,710
And since you know that for certain, you'll definitely want to have an index generated on that particular

267
00:18:31,710 --> 00:18:39,040
column and any other columns that users are likely to specifically search by or grouping by.

268
00:18:39,060 --> 00:18:43,200
Remember, when we learned in the Streams API how we could group by a particular column?

269
00:18:43,440 --> 00:18:46,140
Databases can allow us to do group buys as well.

270
00:18:46,290 --> 00:18:52,770
So any of these key types of columns where you're going to search by or group by or sorting on any of

271
00:18:52,770 --> 00:18:57,030
those types of columns, you will likely want to have an index generated on them.

272
00:18:57,450 --> 00:18:58,750
But here's the cost.

273
00:18:58,770 --> 00:19:07,320
When you have indexes generated on columns in a table and then you insert records into the table, inserts

274
00:19:07,320 --> 00:19:13,770
and updates can take longer now because now every time you do an insert or potentially even an update,

275
00:19:13,950 --> 00:19:20,010
the database will certainly have to do its analysis and re indexing, potentially on inserts.

276
00:19:20,010 --> 00:19:26,070
And it may have to do it on updates, particularly if you modified a column that has an index on it.

277
00:19:26,220 --> 00:19:26,670
OK.

278
00:19:26,910 --> 00:19:33,300
So consider how we initially created the people table in the first place, and then we programmatically

279
00:19:33,300 --> 00:19:40,590
loaded all five million records in on my computer that took around 35 seconds with no index is there.

280
00:19:40,920 --> 00:19:47,310
If I had had indexes on the people table prior to us trying to load the five million records, it would

281
00:19:47,310 --> 00:19:48,150
have taken longer.

282
00:19:48,240 --> 00:19:49,650
Now I don't know how long it would have taken.

283
00:19:49,650 --> 00:19:53,250
I haven't actually tried it, but I can tell you now it would have taken longer.

284
00:19:53,580 --> 00:19:55,470
So that's another thing to keep in mind.

285
00:19:55,740 --> 00:20:00,360
If you're working on a project where, you know, right off the bat, you're going to need to load up

286
00:20:00,360 --> 00:20:02,400
an enormous number of records.

287
00:20:02,400 --> 00:20:06,120
And this is like brand new code and brand new database and everything.

288
00:20:06,360 --> 00:20:13,620
It may be worth considering to not have things like indexes defined and generated on that table initially,

289
00:20:13,710 --> 00:20:17,820
just so that you can quickly load up all of your data into the table.

290
00:20:18,030 --> 00:20:24,450
You can always come back later and then generate those indexes and certain other optimization objects

291
00:20:24,450 --> 00:20:26,250
on the table afterwards.

292
00:20:26,460 --> 00:20:31,920
So that's something definitely worth considering if you know you're going to have to turn around and

293
00:20:31,920 --> 00:20:35,670
load millions or billions of records into a database.

294
00:20:36,120 --> 00:20:36,360
All right.

295
00:20:36,370 --> 00:20:42,390
So maybe the last thing I want to say on this topic is I just want to point out I devised this course

296
00:20:42,390 --> 00:20:47,820
based largely on my observations over the years of some of the problem areas and weaknesses that I've

297
00:20:47,820 --> 00:20:50,460
seen in a lot of developers over the years.

298
00:20:51,120 --> 00:20:56,430
One of those key problems that I've noticed far too often when working with some other developers,

299
00:20:56,430 --> 00:21:02,730
particularly beginners and intermediate developers, is their lack of very, very basic, fundamental

300
00:21:02,730 --> 00:21:05,520
knowledge of things like databases.

301
00:21:05,850 --> 00:21:10,380
Now I am by no means a database expert, nor do I aspire to be one.

302
00:21:10,470 --> 00:21:12,780
There are a lot of different databases in the world.

303
00:21:12,960 --> 00:21:17,370
I don't care to become an expert at even one of them to a great degree.

304
00:21:17,640 --> 00:21:23,880
But there are some ADCs of databases that every developer really does need to understand.

305
00:21:23,970 --> 00:21:25,770
And this is definitely one of them.

306
00:21:25,890 --> 00:21:27,060
It's so basic.

307
00:21:27,300 --> 00:21:31,110
I can't tell you the number of times that I've worked with developers on projects.

308
00:21:31,650 --> 00:21:36,960
They've built an entire application and the people who use the application or the business.

309
00:21:36,960 --> 00:21:42,480
People who determine how the application should function complain about how slow it is every time they

310
00:21:42,480 --> 00:21:46,260
need to retrieve data or work with data in any in any way.

311
00:21:46,800 --> 00:21:53,340
And after just doing a few minutes of looking at the code and how things are working, I have multiple

312
00:21:53,340 --> 00:21:59,550
times asked developers, Did you guys create any indexes on any of the columns that are most commonly

313
00:21:59,550 --> 00:22:01,530
queried by and quite frequently?

314
00:22:01,650 --> 00:22:03,870
I'm not sure they even know what I'm talking about.

315
00:22:04,710 --> 00:22:05,700
That's not good.

316
00:22:06,090 --> 00:22:12,870
You just saw how easy it is to create an index for a particular row and how drastic the timing is when

317
00:22:12,870 --> 00:22:15,210
you don't have an index versus when you do.

318
00:22:15,450 --> 00:22:21,540
It's not a lot of effort to get a huge speed up in performance by simply creating an index.

319
00:22:21,570 --> 00:22:21,960
Right?

320
00:22:21,990 --> 00:22:28,020
So I'm just reiterating the fact that it is my hope and my desire that by taking this course, you will

321
00:22:28,020 --> 00:22:33,900
learn enough of the basics heads and shoulders over a lot of other developers, some of whom may have

322
00:22:33,900 --> 00:22:37,260
been working in the field for several years already.

323
00:22:37,500 --> 00:22:41,850
So, you know, this is a good example of where a little bit of knowledge can go a really long way.

324
00:22:42,270 --> 00:22:43,580
All right, so we're going to end.

325
00:22:43,630 --> 00:22:48,750
A lesson here and in the next lesson, we'll get into some other interesting things with the database.

326
00:22:48,990 --> 00:22:49,950
I'll see you in the next one.
