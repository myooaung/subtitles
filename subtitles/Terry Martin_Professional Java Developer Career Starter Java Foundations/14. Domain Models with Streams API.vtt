WEBVTT
1
00:00:00.480 --> 00:00:01.230
Welcome back.

2
00:00:01.560 --> 00:00:07.170
So in the last lesson, we did a little bit of review, and we also learned a little bit of new techniques

3
00:00:07.170 --> 00:00:12.540
with regard to how we could sum up the salary values, right?

4
00:00:12.810 --> 00:00:18.960
We ended it with somewhat of a review because we ended up just using a map to long, which you had already

5
00:00:18.960 --> 00:00:29.070
previously learned to convert the twenty fifth, the twenty fifth element of our array, which is the

6
00:00:29.070 --> 00:00:30.270
salary value.

7
00:00:30.570 --> 00:00:34.470
We converted that from a string into a long.

8
00:00:34.770 --> 00:00:41.940
And by using the map to long method here and because that map to long method returns a long stream,

9
00:00:41.940 --> 00:00:45.990
not a stream of lungs technically, but a long stream.

10
00:00:46.290 --> 00:00:54.000
Because it is a numerical stream, it has numerical methods on it, such as summing and averaging and

11
00:00:54.000 --> 00:00:54.750
things of that sort.

12
00:00:54.750 --> 00:00:55.710
So that was review.

13
00:00:56.520 --> 00:01:03.500
And then before we did all of that, we also learned how to do the same kind of thing using the Dot

14
00:01:03.600 --> 00:01:06.480
Collect method of the Streams API.

15
00:01:06.570 --> 00:01:12.900
And so here you can see that we are again using a long pass long and we're doing all of that there.

16
00:01:12.900 --> 00:01:15.150
But it's just a slightly different technique.

17
00:01:15.600 --> 00:01:22.590
And I think I mentioned already the reason we're showing these two different ways is because going forward,

18
00:01:22.590 --> 00:01:30.030
we'll be doing more advanced streams API things that can only be done with the collect method.

19
00:01:30.090 --> 00:01:36.780
OK, now in this lesson, before we proceed to learn these more advanced techniques, I want to address

20
00:01:36.780 --> 00:01:37.680
one quick thing.

21
00:01:37.830 --> 00:01:46.080
And that is the fact that in most of the previous lessons, we've been dealing with domain model classes

22
00:01:46.080 --> 00:01:52.740
or objects when whenever we're working with data in the Streams API or even before we learn the Streams

23
00:01:52.740 --> 00:01:53.100
API.

24
00:01:53.100 --> 00:01:59.790
When we were doing collections and things, we were reading data into model objects that were of type

25
00:01:59.790 --> 00:02:03.330
employee right in the last lesson.

26
00:02:03.480 --> 00:02:06.420
We didn't use a domain model class at all.

27
00:02:07.350 --> 00:02:10.530
We just used an array or a series of arrays.

28
00:02:10.830 --> 00:02:16.590
And the main reason that we did it that way was primarily because we didn't really need a domain model

29
00:02:16.590 --> 00:02:24.330
for what we were doing, which was simply adding up one element or one column of all of these arrays,

30
00:02:24.330 --> 00:02:24.720
right?

31
00:02:25.110 --> 00:02:31.950
However, we will learn as we start to explore more of the techniques of the Streams API that the Streams

32
00:02:31.950 --> 00:02:40.680
API lends itself very well towards the data that we are processing being stored in actual objects of

33
00:02:40.680 --> 00:02:43.530
a domain model, and you'll see that shortly here.

34
00:02:43.710 --> 00:02:50.400
So in this lesson, we're just going to take a quick little detour to see how we can take this same

35
00:02:50.400 --> 00:02:53.710
data and throw it into a domain model first.

36
00:02:53.760 --> 00:02:54.190
OK.

37
00:02:55.790 --> 00:02:56.120
All right.

38
00:02:56.150 --> 00:03:00.740
So the way we're going to do this is because we want this to be kind of quick and dirty.

39
00:03:01.400 --> 00:03:07.010
We're going to just create a domain model and define it within the big data class.

40
00:03:07.250 --> 00:03:12.830
And what I specifically mean here is we're essentially going to create a class as an inner or nested

41
00:03:12.830 --> 00:03:14.240
class of big data.

42
00:03:14.300 --> 00:03:17.330
Now, technically, it's not actually going to be a class, by the way.

43
00:03:17.420 --> 00:03:22.930
We're actually going to create a record because I want this to be really, really lightweight.

44
00:03:23.000 --> 00:03:23.450
OK.

45
00:03:23.720 --> 00:03:28.880
And if you may recall records, essentially our classes with less boilerplate.

46
00:03:29.090 --> 00:03:36.110
So when you create a record instead of the class, you don't have to define getters and setters, nor

47
00:03:36.110 --> 00:03:40.140
do you have to define equals or hash code methods or any of that kind of stuff.

48
00:03:40.160 --> 00:03:44.840
You get all of those things kind of generated for you as long as you're willing to accept that all of

49
00:03:44.840 --> 00:03:49.980
the fields that you're defining on the record will will go into the definitions of those things.

50
00:03:50.000 --> 00:03:50.360
OK.

51
00:03:50.750 --> 00:03:51.100
All right.

52
00:03:51.110 --> 00:03:53.330
So let's jump into this.

53
00:03:53.340 --> 00:03:58.670
So the way we're going to do this is we're going to create this record inside of the big data class,

54
00:03:58.670 --> 00:04:04.040
and I'm going to actually just put my cursor right there underneath the definition of the class big

55
00:04:04.040 --> 00:04:05.510
data and hit enter.

56
00:04:05.870 --> 00:04:14.000
And when we create a class, you do class, but when you create a record, you do R, E, C or D like

57
00:04:14.000 --> 00:04:14.750
this would say.

58
00:04:15.820 --> 00:04:19.900
Last May, my one record my one space there.

59
00:04:20.260 --> 00:04:25.210
All right, record and then you give it a name, so I'm going to just call this person.

60
00:04:25.870 --> 00:04:31.750
And now when you're creating a class, the next thing you would do is to have curly braces like this,

61
00:04:31.900 --> 00:04:34.000
just as we have up here on Line seven.

62
00:04:34.120 --> 00:04:40.210
However, when we're creating a record, the next thing that comes here is kind of like you're defining

63
00:04:40.210 --> 00:04:41.170
a constructor.

64
00:04:41.350 --> 00:04:48.370
So you actually just use parentheses here and then you specify what all of the fields are that are going

65
00:04:48.370 --> 00:04:50.440
to be a part of this new record.

66
00:04:50.710 --> 00:04:57.220
And so I think what we're going to want to model here are the first name, last name, salary, and

67
00:04:57.220 --> 00:05:02.320
I'd like to throw in the state as well, because that'll set us up for future lessons.

68
00:05:03.130 --> 00:05:07.960
So we need to find out what the array indexes are for those fields.

69
00:05:08.230 --> 00:05:11.290
So if we jump back over to the spreadsheet?

70
00:05:11.860 --> 00:05:14.560
All right, we'll find the first thing here.

71
00:05:14.560 --> 00:05:18.550
So the first thing field is indexed to last name is for.

72
00:05:18.820 --> 00:05:21.430
And I think salary was already twenty five.

73
00:05:21.730 --> 00:05:26.230
And we're also going to want the state to state is thirty two.

74
00:05:26.240 --> 00:05:27.820
So two, four and thirty two.

75
00:05:27.820 --> 00:05:29.320
I think we already have twenty five.

76
00:05:29.530 --> 00:05:29.730
All right.

77
00:05:29.740 --> 00:05:33.130
So jumping back over to the ADP?

78
00:05:33.250 --> 00:05:34.120
All right.

79
00:05:34.660 --> 00:05:36.730
Well, I guess I was getting a little bit ahead of myself.

80
00:05:36.730 --> 00:05:38.290
We don't we're not quite ready for that yet.

81
00:05:38.320 --> 00:05:40.300
First, let's finish just the finding this record.

82
00:05:40.300 --> 00:05:44.500
So we're going to have a first name, last name, salary and state.

83
00:05:44.800 --> 00:05:48.190
So we'll model the first name and last name as strings.

84
00:05:48.640 --> 00:05:51.060
So we'll say first name notice.

85
00:05:51.070 --> 00:06:00.100
I'm using camel case with a capital N and a string for the last name and for the salary.

86
00:06:00.100 --> 00:06:08.170
We'll do a primitive long salary and then for the state, we'll do another string.

87
00:06:11.690 --> 00:06:12.260
Here we go.

88
00:06:12.650 --> 00:06:16.520
And now to finish this all up, now we use the curly braces.

89
00:06:16.640 --> 00:06:22.130
However, they can just be empty because there's nothing that we need to define in here because all

90
00:06:22.130 --> 00:06:27.230
of the all of the pertinent things that we need will be generated for us automatically.

91
00:06:27.230 --> 00:06:30.050
And so that's again, one of the nice things about using a record.

92
00:06:30.560 --> 00:06:32.540
We don't need to generate getters and setters.

93
00:06:32.540 --> 00:06:35.750
They're already being generated for us on the fly, so to speak.

94
00:06:36.170 --> 00:06:36.740
All right.

95
00:06:37.010 --> 00:06:41.540
So now we can go ahead and make use of our person instances down here.

96
00:06:41.540 --> 00:06:46.700
So the way we all want to do this is down here on line 16.

97
00:06:47.270 --> 00:06:47.720
We're doing it.

98
00:06:47.720 --> 00:06:56.180
We're calling start split and that is resulting in an output of a stream of string arrays, right?

99
00:06:56.180 --> 00:06:57.800
So we're getting the string arrays there.

100
00:06:57.980 --> 00:07:00.680
So then the rest of this is where we're kind of parsing things out.

101
00:07:00.680 --> 00:07:07.120
So I think we don't need any of these three lines 17 through 19, we don't need any of those.

102
00:07:07.120 --> 00:07:12.020
So I'm going to delete those and I will make a new line right here and now.

103
00:07:12.020 --> 00:07:18.380
I think what we'll want to do is we'll want to take that array that's coming out of Line 16 and we will

104
00:07:18.380 --> 00:07:21.890
want to map that array to instances of the person.

105
00:07:21.890 --> 00:07:28.490
So in other words, for each array, turn that into a person essentially, right?

106
00:07:28.640 --> 00:07:34.400
And kind of looking over here at the spreadsheet again, I was pointing out before that, if you think

107
00:07:34.400 --> 00:07:41.180
of each row here as one array, then we're going to kind of just do an object oriented thing where we

108
00:07:41.180 --> 00:07:43.280
convert some of the pertinent.

109
00:07:43.290 --> 00:07:44.150
That's not all of it.

110
00:07:44.150 --> 00:07:50.330
We're going to ignore most of the fields for now that we see here, but we're going to convert the pertinent

111
00:07:50.330 --> 00:07:53.670
fields that we care about into instances of a person.

112
00:07:53.690 --> 00:07:54.140
OK.

113
00:07:54.650 --> 00:08:00.300
And so to do that, since we're doing conversion conversions are done with dot map, right?

114
00:08:00.320 --> 00:08:04.780
When you take one input and then you spit out a different type of output, or it could be the same output,

115
00:08:04.820 --> 00:08:05.210
really.

116
00:08:05.960 --> 00:08:10.400
So we'll do a map here, the input into this, we'll use a lambda expression here.

117
00:08:10.400 --> 00:08:13.000
So the input into the lambda expression will be an array.

118
00:08:13.010 --> 00:08:16.340
So I'm just going to use a because I don't feel like typing too much.

119
00:08:16.640 --> 00:08:16.940
All right.

120
00:08:16.940 --> 00:08:22.760
So the array will map to and now we're just going to create a new instance of a person.

121
00:08:23.820 --> 00:08:30.450
And we'll pass in our inputs, so these inputs will correspond directly to what we defined up here first

122
00:08:30.450 --> 00:08:32.110
name, last name, salary and state.

123
00:08:32.130 --> 00:08:33.360
Same thing down here.

124
00:08:33.630 --> 00:08:34.030
All right.

125
00:08:34.200 --> 00:08:40.640
So now all we have to do is just reference the elements of the array to get those those fields right.

126
00:08:40.650 --> 00:08:43.470
So the first name was in index two.

127
00:08:43.500 --> 00:08:43.860
Right?

128
00:08:44.100 --> 00:08:53.040
So then we can do a two like that and then a four for the last name like so and let's see.

129
00:08:53.040 --> 00:08:54.330
The next one is the salary.

130
00:08:54.540 --> 00:09:00.690
Now, salary is of type long in our domain model here in our person class.

131
00:09:01.470 --> 00:09:07.050
But what we're going to get out of a five by default is a string, as you should know by now.

132
00:09:07.200 --> 00:09:11.190
And so we'll need to pass that using the long that pass long method, right?

133
00:09:11.460 --> 00:09:19.050
So we'll do a long short pass long and then we'll do a twenty five like so.

134
00:09:20.140 --> 00:09:25.640
And then finally, we need the state, which was I have forgotten what the state was, let me go.

135
00:09:25.660 --> 00:09:28.240
Twenty five, I think it was twenty five.

136
00:09:29.450 --> 00:09:31.060
Let's see.

137
00:09:31.400 --> 00:09:32.240
No, oh, no.

138
00:09:32.510 --> 00:09:33.140
Five was the salad.

139
00:09:33.170 --> 00:09:34.610
Thirty two is thirty two, right?

140
00:09:34.640 --> 00:09:34.880
Yeah.

141
00:09:34.910 --> 00:09:35.510
Thirty two.

142
00:09:35.930 --> 00:09:36.350
OK.

143
00:09:37.310 --> 00:09:40.550
So then the state will be a thirty two.

144
00:09:40.700 --> 00:09:43.130
So that finishes up that mapping there.

145
00:09:43.130 --> 00:09:49.970
And then finally, let's uncomment this collect call here because we want to go back to that again.

146
00:09:50.240 --> 00:09:54.560
Now you'll notice here that the collectors is red because it needs to be reimported.

147
00:09:54.560 --> 00:09:57.290
Or I could just go ahead and select this and delete it.

148
00:09:57.500 --> 00:10:03.050
And we can do a static import on the method itself, which I generally prefer so that we can keep the

149
00:10:03.050 --> 00:10:08.840
line a little shorter so I can put my cursor somewhere on the word something long and then to an option

150
00:10:08.840 --> 00:10:13.130
return and statically import that, as we've done in the past.

151
00:10:13.760 --> 00:10:22.760
Now the summing long method takes a method reference or a lambda or an anonymous class.

152
00:10:23.030 --> 00:10:28.460
Any of those things right that implements the the interface that it is expecting.

153
00:10:28.730 --> 00:10:33.500
Now interestingly, here, and here's one of the things that I was kind of hinting at earlier about

154
00:10:33.500 --> 00:10:40.280
the fact that if you use a domain model, a lot of the streams API methods kind of lend themselves very,

155
00:10:40.280 --> 00:10:44.210
very conveniently for you if you are using a domain model.

156
00:10:44.210 --> 00:10:44.960
So watch this.

157
00:10:45.230 --> 00:10:53.180
So this summing long method is expecting an interface or an implementation of an interface that will

158
00:10:53.180 --> 00:10:56.360
take an input and spit out essentially along, right?

159
00:10:56.750 --> 00:10:59.600
Well, watch what we can do here.

160
00:11:00.260 --> 00:11:04.490
I'm going to delete this lambda expression because we don't need that anymore.

161
00:11:04.910 --> 00:11:11.630
Now, remember what's coming out of Line 19 now are instances of person out of this stream.

162
00:11:11.630 --> 00:11:14.210
Now notice it's actually big data dot person.

163
00:11:14.390 --> 00:11:20.500
And the reason for that is because our person class is really a nested class within the big data class.

164
00:11:20.510 --> 00:11:24.500
And so there is no such thing as the person class all by itself.

165
00:11:24.500 --> 00:11:27.320
It's the big data dot person class technically.

166
00:11:27.500 --> 00:11:29.570
And so that's why it's labeled that way there.

167
00:11:29.720 --> 00:11:32.210
But nevertheless, it's a stream of persons, right?

168
00:11:32.660 --> 00:11:36.290
So down here, we're receiving a person.

169
00:11:36.680 --> 00:11:37.820
Now watch this.

170
00:11:38.120 --> 00:11:45.200
We can actually just use a method reference now instead of a lambda expression person salary.

171
00:11:45.680 --> 00:11:46.430
Look at that.

172
00:11:46.670 --> 00:11:54.710
And the reason we can do that is because our record class of person or our record of person is automatically

173
00:11:54.710 --> 00:12:00.050
generating better methods for each of our fields, one of which is called salary now notice.

174
00:12:00.320 --> 00:12:06.050
The record by default doesn't create getter methods that are called get blah blah blah.

175
00:12:06.080 --> 00:12:06.350
Right?

176
00:12:06.530 --> 00:12:08.540
It's this called whatever the field is.

177
00:12:08.550 --> 00:12:12.440
That's a that's a different little bit of a convention for records.

178
00:12:12.620 --> 00:12:19.670
However, it is a method nonetheless, and it is a method that returns a long, which is what the summing

179
00:12:19.670 --> 00:12:22.370
long is expecting here.

180
00:12:22.670 --> 00:12:27.290
And so we can just use this method reference and we don't have to type anything else right?

181
00:12:27.290 --> 00:12:29.150
And that feels quite natural.

182
00:12:30.510 --> 00:12:36.480
So we're essentially telling the Streams API to sum up all of the salaries on the person class, right?

183
00:12:37.200 --> 00:12:37.490
All right.

184
00:12:37.500 --> 00:12:39.690
So now let's run that and see what we get.

185
00:12:40.470 --> 00:12:41.040
All right.

186
00:12:41.040 --> 00:12:42.510
And there's our output now.

187
00:12:43.350 --> 00:12:45.870
Notice it actually took forty four seconds.

188
00:12:45.930 --> 00:12:51.360
I'm going to tell you right now that doesn't have anything to do with the data processing that has more

189
00:12:51.360 --> 00:12:54.930
to do with the way that I'm recording this video on this laptop now.

190
00:12:54.930 --> 00:12:56.640
I've changed my set up a little bit.

191
00:12:56.650 --> 00:13:02.850
I'm trying to trying different things out here, so I would ask that you just ignore the fact that that

192
00:13:03.330 --> 00:13:04.940
apparently took forty four seconds.

193
00:13:04.950 --> 00:13:11.070
That's not to do with with the with the code or anything like that in this particular case.

194
00:13:12.360 --> 00:13:14.520
However, yeah, so we got our output.

195
00:13:14.520 --> 00:13:15.720
So that still works.

196
00:13:15.930 --> 00:13:21.660
So the last thing I kind of want to mention before we wrap up this lesson is just some thoughts around

197
00:13:21.960 --> 00:13:27.960
the difference between using a domain model to process these five million records versus using the array

198
00:13:27.960 --> 00:13:32.130
and other techniques that we might also have wanted to consider.

199
00:13:33.090 --> 00:13:41.910
So be aware that essentially we've got this pipeline here, and you can kind of envision that for each

200
00:13:41.910 --> 00:13:46.620
of the five million records that we are processing or adding up, essentially.

201
00:13:47.190 --> 00:13:53.220
You can imagine that there's a loop going on a for loop that's essentially happening five million times,

202
00:13:53.220 --> 00:13:53.460
right?

203
00:13:53.670 --> 00:13:59.430
So if you imagine that for loop iterating over this pipeline of code five million times.

204
00:13:59.940 --> 00:14:01.650
Couple of things are happening now.

205
00:14:01.680 --> 00:14:09.240
One is when we call split, an array is being created, an instance of an array is being created, and

206
00:14:09.240 --> 00:14:16.740
that means actually five million arrays will be created during the lifetime of this program.

207
00:14:17.040 --> 00:14:26.430
And with the addition of our new person class here on Line 19, five million instances of a person class

208
00:14:26.430 --> 00:14:28.050
will also be created.

209
00:14:28.080 --> 00:14:28.530
OK.

210
00:14:29.040 --> 00:14:36.690
And if we're not careful under certain circumstances, that could be quite wasteful of the memory of

211
00:14:36.690 --> 00:14:37.470
the computer.

212
00:14:38.040 --> 00:14:47.310
But one thing that you can be aware of is the fact that these are arrays and person instances won't

213
00:14:47.310 --> 00:14:48.660
live very long.

214
00:14:48.690 --> 00:14:51.000
Not the individual instances of them.

215
00:14:51.120 --> 00:14:59.370
And the reason for that is because in Java, whenever an object is created, the JVM, the Java virtual

216
00:14:59.370 --> 00:15:05.520
machine, which is kind of like the manager, the thing that I usually am referring to as in Java or

217
00:15:05.520 --> 00:15:12.240
the Java system, the JVM is constantly monitoring and tracking the creation of objects.

218
00:15:12.600 --> 00:15:16.560
And when it realizes that an object is no longer being referenced.

219
00:15:16.830 --> 00:15:24.390
And by that, I mean no longer being used and doesn't have any possibility of ever being used again.

220
00:15:25.440 --> 00:15:30.600
Then the JVM will flag that object for garbage collection.

221
00:15:30.960 --> 00:15:37.260
And so there's this little thread, essentially the garbage collection thread that periodically comes

222
00:15:37.260 --> 00:15:43.320
around looking for objects that have been flagged for garbage collection, and it will collect them

223
00:15:43.320 --> 00:15:46.350
and clear them out of the system memory.

224
00:15:46.530 --> 00:15:46.980
OK.

225
00:15:48.270 --> 00:15:50.550
So that's constantly happening.

226
00:15:50.760 --> 00:15:52.380
Now how frequently it happens.

227
00:15:52.530 --> 00:15:57.210
We can't directly know for any given run of our program.

228
00:15:57.210 --> 00:16:03.450
It just depends on system resources and things that are well beyond most of what we're going to care

229
00:16:03.450 --> 00:16:03.900
about.

230
00:16:04.290 --> 00:16:10.920
But just know that there is this garbage collector that's periodically looking to clear out objects.

231
00:16:11.160 --> 00:16:16.770
Now it might clear those objects out every three iterations.

232
00:16:16.980 --> 00:16:21.870
Occasionally, it might just happen to clear something out as soon as it was created, like right after

233
00:16:21.870 --> 00:16:23.640
that one iteration might be.

234
00:16:23.640 --> 00:16:29.340
Every three iterations might be every 100 iterations, and it could be different at different times.

235
00:16:29.340 --> 00:16:33.490
And in fact, it likely will be at different times throughout our iterations.

236
00:16:33.510 --> 00:16:33.780
OK.

237
00:16:33.960 --> 00:16:39.210
But the main point that I want to make here is that, generally speaking, we're not likely to ever

238
00:16:39.210 --> 00:16:47.040
see in this program five million arrays and five million people or person instances, all sitting in

239
00:16:47.040 --> 00:16:48.690
memory, all at the same time.

240
00:16:48.720 --> 00:16:50.010
That's pretty unlikely.

241
00:16:50.430 --> 00:16:57.570
Maybe, though, we could see 100 or even, I don't know, maybe even a thousand at one time, depending

242
00:16:57.570 --> 00:17:05.410
on how fast the Streams API is kind of streaming and iterating over over this little pipeline here.

243
00:17:05.430 --> 00:17:05.850
OK?

244
00:17:06.000 --> 00:17:10.230
Before the garbage collector decides to come along and get rid of everything.

245
00:17:10.440 --> 00:17:10.830
All right.

246
00:17:12.210 --> 00:17:19.590
So that's something just to be aware of, because if you wrote a pipeline that for some reason was managing

247
00:17:19.590 --> 00:17:27.630
to keep a lot of heavy weight objects around in memory for a really long time, that might be something

248
00:17:27.630 --> 00:17:29.010
where you'd want to decide.

249
00:17:29.010 --> 00:17:29.670
Maybe I don't.

250
00:17:29.710 --> 00:17:31.660
Want to do it in this particular way?

251
00:17:31.690 --> 00:17:33.790
Maybe I want to do it in a different way.

252
00:17:34.000 --> 00:17:34.450
OK.

253
00:17:34.870 --> 00:17:40.720
One other thing that I'll mention, by the way, so we are creating these arrays because we're doing

254
00:17:40.720 --> 00:17:41.440
split.

255
00:17:42.190 --> 00:17:48.250
It might be an interesting exercise at some point for us to consider what this might look like if we

256
00:17:48.250 --> 00:17:51.550
didn't do a split, which results in the creation of an array.

257
00:17:51.760 --> 00:17:58.510
But instead, if we use the regular expression to parse out just the pertinent fields that we are caring

258
00:17:58.510 --> 00:18:05.560
about, and then we used those fields either here or even, I don't know, maybe even possibly directly

259
00:18:05.560 --> 00:18:10.510
in the summing long, although I don't know that might feel a little weird, but it would be kind of

260
00:18:10.510 --> 00:18:13.180
curious just to see how that would work.

261
00:18:13.390 --> 00:18:19.960
Plus, also, regular expressions can be compiled, and so they might have a shot at parsing out those

262
00:18:19.960 --> 00:18:27.190
bits even faster than what the split method is doing here, although the split method is technically

263
00:18:27.190 --> 00:18:30.430
using a regular expression itself to find those commas right.

264
00:18:31.120 --> 00:18:34.930
So I don't know those would be interesting little experiments to try out.

265
00:18:35.470 --> 00:18:35.760
All right.

266
00:18:35.770 --> 00:18:39.930
So at any rate, these are the main points I wanted to make in this lesson.

267
00:18:39.940 --> 00:18:46.000
And now in the next lesson, we'll dive into some slightly more advanced techniques that we can use

268
00:18:46.150 --> 00:18:47.920
with the collect method.

269
00:18:48.070 --> 00:18:49.360
So I'll see you in the next one.
