1
00:00:01,920 --> 00:00:08,230
Halo semuanya dan selamat datang di kuliah pembelajaran yang diawasi menggunakan pengklasifikasi Bayes naif.

2
00:00:08,230 --> 00:00:12,800
Jadi dalam kuliah ini kita akan belajar bagaimana menggunakan classifier dasar naif untuk melakukan

3
00:00:12,800 --> 00:00:15,900
klasifikasi multikelas pada set data yang sudah kita kenal.

4
00:00:15,900 --> 00:00:18,100
Kumpulan data bunga iris.

5
00:00:18,100 --> 00:00:24,850
Dan akan terdiri dari tujuh bagian utama yang akan kita lakukan nota cepat pada notasi dan beberapa istilah matematika yang mungkin Anda

6
00:00:24,850 --> 00:00:27,120
tahu mungkin atau mungkin tidak akrab dengan.

7
00:00:27,420 --> 00:00:35,770
Kemudian bagian dua akan belajar tentang dasar kesalahan akan mendapatkan pengantar malam ini di bagian 3 di bagian

8
00:00:35,770 --> 00:00:39,740
4 akan memiliki gambaran matematika classifier Bayes naif.

9
00:00:39,740 --> 00:00:47,320
Kemudian kita akan membangun classifier dari model probabilitas itu dan bagian 6 akan melihat

10
00:00:47,540 --> 00:00:55,670
basis Gaussian dan di bagian 7 akan menggunakan fase siklus Gaussian belajar untuk menerapkan klasifikasi multiclass.

11
00:00:55,670 --> 00:00:57,530
Jadi itu banyak yang harus dibicarakan.

12
00:00:57,530 --> 00:01:03,770
Dan Anda akan melihat sebagian besar kuliah ini condong lebih ke arah matematika dan pemahaman fase vs siklus yang

13
00:01:04,140 --> 00:01:11,200
dipelajari penerapannya karena sekarang kami telah melakukan begitu banyak klasifikasi multi-kelas Anda mungkin akan masuk ke alur ini segera di mana

14
00:01:11,200 --> 00:01:15,860
Anda tahu caranya untuk mengimplementasikan model yang berbeda dan Anda akan melihat pola itu

15
00:01:15,860 --> 00:01:17,450
muncul lagi di sini.

16
00:01:19,490 --> 00:01:23,230
Jadi mari kita lanjutkan dan mengambil beberapa not cepat pada notasi yang saya kejar.

17
00:01:23,230 --> 00:01:25,820
Kita akan menggunakan seluruh kuliah ini.

18
00:01:26,100 --> 00:01:31,100
Jadi akan ada beberapa notasi canggih dan istilah matematika yang digunakan selama penjelasan

19
00:01:31,100 --> 00:01:32,760
klasifikasi berdasarkan malam.

20
00:01:33,190 --> 00:01:37,050
Jadi, Anda harus terbiasa dengan produk urutan berikut.

21
00:01:37,450 --> 00:01:40,840
Produk dari urutan istilah dapat menjadi simbol produk saat ini.

22
00:01:40,840 --> 00:01:44,690
Dan ini biasanya diturunkan sebagai kue modal.

23
00:01:44,690 --> 00:01:49,500
Jadi arti dari notasi ini dan saya memiliki tautan di sini ke halaman Wikipedia jika Anda

24
00:01:49,500 --> 00:01:50,600
ingin memeriksanya sendiri.

25
00:01:51,020 --> 00:01:57,410
Tetapi untuk produk urutan pada dasarnya Anda memiliki huruf kapital kecil pi ini dan sama seperti

26
00:01:57,410 --> 00:02:01,500
Anda akan menggunakan modal Sigma untuk penjumlahan di sini.

27
00:02:01,500 --> 00:02:09,420
Ini hanya urutan produk yang sangat urutan sehingga misalnya saya sebut satu mengambil produk sampai empat

28
00:02:09,420 --> 00:02:13,890
yang berarti satu kali dua kali tiga kali empat.

29
00:02:13,890 --> 00:02:16,580
Jadi itu sama dengan 24.

30
00:02:18,300 --> 00:02:23,780
Jadi Anda mengambil apa pun yang ada di sana dan alih-alih menjumlahkannya, Anda tinggal mengalikannya

31
00:02:23,780 --> 00:02:25,740
dari apa pun yang diselesaikan.

32
00:02:26,120 --> 00:02:32,010
Dan hal terakhir yang ingin saya lakukan adalah membahas max kami yang dapat Anda lihat di tautan Wikipedia di sini.

33
00:02:32,010 --> 00:02:34,840
Tapi itu pada dasarnya argumen yang maksimal.

34
00:02:35,080 --> 00:02:41,910
Jadi jika kita melihat kembali ke notebook dalam matematika argumen-argumen maksimum yang terkadang disingkat sebagai max

35
00:02:41,910 --> 00:02:45,340
space kita atau max kita satu kata tunggal.

36
00:02:45,810 --> 00:02:51,340
Ini adalah set poin dari argumen yang diberikan dimana fungsi yang diberikan mencapai nilai maksimumnya.

37
00:02:51,650 --> 00:02:57,250
Jadi berbeda dengan global maksimum yang mengacu pada fungsi output besar apa argumen

38
00:02:57,250 --> 00:03:01,990
maksimum tidak mengacu pada input yang menciptakan output maksimum tersebut.

39
00:03:02,170 --> 00:03:06,000
Jadi secara formal didefinisikan seperti ini.

40
00:03:06,000 --> 00:03:15,010
Jadi Anda bisa mengatakan Dengan kata lain himpunan titik x yang f dari x fungsi itu mencapai nilai terbesarnya.

41
00:03:17,160 --> 00:03:23,040
Yang ditetapkan mungkin kosong memiliki satu elemen atau memiliki beberapa elemen untuk memecah ini dalam format

42
00:03:23,040 --> 00:03:25,230
yang benar-benar lebih mudah dimengerti.

43
00:03:25,800 --> 00:03:32,240
Katakanlah fungsi Anda f dari x adalah sama dengan 1 minus nilai absolut x maka itu

44
00:03:32,240 --> 00:03:36,880
berisi nilai maksimumnya pada 1 ketika x sama dengan 0.

45
00:03:36,880 --> 00:03:44,380
Jadi argumen maksimum fungsi itu satu nilai absolut minus x sama dengan 0.

46
00:03:44,380 --> 00:03:53,780
Jadi untuk membuatnya hanya dalam istilah awam sederhana itu hanya argumen maksimum adalah ketika fungsi Anda untuk nilai

47
00:03:53,810 --> 00:03:56,990
apa yang akan mencapai nilai maksimumnya.

48
00:03:56,990 --> 00:03:58,910
Jadi sekali lagi untuk contoh cepat itu.

49
00:03:58,910 --> 00:04:07,010
Jika f dari x sama dengan 1 minus absolut dari nilai absolut X dari X maka itu akan mencapai nilai maksimum 1

50
00:04:07,010 --> 00:04:09,160
ketika x sama dengan 0.

51
00:04:09,160 --> 00:04:13,090
Jadi argumen x dari fungsi itu sama dengan 0 pada set itu.

52
00:04:13,090 --> 00:04:13,440
BAIK.

53
00:04:14,550 --> 00:04:17,720
Jadi, bagian kedua Anda perlu memahami basis di sana.

54
00:04:17,720 --> 00:04:22,400
Jadi untuk pengantar cepat tentang teorema dasar, silakan dan periksa kuliah teorema dasar dalam bagian

55
00:04:22,400 --> 00:04:24,280
statistik lampiran dari kursus ini.

56
00:04:24,280 --> 00:04:29,520
Jadi untuk memahami sepenuhnya saya punya teluk Anda harus memahami teorema dasar.

57
00:04:29,520 --> 00:04:35,260
Jadi, jika Anda tidak terbiasa dengan teorema dasar secara umum, silakan cek

58
00:04:35,260 --> 00:04:37,570
di statistik lampiran statistik.

59
00:04:37,570 --> 00:04:40,070
Saya sekarang berada di bagian 3.

60
00:04:40,070 --> 00:04:43,250
Setelah Anda pergi ke depan dan periksa itu dan isi atau berdiri berdasarkan teorema.

61
00:04:43,950 --> 00:04:48,880
Mari kita lakukan pengantar cepat ke basis malam jadi saya mungkin berbasis dengan

62
00:04:48,880 --> 00:04:54,130
algoritma pembelajaran mesin yang paling praktis dan meskipun namanya itu benar-benar berkinerja sangat baik mengingat

63
00:04:54,130 --> 00:04:54,980
kinerja klasifikasi.

64
00:04:55,380 --> 00:05:01,280
Jadi terbukti sangat kuat untuk fitur-fitur yang relevan yang diabaikannya dan mempelajarinya memprediksi

65
00:05:01,310 --> 00:05:07,500
dengan cepat dan tidak memerlukan banyak penyimpanan sehingga kita mungkin bertanya-tanya mengapa itu disebut naif.

66
00:05:07,500 --> 00:05:15,140
Jadi naif telah ditambahkan ke akun untuk satu asumsi yang diperlukan untuk cara naif untuk bekerja secara optimal

67
00:05:15,770 --> 00:05:20,050
yang semua fitur harus ada di pena satu sama lain.

68
00:05:20,050 --> 00:05:26,050
Jadi misalnya dalam kotak bunga kami, Anda akan menganggap bahwa setiap fitur bunga itu

69
00:05:26,050 --> 00:05:30,300
benar-benar saling menguntungkan dan pada kenyataannya biasanya tidak demikian.

70
00:05:30,300 --> 00:05:36,200
Jadi jika Anda mencoba membandingkan apel dan jeruk, Anda harus mengasumsikan bahwa setiap fitur buah

71
00:05:36,200 --> 00:05:36,930
itu.

72
00:05:38,000 --> 00:05:44,370
Itu ada di liontin setiap fitur lainnya dan dalam set data nyata yang biasanya tidak demikian.

73
00:05:44,370 --> 00:05:48,430
Biasanya fitur entah bagaimana terkait satu sama lain dan naif.

74
00:05:48,430 --> 00:05:52,640
Asumsi naif utama yang Anda buat adalah bahwa semua fitur itu ada di dalam pena.

75
00:05:52,640 --> 00:05:59,640
Jadi terlepas dari itu masih mengembalikan akurasi yang sangat bagus dalam praktek bahkan ketika itu dalam asumsi pena

76
00:05:59,670 --> 00:06:00,830
tidak berlaku.

77
00:06:00,830 --> 00:06:06,910
Jadi pengklasifikasi naif Bayes bekerja sangat baik dalam banyak situasi dunia nyata dan mereka paling

78
00:06:06,910 --> 00:06:09,780
terkenal digunakan dalam penyaringan klasifikasi dokumen spam.

79
00:06:09,780 --> 00:06:15,700
Jadi, jika Anda melihat di internet untuk contoh hari yang lebih naif biasanya Anda akan melihat contoh penyaringan spam

80
00:06:15,700 --> 00:06:16,870
untuk pangkalan pisau.

81
00:06:17,190 --> 00:06:21,530
Dan dalam kursus ini kita akan menggunakannya untuk set data bunga iris karena kita sudah terbiasa dengan set

82
00:06:21,530 --> 00:06:22,260
data itu.

83
00:06:24,680 --> 00:06:30,320
Jadi mari kita lanjutkan dan beralih ke bagian untuk kelas fase malam untuk tinjauan matematika

84
00:06:30,320 --> 00:06:34,800
Jadi ingat, Anda harus terbiasa dengan teorema wajah sebelum menuju ke bagian ini.

85
00:06:35,970 --> 00:06:42,040
Metode berbasis pisau berkelanjutan adalah seperangkat algoritma pembelajaran terawasi berdasarkan Bayes Theorem yang

86
00:06:42,040 --> 00:06:49,860
lagi-lagi Anda dapat melihat dalam enam kuliah lampiran seperti yang kami katakan sebelumnya bahwa asumsi naif tentang independensi

87
00:06:49,860 --> 00:06:51,950
antara setiap pasangan fitur.

88
00:06:51,950 --> 00:06:58,820
Jadi katakanlah Anda diberi variabel kelas y sehingga bisa menjadi kelas Anda yang ingin Anda tempatkan bunga itu di

89
00:06:58,820 --> 00:07:04,640
dalamnya dan Anda memiliki vektor fitur tergantung x hingga X M Jadi Anda memiliki x 1.

90
00:07:04,640 --> 00:07:09,350
Ada satu fitur mungkin itu ukuran kelopak bunga di mana kami memiliki kelopak menara.

91
00:07:10,860 --> 00:07:13,680
Dan kemudian semua jalan melalui acara ex itu semua adalah fitur Anda.

92
00:07:13,680 --> 00:07:19,360
Anda memiliki variabel kelas atau target Y Anda dan kemudian Anda jauh di dalam pena yang menampilkan

93
00:07:19,360 --> 00:07:21,060
vektor x 1 sepanjang Xon.

94
00:07:21,420 --> 00:07:25,970
Jadi, jika Anda mencolokkan ini ke Basis 0 Anda memiliki hubungan berikut.

95
00:07:25,970 --> 00:07:33,040
Jadi probabilitas milik kelas y yang diberikan semua fitur yang cocok dengan probabilitas yang dari kelas

96
00:07:33,040 --> 00:07:38,930
y kali probabilitas semua fitur yang diberikan bahwa Anda di kelas y dibagi dengan

97
00:07:38,930 --> 00:07:41,450
probabilitas memiliki semua fitur tersebut.

98
00:07:41,450 --> 00:07:49,880
Jadi jika kita menggunakan naif itu dalam asumsi pendants sehingga semua fitur tersebut terpisah, kita dapat menyatakan

99
00:07:49,880 --> 00:07:55,410
bahwa probabilitas memiliki fitur itu sama dengan probabilitas berada di target.

100
00:08:00,970 --> 00:08:07,840
Probabilitas memiliki fitur itu sama dengan ini di sini sehingga probabilitas

101
00:08:07,840 --> 00:08:15,100
memiliki fitur individual karena independen karena Anda termasuk dalam variabel kelas y.

102
00:08:15,490 --> 00:08:22,180
Jadi untuk semua yang saya miliki, Anda pada akhirnya dapat menyederhanakan hubungan itu dengan kemungkinan termasuk dalam

103
00:08:22,180 --> 00:08:23,260
kelas itu.

104
00:08:23,260 --> 00:08:29,810
Dengan semua fitur yang terpisah ini, X1 hingga xm di sini,

105
00:08:29,810 --> 00:08:37,950
kami menggantinya dengan yang sekarang, bahkan liontin, mengalikan setiap probabilitas bersyarat tunggal di sini.

106
00:08:37,950 --> 00:08:43,140
Jadi sekarang yang kita miliki adalah hubungan antara target dan fitur menggunakan teorema dasar bersama

107
00:08:43,140 --> 00:08:46,030
dengan asumsi naif bahwa semua fitur independen.

108
00:08:46,030 --> 00:08:47,400
Jadi untuk memecah apa yang dilakukannya.

109
00:08:48,490 --> 00:08:50,050
Dan kamu pada dasarnya.

110
00:08:50,420 --> 00:08:53,150
Lihatlah pangkalan klasik Anda di sana.

111
00:08:53,150 --> 00:08:58,720
Anda mencolokkan variabel kelas Anda dan kemudian Anda jauh di fitur vektor X1

112
00:08:59,770 --> 00:09:03,490
sepanjang XM dan kemudian menggunakan bahkan asumsi liontin.

113
00:09:03,490 --> 00:09:09,840
Anda dapat memecahnya sehingga istilah ini di sini probabilitas ini memiliki semua fitur

114
00:09:09,840 --> 00:09:17,950
yang diberikan mengapa terurai menjadi probabilitas memiliki fitur tunggal diberi kebohongan dan kemudian Anda hanya mengalikannya untuk

115
00:09:17,950 --> 00:09:20,010
semua probabilitas itu.

116
00:09:20,010 --> 00:09:23,270
Itu probabilitas bersyarat untuk semua fitur di ruang Anda.

117
00:09:23,270 --> 00:09:28,590
Jadi sekali lagi Anda memiliki teorema dasar yang Anda mainkan dalam variabel kelas Anda dan vektor

118
00:09:29,110 --> 00:09:34,200
fitur dependen Anda dan kemudian Anda menggunakannya sekarang bahkan asumsi pena untuk mengganti istilah ini.

119
00:09:34,200 --> 00:09:37,300
Kemungkinan ini memiliki semua fitur tersebut.

120
00:09:37,300 --> 00:09:43,280
Mengingat bahwa Anda berada di kelas itu dengan produk memiliki fitur tunggal mengingat bahwa Anda berada

121
00:09:43,280 --> 00:09:48,440
di kelas itu untuk semua Anda adalah fitur tergantung dalam vektor itu.

122
00:09:48,440 --> 00:09:50,740
Oke bagus.

123
00:09:50,740 --> 00:09:55,870
Jadi sekarang kita tahu bahwa kita kemudian dapat membangun classifier dari model probabilitas itu.

124
00:09:55,870 --> 00:09:59,670
Jadi hentikan videonya di sini dan saya akan melanjutkan dan melihat Anda dalam kuliah berikutnya.

125
00:09:59,670 --> 00:10:00,980
OK terima kasih kawan.
