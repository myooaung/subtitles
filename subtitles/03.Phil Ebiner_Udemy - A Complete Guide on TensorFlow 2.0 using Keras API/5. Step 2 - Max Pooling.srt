1
00:00:00,600 --> 00:00:02,910
Hello and welcome back to the course on deep learning.

2
00:00:02,910 --> 00:00:07,330
Today we're talking about Max pooling and we've got some very exciting slides coming up ahead.

3
00:00:07,440 --> 00:00:10,680
And even a special surprise at the very end of the tutorial.

4
00:00:10,980 --> 00:00:12,370
So let's get started.

5
00:00:12,390 --> 00:00:15,990
The first question is what is pooling and why do we need it.

6
00:00:15,990 --> 00:00:20,710
Well to answer that question let's have a look at these images on these three images we've got a cheetah.

7
00:00:20,730 --> 00:00:23,600
In fact it is the same exact cheetah on the first image.

8
00:00:23,610 --> 00:00:26,220
The image is positioned properly.

9
00:00:26,220 --> 00:00:29,600
The cheetah is looking straight at you on the second image.

10
00:00:29,610 --> 00:00:32,310
It's a bit rotated and the third image is a bit squashed.

11
00:00:32,730 --> 00:00:39,960
And the thing here is that we want the neural network to be able to recognize the cheetah in every single

12
00:00:39,960 --> 00:00:41,370
one of these images.

13
00:00:41,400 --> 00:00:43,160
In fact this is just one cheetah.

14
00:00:43,170 --> 00:00:45,050
What if we have lots of different cheetahs.

15
00:00:45,060 --> 00:00:50,850
Here's a cheetah here's a cheetah here's another cheetah here's a cheetah here's a cheetah and here's

16
00:00:50,850 --> 00:00:56,030
a cheetah and we want the neural network to recognize all of these shearers as shearers.

17
00:00:56,250 --> 00:01:03,450
And how can it do that if they're all looking in different directions they're all in different parts

18
00:01:03,450 --> 00:01:04,070
of the image.

19
00:01:04,080 --> 00:01:08,580
They're like their faces our position in different parts of them if somebody is on the right hand side

20
00:01:08,580 --> 00:01:10,780
somebody is in the left corner somebody is in the middle.

21
00:01:10,950 --> 00:01:12,410
They're all a bit different.

22
00:01:12,510 --> 00:01:14,210
The texture is a little bit different.

23
00:01:14,220 --> 00:01:16,140
The lighting is a bit different.

24
00:01:16,140 --> 00:01:21,540
There's lots of little differences and so if the neural network looks for exactly a certain feature

25
00:01:21,720 --> 00:01:29,640
for instance a distinctive feature of the cheetah is the tears that are on its face going from the eyes

26
00:01:29,640 --> 00:01:35,250
or the share the share shadows that look like tears the texture of the pattern that is going from its

27
00:01:35,250 --> 00:01:40,550
eyes down it's on the sides of its nose it looks like tears that's a distinctive feature of the cheetah

28
00:01:40,830 --> 00:01:48,600
but if it's looking for that feature which it learned from certain cheetahs in an exact location or

29
00:01:48,600 --> 00:01:53,390
in the exact shape or form or texture it will never find these other cheetahs.

30
00:01:53,400 --> 00:02:01,170
So we have to make sure that our war neural network has a property called spatial in variance meaning

31
00:02:01,170 --> 00:02:07,080
that it doesn't care where the features I can not.

32
00:02:07,080 --> 00:02:13,110
Not so much as in which part of the image because we're we've kind of taken that into consideration

33
00:02:13,110 --> 00:02:20,460
with our MAP WITH OUR POOL WITH OUR convolution there but it doesn't have to care if the features are

34
00:02:20,460 --> 00:02:26,160
a bit tilted if the features are a bit different in texture if the features are a bit closer of features

35
00:02:26,160 --> 00:02:32,640
or a bit further apart relative to relative to each other so if the feature itself is a bit distorted

36
00:02:32,910 --> 00:02:40,140
in our neural network has to have some level of flexibility to be able to still find that feature and

37
00:02:40,140 --> 00:02:42,630
that is what pooling is all about.

38
00:02:42,660 --> 00:02:45,060
So let's have a look at how pooling works.

39
00:02:45,090 --> 00:02:46,100
Here's our feature map.

40
00:02:46,110 --> 00:02:52,080
So we've already done all convolution and we've completed that part and now we're working with the convolution

41
00:02:52,080 --> 00:02:52,620
layer.

42
00:02:52,620 --> 00:02:53,840
Now we're going to apply pooling.

43
00:02:53,850 --> 00:02:54,600
So how does it work.

44
00:02:54,630 --> 00:02:59,130
We're going to be applying Max pooling there's several different types of pulling it can apply as mean

45
00:02:59,130 --> 00:03:03,720
pooling Max pooling some pooling and we'll comment on those towards the end of the tutorial but for

46
00:03:03,720 --> 00:03:05,030
now we're just applying Max pooling.

47
00:03:05,040 --> 00:03:12,750
So we take a box of two by two pixels like that and again it doesn't have to be two by two you can choose

48
00:03:12,750 --> 00:03:18,360
any size a box and again we'll comment on that towards senatorial and you place it in the top left hand

49
00:03:18,360 --> 00:03:25,410
corner and you find the maximum value in that box and then you record only that value and you disregard

50
00:03:25,410 --> 00:03:26,250
the other three.

51
00:03:26,250 --> 00:03:31,080
So in your box our four values just disregard three you only keep one the maximum which is one in this

52
00:03:31,080 --> 00:03:36,120
case then you move your box to the right by a stride you select the stride once again.

53
00:03:36,150 --> 00:03:42,140
So here we select a strata of two and that's what you normally select you can select the straight one

54
00:03:42,150 --> 00:03:42,930
you can select.

55
00:03:42,930 --> 00:03:47,880
So there are overlapping boxes you can select any kind of stray that you like or even three if you want

56
00:03:48,750 --> 00:03:52,310
but we're selecting Australia to here and that's what is commonly used.

57
00:03:52,410 --> 00:03:57,600
And then you repeat the repeat the process you can record the maximum here if you crossover and doesn't

58
00:03:57,600 --> 00:03:57,890
matter.

59
00:03:57,900 --> 00:03:59,920
You just keep continue doing what you're doing.

60
00:04:00,030 --> 00:04:07,640
So you still record the maximum here zero here the maximum is four here the maximum is to hear the maximum

61
00:04:07,640 --> 00:04:11,230
is 1 0 1 0 2 and then 1.

62
00:04:11,340 --> 00:04:13,910
So as you can see a few things happen.

63
00:04:13,920 --> 00:04:18,830
First of all we still were able to preserve the features Right.

64
00:04:19,020 --> 00:04:24,180
The maximum numbers they represent because we know how the convolution layer works we know that the

65
00:04:24,180 --> 00:04:30,000
maximal or the bit large numbers in your feature map they represent where you actually found the closest

66
00:04:30,000 --> 00:04:31,500
similarity to a feature.

67
00:04:31,590 --> 00:04:38,220
But by then pooling these features we are first of all getting rid of 75 percent of the information

68
00:04:38,220 --> 00:04:46,040
that is not the feature which is which is not the important things that we're looking out for because

69
00:04:46,120 --> 00:04:49,500
we are disregarding three pixels out of four.

70
00:04:49,680 --> 00:04:51,310
So we're only keeping 25 percent.

71
00:04:51,450 --> 00:05:01,220
And then also because we are taking the maximum of the pixels that we or the values that we have we

72
00:05:01,340 --> 00:05:04,130
are therefore accounting for any distortion.

73
00:05:04,130 --> 00:05:12,760
So for instance two images in which for example the cheetah's tears on the eyes are in one image they're

74
00:05:12,770 --> 00:05:17,930
a bit to the left or a bit rotated to the left and another one they're a bit and are how they're supposed

75
00:05:17,930 --> 00:05:23,980
to be or how we like if we take one as the basis and another one there which rotate to the left the

76
00:05:24,440 --> 00:05:26,510
pooled feature will be exactly the same.

77
00:05:26,510 --> 00:05:33,050
So you can see here if we are talking about the cheetahs tears then let's say this is the four and this

78
00:05:33,050 --> 00:05:35,990
is where it was here then if it was a bit rotated.

79
00:05:35,990 --> 00:05:41,240
So for instance the four ended up over here then when we're doing the pooling we're still going to get

80
00:05:41,240 --> 00:05:46,140
the same pooled feature map and that's kind of the principle behind it.

81
00:05:46,180 --> 00:05:52,310
There is a very rough explanation again intuitive explanation but that's the point of pooling that we're

82
00:05:52,310 --> 00:06:00,230
still being able to preserve the features and moreover accounts for their possible spatial or textural

83
00:06:00,230 --> 00:06:02,270
or other kind of distortions.

84
00:06:02,360 --> 00:06:05,740
And in addition to all of that we are reducing the size.

85
00:06:05,750 --> 00:06:07,310
So there is another benefit.

86
00:06:07,310 --> 00:06:12,110
So we've got we're preserving the features we're introducing spatial and variance.

87
00:06:12,120 --> 00:06:19,600
We're reducing the size by 75 percent which is huge which is really going to help us in terms of processing.

88
00:06:19,760 --> 00:06:25,910
And moreover another benefit of pooling is we're reducing the number of parameters so we're reducing

89
00:06:26,630 --> 00:06:31,220
again by 75 percent we're reducing number of parameters that are going to go into our final layers of

90
00:06:31,220 --> 00:06:35,240
the neural network and therefore we're preventing all refitting.

91
00:06:35,240 --> 00:06:42,550
It is a very important benefit of pooling that we're removing information and that is a good thing and

92
00:06:42,560 --> 00:06:50,600
that is a good thing because that way our model won't be able to over fit onto that information because

93
00:06:50,630 --> 00:06:54,200
especially because that information is not relevant remember like at the very start we were talking

94
00:06:54,200 --> 00:07:00,200
about even for human us as humans it's important to see exactly the features rather than all this other

95
00:07:00,200 --> 00:07:02,680
noise that is coming into our eyes.

96
00:07:02,720 --> 00:07:09,000
Well same thing for neural networks they by disregarding the unnecessary non important information we're

97
00:07:09,020 --> 00:07:12,410
helping with preventing of overfishing.

98
00:07:12,440 --> 00:07:14,550
So there we go that is what pooling is about.

99
00:07:14,570 --> 00:07:21,440
And the question here is of course why why Max pulling right there's lots of different types of pooling

100
00:07:21,650 --> 00:07:26,570
and you know why why astride of two why a size of two by two pixels lots of all these things.

101
00:07:26,720 --> 00:07:33,920
And on that note I'd like to introduce you to this lovely research paper called evaluation of pooling

102
00:07:33,920 --> 00:07:40,190
operations in convolution all architectures for object recognition by Dominic Shara from University

103
00:07:40,190 --> 00:07:41,060
of Bonn.

104
00:07:41,090 --> 00:07:47,510
There is the link and the beauty about this paper is that it's very very simple very straightforward.

105
00:07:47,510 --> 00:07:51,470
So if you've never read a research paper before which you'd like to give it a go.

106
00:07:51,470 --> 00:07:54,380
This is a great place to start it's very short.

107
00:07:54,380 --> 00:08:00,710
Only 10 pages very easy to read and plus the extra benefit is that now that we've discussed convolution

108
00:08:00,830 --> 00:08:05,900
and pooling you will be totally comfortable with everything that they're talking about in this paper

109
00:08:05,900 --> 00:08:11,800
and you this is a great way to actually reinforce and also I highly recommend checking this paper out.

110
00:08:11,870 --> 00:08:17,990
I'll take 20 minutes to read it and you can even skip part 2 which is called related work if it feels

111
00:08:17,990 --> 00:08:24,260
a bit farfetched or alienating just don't read that part just go straight to from part 1 to part 3 and

112
00:08:24,380 --> 00:08:29,510
the one thing that you do need to know about this paper they talk about a concept called Sub sampling

113
00:08:30,480 --> 00:08:33,170
while sub sampling is basically average pooling.

114
00:08:33,170 --> 00:08:39,410
So remember how here we were taking we were taking the maximum so in our square we're taking the maximum

115
00:08:39,410 --> 00:08:39,990
value.

116
00:08:39,980 --> 00:08:44,690
There's a concept called mean pooling or some pooling some pooling is you just some of these values

117
00:08:44,690 --> 00:08:51,200
up average pooling or mean pooling you take the average value out of all of these and sub sampling is

118
00:08:51,200 --> 00:08:53,840
kind of like a generalization of mean pooling.

119
00:08:53,840 --> 00:09:01,310
It's it's a more kind of generalized approach to taking the average of all of these values and you can

120
00:09:01,310 --> 00:09:05,810
read a bit more about in the paper but otherwise just think of it as average pooling when you're reading

121
00:09:05,810 --> 00:09:06,690
that paper.

122
00:09:06,860 --> 00:09:11,150
And so that's where you can get some additional information on this topic and now kind of let's recap

123
00:09:11,180 --> 00:09:12,290
where how we got into it.

124
00:09:12,290 --> 00:09:18,800
So there is our input image then we applied the convolution operation and we got the convolution there

125
00:09:19,040 --> 00:09:24,110
and now to each of those feature maps that we get we've applied the pooling layer.

126
00:09:24,230 --> 00:09:30,350
So we've got we've done these two steps convolution and pooling and now we're going to do something

127
00:09:30,350 --> 00:09:34,370
very fun something exciting we're going to experiment with this.

128
00:09:34,400 --> 00:09:44,570
So this is a screenshot I took from a tool created by Adam Hartley from white back when he was at Ryerson

129
00:09:44,570 --> 00:09:50,900
University of computer science and now he's at Carnegie Mellon I think doing his PGD and great tool

130
00:09:50,900 --> 00:09:53,120
so let's open up let's have a look.

131
00:09:53,210 --> 00:09:58,790
So you can find it you can't actually find it through Google you have to know your URL it's as but it's

132
00:09:58,790 --> 00:10:01,280
just hard to find Google because there's no tax here.

133
00:10:01,300 --> 00:10:03,690
SC we're just this year.

134
00:10:04,350 --> 00:10:08,160
Yes dot Ryerson dossier and then this stuff and then.

135
00:10:08,480 --> 00:10:11,950
And basically this is exactly what we're doing.

136
00:10:11,960 --> 00:10:12,650
But visualize.

137
00:10:12,680 --> 00:10:20,690
So here you need to draw a number so let's say I draw on number four and this tool will put the number

138
00:10:20,690 --> 00:10:21,280
four here.

139
00:10:21,290 --> 00:10:24,080
That's your image in our first step.

140
00:10:24,080 --> 00:10:27,040
Then this is the convolution step right.

141
00:10:27,050 --> 00:10:31,970
And this is the pooling step and also pooling by the way is also called down sampling so pulling and

142
00:10:31,970 --> 00:10:33,960
down sampling are the same things.

143
00:10:33,960 --> 00:10:39,140
So you can see it's applied convolution then it's applied pooling and you can see how it exactly works.

144
00:10:39,140 --> 00:10:44,600
You can see what kind of convolutions it has applied or what kind of filters it applied what they look

145
00:10:44,600 --> 00:10:47,520
like to see what features is looking out for.

146
00:10:47,780 --> 00:10:53,150
And then it's applying pooling so it's reducing the size and you can see here that this is important

147
00:10:53,150 --> 00:10:53,330
right.

148
00:10:53,330 --> 00:11:00,920
So you can see that this is the convulsive image and this is the pooled image and you can still see

149
00:11:00,920 --> 00:11:01,730
the same features.

150
00:11:01,730 --> 00:11:04,240
It's just less information but same features right.

151
00:11:04,250 --> 00:11:05,780
The features are preserved.

152
00:11:05,780 --> 00:11:07,970
That's the important part.

153
00:11:08,300 --> 00:11:13,520
And moreover if you know if all four was a bit to the kind of like rotated a bit to the side it would

154
00:11:13,520 --> 00:11:16,900
still be able to pick up very similar pooled layers.

155
00:11:17,000 --> 00:11:19,730
And then after that it's got more layers we haven't talked about that yet.

156
00:11:19,730 --> 00:11:26,640
So then it's got another convolution all convolution layer here which we actually won't have.

157
00:11:27,080 --> 00:11:30,800
And then it has another pool layer but it's basically just repeating that same process.

158
00:11:30,950 --> 00:11:36,110
And then after that this is what we're going to be talking further down in the course he's got the fully

159
00:11:36,110 --> 00:11:38,030
connected layers and so on.

160
00:11:38,030 --> 00:11:39,830
But you can definitely play around with that.

161
00:11:39,830 --> 00:11:47,830
So if I delete that you like if I draw a seven you will see that it actually tells you that the guesses

162
00:11:47,860 --> 00:11:52,970
it guesses that this is a seven and the second guess the second likelihood is a three.

163
00:11:52,990 --> 00:11:58,270
So you can draw some some challenging things and see if it can pick them up so let's say if I draw something

164
00:11:58,270 --> 00:12:01,910
that looks like a zero but it's not a finished zero will it pick it up.

165
00:12:01,910 --> 00:12:06,120
No this this time didn't pick it up it looks like a nine to it to the image.

166
00:12:06,130 --> 00:12:08,400
What if I kind of like finished like that.

167
00:12:08,500 --> 00:12:11,400
So now it thinks it's a zero or a nine.

168
00:12:11,620 --> 00:12:15,640
And you can see over there what's lighting up the zero or the night but we'll talk about that part for

169
00:12:15,640 --> 00:12:16,160
the dark.

170
00:12:16,580 --> 00:12:20,020
There's one more let's say like like eight.

171
00:12:20,170 --> 00:12:23,730
I think it's a pretty hard for this now picked up an eight.

172
00:12:23,740 --> 00:12:29,260
So you can see that goes into an eight and then like after that it stops being recognizable the stops

173
00:12:29,310 --> 00:12:32,060
be making sense to us humans right.

174
00:12:32,110 --> 00:12:37,990
These features that it's working with but at the same time it is correctly recognizing that it's an

175
00:12:38,020 --> 00:12:38,650
eight.

176
00:12:38,930 --> 00:12:39,040
Yeah.

177
00:12:39,070 --> 00:12:45,030
So definitely play around with that you can draw a smiley face see what happens then looks like a 3

178
00:12:45,030 --> 00:12:51,770
to this to this store because the tool is obviously trained up only on digits from zero tonight so it

179
00:12:51,780 --> 00:12:58,540
has to recognize something there are of those and it recognizes a 3 is like in life when you when you

180
00:12:58,540 --> 00:13:05,650
see something like a a type of fruit that you've never seen before like a custard apple or something

181
00:13:06,070 --> 00:13:12,520
and you think that's it's like it's it's a pear because you've never actually seen one before you don't

182
00:13:12,520 --> 00:13:18,130
know what to classify it as same thing here so it hasn't actually trained on smiley faces and that's

183
00:13:18,130 --> 00:13:20,320
why it thinks that a tree is the three.

184
00:13:20,440 --> 00:13:25,720
So there we go it's a very powerful powerful tool it'll be helpful for you to play around of it actually

185
00:13:26,080 --> 00:13:33,820
when you put your mouse over a pixel pixel you'll show it shows you where the feature detector was to

186
00:13:33,820 --> 00:13:40,780
pick up that pixel so you can see where those this pixel is coming from and also so you can see how

187
00:13:40,780 --> 00:13:44,710
the filter was kind of like going through the image exactly how we talked about it of course and here

188
00:13:44,710 --> 00:13:51,790
you can see you can see the the pooling you can see that the pulling is done with the pulling is done

189
00:13:51,790 --> 00:14:00,100
with a little square size of two by two and you can see that it is the straight of two as well just

190
00:14:00,100 --> 00:14:03,910
as we discussed in today's tutorial.

191
00:14:03,910 --> 00:14:04,560
So there we go.

192
00:14:04,600 --> 00:14:09,180
Player have a play around with that and I hope you enjoyed today's session.

193
00:14:09,190 --> 00:14:10,560
I look forward to seeing you next time.

194
00:14:10,570 --> 00:14:12,430
And until then enjoy deep learning.
