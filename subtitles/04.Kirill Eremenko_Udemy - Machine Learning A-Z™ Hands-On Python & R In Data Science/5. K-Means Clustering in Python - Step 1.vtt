WEBVTT
1
00:00:00.210 --> 00:00:04.990
Hello my friends and welcome to the practical activity of this new part.

2
00:00:05.040 --> 00:00:09.590
Part for clustering where we're gonna build two clustering models.

3
00:00:09.690 --> 00:00:12.310
K Means and hierarchical clustering.

4
00:00:12.420 --> 00:00:17.500
And of course we're gonna start with k means which is actually the most popular model in clustering.

5
00:00:17.580 --> 00:00:20.970
And indeed we will see together that it provides fantastic results.

6
00:00:21.300 --> 00:00:27.330
So you just saw the intuition lectures with real and now we're going to put that theory into practice

7
00:00:27.660 --> 00:00:32.630
by building this k means clustering model in both python and R.

8
00:00:32.630 --> 00:00:36.570
All right so first of all let's make sure everyone here is on the same page.

9
00:00:36.570 --> 00:00:42.240
This is the Google Drive folder of which you were provided the link in the previous tutorial you know

10
00:00:42.240 --> 00:00:44.460
right before this tutorial in the article.

11
00:00:44.460 --> 00:00:46.720
So make sure to connect that link.

12
00:00:46.800 --> 00:00:51.690
And now we should all be on the same page and therefore we're going to go to this folder here.

13
00:00:51.690 --> 00:00:57.960
Part for clustering and then will attack K Means clustering and we're going to start with Python of

14
00:00:57.960 --> 00:00:58.740
course.

15
00:00:58.740 --> 00:01:01.650
And this is your folder containing two fouls.

16
00:01:01.650 --> 00:01:07.800
First the K Means clustering implementation in the IPO in the format which therefore you can open with

17
00:01:08.070 --> 00:01:14.760
either Google collaboratively or Jupiter notebook and then you have more customers that CSB which is

18
00:01:14.820 --> 00:01:22.620
the C as we found the dataset with which we will work in this section to build our K Means clustering

19
00:01:22.620 --> 00:01:23.360
model.

20
00:01:23.370 --> 00:01:23.630
All right.

21
00:01:23.640 --> 00:01:29.760
So first step as usual I will explain what this dataset is about which will allow me to explain the

22
00:01:30.060 --> 00:01:31.480
purpose of this mission.

23
00:01:31.490 --> 00:01:34.770
You know the why we want to build the Caymans algorithm and what for.

24
00:01:35.040 --> 00:01:38.610
And then we'll start of course our implementation from scratch.

25
00:01:38.610 --> 00:01:43.640
Step by step and we'll take action with me to build the K Means Algorithm.

26
00:01:43.650 --> 00:01:44.280
All right.

27
00:01:44.400 --> 00:01:46.500
So what is this dataset about.

28
00:01:46.500 --> 00:01:54.330
Well as you can see by the title of this dataset mall customers well it's actually a data set made by

29
00:01:54.390 --> 00:01:54.800
a mall.

30
00:01:54.810 --> 00:02:00.720
You know the strategy team let's say of a mall that collected some data about their customers.

31
00:02:00.720 --> 00:02:02.920
So here it's important to see it this way.

32
00:02:02.970 --> 00:02:07.160
Each row corresponds to a customer of the mall.

33
00:02:07.230 --> 00:02:12.300
And for each of these customers of the mall well the data analyst of this team gathered the following

34
00:02:12.330 --> 00:02:13.210
information.

35
00:02:13.260 --> 00:02:15.960
First the customer I.D. then the jar.

36
00:02:15.960 --> 00:02:18.990
Male female then the age the annual income.

37
00:02:18.990 --> 00:02:21.070
And let's expand this.

38
00:02:21.090 --> 00:02:27.090
Well I can't win here but that less variable is the spending score and it can take values between 1

39
00:02:27.210 --> 00:02:27.910
and 100.

40
00:02:28.230 --> 00:02:31.110
So all these features are pretty clear.

41
00:02:31.110 --> 00:02:38.370
Let me explain what this one means the spending score is a metric made by the mall to measure you know

42
00:02:38.370 --> 00:02:40.560
how much each customer spends.

43
00:02:40.560 --> 00:02:44.180
And so they made this metric which takes values from 1 to 100.

44
00:02:44.190 --> 00:02:49.890
You know that's the scale of the metric such that well the lower the score the less the customer spends

45
00:02:50.010 --> 00:02:52.560
and the higher the score the more the customer spends.

46
00:02:52.560 --> 00:02:56.040
You know in a certain period of time let's say in the past year.

47
00:02:56.080 --> 00:02:56.550
Okay.

48
00:02:56.700 --> 00:03:03.710
So for example this customer actually spends a lot in this mall you know because he has a score of 81.

49
00:03:03.990 --> 00:03:10.120
However this customer spends very few in the mall because she has a score of six.

50
00:03:10.140 --> 00:03:10.680
All right.

51
00:03:10.680 --> 00:03:14.810
So that's just a metric measuring the spending of each customer.

52
00:03:14.820 --> 00:03:21.150
And so now what is the purpose of this mission what did this strategic team or analytics team want to

53
00:03:21.150 --> 00:03:21.840
do.

54
00:03:21.840 --> 00:03:25.140
Well as you might guess since right now we're doing clustering.

55
00:03:25.140 --> 00:03:29.590
This team wants to very simply understand its customers.

56
00:03:29.650 --> 00:03:36.630
You know they want to identify some patterns within its customers within its base of customers.

57
00:03:36.630 --> 00:03:38.780
And that's the key thing to understand here.

58
00:03:38.790 --> 00:03:45.000
You know when doing clustering this time as opposed to you know previously with regression and classification

59
00:03:45.240 --> 00:03:48.420
where we were actually knowing what to predict.

60
00:03:48.420 --> 00:03:52.090
Well this time we actually have no idea what to predict.

61
00:03:52.410 --> 00:03:59.280
But even though we don't know what specifically to predict we still know that we want to identify some

62
00:03:59.280 --> 00:04:01.830
patterns and that's the why of this mission.

63
00:04:01.830 --> 00:04:03.150
You know the purpose of this mission.

64
00:04:03.500 --> 00:04:03.890
OK.

65
00:04:03.920 --> 00:04:06.010
So it's good we understand the why.

66
00:04:06.030 --> 00:04:08.070
And now let us understand how.

67
00:04:08.120 --> 00:04:11.130
How are we going to identify such patterns.

68
00:04:11.130 --> 00:04:17.760
Well we will do this with Caymans of course and more specifically what we will do is we will create

69
00:04:17.910 --> 00:04:19.650
a dependent variable right.

70
00:04:19.730 --> 00:04:23.870
Will create a dependent variable which will take a finite number of values.

71
00:04:23.880 --> 00:04:31.200
You know let's say four or five values and actually each of the values will be a class of this dependent

72
00:04:31.200 --> 00:04:31.830
variable.

73
00:04:31.840 --> 00:04:33.120
We're going to create.

74
00:04:33.120 --> 00:04:35.270
And that's exactly what clustering means.

75
00:04:35.280 --> 00:04:40.560
You know technically in the details if you want to be broad on how to explain clustering you would say

76
00:04:40.560 --> 00:04:43.470
that we are identifying some parents in a data.

77
00:04:43.560 --> 00:04:48.930
But if you want to clearly explain how to identify these patterns in the data well you would say that

78
00:04:48.930 --> 00:04:51.340
we are building a dependent variable.

79
00:04:51.330 --> 00:04:57.170
You know we are creating it in such a way that each of the values of this future depend very well we

80
00:04:57.170 --> 00:05:01.480
are creating are actually the classes of this dependent variable.

81
00:05:01.490 --> 00:05:02.090
All right.

82
00:05:02.090 --> 00:05:08.870
So this will become much more clear once you know we build our Caymans algorithm and we get indeed that

83
00:05:08.930 --> 00:05:10.470
dependent variable we're creating.

84
00:05:10.520 --> 00:05:15.860
But please remember this because you know right after we build our Caymans algorithm I will actually

85
00:05:15.860 --> 00:05:19.910
remind this that indeed we are creating a dependent variable.

86
00:05:19.910 --> 00:05:20.540
All right.

87
00:05:20.630 --> 00:05:22.010
So let us do this.

88
00:05:22.010 --> 00:05:23.660
I hope you're ready and excited.

89
00:05:23.660 --> 00:05:27.860
So now we're going to close this and we're going to start our implementation.

90
00:05:27.890 --> 00:05:34.250
So feel free to open this k means clustering file with either Google collaboratively or Jupiter notebook

91
00:05:34.580 --> 00:05:36.140
whatever is your favorite.

92
00:05:36.140 --> 00:05:43.130
Now I am opening it with Google collaboratively and it is now loading it laying out the notebook.

93
00:05:43.280 --> 00:05:44.190
And there you go.

94
00:05:44.210 --> 00:05:49.700
That's the notebook for came into clustering containing the whole key means implementation.

95
00:05:49.700 --> 00:05:56.970
And now as usual this notebook is an read on the motor that all of you can access the original implementation.

96
00:05:57.140 --> 00:06:02.690
But since this is an action based course where I want all of you to learn by doing you know by taking

97
00:06:02.690 --> 00:06:07.220
action well we're going to re implement it from scratch and to do this.

98
00:06:07.220 --> 00:06:11.140
We're going to create a copy by clicking save a copy in drive.

99
00:06:11.150 --> 00:06:17.390
And as you can see this creates a copy on which you will be able to do some modifications and mostly

100
00:06:17.540 --> 00:06:19.750
re implement this Caymans model.

101
00:06:19.760 --> 00:06:20.450
All right.

102
00:06:20.450 --> 00:06:25.660
So now I hope we're on the same page ready to re implement this and to do this.

103
00:06:25.700 --> 00:06:32.060
As usual we are going to delete each of these code cells but not text sales so that we can keep that

104
00:06:32.150 --> 00:06:33.830
well highlighted structure.

105
00:06:33.830 --> 00:06:42.960
So let's remove all the code cells on the and in a second we'll have the clear structure of this came

106
00:06:42.960 --> 00:06:46.320
into implementation which is in actually five parts.

107
00:06:46.320 --> 00:06:47.550
Let's take it from here.

108
00:06:47.610 --> 00:06:49.770
First we will import the libraries.

109
00:06:49.800 --> 00:06:53.230
That's the classic first step of the data repressing phase.

110
00:06:53.280 --> 00:06:56.460
Then we'll import data set of course inevitable.

111
00:06:56.460 --> 00:07:03.050
Then we will use the elbow method to find the optimal number of clusters so that we don't have to build

112
00:07:03.050 --> 00:07:04.550
a Caymans model several times.

113
00:07:04.710 --> 00:07:11.640
Then knowing this optimal number of cluster as well we will train the Caymans model and dataset with

114
00:07:11.760 --> 00:07:13.740
that optimal number of clusters.

115
00:07:13.740 --> 00:07:16.930
And finally we will visualize the clusters.

116
00:07:16.980 --> 00:07:17.680
All right.

117
00:07:17.760 --> 00:07:19.110
So perfect.

118
00:07:19.110 --> 00:07:23.350
That was the introductory tutorial where we explain instead of everything.

119
00:07:23.400 --> 00:07:29.300
And now in the next tutorial we will start with the very first step which is the data repressing phase.

120
00:07:29.310 --> 00:07:36.180
And as you can see I actually prepared our data depressing template because even for clustering Well

121
00:07:36.450 --> 00:07:41.670
the data processing phase will be almost the same as you can see we are importing the libraries importing

122
00:07:41.670 --> 00:07:42.450
the data set.

123
00:07:42.570 --> 00:07:47.790
But then we won't have to of course split the data set into the training sets and test it because indeed

124
00:07:47.940 --> 00:07:53.680
getting the training set and a test set implies having a dependent variable containing the real results.

125
00:07:53.680 --> 00:07:56.420
And at this point we don't have a dependent variable.

126
00:07:56.430 --> 00:07:59.510
We were just trying to identify one and to create one.

127
00:07:59.700 --> 00:08:00.350
All right.

128
00:08:00.420 --> 00:08:03.640
So no splitting the data sets into the training set and.

129
00:08:03.780 --> 00:08:09.720
And therefore what I would like you to do now before we do it together in the next material is to implement

130
00:08:09.720 --> 00:08:16.560
yourself as that data repricing phase with only these two first code cells you will get a solution and

131
00:08:16.560 --> 00:08:19.870
then of course we will implement a solution together.

132
00:08:19.890 --> 00:08:22.970
So I'll see you in the next material to start this implementation.

133
00:08:23.100 --> 00:08:24.900
And until then enjoy machine learning.
