1
00:00:01,780 --> 00:00:05,340
Hello and welcome back to the course on machine learning.

2
00:00:05,440 --> 00:00:08,760
Today we're talking about the multi armed bandit problem.

3
00:00:08,800 --> 00:00:14,560
Don't you just love these names and they come up such cool names for machine learning algorithms and

4
00:00:14,560 --> 00:00:15,880
problems.

5
00:00:15,880 --> 00:00:23,740
Well today we're indeed talking about this problem and it is the example that we're going to be using

6
00:00:23,740 --> 00:00:25,850
in this whole section on reinforcement learning.

7
00:00:25,840 --> 00:00:31,420
We're going to be looking at different ways that we can solve the multi armed bandit problem and comparing

8
00:00:31,420 --> 00:00:32,370
the results.

9
00:00:32,680 --> 00:00:37,960
But before we can do you I just wanted to mention that the Malte armband The problem is not the only

10
00:00:38,440 --> 00:00:43,330
problem that can be solved with reinforcement learning reinforcement learning is actually really really

11
00:00:43,330 --> 00:00:49,250
cool reinforcement learning for instance is used to train robot dogs to walk.

12
00:00:49,270 --> 00:00:55,660
And I'll give you a quick example for instance you can once you've created a robot dog you can implement

13
00:00:55,660 --> 00:01:00,080
an algorithm inside the robot dog which will tell it how to walk you can tell it.

14
00:01:00,220 --> 00:01:00,460
All right.

15
00:01:00,460 --> 00:01:05,740
Move your front right foot and then move your left back foot and then Front Left foot right back foot

16
00:01:05,740 --> 00:01:10,090
and so on you can actually give the sequence of actions that it needs to take in order to accomplish

17
00:01:10,090 --> 00:01:11,580
a task which is walking.

18
00:01:11,740 --> 00:01:19,690
Or you can implement arean Forsman learning algorithm which will train the dog to walk in a very very

19
00:01:19,780 --> 00:01:20,500
interesting way.

20
00:01:20,500 --> 00:01:25,490
So basically what it will do is they'll say hey dog here are all the actions you can take.

21
00:01:25,930 --> 00:01:29,100
You can move your legs like this you can move your legs like that.

22
00:01:29,110 --> 00:01:32,850
And your goal is to make a step forward.

23
00:01:32,860 --> 00:01:39,670
Every time you make a step forward you are given a reward every time you fall over you're given a punishment

24
00:01:39,700 --> 00:01:45,790
and a reward is basically a one in the arm you don't actually have to give it a carrot or you know something

25
00:01:46,390 --> 00:01:46,910
to eat.

26
00:01:46,930 --> 00:01:50,850
You just give it a 1 in algorithm and a punishment is zero.

27
00:01:50,950 --> 00:01:55,870
And basically every time he takes a step forward it knows it's got a reward and it will just that's

28
00:01:55,870 --> 00:01:56,320
good for it.

29
00:01:56,320 --> 00:02:03,100
So basically you will try all these random sets of actions and see what they lead to every time it takes

30
00:02:03,100 --> 00:02:03,670
a step forward.

31
00:02:03,670 --> 00:02:09,340
Remember that those were good actions and will try to repeat them more and more and actually dogs like

32
00:02:09,340 --> 00:02:11,780
that can learn to walk.

33
00:02:11,860 --> 00:02:17,740
So you don't have to program an actual walking algorithm into it Ill figure out the steps it needs to

34
00:02:17,740 --> 00:02:18,870
take on its own.

35
00:02:18,910 --> 00:02:27,040
I think that's really mind blowing and really cool but unfortunately that is a more a topic more of

36
00:02:27,310 --> 00:02:31,050
on the side of artificial intelligence rather than just machine learning.

37
00:02:31,180 --> 00:02:35,020
And that is you know there can be a whole course on its own.

38
00:02:35,020 --> 00:02:40,930
We're not going to delve into the training robot dogs to walk inside this section inside this section.

39
00:02:40,960 --> 00:02:46,450
We are going to talk about the multi armed bandit problem which is a bit of a different application

40
00:02:46,810 --> 00:02:51,790
of this machine learning branch of reinforcement learning.

41
00:02:52,100 --> 00:02:56,810
And plus of course there's other lots of other applications of reinforcement learning as well.

42
00:02:56,950 --> 00:03:00,880
So moving on to our multi armed bandit problem.

43
00:03:00,880 --> 00:03:05,810
So first of all what on earth is a multi armed bandit right.

44
00:03:05,820 --> 00:03:11,970
So the first thing that comes to mind is like a robber going into a bank and so on and or somebody for

45
00:03:11,980 --> 00:03:19,830
gun but actually a bandit or a one armed band the sort of thing let's simplify things.

46
00:03:20,000 --> 00:03:23,890
A one armed bandit is a slot machine.

47
00:03:23,890 --> 00:03:24,160
Right.

48
00:03:24,160 --> 00:03:25,130
It's one of these.

49
00:03:25,180 --> 00:03:28,120
And why is it called the warm one arm bandit.

50
00:03:28,120 --> 00:03:30,560
Well has got a bit of a history there.

51
00:03:30,760 --> 00:03:35,490
Back in the day they used to have this handle on the right and you could still see their movies and

52
00:03:35,490 --> 00:03:41,050
maybe some places you can still find these slot machines where you actually have to pull the handle

53
00:03:41,050 --> 00:03:46,480
because now they're all electronic and you just press a button right there push push push slot machines.

54
00:03:46,780 --> 00:03:57,120
Whereas back in there you had to pull the lever to make it work to like initiate the game.

55
00:03:57,250 --> 00:04:00,020
And so hence the arm.

56
00:04:00,040 --> 00:04:01,090
But why is it called the bandit.

57
00:04:01,090 --> 00:04:09,310
Well because these machines they would actually you know these are this is one of the quickest way to

58
00:04:09,310 --> 00:04:12,750
lose your money in a casino.

59
00:04:12,820 --> 00:04:14,430
They would take.

60
00:04:14,890 --> 00:04:21,550
I think it was like a 50 percent chance that they would take away your money back in the day so they

61
00:04:21,550 --> 00:04:25,950
would of course you earn less than your.

62
00:04:26,170 --> 00:04:27,640
You're actually winning.

63
00:04:27,640 --> 00:04:34,750
And it was about you know a 50/50 chance whether or not you actually make a or you get a win or you

64
00:04:34,750 --> 00:04:37,940
lose money but then they put a bug into them.

65
00:04:38,020 --> 00:04:42,580
They could read up a little bit on line they put a bug into them that people who were playing them were

66
00:04:42,580 --> 00:04:46,210
losing even faster than were even more frequent than 50 percent.

67
00:04:46,210 --> 00:04:50,380
So hence the name bandit because it was basically robbing you of your money.

68
00:04:50,530 --> 00:04:56,800
And you know one of the quickest way to ways to lose your money hands them all to oh that's what's called

69
00:04:56,800 --> 00:04:58,440
the one armed bandit.

70
00:04:58,870 --> 00:05:00,580
And what does the multi-hour bandit.

71
00:05:00,580 --> 00:05:09,100
Well the a multi armed bandit problem is kind of the challenge that a person is faced when he comes

72
00:05:09,100 --> 00:05:15,870
up to a whole set of these machines when he doesn't have just one has like five or ten hour programming

73
00:05:15,900 --> 00:05:21,650
examples will have an example of 10 but we won't be talking specifically about these machines of course

74
00:05:21,650 --> 00:05:28,870
this is this is the historic problem you'll see just now we'll see that there are many many other applications

75
00:05:29,770 --> 00:05:37,060
that even though it's called the multi are problem it's actually used to solve many other problems as

76
00:05:37,060 --> 00:05:38,080
well.

77
00:05:38,080 --> 00:05:42,590
So basically here you're faced with challenge you've got five of these machines right.

78
00:05:42,610 --> 00:05:52,150
And how do you actually play them to maximize your return from the number of games that you can actually

79
00:05:52,150 --> 00:05:52,330
play.

80
00:05:52,330 --> 00:05:57,460
So you've you know you decided you're going to play you know a hundred times or a thousand times and

81
00:05:57,460 --> 00:05:58,810
you want to maximize return.

82
00:05:58,810 --> 00:06:04,090
How do you figure out which ones of them to play in order to maximize your returns.

83
00:06:04,090 --> 00:06:12,040
Well the problem to describe the problem in more detail we've got to mention that's the assumption here

84
00:06:12,040 --> 00:06:20,200
is that each one of these machines has a distribution behind it so there's a distribution of numbers

85
00:06:20,330 --> 00:06:24,780
out of which or outcomes out of which the machine picks results right.

86
00:06:24,790 --> 00:06:31,260
So it has it has like H1-Bs machines has its own distribution and it picks out a result.

87
00:06:31,270 --> 00:06:36,250
You could you pull the trigger and it just picks out randomly out of its distribution result an outcome

88
00:06:36,250 --> 00:06:39,010
you know whether they win or whether you lose and how much you win.

89
00:06:39,040 --> 00:06:43,660
How much use or could you lose the same money you just put in the coin.

90
00:06:43,810 --> 00:06:49,970
But basically it tells you whether you win or lose based on the distribution that's built into the machine.

91
00:06:49,990 --> 00:06:53,760
But the problem here is that you don't know these distribution right.

92
00:06:53,770 --> 00:06:59,110
You don't know in advance what the distributions are and they are assumed to be different for these

93
00:06:59,110 --> 00:06:59,820
machines.

94
00:06:59,830 --> 00:07:05,080
Sometimes it can be similar or the same in some of the machines but by by default they are different

95
00:07:06,130 --> 00:07:14,470
and your goal is to figure out which of these distributions is the best one for you so let's have a

96
00:07:14,470 --> 00:07:14,650
look.

97
00:07:14,650 --> 00:07:16,660
So there are these this should be sions right.

98
00:07:16,660 --> 00:07:22,870
So for example we've got these five machines the five distributions and as you can see right away just

99
00:07:22,870 --> 00:07:25,920
by looking at this which is the best machine right away.

100
00:07:26,140 --> 00:07:28,160
Obviously the one on the right.

101
00:07:28,210 --> 00:07:32,180
The orange one is the best machine because it's got the best.

102
00:07:32,470 --> 00:07:36,970
You know it's the most left skewed left cues because the tails on the left.

103
00:07:36,970 --> 00:07:39,070
So it's got the most favorable outcomes.

104
00:07:39,080 --> 00:07:41,320
Got the highest mean median and mode.

105
00:07:41,410 --> 00:07:48,280
And you if you knew these distributions and was you would obviously just go to the fifth machine and

106
00:07:48,280 --> 00:07:53,800
you would bet on the machine with machine just on the machine all the time because it's got the best

107
00:07:53,800 --> 00:07:54,520
distribution right.

108
00:07:54,520 --> 00:07:58,980
So on average you would get the best results but you don't know that you don't know that in advance.

109
00:07:58,990 --> 00:08:05,330
And your goal is to figure out you know this is like a it's like a mind game.

110
00:08:05,350 --> 00:08:12,240
You know there's all these movies about machine learning and really cool all the cool mathematics on

111
00:08:12,250 --> 00:08:14,400
how they're using they're cool.

112
00:08:14,440 --> 00:08:23,410
Really good movie was imitation game right about Alan Turing and the and how he was solving the enigma

113
00:08:23,410 --> 00:08:29,050
and so on but a similar kind of concept you don't know which one of these is the best you're going to

114
00:08:29,050 --> 00:08:29,570
figure it out.

115
00:08:29,590 --> 00:08:33,810
But at the same time you are already spending your money doing this right.

116
00:08:33,820 --> 00:08:39,310
You can just you know the longer you take to figure it out there's a tradeoff right.

117
00:08:39,310 --> 00:08:46,770
The longer you take to figure it out the more money you'll probably spend on the wrong ones.

118
00:08:46,990 --> 00:08:49,310
And therefore you have to figure out very quickly.

119
00:08:49,540 --> 00:08:53,170
So there are these two factors that are in play exploration and exploitation.

120
00:08:53,200 --> 00:08:58,890
So you need to explore the machines to find out which one of them is the best one.

121
00:08:58,990 --> 00:09:05,740
And at the same time you need to as soon as you can already start exploiting exploiting these machines

122
00:09:05,740 --> 00:09:09,340
exploiting your findings to make the maximum return.

123
00:09:09,340 --> 00:09:15,280
So basically and there's another methodical con. We finally had all this which is called regret and

124
00:09:15,370 --> 00:09:17,920
regret is it is mathematically defined.

125
00:09:17,920 --> 00:09:21,220
And if you can read more about this is a goal is a really good white paper on it.

126
00:09:21,220 --> 00:09:27,170
It's called using confidence bounds for exploitation and exploration of tradeoffs.

127
00:09:27,250 --> 00:09:37,720
And it is by Pyrrha a lawyer or a PR from Graz University of Technology in Austria really like the white

128
00:09:37,720 --> 00:09:43,600
paper it goes into a lot of detail like I didn't read the whole thing but the first couple of chapters

129
00:09:43,600 --> 00:09:44,490
are pretty good.

130
00:09:44,620 --> 00:09:53,060
If you want to go into detail but basically regret is is when it suffered when you're using an non alternative

131
00:09:53,370 --> 00:09:54,580
not optimal method.

132
00:09:54,580 --> 00:09:54,810
Right.

133
00:09:54,810 --> 00:10:01,720
So the one on the right is the optimal or the one underwrites the optimal machine whenever using the

134
00:10:01,720 --> 00:10:09,040
non-option machine you have a regret which which can be quantified as like as the difference between

135
00:10:09,040 --> 00:10:16,120
the best outcome and the best outcome and you know all of those sums of the money that you put like

136
00:10:16,120 --> 00:10:20,840
your opportunity cost of actually exploring other machines.

137
00:10:20,850 --> 00:10:25,520
And so the longer you explore other non-optimal machines the higher regret.

138
00:10:25,540 --> 00:10:29,710
But at the same time if you don't explore for long enough right.

139
00:10:29,740 --> 00:10:36,020
If you explore if you don't explore for long or long enough then your and a suboptimal machine might

140
00:10:36,020 --> 00:10:38,350
or might appear as an optimal machine.

141
00:10:38,350 --> 00:10:44,530
So for instance this machine or here writes If we explore explore explore but we don't spend enough

142
00:10:44,530 --> 00:10:49,300
time exploring we might think that this is the best machine because it's got quite a good return right

143
00:10:49,300 --> 00:10:53,710
close to this one and we might start exploiting this one for the rest of the time.

144
00:10:53,800 --> 00:10:56,440
But in reality this one was the best one.

145
00:10:56,440 --> 00:11:05,650
So the goal is to find the best one and exploit the best one but spend the least amount of time exploring

146
00:11:05,680 --> 00:11:06,540
all of them.

147
00:11:06,610 --> 00:11:10,770
And while you're exploring you're still earning money but not from the opposite machine right.

148
00:11:10,810 --> 00:11:12,150
So that's the goal.

149
00:11:12,190 --> 00:11:18,040
That's the point of this whole exercise and it's important to understand here that there is the best

150
00:11:18,040 --> 00:11:18,320
one.

151
00:11:18,340 --> 00:11:25,920
So that is where even though these machines you know they have like jackpots sometimes and so on.

152
00:11:25,930 --> 00:11:28,640
But we are assuming that there's just that.

153
00:11:28,690 --> 00:11:33,010
These distributions are finite there and out of them.

154
00:11:33,040 --> 00:11:38,760
There is a best one that you are looking for that's kind of the emphasis or the whole assumption on

155
00:11:38,760 --> 00:11:43,770
this problem if there are more complex options and versions of this problem.

156
00:11:43,780 --> 00:11:49,680
And again check out some additional reading on that topic.

157
00:11:49,690 --> 00:11:51,690
That's that's more even more advanced.

158
00:11:51,700 --> 00:11:54,760
But what we're going to be using this for is that's going to be sufficient.

159
00:11:54,790 --> 00:11:56,630
And why is it going to be sufficient for us.

160
00:11:56,770 --> 00:12:03,430
Because the most common modern application of this that we can think of is the one that we're going

161
00:12:03,430 --> 00:12:07,150
to be exploring is advertising voila.

162
00:12:07,160 --> 00:12:09,850
So let's have a look at some ads going to be fun.

163
00:12:09,920 --> 00:12:15,050
So just a disclaimer this there is no affiliation with Coca-Cola examples are used just for educational

164
00:12:15,050 --> 00:12:15,950
purposes.

165
00:12:15,950 --> 00:12:16,300
All right.

166
00:12:16,300 --> 00:12:17,640
So let's have a look.

167
00:12:17,930 --> 00:12:25,940
We have let's say Coca-Cola or some company wants to run a campaign and it's going to be called Welcome

168
00:12:25,940 --> 00:12:28,180
to the Coke Side of Life campaign.

169
00:12:28,280 --> 00:12:33,140
And if you search this campaign online you'll see that they had you know hundreds of different ads that

170
00:12:33,260 --> 00:12:35,360
they came up with for this campaign.

171
00:12:35,520 --> 00:12:37,750
And here's here's one example them.

172
00:12:37,790 --> 00:12:42,650
These are just some images I pulled from Google so maybe these are even drawn by people but we're going

173
00:12:42,650 --> 00:12:48,500
to assume that these are legitimate ads that we're going to go into the campaign as well we want to

174
00:12:48,500 --> 00:12:51,350
find out which is the best ad which is the ad that it works.

175
00:12:51,350 --> 00:12:52,220
So we've got options.

176
00:12:52,220 --> 00:12:53,250
Number one.

177
00:12:53,270 --> 00:12:57,360
Number two three and before and number five.

178
00:12:57,560 --> 00:13:03,800
And so now our goal is to find out which ad works to maximize our returns.

179
00:13:03,800 --> 00:13:05,940
But right now we don't know which has worked the best right.

180
00:13:05,960 --> 00:13:13,640
So there's no there is a distribution behind it but that distribution will only become known after thousands

181
00:13:13,640 --> 00:13:15,780
and thousands and thousands of people.

182
00:13:15,860 --> 00:13:20,120
Look at these ads and click or not click on these ads and this is actually going to be very similar

183
00:13:20,120 --> 00:13:21,920
to the example that we're going to be looking at.

184
00:13:21,920 --> 00:13:26,780
The example that had LUNs going to be walking you through in the programming tutorials in that example

185
00:13:26,780 --> 00:13:27,900
actually going have 10 ads.

186
00:13:27,900 --> 00:13:29,050
So even more.

187
00:13:29,220 --> 00:13:31,220
And so what can you do here.

188
00:13:31,220 --> 00:13:34,540
Well one way to approach a problem is just run an AB test drive.

189
00:13:34,550 --> 00:13:44,780
So take your five or 50 or 500 ads and run a huge AB test with multiple AB test and wait until you have

190
00:13:44,780 --> 00:13:53,300
enough of a large enough sample and then conclude which is the best right with certain confidence.

191
00:13:53,300 --> 00:13:59,780
But the problem of that is that you would spend a lot of time and money doing that right.

192
00:13:59,780 --> 00:14:02,830
So an AB test is pure exploration right.

193
00:14:02,840 --> 00:14:08,260
You're not exploiting the best option you are exploiting the best option but to the same extent as you're

194
00:14:08,270 --> 00:14:10,460
exploiting the non optimal options right.

195
00:14:10,460 --> 00:14:16,220
So if if we go by our previous distributions if this is the best one if you just want an AB test then

196
00:14:16,520 --> 00:14:23,570
your uniformly distributing or you uniformly using these 5 options and therefore as much as using this

197
00:14:23,580 --> 00:14:24,830
one you're using all four.

198
00:14:24,830 --> 00:14:27,530
All four of them so basically all five of them.

199
00:14:27,530 --> 00:14:35,210
So basically you are exploiting it a bit but on unconsciously you arrive in a random way and therefore

200
00:14:35,420 --> 00:14:38,460
AB tests are just for exploration.

201
00:14:38,460 --> 00:14:46,130
So the challenge is to find out which is the best one but do it while you're exploring.

202
00:14:46,170 --> 00:14:53,000
While you're not to exploit the best one while you're exploring for it dries so find out which of them

203
00:14:53,000 --> 00:14:57,240
is the best one in the process of.

204
00:14:57,920 --> 00:14:59,520
Hold on fire.

205
00:14:59,540 --> 00:15:03,190
Find out which is the best one in the process of the actual launch campaign.

206
00:15:03,200 --> 00:15:04,960
So not don't have two phases.

207
00:15:04,970 --> 00:15:07,130
You do the AB test and then use them most.

208
00:15:07,130 --> 00:15:13,280
The best one but actually find out the best one in the quickest way possible and start exploiting it

209
00:15:13,310 --> 00:15:14,270
along the way.

210
00:15:14,270 --> 00:15:17,690
So that's the challenge here and that's what we're going to be solving.

211
00:15:17,930 --> 00:15:22,590
And that's the modern application of the multi armed bandit problem.

212
00:15:22,790 --> 00:15:24,560
So hopefully you're excited about this.

213
00:15:24,560 --> 00:15:27,620
We've got two great algorithms coming up.

214
00:15:27,620 --> 00:15:29,160
Can't wait to get started.

215
00:15:29,210 --> 00:15:31,020
I look for in the next tutorial.

216
00:15:31,070 --> 00:15:33,310
And until then enjoy machine learning.
