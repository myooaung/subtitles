1

00:00:01,410  -->  00:00:02,570
Great to see you back here.

2

00:00:02,580  -->  00:00:08,500
And today we're going to look at the handy trick that will help your models become a more robust.

3

00:00:08,580  -->  00:00:14,190
Before we continue though I wanted to quickly recap on what we did last night and what we did is we

4

00:00:14,190  -->  00:00:22,380
use the backward elimination method to construct a multiple linear regression using our data and through

5

00:00:22,380  -->  00:00:26,490
that method we constructed four separate models you can see them on the in the background here so Model

6

00:00:26,490  -->  00:00:29,010
1 2 3 and then 4.

7

00:00:29,130  -->  00:00:35,040
And when we get to model 4 we were only left with one independent variable spent on research and development

8

00:00:35,250  -->  00:00:40,860
because all of the other ones were eliminated and basically we completed the backward elimination process

9

00:00:40,880  -->  00:00:41,040
.

10

00:00:41,190  -->  00:00:48,090
However we were left with kind of a feeling that maybe we shouldn't have excluded the last variable

11

00:00:48,240  -->  00:00:48,870
and why is that.

12

00:00:48,870  -->  00:00:56,220
Well first of all we saw that this P-value is not that much bigger than the significance level that

13

00:00:56,220  -->  00:01:03,780
we selected we select a significant level of 0.05 the P-value 0.06 So just a bit greater than the threshold

14

00:01:03,780  -->  00:01:04,230
.

15

00:01:04,290  -->  00:01:09,780
So that kind of leaves us with a feeling maybe we shouldn't have excluded that variable.

16

00:01:09,780  -->  00:01:17,260
The problem here is that this these methods this step was a regression methods they are very arbitrary

17

00:01:17,260  -->  00:01:17,280
.

18

00:01:17,280  -->  00:01:25,410
So once you select your significance level threshold you got to stick to it right you use which is 0.05

19

00:01:25,410  -->  00:01:25,430
.

20

00:01:25,440  -->  00:01:30,990
This one Serpens 0 6 so there's greater and we've just got to cut it off and not look not look back

21

00:01:30,990  -->  00:01:33,510
anymore and just proceed with the method.

22

00:01:33,540  -->  00:01:42,900
So how can we improve our method of building models to assess situations like that and give you like

23

00:01:42,930  -->  00:01:49,080
an extra opinion or have another criteria to tell us whether or not we should have actually kept this

24

00:01:49,260  -->  00:01:50,040
variable.

25

00:01:50,310  -->  00:01:55,230
And there is a way and we're going to talk about it right now.

26

00:01:55,230  -->  00:01:59,320
So let's look at the top part over here.

27

00:01:59,850  -->  00:02:06,510
The top part is responsible for the variable so you have the coefficients and you've got the p values

28

00:02:06,570  -->  00:02:06,960
and so on.

29

00:02:06,960  -->  00:02:09,870
So we've talked about it quite quite extensively.

30

00:02:10,020  -->  00:02:11,510
But let's look at the bottom part.

31

00:02:11,520  -->  00:02:17,980
The second part of our report and here as we discussed before we've got the stats there are for the

32

00:02:18,000  -->  00:02:18,690
model as a whole.

33

00:02:18,690  -->  00:02:21,870
So how well has been fitted how well it's working and so on.

34

00:02:21,870  -->  00:02:29,550
So the stats that we'll be looking at today are are squared and adjusted r squared and they will help

35

00:02:29,550  -->  00:02:38,970
us come up with a cool approach integrated approach to improve our backward elimination method.

36

00:02:38,970  -->  00:02:44,630
So we already talked about both R-squared and adjusted R-squared in that section of course.

37

00:02:44,640  -->  00:02:48,990
However if you chose to skip that section because you're not interested in the formulas and so on then

38

00:02:48,990  -->  00:02:50,840
I'll quickly recap for you now.

39

00:02:51,270  -->  00:03:00,360
So R-squared we're here is basically a characteristic or a parameter of your model which tells you about

40

00:03:00,360  -->  00:03:01,200
the goodness of fit.

41

00:03:01,200  -->  00:03:06,910
So how will your model has been fitted and R-squared squared can never be greater than one and you wanted

42

00:03:06,930  -->  00:03:09,290
to be as close to one as possible.

43

00:03:09,340  -->  00:03:14,110
The closer to one it is the better your model is deemed to be fitted.

44

00:03:14,320  -->  00:03:23,310
However R-Squared is biased and it's biased in a way that the way is constructed and the way these models

45

00:03:23,310  -->  00:03:23,750
are run.

46

00:03:23,760  -->  00:03:32,790
So the ordinary least squares method it doesn't allow R-squared to ever decrease so the more variables

47

00:03:32,790  -->  00:03:35,760
you add to your model the greater R-squared will be.

48

00:03:35,760  -->  00:03:41,850
So basically what we're what this means is that as long as you keep adding variables R-squared will

49

00:03:41,850  -->  00:03:46,860
always grow and we can observe that here so if we start from the end where we have only one variable

50

00:03:47,040  -->  00:03:49,670
you can see that R-Squared is zero point ninety four.

51

00:03:49,890  -->  00:03:51,190
Then R-squared became.

52

00:03:51,330  -->  00:03:54,580
Well if you go this way it's 0.35.

53

00:03:54,830  -->  00:03:56,890
There is zero point ninety five 0 7.

54

00:03:56,910  -->  00:04:01,680
So as you can see the more variables we have the greater R-squared gets and that's that's always going

55

00:04:01,680  -->  00:04:06,270
to be the case just because of the way R-Squared is derived.

56

00:04:06,420  -->  00:04:11,910
And moreover you can even include completely around a variable so if I throw into this model I throw

57

00:04:11,910  -->  00:04:18,610
another variable which is basically the temperature outside like air temperature outside right now then

58

00:04:18,680  -->  00:04:18,800
.

59

00:04:18,900  -->  00:04:21,300
And I throw that in as an independent variable.

60

00:04:21,320  -->  00:04:26,340
Of course it's not a predictor it can predict a profit of a company in our works in New York or California

61

00:04:26,360  -->  00:04:26,570
.

62

00:04:26,850  -->  00:04:33,540
But R-Squared is still going to grow and is going to imply that our model is now even better fitted

63

00:04:33,540  -->  00:04:34,050
.

64

00:04:34,110  -->  00:04:39,320
So that way our square is biased and that's where adjusted R-squared comes into play adjusted R-squared

65

00:04:39,330  -->  00:04:47,550
is very similar to our square has got a very simple formula but it actually has a penalization factor

66

00:04:47,550  -->  00:04:47,830
.

67

00:04:47,880  -->  00:04:55,350
So basically just like R-squared would grow if you add more variables that are square would also grow

68

00:04:55,360  -->  00:05:02,580
but there is a factor which makes it small which reduces the adjusted R-squared as you add more variables

69

00:05:02,580  -->  00:05:02,840
.

70

00:05:02,850  -->  00:05:06,990
So there's kind of these two effects battling each other on one hand it's growing because of the way

71

00:05:06,990  -->  00:05:12,710
it's constructed on the other hand the penalization factor is penalizing you or penalizing that just

72

00:05:12,710  -->  00:05:15,320
in R-squared and reducing it every time you add a variable.

73

00:05:15,320  -->  00:05:22,440
So basically if the variable that you added doesn't make adjusted or doesn't make R-squared grow that

74

00:05:22,440  -->  00:05:27,660
much like for instance here you can see 0.9 5 0 5 2 0 9 5 0 7.

75

00:05:27,660  -->  00:05:30,170
So it only grew by a fraction.

76

00:05:30,180  -->  00:05:31,770
Very very small amount.

77

00:05:31,770  -->  00:05:37,410
Well if that happens then the penalization factor is going to overwhelm this growth and therefore the

78

00:05:37,410  -->  00:05:40,560
adjusted R-squared is actually going to decrease in that scenario.

79

00:05:40,830  -->  00:05:47,430
And that way we can use and we will use the adjusted R-squared to watch the goodness of fit all of our

80

00:05:47,430  -->  00:05:49,550
models and how it changes.

81

00:05:49,560  -->  00:05:50,810
So let's let's go ahead and do that.

82

00:05:50,820  -->  00:05:53,330
Let's observe that just at R-squared in our method.

83

00:05:53,580  -->  00:05:55,760
What was the adjusted R-squared here it was sir.

84

00:05:55,800  -->  00:05:57,450
Point 9 4.

85

00:05:58,110  -->  00:06:07,470
Then once we excluded administration expenses adjusted R-squared went from 0.9 foot 5 to 0.9 4 7 5.

86

00:06:07,470  -->  00:06:14,160
So as you can see here adjusted R-squared went up where it just basically what that means is that the

87

00:06:14,310  -->  00:06:16,320
model is now better.

88

00:06:16,320  -->  00:06:19,470
It's been it's fitted better it works.

89

00:06:19,920  -->  00:06:26,550
These variables in this combination fit the profit variable fit this model to explain the profit variable

90

00:06:26,550  -->  00:06:31,060
better than these variables in this combination to explain the profit variable which is good.

91

00:06:31,060  -->  00:06:32,020
It's a good step.

92

00:06:32,250  -->  00:06:33,090
Okay.

93

00:06:33,090  -->  00:06:37,980
So that means we improved Amahl here adjusted R-squared is 0.9 475.

94

00:06:38,010  -->  00:06:43,140
Let's see what happens when we move to the next step and the next step adjusted R-squared is zero point

95

00:06:43,350  -->  00:06:44,980
nine for a 3.

96

00:06:44,970  -->  00:06:53,130
So it went up again meaning that once again we improved our model so altogether these variables are

97

00:06:53,130  -->  00:06:58,860
doing a better job explaining profit then these variables together are doing a job explaining profit

98

00:06:58,870  -->  00:06:59,040
.

99

00:06:59,160  -->  00:06:59,820
That's great.

100

00:06:59,820  -->  00:07:01,370
We improved our model again.

101

00:07:01,950  -->  00:07:06,190
And now let's see what happens when we take out the last variable marketing spend.

102

00:07:06,210  -->  00:07:14,380
So we went from adjusted R-squared 0.9 8 3 to adjusted R-squared 0.9 for 5 4.

103

00:07:14,610  -->  00:07:15,900
And what does that tell us.

104

00:07:15,900  -->  00:07:24,780
Our risk adjusted R-squared went down and went down by from by zero point zero 03 approximately.

105

00:07:24,780  -->  00:07:32,970
So that means that this model this new model is actually worse than this model so this model was better

106

00:07:32,970  -->  00:07:40,870
fitted to predict or explain the variance in profit than this model is doing so.

107

00:07:41,460  -->  00:07:42,030
So there you go.

108

00:07:42,030  -->  00:07:49,080
So even though we excluded a variable according to our Bacary elimination method this may this variable

109

00:07:49,080  -->  00:07:55,300
shouldn't have been excluded because it was Improve it was with this measure of variable.

110

00:07:55,320  -->  00:08:04,680
This model is actually working better and that is your takeaway handy trick how to observe your models

111

00:08:04,830  -->  00:08:07,630
and how to create them.

112

00:08:07,650  -->  00:08:14,310
You don't only just follow the backwards elimination or whatever method that you are using and arbitrarily

113

00:08:14,340  -->  00:08:22,440
follow the rules just instead follow the rules but also watch the adjusted R-squared and see if it's

114

00:08:22,440  -->  00:08:23,250
actually improving.

115

00:08:23,250  -->  00:08:25,090
So if it's growing then you're doing the right thing.

116

00:08:25,290  -->  00:08:28,850
As soon as you see are adjusted our square drop then you have to stop and question.

117

00:08:28,910  -->  00:08:30,450
I just do the right thing or not.

118

00:08:30,450  -->  00:08:31,410
And you know what.

119

00:08:31,410  -->  00:08:37,250
What is the trade off of excluding a certain variable or opposite of including this variable.

120

00:08:37,260  -->  00:08:42,070
So I just it R-Squared is the kind of your indicator how you're going along the way.

121

00:08:42,600  -->  00:08:44,420
But that's it for today.

122

00:08:44,430  -->  00:08:50,790
Hope you find this just one hope you can apply you'll find ways to apply this in your actual work.

123

00:08:51,020  -->  00:08:52,330
I look forward to seeing you next time.

124

00:08:52,410  -->  00:08:53,940
And until then I'd be analyzing
