1

00:00:00,390  -->  00:00:02,730
Hello and welcome to this art tutorial.

2

00:00:02,810  -->  00:00:08,610
So in the previous tutorial we plotted our den program to find the optimal number of clusters and the

3

00:00:08,610  -->  00:00:11,250
result was five clusters.

4

00:00:11,280  -->  00:00:16,710
So now this new step since we have this optimal number of clusters we are going to fit the hierarchical

5

00:00:16,710  -->  00:00:21,320
clustering algorithm to our data X with obviously five clusters.

6

00:00:21,570  -->  00:00:27,010
OK so the first thing that we need to do is to create a new object of the age class class.

7

00:00:27,150  -->  00:00:33,270
And actually this is something that we already did because if we go back to Step 2 here when we wrote

8

00:00:33,450  -->  00:00:39,930
then program equals h Clast then the distance matrix and the word method we actually created enough

9

00:00:39,950  -->  00:00:45,660
not ject of the H class class and we're going to do the exact same thing right now we're going to create

10

00:00:45,810  -->  00:00:48,810
the exact same object from the class class.

11

00:00:48,870  -->  00:00:53,570
So I'm going to copy this line of code pasted here in step three.

12

00:00:53,850  -->  00:00:59,190
And I'm just going to change the name of the object just to make things nice and clear.

13

00:00:59,250  -->  00:01:02,410
So let's replace here DENTRO from by age C..

14

00:01:02,670  -->  00:01:06,000
And now we have the same object as before only with a different name.

15

00:01:06,270  -->  00:01:11,950
And this actually makes sense because by building a general grum we actually do all the steps of hierarchical

16

00:01:11,970  -->  00:01:19,340
clustering and among all these steps there is this step in which the algorithm found five clusters.

17

00:01:20,310  -->  00:01:23,360
So that means that this object contains the information.

18

00:01:23,400  -->  00:01:30,000
When we have five clusters and so now let's use this object to build our vector of clusters that is

19

00:01:30,000  -->  00:01:35,790
the vector that will tell us which cluster each customer belongs to and to build this vector we're going

20

00:01:35,790  -->  00:01:40,880
to use one of the method of the H class class which is the cat tree method.

21

00:01:41,070  -->  00:01:46,740
So we're going to color vector of clusters y underscore H C equals.

22

00:01:46,920  -->  00:01:50,010
Then we use the cat tree method of the H class class.

23

00:01:50,010  -->  00:01:58,130
So let's type cat tree and then press 1 and then we see that this method requires three arguments.

24

00:01:58,260  -->  00:02:00,010
The first argument is tree.

25

00:02:00,210  -->  00:02:03,720
And of course it's our danger Graham that we just renamed H.C..

26

00:02:03,840  -->  00:02:07,220
Then the second argument is k the number of cluster.

27

00:02:07,740  -->  00:02:13,250
So here we can put five and we will leave the default value for the third parameter.

28

00:02:13,720  -->  00:02:14,040
OK.

29

00:02:14,040  -->  00:02:19,560
Now it's interesting to take a step back because actually this method is called Cat tree which is a

30

00:02:19,560  -->  00:02:24,720
very well-chosen name because indeed we are cutting the tree to take the part of the tree that contains

31

00:02:24,810  -->  00:02:27,620
our five clusters so that makes pretty much sense.

32

00:02:27,810  -->  00:02:33,120
And now since we are actually done with fitting Hollioake who are clustering to our mothers that let's

33

00:02:33,170  -->  00:02:43,170
electroscope section here and execute to find r y h c vector of clusters that appears right here and

34

00:02:43,170  -->  00:02:50,340
now if we type in the console y see here and press ENTER we have all the clusters that the hierarchical

35

00:02:50,340  -->  00:02:53,190
clustering algorithm assigned to each customer.

36

00:02:53,190  -->  00:02:59,340
So for example customer number one belongs to cluster one customer number two belongs to Kuster to Customer

37

00:02:59,340  -->  00:03:01,770
Number 1 0 6 belongs to cluster's 3.

38

00:03:01,830  -->  00:03:04,930
And our last customer belongs to cluster 4.

39

00:03:05,940  -->  00:03:07,380
Okay so congratulations.

40

00:03:07,380  -->  00:03:12,030
We found the right number of clusters and we fitted correctly the hierarchical clustering to a small

41

00:03:12,130  -->  00:03:19,100
dataset and now time for fun in the next tutorial we will be visualizing a hierarchical clustering results

42

00:03:19,100  -->  00:03:19,250
.
