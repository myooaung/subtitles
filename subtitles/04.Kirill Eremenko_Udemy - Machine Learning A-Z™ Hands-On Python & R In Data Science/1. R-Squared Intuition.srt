1

00:00:00,690  -->  00:00:03,750
R-squared this is a very interesting parameter.

2

00:00:03,750  -->  00:00:05,150
A lot of people use it.

3

00:00:05,250  -->  00:00:10,860
And sometimes the user of not knowing the underlying principles of Our Square.

4

00:00:10,860  -->  00:00:17,130
So let's quickly get a understanding of what R-Squared is because we will be using it too.

5

00:00:17,160  -->  00:00:22,630
So time we stopped over here we talked about the simple integration being constructed through the ordinary

6

00:00:22,680  -->  00:00:28,530
least squares method where we are Mizzy minimizing the sum of squares of those differences.

7

00:00:28,600  -->  00:00:32,150
Why I minus why I had.

8

00:00:32,640  -->  00:00:37,040
And basically we are looking at what the model is predicting.

9

00:00:37,050  -->  00:00:44,010
And what is actually happening at a certain level of experience or at a certain level for the independent

10

00:00:44,010  -->  00:00:44,850
variable.

11

00:00:44,850  -->  00:00:46,350
And we look at that difference.

12

00:00:46,350  -->  00:00:51,580
We're squaring it we're summing it for all of the observations we have.

13

00:00:51,950  -->  00:00:59,820
We were counting that sum and then the line that has them smallest sum will be the best fitting line

14

00:00:59,850  -->  00:01:02,060
or will be this simple linear regression model.

15

00:01:02,340  -->  00:01:12,480
So let's get rid of that call out for a second and let's remember this value so we'll need it just now

16

00:01:12,480  -->  00:01:12,690
.

17

00:01:12,750  -->  00:01:19,860
And in fact this value has a name it's called the sum of squares of residuals.

18

00:01:19,920  -->  00:01:24,940
So we'll just labeled SS arrests and now let's do something else before.

19

00:01:25,110  -->  00:01:29,550
We'll get rid of those lines so this is our rule chart with those are aeration and instead of drawing

20

00:01:29,550  -->  00:01:32,140
the regression line let's draw the average line.

21

00:01:32,140  -->  00:01:36,480
So this is your average salary across all of your observations.

22

00:01:36,480  -->  00:01:41,460
Now let's do the same exercise and project our observations onto this line.

23

00:01:41,970  -->  00:01:50,250
And now if we calculate the distances the red distances and we square them then we'll this it will look

24

00:01:50,250  -->  00:01:56,840
like this will be a Y I minus Y average squared and then we'll take the sum of all these distances.

25

00:01:57,180  -->  00:02:02,640
Now this value also has a name and it's called the total sum of squares.

26

00:02:03,030  -->  00:02:11,370
And what r squared is R-squared equal to 1 minus sum of squares of residuals divided by total sum of

27

00:02:11,370  -->  00:02:12,630
squares.

28

00:02:12,720  -->  00:02:20,660
And so what this is saying is that there will always be a sum of all total sum of squares right.

29

00:02:20,670  -->  00:02:26,230
So the average not all your records are not always going to be all equal to the average although it's

30

00:02:26,230  -->  00:02:27,360
a very boring data set.

31

00:02:27,360  -->  00:02:33,100
So some of the total sum of squares will you know will always be some sort of value.

32

00:02:33,450  -->  00:02:39,180
And what you're trying to do with your regression is you're trying to fiddle a line to minimize as we

33

00:02:39,180  -->  00:02:44,370
discussed previously to minimize the sum of squares of residuals to make it as small as possible.

34

00:02:44,580  -->  00:02:44,820
Right.

35

00:02:44,820  -->  00:02:51,930
So in a way the way to think of it intuitively is the average line which we have on the child right

36

00:02:51,930  -->  00:02:58,080
now is also a type of trendline is just horizontal right.

37

00:02:58,080  -->  00:03:00,700
It's not sloped it's just a horizontal trend.

38

00:03:00,720  -->  00:03:06,660
But it kind of also is so you can think of it as a as a model that is fit to a dot.

39

00:03:06,660  -->  00:03:10,370
It's not the best model but you know it's just why average.

40

00:03:10,530  -->  00:03:16,500
So what you're trying to do by fitting a slow line and minimizing the sum of squares of residuals is

41

00:03:16,500  -->  00:03:18,560
you're trying to fit the best line.

42

00:03:18,810  -->  00:03:26,400
And what R-Squared is telling us is it's telling us how good is your line compared to the you know average

43

00:03:26,400  -->  00:03:28,290
line which anybody can think of.

44

00:03:28,290  -->  00:03:32,300
Right so it's not hard to take the average you take a calculator you get the average.

45

00:03:32,310  -->  00:03:36,780
But in order to fit the best fitting line you have to actually run a linear regression.

46

00:03:36,930  -->  00:03:44,820
And if you look at the formula so you tried to minimize s s residual right so somewhat because of residuals

47

00:03:44,820  -->  00:03:53,220
So on the right over there that's part of the formula as you minimise SS residual it goes smaller and

48

00:03:53,220  -->  00:03:54,630
always becomes smaller.

49

00:03:54,870  -->  00:04:01,620
And that way as this residual boy I do bias's total becomes smaller and the one minus SS residual divided

50

00:04:01,620  -->  00:04:03,920
by his total becomes greater.

51

00:04:04,050  -->  00:04:07,700
So ideally if if your SS residual is zero.

52

00:04:07,710  -->  00:04:14,370
So basically your trend line that your modeling goes through all your records then in that case R-Squared

53

00:04:14,370  -->  00:04:15,150
is equal to 1.

54

00:04:15,150  -->  00:04:16,730
And thats the ideal scenario.

55

00:04:16,980  -->  00:04:19,450
But that not normally never happens.

56

00:04:19,470  -->  00:04:26,820
So the closer R-Squared is to 1 the better the further away it is from 1 so the lower It is the worse

57

00:04:26,840  -->  00:04:27,160
.

58

00:04:27,360  -->  00:04:29,790
A good question is can R-squared ever be negative.

59

00:04:29,790  -->  00:04:37,050
The answer is yes of course R-squared can be negative and that is if your for instance SS residual actually

60

00:04:37,590  -->  00:04:43,370
fits your daughter worse then your average life.

61

00:04:43,410  -->  00:04:49,980
Its hard to do but you got to you got to try because if you if you just draw a random line of guess

62

00:04:50,010  -->  00:04:52,170
then facing the wrong way.

63

00:04:52,170  -->  00:04:57,150
So here we be going downwards and probably yes you would get in a negative R-squared.

64

00:04:57,150  -->  00:04:58,180
So thats.

65

00:04:58,260  -->  00:05:00,700
That means that the model is completely broken.

66

00:05:00,720  -->  00:05:03,500
Its better to the average and even to the model.

67

00:05:03,570  -->  00:05:09,270
But normally so our square is normally between zero and one never gets greater than 1 and the closer

68

00:05:09,270  -->  00:05:10,430
is to 1 the better
