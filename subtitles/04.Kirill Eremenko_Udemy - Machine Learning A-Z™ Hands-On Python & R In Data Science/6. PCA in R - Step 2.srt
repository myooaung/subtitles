1
00:00:00,300 --> 00:00:02,340
Hello and welcome to this art it's horrible.

2
00:00:02,340 --> 00:00:04,730
So in this tutorial we are going to like PCA.

3
00:00:04,740 --> 00:00:10,590
And actually I've prepared you the required package to apply this first dimensionality reduction technique

4
00:00:10,740 --> 00:00:12,800
principle component analysis.

5
00:00:12,870 --> 00:00:16,990
So these packages are carrots which I think we already installed.

6
00:00:17,010 --> 00:00:23,010
But if that's not the case and you can check it here in package's you can see if you have carrots available

7
00:00:23,010 --> 00:00:24,250
in the slice of packages.

8
00:00:24,390 --> 00:00:30,410
If you don't see it here you can execute the slide without comment and this will install carrots.

9
00:00:30,570 --> 00:00:31,920
So that's the first package.

10
00:00:32,100 --> 00:00:36,030
Then this is to actually import this carrot package.

11
00:00:36,030 --> 00:00:37,850
So we'll ask you that as well.

12
00:00:37,920 --> 00:00:41,850
And we also need this other package that we installed in part 3.

13
00:00:41,870 --> 00:00:44,830
Cl. the 1871 package.

14
00:00:44,850 --> 00:00:46,750
So normally you should have it installed.

15
00:00:46,770 --> 00:00:47,810
But that's not the case.

16
00:00:47,810 --> 00:00:50,600
You can select this line and install the package.

17
00:00:50,670 --> 00:00:54,360
And don't forget to ask your design as well to select it.

18
00:00:54,420 --> 00:00:57,240
And now we are ready to start applying PCA.

19
00:00:57,510 --> 00:01:02,640
So the first thing that we're going to do is create a new variable that we're going to call PCa that

20
00:01:02,640 --> 00:01:10,070
we will use afterwards to transform our original dataset composed of our 13 features into this new data

21
00:01:10,070 --> 00:01:12,830
set with the new extracted features.

22
00:01:12,830 --> 00:01:16,170
So now to create this subject we are going to use a function.

23
00:01:16,200 --> 00:01:19,020
This is the pre process function.

24
00:01:19,020 --> 00:01:21,120
Here it is from the carrot package.

25
00:01:21,240 --> 00:01:27,480
And let's now press F1 here to see all the info of this preprocess function because you're going to

26
00:01:27,480 --> 00:01:32,970
see that you have some very useful parameters that allow you to apply PCA according to your goals.

27
00:01:32,970 --> 00:01:37,520
For example you can specify a minimum ratio of explains variance.

28
00:01:37,530 --> 00:01:42,480
You want to get that means for example if you want to reduce the dimensionality of your dataset down

29
00:01:42,480 --> 00:01:46,780
to a number of features that will explain at least 60 percent of the variance.

30
00:01:46,890 --> 00:01:51,140
Well you can specify this with one of the parameters of this preprocess function.

31
00:01:51,180 --> 00:01:52,710
So let's have a look at the info.

32
00:01:52,820 --> 00:01:56,030
That's the info and let's jump to the arguments.

33
00:01:56,160 --> 00:01:59,810
So right the first argument is X a matrix or a data frame.

34
00:01:59,820 --> 00:02:03,360
This is actually the data of which we want to reduce the dimensionality.

35
00:02:03,360 --> 00:02:05,790
So this is going to be our training set.

36
00:02:05,820 --> 00:02:07,580
So X will be the training set.

37
00:02:07,660 --> 00:02:09,500
Then the next argument is method.

38
00:02:09,660 --> 00:02:12,810
So method is your dimensional reduction technique.

39
00:02:12,930 --> 00:02:19,380
So as you can see you have several techniques of dimensional reduction D-CA I say so these are other

40
00:02:19,380 --> 00:02:22,060
methods but of course the ones that we want to use.

41
00:02:22,060 --> 00:02:29,340
SPCA principal components analysis tool use method you speciate here then thresh thresh is a very important

42
00:02:29,340 --> 00:02:30,160
parameter.

43
00:02:30,210 --> 00:02:35,760
That's what I've just told you if you want to reduce your dimensionality of your dataset with at least

44
00:02:35,760 --> 00:02:40,770
a minimum amount of explained variance well you can do it by using this Dresch parameter.

45
00:02:40,770 --> 00:02:46,830
And as you can see it's a cutoff and the cumulative percentage variance to be retained by PCA.

46
00:02:46,830 --> 00:02:51,830
So for example if you want your new extracted features to explain at least 60 percent of the variance.

47
00:02:51,960 --> 00:03:00,030
Well you need to specify here thresh equals 0.6 60 percent but we're not going to use this thresh parameter

48
00:03:00,030 --> 00:03:05,430
here because we already know what we want what we want is two independent variables because we want

49
00:03:05,430 --> 00:03:10,890
to be able to visualize the training that results and the test results and that we will be able to get

50
00:03:10,980 --> 00:03:17,160
with the next parameter PCA comp that is the specific number of PCa components to keep.

51
00:03:17,160 --> 00:03:21,780
So that's exactly the number of extracted features you want to obtain in the end.

52
00:03:22,080 --> 00:03:25,360
So he will input PCA come equals to.

53
00:03:25,530 --> 00:03:27,310
So that's our training set.

54
00:03:27,410 --> 00:03:34,020
Our original training set will go from having 13 independent variables the 13 original independent variables

55
00:03:34,020 --> 00:03:41,650
that we have in our dataset to having two new extracted features that will explain the most variants.

56
00:03:41,700 --> 00:03:47,380
And as you can see if we specify the specific parameter this overwrites thresh.

57
00:03:47,400 --> 00:03:52,060
So that's why we don't need to specify the thrust parameter to specify a minimum community.

58
00:03:52,070 --> 00:03:54,330
Percent of explained variance.

59
00:03:54,480 --> 00:03:54,800
All right.

60
00:03:54,810 --> 00:03:57,860
And then you have other parameters but we won't use them.

61
00:03:57,870 --> 00:04:03,800
We actually only need our X to specify the data we want to transform to extract the new features.

62
00:04:03,870 --> 00:04:08,780
The method PCa and the number of extract features we want to get eventually.

63
00:04:08,790 --> 00:04:11,130
That is two new extracted features.

64
00:04:11,370 --> 00:04:12,760
So let's end with the arguments.

65
00:04:12,870 --> 00:04:14,270
Let's start with the first one.

66
00:04:14,370 --> 00:04:15,950
X equals.

67
00:04:16,220 --> 00:04:18,300
So that's training set.

68
00:04:18,300 --> 00:04:19,100
Here we go.

69
00:04:19,200 --> 00:04:25,920
And actually we need to specify the features and actually that's not the whole trend set because remember

70
00:04:25,920 --> 00:04:31,920
PCA is an unsupervised dimensional reduction technique that means that we don't consider the dependent

71
00:04:31,920 --> 00:04:34,310
variable to extract new features.

72
00:04:34,500 --> 00:04:37,550
So we actually need to remove here as a dependent variable.

73
00:04:37,620 --> 00:04:39,730
And remember this hasn't 6:14.

74
00:04:39,810 --> 00:04:43,180
So the way we can do that is the same as we did for feature scanning.

75
00:04:43,200 --> 00:04:46,140
That means we just add here minus 14.

76
00:04:46,500 --> 00:04:46,850
All right.

77
00:04:46,860 --> 00:04:55,370
Now PCA will be applied on all the features 13 features of our trainset perfect now next arguments next

78
00:04:55,370 --> 00:05:01,420
argument is method and as we said method equals in quotes PCA.

79
00:05:01,730 --> 00:05:07,970
All right then come up next argument and last arguments and as we said that's PCA comp.

80
00:05:08,120 --> 00:05:14,810
So PCa and what we want is to you extract features.

81
00:05:14,810 --> 00:05:22,790
All right so that creates the PCA object that will then use on our training set to transform our original

82
00:05:22,790 --> 00:05:29,470
training set composed of 13 independent variables to this new training set of reduced dimensionality.

83
00:05:29,600 --> 00:05:34,150
And that will contain the two new extracted features that will explain the most variants.

84
00:05:34,190 --> 00:05:35,180
So let's do it.

85
00:05:35,300 --> 00:05:40,850
Let's take our trainset because we're going to call this new trend set trends that as well because you

86
00:05:40,850 --> 00:05:46,120
know then we have all our templates and we use this trainset variable name.

87
00:05:46,190 --> 00:05:48,670
So we want to keep this trainset name.

88
00:05:48,680 --> 00:05:55,150
But of course if you want to keep your original training set to set you can use other names like trainset

89
00:05:55,250 --> 00:05:56,770
underscored PCA.

90
00:05:56,900 --> 00:06:03,990
But then if you do that don't forget to change trainset here by Transat PCa and here tested PCA as well

91
00:06:04,190 --> 00:06:09,460
and same for the confusion matrix section and especially here visualizing the 20 that results you will

92
00:06:09,460 --> 00:06:11,160
need to replace trainset here.

93
00:06:11,210 --> 00:06:13,030
By training said PCA.

94
00:06:13,040 --> 00:06:17,740
All right so that's why we're keeping the name in order not to have to change everything.

95
00:06:17,900 --> 00:06:21,100
So let's go back to training set equals.

96
00:06:21,230 --> 00:06:28,760
And now let's transform this original trainset into our new trainset composed of our new extracted features

97
00:06:29,180 --> 00:06:32,920
and to do this is very simple we use to predict function.

98
00:06:33,200 --> 00:06:42,380
And inside we take our PCA objects come up and we apply this PCA transformation object on the original

99
00:06:42,380 --> 00:06:46,580
training set that is named trainset as well.

100
00:06:47,170 --> 00:06:53,540
And so by doing this this original training sets will become this new training set composed of the two

101
00:06:53,630 --> 00:06:55,150
new extracted features.

102
00:06:55,160 --> 00:06:56,150
So let's do it.

103
00:06:56,240 --> 00:07:01,650
Let's start by creating this object and then we will transform our training sets.

104
00:07:01,670 --> 00:07:10,130
So I'm going to select this line and exit executes perfect the PCL object is ready to be used on the

105
00:07:10,190 --> 00:07:17,180
original training set to transform it into our new training set composed of the two extracted features.

106
00:07:17,180 --> 00:07:19,070
So let's execute this as well.

107
00:07:19,070 --> 00:07:20,070
Here we go.

108
00:07:20,120 --> 00:07:22,080
Our new trainset is now created.

109
00:07:22,100 --> 00:07:25,340
We can have a look as you can see when I'm clicking on this.

110
00:07:25,790 --> 00:07:32,090
Well I have a new training set composed of to extract features and remember this tune you extracted

111
00:07:32,090 --> 00:07:34,520
features called the principal components.

112
00:07:34,530 --> 00:07:37,260
That's where you have PC one and PC two.

113
00:07:37,460 --> 00:07:42,550
And of course we still have already been available vector the customer segments have been invaluable.

114
00:07:42,680 --> 00:07:47,050
With its three labels one two and three.

115
00:07:47,060 --> 00:07:47,770
All right perfect.

116
00:07:47,770 --> 00:07:54,140
But now as you can clearly notice the dependent variable vector just went in first position and since

117
00:07:54,140 --> 00:07:56,650
then we're going to use a template on datasets.

118
00:07:56,660 --> 00:08:01,850
I mean the training set and set where the dependent variable is in the last position we will need to

119
00:08:01,850 --> 00:08:04,510
put this invaluable in last position here.

120
00:08:04,730 --> 00:08:06,410
And that's actually very easy.

121
00:08:06,530 --> 00:08:13,160
What we only need to do is play with the indexes to put this customer segment Ben a variable in last

122
00:08:13,160 --> 00:08:14,120
position.

123
00:08:14,180 --> 00:08:17,920
So the method is really easy we're going to take our trainset again.

124
00:08:17,920 --> 00:08:18,680
Here we go.

125
00:08:19,520 --> 00:08:26,740
And then equals and then we take again our trainset then brackets and then inside these brackets we're

126
00:08:26,740 --> 00:08:31,260
going to take the indexes of the columns are training set in the correct order.

127
00:08:31,260 --> 00:08:32,340
We want to get.

128
00:08:32,350 --> 00:08:35,460
So you're going to understand that now we're going to take a vector.

129
00:08:35,590 --> 00:08:39,730
So remember in our vector It's taken with C and then parenthesis.

130
00:08:39,910 --> 00:08:40,410
All right.

131
00:08:40,420 --> 00:08:44,270
And inside these parenthesis we put the correct order of the indexes.

132
00:08:44,290 --> 00:08:45,400
We want to get.

133
00:08:45,430 --> 00:08:47,820
So let's go back to our training set.

134
00:08:47,920 --> 00:08:53,500
The first column we want to get is one that should be the first column of our new training set.

135
00:08:53,680 --> 00:08:55,150
And this has index too.

136
00:08:55,300 --> 00:09:03,550
So here we put the first index which is to then come up and then we input the second index one to get

137
00:09:03,600 --> 00:09:07,240
that is the second column and the second column is pc 2.

138
00:09:07,300 --> 00:09:08,680
And this hasn't x3.

139
00:09:08,680 --> 00:09:16,090
So here we input 3 and then here you put the index of the last column you want to have your training

140
00:09:16,090 --> 00:09:16,580
set.

141
00:09:16,690 --> 00:09:21,550
And the last column you want to have in your training set is this customer segment column because that's

142
00:09:21,550 --> 00:09:22,760
the dependent variable.

143
00:09:22,840 --> 00:09:26,590
And so far this customer segment has next one.

144
00:09:26,650 --> 00:09:30,110
So you need to specify here this index that is 1.

145
00:09:30,430 --> 00:09:36,010
And by doing this our new training set here will be the same trainset that we have here but with a new

146
00:09:36,070 --> 00:09:39,000
order of the columns and that is given by this or here.

147
00:09:39,030 --> 00:09:43,710
First the first and have been available that has next to then the second independent variable that has

148
00:09:43,710 --> 00:09:49,900
an x 3 and eventually the dependable column that has indexed one you're going to see if I select this

149
00:09:49,900 --> 00:09:53,400
line now and execute and if I go back to training set.

150
00:09:53,450 --> 00:09:59,600
Now I have my first two columns as you extract features you want to.

151
00:09:59,680 --> 00:10:05,470
The last column customer segment and last position as our code templates that we're going to use is

152
00:10:05,470 --> 00:10:06,700
expecting it.

153
00:10:06,700 --> 00:10:07,910
So that's perfect.

154
00:10:07,930 --> 00:10:09,460
We can go back to PCA.

155
00:10:09,730 --> 00:10:12,790
And now we need to do the same for the test set.

156
00:10:12,820 --> 00:10:19,030
So what we're going to do is select these two lines copy them and just replace training set here by

157
00:10:19,030 --> 00:10:20,140
test set.

158
00:10:20,170 --> 00:10:21,740
Same here test set.

159
00:10:22,090 --> 00:10:27,030
And same here as well two sets and eventually test it.

160
00:10:27,040 --> 00:10:28,180
All right.

161
00:10:28,180 --> 00:10:31,800
And that's of course the same indexes for the order you want to have.

162
00:10:31,870 --> 00:10:32,670
We can check it out.

163
00:10:32,680 --> 00:10:40,080
I'm going to select this line as you can see so far the test set has its 13 original features then a

164
00:10:40,170 --> 00:10:47,350
fire exit you disliked it now has to you extract that features the principal components 1 and 2 but

165
00:10:47,470 --> 00:10:51,710
the customer segment is in first position we want to put it in the last position.

166
00:10:51,940 --> 00:10:56,310
And so to do this we exit through this line and that will do it.

167
00:10:56,380 --> 00:11:02,770
If I go back to test set now the customer segment is in that position and we are ready to use the following

168
00:11:02,770 --> 00:11:08,980
part of the template predictive test results make the comparison matrix and eventually that's the most

169
00:11:08,980 --> 00:11:09,950
exciting part.

170
00:11:09,970 --> 00:11:15,850
We will now be able to visualize a turning set result because we now have two dimensions in our training

171
00:11:15,850 --> 00:11:17,170
set and tests.

172
00:11:17,440 --> 00:11:20,460
So I look forward to visualizing these results in the next Statoil.

173
00:11:20,470 --> 00:11:22,210
And until then machine learning.
