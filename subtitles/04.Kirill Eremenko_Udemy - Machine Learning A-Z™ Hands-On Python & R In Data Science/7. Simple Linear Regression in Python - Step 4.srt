1
00:00:00,450 --> 00:00:01,420
All right my friends.

2
00:00:01,440 --> 00:00:04,740
Are you ready for the final steps of this implementation.

3
00:00:04,740 --> 00:00:07,350
First we're going to visualize a training set results.

4
00:00:07,350 --> 00:00:09,970
And second we will visualize the test set results.

5
00:00:10,080 --> 00:00:11,060
So let's do this.

6
00:00:11,070 --> 00:00:13,440
Let's start by creating a new code cell.

7
00:00:13,440 --> 00:00:14,490
And there we go.

8
00:00:14,490 --> 00:00:20,370
Now we just want to plot on a nice graphic the real salaries compared to the predicted salaries.

9
00:00:20,400 --> 00:00:26,070
Basically we're gonna have a 2D plot with the x axis being the numbers of years of experience you know

10
00:00:26,070 --> 00:00:34,170
from one to 10 and the y axis being the salaries you know in the range of salaries given in this dataset.

11
00:00:34,410 --> 00:00:41,490
And so we will plot in red points the real salaries and in a blue straight line the predicted salaries.

12
00:00:41,630 --> 00:00:42,080
Okay.

13
00:00:42,150 --> 00:00:47,740
And we will do that both for the predictions and the training set and the predictions in a test.

14
00:00:47,760 --> 00:00:48,500
Are you ready.

15
00:00:48,520 --> 00:00:49,330
Let's do this.

16
00:00:49,830 --> 00:00:55,050
So I didn't expect you to implement this yourself before you know doing it together because there are

17
00:00:55,050 --> 00:00:59,800
actually a lot of new tools that we're gonna use here and especially Matlock lib.

18
00:00:59,870 --> 00:01:05,880
You know you remember this library mad plot lib allows us to plot some nice graphics including the ones

19
00:01:05,880 --> 00:01:06,590
we're about to plot.

20
00:01:06,600 --> 00:01:13,100
So we're gonna first go mad plot lib as a reminder it has to shortcut P LTE actually what we're going

21
00:01:13,100 --> 00:01:20,100
to call is exactly the PI plot module from the MATLAB library and this is what is having the p LTE shortcut.

22
00:01:20,100 --> 00:01:21,220
So there we go.

23
00:01:21,290 --> 00:01:28,230
Let's start by calling five plus P LTE from that plot line and then we're going to call a specific function

24
00:01:28,230 --> 00:01:35,340
from this module which is go scatter and scatter will allow us to put the red points in a corresponding

25
00:01:35,340 --> 00:01:37,800
to the real salaries in the two D plus.

26
00:01:37,800 --> 00:01:38,090
Okay.

27
00:01:38,130 --> 00:01:44,520
So naturally what we have to input here are the coordinates of these red points representing the real

28
00:01:44,520 --> 00:01:49,600
salaries and these coordinates are nothing else than X train and Y train right.

29
00:01:49,620 --> 00:01:53,920
Because remember the X axis will be the numbers of years of experience.

30
00:01:53,950 --> 00:01:58,870
That's what is contained in exchange and the y axis will be the salaries.

31
00:01:58,890 --> 00:02:03,690
And that is what is contained in y trains are here and scatter here we just have to input the coordinates

32
00:02:03,960 --> 00:02:07,920
first X train for the numbers of years of experience.

33
00:02:07,920 --> 00:02:08,580
There you go.

34
00:02:08,610 --> 00:02:11,910
And then why train for the salaries.

35
00:02:11,910 --> 00:02:12,980
Okay.

36
00:02:13,320 --> 00:02:20,460
And then we can add another argument which is color and which will allow us to choose color of these

37
00:02:20,460 --> 00:02:20,910
points.

38
00:02:20,910 --> 00:02:23,720
And as we said we're going to choose red.

39
00:02:23,790 --> 00:02:24,660
Perfect.

40
00:02:24,660 --> 00:02:29,160
And that's the first thing this will just plot the red points corresponding to the real salaries in

41
00:02:29,160 --> 00:02:30,530
a 2D plus.

42
00:02:30,540 --> 00:02:35,030
Then next step or next step step is to plot the regression line.

43
00:02:35,070 --> 00:02:41,850
So remember from the intuition lectures the regression line is the line of predictions coming as close

44
00:02:41,940 --> 00:02:44,190
as possible to the real results.

45
00:02:44,190 --> 00:02:49,890
You know the real salaries and therefore and that's why it is called a linear regression to predictions.

46
00:02:49,890 --> 00:02:55,230
You know the points corresponding to the predicted salaries will follow a straight line right as in

47
00:02:55,230 --> 00:02:56,910
a linear function.

48
00:02:57,120 --> 00:03:02,760
And therefore here we're not going to use the scatter method we're going to use the plot method because

49
00:03:02,760 --> 00:03:05,310
that's what we used to plot curve of a function.

50
00:03:05,370 --> 00:03:08,930
And since our function is linear it will actually be a straight line.

51
00:03:09,240 --> 00:03:09,540
All right.

52
00:03:09,540 --> 00:03:10,440
So there we go.

53
00:03:10,470 --> 00:03:14,960
Let's call first the p LTE module pilot.

54
00:03:15,060 --> 00:03:18,680
Then from this module we're going to call the plot function.

55
00:03:18,690 --> 00:03:19,830
There you go.

56
00:03:19,830 --> 00:03:26,220
And in this function will same as in the scatter function we have to input the coordinates of the points

57
00:03:26,280 --> 00:03:28,760
or line nodes corresponding to the predictions.

58
00:03:28,770 --> 00:03:33,300
Actually you have all the descriptions of the diverse tools we use in Google collab.

59
00:03:33,300 --> 00:03:36,370
That's one of the many beauties of Google collab.

60
00:03:36,390 --> 00:03:41,730
And so you can have a look at more information here if you'd like but that's very intuitive.

61
00:03:41,730 --> 00:03:42,930
We just need to enter.

62
00:03:42,960 --> 00:03:48,420
Once again the coordinates of the predicted salaries and this will just plot the line following these

63
00:03:48,510 --> 00:03:49,380
predicted points.

64
00:03:49,380 --> 00:03:51,050
Okay so let's do this.

65
00:03:51,120 --> 00:03:54,400
According to you what is the first coordinate of these predicted salaries.

66
00:03:54,400 --> 00:03:57,510
Well that's of course X train.

67
00:03:57,810 --> 00:03:58,720
Why is that.

68
00:03:58,720 --> 00:04:02,160
It's because right now we're visualizing the results of the training set.

69
00:04:02,170 --> 00:04:07,800
Okay so these corresponds to the numbers of years of experience of the employees in the training set.

70
00:04:07,830 --> 00:04:09,570
That's the x coordinates.

71
00:04:09,600 --> 00:04:14,730
Okay now we're going to input the y coordinates and according to you which ones are these.

72
00:04:14,730 --> 00:04:17,040
Well it's something we haven't created yet.

73
00:04:17,100 --> 00:04:22,860
You know we created actually the widespread variable containing the predicted salaries of the test set

74
00:04:23,160 --> 00:04:28,250
but we haven't created a vector containing the predicted salaries of the training set and that stall

75
00:04:28,250 --> 00:04:33,300
fine what will actually enter here as to why coordinate of this plot.

76
00:04:33,300 --> 00:04:39,210
We're about to make are going to be exactly the predicted salaries of the training set to get them.

77
00:04:39,210 --> 00:04:47,730
I'm going to copy this and paste that right here but instead of inputting here x test I'm going to input

78
00:04:48,000 --> 00:04:56,010
actually X train because calling the predict method on X train meaning on the numbers of years of experience

79
00:04:56,010 --> 00:05:02,120
of the employees in the training set will get me exactly the predicted salaries of the training set.

80
00:05:02,140 --> 00:05:02,510
All right.

81
00:05:02,530 --> 00:05:06,610
Just as before with predict x test so extreme.

82
00:05:06,640 --> 00:05:07,420
Yes.

83
00:05:07,510 --> 00:05:13,590
And then just as before we're going to choose a color which this time will be blue.

84
00:05:13,930 --> 00:05:14,320
Right.

85
00:05:14,530 --> 00:05:19,140
So that we can clearly see the difference between real salaries and the predicted salaries.

86
00:05:19,200 --> 00:05:21,820
Okay so this will plot the regression line.

87
00:05:21,820 --> 00:05:23,490
Now next step what can we do.

88
00:05:23,500 --> 00:05:25,210
And that's just for the sake of the form.

89
00:05:25,210 --> 00:05:30,810
I want to train you how to build a nice chart or a nice graphic with Python.

90
00:05:30,880 --> 00:05:39,010
So here we're gonna add a title and to do this we have to call the title function and inside the parentheses

91
00:05:39,040 --> 00:05:40,620
we just have to input in quotes.

92
00:05:40,690 --> 00:05:48,190
Well the title we want for a graph and so let's say salary versus experience.

93
00:05:48,230 --> 00:05:48,730
Okay.

94
00:05:48,780 --> 00:05:52,110
You can choose any other title if you prefer another one.

95
00:05:52,110 --> 00:05:57,480
So salary vs. experience and then we're going to specify the training set because indeed then we'll

96
00:05:57,480 --> 00:05:59,390
do the same for the test.

97
00:05:59,530 --> 00:05:59,810
Okay.

98
00:05:59,820 --> 00:06:03,980
Salary versus numbers of years of experience in the train set right.

99
00:06:03,990 --> 00:06:06,750
This is a very precise title.

100
00:06:06,750 --> 00:06:11,280
Now we're just going to add a label to the x axis into the y axis.

101
00:06:11,310 --> 00:06:16,950
And for this we have to use the x label function into which we have to input.

102
00:06:17,040 --> 00:06:24,480
Well the label we want to display on the x axis and we're going to choose in quote of course years of

103
00:06:24,870 --> 00:06:25,960
experience.

104
00:06:26,770 --> 00:06:28,650
All right good.

105
00:06:28,650 --> 00:06:35,610
Now we're gonna copy this because we're gonna do the same for the y axis and the name of the function

106
00:06:35,610 --> 00:06:37,310
for this is why label.

107
00:06:37,320 --> 00:06:40,810
That's why I just did a copy paste and for the Y label.

108
00:06:40,830 --> 00:06:43,980
Well we will choose to display salary.

109
00:06:44,530 --> 00:06:45,340
Okay.

110
00:06:45,450 --> 00:06:47,160
Salary.

111
00:06:47,160 --> 00:06:50,040
And finally in order to show the graphic.

112
00:06:50,040 --> 00:06:55,800
Well we just had to finish here with BLT that show you know the show function.

113
00:06:55,800 --> 00:06:58,390
And this will display the graphic in the Alps.

114
00:06:58,470 --> 00:06:58,930
All right.

115
00:06:59,400 --> 00:07:00,660
So good.

116
00:07:00,660 --> 00:07:03,090
Now we're gonna do the same for the test results.

117
00:07:03,090 --> 00:07:10,140
I'm just going to copy everything here and paste that in a new coat sale right here.

118
00:07:10,170 --> 00:07:15,380
And so now we're going to do the right replacements and this code in order to visualize this I'm not

119
00:07:15,390 --> 00:07:18,000
the change that results but the test results.

120
00:07:18,120 --> 00:07:23,940
And so obviously the first thing we need to replace here are the coordinates of the real observations

121
00:07:23,970 --> 00:07:29,280
because these are the coordinates of the employees in the training set and we want the coordinates of

122
00:07:29,280 --> 00:07:30,540
the employees of the test.

123
00:07:30,600 --> 00:07:38,790
Therefore here we have to replace obviously X trained by X test and then Y train by Y test.

124
00:07:38,790 --> 00:07:39,050
Okay.

125
00:07:39,090 --> 00:07:44,940
So these are for the real observations with the numbers of years of experience and the real salaries

126
00:07:44,990 --> 00:07:46,080
of the test.

127
00:07:46,200 --> 00:07:52,800
And now according to you do we have to replace something here in BLT plot x strain regressive that predict

128
00:07:52,890 --> 00:07:59,530
X train according to you do we have to replace X trained by excess and the same x rayed by excess.

129
00:08:00,060 --> 00:08:06,990
Well you know that kind of a trick question because remember that the regression line that we get is

130
00:08:06,990 --> 00:08:13,710
actually resulting from a unique equation and therefore the predicted salaries of the test set will

131
00:08:13,710 --> 00:08:19,200
be on the same regression line as the predicted salaries of the training set.

132
00:08:19,320 --> 00:08:24,650
And that's why here we actually don't have to replace X trained by accessed here and here.

133
00:08:24,660 --> 00:08:25,310
Okay.

134
00:08:25,380 --> 00:08:31,050
You would actually get the exact same regression line whether you plot the coordinates of X strain and

135
00:08:31,050 --> 00:08:35,690
the predicted salaries of training set or x test and the predicted salaries of the test set.

136
00:08:35,760 --> 00:08:40,950
You can check but that's because the regression line in a simple in our regression model results from

137
00:08:40,950 --> 00:08:45,120
a unique equation and we therefore end up with the same regression line.

138
00:08:45,120 --> 00:08:45,420
Okay.

139
00:08:45,450 --> 00:08:47,940
So no need to replace anything here.

140
00:08:47,940 --> 00:08:53,400
And finally we will just replace your training set by test set and there you go.

141
00:08:53,400 --> 00:08:57,490
Now we're ready to visualize the training set results and the test results.

142
00:08:57,990 --> 00:09:02,100
So let's first run the sales we haven't executed before.

143
00:09:02,100 --> 00:09:04,860
So remember we executed up to the training.

144
00:09:04,960 --> 00:09:10,380
Now we have to execute this one to indeed get the vector whitebread of the predicted salaries in the

145
00:09:10,380 --> 00:09:11,490
test set.

146
00:09:11,520 --> 00:09:12,510
So there we go.

147
00:09:12,540 --> 00:09:14,070
We now have white bread.

148
00:09:14,220 --> 00:09:18,920
And so now we're going to first execute this to visualize the trains that result and we're going to

149
00:09:18,990 --> 00:09:27,990
say now nice to the plot with indeed the real salaries in these red points here and of course are beautiful

150
00:09:27,990 --> 00:09:31,290
regression line containing the predicted salaries.

151
00:09:31,410 --> 00:09:37,710
And we clearly see that this regression line was calculated so that it comes as close as possible to

152
00:09:38,010 --> 00:09:43,440
the real salaries and of course for each of the years of experience here in order to get the predicted

153
00:09:43,440 --> 00:09:48,960
salary you have to project the Europe experience to this blue regression line.

154
00:09:48,960 --> 00:09:55,740
So for example the predicted salary corresponding to eight years of experience is about you know one

155
00:09:55,740 --> 00:09:57,720
hundred thousand dollars per year.

156
00:09:57,750 --> 00:09:58,010
OK.

157
00:09:58,020 --> 00:09:59,090
So that's how it works.

158
00:09:59,100 --> 00:10:03,930
And so we can clearly see that our predicted salaries are very close.

159
00:10:03,930 --> 00:10:08,750
The real salaries you know for most of them but that's on the training set.

160
00:10:08,760 --> 00:10:14,190
Remember that's important because our model was actually trained with these observations you know with

161
00:10:14,190 --> 00:10:16,790
these years of experience and salaries.

162
00:10:16,800 --> 00:10:23,490
Now what we would like to observe is if we had the same result you know the same closeness of the regression

163
00:10:23,490 --> 00:10:29,970
line to the real salaries in the test set with which the model wasn't trained you know we want to evaluate

164
00:10:29,970 --> 00:10:31,450
it on new observations.

165
00:10:31,590 --> 00:10:37,890
And that's exactly what this new graphic will tell us because now we're about to plot this time the

166
00:10:37,890 --> 00:10:43,070
real salaries of the test set and the predicted salaries of the same test set.

167
00:10:43,080 --> 00:10:49,890
So there we go let's run the sale and let's see if we're still close to the real salaries even for new

168
00:10:49,890 --> 00:10:50,670
observations.

169
00:10:50,670 --> 00:10:57,600
And yes absolutely our predicted salaries which are of course on the blue line once again are very close

170
00:10:57,600 --> 00:10:59,600
indeed to the real salaries.

171
00:10:59,610 --> 00:11:07,200
So our moral are simple in our regression model was able to do a wonderful job at predicting new observations.

172
00:11:07,740 --> 00:11:09,030
So congratulations.

173
00:11:09,030 --> 00:11:09,900
That's very exciting.

174
00:11:09,900 --> 00:11:13,110
You've built a very successful first machinery model.

175
00:11:13,110 --> 00:11:19,860
However just remember that the reason why we get such a good regression line here is simply because

176
00:11:19,860 --> 00:11:25,350
there was a linear relationship in the data set between the features and the dependent variable of the

177
00:11:25,360 --> 00:11:29,380
data set other words we had a perfectly linear dataset.

178
00:11:29,400 --> 00:11:34,170
In other words we had a dataset with linear correlations and what I want to make sure you understand

179
00:11:34,170 --> 00:11:40,290
is that these beautiful results won't happen for any dataset because of course you'll get to work on

180
00:11:40,290 --> 00:11:42,900
data with non-linear relationships.

181
00:11:43,050 --> 00:11:46,020
And for these data you will need a nonlinear model.

182
00:11:46,170 --> 00:11:53,310
And that's exactly why in this part two regression we will also study some non-linear models which you

183
00:11:53,310 --> 00:11:59,550
will see will be polynomial regression or as we are which will allow you to get amazing results for

184
00:11:59,680 --> 00:12:02,070
data sets having nonlinear relationships.

185
00:12:02,100 --> 00:12:08,100
But for this dataset we clearly had linear relationships and that's why linear regression more was perfectly

186
00:12:08,100 --> 00:12:08,600
fine.

187
00:12:08,700 --> 00:12:10,400
But I just wanted to highlight this.

188
00:12:10,440 --> 00:12:12,930
Okay so congratulations once again.

189
00:12:12,930 --> 00:12:17,460
I hope you're very happy and excited to have built your very first missionary model.

190
00:12:17,460 --> 00:12:22,650
Now we're going to increase the difficulty a bit because in the next section we will build multiple

191
00:12:22,740 --> 00:12:29,310
linear regression model meaning that instead of having one feature you know only one independent variable

192
00:12:29,610 --> 00:12:31,140
we will have several of them.

193
00:12:31,260 --> 00:12:36,000
And that's exactly the difference between simple in our regression and multiple in our regression.

194
00:12:36,000 --> 00:12:40,320
Simple in our regression is when you have only one feature and multiple in our regressions when you

195
00:12:40,320 --> 00:12:42,270
have several features.

196
00:12:42,270 --> 00:12:49,140
So take a good break now and as soon as you're back with your energy let's implement our second machinery

197
00:12:49,140 --> 00:12:55,940
model in the next practical activity after cubicles intuition lecture and until then enjoy machine learning.
