WEBVTT

00:00.120 --> 00:04.440
Now we start training our model

00:11.200 --> 00:22.690
so we'll first need to call the comp. Meffert we're going to use our term optimizer.

00:22.890 --> 00:35.770
We're going to use that by a curse and Trophy last function.

00:35.920 --> 00:39.850
We're going to use IQ to measure the solids

00:45.160 --> 00:49.000
and then we will just try and use and treat Meffert

00:51.750 --> 01:01.840
we need to pass the X train y train variables into our training Meffert And we also need to define a

01:01.840 --> 01:02.860
batch size.

01:02.860 --> 01:13.140
We're going to use 15 and we're going to train for just five books to see the results right now.

01:13.400 --> 01:23.530
Our neural network is now trying we cover an 88 of almost 30 seconds to train for this epoch.

01:23.810 --> 01:25.350
But we have five books.

01:25.400 --> 01:34.610
So we'll just wait and see that we have a really low level of really high accuracy just at the beginning

01:34.700 --> 01:35.990
of February.

01:36.380 --> 01:47.980
We'll just wait until the network finishes training.

01:48.190 --> 01:54.130
Now that our network has finished training we're going to try to measure the results.

01:54.340 --> 02:00.460
So remember that we had to split our data set in X train and X test.

02:00.940 --> 02:08.060
Well now we're going to use the X test with the evaluate method from class.

02:13.460 --> 02:18.950
We're going to need to pass the X Y test labels as well.

02:18.950 --> 02:22.970
So one model predicts the labels.

02:23.290 --> 02:29.120
You will be able to compare them with the actual expected labels for this input.

02:29.180 --> 02:29.700
OK.

02:36.700 --> 02:38.320
We know the score.

02:38.380 --> 02:44.220
We're going to try to find.

02:44.550 --> 02:51.960
So this means that we achieved ninety nine point ninety four percent accuracy you know where that.
