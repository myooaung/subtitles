WEBVTT

00:00.170 --> 00:07.140
This section we're going to describe the case study or the problem at hand in a form of a machine learning

00:07.140 --> 00:07.860
terminologies.

00:07.860 --> 00:08.600
OK.

00:08.820 --> 00:10.410
So let's get started.

00:10.410 --> 00:16.290
So the first step is here we have our Again images that we acquired using the f n h technique.

00:16.290 --> 00:22.050
So we have some images that are indicating that the cancer is malignant or in some other images that

00:22.050 --> 00:29.220
detect the cancer is benign and then we extract out of this basically 30 features OK which indicating

00:29.220 --> 00:32.210
radius texture perimeter area and smoothness.

00:32.220 --> 00:32.800
All right.

00:32.880 --> 00:34.950
And all that data set has been done for you.

00:34.950 --> 00:38.360
So obviously we're not you know like physicians or doctors of cancer experts.

00:38.420 --> 00:40.330
We're going to look into the images per se.

00:40.350 --> 00:45.350
Our focus right now is to access all these features and all the data you can access it from here it's

00:45.350 --> 00:46.230
in.

00:46.590 --> 00:49.930
If you just follow that link it will give you the access to the data.

00:50.220 --> 00:55.860
And in this data you'll see that we have 30 features and these 30 features we're going to feed them

00:55.950 --> 01:01.620
into the classifier or the machine learning model that can classify to us if the cancer again is malignant

01:01.650 --> 01:02.390
or benign.

01:02.440 --> 01:03.230
Right.

01:03.360 --> 01:06.300
So the first step is how many data sets we have.

01:06.300 --> 01:11.760
So in this case study we're going to have five hundred and sixty nine instances which means that we

01:11.760 --> 01:16.890
have five hundred and sixty nine instances divided between them some of them again malignant some of

01:16.890 --> 01:17.800
them benign.

01:18.160 --> 01:23.370
And in this case study we have two hundred and twelve malignant cases and three hundred and fifty seven

01:23.370 --> 01:24.240
benign cases.

01:24.240 --> 01:24.800
All right.

01:25.170 --> 01:30.120
So what we do again and how we treat the classifier is that we tell the machine learning model when

01:30.120 --> 01:33.620
we train it when we teach it how to classify is OK.

01:33.630 --> 01:39.660
Look at these features which is in this case we have three features and we can teach you the target

01:39.660 --> 01:40.430
class.

01:40.470 --> 01:45.870
We're going to say OK if you look at these features then indicate that the cancer is let's say zero

01:45.990 --> 01:47.720
which is malignant in this case.

01:48.000 --> 01:53.480
And then if you look at these three features may be classified as one which is kind of a benign.

01:53.530 --> 01:59.430
So it's kind of the output is is a binary in a form indicating zero or one for malignant or benign and

01:59.430 --> 02:05.410
that's how we are going to feed or teach our machine learning model how to classify cancer in this case.

02:05.410 --> 02:06.350
All right.

02:06.930 --> 02:10.890
So let's take a look at the technique we're going to be using in this case study which is what we call

02:10.890 --> 02:12.830
it support vector machines.

02:12.960 --> 02:13.580
OK.

02:14.010 --> 02:18.520
So let's assume that we have peed on the x axis first feature.

02:18.540 --> 02:23.310
One of these features one of the three features we call a feature one and the y axis we have other features

02:23.310 --> 02:24.230
feature too.

02:24.630 --> 02:30.660
And as you can see here we have these two classes per se in this or in our case let's assume that this

02:30.660 --> 02:37.530
for example the malignant case and this case these points are the red points are the benign case.

02:37.710 --> 02:44.550
And what we do is we wanted the machine learning strategy or technique to simply separate the two classes

02:45.480 --> 02:46.460
in a very simple form.

02:46.470 --> 02:52.170
We can just draw a line in between here which indicates OK that's the line that the tax or separate

02:52.170 --> 02:53.440
the two classes.

02:53.550 --> 02:57.790
Someone can tell me OK maybe that's not the line maybe we can put this line instead.

02:57.870 --> 02:59.360
Or maybe this line instead.

02:59.430 --> 03:00.030
And so on.

03:00.090 --> 03:00.770
OK.

03:01.020 --> 03:08.820
So the objective of the training of our model of using the support that the machine method is to find

03:08.820 --> 03:11.600
the best line that separates the two classes.

03:11.730 --> 03:12.720
OK.

03:12.720 --> 03:19.710
So that baseline in this case we are going to rely on mainly these two points and these two points in

03:19.710 --> 03:22.490
our study we're going to call it the supported vectors.

03:22.590 --> 03:23.260
OK.

03:23.610 --> 03:27.540
Again we're not going to dig into the math mathematics of all that is going to give you an intuition

03:27.570 --> 03:34.450
of what support vector machines are and how can we apply it in practical Python environment.

03:34.770 --> 03:41.280
So you guys can see here this is basically what we call the maximum margin hyperplane which is the hyperplane

03:41.340 --> 03:45.410
or the line that separates mainly the two classes.

03:45.450 --> 03:46.020
OK.

03:46.260 --> 03:51.000
In order to get this line we use a distance of what we call it the maximal motion distance and that's

03:51.000 --> 03:58.560
the objective of the machine classifier is to find or maximize that maximum margin distance between

03:58.560 --> 03:59.620
the two classes.

03:59.970 --> 04:03.380
And in order to do this we use these two many points.

04:03.390 --> 04:05.610
And in this case we call them support vectors.

04:05.610 --> 04:06.170
Right.

04:06.480 --> 04:13.290
So what do you mean by support vector support vectors are the points that we assume that these points

04:13.330 --> 04:16.660
are on the boundary or a kind of an end on a gray area.

04:16.710 --> 04:17.430
OK.

04:17.430 --> 04:21.990
They are not fully malignant in this case or benign in this case.

04:21.990 --> 04:26.970
It's kind of in between with human eyes for example or physicians might be able to.

04:26.990 --> 04:27.520
I don't know.

04:27.540 --> 04:32.580
This cancer is malignant or benign or for example of this like image is a cat or a dog.

04:32.790 --> 04:33.470
Right.

04:33.820 --> 04:40.140
And that's why the support that they're classified is very unique in this sense that it's simply uses

04:40.140 --> 04:46.830
the points or the support vectors that are on the boundary to draw the boundary and to classify the

04:47.220 --> 04:47.890
classes.

04:48.000 --> 04:52.950
And actually we can see here as well in the other case study that supported machines are very powerful

04:53.130 --> 04:54.460
really powerful techniques.

04:54.870 --> 05:00.960
And why because it's kind of an extreme algorithm it doesn't classify For example the like samples or

05:00.960 --> 05:06.450
these samples it just focus on the supposed doctors or the points on the boundary and separate them

05:06.540 --> 05:07.270
somehow.

05:07.270 --> 05:07.830
All right.

05:08.160 --> 05:14.400
So let's take a look at a practical example to get and maybe more understanding of the intuition behind

05:14.400 --> 05:15.330
that.

05:15.360 --> 05:22.110
So if you guys can see here again we have our two classes we have our hyper hyperplane And here we have

05:22.110 --> 05:23.540
these are the two support doctors.

05:23.550 --> 05:24.070
OK.

05:24.420 --> 05:31.500
So let's assume that we wanted to for example classify images or to teach the machine learning model

05:31.980 --> 05:34.080
to classify images of cats and dogs.

05:34.200 --> 05:34.960
OK.

05:35.580 --> 05:40.630
So for example this point indicates let's say the blue indicates the cats and the red and the heads

05:40.630 --> 05:41.070
of dogs.

05:41.070 --> 05:41.640
OK.

05:42.000 --> 05:50.190
So if you wanted to classify cats these points which just kind of have a completely distinct or completely

05:50.190 --> 05:57.240
different feature compared to the other points you would see that it's very easy.

05:57.240 --> 05:59.060
It can easily identify that this is a cat.

05:59.070 --> 06:03.220
OK which is really simple wide with the features of the cat are very distinct.

06:03.220 --> 06:06.710
Anyone even if you teach a kid can tell you OK this basically a cat.

06:06.720 --> 06:07.570
Right.

06:07.650 --> 06:12.120
If you look at these points on the far left that indicates that these features are for a dog.

06:12.150 --> 06:17.910
OK you can tell that from the feature from the nose from the ears from so on that from the color that

06:17.910 --> 06:19.110
these features indicates.

06:19.120 --> 06:21.340
OK this is like hundred percent dog.

06:21.360 --> 06:27.600
It's very difficult for the machine learning technique to misclassify them to make basically mix cats

06:27.600 --> 06:28.070
and dogs.

06:28.080 --> 06:28.760
Right.

06:28.770 --> 06:34.030
However for the machines what we do in order to teach the model that we rely on the support that there

06:34.040 --> 06:37.770
is which of these two many points there a kind of lie in the boundary.

06:37.800 --> 06:42.390
OK which is basically you can see here kind of an image that you know maybe I had a hard time.

06:42.390 --> 06:47.040
Is this like a dog that has some features of a dog at the same time has some features of a cat scan

06:47.040 --> 06:47.810
of the mix.

06:47.940 --> 06:48.330
Right.

06:48.480 --> 06:55.470
And these are the points that mesh the support that the machine uses to classify or separates the two

06:55.470 --> 06:56.310
classes.

06:56.310 --> 06:57.310
All right.

06:57.540 --> 06:57.930
All right.

06:57.990 --> 07:02.430
I hope you guys enjoyed that section and support that machine section and in the next section we're

07:02.430 --> 07:07.060
going to look into the Jupiter notebook and start to visualize the data.

07:07.080 --> 07:08.670
I hope you guys enjoyed that section.

07:08.670 --> 07:11.020
And until then enjoy machine learning.
