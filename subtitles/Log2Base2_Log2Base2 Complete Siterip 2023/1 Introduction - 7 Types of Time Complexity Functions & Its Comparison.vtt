WEBVTT

1
00:00:00.000 --> 00:00:01.050
in this video 

2
00:00:01.060 --> 00:00:04.320
Let us learn the types of time complexity functions 

3
00:00:04.330 --> 00:00:05.570
and their comparison 

4
00:00:06.110 --> 00:00:07.870
The first one we are going to learn

5
00:00:07.880 --> 00:00:11.120
is big O of 1 that is constant time function 

6
00:00:11.140 --> 00:00:15.680
Whatever may be the input these algorithms only take constant 

7
00:00:15.680 --> 00:00:17.270
time to produce the output 

8
00:00:17.280 --> 00:00:21.040
For example the odd or even number problem, positive or negative 

9
00:00:21.040 --> 00:00:22.250
number problem etc. 

10
00:00:22.520 --> 00:00:25.730
When we project the growth of this constant time function 

11
00:00:25.730 --> 00:00:28.900
in a graph it will remain the same like this 

12
00:00:29.250 --> 00:00:31.530
The second one we are going to discuss is the 

13
00:00:31.530 --> 00:00:34.026
big O of law again or logarithmic

14
00:00:34.026 --> 00:00:34.906
time function 

15
00:00:35.036 --> 00:00:38.146
Any algorithm which takes log n time to produce the 

16
00:00:38.146 --> 00:00:41.546
result will come under Logarithmic time complexity

17
00:00:41.546 --> 00:00:44.476
function for example the binary search algorithm 

18
00:00:44.606 --> 00:00:47.356
And when we project the logarithmic time function 

19
00:00:47.666 --> 00:00:49.156
it will follow this curve 

20
00:00:49.216 --> 00:00:52.386
The third one is big O of n or linear time 

21
00:00:52.386 --> 00:00:57.186
function. Any algorithm whose time complexity is directly proportional to 

22
00:00:57.186 --> 00:01:01.232
the size of input comes under linear time complexity function 

23
00:01:01.322 --> 00:01:04.402
for example finding an element from and unsorted array

24
00:01:04.582 --> 00:01:07.622
And when we project linear time function in graph 

25
00:01:07.632 --> 00:01:10.292
we will get in line like this. The next one 

26
00:01:10.292 --> 00:01:13.522
that we're going to discuss is Big O of nlogn 

27
00:01:13.752 --> 00:01:16.792
Any algorithm which takes nlogn time to produce 

28
00:01:16.792 --> 00:01:19.982
the results will come under the linearithmic time function 

29
00:01:20.302 --> 00:01:22.162
for example the merge sort algorithm

30
00:01:22.402 --> 00:01:25.978
And when we plot linearithmic time function in the graph, we 

31
00:01:25.978 --> 00:01:28.018
will get a curve like this 

32
00:01:28.108 --> 00:01:30.538
The next one is big O of n square 

33
00:01:30.548 --> 00:01:32.498
That is quadratic time function 

34
00:01:32.668 --> 00:01:36.698
Any algorithm whose time complexity is  directly proportional to the 

35
00:01:36.698 --> 00:01:40.578
squared size of input comes under this category.

36
00:01:40.778 --> 00:01:44.898
Some examples are selection sort and bubble sort algorithms and 

37
00:01:44.898 --> 00:01:47.978
when we project the quadratic time function in a graph 

38
00:01:48.068 --> 00:01:49.358
we will get this curve 

39
00:01:49.628 --> 00:01:52.844
The next one is big of n raised 3 or 

40
00:01:52.844 --> 00:01:57.434
cubic time functions and any algorithm whose time complexity is 

41
00:01:57.434 --> 00:02:01.584
directly proportional to the cube of size of input comes 

42
00:02:01.584 --> 00:02:03.824
under cubic time complexity function 

43
00:02:03.924 --> 00:02:08.004
An example is any algorithm which uses three looping statements 

44
00:02:08.014 --> 00:02:11.344
of size n and then we project a cubic time 

45
00:02:11.344 --> 00:02:11.884
function 

46
00:02:12.074 --> 00:02:13.514
It will follow this curve 

47
00:02:13.744 --> 00:02:16.214
The next one is big O of 2 raised to n 

48
00:02:16.364 --> 00:02:18.484
There is exponential time function 

49
00:02:18.920 --> 00:02:21.920
An algorithm that takes 2 raised to n, time is 

50
00:02:21.920 --> 00:02:24.740
considered an exponential time algorithm 

51
00:02:24.750 --> 00:02:26.800
For example finding Nth Fibonnaci num

52
00:02:26.800 --> 00:02:29.420
 and if we plotted in a graph it will 

53
00:02:29.420 --> 00:02:30.590
be something like this 

54
00:02:31.040 --> 00:02:33.040
The exponential time can be anything 

55
00:02:33.040 --> 00:02:34.690
It may be 2 raised to n, it 

56
00:02:34.690 --> 00:02:35.820
Maybe 3 raised to n

57
00:02:35.830 --> 00:02:37.540
Or it may be n raised to n

58
00:02:38.680 --> 00:02:42.020
If we compare the time complexity functions the order will 

59
00:02:42.020 --> 00:02:45.380
be like this one less than Logn less than n

60
00:02:45.390 --> 00:02:48.370
less than nLogn less than n^2 less than 

61
00:02:48.380 --> 00:02:51.140
n^3 less than 2 raised to n less than 

62
00:02:51.150 --> 00:02:54.300
3 raised to n less than etcetera less than

63
00:02:54.300 --> 00:02:54.830
n raised to n

64
00:02:55.160 --> 00:02:59.080
If we consider square root time complexity here then 

65
00:02:59.080 --> 00:03:01.730
it comes between logn and n 

66
00:03:02.020 --> 00:03:04.410
That is the square root of N is greater than 

67
00:03:04.410 --> 00:03:07.500
Logn and it is less than than n time function 

68
00:03:07.640 --> 00:03:10.300
so we can place square root of n here 

69
00:03:11.140 --> 00:03:13.920
Now let's take some n values and see how the 

70
00:03:13.920 --> 00:03:16.820
number grows for each time complexity functions 

71
00:03:17.580 --> 00:03:20.700
Based on this result we can understand that big O of 1

72
00:03:20.710 --> 00:03:24.190
is the fastest time function and n power n 

73
00:03:24.200 --> 00:03:25.490
is the slowest one 

74
00:03:26.040 --> 00:03:30.600
And also when n increases, the exponential time complexity function 

75
00:03:30.600 --> 00:03:34.380
grows drastically compared to other functions. So, we should avoid 

76
00:03:34.380 --> 00:03:37.530
writing algorithms that take exponential time 

77
00:03:37.790 --> 00:03:39.570
But every problem is unique 

78
00:03:39.680 --> 00:03:43.140
Some problems won't have an easy solution but whatever the 

79
00:03:43.140 --> 00:03:46.190
problem is, we should always try to reduce the time 

80
00:03:46.190 --> 00:03:50.640
complexity of the algorithm for example for some problems 

81
00:03:50.660 --> 00:03:53.650
if you come up with big O of n square algorithm,

82
00:03:53.690 --> 00:03:56.290
try to reduce it to big O of n by using 

83
00:03:56.290 --> 00:03:57.620
a better data structure 

84
00:03:57.620 --> 00:04:01.810
programming technique always tried to reduce the time complexity of 

85
00:04:01.810 --> 00:04:04.250
an algorithm as minimal as possible.

86
00:04:04.520 --> 00:04:05.090
Minimal the time

87
00:04:05.090 --> 00:04:08.790
complexity, the more efficient your algorithm will be. 

88
00:04:08.800 --> 00:04:12.810
So, understanding these time functions and their comparison is very 

89
00:04:12.810 --> 00:04:15.180
important in algorithm analysis 

