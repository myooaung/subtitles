WEBVTT
1

00:00:00.680  -->  00:00:05.490
This material we're talking about the difference between training and testing a model and how to avoid

2

00:00:05.490  -->  00:00:06.540
overfitting.

3

00:00:06.930  -->  00:00:12.030
Here we've got the data set that we want to build a model for and what we've learned so far is that

4

00:00:12.060  -->  00:00:18.420
we have to simply select the right parameters and throw them into a logistic regression and that will

5

00:00:18.420  -->  00:00:25.480
spit out scores of probabilities that we'll be able to use in our judgment graphic segmentation.

6

00:00:26.280  -->  00:00:27.540
And that is all good.

7

00:00:27.660  -->  00:00:35.460
However you might want to take a part of your data set a sample so a random sample about 10 to 20 percent

8

00:00:35.850  -->  00:00:43.140
and split them separate them from the people that or the requisites are actually going to be in putting

9

00:00:43.140  -->  00:00:44.730
into your model.

10

00:00:44.820  -->  00:00:45.650
And why is that.

11

00:00:45.750  -->  00:00:51.510
Well the reason for that is that then you can move these people aside all these records you can train

12

00:00:51.510  -->  00:00:58.790
your model just on the remaining 80 or 90 percent of your population or of the sample that you're training

13

00:00:58.790  -->  00:00:59.770
a model on.

14

00:00:59.910  -->  00:01:05.560
And then later you can test how your model works on the sample that you separate.

15

00:01:05.670  -->  00:01:11.640
And that way you will be sure that that test the second test is not biased.

16

00:01:11.640  -->  00:01:18.720
So as a result of testing this model or training it and then testing it you'll come you'll have to accuracy

17

00:01:18.720  -->  00:01:20.510
rates accuracy ratios.

18

00:01:20.520  -->  00:01:24.900
So what acceleration will be for the train data and that is the larger data set.

19

00:01:24.900  -->  00:01:26.930
There will be building a model for.

20

00:01:26.940  -->  00:01:30.420
And then you will have an accuracy ratio for your test data set.

21

00:01:30.420  -->  00:01:31.370
The smaller one.

22

00:01:31.560  -->  00:01:36.690
So the first ratio the trainer ratio even though it does tell us a lot about the model at the same time

23

00:01:36.710  -->  00:01:36.740
.

24

00:01:36.750  -->  00:01:42.180
It might be a bit biased because we did use the same data set to build the model and now we're checking

25

00:01:42.180  -->  00:01:47.340
how the model predicts that same data set whereas the test data set is completely separate from the

26

00:01:47.340  -->  00:01:47.970
model.

27

00:01:47.970  -->  00:01:52.500
Those records were not used in the construction of the model and therefore the second accuracy ratio

28

00:01:52.500  -->  00:01:58.770
that you will get will be a validation for the first so if you see a significant difference then that

29

00:01:58.770  -->  00:02:05.620
means that perhaps your model might be over fitted for the data that was used to generate this model

30

00:02:05.620  -->  00:02:05.640
.

31

00:02:05.640  -->  00:02:12.960
Remember we talked about overfitting that if your model relies on some anomalies or some specifics of

32

00:02:12.960  -->  00:02:17.510
that data set that you put into the model then it might become overfitting.

33

00:02:17.520  -->  00:02:20.420
And then when you apply to real data the results might be different.

34

00:02:20.520  -->  00:02:27.240
Well here you kind of creating a safety net for yourself that you feel was refitted or if the model

35

00:02:27.240  -->  00:02:32.680
was isn't the best performing model so it's just working good on the training data set.

36

00:02:32.850  -->  00:02:38.040
Then you won't find this out on real data when you actually make predictions you'll find out early on

37

00:02:38.040  -->  00:02:41.000
you will see it on the test data set.

38

00:02:41.280  -->  00:02:43.650
And that way you'll be able to rebuild the model.

39

00:02:43.650  -->  00:02:48.390
So if something goes wrong you just go back and you use the old training data set to build a different

40

00:02:48.390  -->  00:02:50.280
model then you do the same procedure.

41

00:02:50.310  -->  00:02:54.040
So separating a test data set is very common.

42

00:02:54.060  -->  00:03:01.050
It is actually a standard technique used in modeling and you should definitely do that when you are

43

00:03:01.050  -->  00:03:02.160
creating your own models.

44

00:03:02.340  -->  00:03:07.110
In our example when we're building our Joe demographic segmentation the test data set has already been

45

00:03:07.110  -->  00:03:14.010
provided for us and we use as you'll see in this section we'll be using that to verify the model that

46

00:03:14.010  -->  00:03:15.140
we've already created.

47

00:03:15.350  -->  00:03:20.490
However further down in this course I will show you some tips and tricks on how to properly separate

48

00:03:20.760  -->  00:03:28.320
a test not a set because even such a trivial procedure has some under-water stones that come with it

49

00:03:28.320  -->  00:03:28.350
.

50

00:03:28.350  -->  00:03:33.720
So we'll definitely talk about separating your training and testing data sets further down in the course
