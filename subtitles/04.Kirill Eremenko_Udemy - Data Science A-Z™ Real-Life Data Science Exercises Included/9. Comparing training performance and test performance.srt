1

00:00:00,690  -->  00:00:05,960
In the previous tutorial we ran our model on our test data and here's the result.

2

00:00:06,180  -->  00:00:08,370
So we have the wrong number.

3

00:00:08,370  -->  00:00:15,150
We have the predicted probability of the person leaving and we have the exited the actual value did

4

00:00:15,150  -->  00:00:16,730
the person leave or not.

5

00:00:16,830  -->  00:00:23,060
And I just want to clarify one more time that when we run the model we did not use this test data.

6

00:00:23,070  -->  00:00:31,110
We created the model using the main data which is in our churn modeling file then we input this data

7

00:00:31,390  -->  00:00:38,340
where we know it was appended to our churn multi-file But these test records they didn't have the exit

8

00:00:38,360  -->  00:00:40,610
column appended we added that later.

9

00:00:40,620  -->  00:00:49,180
So this prediction is nowhere is in no way associated with this exited actual value.

10

00:00:49,260  -->  00:00:54,840
And so what that means is the model is predicting whether they will or not they will exit and all we

11

00:00:54,840  -->  00:01:00,360
need to do now is actually test check how well it is predicting because this is like the real deal it's

12

00:01:00,360  -->  00:01:08,010
a simulation of the real application of the model in a real environment.

13

00:01:08,010  -->  00:01:14,500
So what we want to do now is run this data through our Kepcher of template.

14

00:01:14,580  -->  00:01:16,110
Now let's go ahead and do that.

15

00:01:16,650  -->  00:01:24,110
So I'm going to bring up the cap curve template there it is maybe expand this whole thing.

16

00:01:24,150  -->  00:01:24,790
Okay.

17

00:01:25,140  -->  00:01:28,810
So where is our data set.

18

00:01:28,920  -->  00:01:33,230
It's in this file.

19

00:01:33,360  -->  00:01:34,850
And first thing we need to do.

20

00:01:34,860  -->  00:01:42,070
Remember we need to order our data set by this last column.

21

00:01:42,090  -->  00:01:47,670
So by way I'm going to maybe this time just do it like this.

22

00:01:47,670  -->  00:01:55,200
So Data Filter and now are sorted by largest to smallest.

23

00:01:55,200  -->  00:02:01,680
So that's the most probable person to leave and the least probabl person to leave is at the bottom.

24

00:02:01,680  -->  00:02:02,930
That's a probability.

25

00:02:03,100  -->  00:02:10,980
And now all we have to do is copy this data copy and go to our Kepcher template.

26

00:02:10,980  -->  00:02:11,250
All right.

27

00:02:11,250  -->  00:02:13,190
And we need to put in here remember'd says ordered.

28

00:02:13,190  -->  00:02:15,270
So we did do that we ordered it.

29

00:02:15,270  -->  00:02:18,090
So I'm going to paste it in here.

30

00:02:18,910  -->  00:02:20,540
OK I'll just try.

31

00:02:20,580  -->  00:02:24,710
Please click delete the ring and paste.

32

00:02:24,900  -->  00:02:32,570
So that's good because it is a total of 1000 records two legs that is 260 26 percent exited.

33

00:02:32,610  -->  00:02:37,070
Now old delete this and all we need to do is take 1.

34

00:02:37,110  -->  00:02:42,990
This Lustral not to just the last one and either drag it like that or you can just double click on the

35

00:02:42,990  -->  00:02:46,940
corner and it will automatically go to the end.

36

00:02:47,040  -->  00:02:51,570
So as you can see it's all popular and just go down to the bottom and check that there's no no issues

37

00:02:51,570  -->  00:02:52,940
along the way.

38

00:02:53,550  -->  00:02:53,820
Yup.

39

00:02:53,820  -->  00:02:59,610
So everything adds up at the end there's a thousand records shown and 60 exited 260 exited 100 percent

40

00:02:59,610  -->  00:03:00,270
everywhere.

41

00:03:00,370  -->  00:03:01,340
Everything's good.

42

00:03:01,620  -->  00:03:02,110
OK.

43

00:03:02,250  -->  00:03:06,450
And actually even the confusion matrix is already populated for us as well.

44

00:03:06,510  -->  00:03:10,160
So you can see how many type 1 Type 2 errors the model has made.

45

00:03:10,220  -->  00:03:15,900
And now all we have to do is as we did previously select this column press control hold control and

46

00:03:15,900  -->  00:03:19,370
select these columns insert line.

47

00:03:19,650  -->  00:03:21,420
Bam done.

48

00:03:21,450  -->  00:03:23,510
So get rid of that.

49

00:03:23,580  -->  00:03:25,630
There is our cap curve.

50

00:03:26,490  -->  00:03:35,760
So that's what it looks like and it looks very similar to the one we had for the real fall when we were

51

00:03:35,760  -->  00:03:36,440
building the model.

52

00:03:36,450  -->  00:03:38,210
But it's a bit different.

53

00:03:38,210  -->  00:03:45,420
So if I do the 50 percent line which is somewhere over here you can see that the model is performing

54

00:03:45,420  -->  00:03:47,720
less than 80 percent at the 50 percent line.

55

00:03:47,730  -->  00:03:52,050
So once again we're not going to calculate the area in the area of the ideal line and calculate the

56

00:03:52,620  -->  00:03:55,720
actual accuracy ratio.

57

00:03:55,770  -->  00:03:57,740
We'll leave that to stats programs.

58

00:03:57,770  -->  00:04:00,030
But just by looking at this

59

00:04:02,730  -->  00:04:09,660
picture we can see that the model is performing well really well but a bit worse than it was on the

60

00:04:09,720  -->  00:04:10,210
train.

61

00:04:10,290  -->  00:04:16,460
So let's go ahead and bring up the train data result over here so we can compare side by side.

62

00:04:16,980  -->  00:04:17,910
There it is.

63

00:04:17,910  -->  00:04:21,080
It was we saved that in our Excel file over here.

64

00:04:21,120  -->  00:04:25,920
So this is what we had before this what we have now.

65

00:04:25,920  -->  00:04:29,940
All right so here they are side by side and you can see two things right away.

66

00:04:29,940  -->  00:04:35,610
First of all the model is performing a bit worse on the test data than you can see that because at the

67

00:04:35,610  -->  00:04:44,310
50 percent mark the models only capturing about seventy eight I would say maybe seventy five percent

68

00:04:44,490  -->  00:04:53,070
of the Turners in this scenario in the testing are at the same time in the training environment.

69

00:04:53,100  -->  00:04:55,320
The model was able to capture 81 percent.

70

00:04:55,320  -->  00:04:59,900
So about a 3 percent drop over there three or six percent drop.

71

00:05:00,210  -->  00:05:02,340
Just moving from train daughter to test.

72

00:05:02,350  -->  00:05:08,310
And don't forget that the train the test that is pretty much just part of the or the test or is part

73

00:05:08,310  -->  00:05:14,840
of the trend or just we separated it before we built the model so these people actually came from the

74

00:05:14,840  -->  00:05:20,840
same time snapshot that when we created this whole lot of it and the second thing that you can see is

75

00:05:20,840  -->  00:05:23,250
that this model is a bit more rugged.

76

00:05:23,270  -->  00:05:26,900
So like you can actually see the bumps in this model.

77

00:05:26,900  -->  00:05:30,020
It's more obvious than they are here.

78

00:05:30,020  -->  00:05:32,330
This one looks a bit smoother.

79

00:05:32,600  -->  00:05:38,840
So the second observation can be explained by the fact that there's less record so there's only a thousand

80

00:05:38,840  -->  00:05:45,830
records here and therefore every like the concentration of breakers here is 10 times less than here

81

00:05:46,160  -->  00:05:54,920
and therefore any kind of deviation or anomalies or randomness in the records it's you can sense it

82

00:05:54,920  -->  00:06:01,400
more because there's just generally less records and therefore that's why the line looks less smooth

83

00:06:01,400  -->  00:06:01,590
.

84

00:06:01,640  -->  00:06:07,930
Here you can still see some ruggedness but it kind of smooths out because there 10 times more records

85

00:06:07,940  -->  00:06:16,310
and even if one or two are deviating from the norm then they're smoothed out by the other eight as opposed

86

00:06:16,310  -->  00:06:18,290
to here where there's 10 times less.

87

00:06:18,290  -->  00:06:19,300
So that's the first thing.

88

00:06:19,310  -->  00:06:23,690
And you will notice that the less data you can put them into the model the more of these jagged lines

89

00:06:24,080  -->  00:06:25,020
you will have.

90

00:06:25,340  -->  00:06:29,650
And the second the first observation the main one that's the deterioration of performance.

91

00:06:29,690  -->  00:06:32,330
Well there is a couple of reasons why that could be.

92

00:06:32,330  -->  00:06:39,440
First of all perhaps maybe our model is over fitted and you will find that to a certain extent models

93

00:06:39,740  -->  00:06:45,520
will it's natural for a model to be better fitted to the daughter that is trained on.

94

00:06:45,620  -->  00:06:50,300
It's it's like in in anything you say even if you're doing martial arts right.

95

00:06:50,300  -->  00:06:57,490
You're better at the gym that you are training at than at a gym where you go.

96

00:06:57,500  -->  00:07:01,250
Or let's say soccer or or American football right.

97

00:07:01,330  -->  00:07:02,370
Your as a whole.

98

00:07:02,390  -->  00:07:07,250
If you're the home team you'll always play a little bit better on your own ground than when you're playing

99

00:07:07,370  -->  00:07:09,400
away and somebody else's field.

100

00:07:09,590  -->  00:07:14,800
So that's OK as long as it's not too much of a drop.

101

00:07:14,810  -->  00:07:20,300
The other reason why this could happen that the drop off here is once again because there's less records

102

00:07:20,360  -->  00:07:27,230
because we only have 1000 records for this test which is which is OK which is fine but maybe there is

103

00:07:27,230  -->  00:07:33,320
some you know maybe all those records some how it happened that they are a bit skewed one way or the

104

00:07:33,360  -->  00:07:36,800
you know they have a certain characteristic that these other records don't have.

105

00:07:37,010  -->  00:07:39,850
And that can affect this.

106

00:07:40,400  -->  00:07:46,730
What you're seeing and that is also there has also to do a lot with how the sample the test sample is

107

00:07:46,730  -->  00:07:52,050
selected from the overall the whole data set that you have for your training and testing.

108

00:07:52,280  -->  00:07:56,570
It is very important to select the correct that we will talk about this further down in the course how

109

00:07:56,570  -->  00:08:03,800
to correctly select a test sample to minimize any potential for this effect when just because you select

110

00:08:03,810  -->  00:08:08,190
a test sample incorrectly the results are not matching up.

111

00:08:08,270  -->  00:08:11,100
So but otherwise this is good.

112

00:08:11,160  -->  00:08:14,540
It's it Matt it validates that our model is performing.

113

00:08:14,540  -->  00:08:21,290
So basically in this case even without knowing anything about this data all model was able to predict

114

00:08:21,290  -->  00:08:22,350
quite quite well.

115

00:08:22,410  -->  00:08:30,050
So imagine this like you can by contacting just 50 percent of your sample of these thousand people by

116

00:08:30,050  -->  00:08:37,460
contacting 500 of them you will get nearly 80 percent of those who are actually at risk at living at

117

00:08:37,490  -->  00:08:39,740
a high risk that you'll actually leave.

118

00:08:39,740  -->  00:08:45,860
So that that is a great result and that's why we consider models between 70 to 80 percent good models

119

00:08:45,870  -->  00:08:46,390
.

120

00:08:47,120  -->  00:08:54,000
And so our model has possible Ed. This is how you use test data to validate.

121

00:08:54,050  -->  00:08:58,250
One other thing I wanted to mention is that this is a very powerful technique that we use just here

122

00:08:58,250  -->  00:08:58,490
.

123

00:08:58,490  -->  00:09:00,960
We plotted the cap curve.

124

00:09:01,130  -->  00:09:06,770
The cumulative accuracy profile for both models and we compared it so just visually comparing of course

125

00:09:06,770  -->  00:09:08,820
we can calculate the area.

126

00:09:08,840  -->  00:09:14,730
And so on be more mathematical it but just visually comparing We can tell right away which CNR is better

127

00:09:14,730  -->  00:09:14,750
.

128

00:09:14,750  -->  00:09:16,450
So the models performing better here.

129

00:09:16,760  -->  00:09:22,070
But you can also use the same exact technique to comparing models to a different model.

130

00:09:22,070  -->  00:09:27,710
So if you had two options or the model so you create one more and then you create the second model and

131

00:09:28,580  -->  00:09:30,590
you didn't know which one was better.

132

00:09:30,860  -->  00:09:34,040
Then you could put them side by side like this.

133

00:09:34,070  -->  00:09:39,320
Use this same type template the cap curve template create the cap curves and for two separate models

134

00:09:39,410  -->  00:09:41,450
but run them on the same data set.

135

00:09:41,450  -->  00:09:42,920
So here we are using different data.

136

00:09:42,920  -->  00:09:44,720
We're using trained out and test data.

137

00:09:44,840  -->  00:09:50,540
But if you run them both on on the test data set for instance this model on the test not a set and then

138

00:09:50,540  -->  00:09:56,360
a different model in the test data set and you compare it you can just say in the same way compare visually

139

00:09:56,360  -->  00:09:57,020
the graphs.

140

00:09:57,020  -->  00:10:03,980
And that way you can assess which model is is better and so is going to be like a random metric or an

141

00:10:04,010  -->  00:10:10,370
unreliable metric like accuracy rate from the confusion matrix.

142

00:10:10,400  -->  00:10:16,130
Here you can actually it's a more reliable metric because as you can see it's taking account all the

143

00:10:16,130  -->  00:10:21,920
records it's you can visually see how it's going so if there's any problem with the model you will find

144

00:10:21,920  -->  00:10:23,690
that you see it right away.

145

00:10:23,690  -->  00:10:30,770
And the third scenario when you can use this technique as well is when you're comparing a model to itself

146

00:10:30,830  -->  00:10:31,760
over time.

147

00:10:31,760  -->  00:10:37,130
So this is how you modeled performing Now this is before and test data and then you know six months

148

00:10:37,130  -->  00:10:40,640
later or 12 months later you run this same test.

149

00:10:40,640  -->  00:10:46,730
But for a new data set in the future like for the people that are going to be banking with you in six

150

00:10:46,730  -->  00:10:53,240
months and for their behavior and for that geo political environment you run the same model on those

151

00:10:53,240  -->  00:10:58,300
people and you see how it changed you look at the curve and this is this is a very important to me.

152

00:10:58,310  -->  00:11:01,810
We'll talk about this more as well when we're talking about deterioration over time.

153

00:11:01,820  -->  00:11:07,380
Just wanted to run ahead a bit so that you're prepared and you're kind of thinking about this already

154

00:11:07,400  -->  00:11:07,900
now.

155

00:11:07,970  -->  00:11:14,120
Before we get to that tutorial you'll see that over time maybe your model will be getting worse and

156

00:11:14,420  -->  00:11:18,290
like this curve this red car will be getting to the blue one every time you check your morals every

157

00:11:18,290  -->  00:11:19,020
six months.

158

00:11:19,250  -->  00:11:23,390
And that will speak more of the situation but more on that later.

159

00:11:23,480  -->  00:11:29,270
This is all for today I hope you found today's information useful and definitely use this technique

160

00:11:29,270  -->  00:11:29,960
in your career.

161

00:11:29,960  -->  00:11:33,150
It can help you create a much better models
