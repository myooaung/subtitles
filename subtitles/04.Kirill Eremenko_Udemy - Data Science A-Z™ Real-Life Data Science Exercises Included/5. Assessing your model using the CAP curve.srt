1

00:00:00,330  -->  00:00:06,390
Cap analysis we've talked about cap a lot and in fact we've talked about cap that much that I'm no longer

2

00:00:06,510  -->  00:00:13,230
even saying cumulative accuracy profile because I am assuming that you're entirely comfortable with

3

00:00:13,290  -->  00:00:15,690
this abbreviation and the whole term and what it means.

4

00:00:15,690  -->  00:00:21,690
So let's see how to the cap as we've discussed.

5

00:00:21,720  -->  00:00:28,560
There are three lines that are important on the Kepcher of the blue line which is the random line when

6

00:00:28,560  -->  00:00:31,920
you select your samples at random.

7

00:00:31,950  -->  00:00:38,940
The red line which is our model line the and different models will have different red lines but basically

8

00:00:38,940  -->  00:00:39,970
look something like that.

9

00:00:40,170  -->  00:00:46,470
And the gray line which is the perfect model or when you have a crystal ball when you can select all

10

00:00:46,530  -->  00:00:54,960
of the future turners or purchaser's or whatever action takers and you can select them right away on

11

00:00:54,960  -->  00:00:59,760
the dot before even selecting one single person that you don't want to select.

12

00:00:59,760  -->  00:01:06,130
And so these are the three main lines and how do we analyze this cap Kaveri know how to build it but

13

00:01:06,210  -->  00:01:09,240
what can we derive what insights can we derive from here.

14

00:01:09,390  -->  00:01:14,670
Well it's kind of intuitive that the closer your red line is to the gray line the better you model the

15

00:01:14,670  -->  00:01:17,610
closer to the blue line the worse.

16

00:01:17,610  -->  00:01:19,710
So how can we quantify this effect.

17

00:01:20,010  -->  00:01:26,820
Well there is a standard approach to calculate the accuracy ratio and to calculate accuracy ratio and

18

00:01:26,820  -->  00:01:34,170
you take the area under the perfect model or the perfect line which is color in gray here and it's called

19

00:01:34,260  -->  00:01:35,360
a pea.

20

00:01:35,730  -->  00:01:44,580
And then you need to take that area under the red line which is colored in red here which is a R and

21

00:01:44,790  -->  00:01:46,690
then you need to divide one by the other.

22

00:01:46,710  -->  00:01:53,240
So you need to divide a r by AP and then this ratio that you get is obviously between 0 and 1.

23

00:01:53,400  -->  00:01:59,310
And the closer this ratio is to 2:1 the better the further it is away from one close to zero the worse

24

00:01:59,310  -->  00:02:00,280
.

25

00:02:00,360  -->  00:02:05,010
However it can be quite complicated to calculate this area under the curve statistical tools can do

26

00:02:05,040  -->  00:02:05,720
for you.

27

00:02:05,850  -->  00:02:14,060
But how can you assess the cap curve by just looking at it so visually it's not that easy to get this

28

00:02:14,070  -->  00:02:16,410
quantifiable metric just by looking at the curve.

29

00:02:16,560  -->  00:02:19,960
So there's a second approach and that's what we're going to discuss.

30

00:02:19,960  -->  00:02:28,650
Now let's get rid of areas and instead of looking at the area what you can do is look at the 50 percent

31

00:02:28,650  -->  00:02:35,940
line on the horizontal axis and look where it crosses your model and then look at where that line the

32

00:02:35,970  -->  00:02:42,210
horizontal line from there crosses the vertical axis So basically how many turners will you pick up

33

00:02:42,600  -->  00:02:50,610
or action takers or how many positive outcomes are you going to identify if you take 50 percent of your

34

00:02:50,610  -->  00:02:51,590
population.

35

00:02:51,690  -->  00:02:55,010
And in this case we can see it's around 90 percent or something like that.

36

00:02:55,260  -->  00:03:01,890
And just by looking at that there's like a rule of thumb how you can assess your model based on that

37

00:03:01,890  -->  00:03:03,630
X number and here it is.

38

00:03:03,660  -->  00:03:04,200
Are you ready.

39

00:03:04,200  -->  00:03:05,000
Here we go.

40

00:03:05,010  -->  00:03:10,040
So if x is less than 60 percent the model is rubbish.

41

00:03:10,350  -->  00:03:14,040
Basically it's not useful at all.

42

00:03:14,080  -->  00:03:14,580
You have.

43

00:03:14,630  -->  00:03:19,290
You can create a better one probably you can create a better one and you need to try again.

44

00:03:19,620  -->  00:03:27,090
If you model your X is between 60 percent and 70 percent then the model is considered to be poor poor

45

00:03:27,090  -->  00:03:30,360
or average and by the way these are my this is my rule of thumb.

46

00:03:30,360  -->  00:03:33,470
Other people might have a different rule of thumb but this is what I go by.

47

00:03:33,740  -->  00:03:38,250
If is between 60 percent and over and it's it's a poor model to be honest like you can you can do better

48

00:03:38,250  -->  00:03:39,970
than that.

49

00:03:40,500  -->  00:03:46,080
If it's if X is between 70 percent and 80 percent that's a good model that's already where you should

50

00:03:46,080  -->  00:03:53,340
be aiming for anything above 70 percent that can deliver good quality insights to the business and actually

51

00:03:53,340  -->  00:03:54,750
deliver value.

52

00:03:54,750  -->  00:03:58,590
Anything between 80 percent and 90 percent like we see here is very good.

53

00:03:58,590  -->  00:04:00,180
It's extremely good.

54

00:04:00,180  -->  00:04:03,160
That's if you can get a model over 80 percent.

55

00:04:03,240  -->  00:04:06,320
That is an amazing result.

56

00:04:06,510  -->  00:04:10,430
And anything above 90 percent up to 100 that is just too good.

57

00:04:10,620  -->  00:04:17,760
It is too good to believe and the are there is one option that there should be very careful here with

58

00:04:18,060  -->  00:04:19,320
his overfitting.

59

00:04:19,380  -->  00:04:25,290
If your model is showing you results like 90 percent or safe emulsion you're 100 percent then the obvious

60

00:04:25,290  -->  00:04:30,390
answer there is that one of your independent variables is actually a post facto variable meaning that

61

00:04:30,900  -->  00:04:33,880
it shouldn't be in the data because it's looking into the future.

62

00:04:34,110  -->  00:04:39,660
The person who supplied that variable forgot to take it out or forgot to explain to you that you know

63

00:04:39,900  -->  00:04:46,610
their credit score actually is turned into zero after they leave the bank and therefore everybody offer

64

00:04:46,650  -->  00:04:52,250
zero credit score obviously has left the bank and therefore your model is picking them up like like

65

00:04:52,280  -->  00:04:53,510
it's super easy.

66

00:04:53,520  -->  00:04:57,840
So if you have 100 percent that's definitely something on a few variables even if you have 90 to 100

67

00:04:57,840  -->  00:05:02,070
percent you have to check that there could be some forward looking variables.

68

00:05:02,070  -->  00:05:08,190
The other thing is overfitting you could be overfitting a model and what that means is that you your

69

00:05:08,190  -->  00:05:16,410
model has been so well fit that specific data set that you supplied it that when you try it just heavily

70

00:05:16,410  -->  00:05:18,430
relying on the normal is in that data set.

71

00:05:18,570  -->  00:05:24,690
And when you feel it's a new data set like you know in a month time or something like not not training

72

00:05:24,690  -->  00:05:26,730
data not the data that you trained your model on.

73

00:05:26,730  -->  00:05:29,760
We'll talk about this a bit a lot more actually in the coming tutorials.

74

00:05:29,770  -->  00:05:35,850
But so if you feed this model some data that you want to actually predict on then you will crash it

75

00:05:35,860  -->  00:05:40,500
all it won't crash and it won't perform as well perform you know at the 60 percent mark or something

76

00:05:40,500  -->  00:05:40,530
.

77

00:05:40,530  -->  00:05:44,460
So that means a model is overfit it and be very careful about that.

78

00:05:44,460  -->  00:05:49,950
We'll talk about overfitting more in fact in the coming tutorials we will learn how to avoid that problem

79

00:05:49,970  -->  00:05:50,150
.

80

00:05:50,310  -->  00:05:58,140
And finally if you can get an x or this parameter to be between 90 percent Harmsen and you're not using

81

00:05:58,140  -->  00:06:03,430
for looking parameters or you're not overfitting then give me a call because I might have a job for

82

00:06:03,430  -->  00:06:11,580
you people like that are rare and I have a lot of head hunters looking for people who can do modeling

83

00:06:11,580  -->  00:06:12,060
like that.

84

00:06:12,060  -->  00:06:19,560
So definitely keep that in mind and know to finish off today's Tauriel we're going to jump into excel

85

00:06:19,590  -->  00:06:27,480
and have a look at our model and see how it compares how it actually performs on that scale so we're

86

00:06:27,480  -->  00:06:33,510
going to take a line very simple visual analysis so there's a 50 percent line we're going to drag a

87

00:06:33,510  -->  00:06:40,110
vertical line or here as you can see it crosses the model at about 80 percent or 80 and a half percent

88

00:06:40,110  -->  00:06:40,580
.

89

00:06:40,620  -->  00:06:43,110
Very good model.

90

00:06:43,260  -->  00:06:50,430
So all we have to do now is make sure we're not overfitting it and then we can start using it.

91

00:06:50,430  -->  00:06:58,120
So in the next tutorial what is going to happen I will give you a cap template that I promised.

92

00:06:58,170  -->  00:07:05,010
And then after that we will learn how to check for overfitting and models and learn how to use test

93

00:07:05,100  -->  00:07:07,750
data and the differences between training and test data.

94

00:07:07,980  -->  00:07:09,300
I look forward to seeing you then.

95

00:07:09,300  -->  00:07:11,010
Until next time happy analyzing
