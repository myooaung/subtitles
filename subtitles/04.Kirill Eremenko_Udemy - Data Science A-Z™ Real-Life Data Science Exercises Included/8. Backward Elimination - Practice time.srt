1

00:00:00,370  -->  00:00:02,460
All right exciting to Tauriel ahead.

2

00:00:02,460  -->  00:00:07,440
Today we're going to build our very first multiple linear regression and we're going to be using the

3

00:00:07,440  -->  00:00:09,230
backward elimination method.

4

00:00:09,420  -->  00:00:11,030
I hope you're pumped about this.

5

00:00:11,040  -->  00:00:12,730
Let's get straight into it.

6

00:00:12,750  -->  00:00:22,110
Open up Grettel and let's connect our data file open data mine is in on my desktop modeling section

7

00:00:22,380  -->  00:00:23,550
multiple integration.

8

00:00:23,640  -->  00:00:25,150
So it's a CSP file.

9

00:00:25,170  -->  00:00:27,120
There it is.

10

00:00:27,870  -->  00:00:28,830
That's fine.

11

00:00:28,830  -->  00:00:30,000
We don't need to do that.

12

00:00:30,270  -->  00:00:36,300
And the first thing you can see here is that Grettel has identified that we have a categorical variable

13

00:00:37,290  -->  00:00:42,730
it says variable for which Skuld's state is a string so it is a warning.

14

00:00:42,730  -->  00:00:44,370
So we're going to have to deal with this.

15

00:00:44,400  -->  00:00:46,770
And there's two categories New York and California.

16

00:00:46,770  -->  00:00:49,130
So very very convenient.

17

00:00:49,140  -->  00:00:51,020
Now we know that there is two categories.

18

00:00:51,060  -->  00:00:54,400
So let's go ahead and deal with these dummy variables right away.

19

00:00:55,050  -->  00:01:01,710
As we discussed previously because we have a categorical variable we can't just included in our multiple

20

00:01:02,100  -->  00:01:11,850
linear regression formula equation because that way it's it's a it's not a number so we need to replace

21

00:01:11,850  -->  00:01:15,260
it with some dummy variables as we discussed before.

22

00:01:15,360  -->  00:01:16,850
And that's exactly what we're going to do here.

23

00:01:16,860  -->  00:01:18,510
It's very simple to do in griddle.

24

00:01:18,510  -->  00:01:19,980
All you have to do is select a variable.

25

00:01:19,980  -->  00:01:25,630
Go to add and down here it actually has an option dummys for discrete variable.

26

00:01:25,860  -->  00:01:30,980
Click that and here make sure you encoding the right variable.

27

00:01:31,050  -->  00:01:33,260
And here you have three options and code all values.

28

00:01:33,270  -->  00:01:35,740
Or you can skip the lowest value or the highest value.

29

00:01:35,910  -->  00:01:37,350
And Grettel smart like that.

30

00:01:37,350  -->  00:01:44,010
It knows that you won't be able to use all of your dummy variables in your models anyway.

31

00:01:44,050  -->  00:01:49,620
You're going to have to omit one of your dummy variables and we discussed that also in this cause just

32

00:01:49,620  -->  00:01:54,930
previously when we're talking about the dummy variable trap because you can't if you include all of

33

00:01:54,930  -->  00:01:56,850
them then your model won't work.

34

00:01:56,880  -->  00:02:02,400
So it's right away it's offering you to skip one of them but as we agreed we're going to encode all

35

00:02:02,410  -->  00:02:02,510
.

36

00:02:02,580  -->  00:02:07,680
And then we'll select the ones that the one we want to use ourselves because that gives us a bit more

37

00:02:07,680  -->  00:02:08,670
flexibility.

38

00:02:08,670  -->  00:02:10,650
So we'll just click OK here.

39

00:02:11,220  -->  00:02:15,900
And if you expand state now you will see that there's two dummy variables the state underscore one in

40

00:02:15,900  -->  00:02:17,470
DC underscore.

41

00:02:18,120  -->  00:02:20,820
And one is for New York and once for California.

42

00:02:20,850  -->  00:02:23,640
We don't want to remember the names and which one is for what.

43

00:02:23,640  -->  00:02:25,970
So we'll just quickly modify the names.

44

00:02:26,010  -->  00:02:33,570
Right click your verbal click Edit attributes and here change take New York and put it in the name of

45

00:02:33,570  -->  00:02:34,440
the variable.

46

00:02:34,710  -->  00:02:38,510
So it's called variable New York or you can have spaces so get rid of the space.

47

00:02:38,550  -->  00:02:44,880
Click this check mark here and then proceed to the next variable by clicking the down arrow to California

48

00:02:44,890  -->  00:02:45,410
.

49

00:02:46,170  -->  00:02:47,330
And same thing.

50

00:02:47,550  -->  00:02:50,040
OK so now we have two dummy variables.

51

00:02:50,070  -->  00:02:51,350
New York and California.

52

00:02:51,360  -->  00:02:53,050
And they're really great.

53

00:02:53,070  -->  00:02:56,410
We're ready to proceed with our modeling part.

54

00:02:56,580  -->  00:03:07,620
So I've put a picture here of our previous slide by the way I didn't mention this but I am intending

55

00:03:07,620  -->  00:03:13,320
on attaching the slides as a downloadable file to the previous Lakesha So go ahead and download that

56

00:03:13,410  -->  00:03:19,090
in the course materials and you can you know keep this file for yourself and then refer to it whenever

57

00:03:19,170  -->  00:03:20,580
whenever you need to.

58

00:03:20,580  -->  00:03:24,950
So this is our building a model backward elimination method.

59

00:03:25,290  -->  00:03:30,990
Our first step is to select a significant level for variables to stay in the model.

60

00:03:31,140  -->  00:03:34,110
In our example we're going to use 0.05.

61

00:03:34,110  -->  00:03:36,570
So I'm going to say it out loud.

62

00:03:36,570  -->  00:03:40,960
I am selecting the significance level to be 5 percent or 0.05.

63

00:03:41,010  -->  00:03:41,340
Good.

64

00:03:41,340  -->  00:03:45,720
Step 1 done next fit the full model of all possible predictors.

65

00:03:45,720  -->  00:03:47,460
Let's go ahead and do that.

66

00:03:48,030  -->  00:03:56,070
So model ordinary least squares and here we're going to take profit and we're going to move it into

67

00:03:56,140  -->  00:03:59,820
our dependent variable and because we're going to be doing this process quite a few times is going to

68

00:03:59,820  -->  00:04:02,340
be an iterative approach.

69

00:04:02,340  -->  00:04:06,950
We're going to click this box here set as default so every time we come back to his menu.

70

00:04:07,020  -->  00:04:09,410
Profit is already the dependent variable.

71

00:04:09,510  -->  00:04:14,370
And now let's go ahead and move our independent variables into the regressors box.

72

00:04:14,430  -->  00:04:16,020
We'll start off one by one here.

73

00:04:16,050  -->  00:04:19,050
R&D spend so spend on research and development.

74

00:04:19,050  -->  00:04:20,320
Yes that's one of them.

75

00:04:20,490  -->  00:04:22,180
Administration expenses yes.

76

00:04:22,200  -->  00:04:23,110
Marketing spend.

77

00:04:23,160  -->  00:04:25,140
Yes State No.

78

00:04:25,230  -->  00:04:29,350
Because we've agreed that we will replace state with dummy variables.

79

00:04:29,370  -->  00:04:33,140
Profit is our dependent variable and now we have two dummy variables.

80

00:04:33,390  -->  00:04:41,070
We can only include one in order to avoid the dummy variable trap and we're going to include the New

81

00:04:41,070  -->  00:04:45,090
York will which include the New York one you feel it you can feel free to include whichever one you

82

00:04:45,090  -->  00:04:45,750
like.

83

00:04:45,750  -->  00:04:46,710
So there we go.

84

00:04:46,710  -->  00:04:49,220
Our regressors are ready and all we have to do is cook.

85

00:04:49,230  -->  00:04:50,100
Okay.

86

00:04:50,990  -->  00:04:58,700
Vola congratulations this is your first multiple linear regression model and as you can see here you

87

00:04:58,700  -->  00:05:07,000
have the four variables present plus the constant you are modeling independent dependent variable profit

88

00:05:07,030  -->  00:05:07,230
.

89

00:05:07,520  -->  00:05:08,830
And let's have a look at this.

90

00:05:08,840  -->  00:05:13,230
And now we know how to read these Let's extract some information from him.

91

00:05:13,280  -->  00:05:18,080
So these are coefficients and we'll talk about interpretive coefficients in the next tutorial so we'll

92

00:05:18,080  -->  00:05:19,250
leave that for now.

93

00:05:19,540  -->  00:05:22,440
We're not going to focus on the center arrow to.

94

00:05:22,520  -->  00:05:24,800
What we're interested in is in the p value right.

95

00:05:24,830  -->  00:05:28,670
So we've got the p values for all of all four variables.

96

00:05:28,790  -->  00:05:33,140
And here you can see some stars meaning that it's a good P-value it's a significant variable because

97

00:05:33,350  -->  00:05:38,890
it is so small it is seven times ten to the power of minus when you show tiny values.

98

00:05:39,080  -->  00:05:45,400
These values are quite large actually so 0.60 5 0.12 0.60 2.

99

00:05:45,440  -->  00:05:48,070
So that's why they don't have stars you get.

100

00:05:48,080  -->  00:05:53,500
I think the way it works is you get three stars if you're less than zero point zero or one two stars

101

00:05:53,510  -->  00:06:00,490
if you're less than zero point zero five and one star If you're less than point 0 1 so 10 percent.

102

00:06:00,530  -->  00:06:03,560
So that's how this rating system goes.

103

00:06:03,780  -->  00:06:08,980
Anyway let's go back to our backwood elimination step by step method.

104

00:06:09,410  -->  00:06:12,980
So we've run the former model with all possible predictors.

105

00:06:13,070  -->  00:06:15,350
How about we do the next step now step three.

106

00:06:15,350  -->  00:06:18,590
Consider the predicter with the highest P-value.

107

00:06:18,740  -->  00:06:18,980
Right.

108

00:06:18,980  -->  00:06:25,350
So let's go ahead and look at him predict some of the highest P-value is this guy administration.

109

00:06:25,370  -->  00:06:26,270
He's got the highs.

110

00:06:26,320  -->  00:06:28,900
Good we've picked him out next.

111

00:06:29,120  -->  00:06:37,580
If the P-value is greater than the significance level go to Step Four Let's check that P-value is greater

112

00:06:37,580  -->  00:06:38,850
than 0.05.

113

00:06:38,870  -->  00:06:39,650
Definitely greater.

114

00:06:39,650  -->  00:06:47,390
So we're going to step 4 and Step 4 remove this predicter and fit the model before this variable and

115

00:06:47,390  -->  00:06:48,730
then move back to Step 3.

116

00:06:48,890  -->  00:06:50,370
OK that's interesting.

117

00:06:50,360  -->  00:06:51,950
Let's go ahead and do that.

118

00:06:51,950  -->  00:06:57,150
So basically what that's telling us is running you model blue for this variable.

119

00:06:57,350  -->  00:06:58,570
We're going to do exactly that.

120

00:06:58,580  -->  00:07:02,420
We won't touch this window we'll leave it open and we'll go back to Grettel.

121

00:07:02,990  -->  00:07:07,500
And here we're going to go model ordinary least squares.

122

00:07:07,490  -->  00:07:17,030
And now we're going to take administration out of our model so we'll just remove it like that and we'll

123

00:07:17,030  -->  00:07:18,810
click OK.

124

00:07:18,890  -->  00:07:28,220
So now if we go back here and put it side by side you will see what happened now we have one variable

125

00:07:28,310  -->  00:07:35,310
less so here administration is present here administration is no longer present.

126

00:07:35,450  -->  00:07:37,670
And also you can see that some things have changed.

127

00:07:37,670  -->  00:07:43,880
So for instance the constant has changed the coefficients have changed the p values have changed basically

128

00:07:43,970  -->  00:07:50,650
everything has changed and even a star has appeared for marketing spend so before it was so large says

129

00:07:50,660  -->  00:07:56,660
0.12 it was greater than 10 percent now it's less than 10 percent so it's got a star so it became more

130

00:07:56,660  -->  00:08:00,850
significant without the administration Mirable present.

131

00:08:00,860  -->  00:08:01,580
And that happened.

132

00:08:01,580  -->  00:08:02,480
That's normal.

133

00:08:02,480  -->  00:08:10,130
That's there's lots of factors that influence that and excluding or including variables will always

134

00:08:10,130  -->  00:08:13,010
affect your existing variables.

135

00:08:13,040  -->  00:08:19,730
And that's one of the reasons why you can't just exclude it exclude administration and assume that everything

136

00:08:19,730  -->  00:08:20,810
else stays the same.

137

00:08:20,810  -->  00:08:23,820
That's exactly why we have to rerun the model.

138

00:08:24,260  -->  00:08:25,990
And so we are ready to proceed to the next step.

139

00:08:26,000  -->  00:08:29,510
But before we do I wanted to show you one quick thing.

140

00:08:29,530  -->  00:08:30,010
Good.

141

00:08:30,120  -->  00:08:38,300
Good exercise to do and this is not part of our step by step method and this is also not the awesome

142

00:08:38,630  -->  00:08:42,240
tip or hint that we're going to look at to make the role model robust.

143

00:08:42,260  -->  00:08:47,650
This is just something for us something for us to understand what happened here.

144

00:08:48,140  -->  00:08:54,350
A way to understand is always a good way to understand is always to visualize things so let's go ahead

145

00:08:54,380  -->  00:08:59,980
and visualize this variable or visualize the proffered against this variable.

146

00:09:00,080  -->  00:09:06,440
If we hold all other variables constant It's very simple to do just go to graphs Graf's fitted actual

147

00:09:06,440  -->  00:09:10,210
plot and here select against administration.

148

00:09:10,340  -->  00:09:16,580
And what that will do is it will plot profit against the administration bearable assuming that all other

149

00:09:17,810  -->  00:09:19,610
variables are held constant.

150

00:09:19,700  -->  00:09:25,170
And so the blue values are fitted the red vows the actual So ignore the blue values for now.

151

00:09:25,580  -->  00:09:26,660
What are we looking at.

152

00:09:26,660  -->  00:09:33,080
Is that is there a any kind of relationship any kind of obvious relationship that we can see between

153

00:09:33,600  -->  00:09:35,120
a profit and an inspiration.

154

00:09:35,120  -->  00:09:42,130
So is like like we used to see like a line that we can go that we can draw that goes through the various

155

00:09:42,480  -->  00:09:46,370
variables all the values and it's quite close to me personally.

156

00:09:46,370  -->  00:09:48,020
Looks like there is no relationship.

157

00:09:48,050  -->  00:09:53,540
And like it's all scattered all over the place and what that means is that even if you change administrations

158

00:09:53,540  -->  00:10:00,230
spend so much money you're investing into your administration or how much that expense is if you increase

159

00:10:00,230  -->  00:10:02,480
or decrease it you can't really effect profit.

160

00:10:02,480  -->  00:10:08,810
So by changing this independent variable the dependent variable is not affected and that is exactly

161

00:10:08,810  -->  00:10:16,340
why we chose to exclude administration from our model because it is not a predictor of profit.

162

00:10:16,670  -->  00:10:20,600
You take two companies that are identical but they spend different amounts on the industry and you can

163

00:10:20,600  -->  00:10:25,430
really tell which one will have a higher profit or you can even according to a model make a prediction

164

00:10:25,450  -->  00:10:25,670
.

165

00:10:25,880  -->  00:10:31,820
So we're going to close this window now that should kind of explain a little bit better more intuitively

166

00:10:32,240  -->  00:10:37,130
what this means that we're excluding a variable from our modeling.

167

00:10:37,130  -->  00:10:42,710
Now we're going to move on to this part we're going to proceed with the next step over backward elimination

168

00:10:42,710  -->  00:10:43,310
process.

169

00:10:43,370  -->  00:10:52,100
So I'm going to bring up the rules again and here we can see that we've just fit the model for the new

170

00:10:52,100  -->  00:10:54,830
variable and now we're going to do this part again.

171

00:10:54,830  -->  00:11:01,010
So consider the predicter of highest P-value check if P-value is greater than your significant level

172

00:11:01,010  -->  00:11:01,080
.

173

00:11:01,130  -->  00:11:05,710
And if it is go to Step 4 Let's go ahead and check that.

174

00:11:05,720  -->  00:11:13,470
So we'll find the variable the highest P-value which is this one New York so our dummy variable has

175

00:11:13,470  -->  00:11:19,640
the highest P value 0.5 sound very high p value definitely greater than our significant level which

176

00:11:19,640  -->  00:11:21,310
is 0.05.

177

00:11:21,740  -->  00:11:25,670
And therefore we need to exclude this variable from our model as well.

178

00:11:25,780  -->  00:11:33,530
Let's go ahead and do that model ordinarily squares take New York and take it out.

179

00:11:33,830  -->  00:11:38,190
Click OK and let's move this one over here.

180

00:11:38,210  -->  00:11:38,620
All right.

181

00:11:38,630  -->  00:11:40,590
So what have we got so far.

182

00:11:40,670  -->  00:11:47,360
We've got two variables once again coefficients changed the constant changed P values changed as you

183

00:11:47,360  -->  00:11:49,620
can see this P-value got even smaller.

184

00:11:49,670  -->  00:11:54,330
It's now 0.06 it can it can really go both ways.

185

00:11:54,460  -->  00:11:57,780
You never know until you actually run the model.

186

00:11:57,830  -->  00:12:01,310
But now we've got a new picture.

187

00:12:01,310  -->  00:12:03,830
We've got two variables and we're in for next step.

188

00:12:03,830  -->  00:12:09,410
Once again you can quickly check the graph if you like go to fit actual plot.

189

00:12:09,890  -->  00:12:13,650
And here we want to check against New York.

190

00:12:13,670  -->  00:12:16,570
So look at the Reds again.

191

00:12:16,640  -->  00:12:19,400
Basically because it is a categorical variable.

192

00:12:19,400  -->  00:12:21,560
This is a dummy variable now.

193

00:12:21,980  -->  00:12:25,090
So 0 1 Remember we're talking about the on off switch.

194

00:12:25,100  -->  00:12:26,270
So are you in New York.

195

00:12:26,270  -->  00:12:26,680
Yes.

196

00:12:26,690  -->  00:12:27,710
Are you not in New York.

197

00:12:27,710  -->  00:12:28,660
Where else can you be.

198

00:12:28,670  -->  00:12:30,640
But California are in California.

199

00:12:30,650  -->  00:12:36,080
So but basically what is this is saying is being on not being in New York is not really doesn't really

200

00:12:36,080  -->  00:12:41,930
make a difference the way if if there was a difference you'd see like a lot of red here and a lot of

201

00:12:41,930  -->  00:12:46,390
red here meaning that if you're in New York your profit is much higher than if you're not in your.

202

00:12:46,400  -->  00:12:53,300
But here it's kind of evenly distributed across like across the whole line here and across the whole

203

00:12:53,300  -->  00:12:59,530
line here so no wonder we were so suggested to exclude that variable from our regression.

204

00:12:59,540  -->  00:13:03,770
It doesn't doesn't really predict anything it's not that much of a predictor.

205

00:13:03,770  -->  00:13:06,140
So that's why we took it out.

206

00:13:06,170  -->  00:13:06,730
All right.

207

00:13:06,980  -->  00:13:08,580
So now we're doing the next step again.

208

00:13:08,600  -->  00:13:12,060
We don't need to go back to rules because by now we should remember them.

209

00:13:12,500  -->  00:13:14,510
Look for the highest P-value.

210

00:13:14,720  -->  00:13:15,770
This one.

211

00:13:15,980  -->  00:13:20,800
And check if it's greater or less than our significance level.

212

00:13:20,840  -->  00:13:27,570
So 0.06 is quite close to zero are five but it's still greater than 0 0 0.05.

213

00:13:27,590  -->  00:13:28,690
So what does that mean.

214

00:13:28,700  -->  00:13:30,370
We need to exclude this verb.

215

00:13:30,620  -->  00:13:32,710
Let's go ahead and do that.

216

00:13:32,750  -->  00:13:39,350
This is our Grettel software and we're going to go orderly squares once again.

217

00:13:39,620  -->  00:13:40,150
Which one is it.

218

00:13:40,160  -->  00:13:41,030
Marketing spend.

219

00:13:41,030  -->  00:13:42,700
So we're going to take it out.

220

00:13:42,800  -->  00:13:46,410
It'll click OK and now we'll move it over here.

221

00:13:46,910  -->  00:13:52,290
OK let's have a look at what we have now.

222

00:13:52,310  -->  00:13:56,120
So now we have only one variable left it's very significant.

223

00:13:56,120  -->  00:13:59,680
Lots of stars is definitely less than zero point zero five.

224

00:13:59,870  -->  00:14:01,480
So what does our method tell us.

225

00:14:01,550  -->  00:14:04,250
Let's go back to our method here.

226

00:14:04,250  -->  00:14:08,140
Our method would say that we've only got we get to this part.

227

00:14:08,180  -->  00:14:09,250
This is not true.

228

00:14:09,320  -->  00:14:13,130
As you remember that means we don't go to Step Four we go to Finne.

229

00:14:13,160  -->  00:14:14,150
Your model is.

230

00:14:14,720  -->  00:14:15,330
Good.

231

00:14:15,590  -->  00:14:21,740
So theoretically according to this approach this is our model Don it only actually has one variable

232

00:14:21,750  -->  00:14:21,780
.

233

00:14:21,800  -->  00:14:24,980
We went from four variables down to one.

234

00:14:25,790  -->  00:14:27,710
And it's very very significant.

235

00:14:27,710  -->  00:14:34,010
So what I wanted to show you here is let's do the same thing we did with the previous ones and let's

236

00:14:34,010  -->  00:14:38,390
look at the chart and see what what actually went on here is is marking spend.

237

00:14:38,390  -->  00:14:42,530
Really that's not much of a predictor.

238

00:14:42,530  -->  00:14:44,810
Let's go to Graf's fitted versus actual.

239

00:14:44,810  -->  00:14:50,870
And we'll go against marketing spend and what you can see here is even though they're kind of scatted

240

00:14:50,870  -->  00:14:51,600
right.

241

00:14:51,650  -->  00:14:58,610
The observations will look at the red ones and there are some outliers but in reality.

242

00:14:58,610  -->  00:15:02,240
Personally I think I could draw a line for this I could go like like that.

243

00:15:02,450  -->  00:15:11,030
Yeah it does look like there is a good level of corruption here and that is what we saw here that marketing

244

00:15:11,030  -->  00:15:12,010
spend.

245

00:15:12,180  -->  00:15:19,340
It's the one star basically that it's not a huge P-value like we had with administration of New York

246

00:15:19,340  -->  00:15:25,210
it's quite a small p value but still it's not sufficient enough for our significant level.

247

00:15:25,550  -->  00:15:33,020
And this is the problem with these step wise regression building methods that they're very arbitrary

248

00:15:33,020  -->  00:15:33,150
.

249

00:15:33,170  -->  00:15:40,880
We once we said our significant level is 0.05 we stick to that and we just follow this cold blooded

250

00:15:40,880  -->  00:15:46,730
rule that if it's greater than 0.05 we have excluded from our model and there's nothing you can do about

251

00:15:46,730  -->  00:15:46,820
it.

252

00:15:46,820  -->  00:15:49,030
So that's that's the rule and that's how it works.

253

00:15:49,370  -->  00:15:54,260
But in reality when you look at something like this you think maybe there is a chance that just maybe

254

00:15:54,260  -->  00:15:58,400
I should have kept it in maybe my model work would have worked better with it.

255

00:15:58,610  -->  00:15:59,740
And how do you tell.

256

00:15:59,900  -->  00:16:05,290
And this is where I'll show you the handy trick that will help you make the models more robust.

257

00:16:05,470  -->  00:16:07,280
And we'll talk about it in the next tutorial
