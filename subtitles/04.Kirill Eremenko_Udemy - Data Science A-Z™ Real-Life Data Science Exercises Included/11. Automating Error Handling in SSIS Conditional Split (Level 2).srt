1

00:00:00,540  -->  00:00:06,030
Pay and welcome back to a course in the previous tutorial we learned how to use a conditional split

2

00:00:06,030  -->  00:00:08,040
to filter out bad records.

3

00:00:08,160  -->  00:00:09,840
And today we're going to take it a step further.

4

00:00:09,850  -->  00:00:17,010
We're going to use two conditionals splits in one Sosias project and to start off with what I wanted

5

00:00:17,010  -->  00:00:23,580
to show you is that you don't have to first upload your daughter to school to then understand what you

6

00:00:23,580  -->  00:00:26,810
need to filter out and then go back to sucess and redo that.

7

00:00:26,880  -->  00:00:29,100
Not at all you can do that right away.

8

00:00:29,160  -->  00:00:35,130
If you know what you're after you can right away create the correct says package and to demonstrate

9

00:00:35,130  -->  00:00:41,260
that we will first truncate our table in escarole so I'm going to open up a skill.

10

00:00:41,520  -->  00:00:46,950
And because we're going to be uploading the data I'm going to truncate this table so fake names.

11

00:00:47,180  -->  00:00:50,200
They're all tableful fake names so we're going to create a new query.

12

00:00:50,310  -->  00:00:54,510
And I'm just going to write up the truncate script right away.

13

00:00:54,510  -->  00:00:55,450
There it is.

14

00:00:55,620  -->  00:00:58,490
You already know how to do this by now.

15

00:00:58,680  -->  00:01:00,970
And now I'm going to execute that.

16

00:01:01,140  -->  00:01:07,880
And so if I look at the table now it's empty so it's prepared for the upload but it is empty.

17

00:01:07,980  -->  00:01:10,590
So we can get rid of us for now.

18

00:01:10,890  -->  00:01:17,520
And back in s.c.s we want to add another conditional split and let's say for instance that you already

19

00:01:17,520  -->  00:01:23,100
know what you're going to be doing if there's not a you know that you are required to analyze this data

20

00:01:23,100  -->  00:01:23,800
set.

21

00:01:23,930  -->  00:01:33,840
And for instance visualize or analyze how different zip codes are spending money so you need to understand

22

00:01:33,840  -->  00:01:38,820
how the money spent is distributed across zip codes and therefore you definitely know that you will

23

00:01:38,820  -->  00:01:41,340
need these two fields and your daughter.

24

00:01:41,340  -->  00:01:44,080
You will need the amount spent and you need the zipcode.

25

00:01:44,340  -->  00:01:50,490
And if a record does not have either of those two then you can do nothing with that record it cannot

26

00:01:50,490  -->  00:01:55,860
participate in your analysis and therefore you need a conditional split to filter out those records

27

00:01:55,870  -->  00:01:56,100
.

28

00:01:56,310  -->  00:01:59,350
So let's create that conditional split.

29

00:01:59,360  -->  00:02:05,340
Now I'm going to go into other transforms and I'm going to look for my conditional split.

30

00:02:05,340  -->  00:02:05,840
There it is.

31

00:02:05,850  -->  00:02:08,840
And I'm just going to drag it over here onto the chart.

32

00:02:09,300  -->  00:02:15,420
And now we want to delete this arrow because we want our daughter to first go into the new conditional

33

00:02:15,420  -->  00:02:22,880
split and then we wanted to go into the old conditional split if it does meet our requirement for those

34

00:02:23,050  -->  00:02:23,900
fields.

35

00:02:23,910  -->  00:02:30,210
So now I'm going to out of Florida this nation this is where we're going to keep all the records that

36

00:02:30,540  -->  00:02:33,370
don't have sufficient data.

37

00:02:33,420  -->  00:02:37,770
Now we're going to set up our conditional split here.

38

00:02:37,800  -->  00:02:47,160
We want obviously in an output name and we're going to call it insufficient data and the condition is

39

00:02:47,160  -->  00:02:49,640
going to be we're going to analyze the columns.

40

00:02:49,680  -->  00:02:55,860
So we need a string function the len function which we used previously and here we're going to look

41

00:02:55,920  -->  00:02:57,520
at this time.

42

00:02:57,570  -->  00:03:05,940
First of all amount spent or amount paid and it has to be if it's insufficient data that means that

43

00:03:06,300  -->  00:03:11,820
this amount is or the length of this column is equal to zero.

44

00:03:11,820  -->  00:03:25,530
So we need our operators are equal operator and equal to zero or so the logical or the zip code where

45

00:03:25,520  -->  00:03:33,690
is it because so we also need lenth land of zip code is 0 as well

46

00:03:36,660  -->  00:03:38,970
or not as well or is zero.

47

00:03:38,970  -->  00:03:43,080
So one of the two is either this one or that one.

48

00:03:43,080  -->  00:03:45,300
If that is the case then there is insufficient data.

49

00:03:45,300  -->  00:03:51,570
This record does not have sufficient data to participate in the analysis and otherwise we're going to

50

00:03:51,570  -->  00:03:56,850
call it check pass so we can really call them good records yet because they still have to pass another

51

00:03:56,850  -->  00:03:57,420
check.

52

00:03:57,690  -->  00:03:59,610
And now we're going to click OK.

53

00:03:59,910  -->  00:04:06,190
So first of all we're going to really matter in which order to do this check pass to go there.

54

00:04:06,420  -->  00:04:13,170
And the other ones insufficient data they go there so make it a bit better like that.

55

00:04:13,170  -->  00:04:14,450
That looks good.

56

00:04:14,460  -->  00:04:16,950
So now the question here is

57

00:04:19,860  -->  00:04:24,420
the question is which in which order do you put this place.

58

00:04:24,420  -->  00:04:30,240
Well it's up to it's up to your specific project do you want to filter out the bad records first and

59

00:04:30,240  -->  00:04:36,360
put them into a separate file and then look for a sufficient or insufficient data or do you want to

60

00:04:36,360  -->  00:04:37,380
check for insufficient data.

61

00:04:37,380  -->  00:04:40,670
First it depends on how you're going to be processing these errors.

62

00:04:40,770  -->  00:04:43,200
Is somebody else going to be populating them for you.

63

00:04:43,230  -->  00:04:48,000
You have to send different departments are going to be fixing up manually because for instance in this

64

00:04:48,000  -->  00:04:53,460
case if there was insufficient data then I can do anything with this record even if I'm able to fix

65

00:04:53,460  -->  00:05:00,090
up some anomalies or get rid of the corruption in those records then I will still not have that correct

66

00:05:00,090  -->  00:05:03,120
data to perform my analysis.

67

00:05:03,630  -->  00:05:10,350
On the other hand the bad records here I might be able to fix up the data since the conditional split

68

00:05:10,350  -->  00:05:16,650
is telling me that the fields are in place so the amount spent or amount paid and the zip code are in

69

00:05:16,650  -->  00:05:22,170
place I might be able to fix up the data quickly and then include in my analysis but if these ones most

70

00:05:22,170  -->  00:05:24,430
likely I won't be able to do anything.

71

00:05:24,420  -->  00:05:27,990
There's still a chance that the door is in there it's just been shifted around.

72

00:05:28,000  -->  00:05:34,890
But you can have a look at that once the file is ready but there is a possibility is higher that probably

73

00:05:34,890  -->  00:05:36,160
the data is just not there.

74

00:05:36,360  -->  00:05:43,590
So that's that's how we split our data we reach on the table so the only thing left that we have to

75

00:05:43,590  -->  00:05:48,400
do is set up this flat file destination we're going to double click new manager.

76

00:05:48,420  -->  00:05:55,560
As usual it's going to be a delimited file here for the manager by the way we haven't been specifying

77

00:05:55,560  -->  00:06:03,030
names doesn't really matter but if you want a bit more order in your connection managers then go feel

78

00:06:03,030  -->  00:06:08,670
free to specify name here we're going to go to our correct folder.

79

00:06:08,670  -->  00:06:13,070
So in this case it's analysis data errors.

80

00:06:13,110  -->  00:06:18,080
This is automatically exclude results and we're going to paste that in here.

81

00:06:18,450  -->  00:06:21,930
And we're going to create a new field our new text document.

82

00:06:21,930  -->  00:06:23,490
And this one we're going to call

83

00:06:26,900  -->  00:06:28,500
We're going to call it fake names.

84

00:06:28,530  -->  00:06:29,430
Insufficient data.

85

00:06:29,430  -->  00:06:33,750
So it's different we don't want to put in the same obviously file so they don't get mixed up we want

86

00:06:33,750  -->  00:06:44,540
to put in this file click open and we want the text qualifier column names checked columns.

87

00:06:44,630  -->  00:06:45,960
They're advanced.

88

00:06:45,970  -->  00:06:49,460
Everything's good feedback has 5000 preview.

89

00:06:49,490  -->  00:06:50,350
OK.

90

00:06:50,390  -->  00:06:52,850
Good mappings good.

91

00:06:52,860  -->  00:06:55,530
So before I launch this I wanted to show you something.

92

00:06:55,620  -->  00:07:00,780
If you go into your automatically exclude results folder remember that we already have data in this

93

00:07:00,840  -->  00:07:01,680
file.

94

00:07:01,830  -->  00:07:07,770
Well you don't have to worry about truncating these files because by default when this package is run

95

00:07:08,010  -->  00:07:10,530
flat file disconnections will be truncated.

96

00:07:10,530  -->  00:07:14,700
On the other hand this is different to what happens to the database tables.

97

00:07:14,700  -->  00:07:17,530
They don't get truncated so you have to do that manually.

98

00:07:17,820  -->  00:07:23,680
So there we go everything set up so let's go ahead and run this.

99

00:07:24,030  -->  00:07:29,610
You can zoom zoom in a little bit so you can see that quite a lot of records went into the insufficient

100

00:07:29,640  -->  00:07:35,150
data file and only four records now went into the bad records file.

101

00:07:35,280  -->  00:07:39,720
So let's go and have a look at these files over here.

102

00:07:40,620  -->  00:07:43,430
I'm going to open this up with Notepad.

103

00:07:43,500  -->  00:07:48,280
Plus plus as you can see there is exactly four records as we specified.

104

00:07:48,300  -->  00:07:57,660
And these are the ones where you do have the information on the money spent and the zip code somewhere

105

00:07:57,870  -->  00:07:58,660
here I think.

106

00:07:58,680  -->  00:08:01,000
That's zip code.

107

00:08:01,110  -->  00:08:05,250
But at the same time something's wrong with the file in general.

108

00:08:05,250  -->  00:08:09,480
And then the other one fake names insufficient data.

109

00:08:09,480  -->  00:08:16,950
Here you can see that there is no data on for most of them there's no data on the amount spent.

110

00:08:17,100  -->  00:08:24,500
And at the same time some of them also don't have the zip code specified for these records.

111

00:08:24,580  -->  00:08:29,100
So like here for example got them on spend but you don't have the zip codes so you can't do anything

112

00:08:29,100  -->  00:08:29,510
of it.

113

00:08:29,520  -->  00:08:35,200
So this file you would send it back to the person that gave it to you and you would ask them to put

114

00:08:35,200  -->  00:08:39,020
it in the correct dot that you require for your analysis.

115

00:08:39,030  -->  00:08:42,770
So that's how you use to conditional splits together.

116

00:08:42,960  -->  00:08:46,310
Very powerful you can use as many as you want just keep adding them on.

117

00:08:46,500  -->  00:08:53,160
And as we saw you don't have to first upload your daughter to a Kill if you know already what you're

118

00:08:53,160  -->  00:08:54,060
after.

119

00:08:54,060  -->  00:08:57,870
Then you can set all of this up and then upload the data to us.

120

00:08:57,880  -->  00:09:02,070
Also you have a nice clean table in your database ready for you to start working with
