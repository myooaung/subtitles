1
00:00:01,020 --> 00:00:02,490
[Autogenerated] All right, let's dive in tow.

2
00:00:02,490 --> 00:00:07,510
Auto Skilling groups Now this slide is going to pertain to the priest

3
00:00:07,510 --> 00:00:11,390
scaling that happens in an auto Skilling group.

4
00:00:11,390 --> 00:00:14,540
You can see we have a simple two tiered architecture er

5
00:00:14,540 --> 00:00:17,980
spanned across to availability zones.

6
00:00:17,980 --> 00:00:21,340
And in the middle here we have on Auto Skilling Group.

7
00:00:21,340 --> 00:00:27,150
Now what this auto scaling group allows us to do is automate Skilling out and

8
00:00:27,150 --> 00:00:32,980
back in on demand when certain metric thresholds are crossed.

9
00:00:32,980 --> 00:00:34,240
So in this instance,

10
00:00:34,240 --> 00:00:38,520
we have a group of users making a request to our load balancer.

11
00:00:38,520 --> 00:00:43,740
That's fording those requests to our auto scaling group Instances.

12
00:00:43,740 --> 00:00:48,630
But let's say we start getting more traffic so that user base

13
00:00:48,630 --> 00:00:53,180
doubles now and so does our internal traffic.

14
00:00:53,180 --> 00:00:57,700
Going to our instances while using auto Skilling groups

15
00:00:57,700 --> 00:01:03,620
within a W S allows us to automatically scale are groups of

16
00:01:03,620 --> 00:01:07,810
instances specific to this workload.

17
00:01:07,810 --> 00:01:12,240
And the beauty of this is that we can scale both out like I mentioned

18
00:01:12,240 --> 00:01:16,040
and back in once thresholds are back to normal.

19
00:01:16,040 --> 00:01:21,710
So it really builds on the paper use model that a W s loves the push you

20
00:01:21,710 --> 00:01:26,270
only pay for compute that you use And with that auto,

21
00:01:26,270 --> 00:01:29,850
Skilling itself, as a service is free to use.

22
00:01:29,850 --> 00:01:34,880
You only pay for the compute that you're scaling out and in.

23
00:01:34,880 --> 00:01:39,180
So now that we have a general understanding of how it works,

24
00:01:39,180 --> 00:01:42,340
let's dive in a little bit deeper.

25
00:01:42,340 --> 00:01:47,520
Now, in the upcoming demos, we're going to walk through a few different tasks.

26
00:01:47,520 --> 00:01:51,990
We're going to explore launch configurations and launch templates in the

27
00:01:51,990 --> 00:01:56,070
differences between them and then using our launch template,

28
00:01:56,070 --> 00:02:00,080
we're going to demo automating via user data.

29
00:02:00,080 --> 00:02:03,850
So will automate some actions via Cem user data to show

30
00:02:03,850 --> 00:02:07,340
how easy it is to repeat deployments.

31
00:02:07,340 --> 00:02:11,160
The next thing we'll do is we're going to deploy an auto scaling

32
00:02:11,160 --> 00:02:15,140
group based on the launch template that we created.

33
00:02:15,140 --> 00:02:15,910
And when we do,

34
00:02:15,910 --> 00:02:20,520
this will specify some metrics that air measured that

35
00:02:20,520 --> 00:02:25,010
determine the scaling behavior of our group.

36
00:02:25,010 --> 00:02:26,170
And then, lastly,

37
00:02:26,170 --> 00:02:31,800
we're going to attach an auto scaling group to a load balancer within our V p.

38
00:02:31,800 --> 00:02:32,910
C.

39
00:02:32,910 --> 00:02:34,240
And by doing this,

40
00:02:34,240 --> 00:02:39,150
we're going to explore how routing between public and private sub nets

41
00:02:39,150 --> 00:02:44,040
work for this multiple availability zone architecture.

42
00:02:44,040 --> 00:02:45,060
So with that,

43
00:02:45,060 --> 00:02:56,000
let's go ahead in here and we'll pick back up in the next clip within the AWS consul and start exploring auto scaling groups

