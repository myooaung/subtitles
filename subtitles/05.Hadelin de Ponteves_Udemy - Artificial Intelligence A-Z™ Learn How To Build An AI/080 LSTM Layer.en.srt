1
00:00:00,720 --> 00:00:03,450
Hello and welcome back to the course on artificial intelligence.

2
00:00:03,490 --> 00:00:07,570
In today's tutorial we're going to talk about an add on that we're going to be implementing for our

3
00:00:07,580 --> 00:00:08,860
8:3 algorithm.

4
00:00:08,860 --> 00:00:12,970
It's called The Long short term memory or the LSD for short.

5
00:00:12,970 --> 00:00:20,080
So let's have a look at what we have so far and then we'll discuss why we need the LSD and what what

6
00:00:20,080 --> 00:00:24,440
else to him is so so far we've discussed through shall we.

7
00:00:24,440 --> 00:00:29,950
And we've talked about all three letter A's in the 3C and of course we've seen that it's actually a

8
00:00:29,950 --> 00:00:34,990
bit more complete or much more complex than what we have on this image we actually have three or more

9
00:00:35,110 --> 00:00:39,640
multiple agents going through the environment and they're communicating between each other and so on.

10
00:00:39,640 --> 00:00:44,890
But for simplicity's sake for today's story we're going to just illustrate everything with this one

11
00:00:45,190 --> 00:00:47,580
agent at the end we have this report the critic part.

12
00:00:47,590 --> 00:00:53,030
So basically once we have a state let's state to this image as it goes through convolutional there then

13
00:00:53,050 --> 00:00:55,360
goes through a pulling Lego shuffling of flattening a layer.

14
00:00:55,360 --> 00:01:02,500
And at this point we have values or numbers which are then propagated through the network and they go

15
00:01:02,500 --> 00:01:08,620
into the hidden layers and then as the output we get the policy or the actor parts and they get the

16
00:01:08,830 --> 00:01:15,670
value of the state or we get the critic part and what's we're going to do today is we're going to talk

17
00:01:15,670 --> 00:01:21,010
about this hidden part in the hidden layers we can actually take it to the next level and we can add

18
00:01:21,010 --> 00:01:21,700
a notification.

19
00:01:21,730 --> 00:01:26,440
And we've already seen that multiple notifications exist for they shall move seen one of them we've

20
00:01:26,440 --> 00:01:32,900
seen that in some cases you can have this main part of the network which is individual to every agent.

21
00:01:32,920 --> 00:01:39,220
Or you can have this main part of the network which is shared and that's what we saw that in our previous

22
00:01:39,220 --> 00:01:42,150
intuition trials we had a shared part of the network.

23
00:01:42,190 --> 00:01:47,560
This network was shared between the agents and as Adlon will tell you more in the practical tutorials

24
00:01:47,830 --> 00:01:50,660
that really helps with the challenge of breakup.

25
00:01:50,830 --> 00:01:55,560
And there are lots lots of lots of other ways you can modify the algorithm.

26
00:01:55,720 --> 00:01:59,720
Lots of other additions that can be implemented.

27
00:01:59,920 --> 00:02:03,400
And one of them we're going to discuss because we're actually going to have in the practical side of

28
00:02:03,700 --> 00:02:10,300
the trolls here before you hit and Lares which you can add is an elist Himmler a neural network Klare

29
00:02:10,480 --> 00:02:18,610
which allows your valuation algorithm to have memory which allows the algorithm to remember what happened

30
00:02:18,610 --> 00:02:21,050
before and we'll talk about LACMA just now in more detail.

31
00:02:21,130 --> 00:02:26,080
But basically you can add an extra layer here which is elist him Lehre and enhance your algorithm with

32
00:02:26,080 --> 00:02:30,190
some additional Nimer of another feature and which you will actually see in the practical Sorrells is

33
00:02:30,190 --> 00:02:36,250
that we didn't even need any hidden layers after they all similar So you'll see that in Atlanta implementation.

34
00:02:36,250 --> 00:02:38,860
He's got the flattening there right away.

35
00:02:38,860 --> 00:02:43,530
After that he's got the stemware So basically this box represents the elist gambler.

36
00:02:43,630 --> 00:02:48,730
And then after that right away you've got the output so you don't even need any any other hidden Lares

37
00:02:48,730 --> 00:02:53,320
after that simply because that's how much power the LSM lair adds to the algorithm.

38
00:02:53,350 --> 00:02:59,200
And again the algorithm or the architecture of your your own network it's a very visual thing it's a

39
00:02:59,200 --> 00:03:00,260
personal preference.

40
00:03:00,270 --> 00:03:05,010
It's a very creative thing so you might want to have to elist gamblers you might have well-learned analyst

41
00:03:05,020 --> 00:03:05,700
Jim Lehrer.

42
00:03:05,710 --> 00:03:09,130
That is several like five hidden layers after they list them.

43
00:03:09,160 --> 00:03:11,750
That's totally up to you and for you to experiment and explore.

44
00:03:11,920 --> 00:03:18,430
But this is what we came up with in the practical tutorials so you'll see that we have a flattening

45
00:03:18,580 --> 00:03:24,410
flat layer and after that we've got an ls dam lair and then the output.

46
00:03:24,420 --> 00:03:28,680
So now we've talked about the other similar so much what is this a handler.

47
00:03:28,840 --> 00:03:34,750
Well the LACMA lair adds memory gives a feature like allows the neural network to have memory about

48
00:03:34,750 --> 00:03:42,580
what happened in the previous iterations and it is often symbolized or shown with a symbol which looks

49
00:03:42,580 --> 00:03:43,280
like this.

50
00:03:43,300 --> 00:03:46,110
This is just getting started into it and I'm just putting here.

51
00:03:46,120 --> 00:03:51,820
I know it looks very crooked but I'm putting it here so you can see when we further discuss this image.

52
00:03:51,820 --> 00:03:58,470
You can see what's going on so this the output of this letter goes in to here and that is our.

53
00:03:58,660 --> 00:04:04,480
So this is a whole layer going in here so it's a vector of values x is a vector avows goes into the

54
00:04:04,570 --> 00:04:06,080
stem which we'll just discard the cell.

55
00:04:06,250 --> 00:04:10,540
And then as an output you get another vector which is you know the concatenation of these store or some

56
00:04:10,540 --> 00:04:15,030
Somehow it ties in our case as an output you get this and you get this.

57
00:04:15,040 --> 00:04:17,350
So let's have a look at this in more detail.

58
00:04:17,350 --> 00:04:19,090
So it's going to focus on this part.

59
00:04:19,120 --> 00:04:23,320
In fact we get into as you probably noticed by the letters being on the side we're going to turn it

60
00:04:23,650 --> 00:04:24,430
to the side.

61
00:04:24,430 --> 00:04:31,120
So like that and the whole this whole like jumble around was just to reiterate the fact that even though

62
00:04:31,120 --> 00:04:36,910
it looks like this what is actually happening is a layer of values a whole vector of values is going

63
00:04:36,910 --> 00:04:37,530
in here.

64
00:04:37,630 --> 00:04:41,440
Something is happening which will just cause just now and then a whole vector valises is going on.

65
00:04:41,440 --> 00:04:47,310
So this is the layer it's not just one element of the this is the layer itself.

66
00:04:47,350 --> 00:04:55,590
So let's go back again just to reiterate Lehre goes into this where something happens Lehre comes out.

67
00:04:55,810 --> 00:04:58,680
So that's that's the LACMA is just on its side.

68
00:04:58,690 --> 00:05:02,370
So it's just easier to just this way and that's a common representation.

69
00:05:02,500 --> 00:05:07,870
Right now there we agree why this image was on its side and how are we going to proceed with this.

70
00:05:07,960 --> 00:05:11,710
Let's start digging into this LACMA situation a bit more.

71
00:05:11,710 --> 00:05:14,070
So what happens inside Ellis Jim Lehrer.

72
00:05:14,080 --> 00:05:15,400
So this is what it looks like.

73
00:05:15,610 --> 00:05:20,830
And of course this is looks very complex and we're definitely not going to go through all of this right

74
00:05:20,860 --> 00:05:24,000
now simply because there's quite a lot to discuss.

75
00:05:24,010 --> 00:05:32,080
The point was Operation Xolair wise operations and just there's just a lot going on or a lot of intricate

76
00:05:32,110 --> 00:05:37,720
details which we're not going to go into because otherwise would blow out this of course and this is

77
00:05:37,720 --> 00:05:42,410
not the purpose is not to talk about Else dams here which are going to utilize the LACMA.

78
00:05:42,430 --> 00:05:48,520
And if you'd like to learn more about Ellis systems you can either go to or we're here.

79
00:05:48,520 --> 00:05:50,130
Christopher Ola's blog.

80
00:05:50,500 --> 00:05:56,750
He's got a good description of his stems or we also talk about LACMA in our deep learning age is of

81
00:05:56,770 --> 00:05:58,060
course you can check it out.

82
00:05:58,060 --> 00:06:01,420
We've got a whole section on recurrent neural networks and systems as well.

83
00:06:01,540 --> 00:06:06,470
So basically this is the internal part of the system.

84
00:06:06,520 --> 00:06:12,160
And what happens is like the leg goes in so we're going to talk about this on on an intuitive level

85
00:06:12,160 --> 00:06:17,650
on a very basic level just just what was going to be enough for us to understand what happens or why

86
00:06:17,650 --> 00:06:18,400
there's memory.

87
00:06:18,400 --> 00:06:23,530
And so that you can also better understand what Atlanta is talking about when he's implementing this.

88
00:06:23,560 --> 00:06:29,440
So Largo's in all of this is something something basically goes on here Larry goes up.

89
00:06:29,710 --> 00:06:35,710
What do we need to actually see is that there are these out these parts there's actually additional

90
00:06:35,800 --> 00:06:37,480
inputs into this Lehre.

91
00:06:37,480 --> 00:06:42,970
So remember this usually you have like an input from a previous Lehre then this letter and then you

92
00:06:42,970 --> 00:06:49,290
have an output if you think of that image we had previously the normal network which is not not on its

93
00:06:49,290 --> 00:06:52,660
side which is like from left to right from top to bottom to top.

94
00:06:52,810 --> 00:06:55,350
But unless you actually have more inputs.

95
00:06:55,360 --> 00:06:59,410
So I know it's getting even more complex but these things at least we can understand them.

96
00:06:59,410 --> 00:07:03,380
So this is your memory cell.

97
00:07:03,400 --> 00:07:06,760
This is the key and this is what you'll hear Heidel Atlanta talk about.

98
00:07:06,880 --> 00:07:15,220
So the memory cell is something that is saved in the elist him so these inputs and outputs are actually

99
00:07:15,490 --> 00:07:18,280
here what you're looking at is the time axis.

100
00:07:18,280 --> 00:07:26,260
So this is unraveled in time so in one specific iteration this happens but then this value is taken

101
00:07:26,260 --> 00:07:30,910
from the possed and this values passed into these values these values are taken from the past and these

102
00:07:30,910 --> 00:07:35,660
values are passed onto the future and how they pass wealth through the way the else teamwork so we're

103
00:07:35,680 --> 00:07:38,480
followed worrying about too much what's going on here.

104
00:07:38,590 --> 00:07:44,950
All we need to understand is that when the letter goes in and here we really have a value which came

105
00:07:44,950 --> 00:07:51,740
from the past which is stored inside the LSD inside the long short term memory.

106
00:07:52,060 --> 00:07:59,950
We've got this memory cell and whatever value was here before it is just it just stays here as you can

107
00:07:59,950 --> 00:08:04,960
see it just goes through it flows through freely except for these pointwise operations where it can

108
00:08:04,960 --> 00:08:07,210
be either closed off or something can be added to it.

109
00:08:07,330 --> 00:08:13,360
But regardless of that it's just some value that flows through freely so it's basically it's passed

110
00:08:13,360 --> 00:08:14,900
onto the next point in time next point.

111
00:08:14,920 --> 00:08:20,350
So you could just think of it as a like some memory that like a flash drive or something like that that

112
00:08:20,350 --> 00:08:25,750
this cell has and so just remembers the previous value that was in here and then it can use that to

113
00:08:25,750 --> 00:08:30,350
do to either add to it or read from that valiance on.

114
00:08:30,370 --> 00:08:33,670
And this value is the hidden state.

115
00:08:34,000 --> 00:08:37,670
So hence the H and the hidden state is basically.

116
00:08:37,740 --> 00:08:42,000
And now the value that comes from the past and then is used inside the system.

117
00:08:42,010 --> 00:08:48,180
And as you can see at the end after all this happens what you get is you get a letter that comes out

118
00:08:48,220 --> 00:08:53,170
and it is so that you get this value that comes out and it is the same value that's passed forward.

119
00:08:53,170 --> 00:08:59,440
So basically the Ellis team remembers two things there's a constant value that is just like stays in

120
00:08:59,440 --> 00:09:04,720
the list and that can be changed like this is a flash drive for like a constant value.

121
00:09:04,720 --> 00:09:05,990
So the memory cell.

122
00:09:06,040 --> 00:09:11,940
And so you can you can you have the luxury of storing something in that space and that memory and it

123
00:09:11,930 --> 00:09:15,290
will be passed onto the future so whenever in the next iteration.

124
00:09:15,320 --> 00:09:20,620
So like the algorithm was in an environment it saw something did something and so on.

125
00:09:20,650 --> 00:09:25,690
And then in the LACMA you can store a certain value then it will remember this value even when it's

126
00:09:25,690 --> 00:09:26,960
in the next state.

127
00:09:27,400 --> 00:09:31,420
And also the other value they'll remember ill remember its previous output.

128
00:09:31,420 --> 00:09:35,370
It automatically will remember its previous output so the output goes here and goes here.

129
00:09:35,560 --> 00:09:42,160
So that's basically the very very very high level of what happens in an LSM.

130
00:09:42,160 --> 00:09:47,530
Once again if you'd like more details as lots of resources where you can find and at this stage we just

131
00:09:47,530 --> 00:09:51,100
don't need to go into that much detail on all of these things.

132
00:09:51,100 --> 00:09:56,440
We just need to understand you know what a memory cell is what adherence to the memory cell is what

133
00:09:56,440 --> 00:10:02,270
a head of state is and how like how the facilitates memory for him.

134
00:10:02,330 --> 00:10:09,920
And the question is so now that we kind of have a general overview of all of this to reinforce or to

135
00:10:10,250 --> 00:10:16,220
solidify this knowledge you're kind of like give a reason for this knowledge.

136
00:10:16,220 --> 00:10:19,160
Let's ask the question why do we need memory.

137
00:10:19,190 --> 00:10:23,180
Why do we need memory in our A-3 or other algorithms.

138
00:10:23,180 --> 00:10:26,990
Well let's look at our example the challenge that we're taking on in this section.

139
00:10:26,990 --> 00:10:32,420
So the challenge is breakout and what happens and break will and break out you've got this environment

140
00:10:32,420 --> 00:10:37,340
these little blocks that you need to destroy with this little ball and you need to make sure that this

141
00:10:37,340 --> 00:10:41,120
is your kind of like racket or platform that's moving around.

142
00:10:41,150 --> 00:10:46,610
And it must wherever the ball is flying it must catch the ball and bounce off the platform and go back

143
00:10:46,610 --> 00:10:48,160
and hit balls of the walls as well.

144
00:10:48,160 --> 00:10:50,060
Go back a block and come back.

145
00:10:50,060 --> 00:10:54,270
And so that's the essence of what you need to accomplish.

146
00:10:54,290 --> 00:11:02,330
But now let's look at this ball like imagine you're a and and 83 C algorithm dure or an agent inside

147
00:11:02,330 --> 00:11:04,040
one of those agents inside 08:30.

148
00:11:04,160 --> 00:11:07,550
You see this picture what do you extract from here.

149
00:11:07,670 --> 00:11:09,580
What would your action be here for you.

150
00:11:09,740 --> 00:11:11,790
So you can see the balls flying right.

151
00:11:11,840 --> 00:11:13,640
So well it is flying right.

152
00:11:13,640 --> 00:11:16,610
So it's going somewhere and maybe it's flying towards the right you can.

153
00:11:16,610 --> 00:11:20,230
Could you make this conclusion could you like anticipate that it's coming towards you.

154
00:11:20,240 --> 00:11:23,720
You probably could and maybe you're in the right spot to catch the ball.

155
00:11:23,930 --> 00:11:28,890
But what if the ball is actually not flying that way but is flying that what if it's flying that way.

156
00:11:28,910 --> 00:11:34,250
The thing is you cannot tell from this one image which way it's flying because you don't know where

157
00:11:34,250 --> 00:11:36,370
it was in the previous moment of time.

158
00:11:36,560 --> 00:11:39,220
So if it was here then it's flying this way.

159
00:11:39,230 --> 00:11:43,850
So if you had if you knew the previous moment time if you knew that it was here you'd be there now you

160
00:11:43,850 --> 00:11:48,650
know here is as a human you just draw a line for these two and you will says going this way.

161
00:11:48,920 --> 00:11:52,360
But if you knew it here you draw lines just as going this way.

162
00:11:52,490 --> 00:11:54,320
Moreover look at this.

163
00:11:54,320 --> 00:11:57,130
It could have actually been somewhere like over here.

164
00:11:57,140 --> 00:12:01,280
Maybe it's going up maybe it's actually going that way so maybe it was here and I was going up with

165
00:12:01,460 --> 00:12:05,960
so just from that one image is very hard is actually impossible.

166
00:12:05,960 --> 00:12:10,540
It's just like geometrically impossible to tell which way the ball is flying.

167
00:12:10,550 --> 00:12:18,830
And so that's why the LSD the memory actually really really helps our Mfat the memory it can still you

168
00:12:18,830 --> 00:12:24,230
can still do a good job but could probably guess or you know find other ways of understanding where

169
00:12:24,230 --> 00:12:24,610
to go.

170
00:12:24,620 --> 00:12:31,520
But with the stem move just even that one memory so if we go back even with that one value that that

171
00:12:31,520 --> 00:12:37,460
was kind of like the output of the previous value or maybe you know maybe the you can store it here

172
00:12:37,460 --> 00:12:43,250
or based on this value or based on the information it gets from the previous point in time.

173
00:12:43,250 --> 00:12:45,920
So let's say from what happened here.

174
00:12:45,920 --> 00:12:51,650
So that's where your ball was before so you can pass on information about the environment from the previous

175
00:12:51,650 --> 00:12:53,200
point in time through here.

176
00:12:53,270 --> 00:12:57,900
Then now you have it now you know not only have your information from the image.

177
00:12:58,040 --> 00:13:02,850
If we go back even further you'll remember that information from the image.

178
00:13:02,870 --> 00:13:06,050
Well this is doomed but we're actually working to break out information.

179
00:13:06,050 --> 00:13:10,020
The image came here here here turned into these flattened values.

180
00:13:10,160 --> 00:13:11,500
And so that information for them.

181
00:13:11,510 --> 00:13:13,320
Image coming into the whole system.

182
00:13:13,340 --> 00:13:20,150
And now all of a sudden as as you remember coming from from not from somewhere but from the previous

183
00:13:20,600 --> 00:13:21,290
point in time.

184
00:13:21,290 --> 00:13:24,630
So that's where you of actually demonstrate come from top or from the ball from left right.

185
00:13:24,650 --> 00:13:28,410
Actually it's just it's just stays in the elist him lair.

186
00:13:28,490 --> 00:13:31,170
You have that information just through the architecture.

187
00:13:31,180 --> 00:13:33,980
They'll say you have information about what happened previously.

188
00:13:34,160 --> 00:13:40,940
And so we go back that information here helps you now make a decision on what to do.

189
00:13:40,940 --> 00:13:42,930
Helps the algorithm make a decision.

190
00:13:43,010 --> 00:13:45,010
And now all of a sudden it knows that.

191
00:13:45,140 --> 00:13:45,500
OK.

192
00:13:45,500 --> 00:13:48,320
So the ball is actually lying in either.

193
00:13:48,350 --> 00:13:52,730
Let's say it's flying in this direction or in this direction so I'm in the right place I should stick

194
00:13:52,730 --> 00:13:57,050
around here the ball is coming in my direction or if it or if it realizes the ball is lying there it

195
00:13:57,050 --> 00:14:00,710
should start moving to the left because if it waits a bit longer it'll be too late.

196
00:14:00,740 --> 00:14:01,780
And they will miss the ball.

197
00:14:01,940 --> 00:14:08,630
So basically that's how the elist them where really helps in the algorithm and that's exactly what we

198
00:14:08,630 --> 00:14:12,360
will see when you're doing the practical tutorials of Atlanta.

199
00:14:12,500 --> 00:14:14,370
So there you go that's how these teams work.

200
00:14:14,480 --> 00:14:20,720
And just one additional note as we mentioned at the start Ellis teams are not 100 percent necessary.

201
00:14:20,720 --> 00:14:25,430
They're not a complete They're not completely attached they algorithm.

202
00:14:25,550 --> 00:14:29,420
You might want to have them in a through C algorithm you might not want to have them depending on the

203
00:14:29,420 --> 00:14:31,180
situation to bring in Arctic's you choose.

204
00:14:31,250 --> 00:14:37,340
There are lots of additions and we've already discussed the addition or the modification where the neural

205
00:14:37,340 --> 00:14:40,950
network is shared between actors are not shared between agents or not.

206
00:14:41,010 --> 00:14:46,610
Now nonetheless elist Jim there's another one that you will see in the practical tutorials where we

207
00:14:46,610 --> 00:14:51,280
add entropy which is calculated through a policy lösen Adlon will walk you through that.

208
00:14:51,290 --> 00:14:57,190
So basically there's lots of different modifications that can happen in an A-380 algorithm.

209
00:14:57,290 --> 00:15:03,180
Just remember that it depends on what you want to achieve and it's also something that would encourage

210
00:15:03,180 --> 00:15:09,060
you to explore if you're going to be implementing lots of these and trying different algorithms.

211
00:15:09,180 --> 00:15:14,880
We've already discussed a couple and maybe you can find some additional modifications that might be

212
00:15:14,880 --> 00:15:19,110
of interest to you or maybe when you're watching these tutorials maybe buy them more modifications have

213
00:15:19,110 --> 00:15:21,330
come out which are very interesting.

214
00:15:21,330 --> 00:15:27,330
So definitely that's something that you could look into and that could further enhance your knowledge

215
00:15:27,420 --> 00:15:30,740
of artificial intelligence and how to create these algorithms.

216
00:15:30,780 --> 00:15:34,200
And on that note I hope you enjoyed this tutorial and I'll look for you next time.

217
00:15:34,200 --> 00:15:35,380
Until then enjoy.

218
00:15:35,380 --> 00:15:35,590
I.
