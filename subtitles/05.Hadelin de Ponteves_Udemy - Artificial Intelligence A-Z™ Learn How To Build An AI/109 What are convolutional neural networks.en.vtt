WEBVTT
1
00:00:00.490 --> 00:00:02.980
Hello and welcome back to the course on deep learning.

2
00:00:02.980 --> 00:00:06.900
Today we're kicking off convolutional neural networks is going to be exciting.

3
00:00:06.910 --> 00:00:08.610
Let's dive straight into it.

4
00:00:08.620 --> 00:00:10.840
We're going to start off with an image.

5
00:00:10.930 --> 00:00:13.210
What do you see when you look at this image.

6
00:00:13.580 --> 00:00:19.480
Do you see a person looking at you or do you see a person looking to the right you can see that your

7
00:00:19.480 --> 00:00:25.860
brain is is struggling is struggling to adjust if you look to the right side of the image.

8
00:00:25.870 --> 00:00:29.180
Just look at the right border there which you'll see a person looking to the right.

9
00:00:29.260 --> 00:00:33.320
If you look at the left border of the image you'll see a person looking at you.

10
00:00:33.700 --> 00:00:42.760
And this just proves that what our brain is looking for when we see things is features depending on

11
00:00:42.760 --> 00:00:46.140
the features that it sees depending on the features that you process.

12
00:00:46.180 --> 00:00:48.610
You categorize things in certain ways.

13
00:00:48.730 --> 00:00:54.010
So when you look on the right side of the image you see certain features of a person looking to ride

14
00:00:54.010 --> 00:01:00.190
because they're closer to your center of focus and therefore your brain classifies as a person looking

15
00:01:00.190 --> 00:01:00.930
to the right.

16
00:01:01.000 --> 00:01:06.790
When you look to the left side of the image you see more features of a person looking at you and therefore

17
00:01:06.790 --> 00:01:09.580
your brain classifies it as such.

18
00:01:09.580 --> 00:01:11.150
So let's have a look at another one.

19
00:01:11.230 --> 00:01:12.840
This is a very famous image.

20
00:01:12.910 --> 00:01:14.530
You probably have already seen it.

21
00:01:14.680 --> 00:01:16.240
But what you see here.

22
00:01:16.820 --> 00:01:23.830
So some people will say that they see a young lady wearing a dress looking away.

23
00:01:23.830 --> 00:01:29.980
Some people say they see an old lady wearing a scarf on her head looking down.

24
00:01:30.280 --> 00:01:36.250
So I'm going to point this out and you'll see that will become very obvious so this is the face of the

25
00:01:36.250 --> 00:01:37.510
young lady looking away.

26
00:01:37.510 --> 00:01:40.450
She's looking into the distance as her coat.

27
00:01:40.440 --> 00:01:44.940
That's her hair that's her little feather in her hair and on the other hand.

28
00:01:44.980 --> 00:01:53.530
This is the head of the old lady looking down her nose her mouth her chin that's the scarf on her head

29
00:01:53.560 --> 00:01:55.560
and she's looking down.

30
00:01:55.780 --> 00:02:01.960
So as you can see two in one and depending on which features your brain picks up it will switch between

31
00:02:02.620 --> 00:02:06.710
classifying each image as one or the other.

32
00:02:06.910 --> 00:02:13.930
The oldest one of these illusions recorded in the printed work is this one.

33
00:02:13.930 --> 00:02:15.220
It's the duck or the rabbit.

34
00:02:15.230 --> 00:02:17.020
So is this a duck or is this a rabbit.

35
00:02:17.020 --> 00:02:18.330
Another example.

36
00:02:18.430 --> 00:02:25.030
And now I'm going to show an image which will just for a second just look at it and see what what what

37
00:02:25.030 --> 00:02:28.670
emotions or what kind of experience visual experience you go through.

38
00:02:29.110 --> 00:02:36.610
So what do you see does you feel like a bit not dizzy but a little bit dazzled like your brain is trying

39
00:02:36.610 --> 00:02:40.230
to try and understand what it is what it is like it's trying to.

40
00:02:40.330 --> 00:02:49.240
Is jumping between her eyes up and down eyes and this is a classic example of when there are certain

41
00:02:49.240 --> 00:02:53.850
features where it could be this it could be that but your brain cannot decide.

42
00:02:54.130 --> 00:02:58.230
And because both seem plausible.

43
00:02:58.290 --> 00:03:04.360
Yeah so basically all these examples illustrate to us how the brain works that it processes certain

44
00:03:04.360 --> 00:03:10.970
features on an image or on whatever you see in real life and it classifies that as.

45
00:03:10.980 --> 00:03:16.150
You probably have been in situations when you look over your shoulder quickly and you see something

46
00:03:16.150 --> 00:03:23.500
you think it's I don't know if it's like a a ball but it turns out to be a cat or you think it's a it's

47
00:03:23.500 --> 00:03:24.030
a car.

48
00:03:24.070 --> 00:03:28.030
Turns out to be a shadow or things like that that's because you don't have enough time to process those

49
00:03:28.030 --> 00:03:31.030
features or you don't have enough features to classify things as such.

50
00:03:31.240 --> 00:03:38.570
And this is for me this is very interesting because what we're going to be doing with neural networks

51
00:03:38.570 --> 00:03:43.630
with have convolutional neural networks is very similar and you'll find that the way that computers

52
00:03:43.630 --> 00:03:48.190
are going to be processing images is going to be extremely similar to the way we are processing images

53
00:03:48.210 --> 00:03:53.500
so it's is very valuable to understand and just kind of remember these things that this is how we do

54
00:03:53.500 --> 00:03:53.580
it.

55
00:03:53.590 --> 00:03:58.450
And I'm going to take this lady off your screens because she's probably already freaking out by now.

56
00:03:58.630 --> 00:04:00.940
So here's something different.

57
00:04:00.940 --> 00:04:07.870
Here's an experiment an experiment done on computers on convolutional neural network so we're slowly

58
00:04:07.870 --> 00:04:11.150
moving now from humans to computers.

59
00:04:11.350 --> 00:04:18.490
And this slide is from a told by Geoffrey Hinton and here you have basically describes an experiment

60
00:04:18.490 --> 00:04:24.440
that he had done on some conventional neural networks that he had trained up.

61
00:04:24.460 --> 00:04:29.560
So here you see three images and we're going to go through them with left to right and see how you would

62
00:04:29.560 --> 00:04:31.870
classify them and then see how they can be reclassified.

63
00:04:31.870 --> 00:04:35.440
So on the left what do you think this is.

64
00:04:35.440 --> 00:04:37.710
He probably said cheetah and you will be right.

65
00:04:37.710 --> 00:04:41.740
And this is what the computer said so and the right right away right off the bat we're going to learn

66
00:04:41.740 --> 00:04:48.400
how to read these images because if you going to go deep into call convolutional neural networks no

67
00:04:48.400 --> 00:04:54.050
pun intended you're going to start learning more and more about and using them you'll see a lot of these.

68
00:04:54.070 --> 00:05:01.050
So and I've actually seen people read them incorrectly so here at the top Shida is what it actually

69
00:05:01.050 --> 00:05:01.470
is.

70
00:05:01.470 --> 00:05:07.920
So that's the actual correct label of the image that's what's the label of the images regardless of

71
00:05:07.920 --> 00:05:09.180
any processing.

72
00:05:09.300 --> 00:05:16.770
And the computer vision and then here are the guesses the top four or five sometimes guesses of the

73
00:05:17.370 --> 00:05:24.520
algorithm and they're given the probabilities so the computer said or the neural network said Chitta

74
00:05:24.810 --> 00:05:27.460
personal apparel or Egyptian cat can be one of the four.

75
00:05:27.540 --> 00:05:29.120
And cheetah has the highest vote.

76
00:05:29.130 --> 00:05:34.820
And throughout this part of the Course you understand what these votes mean and how they are derived.

77
00:05:34.830 --> 00:05:36.600
But for now it's pretty intuitive right.

78
00:05:36.600 --> 00:05:40.700
So it's a cheetah in reality and the neural network guessed right.

79
00:05:40.710 --> 00:05:44.600
It said with a hyper ability about like 95 99 percent.

80
00:05:45.900 --> 00:05:46.860
Then the second one.

81
00:05:46.860 --> 00:05:51.050
What do you think does it that is that it is a bullet train.

82
00:05:51.300 --> 00:05:57.600
And the neural network was able to distinguish between bullet train passenger car subway train electric

83
00:05:57.600 --> 00:05:58.020
locomotive.

84
00:05:58.020 --> 00:05:59.380
Those are the top choice of course.

85
00:05:59.400 --> 00:06:05.850
It had many more options these neural networks learn to distinguish from not just four categories from

86
00:06:06.000 --> 00:06:08.760
dozens thousands of categories at the same time.

87
00:06:08.760 --> 00:06:10.750
So those are the four options that it picked.

88
00:06:10.920 --> 00:06:12.750
And so that's bullet train and its will.

89
00:06:12.760 --> 00:06:17.210
And so what did you think the last one is it very.

90
00:06:17.350 --> 00:06:22.470
There are a couple of options or it's not very clear what is it could be a frying pan could be a magnifying

91
00:06:22.470 --> 00:06:29.550
glass it could be even maybe a pair of scissors some might say while the neural network said it was

92
00:06:29.550 --> 00:06:30.540
a pair of scissors.

93
00:06:30.750 --> 00:06:32.590
But you can see how you can go wrong here.

94
00:06:32.610 --> 00:06:35.440
First of all it's not a very clear image.

95
00:06:35.520 --> 00:06:43.920
And also you can see that the probabilities are not as clear here so the neural network was a bit confused

96
00:06:43.920 --> 00:06:46.280
a bit indecisive just as we are.

97
00:06:46.280 --> 00:06:51.710
So I said Scissors with the high probability but then it had hand-glass which it actually was with not

98
00:06:51.810 --> 00:06:55.760
not so far away on second place and frying pan stethoscope.

99
00:06:55.920 --> 00:07:01.620
So basically here you can see that scissors was its first guess but the correct option was number two

100
00:07:01.620 --> 00:07:03.050
and that's why it's highlighted in red.

101
00:07:03.300 --> 00:07:07.050
So there we go those That's what all the drugs are already capable of.

102
00:07:07.050 --> 00:07:08.880
And this is actually quite an old slide.

103
00:07:08.880 --> 00:07:10.610
This was several years ago.

104
00:07:10.650 --> 00:07:16.100
Now they're even better and you will see that from the practical application that you'll be coding together

105
00:07:16.170 --> 00:07:16.760
had lunch.

106
00:07:16.920 --> 00:07:18.430
But now let's try this out a bit better.

107
00:07:18.430 --> 00:07:23.770
What convenance or convolutional neural networks actually are and why are they gained so much popularity.

108
00:07:23.970 --> 00:07:31.380
And they actually are gaining popularity so you can see here a Google Trends comparison I did just yesterday.

109
00:07:31.770 --> 00:07:39.420
Here you can see that convention illusional neural networks are even taking over artificial neural networks

110
00:07:39.420 --> 00:07:43.260
so a massive increase.

111
00:07:43.260 --> 00:07:49.530
And this is going to keep going that way because it is a very important field that that is where all

112
00:07:50.130 --> 00:07:52.530
the things happen such as like self-driving cars.

113
00:07:52.530 --> 00:07:59.340
How do they recognize people on the road how to recognize stop signs and things like that how do how

114
00:07:59.340 --> 00:08:07.680
does Facebook is Facebook able to tag images or people in images and not only just like remember previously

115
00:08:07.980 --> 00:08:14.240
years ago you had to tell people yourself then it would recognize faces you had to add the names.

116
00:08:14.250 --> 00:08:18.420
And now it just recognizes the faces and adds the names at the same time.

117
00:08:18.630 --> 00:08:26.070
Well that is what convolutional neural networks are capable as being on Facebook.

118
00:08:26.160 --> 00:08:34.710
If Jeffrey Hinton is the godfather of artificial neural networks and deep learning then yalla Kuhn is

119
00:08:34.830 --> 00:08:43.650
the grandfather of convolutional neural networks Lukken is a student of Jeffrey Hinton's and in fact

120
00:08:43.650 --> 00:08:45.640
here you can see them together.

121
00:08:45.720 --> 00:08:51.950
And Jeffrey Hinton now is pioneering de-planing at Google young.

122
00:08:52.020 --> 00:08:57.010
Is the director of Facebook artificial intelligence research and also a professor at NYU.

123
00:08:57.030 --> 00:09:02.650
So we're slowly aware of this part of the core slowly we are building up this way.

124
00:09:02.670 --> 00:09:10.770
These names are this kind of picture of the profiles of the people who are driving this field and next

125
00:09:10.950 --> 00:09:16.680
in the next couple of pars will get to know about a few more and we'll have this whole Mafia as they

126
00:09:16.680 --> 00:09:22.320
call themselves or you can call them mafia or conspiracy of deep learning and you'll learn a bit more

127
00:09:22.320 --> 00:09:24.140
about how this whole field developed.

128
00:09:24.480 --> 00:09:27.200
Yeah it's just these are just some great great people.

129
00:09:27.450 --> 00:09:35.370
And so RIKOON back in the 80s and the 90s made significant contributions to the field of convolutional

130
00:09:35.370 --> 00:09:36.300
neural networks.

131
00:09:36.330 --> 00:09:44.310
And as you'll see throughout this course has been able to develop or help the world develop something

132
00:09:44.340 --> 00:09:46.650
so extremely powerful.

133
00:09:46.650 --> 00:09:51.390
So moving on to how can illusional neural networks work.

134
00:09:51.420 --> 00:09:56.150
You have an input it's very simple it's very straightforward so they have an input image.

135
00:09:56.160 --> 00:10:01.930
It goes through the can illusional neural network and you have an label so it classifies that image

136
00:10:01.990 --> 00:10:06.630
as something like has a Cheeto or a bullet train or something else.

137
00:10:06.790 --> 00:10:10.780
Now kind of like going into a bit more detail.

138
00:10:10.900 --> 00:10:19.540
For instance you can officer neroli has been trained up on on certain images on certain classified images

139
00:10:19.780 --> 00:10:23.600
or categorized images prior there been higher prior.

140
00:10:23.710 --> 00:10:29.510
After that you can give it let's say a neural network has been trained up to recognize facial expressions

141
00:10:29.510 --> 00:10:37.030
and motions you can give it a face of a smiling person not just a face like a drawing of a face like

142
00:10:37.030 --> 00:10:39.330
this but actual face of a person smiling.

143
00:10:39.430 --> 00:10:44.910
And I'll tell you that that person is happy and you can get a face of a person that's frowning.

144
00:10:44.910 --> 00:10:47.180
I'll tell you that the person is sad.

145
00:10:47.280 --> 00:10:52.570
He can recognize these emotions and as you can see that's already very powerful in terms of so many

146
00:10:52.570 --> 00:10:59.740
different implications just this one example you can think of right away and in both cases Ill give

147
00:10:59.740 --> 00:11:04.970
you a operability so it won't say you know we're 100 percent the person's happy or sad.

148
00:11:04.970 --> 00:11:13.000
It'll be 99 or 98 or maybe 80 percent when it's unclear of what's going on and just like we are right

149
00:11:13.000 --> 00:11:16.620
sometimes we can mistake things for what they're not.

150
00:11:16.660 --> 00:11:23.620
Or sometimes we can sometimes it's just not clear if the person is smiling or frowning or if it's if

151
00:11:23.620 --> 00:11:27.910
it's a dog or a cat or if it's a train or a bullet train.

152
00:11:28.110 --> 00:11:32.620
All right sometimes we don't have it we haven't seen enough features in all goes down to features because

153
00:11:32.980 --> 00:11:38.600
that's how we process visual information as we saw from the start of this tutorial.

154
00:11:38.620 --> 00:11:44.140
So but how does a neural network housing neural network able to recognize these features.

155
00:11:44.140 --> 00:11:48.770
Well it all starts at the very basic level you have.

156
00:11:48.790 --> 00:11:54.160
Let's say you have an image you have two images one is black and white image of two by two pixels and

157
00:11:54.160 --> 00:12:01.270
one is a color image of two by two pixels while neural networks leverage the fact that the black and

158
00:12:01.270 --> 00:12:04.690
white image is a two dimensional array.

159
00:12:04.690 --> 00:12:09.610
So the way we see it right now on the left is just the visual representation.

160
00:12:09.630 --> 00:12:11.110
I suppose some kind of picture.

161
00:12:11.250 --> 00:12:16.600
And for simplicity's sake it's just a two way to picture but in computer terms it's actually a two dimensional

162
00:12:16.600 --> 00:12:22.180
array with every single one of those pixels having a value between 0 and 55.

163
00:12:22.360 --> 00:12:27.670
So that's eight bits of information to the two to the power of eight is 256.

164
00:12:27.670 --> 00:12:32.130
So therefore the values from 0 to 255 and that's intensity of the color.

165
00:12:32.260 --> 00:12:36.240
And in this case the color white so 0 will be a completely black pixel.

166
00:12:36.370 --> 00:12:43.720
255 will be a completely white pixel and between them you have the grayscale range of possible options

167
00:12:43.720 --> 00:12:44.490
for this pixel.

168
00:12:44.650 --> 00:12:50.740
And based on that information computers are able to then work with the image and that's kind of like

169
00:12:50.740 --> 00:12:56.510
the starting point that any image is actually has a digital representation has a digital form.

170
00:12:56.620 --> 00:13:03.460
And those are just basically ones and zeros that form a number 0 to 255 for every single pixel and that's

171
00:13:03.460 --> 00:13:04.340
what the computer works with.

172
00:13:04.340 --> 00:13:08.410
It doesn't actually work with you know colors or anything it works with the ones and zeros at the end

173
00:13:08.410 --> 00:13:08.790
of the day.

174
00:13:08.800 --> 00:13:12.820
That's as kind of like the foundation of it all.

175
00:13:13.360 --> 00:13:17.110
And in a color image it's actually a three dimensional array.

176
00:13:17.230 --> 00:13:24.580
You've got blue pixel blue Larry Green and the red glare and arrows and that sense for RGV red green

177
00:13:24.580 --> 00:13:25.130
blue.

178
00:13:25.420 --> 00:13:29.740
And each one of those colors has its own intensity.

179
00:13:29.740 --> 00:13:37.010
So basically a pixel has three three values assigned to it.

180
00:13:37.030 --> 00:13:41.090
Each one of them is between 0 and 256 255.

181
00:13:41.380 --> 00:13:48.340
And therefore you can find out what's this image what color exactly this pixel is.

182
00:13:48.340 --> 00:13:53.520
By combining those three values and again computers are going to be working with that.

183
00:13:53.530 --> 00:13:58.930
So that's the foundation of it all that's the red channel the green channel the blue channel.

184
00:13:59.530 --> 00:14:08.590
And finally let's have a look at for instance an example of a very trivial example of a smiling face.

185
00:14:08.820 --> 00:14:09.610
In computer terms.

186
00:14:09.610 --> 00:14:17.710
If we just really simplify things instead of having from 0 to 255 and having those values just so that

187
00:14:17.710 --> 00:14:25.690
we can understand things better and really grasp the concepts we're going to say zero is is white one

188
00:14:25.690 --> 00:14:26.590
is black.

189
00:14:26.590 --> 00:14:26.800
Right.

190
00:14:26.800 --> 00:14:33.460
So we're just going to simplify things to the extreme and you will see that that image can be represented

191
00:14:33.460 --> 00:14:33.900
like that.

192
00:14:34.000 --> 00:14:39.150
So the reason why we've brought this up is because we go into all of our intuitions Stroh's we get to

193
00:14:39.160 --> 00:14:44.680
structure an image is like this which is very simple but at the same time then all those concepts can

194
00:14:44.680 --> 00:14:50.530
translate back to the 0 2 256 range of values and everything applies the same way there.

195
00:14:50.740 --> 00:14:54.900
And the steps are we're going to be going through if these images are optimal one evolution.

196
00:14:54.910 --> 00:14:56.820
Step number two max pooling.

197
00:14:56.830 --> 00:15:02.550
Step number three flattening and step number a full connection and I can imagine that probably all of

198
00:15:02.560 --> 00:15:09.880
these words mean much to you at the moment but by the end of this section of the course you will understand

199
00:15:10.000 --> 00:15:13.940
them in great detail and exactly what they're doing.

200
00:15:13.960 --> 00:15:16.020
So we'll get started in the next tutorial.

201
00:15:16.030 --> 00:15:24.400
For now the additional reading that you might want to look into is a young Lukens original paper that

202
00:15:24.640 --> 00:15:28.200
gave rise to an emotional neural networks.

203
00:15:28.200 --> 00:15:31.590
It's called gradient based learning applied to documentary cognition.

204
00:15:31.660 --> 00:15:34.550
You may have seen this image before floating around the Internet.

205
00:15:34.630 --> 00:15:40.990
It is from that paper so if you want to go back to the very beginnings of how it all happened where

206
00:15:40.990 --> 00:15:46.420
it all came from this is the paper to look into and I look forward to seeing in the next tutorial.

207
00:15:46.420 --> 00:15:48.280
Until then enjoy deep learning.
