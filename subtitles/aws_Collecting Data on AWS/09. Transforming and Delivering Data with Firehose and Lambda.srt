1
00:00:01,180 --> 00:00:04,310
Let's look at a demo involving Amazon Kinesis.

2
00:00:04,310 --> 00:00:05,910
Now a quick warning.

3
00:00:05,910 --> 00:00:08,710
This is not included inside of the AWS Free tier,

4
00:00:08,710 --> 00:00:11,620
so some of these services that you're using will leverage

5
00:00:11,620 --> 00:00:14,320
things that AWS will actually charge you for.

6
00:00:14,320 --> 00:00:16,290
So if you decide to go through with it in your own

7
00:00:16,290 --> 00:00:18,310
AWS account that you're paying for,

8
00:00:18,310 --> 00:00:21,800
just be sure that you delete the services after you're done with this demo

9
00:00:21,800 --> 00:00:24,440
to make sure you don't keep getting charged for them.

10
00:00:24,440 --> 00:00:25,120
First,

11
00:00:25,120 --> 00:00:27,780
we'll be looking at creating a Firehose delivery

12
00:00:27,780 --> 00:00:29,580
stream inside of the AWS console.

13
00:00:29,580 --> 00:00:33,890
We'll create a Kinesis data stream source for that Firehose delivery stream,

14
00:00:33,890 --> 00:00:37,970
and then we'll use a script to send data into the data stream so that it

15
00:00:37,970 --> 00:00:41,140
will then go to the Firehose delivery stream after that.

16
00:00:41,140 --> 00:00:41,900
Now we're of course,

17
00:00:41,900 --> 00:00:43,910
going to have to create the Firehose delivery stream

18
00:00:43,910 --> 00:00:46,960
inside of the AWS console and configure with the Kinesis

19
00:00:46,960 --> 00:00:48,950
data stream that we also created,

20
00:00:48,950 --> 00:00:51,420
but we'll also create a Lambda function that we

21
00:00:51,420 --> 00:00:53,810
configure with Firehose to process the data.

22
00:00:53,810 --> 00:00:57,730
We'll use that to transform data from JSON format to CSV.

23
00:00:57,730 --> 00:00:59,160
In this example,

24
00:00:59,160 --> 00:01:02,440
we'll be imagining that the Globomantics finance team needs the

25
00:01:02,440 --> 00:01:04,930
data in CSV format because that's something they're a bit more

26
00:01:04,930 --> 00:01:06,850
comfortable with than the JSON format,

27
00:01:06,850 --> 00:01:09,540
in order to put it into something like Excel and let them

28
00:01:09,540 --> 00:01:12,040
process the data and run their own analysis on it.

29
00:01:12,040 --> 00:01:15,240
So we'll need to take this data and output it to S3,

30
00:01:15,240 --> 00:01:17,540
where we're going to assume that there's an application waiting

31
00:01:17,540 --> 00:01:20,040
to provide it to those finance professionals.

32
00:01:20,040 --> 00:01:24,380
So let's go ahead and get started by jumping into the AWS console now.

33
00:01:24,380 --> 00:01:27,900
Over here in the AWS console we'll go to the Services

34
00:01:27,900 --> 00:01:31,040
drop‑down and then look for Kinesis.

35
00:01:31,040 --> 00:01:34,540
We'll click on the Kinesis button here, and in this new window,

36
00:01:34,540 --> 00:01:38,480
we can either click Create data stream with the Kinesis Data Streams selected,

37
00:01:38,480 --> 00:01:42,900
or we can go over the left side here and click into the Data streams section.

38
00:01:42,900 --> 00:01:43,840
From here,

39
00:01:43,840 --> 00:01:47,640
we're still going to need to create our first data stream if we haven't already.

40
00:01:47,640 --> 00:01:48,550
Now, in this case,

41
00:01:48,550 --> 00:01:50,930
I'm going to make sure to name my stream the exact same

42
00:01:50,930 --> 00:01:52,840
thing that's in my code for this demo.

43
00:01:52,840 --> 00:01:55,140
Let's take a look at this now.

44
00:01:55,140 --> 00:01:56,700
Inside the code for this section,

45
00:01:56,700 --> 00:02:00,950
you'll see that we haven't in index.py file and a streamer.py file.

46
00:02:00,950 --> 00:02:04,640
Now inside of this streamer.py file we'll be using this to

47
00:02:04,640 --> 00:02:08,490
send data into a stream that we create, a Kinesis data stream,

48
00:02:08,490 --> 00:02:10,390
not a Firehose delivery stream.

49
00:02:10,390 --> 00:02:13,580
So we'll need to make sure that the stream name in this file, in

50
00:02:13,580 --> 00:02:17,310
this case it's currently listed as sales, is the same as the stream

51
00:02:17,310 --> 00:02:19,640
name we give to our Kinesis data stream.

52
00:02:19,640 --> 00:02:22,940
We'll also need to make sure that it's in the same AWS region.

53
00:02:22,940 --> 00:02:23,420
In this case,

54
00:02:23,420 --> 00:02:27,140
you can see it's in us‑east‑1, so we'll need to make sure this is

55
00:02:27,140 --> 00:02:30,940
the same region that we're in in the AWS console.

56
00:02:30,940 --> 00:02:35,040
So let's go back to the AWS console now and create our stream.

57
00:02:35,040 --> 00:02:39,810
We'll call it sales, and then because we we're in the northern Virginia region,

58
00:02:39,810 --> 00:02:42,390
this means that work in the correct region in this case,

59
00:02:42,390 --> 00:02:43,680
in us‑east‑1.

60
00:02:43,680 --> 00:02:46,640
But just make sure those two things line up for you as well.

61
00:02:46,640 --> 00:02:47,220
From here,

62
00:02:47,220 --> 00:02:49,590
we can scroll down a little bit and determine how

63
00:02:49,590 --> 00:02:51,640
many shards we want in this stream.

64
00:02:51,640 --> 00:02:54,130
In this case, I want the cheapest stream possible,

65
00:02:54,130 --> 00:02:56,070
so I'm going to type in 1 here.

66
00:02:56,070 --> 00:02:58,940
Now, this will still be outside of the AWS Free tier,

67
00:02:58,940 --> 00:03:01,140
so make sure you delete this stream once you're done

68
00:03:01,140 --> 00:03:03,140
to avoid getting a bill for it.

69
00:03:03,140 --> 00:03:06,680
Now let's scroll down and make sure that we have 1 selected here when

70
00:03:06,680 --> 00:03:10,560
we're creating our stream because we could accidentally select a lot more

71
00:03:10,560 --> 00:03:13,240
than 1 and end up getting charged a lot more.

72
00:03:13,240 --> 00:03:16,380
But with that selected, we can click Create data stream.

73
00:03:16,380 --> 00:03:18,630
Now, this might take a minute, but once it's created,

74
00:03:18,630 --> 00:03:25,140
we'll be able to use it in configuration with a delivery stream as well.

75
00:03:25,140 --> 00:03:26,470
So now that it's been created,

76
00:03:26,470 --> 00:03:30,860
we can go over to the delivery stream section to configure this Kinesis

77
00:03:30,860 --> 00:03:34,840
data stream as an input source for a new data firehose.

78
00:03:34,840 --> 00:03:36,930
So once were in the Data Firehose section,

79
00:03:36,930 --> 00:03:40,240
we can scroll down and click Create delivery stream.

80
00:03:40,240 --> 00:03:43,060
From here we'll need to give our delivery stream a name.

81
00:03:43,060 --> 00:03:46,600
This is less important than what we named our Kinesis data stream.

82
00:03:46,600 --> 00:03:48,820
Let's call our delivery stream salestoS3,

83
00:03:48,820 --> 00:03:54,940
since we'll be sending the Kinesis data stream called sales over into Amazon S3.

84
00:03:54,940 --> 00:03:57,950
Now let's scroll down and choose a source that we're going to be using.

85
00:03:57,950 --> 00:04:00,110
In this case, we're not going to be using a direct put,

86
00:04:00,110 --> 00:04:03,670
so we'll need to select the Kinesis data stream that we just created.

87
00:04:03,670 --> 00:04:07,120
And under this we'll need to select that particular stream.

88
00:04:07,120 --> 00:04:11,500
So we'll click sales here, and then we'll scroll down a little bit further.

89
00:04:11,500 --> 00:04:12,690
Now that we've got all that configured,

90
00:04:12,690 --> 00:04:15,740
we can click Next for the next section to determine how

91
00:04:15,740 --> 00:04:17,870
we might want to process records.

92
00:04:17,870 --> 00:04:18,430
In this case,

93
00:04:18,430 --> 00:04:20,840
we do want to process the records because they'll be coming

94
00:04:20,840 --> 00:04:24,250
in as JSON from our Kinesis data stream and the things that

95
00:04:24,250 --> 00:04:28,430
are sending data into that, and we'll want to transform them into a CSV.

96
00:04:28,430 --> 00:04:33,080
So let's click Enabled here, and instead of choosing a Lambda function,

97
00:04:33,080 --> 00:04:34,440
let's create a new one.

98
00:04:34,440 --> 00:04:34,790
Now,

99
00:04:34,790 --> 00:04:37,540
you can use any of the blueprints here because we're actually going

100
00:04:37,540 --> 00:04:40,640
to be modifying the function that we're using.

101
00:04:40,640 --> 00:04:45,490
So let's start with the General Kinesis Data Firehose Processing function.

102
00:04:45,490 --> 00:04:49,580
Let's just give this a name of sales‑proc for sales processing.

103
00:04:49,580 --> 00:04:53,100
Now, I'm going to scroll down and we'll be able to create this function.

104
00:04:53,100 --> 00:04:53,530
Currently,

105
00:04:53,530 --> 00:04:56,510
we can't modify much that's inside of it because we're in the

106
00:04:56,510 --> 00:04:58,740
process of building it out from a template.

107
00:04:58,740 --> 00:05:03,640
But once it's created, we can go back in and edit it.

108
00:05:03,640 --> 00:05:05,440
So now that the function is created,

109
00:05:05,440 --> 00:05:07,890
we can scroll down in this configuration section,

110
00:05:07,890 --> 00:05:10,580
and we'll change a few things about our function.

111
00:05:10,580 --> 00:05:13,820
Actually, instead of JavaScript and Node.js code,

112
00:05:13,820 --> 00:05:15,460
I want to run a Python function,

113
00:05:15,460 --> 00:05:18,080
so I'm to select the most recent version of Python,

114
00:05:18,080 --> 00:05:20,840
which at the time here is Python 3.8.

115
00:05:20,840 --> 00:05:27,510
Now going to change this index.js file from index.js to index.py.

116
00:05:27,510 --> 00:05:29,620
Now the last thing I'm going to need to change is the

117
00:05:29,620 --> 00:05:32,090
code that's currently in index.py.

118
00:05:32,090 --> 00:05:34,950
So let's go over to my VS Code editor where I've

119
00:05:34,950 --> 00:05:37,200
copied the files for this module.

120
00:05:37,200 --> 00:05:40,370
Inside of here, instead of the streamer code,

121
00:05:40,370 --> 00:05:43,280
we're going to want to go up to the index.py file to

122
00:05:43,280 --> 00:05:45,720
copy the code for the Lambda handler.

123
00:05:45,720 --> 00:05:50,390
Let's copy the entire chunk of code here and then go back to the AWS

124
00:05:50,390 --> 00:05:55,110
console to paste it into the index.py file and then hit Save.

125
00:05:55,110 --> 00:05:56,700
Inside of this code,

126
00:05:56,700 --> 00:06:00,680
it's going to process all the records coming in from the Kinesis data stream,

127
00:06:00,680 --> 00:06:04,550
and then it's going to take those records and change them from JSON

128
00:06:04,550 --> 00:06:09,170
format by loading the JSON in with the JSON library from Python and

129
00:06:09,170 --> 00:06:14,250
then output them as a CSV by adding the comma separation between the

130
00:06:14,250 --> 00:06:16,660
values that was in the JSON.

131
00:06:16,660 --> 00:06:17,520
From there,

132
00:06:17,520 --> 00:06:21,790
it's going to send them out as the output record format here back out to

133
00:06:21,790 --> 00:06:25,880
Kinesis Firehose to let it know how to deliver it into Amazon S3.

134
00:06:25,880 --> 00:06:26,870
So with this all saved,

135
00:06:26,870 --> 00:06:30,380
we should be able to use this function inside of our Kinesis Firehose.

136
00:06:30,380 --> 00:06:34,270
So let's go back here for now, and let's click Close,

137
00:06:34,270 --> 00:06:36,470
and now we should be able to choose our Lambda function

138
00:06:36,470 --> 00:06:38,630
from a list of functions in our account.

139
00:06:38,630 --> 00:06:42,310
Now I have a bunch here right now, but we can search for the one we just made,

140
00:06:42,310 --> 00:06:44,690
which in this case was sales‑proc.

141
00:06:44,690 --> 00:06:47,880
So let's select that one here and make sure we have the latest

142
00:06:47,880 --> 00:06:50,630
version of our function selected from this drop‑down.

143
00:06:50,630 --> 00:06:53,450
If we had any other versions, they might appear here,

144
00:06:53,450 --> 00:06:56,640
but we're going to stick with that most recently updated one.

145
00:06:56,640 --> 00:06:58,770
So now I'm going to scroll down even further.

146
00:06:58,770 --> 00:07:01,450
And you'll notice that there's this alert that's warning

147
00:07:01,450 --> 00:07:03,640
us about our timeout for a function.

148
00:07:03,640 --> 00:07:05,800
What this is saying is essentially that we might be

149
00:07:05,800 --> 00:07:07,980
sending a lot of data into Lambda,

150
00:07:07,980 --> 00:07:11,140
and it might need more than 3 seconds to process that data,

151
00:07:11,140 --> 00:07:14,580
which is currently with the timeout is set for this Lambda function.

152
00:07:14,580 --> 00:07:18,110
So to change this, we'll want to go back to our Lambda function,

153
00:07:18,110 --> 00:07:21,440
go over to the settings for this even further below the code,

154
00:07:21,440 --> 00:07:25,000
and when we see the basic settings, we'll be able to edit those.

155
00:07:25,000 --> 00:07:27,160
And here we'll need to change the timeout,

156
00:07:27,160 --> 00:07:31,740
let's say from 3 seconds up to 3 full minutes.

157
00:07:31,740 --> 00:07:34,960
Now, after that, I can scroll down and hit Save,

158
00:07:34,960 --> 00:07:37,250
and this Lambda function should be able to spend more

159
00:07:37,250 --> 00:07:39,940
time processing the data if it needs it.

160
00:07:39,940 --> 00:07:43,020
From here, we can go back to the Kinesis Firehose section,

161
00:07:43,020 --> 00:07:47,150
scroll down even further, and then click the Next button.

162
00:07:47,150 --> 00:07:51,070
From here we'll need to pick the destination that we want.

163
00:07:51,070 --> 00:07:52,840
Now these are all the destination options that we

164
00:07:52,840 --> 00:07:54,900
talked about in the previous videos.

165
00:07:54,900 --> 00:07:57,540
In this case, I'm going to leave Amazon S3 selected,

166
00:07:57,540 --> 00:08:02,270
as it's where we want this data to go for our Globomantics finance team users.

167
00:08:02,270 --> 00:08:05,990
So let's scroll down even further and set up a bucket for them.

168
00:08:05,990 --> 00:08:09,840
Now in this case I want to use a new bucket so I'll click Create new.

169
00:08:09,840 --> 00:08:13,780
So I'm going to name my bucket sales‑bucket‑globomantics‑12.

170
00:08:13,780 --> 00:08:15,060
Now, in your case,

171
00:08:15,060 --> 00:08:17,250
you're going to want to name this something completely different.

172
00:08:17,250 --> 00:08:21,540
It can be your name, your favorite animal, and some gibberish alongside of that.

173
00:08:21,540 --> 00:08:26,300
It doesn't really matter, as long as it conforms to S3 bucket naming conventions.

174
00:08:26,300 --> 00:08:29,580
Really, just use some dashes, letters, and numbers,

175
00:08:29,580 --> 00:08:32,650
and as long as you keep the dashes after the first character,

176
00:08:32,650 --> 00:08:34,740
you should be pretty good to go.

177
00:08:34,740 --> 00:08:40,540
So once you're done naming this bucket, you can click Create S3 bucket.

178
00:08:40,540 --> 00:08:44,410
Now that the bucket is created and we've configured our Lambda function,

179
00:08:44,410 --> 00:08:46,870
we should be able to scroll down to the very bottom and just

180
00:08:46,870 --> 00:08:49,170
click Next in order to get things rolling.

181
00:08:49,170 --> 00:08:53,330
From here, we have the last few settings that we need to set,

182
00:08:53,330 --> 00:08:56,230
the buffer size, which we've talked about a lot before.

183
00:08:56,230 --> 00:08:56,820
In this case,

184
00:08:56,820 --> 00:09:00,100
I'm going to bring it down to 1 so that we can make sure that it's

185
00:09:00,100 --> 00:09:02,680
going to send data over as quickly as possible.

186
00:09:02,680 --> 00:09:06,670
And I'm also going to set the buffer interval down to the minimum of 60 seconds.

187
00:09:06,670 --> 00:09:10,940
This means that at a minimum, we'll see the data in 60 seconds or less.

188
00:09:10,940 --> 00:09:14,630
So now that we have these last configuration options set,

189
00:09:14,630 --> 00:09:18,240
we'll scroll down to the bottom again and need to set up on IAM role.

190
00:09:18,240 --> 00:09:21,040
You might have to click this depending on if you already have an

191
00:09:21,040 --> 00:09:23,880
IAM role created to use for Kinesis Firehose.

192
00:09:23,880 --> 00:09:26,050
I'm going to click Create new or choose,

193
00:09:26,050 --> 00:09:29,560
and this will direct me over to Identity and Access Management.

194
00:09:29,560 --> 00:09:33,460
It should create a role for me or allow me to pick one from this drop‑down here.

195
00:09:33,460 --> 00:09:35,860
In this case, it's already prepopulated the role,

196
00:09:35,860 --> 00:09:38,930
so I'm going to click Allow. Now once I do this,

197
00:09:38,930 --> 00:09:41,810
we should be able to use this Firehose delivery role in

198
00:09:41,810 --> 00:09:45,040
combination with my Kinesis Firehose, so I'm going to click Next

199
00:09:45,040 --> 00:09:48,760
again, and we'll review the last bit of configuration and

200
00:09:48,760 --> 00:09:52,140
finally click Create delivery stream.

201
00:09:52,140 --> 00:09:55,230
So now that our delivery stream is being created,

202
00:09:55,230 --> 00:09:59,660
we should be able to see the data inside of S3 as soon as it gets sent over to

203
00:09:59,660 --> 00:10:08,000
the Kinesis data stream, gets ingested by the Kinesis Firehose, processed by the Lambda function, and then eventually sent to S3.

