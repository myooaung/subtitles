WEBVTT
1
00:00:01.120 --> 00:00:03.390
So what are some of the ways we can use Kinesis Data

2
00:00:03.390 --> 00:00:05.840
Analytics to analyze our data?

3
00:00:05.840 --> 00:00:08.350
If we're streaming product sales data, for example,

4
00:00:08.350 --> 00:00:10.810
we might use a built‑in Kinesis data Analytics

5
00:00:10.810 --> 00:00:13.320
function to find the top selling item.

6
00:00:13.320 --> 00:00:16.020
We could also use the built‑in machine learning capabilities

7
00:00:16.020 --> 00:00:18.780
of Kinesis Data Analytics to provide machine learning

8
00:00:18.780 --> 00:00:21.240
functions like anomaly detection.

9
00:00:21.240 --> 00:00:24.580
And another example might be to leverage the S3 reference

10
00:00:24.580 --> 00:00:27.710
data I mentioned earlier to enrich data in our stream and

11
00:00:27.710 --> 00:00:30.810
perform more complex analysis.

12
00:00:30.810 --> 00:00:33.100
What about data that we want to transform?

13
00:00:33.100 --> 00:00:36.840
Most data engineering processes require some alteration of data.

14
00:00:36.840 --> 00:00:40.700
So how can we leverage Kinesis Data Analytics to help with us?

15
00:00:40.700 --> 00:00:41.320
Well, to start,

16
00:00:41.320 --> 00:00:46.070
you can use Kinesis Data Analytics to transform between common data formats.

17
00:00:46.070 --> 00:00:49.180
There are well‑documented examples of how to transform between

18
00:00:49.180 --> 00:00:54.770
formats like Apache logs and JSON or CSV formats. For more complex

19
00:00:54.770 --> 00:00:58.720
data analytics and transformation needs, you can use custom regexs to

20
00:00:58.720 --> 00:01:00.530
determine how to process your data.

21
00:01:00.530 --> 00:01:03.280
This can allow you to process unique data formats or to

22
00:01:03.280 --> 00:01:06.540
extract relevant data from larger string fields.

23
00:01:06.540 --> 00:01:07.510
Similarly,

24
00:01:07.510 --> 00:01:10.980
you can perform string splitting and manipulation operations to

25
00:01:10.980 --> 00:01:14.270
help you parse through common file formats like pipe‑separated

26
00:01:14.270 --> 00:01:16.710
values or comma‑separated values.

27
00:01:16.710 --> 00:01:19.750
These are just a subset of the transformation possibilities

28
00:01:19.750 --> 00:01:23.750
that Kinesis Data Analytics makes available.

29
00:01:23.750 --> 00:01:25.490
In addition to transformations,

30
00:01:25.490 --> 00:01:28.420
we can also review existing stream data and then do

31
00:01:28.420 --> 00:01:30.740
aggregations on top of that data.

32
00:01:30.740 --> 00:01:34.030
One of the most common ways to do this would be to leverage common

33
00:01:34.030 --> 00:01:38.340
SQL‑style aggregations, like SUMs and COUNTs, where you may wish to do

34
00:01:38.340 --> 00:01:41.010
a GROUP BY by some particular dimension.

35
00:01:41.010 --> 00:01:41.750
However,

36
00:01:41.750 --> 00:01:44.790
there are more advanced streaming data aggregations that really allow

37
00:01:44.790 --> 00:01:47.690
the benefits of Kinesis Data Analytics to shine.

38
00:01:47.690 --> 00:01:51.330
One of these is the tumbling window aggregations. These allow you to

39
00:01:51.330 --> 00:01:54.880
review all the data that comes in in a particular period,

40
00:01:54.880 --> 00:01:55.740
for example,

41
00:01:55.740 --> 00:01:58.870
all the data that comes in every 60 seconds, and then to

42
00:01:58.870 --> 00:02:01.090
aggregate metrics over that period.

43
00:02:01.090 --> 00:02:05.420
These aggregations occur in near real time against the incoming data streams,

44
00:02:05.420 --> 00:02:09.730
allowing you to get the most recent metrics possible. Now,

45
00:02:09.730 --> 00:02:13.440
while tumbling window aggregations collect data that occurs in a period

46
00:02:13.440 --> 00:02:16.490
and provides metrics in subsequent adjacent periods,

47
00:02:16.490 --> 00:02:19.080
you might want an aggregation of the most recent 60

48
00:02:19.080 --> 00:02:22.080
seconds of data at all times.

49
00:02:22.080 --> 00:02:25.450
In those cases, you can use sliding window aggregations.

50
00:02:25.450 --> 00:02:26.250
Essentially,

51
00:02:26.250 --> 00:02:29.650
these sliding windows take the streaming data and recompute the

52
00:02:29.650 --> 00:02:34.750
aggregations as new data enters and exits the period in question.

53
00:02:34.750 --> 00:02:38.160
So now that we've covered input sources and the various ways data

54
00:02:38.160 --> 00:02:41.220
can be manipulated by Kinesis Data Analytics,

55
00:02:41.220 --> 00:02:45.440
let's take a quick look at what happens to the data after we've acted on it.

56
00:02:45.440 --> 00:02:46.400
First off,

57
00:02:46.400 --> 00:02:49.260
the Kinesis Data Analytics service has its own interactive

58
00:02:49.260 --> 00:02:51.450
console for dealing with stream data.

59
00:02:51.450 --> 00:02:55.300
This allows you to immediately see the results of any stream manipulations or

60
00:02:55.300 --> 00:02:58.740
transformations that you're making on an incoming data stream.

61
00:02:58.740 --> 00:03:01.010
This technically isn't an output,

62
00:03:01.010 --> 00:03:04.460
but it is a place for you to see your data after transformations.

63
00:03:04.460 --> 00:03:08.120
The first real output source is Kinesis Data Streams.

64
00:03:08.120 --> 00:03:10.810
When Kinesis Data Analytics processes a stream,

65
00:03:10.810 --> 00:03:15.340
it can pump data directly to a new output Kinesis Data Stream. Outputting

66
00:03:15.340 --> 00:03:19.070
to a Kinesis Data Stream allows for a lot of flexibility to have that

67
00:03:19.070 --> 00:03:22.710
processed data be picked up by another application, processed again by

68
00:03:22.710 --> 00:03:26.560
another Data Analytics Stream, or a myriad of other options with custom

69
00:03:26.560 --> 00:03:31.060
applications. Kinesis Data Analytics can also output to a Kinesis Data

70
00:03:31.060 --> 00:03:32.880
Firehose delivery stream.

71
00:03:32.880 --> 00:03:36.030
This option is a great choice when you'd like to send your data along

72
00:03:36.030 --> 00:03:40.890
to be stored in S3, ingested into Elasticsearch, or sent into any of

73
00:03:40.890 --> 00:03:44.020
the other integrations that Firehose offers.

74
00:03:44.020 --> 00:03:48.110
Kinesis Data Analytics can also be processed by AWS Lambda functions,

75
00:03:48.110 --> 00:03:51.510
which can perform additional operations on the data that aren't bound by

76
00:03:51.510 --> 00:03:55.140
the same limitations of other output destinations.

77
00:03:55.140 --> 00:03:56.680
In any of these scenarios,

78
00:03:56.680 --> 00:04:00.310
there are opportunities to send data from Kinesis Data Streams to

79
00:04:00.310 --> 00:04:05.580
various AWS services or external providers. S3, Redshift, Splunk, and

80
00:04:05.580 --> 00:04:08.380
Elasticsearch are common options for next steps.

81
00:04:08.380 --> 00:04:08.970
However,

82
00:04:08.970 --> 00:04:12.260
you can do a lot of customizations and send them to many

83
00:04:12.260 --> 00:04:15.440
other services outside of this subset.

84
00:04:15.440 --> 00:04:19.600
So now that we know a bit about the sources Kinesis Data Analytics has, what

85
00:04:19.600 --> 00:04:27.000
it can do in terms of transformations, and where it can output to, let's take a look at Kinesis Data Analytics in action.

