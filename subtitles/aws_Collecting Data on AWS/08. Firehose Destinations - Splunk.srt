1
00:00:01,010 --> 00:00:02,020
In this example,

2
00:00:02,020 --> 00:00:05,840
we'll be looking at how to get data from Kinesis Firehose into Splunk,

3
00:00:05,840 --> 00:00:10,340
a third‑party tool that allows you to visualize and analyze your data.

4
00:00:10,340 --> 00:00:13,530
Now, we'll start in a very similar scenario to previous examples

5
00:00:13,530 --> 00:00:16,460
with a Kinesis Firehose that's ingesting some data.

6
00:00:16,460 --> 00:00:19,650
Once we fill up our buffer size or the buffer interval runs out,

7
00:00:19,650 --> 00:00:22,360
we'll try and send our data over into Splunk.

8
00:00:22,360 --> 00:00:22,850
Now,

9
00:00:22,850 --> 00:00:26,170
in any cases when we have data that's unable to be sent into Splunk,

10
00:00:26,170 --> 00:00:30,580
we'll then send that data over to S3 so we can look at it and determine

11
00:00:30,580 --> 00:00:33,870
why it wasn't able to send into Splunk, and what the failures were when

12
00:00:33,870 --> 00:00:36,280
we tried to do that. With Splunk,

13
00:00:36,280 --> 00:00:39,800
we can do many of the same things that we did with earlier destinations.

14
00:00:39,800 --> 00:00:41,550
When data goes into Kinesis Firehose,

15
00:00:41,550 --> 00:00:46,240
we can send it over to AWS Lambda, and from here we can then have this

16
00:00:46,240 --> 00:00:49,040
data be processed in the same ways we were doing earlier,

17
00:00:49,040 --> 00:00:52,470
where it gets processed and then comes back as either a successfully

18
00:00:52,470 --> 00:00:56,640
processed record, a dropped record or a failed transformation.

19
00:00:56,640 --> 00:00:58,720
From there, we take the dropped records out,

20
00:00:58,720 --> 00:01:02,350
send our records that are successfully transformed into Splunk, and send

21
00:01:02,350 --> 00:01:05,560
our failed transformation records into an S3 bucket so we can look at them

22
00:01:05,560 --> 00:01:08,800
in more detail. Now we could also do the same thing we were doing in

23
00:01:08,800 --> 00:01:12,690
earlier sections, where we take a copy of the data and store it in an S3

24
00:01:12,690 --> 00:01:14,560
bucket without making any changes.

25
00:01:14,560 --> 00:01:15,030
At this point,

26
00:01:15,030 --> 00:01:17,550
we could either send the data directly to Splunk and see if

27
00:01:17,550 --> 00:01:20,730
there's any failures, and store those failures in S3, or we could

28
00:01:20,730 --> 00:01:23,550
take the exact same approach we were doing just a second ago by

29
00:01:23,550 --> 00:01:25,210
sending the data over to Lambda,

30
00:01:25,210 --> 00:01:28,890
having it be processed and returned to us, and then having that

31
00:01:28,890 --> 00:01:33,200
data either go from Kinesis Firehose directly into Splunk if it

32
00:01:33,200 --> 00:01:37,300
was a successfully processed item, or over to an S3 bucket if it

33
00:01:37,300 --> 00:01:39,440
was a failed transformation.

34
00:01:39,440 --> 00:01:41,740
So now that you know how to use Kinesis Firehose in

35
00:01:41,740 --> 00:01:50,000
combination with multiple destinations, let's take a look at a hands‑on demo using Kinesis Firehose in the AWS console.

