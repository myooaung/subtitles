WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:01.400
Hey,

00:00:01.400 --> 00:00:03.040
let's talk about server less.

00:00:03.040 --> 00:00:03.980
Sounds pretty cool,

00:00:03.980 --> 00:00:04.340
right?

00:00:04.340 --> 00:00:06.880
To understand better what it's serverless.

00:00:06.880 --> 00:00:12.900
Let's re wise how normal server works back in is deployed servers running and waiting for

00:00:12.900 --> 00:00:13.690
connections.

00:00:13.690 --> 00:00:15.160
Nothing's wrong here,

00:00:15.160 --> 00:00:17.350
but here is one small disadvantage.

00:00:17.350 --> 00:00:18.520
We have no users,

00:00:18.520 --> 00:00:22.050
while server continues to Ron and consumer resources.

00:00:22.050 --> 00:00:28.440
Not very beneficial is it would serve unless a server that is deployed runs on demand.

00:00:28.440 --> 00:00:34.030
Or it is better to say that code executes on demand on Lee when it's needed.

00:00:34.030 --> 00:00:36.030
If nobody's access in decode,

00:00:36.030 --> 00:00:37.840
it is not executed.

00:00:37.840 --> 00:00:39.190
Most of the time,

00:00:39.190 --> 00:00:41.510
Serverless approach is presented.

00:00:41.510 --> 00:00:43.640
Informal server Last functions.

00:00:43.640 --> 00:00:48.110
Each function is deployed separately and has its own execution context.

00:00:48.110 --> 00:00:49.870
When it function is deployed,

00:00:49.870 --> 00:00:51.480
it has its own Http,

00:00:51.480 --> 00:00:54.710
your l that is used to investigate the function.

00:00:54.710 --> 00:00:58.240
Your L is like a trigger to execute the code.

00:00:58.240 --> 00:01:00.980
There is no actual server at the end.

00:01:00.980 --> 00:01:04.050
There is just code that execute on demand.

00:01:04.050 --> 00:01:05.350
Under the hood,

00:01:05.350 --> 00:01:08.900
all the magic is powered by docker containers.

00:01:08.900 --> 00:01:16.000
A container is a small as elated package off Whatever is put inside with virtual machines,

00:01:16.000 --> 00:01:20.250
the entire operating system is as elated with containers on Lee.

00:01:20.250 --> 00:01:26.780
The content that is put inside it allows to run multiple containers on one operating system

00:01:26.780 --> 00:01:26.780
.

00:01:26.780 --> 00:01:28.510
Every deployed function,

00:01:28.510 --> 00:01:34.880
with all its code and dependencies is put inside its own container that trans on demand

00:01:34.880 --> 00:01:36.550
when the function is triggered.

00:01:36.550 --> 00:01:39.540
But containers also must be hosted and deployed.

00:01:39.540 --> 00:01:43.370
Samba right This is controlled and managed by cloud provider.

00:01:43.370 --> 00:01:45.060
We don't need to worry about that.

00:01:45.060 --> 00:01:47.360
And because everything is managed for us,

00:01:47.360 --> 00:01:50.920
we also don't need to worry about scaling and maintenance.

00:01:50.920 --> 00:01:56.250
Deployed campaigners will scale automatically based on number off invocations.

00:01:56.250 --> 00:02:02.970
Now we know that every server less function is separate piece of code that is run on Lee

00:02:02.970 --> 00:02:09.410
when actually used one function is not aware off another how we're able to share some code

00:02:09.410 --> 00:02:11.120
across multiple functions.

00:02:11.120 --> 00:02:12.090
For example,

00:02:12.090 --> 00:02:17.150
all of deployed functions must access some shared variable or another function.

00:02:17.150 --> 00:02:19.550
It depends and cloud provider with fire.

00:02:19.550 --> 00:02:22.700
Base Cloud functions code is shared in the global scope.

00:02:22.700 --> 00:02:29.200
What are the drawbacks that the main one is called start when code is not executed for a

00:02:29.200 --> 00:02:29.720
while,

00:02:29.720 --> 00:02:32.480
that functions container goes to sleep.

00:02:32.480 --> 00:02:38.350
When someone tries to access the code container spins up and it takes some time.

00:02:38.350 --> 00:02:40.830
This is so called cold start.

00:02:40.830 --> 00:02:42.700
It depends on multiple factors.

00:02:42.700 --> 00:02:43.550
For example,

00:02:43.550 --> 00:02:46.450
how large is decode for that function?

00:02:46.450 --> 00:02:50.780
Or how many dependencies attests after a code is executed,

00:02:50.780 --> 00:02:56.290
the container stays in warmed state for a while and waits for subsequent requests.

00:02:56.290 --> 00:02:59.250
It means that cold start will not take place.

00:02:59.250 --> 00:03:00.930
But after some time,

00:03:00.930 --> 00:03:03.350
when there is no requests at all,

00:03:03.350 --> 00:03:05.150
container will go to sleep,

00:03:05.150 --> 00:03:07.700
and next time we will see the cold.

00:03:07.700 --> 00:03:09.520
Start with server Less.

00:03:09.520 --> 00:03:16.240
Pricing is evaluated based on number off invocations and how long each execution lusted.

00:03:16.240 --> 00:03:21.360
Firebase cloud functions have free tear off to millions free invocations per month,

00:03:21.360 --> 00:03:22.810
and this is amazing.

00:03:22.810 --> 00:03:28.020
Now we know what is serving less and what are cloud functions.

00:03:28.020 --> 00:03:29.250
Hope you liked it.

00:03:29.250 --> 00:03:30.750
See you in the next one.

