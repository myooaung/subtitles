WEBVTT
1
00:00:00.150 --> 00:00:07.230
The eight areas academic cloud, architecting, modernizing, implementing elasticity and high availability

2
00:00:07.230 --> 00:00:08.610
and monitoring.

3
00:00:08.940 --> 00:00:14.940
So the architecture need that we have for the cafe is that the cafe will be featured in a famous TV

4
00:00:14.940 --> 00:00:15.750
food show.

5
00:00:15.750 --> 00:00:20.660
When it is, the architecture must handle significant increase in capacity.

6
00:00:20.670 --> 00:00:26.760
What are the solutions on the options that we can use as a solution architect in order to basically

7
00:00:26.760 --> 00:00:32.880
make the cafe architecture highly available and highly scalable, we want to build a reactive market.

8
00:00:32.890 --> 00:00:39.270
Instead, I want to communicate that our architecture will be able to respond to an increased demand

9
00:00:39.270 --> 00:00:41.820
by adjusting dynamically its capacity.

10
00:00:41.820 --> 00:00:44.070
And we call this elastic and the scale of it.

11
00:00:44.070 --> 00:00:51.120
We also want to have an architecture which is resilient, which means it can adapt against changes,

12
00:00:51.120 --> 00:00:58.020
and you don't need to have a direct human intervention in order to fix the architecture or to configure

13
00:00:58.020 --> 00:00:58.140
it.

14
00:00:58.140 --> 00:01:04.920
We want the architecture to be responsive and message driven as well, which means we want the architecture

15
00:01:04.980 --> 00:01:09.770
to adapt against the data that it receives in daily basis.

16
00:01:09.780 --> 00:01:12.990
So this is take us to scaling your computer resource.

17
00:01:12.990 --> 00:01:20.220
So what we mean by elasticity, an elastic infrastructure can expand and contract as capacity needs

18
00:01:20.220 --> 00:01:20.550
change.

19
00:01:20.700 --> 00:01:26.700
So you can increase the number of servers when the traffic spikes lowering rise capacity in your database,

20
00:01:26.700 --> 00:01:33.330
when the traffic goes down and handling the day to day fluctuation of demand throughout your architecture,

21
00:01:33.330 --> 00:01:39.900
if you look at the scale and killing is a technique that we use to adjust the capacity of our infrastructure

22
00:01:39.900 --> 00:01:42.690
dynamically without any human intervention.

23
00:01:42.690 --> 00:01:45.480
Normally we have two types of scaling.

24
00:01:45.480 --> 00:01:47.340
We have horizontally scaling.

25
00:01:47.340 --> 00:01:54.330
So if we have one web server, so if this is with one, we want to increase this and we generate multiple

26
00:01:54.330 --> 00:02:00.960
instances of the same application and each application will have for each an instance when you have

27
00:02:00.960 --> 00:02:07.680
the same software or application to serve customers with horizontal scaling, we are just increasing

28
00:02:07.680 --> 00:02:09.840
the number of horizontally each.

29
00:02:10.020 --> 00:02:17.310
A new instance will be able to serve this service that you are trying to provide for you end customer

30
00:02:17.310 --> 00:02:18.600
with vertical scaling.

31
00:02:18.600 --> 00:02:20.670
And this is a very famous approach.

32
00:02:20.670 --> 00:02:24.870
We really do relational database system with vertical scaling.

33
00:02:24.870 --> 00:02:32.940
You have, for example, an audience with T two micro and you want to scale it up and increase the capacity

34
00:02:32.940 --> 00:02:36.120
in terms of CPU or even disk space.

35
00:02:36.120 --> 00:02:42.580
You want to scale it vertically and you want to change it from three to make 32, for example, build.

36
00:02:42.600 --> 00:02:49.020
So if these two small is not enough, you are able also to increase it vertically as well, all the

37
00:02:49.020 --> 00:02:53.000
way to be too large or 3 to 2 users.

38
00:02:53.040 --> 00:02:59.030
Look now to the first also scaling which is Amazon easy two where we can launch or terminate in a sense

39
00:02:59.030 --> 00:03:05.520
is based on our condition and needs and they can automatically register new instances with the load

40
00:03:05.520 --> 00:03:09.750
balancer and they can launch those in instances in a mostly available.

41
00:03:10.230 --> 00:03:14.040
So auto scanning always work in the side the same region.

42
00:03:14.040 --> 00:03:19.890
It will help you to launch multiple instances in multi A-Z but not in multi region.

43
00:03:19.900 --> 00:03:22.830
There is multiple scaling options in us.

44
00:03:22.920 --> 00:03:27.120
The first one is the scheduled one, which is good for a predictable workload.

45
00:03:27.120 --> 00:03:33.420
If you have a customer and you know his workload, he knows how much customer base he has in the end

46
00:03:33.420 --> 00:03:36.680
user, then you can use that kind of casual work.

47
00:03:36.720 --> 00:03:42.030
You could simply say, I want to create an easy two instances every Monday morning.

48
00:03:42.030 --> 00:03:48.660
I want to have four AC, two instances every Monday morning at 9 a.m., and I want to scale them down

49
00:03:48.720 --> 00:03:50.960
every Monday evening at 5 p.m..

50
00:03:51.000 --> 00:03:56.850
You would also have, for example, the option to scale your infrastructure in this specific date.

51
00:03:56.850 --> 00:03:59.490
So maybe you don't need those two instances.

52
00:04:00.120 --> 00:04:04.350
You might just need seven three days out of seven days.

53
00:04:04.350 --> 00:04:07.740
And the second one is called dynamic escape.

54
00:04:07.770 --> 00:04:08.910
With dynamic scaling.

55
00:04:08.910 --> 00:04:13.860
We normally have a scaling target and that monitor is the infrastructure.

56
00:04:13.860 --> 00:04:21.240
And once your easy to in instances reaches a specific threshold, it will trigger the auto scaling.

57
00:04:21.240 --> 00:04:23.040
The last one is predicted.

58
00:04:23.040 --> 00:04:27.570
With the predicted, you will have normally a machine learning component built by us.

59
00:04:27.570 --> 00:04:32.820
It's going to be built by you looking to your data, building your data for one month or two months

60
00:04:32.820 --> 00:04:33.600
or so on.

61
00:04:33.600 --> 00:04:39.360
And based on those data, it's going to predict how much scalability you need for the next.

62
00:04:39.360 --> 00:04:42.600
Maybe there is a next season coming like St Patrick's Day.

63
00:04:42.600 --> 00:04:47.060
Then normally in that day you sell a lot of services and goods ended.

64
00:04:47.350 --> 00:04:53.850
In this case, it will scale your infrastructure and make it proactively ready to meet the new.

65
00:04:54.090 --> 00:04:58.620
So for example, if you have someone who is sitting on the Christmas tree and all of the scaling policy

66
00:04:58.620 --> 00:04:59.850
for him to be scanned.

67
00:05:00.200 --> 00:05:05.600
Only for the Christmas season because nobody will buy a Christmas tree outside the Christmas season.

68
00:05:05.690 --> 00:05:11.180
So in dynamic scaling policies, we have multiple times, we have the symbol scale and they normally

69
00:05:11.180 --> 00:05:12.330
ask about this index.

70
00:05:12.680 --> 00:05:18.800
In single scanning adjustment, you have a new workload, it's a new start, or sometimes you are dealing

71
00:05:18.800 --> 00:05:24.590
with a spiky workload you can to predict you creating a machine for people to want to do a dev or at

72
00:05:24.590 --> 00:05:26.270
this thing of a software.

73
00:05:26.270 --> 00:05:28.610
So you would never know how much capacity they need.

74
00:05:28.640 --> 00:05:33.650
So you can just to create a scaling policy, you could also use a scaling.

75
00:05:33.650 --> 00:05:40.310
With this type of scaling here, you will do the adjustment depending on the size and the metric that

76
00:05:40.310 --> 00:05:41.240
you are monitoring.

77
00:05:41.330 --> 00:05:50.180
For example, if you are watching the CPU level, you can see when CPU is greater than a 22, when CPU

78
00:05:50.210 --> 00:05:58.300
greater than 61, when CPU lower than a 22, when CPU is below ten.

79
00:05:58.310 --> 00:06:05.600
Then dealing with a step of scaling, you can make multiple step adjustment and this is very important

80
00:06:05.600 --> 00:06:06.500
to avoid.

81
00:06:06.510 --> 00:06:08.150
Resource is if crashing.

82
00:06:08.150 --> 00:06:15.620
What you need to do in all cases is to avoid having an auto scaling that could create a lunch and easy

83
00:06:15.620 --> 00:06:18.560
to very quickly and terminate the instance very quick.

84
00:06:18.560 --> 00:06:20.420
This results in two things.

85
00:06:20.420 --> 00:06:23.930
The infrastructure will not be stable in a state in the state.

86
00:06:23.930 --> 00:06:29.600
And the second thing, you will find that the resistance of the data is hard to maintain.

87
00:06:29.600 --> 00:06:35.120
So to avoid resource extraction, creating the resources very quickly and deleting the resources also

88
00:06:35.120 --> 00:06:41.710
very quickly, whether you do the scaling or you make sure when you work a specific metric that the

89
00:06:41.720 --> 00:06:43.760
event is long enough.

90
00:06:43.760 --> 00:06:49.280
So if you live in a greater than six feet, you want this, if you will, able to remain at the minimum

91
00:06:49.280 --> 00:06:54.930
for 5 minutes above 60, then you still specifically when you terminate machines.

92
00:06:54.950 --> 00:07:01.820
So when you skim down, you want to make sure that the CPU is below 20% for a long period of time,

93
00:07:01.820 --> 00:07:07.280
let's say 10 minutes before you can terminate or scale down your easy to an instance.

94
00:07:07.370 --> 00:07:15.170
The first step to create or the scaling is to create an auto scale or in other auto scaling group you

95
00:07:15.170 --> 00:07:21.860
specify the minimum capacity, the maximum, and that is now my view for the desired, regardless what

96
00:07:21.860 --> 00:07:28.610
people really can say in different textbooks references is that if I am monitoring the CPU, so this

97
00:07:28.610 --> 00:07:37.460
is my CPU living and I'm saying if the CPU or if the CPU utilization is above 20%, then you need to

98
00:07:37.460 --> 00:07:38.150
scale up.

99
00:07:38.150 --> 00:07:41.560
So the minimum I have is to the maximum is six.

100
00:07:41.600 --> 00:07:43.730
I'm going to keep adding more machine.

101
00:07:43.740 --> 00:07:47.330
And this is a scale seven scaling policy with R2 scaling.

102
00:07:47.660 --> 00:07:55.690
Now when the CPU reach 60% utilization, I'm going also to scale again and add more AC two instances.

103
00:07:55.790 --> 00:08:04.970
Now I said also is the CPU below 20, I'm going to scale down now what if the CPU is in between 20%

104
00:08:04.970 --> 00:08:07.760
utilization and 60% utilization?

105
00:08:07.760 --> 00:08:14.750
In this particular scenario, you could maintain the desired capacity when everything is working normally,

106
00:08:14.780 --> 00:08:22.940
there is no up in the CPU utilization or down metrics of the sub utilization, and I would love to maintain

107
00:08:22.970 --> 00:08:23.580
that desire.

108
00:08:23.580 --> 00:08:24.230
That's capacity.

109
00:08:24.230 --> 00:08:31.610
With auto scaling, you can create a multiple on demand and and reserve instance and the magic formula

110
00:08:31.610 --> 00:08:32.570
and also support.

111
00:08:32.570 --> 00:08:38.470
In this sense, you can also make more participation from multiple different times of easy.

112
00:08:38.690 --> 00:08:44.470
I prefer normally to have 80% of my capacity via reserve.

113
00:08:44.630 --> 00:08:49.430
In instances do the capacity needs will be met by 80% of a result.

114
00:08:49.430 --> 00:08:56.690
In instances that say I need an easy to in instances as maximum, okay and then I will leave the 20%

115
00:08:56.690 --> 00:09:03.380
for on demand, which means every time I got a spike and a predictable capacity needs, I could create

116
00:09:03.380 --> 00:09:05.730
an ongoing or I could decrease.

117
00:09:05.870 --> 00:09:14.320
Instead of a 20% on demand, I could give it up to ten 20% here and 70% on a reserve.

118
00:09:14.330 --> 00:09:23.450
And then this is you make a better scalability options and also it will make my capacity me cost optimized

119
00:09:23.450 --> 00:09:25.310
so I can make the same thing.

120
00:09:25.310 --> 00:09:31.670
I could reach high level of scalability and I also reach a high level, of course, optimization.

121
00:09:31.670 --> 00:09:37.340
A few things to consider when you do all the scale multiple times of automatically scaling and you fusion

122
00:09:37.340 --> 00:09:42.830
them or hybrid them together and you have to use or look to use symbol or step or target.

123
00:09:42.830 --> 00:09:49.190
The tracking is scaling where you can have multiple metrics or multiple receive instead of having only

124
00:09:49.190 --> 00:09:52.580
the CPU and decide when to scale out and to scale.

125
00:09:52.610 --> 00:09:59.330
And maybe you better use lifecycle help with integration of all the scaling with symbol notification

126
00:09:59.330 --> 00:09:59.840
service.

127
00:09:59.920 --> 00:10:05.420
Or send an email to a service that can tell you that your instances are scaling up.

128
00:10:05.450 --> 00:10:09.490
You can understand the behavior of your system and you reach a convergence.

129
00:10:09.970 --> 00:10:14.900
So look now to create a scaling policy for Amazon easy to auto scaling.

130
00:10:14.920 --> 00:10:17.020
Another thing is to scale your.
