WEBVTT
1
00:00:05.230 --> 00:00:07.840
Or continuing on with the code from the last video.

2
00:00:08.950 --> 00:00:13.810
You might be asking next, how do I say counts by pit type and not just dogs?

3
00:00:14.140 --> 00:00:18.790
Obviously, you do not want to have to write a different statement for each pet type, each with a different

4
00:00:18.790 --> 00:00:21.070
filter, getting count by pet type.

5
00:00:21.970 --> 00:00:25.450
Well, this is actually a job for the collectors dog grouping by method.

6
00:00:26.170 --> 00:00:26.810
Let's have a look at that.

7
00:00:26.810 --> 00:00:29.380
And it's a pencil code to our main method.

8
00:00:29.410 --> 00:00:31.270
And again, we're in stream group in Java.

9
00:00:33.730 --> 00:00:34.480
Except that import.

10
00:00:38.140 --> 00:00:42.630
I'm going to cover the grouping by method in more detail in a bit, but suffice it to say here that

11
00:00:42.630 --> 00:00:47.550
the first statement groups by the Pitts type counting pitts' by pit type.

12
00:00:48.000 --> 00:00:52.440
So factually wrong this now we can see they are put there.

13
00:00:53.160 --> 00:00:57.140
And obviously your results may look different because we're using a random function.

14
00:00:58.140 --> 00:01:00.590
So if I read this again, you see I get a different result.

15
00:01:02.070 --> 00:01:07.320
You can do the work of both statements in one stream pipeline if you do not need to use the information

16
00:01:07.320 --> 00:01:08.210
in any other way.

17
00:01:08.520 --> 00:01:10.450
No assignment to local variable dated.

18
00:01:10.950 --> 00:01:14.190
Let's have a go to replacing the code and we'll do it another way.

19
00:01:15.180 --> 00:01:19.860
Sort of replaces code here as follows if we run this.

20
00:01:23.400 --> 00:01:27.060
So the outputs the same as last time, other than the fact that the numbers are different because of

21
00:01:27.060 --> 00:01:28.440
the fact that we're using random here.

22
00:01:30.880 --> 00:01:36.910
I think you can see now that streams effectively turn your data sets in Java into query about tables

23
00:01:36.910 --> 00:01:43.060
or views and the streaming collectors' methods combined of your features somewhat equivalent to siecle

24
00:01:43.060 --> 00:01:43.710
commands.

25
00:01:44.230 --> 00:01:50.470
So let's actually try a few more examples here or more cardie except the import.

26
00:01:53.850 --> 00:01:59.930
So looking at this code, I'm crewing the data getting the average age of a pit by state and by pit

27
00:01:59.940 --> 00:02:02.550
type and collecting the information into a map.

28
00:02:03.660 --> 00:02:05.730
So look at the grouping by methods.

29
00:02:05.730 --> 00:02:06.690
First argument.

30
00:02:07.740 --> 00:02:14.040
In the previous example I passed, it was a it on pet, but in this example I'm passing it multiple

31
00:02:14.040 --> 00:02:19.380
attributes, method references on pet using a list generated by race track list.

32
00:02:20.040 --> 00:02:23.310
So this results in a map whose key is a list of attributes.

33
00:02:24.000 --> 00:02:29.910
In addition, I'm using the averaging into method as the second parameter to grouping by and passing

34
00:02:29.910 --> 00:02:30.330
this method.

35
00:02:30.330 --> 00:02:31.920
The Pet Age attribute.

36
00:02:32.310 --> 00:02:37.740
A map is returned and now I can specifically query the map for the information I want in this case about

37
00:02:37.740 --> 00:02:40.810
the average age of a dog in the state of Colorado.

38
00:02:40.980 --> 00:02:42.410
That's the CEO abbreviation.

39
00:02:42.810 --> 00:02:43.740
So if we run this now.

40
00:02:47.130 --> 00:02:52.380
We can see the output at the bottom of the screen now, it could have written it as a single stream

41
00:02:52.380 --> 00:02:58.410
pipeline, but I wanted to show you how to connect into a map with a multi-dimensional key and how to

42
00:02:58.410 --> 00:03:02.040
access data from the map returned from the pipeline operations.

43
00:03:02.490 --> 00:03:03.690
Let's look at another example.

44
00:03:05.510 --> 00:03:12.080
Pist is covered in this kind of similar to the previous example, but here I do use a single stream

45
00:03:12.080 --> 00:03:18.860
pipeline to get counterspy by state and type, then sort the data using a multi-dimensional key in the

46
00:03:18.870 --> 00:03:25.130
comparator lambda expression, and then finally to make the output a bit smaller, a filter, it just

47
00:03:25.130 --> 00:03:26.630
dog and cat types.

48
00:03:26.990 --> 00:03:33.310
So if we run this, we can see that the dataset was sorted and filtered accordingly.

49
00:03:35.480 --> 00:03:41.540
The collective grouping method allows you to specify a more specific type you want your data to be collected

50
00:03:41.540 --> 00:03:41.900
into.

51
00:03:42.230 --> 00:03:43.070
Let's have a look at that.

52
00:03:43.520 --> 00:03:44.650
It's going to post McHardy

53
00:03:47.340 --> 00:03:48.620
except import.

54
00:03:49.400 --> 00:03:55.550
So here what I'm doing is I removed the sorted operation in the pipeline and instead of specified,

55
00:03:55.880 --> 00:04:00.170
I want data to be collected into a tree map, which, if you recall, is a sorted map.

56
00:04:00.500 --> 00:04:01.490
So if we run this now.

57
00:04:03.280 --> 00:04:08.950
It's clear that our collection is sorted without any additional work or specification on my part.

58
00:04:10.940 --> 00:04:16.460
What do you use this mechanism on the example where I collect the average age of a pit grouped by multiple

59
00:04:16.460 --> 00:04:22.940
attributes, in the first example, I created a map with a key that was a list of the attributes which

60
00:04:22.940 --> 00:04:25.040
showed a flattened view of the average ages.

61
00:04:25.580 --> 00:04:31.310
In this example that I'm about to paste in and create a map with a nested map allowing me to keep a

62
00:04:31.310 --> 00:04:35.540
hierarchical view of averages within pit types within states.

63
00:04:35.540 --> 00:04:38.420
For example, let's have a look at that postcard in.

64
00:04:41.430 --> 00:04:48.270
So here, my local variable is a map, a tree map keyed by a string picked out state, and the value

65
00:04:48.270 --> 00:04:54.120
was another map tree map also keyed by a string type with a value of long.

66
00:04:54.700 --> 00:04:56.940
They can have pets by pet type and state.

67
00:04:58.200 --> 00:04:59.160
So if we run this now.

68
00:05:01.490 --> 00:05:06.890
And there's the output now that's a nice representation of the data, right, as long as the case is

69
00:05:06.890 --> 00:05:12.650
string's or comparables and a specified trebeck result, sorting is built in.

70
00:05:13.640 --> 00:05:19.710
Finally, there's another static method on collections called Collectors', not partitioning the partitions

71
00:05:19.760 --> 00:05:21.310
stream into a map of two Cege.

72
00:05:21.320 --> 00:05:25.940
True or false, you pass a predicate to the method which then generates a map.

73
00:05:26.690 --> 00:05:29.670
That's the principle code to our method.

74
00:05:31.730 --> 00:05:33.710
So here I'm creating a local variable.

75
00:05:33.920 --> 00:05:37.490
Dogs are not dogs, which is of the top map boolean.

76
00:05:38.060 --> 00:05:44.650
Then a list of pet objects which are top dog go into the true bucket and all others go into the false

77
00:05:44.720 --> 00:05:45.050
bucket.

78
00:05:45.950 --> 00:05:52.700
I use the resulting map to retrieve the list of just dogs and print the first five running this.

79
00:05:54.840 --> 00:05:56.880
We can see the output at the bottom of the screen there.

80
00:05:57.600 --> 00:06:02.210
Now what a posted some more code and we'll ask you a question.

81
00:06:02.490 --> 00:06:03.630
What does this code do?

82
00:06:04.560 --> 00:06:05.250
There's a code.

83
00:06:07.270 --> 00:06:12.790
Well, instead of collecting the pet population into a list of dog pet objects and the list of other

84
00:06:12.790 --> 00:06:19.090
pet objects, this one collects the pet population into a map that lists the can of pets by the veterinary

85
00:06:19.090 --> 00:06:19.690
practice.

86
00:06:20.790 --> 00:06:22.000
They run this now.

87
00:06:25.140 --> 00:06:27.020
We see the output at the bottom of the screen.

88
00:06:31.000 --> 00:06:36.480
The table below lists a few of the methods I've been reviewing in this video and the previous one so

89
00:06:36.480 --> 00:06:40.660
that you can see the signatures keeping in mind that these submitted signatures are simplified.

90
00:06:40.990 --> 00:06:46.120
So looking at the collectors grouping and petitioning methods, keep in mind that all returned collector,

91
00:06:46.360 --> 00:06:51.580
which can be used in the collect method or trained in these methods, first of all, we've got is scraping

92
00:06:51.580 --> 00:06:57.880
by, which accepts a function that allows you to buy a function which is often a method of reference

93
00:06:57.880 --> 00:06:59.320
for a getter on an object.

94
00:06:59.710 --> 00:07:04.420
The result is a collection of elements grouped by the specified attribute, for example.

95
00:07:05.660 --> 00:07:07.760
We've got grouping by, again, overloaded.

96
00:07:08.060 --> 00:07:13.160
This one takes two parameters, a function and a collector, and it allows you to group by a function,

97
00:07:13.440 --> 00:07:18.680
but to use an additional reduction or grouping collector to do some aggregate operations, like getting

98
00:07:18.680 --> 00:07:20.860
a total sum average, et cetera.

99
00:07:21.920 --> 00:07:28.070
The next grouping by method has three parameters function, supplier and collector, and it allows you

100
00:07:28.070 --> 00:07:34.190
to group by a function specifying the type of the collection which the data will be returned to and

101
00:07:34.190 --> 00:07:37.850
use a reduction or grouping collector to do some aggregate operations.

102
00:07:37.880 --> 00:07:40.510
Again, like getting a title with some an average cetera.

103
00:07:41.460 --> 00:07:47.520
Next, petitioning by with a parameter of predicate and allows you to create a map of a boolean and

104
00:07:47.520 --> 00:07:51.180
a list of type T based on some bifocal view of the data.

105
00:07:51.660 --> 00:07:54.670
Next, we have petitioning by which has got two parameters.

106
00:07:54.810 --> 00:07:57.630
The overlayed version, a predicate and a collector.

107
00:07:58.000 --> 00:08:03.330
And it allows you to create a map which is a boolean, an object of type T based on some bifurcated

108
00:08:03.330 --> 00:08:09.330
view of the data and using a reduction or grouping or any other collector to return a ResultSet.

109
00:08:10.930 --> 00:08:15.850
All right, so this video and the previous one covered a lot of ground, but I hope I've introduced

110
00:08:15.850 --> 00:08:22.390
you to the enormous possibilities offered by the combinations of the stream and collectors classes using

111
00:08:22.390 --> 00:08:24.490
a stream pipeline, the exam.

112
00:08:24.490 --> 00:08:29.530
We'll expect you to be familiar with many of the same methods and the most commonly used collectors.

113
00:08:30.280 --> 00:08:32.200
Let's move on now to the next video.
