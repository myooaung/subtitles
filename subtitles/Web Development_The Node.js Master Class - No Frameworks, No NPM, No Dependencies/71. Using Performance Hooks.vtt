WEBVTT
ï»¿1
00:00:00.000 --> 00:00:08.550
there many times when you'll be building or running a no Js application that everything

2
00:00:08.550 --> 00:00:10.090
will technically be working.

3
00:00:10.090 --> 00:00:15.500
But it's just not working at the speed that it was on local host or the speed that it used

4
00:00:15.500 --> 00:00:15.820
to.

5
00:00:15.820 --> 00:00:17.620
Sometimes you introduced a new feature,

6
00:00:17.620 --> 00:00:19.610
and it slows down other features.

7
00:00:19.610 --> 00:00:26.510
And so there are many situations where you need to be able to diagnose where a performance

8
00:00:26.510 --> 00:00:29.150
problem or speed problem is a curry.

9
00:00:29.150 --> 00:00:30.780
In this lecture,

10
00:00:30.780 --> 00:00:33.660
we're going to dive into how to use notes.

11
00:00:33.660 --> 00:00:41.840
Performance Hooks module in order to time the execution of your code to be able to pinpoint

12
00:00:41.840 --> 00:00:44.760
exactly where issues might be occurring.

13
00:00:44.760 --> 00:00:45.610
To do this,

14
00:00:45.610 --> 00:00:48.690
let's go ahead and require this Performance Oaks module.

15
00:00:48.690 --> 00:00:51.210
I'm gonna call it Underscore performance,

16
00:00:51.210 --> 00:01:01.850
and it's going to be require perf hooks with an underscore between them docked performance

17
00:01:01.850 --> 00:01:01.850
.

18
00:01:01.850 --> 00:01:09.790
Now all this performance data that we're going to add to one of our handlers isn't

19
00:01:09.790 --> 00:01:12.460
something that just should be logged out all the time.

20
00:01:12.460 --> 00:01:17.860
We want to log it conditionally only under certain node debug settings,

21
00:01:17.860 --> 00:01:21.450
so let's go ahead and include utilities module.

22
00:01:21.450 --> 00:01:31.760
Far Util equals require you till and then define debug which will use instead of Consul

23
00:01:31.760 --> 00:01:34.320
logging as you till,

24
00:01:34.320 --> 00:01:34.810
uh,

25
00:01:34.810 --> 00:01:35.820
debug log.

26
00:01:35.820 --> 00:01:41.500
But this time the magic phrase will be performance.

27
00:01:41.500 --> 00:01:45.890
So the only way you'll see the console logging that we're doing related to tracking

28
00:01:45.890 --> 00:01:49.420
performance will be if you start the application with node underscore,

29
00:01:49.420 --> 00:01:51.220
debug equals performance.

30
00:01:51.220 --> 00:01:53.010
Have been node index dot Js.

31
00:01:53.010 --> 00:01:56.950
Let's go ahead and move down to where the session tokens are getting created.

32
00:01:56.950 --> 00:01:59.230
So I'm gonna look for handlers.

33
00:01:59.230 --> 00:02:00.750
Tokens post.

34
00:02:00.750 --> 00:02:04.010
This is a fairly straightforward route.

35
00:02:04.010 --> 00:02:10.170
It takes in payload needs to read the user associated with that payload kore EDA hashed

36
00:02:10.170 --> 00:02:15.960
password to compare the password that has been sent from the user to the one that we have

37
00:02:15.960 --> 00:02:16.770
on file.

38
00:02:16.770 --> 00:02:19.320
Then it needs to create a token and persistent to disk.

39
00:02:19.320 --> 00:02:20.480
Then we trying to users.

40
00:02:20.480 --> 00:02:24.490
Now speed has not really been an issue with this route.

41
00:02:24.490 --> 00:02:25.770
But let's say that it is,

42
00:02:25.770 --> 00:02:28.600
and we're not sure why this is occurring.

43
00:02:28.600 --> 00:02:34.690
We're gonna walk through how to augment this handler so that we can benchmark the code

44
00:02:34.690 --> 00:02:37.070
execution at different points in time.

45
00:02:37.070 --> 00:02:39.770
As this code goes through these different steps,

46
00:02:39.770 --> 00:02:44.370
What that's going to look like is we're going to create things called performance marks,

47
00:02:44.370 --> 00:02:50.400
and you can think of performance marks as points in time or pointing code execution that

48
00:02:50.400 --> 00:02:53.050
have a specific label on them we're going to.

49
00:02:53.050 --> 00:02:53.630
Then,

50
00:02:53.630 --> 00:02:54.670
after we look put in,

51
00:02:54.670 --> 00:02:57.160
all of our labels do performance,

52
00:02:57.160 --> 00:03:03.390
measuring and performance measuring allows you to measure the code execution between

53
00:03:03.390 --> 00:03:05.930
different marks that you have set up earlier.

54
00:03:05.930 --> 00:03:06.730
Lastly,

55
00:03:06.730 --> 00:03:10.650
we're going to log out the results of all those measurements.

56
00:03:10.650 --> 00:03:14.150
So let's go ahead and add these performance marks to do so.

57
00:03:14.150 --> 00:03:15.850
It's fairly straightforward.

58
00:03:15.850 --> 00:03:18.210
We just want to call Underscore performance,

59
00:03:18.210 --> 00:03:24.160
which is the name that we gave to this module dot mark and then give it a name.

60
00:03:24.160 --> 00:03:25.480
So in this case,

61
00:03:25.480 --> 00:03:27.760
this name is going to be entered function.

62
00:03:27.760 --> 00:03:30.580
It's fine for these to be human readable.

63
00:03:30.580 --> 00:03:31.350
In fact,

64
00:03:31.350 --> 00:03:34.490
it gives you an advantage when you're creating your reports,

65
00:03:34.490 --> 00:03:39.350
you don't have to remember what Point X y z ABC was you just remembered.

66
00:03:39.350 --> 00:03:43.480
I want to measure from where the function was entered to some other point.

67
00:03:43.480 --> 00:03:45.880
So that's the performance mark.

68
00:03:45.880 --> 00:03:47.250
The next one we want to dio.

69
00:03:47.250 --> 00:03:53.080
It's just below where the inputs have been validated and we will call.

70
00:03:53.080 --> 00:03:55.440
This includes Validated.

71
00:03:55.440 --> 00:03:56.690
Next.

72
00:03:56.690 --> 00:04:01.480
Let's add a performance mark just before this user's data gets red.

73
00:04:01.480 --> 00:04:05.150
So we're gonna call this performance mark Beginning,

74
00:04:05.150 --> 00:04:06.210
user,

75
00:04:06.210 --> 00:04:06.850
look up.

76
00:04:06.850 --> 00:04:09.440
When this function calls back,

77
00:04:09.440 --> 00:04:12.720
let's add a performance mark saying User,

78
00:04:12.720 --> 00:04:13.620
look up.

79
00:04:13.620 --> 00:04:19.730
Complete Now that's moved down to where the password hashing is happening because that

80
00:04:19.730 --> 00:04:21.980
could be taking a significant amount of time.

81
00:04:21.980 --> 00:04:24.630
That could be the thing that is slowing down our system.

82
00:04:24.630 --> 00:04:30.350
So let's put a performance mark right before they have the password saying beginning,

83
00:04:30.350 --> 00:04:38.750
password hashing and after the password hashing function returns saying Password hashing

84
00:04:38.750 --> 00:04:47.180
complete Now Another thing that could be slowing things down is when we're creating this

85
00:04:47.180 --> 00:04:48.090
random string.

86
00:04:48.090 --> 00:04:52.570
And so let's put in a performance mark just before we do that,

87
00:04:52.570 --> 00:04:58.750
saying creating data for the token and then we want to measure everything it's doing right

88
00:04:58.750 --> 00:04:59.260
here.

89
00:04:59.260 --> 00:05:04.320
So we're gonna put in our next performance mark just before we store the token saying,

90
00:05:04.320 --> 00:05:13.560
beginning storing token and then another one after the data create function returns or

91
00:05:13.560 --> 00:05:14.390
calls back,

92
00:05:14.390 --> 00:05:17.750
saying storing token complete.

93
00:05:17.750 --> 00:05:20.240
Now this point,

94
00:05:20.240 --> 00:05:24.880
we don't really care about whether there is an air,

95
00:05:24.880 --> 00:05:27.830
whether we're calling back a 200 or 500 to the user.

96
00:05:27.830 --> 00:05:33.250
We just want to start measuring between these different points and then logging out all

97
00:05:33.250 --> 00:05:34.090
those measurements.

98
00:05:34.090 --> 00:05:42.250
So I want to first gather all the measurements and let's create six of them for this.

99
00:05:42.250 --> 00:05:44.450
We're going to call performance.

100
00:05:44.450 --> 00:05:45.760
Don't measure.

101
00:05:45.760 --> 00:05:50.220
Then we need to pass it three things we need to pass it.

102
00:05:50.220 --> 00:05:52.200
The name of this new measurement,

103
00:05:52.200 --> 00:05:53.880
which could be something of our own creation,

104
00:05:53.880 --> 00:05:59.680
and then the name of two marks that we want to measure the timing between.

105
00:05:59.680 --> 00:06:01.330
So in his first case,

106
00:06:01.330 --> 00:06:05.100
let's call this first measurement beginning to end,

107
00:06:05.100 --> 00:06:13.070
and we're going to measure between this point entered function and this point storing token

108
00:06:13.070 --> 00:06:13.570
complete.

109
00:06:13.570 --> 00:06:16.950
So beginning to end entered,

110
00:06:16.950 --> 00:06:21.450
function and story token complete.

111
00:06:21.450 --> 00:06:29.350
Let's create another measurement that has to do with validating user input.

112
00:06:29.350 --> 00:06:31.700
To figure that out,

113
00:06:31.700 --> 00:06:35.970
we want to measure between where the user entered the function,

114
00:06:35.970 --> 00:06:38.890
so entered function will still be the start point.

115
00:06:38.890 --> 00:06:42.840
But the end point is going to be that the inputs have been validated,

116
00:06:42.840 --> 00:06:45.960
so inputs validated.

117
00:06:45.960 --> 00:06:49.750
Let's create another one called user Look up,

118
00:06:49.750 --> 00:06:56.840
and this is going to measure the time it takes us to actually go fetch the user's data from

119
00:06:56.840 --> 00:06:57.750
the file system.

120
00:06:57.750 --> 00:07:02.530
So we're going to start it with beginning user.

121
00:07:02.530 --> 00:07:05.540
Look up and we're going to end it with user.

122
00:07:05.540 --> 00:07:07.030
Look up complete.

123
00:07:07.030 --> 00:07:12.120
Remember that this performance mark and this performance mark that's created another

124
00:07:12.120 --> 00:07:14.200
measurement for password hashing.

125
00:07:14.200 --> 00:07:21.010
And we're going to have the start point B beginning password,

126
00:07:21.010 --> 00:07:24.380
passion and the endpoint be password,

127
00:07:24.380 --> 00:07:25.150
hash and complete.

128
00:07:25.150 --> 00:07:32.820
That is this point and this point.

129
00:07:32.820 --> 00:07:33.680
Next,

130
00:07:33.680 --> 00:07:37.950
let's create a measurement for token data creation.

131
00:07:37.950 --> 00:07:44.230
So we're actually going to measure between creating data for token and beginning storing

132
00:07:44.230 --> 00:07:44.650
token.

133
00:07:44.650 --> 00:07:55.770
You probably guess what our last special man is going to be.

134
00:07:55.770 --> 00:07:58.750
It is going to be for token storing,

135
00:07:58.750 --> 00:08:01.840
so we're going to measure between these last two points beginning,

136
00:08:01.840 --> 00:08:04.470
storing token and storing token complete.

137
00:08:04.470 --> 00:08:13.850
Now,

138
00:08:13.850 --> 00:08:20.050
all of our measurements exist and they are still gathered up within this performance module

139
00:08:20.050 --> 00:08:20.050
.

140
00:08:20.050 --> 00:08:23.510
This is not going to automatically log anything to the consul at this point.

141
00:08:23.510 --> 00:08:26.790
All we've done is create marks and then create measurements.

142
00:08:26.790 --> 00:08:29.090
In order to get this data out of here,

143
00:08:29.090 --> 00:08:31.510
we need to actually manually lock it out.

144
00:08:31.510 --> 00:08:35.990
The way you do that the way you love out all the measurements.

145
00:08:35.990 --> 00:08:42.500
His first create the measurements array by calling underscore performance.

146
00:08:42.500 --> 00:08:46.790
Don't get entries by type,

147
00:08:46.790 --> 00:08:50.450
and the type is measure.

148
00:08:50.450 --> 00:08:54.620
And this is just this Intacs very particular to the performance module.

149
00:08:54.620 --> 00:08:55.500
At this point.

150
00:08:55.500 --> 00:08:56.260
After you call,

151
00:08:56.260 --> 00:08:59.850
get entries by type measure you have an array of measurements,

152
00:08:59.850 --> 00:09:10.290
so we want to call measurements for each and then cycle through each measurement for us

153
00:09:10.290 --> 00:09:11.280
rather than log it out.

154
00:09:11.280 --> 00:09:15.000
We're going to use this debug that we created up here.

155
00:09:15.000 --> 00:09:17.950
We're actually going to put these measurements out yellow.

156
00:09:17.950 --> 00:09:25.550
So I'm going to go to our server and a copy where we used covered writing before.

157
00:09:25.550 --> 00:09:27.180
Pace that in here.

158
00:09:27.180 --> 00:09:31.150
I'm gonna change the code from 36 to 33 which is gonna make it yellow.

159
00:09:31.150 --> 00:09:33.650
And rather than having this string come out,

160
00:09:33.650 --> 00:09:42.730
I want the string that comes out to be measurement dot name followed by a space and then

161
00:09:42.730 --> 00:09:45.350
measurement duration.

162
00:09:45.350 --> 00:09:48.690
So this is just going to log out the name of the measurement.

163
00:09:48.690 --> 00:09:51.250
The duration diminishment went after another,

164
00:09:51.250 --> 00:09:54.690
and rather than calling console dot log,

165
00:09:54.690 --> 00:09:56.680
it's gonna be called as D book.

166
00:09:56.680 --> 00:09:57.290
Okay,

167
00:09:57.290 --> 00:09:58.670
now let's start this app up.

168
00:09:58.670 --> 00:09:59.130
Remember,

169
00:09:59.130 --> 00:10:03.810
we're not going to see any of these performance metrics getting logged if we don't start it

170
00:10:03.810 --> 00:10:05.810
with the performance debug.

171
00:10:05.810 --> 00:10:12.410
So we're going to call node debug equals performance,

172
00:10:12.410 --> 00:10:19.150
and then node index dot Js Let's go over to post,

173
00:10:19.150 --> 00:10:19.550
man.

174
00:10:19.550 --> 00:10:24.810
I'm gonna send a request to a P I slash tokens post got a 200 back.

175
00:10:24.810 --> 00:10:29.050
Look back here and we see or performance benchmarks locked out,

176
00:10:29.050 --> 00:10:30.550
validating user input.

177
00:10:30.550 --> 00:10:34.150
I took this long beginning to end that long.

178
00:10:34.150 --> 00:10:35.550
User look up.

179
00:10:35.550 --> 00:10:39.050
Password hashing token data creation,

180
00:10:39.050 --> 00:10:40.070
token story.

181
00:10:40.070 --> 00:10:43.070
And these are measured in milliseconds.

182
00:10:43.070 --> 00:10:45.120
Since it's a debug log,

183
00:10:45.120 --> 00:10:50.770
you have the name of the debug flag printed and in the process I d.

184
00:10:50.770 --> 00:10:51.210
But really,

185
00:10:51.210 --> 00:10:54.490
the information that we're looking for is what's coming out in yellow.

186
00:10:54.490 --> 00:10:55.240
So,

187
00:10:55.240 --> 00:10:56.230
as you can see,

188
00:10:56.230 --> 00:11:02.070
using performance marks and performance measurements gives you a really robust way to

189
00:11:02.070 --> 00:11:06.530
analyze exactly what is going on with your code.

190
00:11:06.530 --> 00:11:14.050
The metrics when they come out of the measurement array won't necessarily be in the order

191
00:11:14.050 --> 00:11:16.140
that you originally specified them.

192
00:11:16.140 --> 00:11:18.120
We measured beginning to and first,

193
00:11:18.120 --> 00:11:18.540
but here,

194
00:11:18.540 --> 00:11:20.060
beginning to end It's second,

195
00:11:20.060 --> 00:11:21.810
so you don't want to read this linearly.

196
00:11:21.810 --> 00:11:25.110
We want to keep track of the meaning of each one of these things and look at them

197
00:11:25.110 --> 00:11:25.640
separately.

198
00:11:25.640 --> 00:11:27.000
In our case,

199
00:11:27.000 --> 00:11:31.750
we can see that the thing that took the longest out of any given step besides beginning to

200
00:11:31.750 --> 00:11:33.670
end is token story,

201
00:11:33.670 --> 00:11:37.250
persisting that new token data to disk.

202
00:11:37.250 --> 00:11:39.450
It took us 1.3 milliseconds,

203
00:11:39.450 --> 00:11:45.060
whereas reading out the user data from the disc only took half a millisecond.

204
00:11:45.060 --> 00:11:48.750
So if there is something that we're going to optimize here for performance,

205
00:11:48.750 --> 00:11:55.780
if that 1.3 milliseconds was unacceptable to us than we would start optimizing the token

206
00:11:55.780 --> 00:12:00.250
storing portion and start experimenting with other ways to store that data faster.

207
00:12:00.250 --> 00:12:04.690
So now we can kill this F and move on to the next lecture.

