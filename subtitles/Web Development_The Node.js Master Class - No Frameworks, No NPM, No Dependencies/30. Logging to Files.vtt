WEBVTT
ï»¿1
00:00:00.000 --> 00:00:04.460
At this point,

2
00:00:04.460 --> 00:00:07.500
the back end of our application is fully featured.

3
00:00:07.500 --> 00:00:08.670
In later lectures,

4
00:00:08.670 --> 00:00:12.700
we will add some testing and make some performance adjustments.

5
00:00:12.700 --> 00:00:14.890
But as faras features go,

6
00:00:14.890 --> 00:00:17.350
we have everything that we need.

7
00:00:17.350 --> 00:00:20.380
The last bits that we want to add now,

8
00:00:20.380 --> 00:00:21.050
however,

9
00:00:21.050 --> 00:00:22.580
are about logging,

10
00:00:22.580 --> 00:00:28.570
so we're not gonna be adding more services or user facing background workers.

11
00:00:28.570 --> 00:00:36.490
But we will be adding the ability for an admin like us to see and use logs a little bit

12
00:00:36.490 --> 00:00:38.620
easier in this lecture.

13
00:00:38.620 --> 00:00:44.180
We're gonna go over logging to physical files on the file system,

14
00:00:44.180 --> 00:00:45.610
and in the next lecture,

15
00:00:45.610 --> 00:00:50.260
we're going to talk more about log in to the console in more advanced ways.

16
00:00:50.260 --> 00:00:52.750
So returning to the workers file,

17
00:00:52.750 --> 00:00:57.260
let's log out any time a check is performed.

18
00:00:57.260 --> 00:00:59.950
And let's just log what happened.

19
00:00:59.950 --> 00:01:03.510
The outcome of the check the new state of the U.

20
00:01:03.510 --> 00:01:04.170
R L,

21
00:01:04.170 --> 00:01:09.120
and whether or not an alert is warranted before we log it to a file,

22
00:01:09.120 --> 00:01:13.490
let's just log it to the council here so we can see what's coming.

23
00:01:13.490 --> 00:01:23.150
So we'll law check outcome state an alert warranted.

24
00:01:23.150 --> 00:01:29.220
I'm going to start up the app again and remember the checks won't run immediately when the

25
00:01:29.220 --> 00:01:30.050
APP starts,

26
00:01:30.050 --> 00:01:36.970
and then again a minute later so we can see that these 1st 2 logs for the two existing

27
00:01:36.970 --> 00:01:38.540
checks have come through.

28
00:01:38.540 --> 00:01:40.040
There is no air.

29
00:01:40.040 --> 00:01:45.920
The response code that this one got was 302 The response code for this one was 301 and they

30
00:01:45.920 --> 00:01:47.250
were both up.

31
00:01:47.250 --> 00:01:49.620
They had both previously been up,

32
00:01:49.620 --> 00:01:53.250
and so no alert was needed in either case.

33
00:01:53.250 --> 00:01:59.730
Now it is going to kill that and let's make the workers run a little bit quicker so that we

34
00:01:59.730 --> 00:02:02.240
can see logs coming in a little bit faster.

35
00:02:02.240 --> 00:02:09.080
I'm gonna change this to run every five seconds instead of 60 and we'll see these two lines

36
00:02:09.080 --> 00:02:12.670
appear over and over again once every five seconds.

37
00:02:12.670 --> 00:02:18.070
Okay,

38
00:02:18.070 --> 00:02:19.730
now that that's ran a few times,

39
00:02:19.730 --> 00:02:20.650
we can kill that.

40
00:02:20.650 --> 00:02:26.720
What you just saw happen in the console is basically the same thing that we are going to

41
00:02:26.720 --> 00:02:27.440
want to do.

42
00:02:27.440 --> 00:02:32.370
But we want to send it to actual log files and then later on,

43
00:02:32.370 --> 00:02:38.940
we're going to write a worker that will rotate the log files and compress them to make room

44
00:02:38.940 --> 00:02:45.210
on the file system and make it easier to manage the logs and look for longs at a past date

45
00:02:45.210 --> 00:02:45.210
.

46
00:02:45.210 --> 00:02:46.560
But for now,

47
00:02:46.560 --> 00:02:52.480
let's just focus on actually writing these kind of logs to a log file.

48
00:02:52.480 --> 00:02:57.140
So back up to where we console locked out,

49
00:02:57.140 --> 00:03:02.900
actually want to add a couple more parameters to what needs to be loved.

50
00:03:02.900 --> 00:03:04.090
First,

51
00:03:04.090 --> 00:03:10.250
I want to say log the outcome of the check.

52
00:03:10.250 --> 00:03:14.150
I want to love the original check data,

53
00:03:14.150 --> 00:03:17.340
Then the Czech outcome,

54
00:03:17.340 --> 00:03:18.450
the state,

55
00:03:18.450 --> 00:03:19.310
whether or not alert,

56
00:03:19.310 --> 00:03:20.150
was warranted,

57
00:03:20.150 --> 00:03:26.850
and then the time of the check time of check should equal date now.

58
00:03:26.850 --> 00:03:37.590
And so I'm actually going to pull the time of check into a variable and then use that

59
00:03:37.590 --> 00:03:39.220
variable anywhere.

60
00:03:39.220 --> 00:03:40.890
We had needed date now,

61
00:03:40.890 --> 00:03:49.860
So I'm gonna move this stuff above here and use time of check as variable for last checked

62
00:03:49.860 --> 00:03:49.860
.

63
00:03:49.860 --> 00:03:53.980
So we're still logging this the console and the next thing we'll do is change that.

64
00:03:53.980 --> 00:03:54.850
But for now,

65
00:03:54.850 --> 00:03:56.970
that's running again.

66
00:03:56.970 --> 00:03:58.670
See all that data coming through?

67
00:03:58.670 --> 00:04:03.150
You can see that it's a much larger alert to go to the console,

68
00:04:03.150 --> 00:04:07.720
and this is one of the reasons that we want to send it to an actual mark file.

69
00:04:07.720 --> 00:04:14.050
Is this much data coming to the console is just very hard to grok for the user.

70
00:04:14.050 --> 00:04:15.650
So let's kill that.

71
00:04:15.650 --> 00:04:17.120
And now,

72
00:04:17.120 --> 00:04:23.620
rather than calling console dot log let's call workers dot log workers don't log doesn't

73
00:04:23.620 --> 00:04:24.280
exist yet.

74
00:04:24.280 --> 00:04:29.960
So now we can go about writing this function which takes in all these parameters and then

75
00:04:29.960 --> 00:04:31.550
rights it to a file.

76
00:04:31.550 --> 00:04:36.770
So I'm going to go down here just above where we put in the loop and actually start writing

77
00:04:36.770 --> 00:04:42.370
this function when you say workers don't log equals a function that takes in all these

78
00:04:42.370 --> 00:04:43.250
parameters.

79
00:04:43.250 --> 00:04:51.370
And since this is really just a private function only used here,

80
00:04:51.370 --> 00:04:53.420
we don't need to do much sanity checking.

81
00:04:53.420 --> 00:05:00.050
So let's say that we want to form the log data and then we'll go about actually writing it

82
00:05:00.050 --> 00:05:00.050
.

83
00:05:00.050 --> 00:05:03.650
We're gonna see the log data is an object.

84
00:05:03.650 --> 00:05:06.420
Our logs,

85
00:05:06.420 --> 00:05:08.790
they're going to be written as Jason.

86
00:05:08.790 --> 00:05:15.550
So we're just gonna form these big JavaScript objects were gonna say that check equals

87
00:05:15.550 --> 00:05:21.550
original check data outcome vehicles check out.

88
00:05:21.550 --> 00:05:25.420
Come state equal.

89
00:05:25.420 --> 00:05:42.360
State alert equals whether or not an alert was warranted and time because the time of now

90
00:05:42.360 --> 00:05:46.770
that we have log data object that's converted onto a string so that we can do something

91
00:05:46.770 --> 00:05:47.170
with it.

92
00:05:47.170 --> 00:06:07.550
And now let's figure out what to call the log file that we're ready to.

93
00:06:07.550 --> 00:06:15.930
So there's a lots of different ways to write walk files.

94
00:06:15.930 --> 00:06:18.950
You can write all your logs to the same file.

95
00:06:18.950 --> 00:06:23.600
Or you could write different logs for different users or different logs for different

96
00:06:23.600 --> 00:06:24.210
checks.

97
00:06:24.210 --> 00:06:25.520
We're going to decide,

98
00:06:25.520 --> 00:06:26.040
Teoh,

99
00:06:26.040 --> 00:06:26.620
right,

100
00:06:26.620 --> 00:06:28.930
different logs for different checks.

101
00:06:28.930 --> 00:06:30.200
And then later on,

102
00:06:30.200 --> 00:06:32.950
we'll go about splitting those logs up by time.

103
00:06:32.950 --> 00:06:35.040
Step So there will be one log.

104
00:06:35.040 --> 00:06:41.260
That is about this check from this time to this time and another log that is about that

105
00:06:41.260 --> 00:06:43.550
same check from another time to another time.

106
00:06:43.550 --> 00:06:45.130
So for now,

107
00:06:45.130 --> 00:06:52.640
all we need to worry about is writing this log to a log file whose name is the same as the

108
00:06:52.640 --> 00:06:53.310
check I D.

109
00:06:53.310 --> 00:07:01.970
So we're gonna say that the log file name is original Check data that i d.

110
00:07:01.970 --> 00:07:05.650
Now that we know which file we want to write to,

111
00:07:05.650 --> 00:07:07.460
and we have the string that we want to write,

112
00:07:07.460 --> 00:07:13.510
all we need to do is upend the log string to the file we want to write to.

113
00:07:13.510 --> 00:07:14.400
For that,

114
00:07:14.400 --> 00:07:17.780
we're going to call the function and a library that doesn't exist yet.

115
00:07:17.780 --> 00:07:20.400
So we're gonna call logs append,

116
00:07:20.400 --> 00:07:23.450
pass it the log file name,

117
00:07:23.450 --> 00:07:25.850
pass it the log string,

118
00:07:25.850 --> 00:07:30.050
and then it'll pass us back and error.

119
00:07:30.050 --> 00:07:37.240
We're going to say if there's no air and we'll log out to the console,

120
00:07:37.240 --> 00:07:41.350
that logging to file succeeded.

121
00:07:41.350 --> 00:07:44.260
And if there is an air,

122
00:07:44.260 --> 00:07:51.000
we're gonna log out to the console that logging to file failed.

123
00:07:51.000 --> 00:07:52.700
Now,

124
00:07:52.700 --> 00:07:53.290
obviously,

125
00:07:53.290 --> 00:07:58.340
we're going to need to create to this log library and the A pen function that lives inside

126
00:07:58.340 --> 00:07:58.690
of it.

127
00:07:58.690 --> 00:07:59.980
But before we do,

128
00:07:59.980 --> 00:08:06.600
let's go ahead and move up and require it where we know what's going toe live.

129
00:08:06.600 --> 00:08:13.190
So we're going to say of our logs equals require dot,

130
00:08:13.190 --> 00:08:14.230
slash logs.

131
00:08:14.230 --> 00:08:19.450
Now we can go about actually creating that file.

132
00:08:19.450 --> 00:08:31.550
So now logs dot Js lives inside lip border,

133
00:08:31.550 --> 00:08:35.490
which is the same quarter that this workers file lives in.

134
00:08:35.490 --> 00:08:42.940
So now let's go about actually rating this logs append function in that new file that we

135
00:08:42.940 --> 00:08:43.530
just created.

136
00:08:43.530 --> 00:08:58.850
So I'm gonna open it up and say that this is a library for storing and rotating blog's.

137
00:08:58.850 --> 00:09:06.590
This is going to have a few dependencies that will go into in more detail later.

138
00:09:06.590 --> 00:09:07.810
But for now to snow,

139
00:09:07.810 --> 00:09:09.040
we need FS,

140
00:09:09.040 --> 00:09:12.050
which is the file system.

141
00:09:12.050 --> 00:09:16.350
We're going to need path which we've used before,

142
00:09:16.350 --> 00:09:22.080
and we're gonna need a library we haven't mentioned yet called Z lib,

143
00:09:22.080 --> 00:09:26.550
which is all about compressing and decompressing files.

144
00:09:26.550 --> 00:09:29.900
That's the lib equals require.

145
00:09:29.900 --> 00:09:34.380
We're going to want to store this library inside of a container.

146
00:09:34.380 --> 00:09:39.250
So we say container for the module,

147
00:09:39.250 --> 00:09:44.930
he's gonna call it live and down at the bottom.

148
00:09:44.930 --> 00:10:01.540
We are going to export it now.

149
00:10:01.540 --> 00:10:03.120
Where we going to rate?

150
00:10:03.120 --> 00:10:09.730
These logs were going to do something similar to what we did in data where we in the root

151
00:10:09.730 --> 00:10:16.750
directory created a dot data folder but instead is going to be a dot logs for So let's go

152
00:10:16.750 --> 00:10:18.200
ahead and create that.

153
00:10:18.200 --> 00:10:26.100
We're gonna say week directory dot logs And now we have a place for all these logs to go.

154
00:10:26.100 --> 00:10:30.050
But just like we did for the data library here,

155
00:10:30.050 --> 00:10:36.160
we need to establish at the top of our file the base directory that we're going to be

156
00:10:36.160 --> 00:10:36.750
working in.

157
00:10:36.750 --> 00:10:46.090
And whereas for data it was a dot data folder for logs,

158
00:10:46.090 --> 00:10:51.180
it's going to be looks now.

159
00:10:51.180 --> 00:10:54.820
We can go ahead and start writing that upend function,

160
00:10:54.820 --> 00:11:01.450
so this function will be upend a strength to a file.

161
00:11:01.450 --> 00:11:08.550
Create the file if it does not exist.

162
00:11:08.550 --> 00:11:11.740
River If we're doing with check X y Z,

163
00:11:11.740 --> 00:11:16.550
we're going to be attempting to write that Jason string to a file called X Y C.

164
00:11:16.550 --> 00:11:21.280
If that file does not exist yet because it's the first time we've written it or because

165
00:11:21.280 --> 00:11:25.390
later on we might have rotated that log out or compress the old one,

166
00:11:25.390 --> 00:11:30.960
we want to go ahead and create the file before a pending anything to it.

167
00:11:30.960 --> 00:11:32.850
So live append.

168
00:11:32.850 --> 00:11:40.390
It's going to be a function that takes in a file name the string that should be appended

169
00:11:40.390 --> 00:11:41.890
and a call back.

170
00:11:41.890 --> 00:11:50.750
So we're going to do similar things to what we did in the data file.

171
00:11:50.750 --> 00:11:56.470
We are going to start by opening the file for a pending.

172
00:11:56.470 --> 00:11:59.430
For that,

173
00:11:59.430 --> 00:12:05.750
we're going to use F esta open call the base directory.

174
00:12:05.750 --> 00:12:14.180
I had the file name add dot log because we might as well call it dot log.

175
00:12:14.180 --> 00:12:15.550
Since they are log files,

176
00:12:15.550 --> 00:12:20.890
we're going to use the A switch because we're opening it for a pending and we want it to be

177
00:12:20.890 --> 00:12:21.290
created.

178
00:12:21.290 --> 00:12:29.470
If it does not exist and they will pass back in air and a file descriptor,

179
00:12:29.470 --> 00:12:36.450
if there is not an air and there is a file descriptor we want to continue,

180
00:12:36.450 --> 00:12:42.350
Otherwise we want to call back the error.

181
00:12:42.350 --> 00:12:46.950
Could not open file for a pending,

182
00:12:46.950 --> 00:12:48.870
but if everything was fine,

183
00:12:48.870 --> 00:12:53.450
we want to append to the file and close it.

184
00:12:53.450 --> 00:12:58.230
So we will say F s that attend file,

185
00:12:58.230 --> 00:13:00.550
which is a built in function in that module.

186
00:13:00.550 --> 00:13:08.010
We want to pass it to file descriptor and then the string.

187
00:13:08.010 --> 00:13:11.440
And then we're actually going to add on slash end,

188
00:13:11.440 --> 00:13:13.260
which is a new line character,

189
00:13:13.260 --> 00:13:18.230
because we're going to be adding on Jason Jason one line at a time.

190
00:13:18.230 --> 00:13:23.530
And we might as well add a new line character after each Jason string that we add just to

191
00:13:23.530 --> 00:13:29.070
make it easier to parse both visually and programmatically later on,

192
00:13:29.070 --> 00:13:31.250
that's gonna pass us back in air.

193
00:13:31.250 --> 00:13:35.340
So we will say if there is not an error,

194
00:13:35.340 --> 00:13:37.190
that the impending work fine.

195
00:13:37.190 --> 00:13:39.140
And we want to go ahead and close the file.

196
00:13:39.140 --> 00:13:50.050
But if pending the file hit in error do we want to call back here a pending to file

197
00:13:50.050 --> 00:13:53.110
Everything was fine,

198
00:13:53.110 --> 00:13:54.170
as I mentioned.

199
00:13:54.170 --> 00:13:56.770
Will call fs dot clothes,

200
00:13:56.770 --> 00:13:58.750
pass a file descriptor.

201
00:13:58.750 --> 00:14:01.250
They'll pass us back an air.

202
00:14:01.250 --> 00:14:05.350
If there is no air,

203
00:14:05.350 --> 00:14:10.980
we'll call back false because we use an air back.

204
00:14:10.980 --> 00:14:13.250
But if there was an error,

205
00:14:13.250 --> 00:14:21.650
we'll call back air closing file that waas being upended.

206
00:14:21.650 --> 00:14:24.040
Okay,

207
00:14:24.040 --> 00:14:25.780
so that's the entire pen function.

208
00:14:25.780 --> 00:14:28.940
So let's go ahead and try to run the APP again,

209
00:14:28.940 --> 00:14:32.870
see if these new files gets created in this directory.

210
00:14:32.870 --> 00:14:37.450
And if the data gets appended to it started up.

211
00:14:37.450 --> 00:14:45.540
We got logging to file succeeded and no alert needed,

212
00:14:45.540 --> 00:14:48.040
which is the old logging that we used to do again.

213
00:14:48.040 --> 00:14:49.000
Five seconds later,

214
00:14:49.000 --> 00:14:50.630
we got longing to file succeeded,

215
00:14:50.630 --> 00:14:52.650
and it seems to be working fine.

216
00:14:52.650 --> 00:14:55.000
So if he opened up these files,

217
00:14:55.000 --> 00:15:01.350
we should see three in each of them and we do.

218
00:15:01.350 --> 00:15:06.980
Each line has a different time stamp and they're all on new lines.

219
00:15:06.980 --> 00:15:08.840
But besides that,

220
00:15:08.840 --> 00:15:13.780
they are pretty much all the same because none of this information was changing.

221
00:15:13.780 --> 00:15:21.630
All the checks said that the state was up and there was no need to alert the user,

222
00:15:21.630 --> 00:15:23.140
so alert was always false.

223
00:15:23.140 --> 00:15:23.870
All right,

224
00:15:23.870 --> 00:15:25.750
so the logging is working fine.

225
00:15:25.750 --> 00:15:27.320
But as you can imagine,

226
00:15:27.320 --> 00:15:31.350
even though this is only going to be running once every minute instead of once every five

227
00:15:31.350 --> 00:15:31.890
minutes,

228
00:15:31.890 --> 00:15:35.300
these log files will get pretty big pretty quickly.

229
00:15:35.300 --> 00:15:37.880
And so once a day,

230
00:15:37.880 --> 00:15:42.880
we want to take a lot of files that have gotten full with data over the last day and use

231
00:15:42.880 --> 00:15:45.320
the Z Lib library to compress them.

232
00:15:45.320 --> 00:15:47.430
Make them a small is possible.

233
00:15:47.430 --> 00:15:50.010
They should be able to make them very small because,

234
00:15:50.010 --> 00:15:51.040
as you can see,

235
00:15:51.040 --> 00:15:52.650
there are a lot of repetitive data,

236
00:15:52.650 --> 00:15:55.270
so we want to make them very small,

237
00:15:55.270 --> 00:15:59.130
then allow the app to add today's logs.

238
00:15:59.130 --> 00:16:01.250
Today's Jason in a fresh,

239
00:16:01.250 --> 00:16:05.780
empty file instead of a pending to a larger and larger file,

240
00:16:05.780 --> 00:16:08.740
and after we compress the old logs,

241
00:16:08.740 --> 00:16:12.870
we want to save them with a time stamp in their name,

242
00:16:12.870 --> 00:16:18.300
so that if we want to look up the logs from that say January 1st,

243
00:16:18.300 --> 00:16:25.990
All we have to do is figure out what the file name would be for January 1st and decompress

244
00:16:25.990 --> 00:16:26.820
that file,

245
00:16:26.820 --> 00:16:28.150
then read the contents within it.

246
00:16:28.150 --> 00:16:31.190
All of that will make more sense as we go through this.

247
00:16:31.190 --> 00:16:31.810
For now,

248
00:16:31.810 --> 00:16:37.220
I'm just going to close these logs and let's go back to the Workers Tab,

249
00:16:37.220 --> 00:16:40.780
where we're going to add a new loop to the initialization script,

250
00:16:40.780 --> 00:16:45.670
telling the workers to go about compressing and modifying the laws.

251
00:16:45.670 --> 00:16:49.280
What we call rotate him the logs once every 24 hours.

252
00:16:49.280 --> 00:16:50.430
Right before you do that,

253
00:16:50.430 --> 00:16:55.590
I'm just going to change this back to Ron wants a minute instead of what's every five

254
00:16:55.590 --> 00:16:57.510
seconds clear out the terminal.

255
00:16:57.510 --> 00:17:00.960
Now let's add those workers.

256
00:17:00.960 --> 00:17:03.150
The moment the APP starts up,

257
00:17:03.150 --> 00:17:07.750
we want to call one worker called Rotate Logs,

258
00:17:07.750 --> 00:17:14.810
and that is going to compress all the logs immediately so that an act that is just starting

259
00:17:14.810 --> 00:17:20.370
up will have all fresh logs for its services to write to.

260
00:17:20.370 --> 00:17:29.520
We're just gonna call that workers dot rotate logs the other function that we want to call

261
00:17:29.520 --> 00:17:30.950
in the initialization script.

262
00:17:30.950 --> 00:17:43.570
I will call the compression loop so logs will be compressed made around for that,

263
00:17:43.570 --> 00:17:52.060
we're gonna call workers dot log rotation that log rotation loop going to work much in the

264
00:17:52.060 --> 00:17:54.220
way the workers dot loop does.

265
00:17:54.220 --> 00:18:01.360
Whereas it is just going to call rotate logs once every 24 hours so we can go ahead and

266
00:18:01.360 --> 00:18:04.860
write that it is a very small function.

267
00:18:04.860 --> 00:18:16.950
It is a timer to execute the log rotation process once per day.

268
00:18:16.950 --> 00:18:28.880
So we're going to say workers log rotation loop is a function and I'm in a copy working

269
00:18:28.880 --> 00:18:33.740
start loop excrete to do the same thing.

270
00:18:33.740 --> 00:18:35.120
We're gonna set an interval.

271
00:18:35.120 --> 00:18:37.480
But instead of calling workers don't gather all checks,

272
00:18:37.480 --> 00:18:38.790
we're gonna call workers duck,

273
00:18:38.790 --> 00:18:43.660
rotate logs and instead of calling it once a minute,

274
00:18:43.660 --> 00:18:45.520
we're gonna call it once a day.

275
00:18:45.520 --> 00:18:49.160
So 1000 most seconds in a second,

276
00:18:49.160 --> 00:18:51.660
60 seconds in a minute,

277
00:18:51.660 --> 00:18:54.160
60 minutes in an hour,

278
00:18:54.160 --> 00:18:55.950
24 hours in a day.

279
00:18:55.950 --> 00:18:57.270
So now,

280
00:18:57.270 --> 00:18:58.780
once per day,

281
00:18:58.780 --> 00:18:59.870
this will get cold.

282
00:18:59.870 --> 00:19:03.590
So now we need to go about righting what it's calling rate.

283
00:19:03.590 --> 00:19:05.640
The rotate logs function.

284
00:19:05.640 --> 00:19:07.180
So just above it,

285
00:19:07.180 --> 00:19:12.690
I'm going to write that function which will be to rotate,

286
00:19:12.690 --> 00:19:14.470
make a compress,

287
00:19:14.470 --> 00:19:25.480
the log files workers rotate logs is in function doesn't take any parameters.

288
00:19:25.480 --> 00:19:38.010
What is going to do is start by listing all the non compressed log files that are sitting

289
00:19:38.010 --> 00:19:40.710
in the dark logs for the dot log.

290
00:19:40.710 --> 00:19:47.230
Supporter as time goes on is going to be full of compressed files that are already stepped

291
00:19:47.230 --> 00:19:50.670
up and un compressed files that need to be compressed.

292
00:19:50.670 --> 00:19:55.660
So the first thing we need to do is list everything that needs to be compressed.

293
00:19:55.660 --> 00:19:59.550
So we're going to start calling a bunch of functions that don't exist yet.

294
00:19:59.550 --> 00:20:03.350
Then we're going to go in and actually write those functions so that first function that

295
00:20:03.350 --> 00:20:07.260
doesn't exist is called logs dot list.

296
00:20:07.260 --> 00:20:10.220
We're gonna pass it false,

297
00:20:10.220 --> 00:20:11.180
because when we write it,

298
00:20:11.180 --> 00:20:16.230
we're gonna allow the user whoever's calling this function to pass it a Boolean indicating

299
00:20:16.230 --> 00:20:23.270
whether or not it should include compressed files in its list that it gives out of all the

300
00:20:23.270 --> 00:20:24.240
logs in the forger.

301
00:20:24.240 --> 00:20:27.160
If you say long stout list true,

302
00:20:27.160 --> 00:20:30.590
then it will give you all of the logs,

303
00:20:30.590 --> 00:20:33.220
including the compressed ones.

304
00:20:33.220 --> 00:20:37.440
But we want Teoh just have the non compress one,

305
00:20:37.440 --> 00:20:41.630
so we're gonna pass it false so longs dot list false,

306
00:20:41.630 --> 00:20:48.950
and it's going to pass us back and air and a whole bunch of logs in array.

307
00:20:48.950 --> 00:21:00.980
So if there is not an air and there are logs and the logs have a length,

308
00:21:00.980 --> 00:21:02.480
then we'll continue on.

309
00:21:02.480 --> 00:21:03.840
Otherwise,

310
00:21:03.840 --> 00:21:12.660
we're going to simply log out here I could not find,

311
00:21:12.660 --> 00:21:14.580
and he logs to rotate.

312
00:21:14.580 --> 00:21:18.780
But if we were able to find a whole bunch of logs that need to be compressed,

313
00:21:18.780 --> 00:21:23.770
then we are going to call logs for each and started looping through them.

314
00:21:23.770 --> 00:21:33.620
So as we go through each one,

315
00:21:33.620 --> 00:21:38.950
we want to compress the data to a different file,

316
00:21:38.950 --> 00:21:44.290
and then we'll go about actually emptying out or truncating that log file that we're

317
00:21:44.290 --> 00:21:44.900
working with.

318
00:21:44.900 --> 00:21:55.440
So we want to say that the log I D that we are getting that's coming from this log name is

319
00:21:55.440 --> 00:21:57.900
going to be the same as the log name,

320
00:21:57.900 --> 00:22:03.950
except we need to replace dot log with an empty string,

321
00:22:03.950 --> 00:22:09.990
just like we had to strip Jason off of the files that we were storing in the data folder.

322
00:22:09.990 --> 00:22:14.560
We need to strip dot log off of the logs that were storing in the dot logs quarter.

323
00:22:14.560 --> 00:22:18.910
So the i d is the same file name without doubt.

324
00:22:18.910 --> 00:22:19.340
Log.

325
00:22:19.340 --> 00:22:22.840
So the new file i d.

326
00:22:22.840 --> 00:22:28.260
The new compressed file that we're going to create is going to be the same log I d.

327
00:22:28.260 --> 00:22:35.550
But we're going to add on a dash and in the current time stamp.

328
00:22:35.550 --> 00:22:41.620
So it will be very easy to identify which logs are compressed in which aren't the UN

329
00:22:41.620 --> 00:22:46.820
compressed logs that just getting filled up with today's data are going to be just an i.

330
00:22:46.820 --> 00:22:47.340
D.

331
00:22:47.340 --> 00:22:56.070
And the compressed logs that reference data from yesterday or some day in the past are

332
00:22:56.070 --> 00:22:57.530
going to be an I D.

333
00:22:57.530 --> 00:23:04.360
And then a dash and then a date timestamp representing the moment in time that that log was

334
00:23:04.360 --> 00:23:05.050
compressed.

335
00:23:05.050 --> 00:23:06.990
So now we have the new file i d.

336
00:23:06.990 --> 00:23:09.350
We can call another function that doesn't exist yet,

337
00:23:09.350 --> 00:23:12.050
which is logs compress.

338
00:23:12.050 --> 00:23:15.660
We want to tell it to compress log I d.

339
00:23:15.660 --> 00:23:21.600
So we're identifying the log and we want to move everything to new file I D.

340
00:23:21.600 --> 00:23:24.490
And we want to get back in air.

341
00:23:24.490 --> 00:23:32.050
If there is no air will continue.

342
00:23:32.050 --> 00:23:45.080
But if there is an air than we want Teoh log out air compressing one of the log files and

343
00:23:45.080 --> 00:23:47.660
we might have sold log out whatever that error Waas.

344
00:23:47.660 --> 00:23:49.550
But if there is no air,

345
00:23:49.550 --> 00:23:55.710
then we want to go about truncating the log and by truncating log,

346
00:23:55.710 --> 00:24:02.860
I mean emptying everything out of the original log file that we are rotating through that

347
00:24:02.860 --> 00:24:04.520
came to us as log name.

348
00:24:04.520 --> 00:24:05.660
So in other words,

349
00:24:05.660 --> 00:24:12.320
emptying out this log file after we've gone about taking the contents out of it and moving

350
00:24:12.320 --> 00:24:14.660
the contents to a new compressed file.

351
00:24:14.660 --> 00:24:17.040
So we're gonna truncate the log,

352
00:24:17.040 --> 00:24:21.080
which means we'll call it logs dot truncate,

353
00:24:21.080 --> 00:24:22.850
which also doesn't exist yet.

354
00:24:22.850 --> 00:24:24.530
Pass it a log,

355
00:24:24.530 --> 00:24:29.100
I d and expect back an error.

356
00:24:29.100 --> 00:24:35.690
If there is no error,

357
00:24:35.690 --> 00:24:43.760
we're going to log out success truncating log file.

358
00:24:43.760 --> 00:24:47.570
And if there is an air,

359
00:24:47.570 --> 00:24:56.350
we're going toe long out here truncating log file.

360
00:24:56.350 --> 00:25:01.160
So that's everything that we need to do in the workers file.

361
00:25:01.160 --> 00:25:02.170
But as you can see,

362
00:25:02.170 --> 00:25:03.970
we've gotta work cut out for us.

363
00:25:03.970 --> 00:25:08.810
We need these new functions were in in this new logs library.

364
00:25:08.810 --> 00:25:10.160
So let's go about doing that.

365
00:25:10.160 --> 00:25:13.160
We might as well start with logs dot list.

366
00:25:13.160 --> 00:25:15.160
As I mentioned,

367
00:25:15.160 --> 00:25:23.650
this function is going to list all of the logs and optionally include the compressed bugs,

368
00:25:23.650 --> 00:25:27.080
and it's going to optionally include them via that 1,000,000,000.

369
00:25:27.080 --> 00:25:37.440
So live that list is a function that takes in a boolean of whether or not they should

370
00:25:37.440 --> 00:25:44.100
include compressed logs in the list and a call back.

371
00:25:44.100 --> 00:25:47.660
We're going to use the file system,

372
00:25:47.660 --> 00:25:54.270
function re adder or however you say it.

373
00:25:54.270 --> 00:26:03.260
We're gonna call the base directory and they're gonna passes back and air and data.

374
00:26:03.260 --> 00:26:11.760
We're going to say If there is no air and there is data and that data array has a length,

375
00:26:11.760 --> 00:26:14.640
then we'll continue.

376
00:26:14.640 --> 00:26:15.740
Otherwise,

377
00:26:15.740 --> 00:26:23.460
we're just going to call back the air and the data to whoever called us If everything was

378
00:26:23.460 --> 00:26:23.990
fine,

379
00:26:23.990 --> 00:26:30.090
we want to create an empty array that will eventually hold all the trimmed file names,

380
00:26:30.090 --> 00:26:33.850
the file names without the dot log on them.

381
00:26:33.850 --> 00:26:37.450
So we're going to say data for each.

382
00:26:37.450 --> 00:26:41.410
It's going to be a function that gives us file name.

383
00:26:41.410 --> 00:26:47.610
And now the strings that we add to the array would depend on whether or not this string

384
00:26:47.610 --> 00:26:51.250
represents and it compressed log and whether or not.

385
00:26:51.250 --> 00:26:53.590
We're supposed to include the compressed logs.

386
00:26:53.590 --> 00:26:58.160
So the first bit of data will be just for the dot log files.

387
00:26:58.160 --> 00:27:01.050
So add the dot log files,

388
00:27:01.050 --> 00:27:03.280
which we always want to do.

389
00:27:03.280 --> 00:27:13.950
So we want to say that if the file name index of dot log is greater,

390
00:27:13.950 --> 00:27:16.320
the negative one.

391
00:27:16.320 --> 00:27:17.050
So in other words,

392
00:27:17.050 --> 00:27:20.250
if the file name includes the string dot log,

393
00:27:20.250 --> 00:27:29.670
then we can go ahead and push that name onto the array after we strip off dot log So trump

394
00:27:29.670 --> 00:27:38.250
file names push final name replace dot log with an empty string.

395
00:27:38.250 --> 00:27:43.630
Now we want to optionally add on the compressed files,

396
00:27:43.630 --> 00:27:44.680
which for our case,

397
00:27:44.680 --> 00:27:48.990
are gonna be called dot gc dot be 64.

398
00:27:48.990 --> 00:27:51.830
That is because we're doing Z lib compression,

399
00:27:51.830 --> 00:27:58.100
which normally makes things and in dot gz But then we are based 64 encoding them so that we

400
00:27:58.100 --> 00:28:00.050
can read them easily later.

401
00:28:00.050 --> 00:28:04.660
So we're adding on the dot B 64 extension as well.

402
00:28:04.660 --> 00:28:11.570
So we're saying we want to add on the dot gz files to this array,

403
00:28:11.570 --> 00:28:23.770
so we're gonna say if final name index of dot gc dot B 64 is greater than negative one and

404
00:28:23.770 --> 00:28:26.680
the include compressed logs.

405
00:28:26.680 --> 00:28:28.750
1,000,000,000 is true then,

406
00:28:28.750 --> 00:28:33.910
and only then do we want to add them to the rays well after we trim off their extension.

407
00:28:33.910 --> 00:28:35.690
So trim file names,

408
00:28:35.690 --> 00:28:41.100
push file name,

409
00:28:41.100 --> 00:28:45.980
replace Dutch Easy.

410
00:28:45.980 --> 00:28:51.630
Don't be 64 with an empty string.

411
00:28:51.630 --> 00:28:55.970
Lastly,

412
00:28:55.970 --> 00:29:00.110
after we've gone through this for each loop synchronously,

413
00:29:00.110 --> 00:29:10.170
we want to call back to the requester no error and then the array of trimmed found names.

414
00:29:10.170 --> 00:29:11.980
So that list function should be working.

415
00:29:11.980 --> 00:29:13.950
We can move on to the next thing that we need it,

416
00:29:13.950 --> 00:29:16.290
which is live dot compress.

417
00:29:16.290 --> 00:29:20.400
And in order for us to easily test out whether compresses working,

418
00:29:20.400 --> 00:29:24.670
we should also write lab dot decompress afterwards.

419
00:29:24.670 --> 00:29:34.800
So lived a compress is going to compress the contents of one dot log file into a dot gz dot

420
00:29:34.800 --> 00:29:40.570
b 64 file within the same directory.

421
00:29:40.570 --> 00:29:45.950
So it is going to be a function,

422
00:29:45.950 --> 00:29:55.160
but as we know takes a log i d a new file i d and a call back.

423
00:29:55.160 --> 00:30:02.660
We need to first to find the source file,

424
00:30:02.660 --> 00:30:12.000
So that's going to be log I d dot log and the destination file that this compressed data

425
00:30:12.000 --> 00:30:14.170
needs to go to a destination.

426
00:30:14.170 --> 00:30:19.580
File equals new file.

427
00:30:19.580 --> 00:30:37.720
I d don't jeezy dot b 64 Now we want to read the source for that.

428
00:30:37.720 --> 00:30:40.260
We're going to use FS read file,

429
00:30:40.260 --> 00:30:45.490
pass it in the base directory,

430
00:30:45.490 --> 00:30:49.160
plus the source file name.

431
00:30:49.160 --> 00:30:55.120
We want to read it in with utf a encoding.

432
00:30:55.120 --> 00:31:02.950
And they're gonna pass us back an error and the string contents of that file,

433
00:31:02.950 --> 00:31:12.820
which we're gonna call input string if there is no air and there is an input strength will

434
00:31:12.820 --> 00:31:16.550
continue to try to compress that inputs drink.

435
00:31:16.550 --> 00:31:17.770
Otherwise,

436
00:31:17.770 --> 00:31:20.160
we're just gonna call back the air that we got.

437
00:31:20.160 --> 00:31:27.550
Now we want to compress the data using she's it.

438
00:31:27.550 --> 00:31:31.710
Jesus comes with the Z Lib library,

439
00:31:31.710 --> 00:31:39.150
and now we're going to compress that string into data through that library.

440
00:31:39.150 --> 00:31:42.880
So we're gonna say z lib dot Jeez,

441
00:31:42.880 --> 00:31:45.050
it and then pass it.

442
00:31:45.050 --> 00:31:45.850
Input string.

443
00:31:45.850 --> 00:31:53.090
If we're gonna expect back an air and a buffer,

444
00:31:53.090 --> 00:31:56.050
the buffer is going to contain the compressed data.

445
00:31:56.050 --> 00:32:01.600
If there's no air and there was a buffer will continue.

446
00:32:01.600 --> 00:32:02.710
Otherwise,

447
00:32:02.710 --> 00:32:10.520
we'll call back that air that we got to the requester that everything was fine then we want

448
00:32:10.520 --> 00:32:17.160
to send the data that new compressed data to the destination file.

449
00:32:17.160 --> 00:32:23.350
So we want to f s got open the destination file.

450
00:32:23.350 --> 00:32:31.810
That's going to be lived based directory plus destination file.

451
00:32:31.810 --> 00:32:43.480
We're going to open it with the WFP's flag for writing and expect back an air and a file

452
00:32:43.480 --> 00:32:54.840
descriptor if there is no air and there is a file descriptor will continue to right to the

453
00:32:54.840 --> 00:32:55.760
destination file.

454
00:32:55.760 --> 00:32:58.660
Otherwise,

455
00:32:58.660 --> 00:33:06.250
we're going to call that the air that we get for writing to the destination file.

456
00:33:06.250 --> 00:33:10.050
We're going to use FS right file.

457
00:33:10.050 --> 00:33:13.230
We're gonna pass it the file descriptor,

458
00:33:13.230 --> 00:33:16.920
pass it the buffer.

459
00:33:16.920 --> 00:33:23.340
But then we are going to call built in function on this buffer called to String,

460
00:33:23.340 --> 00:33:31.860
and we want to pass it the parameter base 64 so it nodes to make a base 64 encoded straight

461
00:33:31.860 --> 00:33:31.860
.

462
00:33:31.860 --> 00:33:32.870
So,

463
00:33:32.870 --> 00:33:33.550
in other words,

464
00:33:33.550 --> 00:33:35.880
this buffer is going to become a base.

465
00:33:35.880 --> 00:33:43.860
64 included string so that it could be written to a file and that right file function is

466
00:33:43.860 --> 00:33:45.520
gonna pass us back an error.

467
00:33:45.520 --> 00:33:47.490
If there's nine air,

468
00:33:47.490 --> 00:33:51.850
we should close the destination file.

469
00:33:51.850 --> 00:33:55.290
Otherwise,

470
00:33:55.290 --> 00:34:04.600
we should call back the air for closing the destination file were calling F s clothes with

471
00:34:04.600 --> 00:34:05.450
the five of Scripture.

472
00:34:05.450 --> 00:34:15.160
And again,

473
00:34:15.160 --> 00:34:16.770
if there's no air,

474
00:34:16.770 --> 00:34:20.050
we want to call back false.

475
00:34:20.050 --> 00:34:22.280
And if there is an air,

476
00:34:22.280 --> 00:34:24.350
we want to call it back.

477
00:34:24.350 --> 00:34:29.020
All right,

478
00:34:29.020 --> 00:34:33.910
so that is how you compress a file using G zip,

479
00:34:33.910 --> 00:34:35.280
which is part of ze lib,

480
00:34:35.280 --> 00:34:41.680
and how you base 64 encode the string so that you can write it to a text file.

481
00:34:41.680 --> 00:34:46.490
So now that you have that kind of data compressed into a file,

482
00:34:46.490 --> 00:34:47.460
at some point,

483
00:34:47.460 --> 00:34:49.350
you'll likely need to decompress it.

484
00:34:49.350 --> 00:34:51.370
So let's just write that function.

485
00:34:51.370 --> 00:34:53.900
Even though we don't have plans to use it right now,

486
00:34:53.900 --> 00:34:55.300
it will be useful later.

487
00:34:55.300 --> 00:35:10.960
So we want to decompress the contents of a dot gz dot B 64 file into a string variable.

488
00:35:10.960 --> 00:35:15.750
So live decompress.

489
00:35:15.750 --> 00:35:24.260
It's going to be a function that takes in a file I t.

490
00:35:24.260 --> 00:35:26.050
And a call back.

491
00:35:26.050 --> 00:35:41.440
We're gonna construct the file name as file I t plus dot pz dot b 64 And now we're gonna

492
00:35:41.440 --> 00:35:43.180
call fs read file,

493
00:35:43.180 --> 00:35:46.120
pass it the base directory,

494
00:35:46.120 --> 00:35:50.850
plus the file name.

495
00:35:50.850 --> 00:35:55.710
Tell it,

496
00:35:55.710 --> 00:36:02.590
Teoh utf eight What we're reading and expect back air and the string.

497
00:36:02.590 --> 00:36:05.340
If there is no air and a string,

498
00:36:05.340 --> 00:36:07.830
we're gonna continue.

499
00:36:07.830 --> 00:36:12.780
Otherwise we'll call back whatever that air Waas If there was a string,

500
00:36:12.780 --> 00:36:15.540
we need to decompress the data.

501
00:36:15.540 --> 00:36:21.900
So we're going to create a buffer out of this base 64 encoded strength.

502
00:36:21.900 --> 00:36:27.370
So we're really doing the reverse steps that we did before before we started with a string

503
00:36:27.370 --> 00:36:27.370
,

504
00:36:27.370 --> 00:36:34.090
created a Jesus buffer out of it and then sent that buffer to base 64 encoded strength.

505
00:36:34.090 --> 00:36:40.660
Now we're starting with the base 64 encoded string were decompressing it into a buffer.

506
00:36:40.660 --> 00:36:46.740
And then we're going from a buffer unzipping that buffer into a plane string.

507
00:36:46.740 --> 00:36:52.340
So first need to decompress the data far input,

508
00:36:52.340 --> 00:37:03.950
buffer equals and new buffer from this string which we know is based 64.

509
00:37:03.950 --> 00:37:08.400
So we're saying create a new buffer out of these beginnings.

510
00:37:08.400 --> 00:37:12.150
Now we want to call a Z lib unzip,

511
00:37:12.150 --> 00:37:22.910
which is the opposite of the zip that we used that Jesus z lib dot unzip Pass it input

512
00:37:22.910 --> 00:37:30.580
buffer and we're gonna expect out an air and an output buffer.

513
00:37:30.580 --> 00:37:35.600
There is no air and there is an output buffer.

514
00:37:35.600 --> 00:37:39.770
We'll continue otherwise we'll call back whatever that air waas.

515
00:37:39.770 --> 00:37:46.070
But if we got the output buffer,

516
00:37:46.070 --> 00:37:48.240
then we just want to call back in general.

517
00:37:48.240 --> 00:37:52.430
Which means we need to create a string out of this buffer.

518
00:37:52.430 --> 00:37:59.860
So we're gonna call straying equals output buffer two strings without any parameters.

519
00:37:59.860 --> 00:38:01.720
Now we have a strain to call back,

520
00:38:01.720 --> 00:38:09.030
so we can Colback no air plus the string.

521
00:38:09.030 --> 00:38:11.770
So that's our decompression function,

522
00:38:11.770 --> 00:38:14.730
and we'll go about testing that later on.

523
00:38:14.730 --> 00:38:15.810
Lastly,

524
00:38:15.810 --> 00:38:22.590
one of the functions that we called in workers was Libdeh truncate or logs dot truncate.

525
00:38:22.590 --> 00:38:27.350
So we need to have a function for truncating a lot file.

526
00:38:27.350 --> 00:38:32.740
So live truncate equals function.

527
00:38:32.740 --> 00:38:45.840
It takes in a log i d and a callback and it's just going to call file system truncate pass

528
00:38:45.840 --> 00:38:47.030
into base directory,

529
00:38:47.030 --> 00:39:00.570
plus the log I d plus Dr Log Tell it to truncated all the way and expect back an air.

530
00:39:00.570 --> 00:39:02.490
If there is no air,

531
00:39:02.490 --> 00:39:06.700
we'll call back false.

532
00:39:06.700 --> 00:39:11.530
And if there is an error,

533
00:39:11.530 --> 00:39:13.940
we'll call it back.

534
00:39:13.940 --> 00:39:18.440
So that is our whole logs library.

535
00:39:18.440 --> 00:39:27.330
Now we can start our workers back up and see if this log rotation and compression is

536
00:39:27.330 --> 00:39:28.270
working properly,

537
00:39:28.270 --> 00:39:31.150
and now we can actually just start it up.

538
00:39:31.150 --> 00:39:33.580
It's going to call rotate logs immediately,

539
00:39:33.580 --> 00:39:35.320
which should do everything we need.

540
00:39:35.320 --> 00:39:40.700
We don't need to worry about the log rotation Luke firing again because it's not going to

541
00:39:40.700 --> 00:39:43.470
happen again for 24 hours.

542
00:39:43.470 --> 00:39:44.830
Let's start up.

543
00:39:44.830 --> 00:39:53.120
Looks like we have an air and it looks like this happened because I included these

544
00:39:53.120 --> 00:39:54.500
parameters incorrectly.

545
00:39:54.500 --> 00:39:56.500
I wasn't supposed to separate this with the plus.

546
00:39:56.500 --> 00:39:58.430
I'm supposed to separate that with a comma.

547
00:39:58.430 --> 00:40:01.110
So let's kill that and try it again.

548
00:40:01.110 --> 00:40:03.970
Okay,

549
00:40:03.970 --> 00:40:07.870
Looks like locking to the final succeeded as it was before.

550
00:40:07.870 --> 00:40:12.830
And we have to success truncating the log files messages logged out.

551
00:40:12.830 --> 00:40:13.750
I'm gonna kill that.

552
00:40:13.750 --> 00:40:17.470
And let's look at what's actually living in this part.

553
00:40:17.470 --> 00:40:18.220
The file system.

554
00:40:18.220 --> 00:40:22.160
Now we have our original logs,

555
00:40:22.160 --> 00:40:25.110
which now just have one line each,

556
00:40:25.110 --> 00:40:30.520
and you can see that is because we just log to the files and we just looked at those files

557
00:40:30.520 --> 00:40:32.130
after the Trump Cajun happened.

558
00:40:32.130 --> 00:40:34.350
But the truncation happened,

559
00:40:34.350 --> 00:40:43.920
which means we have all this base 64 encoded data inside of these dot gz dot be 64 files.

560
00:40:43.920 --> 00:40:46.190
So compression is happening.

561
00:40:46.190 --> 00:40:49.660
And after the compression happens and wipes out those files,

562
00:40:49.660 --> 00:40:53.270
those Longs air still getting filled up as normal.

563
00:40:53.270 --> 00:40:57.770
So logging and what we call log rotation is working fine.

564
00:40:57.770 --> 00:41:04.330
That is how you log to the file system in a later lecture and a future section.

565
00:41:04.330 --> 00:41:08.060
We will actually use that decompression function,

566
00:41:08.060 --> 00:41:09.110
but for now,

567
00:41:09.110 --> 00:41:10.400
we don't really need it.

568
00:41:10.400 --> 00:41:14.820
And we'll look into that in more detail when we actually need to decompress some logs.

569
00:41:14.820 --> 00:41:16.210
But for now,

570
00:41:16.210 --> 00:41:20.940
everything is working fine and so we can move on to the next lecture,

571
00:41:20.940 --> 00:41:25.060
which is about more logging but is about long to the console,

572
00:41:25.060 --> 00:41:27.170
as opposed to log files.

