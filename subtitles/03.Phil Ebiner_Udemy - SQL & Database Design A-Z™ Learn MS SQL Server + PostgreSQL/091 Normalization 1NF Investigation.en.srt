1
00:00:00,740 --> 00:00:05,870
Hello and welcome back to the course on databases now that we've got our table uploaded here it is transactions

2
00:00:06,200 --> 00:00:11,270
we can go here and start normalizing it and see what will come up in the process.

3
00:00:11,270 --> 00:00:16,760
So let's get started with the first step which is going to click anywhere here and search query tool

4
00:00:17,090 --> 00:00:25,080
and we're going to write a very very simple query and just say selects are from transactions just so

5
00:00:25,080 --> 00:00:27,840
we can see what we have inside this table.

6
00:00:27,840 --> 00:00:34,890
Now let's quickly just the columns we're doing this so that we can see the full name of the column and

7
00:00:34,890 --> 00:00:40,350
also we can see some of the sample data in full just so that we understand better what's going on.

8
00:00:40,350 --> 00:00:46,100
So here is we've got shipping state item item let's give it some more space.

9
00:00:47,650 --> 00:00:52,500
All right so what is our very first step in the process of normalization.

10
00:00:52,630 --> 00:00:58,390
Well the very first step that we need to perform is we need to check if this table is in first normal

11
00:00:58,390 --> 00:00:58,900
form.

12
00:00:58,990 --> 00:00:59,250
Right.

13
00:00:59,260 --> 00:01:05,290
In order to do that let's go ahead and just first of all get acquainted with these columns and see what's

14
00:01:05,290 --> 00:01:05,670
going on.

15
00:01:05,740 --> 00:01:07,840
So here we've got the transaction ID.

16
00:01:08,320 --> 00:01:11,100
It's a unique identifier for every single row.

17
00:01:11,110 --> 00:01:17,860
And the way these columns normally work in databases is the database is already set up for this to be

18
00:01:17,860 --> 00:01:19,110
the primary key.

19
00:01:19,150 --> 00:01:25,840
And as you know as you just add new columns this is a bit different because we uploaded this file from

20
00:01:25,840 --> 00:01:27,610
osseous from Assissi right.

21
00:01:27,610 --> 00:01:29,210
We uploaded this there from US-Israel river.

22
00:01:29,380 --> 00:01:37,000
But when it's in an actual online transaction processing database or some other kind of database what

23
00:01:37,000 --> 00:01:45,380
happens is as new records come into this table this idea is just increased by one every single time.

24
00:01:45,430 --> 00:01:50,620
And so this is like an incremental idea and that guarantees that it is going to be unique and you can

25
00:01:50,620 --> 00:01:54,070
see that this is exactly the case which was happening here.

26
00:01:54,070 --> 00:01:59,790
So you can see this is the newest transaction and then they're falling off in descending order.

27
00:01:59,810 --> 00:02:04,370
So these are later transactions that happened earlier on.

28
00:02:04,600 --> 00:02:09,580
And as you can see the idea was also smaller so the idea was increasing as the transactions were coming

29
00:02:09,580 --> 00:02:10,920
in then.

30
00:02:10,930 --> 00:02:13,780
So that's how timestamped and it's in seconds.

31
00:02:13,780 --> 00:02:15,400
So it's up to the second.

32
00:02:15,520 --> 00:02:20,470
And then you've got the customer ID that I identify a number of the customers got the customer first

33
00:02:20,470 --> 00:02:23,960
name surname the shipping state.

34
00:02:23,980 --> 00:02:26,570
So basically this is the state of the customer where they live.

35
00:02:26,590 --> 00:02:29,930
So that's where the item is to be shipped the item that they purchased.

36
00:02:29,950 --> 00:02:36,460
So this is their item code then the description of the items are pillowcase mints pajama's sheets coat

37
00:02:37,450 --> 00:02:38,710
blanket and so on.

38
00:02:38,860 --> 00:02:46,220
And the retail price of that item and the loyalty discount that was applied to that purchase as we can

39
00:02:46,220 --> 00:02:50,060
assume because it has the word loyalty that means it's related to the customer.

40
00:02:50,090 --> 00:02:50,320
Right.

41
00:02:50,330 --> 00:02:56,180
So customers who have been shopping for longer will have a higher loyalty discount or there's some sort

42
00:02:56,180 --> 00:03:01,810
of correlation and maybe some customers that purchased have purchased more in their history.

43
00:03:02,120 --> 00:03:10,070
So there we go those are our homes and the first thing we need to do is check now if the tables in personal

44
00:03:10,160 --> 00:03:19,120
form and so if we remember all mnemonic which talks about the key.

45
00:03:19,280 --> 00:03:31,040
So basically every attribute every non prime attribute should tell a should say a fact about the key

46
00:03:31,310 --> 00:03:34,790
the whole key and only add nothing but the key.

47
00:03:34,880 --> 00:03:42,410
And so basically the first part is that there is a key and what that tells us if we remember from the

48
00:03:42,410 --> 00:03:47,330
theory part is that there cannot be any duplicate rows.

49
00:03:47,330 --> 00:03:52,700
That's number one and number two which is a bit unrelated to the mnemonic is that we cannot have any

50
00:03:54,080 --> 00:03:57,020
We cannot have cells with more than one value in them right.

51
00:03:57,070 --> 00:04:07,070
So let's go ahead and go through the stable like we just look through it and just try to understand

52
00:04:07,070 --> 00:04:09,540
if it's possible that they are unusual.

53
00:04:09,640 --> 00:04:12,930
It's possible that any of those conditions is not met.

54
00:04:12,950 --> 00:04:18,170
So here you can see that this is indeed every single time unique.

55
00:04:18,170 --> 00:04:23,610
So by definition they cannot be any duplicate rows in this table.

56
00:04:23,960 --> 00:04:32,570
And also you can see that by the looks of it every single cell has a atomic value.

57
00:04:32,570 --> 00:04:34,420
Those values are called Atomic.

58
00:04:34,650 --> 00:04:39,080
So it's a very controversial term Tolmach you can read a bit more about it online.

59
00:04:39,080 --> 00:04:44,900
Some people prefer choosing some people prefer not to use it is hard to say if it's it's a good term

60
00:04:44,900 --> 00:04:45,320
to use.

61
00:04:45,320 --> 00:04:52,460
But basically what it implies is that every single cell has indeed a single value.

62
00:04:52,470 --> 00:04:58,160
Sort of like comma separated or somehow otherwise separated values that should be in different rows.

63
00:04:58,220 --> 00:05:00,770
So as you can see it looks like both conditions are met here.

64
00:05:00,830 --> 00:05:07,880
I'm just going to show you another way to 100 percent verify that there is no duplicate rows.

65
00:05:07,970 --> 00:05:11,360
So what are you going to do is we're going to say select count

66
00:05:15,380 --> 00:05:22,360
star from transactions you run that he'll tell you how many zeros.

67
00:05:22,380 --> 00:05:24,530
Three hundred three thousand fifty five.

68
00:05:24,530 --> 00:05:28,430
So just put a comment and say three thousand four fifty five.

69
00:05:28,490 --> 00:05:31,890
And now do the same thing.

70
00:05:32,080 --> 00:05:35,830
But this time instead of just saying Slick's can start from transactions.

71
00:05:35,990 --> 00:05:40,450
We're going to replace transactions with a subquery and I'll explain this in a second so just follow

72
00:05:40,450 --> 00:05:42,670
along and type in this code.

73
00:05:42,670 --> 00:05:47,910
So here we replace transactions with two brackets for null and opening and closing bracket.

74
00:05:48,010 --> 00:05:57,430
And inside we're going to say select store or select distinct star from Trend actions.

75
00:05:57,920 --> 00:06:05,740
And so if you run just these two lines by themselves what this will do this distinct word it it modifies

76
00:06:05,740 --> 00:06:11,220
this query to only select the unique rows from this table.

77
00:06:11,220 --> 00:06:17,790
So by running this query that you're guaranteed that there are no duplicates in this table anymore.

78
00:06:18,040 --> 00:06:21,160
And now what we're doing is on top of that.

79
00:06:21,160 --> 00:06:28,030
So on this table that we've got as a result now we're applying this select count from the subquery.

80
00:06:28,030 --> 00:06:36,350
The only thing is here we have to say as a team or something that's so tempy distinct doesn't matter

81
00:06:36,350 --> 00:06:39,210
what name you give it you can just say a something.

82
00:06:39,260 --> 00:06:42,410
So let's say ABC.

83
00:06:42,800 --> 00:06:48,770
So if you run this now it will count the number of rows in this table which only has two distinct rows

84
00:06:48,770 --> 00:06:52,310
and therefore it will count two distinct rows in the whole table.

85
00:06:52,310 --> 00:06:55,540
There we go 300 three thousand four hundred and fifty five.

86
00:06:55,540 --> 00:07:02,500
So we have confirmed that the number of rows in the table is equal to the number of distinct rows.

87
00:07:02,500 --> 00:07:05,490
So if there were any duplicates this number would be less.

88
00:07:05,660 --> 00:07:10,850
But since the number is the same as it was for the normal count that means that there are no duplicate

89
00:07:10,850 --> 00:07:11,400
rows.

90
00:07:11,540 --> 00:07:18,560
And so basically what that does for us is it confirms that this table is in first normal form.

91
00:07:18,560 --> 00:07:26,710
So we've seen that there are no values 2 values in one cell and we can see that.

92
00:07:26,720 --> 00:07:33,830
And also it's you can investigate that further just by knowing where the table came from and how it's

93
00:07:33,830 --> 00:07:34,820
been structured.

94
00:07:36,130 --> 00:07:38,670
Also we've confirmed that there are no duplicate rows.

95
00:07:38,860 --> 00:07:43,140
So as a result of this table is in first normal form.

96
00:07:43,180 --> 00:07:47,220
Next we're going to investigate the second and third normal forms.

97
00:07:47,260 --> 00:07:51,210
And those are going to be some very exciting tutorials called wait to see you next time.

98
00:07:51,220 --> 00:07:52,760
Until then happy analyzing.
