1
00:00:00,500 --> 00:00:05,790
Hello and welcome back to the course on databases now that we've got our table uploaded here it is transactions.

2
00:00:05,960 --> 00:00:11,000
We can go ahead and start normalizing it and see what will come up in the process.

3
00:00:11,000 --> 00:00:15,310
So let's get started with the first step and we're going to write a very very simple query and just

4
00:00:15,320 --> 00:00:23,270
say select star for all transactions just so we can see what we have inside this table.

5
00:00:23,580 --> 00:00:28,420
All right so what is our very first step in the process of normalization.

6
00:00:28,560 --> 00:00:34,320
Well the very first step that we need to perform is we need to check if this table is in first normal

7
00:00:34,320 --> 00:00:34,840
form.

8
00:00:34,920 --> 00:00:35,180
Right.

9
00:00:35,190 --> 00:00:41,190
In order to do that let's go ahead and just first of all get acquainted with these columns and see what's

10
00:00:41,190 --> 00:00:41,670
going on.

11
00:00:41,670 --> 00:00:43,720
So here we've got the transaction ID.

12
00:00:44,250 --> 00:00:50,940
It's a unique identifier for every single row and the way these columns normally work in databases is

13
00:00:51,510 --> 00:00:55,050
the database is already set up for this to be the primary key.

14
00:00:55,080 --> 00:01:01,770
And as you know as you just add new columns this is a bit different because we uploaded this file from

15
00:01:01,770 --> 00:01:03,250
osseous from Assissi.

16
00:01:03,250 --> 00:01:09,240
All right we uploaded this there from usses river but when it's in an actual online transaction processing

17
00:01:09,600 --> 00:01:18,690
database or some other kind of database what happens is as new records come into this table this idea

18
00:01:18,690 --> 00:01:24,240
is just increased by one every single time and slow is like an incremental idea and that guarantees

19
00:01:24,240 --> 00:01:26,320
that it is going to be unique then.

20
00:01:26,340 --> 00:01:28,990
So that's how timestamp and it's in seconds.

21
00:01:29,160 --> 00:01:30,730
So it's up to the second.

22
00:01:30,870 --> 00:01:36,060
And then we've got the customer ID the identifying number of the customers got the customer first name

23
00:01:36,060 --> 00:01:39,360
surname the shipping state.

24
00:01:39,360 --> 00:01:41,970
So basically this is the state of the customer where they live.

25
00:01:42,000 --> 00:01:45,330
So that's where the item has to be shipped the item that they purchased.

26
00:01:45,360 --> 00:01:51,870
So this is their item code than the description of the items or pillow casements pajamas sheets coat

27
00:01:52,860 --> 00:02:00,360
blanket and so on and the retail price of that item and the loyalty discount that was applied to that

28
00:02:00,360 --> 00:02:05,460
purchase as we can assume because it has the word loyalty it means it's it's related to the customer.

29
00:02:05,510 --> 00:02:05,740
Right.

30
00:02:05,760 --> 00:02:12,900
So customers who have been shopping for longer will have a higher loyalty discount or some sort of correlation

31
00:02:12,910 --> 00:02:17,550
that maybe some customers that purchased have purchased more in their history.

32
00:02:17,550 --> 00:02:19,250
So there we go those are our homes.

33
00:02:19,290 --> 00:02:26,050
And the first thing we need to do is check now if this tables in personal form.

34
00:02:26,190 --> 00:02:34,530
And so if we remember all mnemonic which talks about the key.

35
00:02:34,710 --> 00:02:46,440
So basically every attribute every non prime attribute should tell a should say a fact about the key

36
00:02:46,740 --> 00:02:50,250
the whole key and only add nothing but the key.

37
00:02:50,310 --> 00:02:57,810
And so basically the first part is that there is a key and what that tells us if we remember from the

38
00:02:57,810 --> 00:03:02,750
theory part is that they cannot be any duplicate rows.

39
00:03:02,760 --> 00:03:08,130
That's number one and number two which is a bit unrelated to the mnemonic is that we cannot have any

40
00:03:09,480 --> 00:03:12,220
We cannot have cells with more than one value in them.

41
00:03:12,240 --> 00:03:12,470
Right.

42
00:03:12,470 --> 00:03:22,470
So let's go ahead and go through the stable like we just look through it and just try to understand

43
00:03:22,500 --> 00:03:28,120
if it's possible that they are if any of that is possible that any of those conditions is not met.

44
00:03:28,350 --> 00:03:33,330
So here you can see that this is indeed every single time unique.

45
00:03:33,600 --> 00:03:39,040
So by definition they're count would be any duplicate rows in this table.

46
00:03:39,390 --> 00:03:49,880
And also you can see that by the looks of it every single cell has a atomic value those values are atomic.

47
00:03:50,000 --> 00:03:54,480
And so it's a very controversial term Tolmach you can read a bit more about it online.

48
00:03:54,480 --> 00:03:57,860
Some people prefer choosing some people prefer not to use it.

49
00:03:58,020 --> 00:04:03,660
It's hard to say if it's it's a good term to use but basically what it implies is that every single

50
00:04:03,660 --> 00:04:07,910
cell has indeed a single value.

51
00:04:07,910 --> 00:04:13,570
Sort of like comma separated or somehow otherwise separated values that should be in different rows.

52
00:04:13,620 --> 00:04:16,200
So as you can see it looks like both conditions are met here.

53
00:04:16,260 --> 00:04:23,380
I'm just going to show you another way to 100 percent verify that there is no duplicate rows.

54
00:04:23,400 --> 00:04:26,790
So what are you going to do is we're going to say select count

55
00:04:30,800 --> 00:04:37,890
star from transactions you run that he'll tell you how many Euros.

56
00:04:37,910 --> 00:04:38,690
Three hundred.

57
00:04:38,810 --> 00:04:39,940
Three thousand four hundred fifty five.

58
00:04:39,940 --> 00:04:47,330
So just put a comment and say 3000 fifty five and now do the same thing.

59
00:04:47,530 --> 00:04:52,840
But this time instead of just saying Slick's can start from transactions we're going to replace transactions

60
00:04:52,840 --> 00:04:58,090
with a subquery and I'll explain this in a second so just follow along and type in this code.

61
00:04:58,090 --> 00:05:03,340
So here we replace transactions with two brackets for an opening and closing record.

62
00:05:03,430 --> 00:05:13,040
And inside we're going to say select store or select distinct star from Trend actions.

63
00:05:13,350 --> 00:05:21,180
And so if you run just these two lines by themselves what this will do this distinct word it modifies

64
00:05:21,180 --> 00:05:26,640
this query to only select the unique rows from this table.

65
00:05:26,640 --> 00:05:33,170
So by running this query you're guaranteed that there are no duplicates in this table anymore.

66
00:05:33,480 --> 00:05:36,570
And now what we're doing is on top of that.

67
00:05:36,570 --> 00:05:43,440
So on this table that we've got as a result now we're applying this select count from the subquery.

68
00:05:43,440 --> 00:05:51,900
The only thing is here we have to say as tiam or something that's so tempy distinct doesn't matter what

69
00:05:51,900 --> 00:05:54,650
name you give it you can just say a something.

70
00:05:54,690 --> 00:05:57,890
So let's say ABC.

71
00:05:58,200 --> 00:06:04,170
So if you run this now it will count the number of rows in this table which only has two distinct rows

72
00:06:04,170 --> 00:06:07,740
and therefore it will count two distinct rows in the whole table.

73
00:06:07,740 --> 00:06:10,980
There we go 300 three thousand four hundred and fifty five.

74
00:06:10,980 --> 00:06:17,940
So we have confirmed that the number of rows in the table is equal to the number of distinct rows.

75
00:06:17,940 --> 00:06:20,940
So if there were any duplicate this number would be less.

76
00:06:21,090 --> 00:06:26,280
But since the number is the same as it was for the normal count that means that there are no duplicate

77
00:06:26,280 --> 00:06:26,830
rows.

78
00:06:26,980 --> 00:06:33,990
And so basically what that does for us is it confirms that this table is in first normal form.

79
00:06:33,990 --> 00:06:42,110
So we've seen that there are no values to values in one cell and we can see that.

80
00:06:42,120 --> 00:06:48,210
And also it's you can investigate that further just by knowing what that where the table came from and

81
00:06:48,870 --> 00:06:51,470
how it's being structured.

82
00:06:51,560 --> 00:06:54,270
Also we've confirmed that there are no duplicate rows.

83
00:06:54,290 --> 00:06:58,540
So as a result of this table is in first normal form.

84
00:06:58,580 --> 00:07:02,640
Next we're going to investigate the second and third normal forms.

85
00:07:02,690 --> 00:07:06,540
And those are going to be some very exciting tutorials called wait to see the next time.

86
00:07:06,620 --> 00:07:08,180
Until then happy analyzing.
