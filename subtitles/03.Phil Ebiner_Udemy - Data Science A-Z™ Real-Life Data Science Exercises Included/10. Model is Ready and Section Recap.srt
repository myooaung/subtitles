1

00:00:00,810  -->  00:00:07,870
Last time we talked about the correlation matrix and also the intuition behind multicollinearity.

2

00:00:08,220  -->  00:00:12,630
And today we're going to finish off this whole section of a conclusion.

3

00:00:12,690  -->  00:00:18,960
But before we do that I would like us to save the model because we will be using it in the next section

4

00:00:18,960  -->  00:00:19,670
of the course.

5

00:00:19,830  -->  00:00:21,640
So I'm going to close this.

6

00:00:21,650  -->  00:00:25,810
You don't need the correlation matrix here in our final version of the model.

7

00:00:25,830  -->  00:00:31,140
The one just makes shows the one that includes LOEG balance and doesn't have any wealth accumulation

8

00:00:31,140  -->  00:00:32,930
or log of wealth accumulation.

9

00:00:32,940  -->  00:00:38,230
So basically if you use the same variables as me then it should look like this.

10

00:00:38,310  -->  00:00:48,900
What you need to do is go to File Save As I'm going to save it as an RTFM Word document click OK and

11

00:00:48,900  -->  00:00:55,670
then just select a folder I'm going to save mine in my standard folder for this section save.

12

00:00:55,770  -->  00:00:58,140
Oh yeah definitely a name.

13

00:00:58,290  -->  00:01:06,860
So what I'm going to call it let's call it in my case model model 20 code named model 20.

14

00:01:07,160  -->  00:01:09,110
OK save.

15

00:01:09,300  -->  00:01:15,540
And now if I go to my folder you'll see in your document here.

16

00:01:15,690  -->  00:01:16,820
So this is my model.

17

00:01:16,980  -->  00:01:19,440
Scott this thing is to be fixed up.

18

00:01:19,590  -->  00:01:26,480
So basically save the final results and that will allow us to when we need to recreate the model because

19

00:01:26,480  -->  00:01:28,950
we'll know which variables went into this model.

20

00:01:29,460  -->  00:01:31,890
And so we're just going to save that.

21

00:01:32,480  -->  00:01:33,180
OK.

22

00:01:33,480  -->  00:01:34,450
So that's ready.

23

00:01:34,590  -->  00:01:40,130
And at this stage we can say thank you Grettel it really helped us out.

24

00:01:40,560  -->  00:01:45,540
What I would like to do now is move on to our recap for the section.

25

00:01:45,540  -->  00:01:46,590
So just close Grettel

26

00:01:49,260  -->  00:01:50,960
ops.

27

00:01:51,210  -->  00:02:03,260
There we go so there is our recap section recap what did we learn in this section and this section learned

28

00:02:03,250  -->  00:02:03,340
.

29

00:02:03,360  -->  00:02:11,100
Number one what a demographic segmentation is we talked about we talked about grouping of customers

30

00:02:11,100  -->  00:02:20,370
by similarities of their behavior and using prior knowledge to predict any future trends and basically

31

00:02:20,400  -->  00:02:21,780
predict future behavior.

32

00:02:21,780  -->  00:02:29,580
So you can anticipate it so you can pre-empted maybe do something about it if required so examples are

33

00:02:29,580  -->  00:02:35,340
like for example looped in here is chern modeling to understand when your customers are going to leave

34

00:02:35,400  -->  00:02:38,240
and who is more likely to leave who's less likely to leave.

35

00:02:38,370  -->  00:02:41,880
There's lots of different applications of demographics segmentation.

36

00:02:42,150  -->  00:02:49,050
Number two is we practice building a real segmentation model which was great fun we had real variables

37

00:02:49,070  -->  00:02:49,250
.

38

00:02:49,380  -->  00:02:56,470
So it was variables that you would find in a bank such as balances credit card.

39

00:02:56,520  -->  00:02:57,070
Yes.

40

00:02:57,620  -->  00:03:00,600
What's the â‚¬10 of the customers ages and so on.

41

00:03:00,600  -->  00:03:04,790
So something that is very very like the real world.

42

00:03:04,800  -->  00:03:09,810
It's a law like that you would actually build it in the real world and we went step by step through

43

00:03:09,960  -->  00:03:15,560
everything and understood how to exclude variables how to see that our model is still robust.

44

00:03:15,750  -->  00:03:21,780
And we went the whole journey from start to finish which was which was a great experience in my view

45

00:03:21,780  -->  00:03:23,130
.

46

00:03:23,130  -->  00:03:25,610
We also learned how to transform independent variables.

47

00:03:25,620  -->  00:03:26,690
So that's an important part.

48

00:03:26,700  -->  00:03:33,300
If you think that's been a variable is misrepresenting the effect just due to the nature of the effect

49

00:03:33,330  -->  00:03:39,000
because it should be represented by this variable is a role for my brain should be squared or there

50

00:03:39,000  -->  00:03:41,310
should be a square root a logarithm or something.

51

00:03:41,310  -->  00:03:47,280
I mean looked an example of taking a logarithm of balance plus one we learned how to create derived

52

00:03:47,280  -->  00:03:53,880
variables so new independent variables and you would need to do this in cases when you have certain

53

00:03:53,880  -->  00:04:00,620
business knowledge around how variables are combined to achieve the desired outcome.

54

00:04:00,660  -->  00:04:03,720
Very very powerful technique as well.

55

00:04:03,730  -->  00:04:10,770
The we understood the intuition behind multicollinearity and why it is basically bad for your models

56

00:04:10,920  -->  00:04:16,300
if they're correlated independent variables that you're putting into the models.

57

00:04:16,320  -->  00:04:23,910
We also looked at how to check for multicollinearity using variants inflation factors and also how to

58

00:04:23,910  -->  00:04:29,220
read the correlation metrics and basically check for multiple neurology effect that fixed that way as

59

00:04:29,220  -->  00:04:29,700
well.

60

00:04:29,700  -->  00:04:36,240
So those are two techniques that'll allow you to get rid of or pre-empting any multicollinearity in

61

00:04:36,240  -->  00:04:39,440
your models and act upon it in a timely manner.

62

00:04:39,570  -->  00:04:41,970
So two things that I wanted to mention.

63

00:04:42,060  -->  00:04:48,300
First of all of course this is not your hundred percent coverage of everything that you will ever do

64

00:04:48,300  -->  00:04:49,350
when building a model.

65

00:04:49,350  -->  00:04:56,010
However what we looked at today represents approximately 80 percent of any kind of techniques that you

66

00:04:56,010  -->  00:05:01,800
will be using to Korean model it's usually this standardized approach a lot of is trial and error experimenting

67

00:05:01,800  -->  00:05:07,500
with derived and transformed variables understanding which variables to include exclusions on of course

68

00:05:07,560  -->  00:05:12,180
their little other things that you will learn along the way you will pick them up as you create more

69

00:05:12,180  -->  00:05:12,770
of these.

70

00:05:12,780  -->  00:05:18,630
But what I gave you here this blueprint this is an 80 percent base of what you will need in modeling

71

00:05:18,980  -->  00:05:20,470
and the second point is tools.

72

00:05:20,550  -->  00:05:24,190
Let's face it Grettel is not going to be the ultimate tool that you're going to be using.

73

00:05:24,240  -->  00:05:31,110
However any tool that you'll be using will have its own way of showing you the Vivus or the correlation

74

00:05:31,110  -->  00:05:35,520
matrix or running a binary logistic regression.

75

00:05:35,520  -->  00:05:42,630
So those things you get accustomed to quite easily and once you know them the fundamentals are the same

76

00:05:42,630  -->  00:05:42,650
.

77

00:05:42,660  -->  00:05:48,360
And what was important about the section is for you to grasp the fundamentals to understand how exactly

78

00:05:48,630  -->  00:05:52,070
these things are done and why they are done in this way.

79

00:05:52,380  -->  00:05:58,710
And so once you've learnt that you can move on and wherever you apply this knowledge you're going to

80

00:05:58,710  -->  00:05:59,970
be successful.

81

00:06:00,540  -->  00:06:03,120
Thank you for staying with me through this section.

82

00:06:03,120  -->  00:06:04,600
It was fun exciting.

83

00:06:04,640  -->  00:06:07,680
The next one we're going to assess our models.

84

00:06:07,730  -->  00:06:10,920
We'll show you how to read the cumulative accuracy profile.

85

00:06:10,920  -->  00:06:18,840
We'll talk about the accuracy paradox and I will give you a template an actual Excel template for you

86

00:06:18,840  -->  00:06:21,350
to take home and play around with.

87

00:06:21,390  -->  00:06:23,020
That will help you assess your models.

88

00:06:23,220  -->  00:06:25,340
I look forward to seeing in the next section of the course.

89

00:06:25,380  -->  00:06:27,200
And until then I'd be analyzing
