WEBVTT
1

00:00:01.410  -->  00:00:08.580
All right so this is a solution for homework from the error handling in all phases one and two section

2

00:00:08.580  -->  00:00:09.840
of the course.

3

00:00:09.840  -->  00:00:11.700
We've got no data downloaded here.

4

00:00:11.700  -->  00:00:14.830
Let's go ahead and put it into a project folder.

5

00:00:15.000  -->  00:00:16.850
So I have a folder here for homework.

6

00:00:16.860  -->  00:00:21.930
I'm going to create a new copy of our project template give today's date.

7

00:00:22.490  -->  00:00:32.190
You know it is already September and we're going to give it a name so let's call it homework DTL phases

8

00:00:32.310  -->  00:00:34.070
one and two.

9

00:00:34.710  -->  00:00:39.770
And here we've really got all of the file structure of folder structure that we need.

10

00:00:39.840  -->  00:00:42.980
Let's copy this file into the original doc.

11

00:00:42.990  -->  00:00:44.250
Once again we're not going to touch it here.

12

00:00:44.270  -->  00:00:47.610
We're going to make a copy and put into prepared folder.

13

00:00:47.820  -->  00:00:55.160
So if we open up now we can see that here we've got a lot of columns.

14

00:00:55.170  -->  00:00:56.500
Quite a few.

15

00:00:56.570  -->  00:01:03.270
And then we've got the three columns that we definitely need at the end of here and we've already looked

16

00:01:03.270  -->  00:01:04.230
at the number of rows.

17

00:01:04.260  -->  00:01:08.950
That's cool so let's commence this whole process.

18

00:01:08.970  -->  00:01:09.810
What do we do first.

19

00:01:09.810  -->  00:01:19.300
First of all we need to rename the file to see right so that we can open it in Excel Excel.

20

00:01:19.330  -->  00:01:22.470
Here let's open it up open

21

00:01:26.400  -->  00:01:28.680
and all files.

22

00:01:28.710  -->  00:01:29.730
There it is.

23

00:01:29.730  -->  00:01:33.370
So this brings up the text import wizard.

24

00:01:33.780  -->  00:01:36.240
Of course it can be delimited.

25

00:01:36.750  -->  00:01:38.330
It's going to be comma delimited.

26

00:01:38.370  -->  00:01:39.720
Next.

27

00:01:40.350  -->  00:01:43.440
Make sure that all of these are selected then it's like text.

28

00:01:43.450  -->  00:01:46.480
Finish.

29

00:01:46.590  -->  00:01:51.350
All right so all file Aldara is in the file is in Excel.

30

00:01:51.570  -->  00:01:56.060
And now we can perform what we normally do is look for dollar amounts.

31

00:01:56.060  -->  00:02:01.890
Knodell amounts here and all the data so that doesn't count because that's just it is.

32

00:02:01.980  -->  00:02:03.510
We'll leave it as a text.

33

00:02:03.870  -->  00:02:06.670
This one we're going to change into the correct format.

34

00:02:06.750  -->  00:02:08.220
So this is good practice.

35

00:02:08.220  -->  00:02:10.530
We're going to go to text to columns.

36

00:02:10.530  -->  00:02:15.750
We're going to change this delimited no delimiter finish change date.

37

00:02:15.740  -->  00:02:23.140
So here it looks like day or month day year so let's change that finish.

38

00:02:23.250  -->  00:02:24.240
Good.

39

00:02:24.270  -->  00:02:27.210
Now we need the correct format for the database.

40

00:02:27.330  -->  00:02:29.310
The canonical format.

41

00:02:29.310  -->  00:02:31.400
So we're going to go custom.

42

00:02:32.000  -->  00:02:34.100
Why why why.

43

00:02:34.350  -->  00:02:36.550
Well I'm MDD.

44

00:02:36.570  -->  00:02:37.230
There we go.

45

00:02:37.260  -->  00:02:38.750
So that's ready.

46

00:02:39.260  -->  00:02:39.630
OK.

47

00:02:39.630  -->  00:02:45.440
So this is our Excel file we can save it as a CSP file.

48

00:02:45.450  -->  00:02:46.550
So I'll leave that on there.

49

00:02:46.550  -->  00:02:50.080
Now we're going to call and save another one here.

50

00:02:50.160  -->  00:02:50.430
Yes.

51

00:02:50.430  -->  00:02:53.340
Be awesome.

52

00:02:54.450  -->  00:02:55.870
Yes that's OK.

53

00:02:55.950  -->  00:02:56.750
OK that's done.

54

00:02:56.750  -->  00:03:01.000
So let's close that.

55

00:03:01.210  -->  00:03:02.400
I don't have to say it again.

56

00:03:02.400  -->  00:03:03.330
Don't worry.

57

00:03:03.330  -->  00:03:04.170
There we go.

58

00:03:04.170  -->  00:03:08.610
So now we can open up have a look.

59

00:03:08.610  -->  00:03:09.570
Have a look here.

60

00:03:09.570  -->  00:03:16.380
So the thing that we should notice right away probably like a quick caveat that this is the same as

61

00:03:16.380  -->  00:03:20.910
what we did before we can see here that now new columns have appeared.

62

00:03:20.940  -->  00:03:27.750
This is an empty column just another empty column so Excel has added empty columns here for us and that

63

00:03:27.750  -->  00:03:36.850
is saving us from rows being eaten up by other rows and we talked about this in the course.

64

00:03:37.080  -->  00:03:40.890
So that's just something to notice here.

65

00:03:41.130  -->  00:03:46.080
What are we going to do now is we're going to start uploading the file right so we're going to go to

66

00:03:46.140  -->  00:03:51.810
upload a dot on copy that and give it a name.

67

00:03:51.810  -->  00:03:53.940
So that's how we're going to put our file.

68

00:03:54.120  -->  00:03:57.060
Let's go get it.

69

00:03:57.060  -->  00:03:57.590
There we go.

70

00:03:57.630  -->  00:04:07.150
So now we can proceed to Sosias and launching Microsoft Visual Studio the shell.

71

00:04:08.370  -->  00:04:08.970
OK.

72

00:04:08.970  -->  00:04:15.390
So let's create a new project here.

73

00:04:15.390  -->  00:04:18.340
Integration Services project Let's call this one a home.

74

00:04:18.510  -->  00:04:27.410
We're e t l phases one and two.

75

00:04:32.220  -->  00:04:36.470
Maybe let's expand that data flow task.

76

00:04:36.480  -->  00:04:36.900
All right.

77

00:04:36.900  -->  00:04:40.290
We're going to try to do this as quick as possible.

78

00:04:42.030  -->  00:04:43.450
Want my time myself.

79

00:04:43.560  -->  00:04:50.580
But first the simpler task of course I got it down to like 49 seconds I think that was pretty fast anyway

80

00:04:50.580  -->  00:04:50.720
.

81

00:04:50.880  -->  00:04:52.620
Floodwall source.

82

00:04:53.250  -->  00:04:58.860
Yep obviously always you know a flat Passau is always need a destination.

83

00:04:58.870  -->  00:05:01.830
And as we already know we're going to have two conditional splits.

84

00:05:01.830  -->  00:05:08.560
Other transforms Where are all conditional splits because we're going to have to have them because we

85

00:05:08.560  -->  00:05:15.900
want to take out bad records and take out records that don't have sufficient information.

86

00:05:15.900  -->  00:05:18.530
Next we're going to flood the station.

87

00:05:18.540  -->  00:05:22.350
That's where one type of error is going to go that's where the other type is going to go.

88

00:05:22.530  -->  00:05:23.730
So everything's ready.

89

00:05:23.740  -->  00:05:26.620
First we start with them source right.

90

00:05:26.680  -->  00:05:28.310
So where is our folder.

91

00:05:28.330  -->  00:05:30.110
There's a folder.

92

00:05:30.150  -->  00:05:30.980
Go back here.

93

00:05:31.000  -->  00:05:37.150
Create a new flat file connection manager browse look at looking for its history file.

94

00:05:37.140  -->  00:05:38.540
There it is.

95

00:05:38.610  -->  00:05:45.630
Take Scuola fire columns look through the columns as we can see those two empty columns have been indeed

96

00:05:45.660  -->  00:05:46.660
added.

97

00:05:46.690  -->  00:05:49.480
There are probably some shifts here but we don't really care.

98

00:05:49.500  -->  00:05:53.060
This was more of a practice thing for us in the actual course.

99

00:05:53.060  -->  00:05:58.090
Now we know how to deal with this automatically so it don't even bother about searching for them in

100

00:05:58.080  -->  00:05:59.550
that specific window.

101

00:05:59.620  -->  00:06:04.150
So here we're going to set everything to a thousand.

102

00:06:04.140  -->  00:06:06.480
Hopefully it fits preview.

103

00:06:06.610  -->  00:06:10.930
Once again you can check columns.

104

00:06:11.040  -->  00:06:12.550
All right so here's another area.

105

00:06:12.560  -->  00:06:16.950
Here's a new era which we didn't have in the course so doing this homework.

106

00:06:17.250  -->  00:06:20.260
You probably freaks out when you saw this.

107

00:06:20.260  -->  00:06:21.290
I'm sure you didn't.

108

00:06:21.490  -->  00:06:23.710
I'm sure you were fine with it so what does it say.

109

00:06:23.700  -->  00:06:29.080
It says that era at dataflow task this was like a surprise error for you.

110

00:06:29.070  -->  00:06:33.560
Delphos task there is more than one data source column with the name name.

111

00:06:33.660  -->  00:06:36.040
The data source code must names must be unique.

112

00:06:36.090  -->  00:06:37.290
So what does that mean.

113

00:06:37.290  -->  00:06:40.500
That means our data set has two columns of the same name.

114

00:06:40.500  -->  00:06:42.230
So we're going to have to cancel this.

115

00:06:42.250  -->  00:06:45.180
We're gonna have to go back to the data set and investigate.

116

00:06:45.190  -->  00:06:49.560
Once again we're not touching our original data right so what are we going to do.

117

00:06:49.560  -->  00:06:56.050
Now we're going to delete this because the upload failed and any changes that you make you have to make

118

00:06:56.040  -->  00:06:59.720
in your prepared data so let's go ahead and have a look here.

119

00:06:59.760  -->  00:07:00.300
So here you go.

120

00:07:00.300  -->  00:07:06.090
Numbered gender title name name address so that's all problem.

121

00:07:06.110  -->  00:07:07.270
They're the same.

122

00:07:07.260  -->  00:07:07.980
We have to re.

123

00:07:08.010  -->  00:07:09.220
We have to fix this.

124

00:07:09.250  -->  00:07:12.330
We are in the prepared data folder so we can fix it right away.

125

00:07:12.570  -->  00:07:17.550
In this yes we file in Notepad plus plus the first one here.

126

00:07:17.550  -->  00:07:24.300
Natasha Nathan Chan innocence Valentine those are first names.

127

00:07:24.300  -->  00:07:31.790
Second one is surnames so let's change this surname save.

128

00:07:31.920  -->  00:07:33.050
That's right.

129

00:07:33.050  -->  00:07:34.460
Just say that right.

130

00:07:34.690  -->  00:07:35.490
Close.

131

00:07:35.640  -->  00:07:35.970
Good.

132

00:07:35.980  -->  00:07:42.580
Now we can take this copyright copy and we'll put in uploaded daughter.

133

00:07:42.920  -->  00:07:43.400
OK.

134

00:07:43.620  -->  00:07:47.760
I'm real curious how you went with that surprise there it was.

135

00:07:47.760  -->  00:07:49.570
You probably went fine I'm sure.

136

00:07:49.560  -->  00:07:50.230
Anyway.

137

00:07:50.400  -->  00:07:53.840
So we get you a flat file source new.

138

00:07:53.850  -->  00:07:55.160
Let's do this again.

139

00:07:55.320  -->  00:08:00.400
This is what I mean when I say 70 percent of the time is done upload it because you have to redo so

140

00:08:00.390  -->  00:08:01.890
much stuff.

141

00:08:01.980  -->  00:08:03.450
Daughter prep prep soon.

142

00:08:03.490  -->  00:08:06.270
In about 10 it takes qualified columns.

143

00:08:06.270  -->  00:08:08.350
Good good.

144

00:08:08.670  -->  00:08:12.780
Now let's have a look here we could have actually noticed that here but we weren't looking for it right

145

00:08:12.780  -->  00:08:13.060
.

146

00:08:13.080  -->  00:08:14.920
So name surname good.

147

00:08:15.030  -->  00:08:20.850
Now all of this goes to a thousand awesome preview.

148

00:08:20.860  -->  00:08:24.270
All right but see if it lets us create it now looking good.

149

00:08:24.650  -->  00:08:27.950
OK let's connect conditional split.

150

00:08:28.000  -->  00:08:32.000
So what are we going to do first in the course we first looked at.

151

00:08:32.010  -->  00:08:36.210
Or rows that had insufficient data so let's go ahead and do the same here.

152

00:08:36.490  -->  00:08:45.720
So this is going to be insufficient data and condition here is going to be that one of our columns is

153

00:08:45.820  -->  00:08:54.270
empty one of the critical columns so let's use Lenn and look at all Criddle columns.

154

00:08:54.270  -->  00:09:00.420
They here blood type sorites equals zero or so you can type these up yourself.

155

00:09:00.420  -->  00:09:03.560
You don't have to drag them from there if you know them.

156

00:09:04.570  -->  00:09:05.900
So every blood type.

157

00:09:05.940  -->  00:09:08.030
Yep kilograms equals zero.

158

00:09:08.050  -->  00:09:10.760
Or finally.

159

00:09:11.130  -->  00:09:12.970
So which one Len.

160

00:09:13.610  -->  00:09:17.740
Centimeters centimeters equals zero.

161

00:09:18.000  -->  00:09:26.330
OK so the thing you should notice here is that because our critical columns are at the very end we're

162

00:09:26.350  -->  00:09:33.550
going to have a bit of an overlap between errors well is insufficient data and errors where there is

163

00:09:35.910  -->  00:09:37.200
a bad record.

164

00:09:37.300  -->  00:09:42.090
And that's just because of the methodology that we're using but we'll talk about that when we get to

165

00:09:42.100  -->  00:09:42.210
it.

166

00:09:42.210  -->  00:09:43.390
So that's fine.

167

00:09:43.380  -->  00:09:47.230
Insufficient data then we'll just see say check past.

168

00:09:48.090  -->  00:09:54.820
OK so here we want to put everything not check possed insufficient data and put it in there.

169

00:09:54.850  -->  00:09:56.830
Let's create this file right away.

170

00:09:57.370  -->  00:10:00.710
It's going to be a delimited file browse.

171

00:10:00.780  -->  00:10:02.450
So upload a daughter up.

172

00:10:02.470  -->  00:10:04.650
No analysis right so we're going to

173

00:10:07.580  -->  00:10:16.940
create a folder so that say upload errors and here we're going to create a file a new text document

174

00:10:16.940  -->  00:10:17.780
.

175

00:10:18.080  -->  00:10:19.440
Once again the date.

176

00:10:19.550  -->  00:10:25.050
And then we're going to say in sufficient data.

177

00:10:25.440  -->  00:10:31.070
Also we have to of course we have to look at the name of the file so fake names.

178

00:10:31.080  -->  00:10:34.010
OK so is fix that up.

179

00:10:34.310  -->  00:10:37.990
Fake fake names UK.

180

00:10:38.450  -->  00:10:39.560
Insufficient data.

181

00:10:39.680  -->  00:10:40.740
All right.

182

00:10:41.060  -->  00:10:43.610
Maybe put this together.

183

00:10:43.610  -->  00:10:44.140
All right.

184

00:10:44.180  -->  00:10:45.670
Open it up.

185

00:10:45.670  -->  00:10:47.470
Call the fire.

186

00:10:47.480  -->  00:10:48.950
Call them names.

187

00:10:48.950  -->  00:10:52.270
Columns advanced preview.

188

00:10:52.310  -->  00:10:53.410
Good mappings.

189

00:10:53.450  -->  00:10:54.540
Click the mappings.

190

00:10:54.580  -->  00:10:57.910
OK so that's done now and this conditional split.

191

00:10:57.920  -->  00:11:02.710
We're going to check for corrupt records using that methodology which we talked about.

192

00:11:02.710  -->  00:11:10.690
So we're going to say sharing functions if condition L-N of.

193

00:11:10.790  -->  00:11:11.100
All right.

194

00:11:11.110  -->  00:11:12.850
So anything else shifts to the right.

195

00:11:12.860  -->  00:11:16.130
This is going to be greater than zero or

196

00:11:18.650  -->  00:11:25.980
Lenn centimeters is equal to.

197

00:11:26.030  -->  00:11:26.320
Right.

198

00:11:26.320  -->  00:11:27.720
So there's nothing in that call.

199

00:11:27.830  -->  00:11:32.490
So the interesting thing here is that because we already check this condition then equal then scenarios

200

00:11:32.510  -->  00:11:33.520
equals zero.

201

00:11:33.530  -->  00:11:38.370
This is never going to be the case because all of these records with Lenn of sending me Jersey colza

202

00:11:38.370  -->  00:11:41.390
are already in the insufficient data folder.

203

00:11:41.390  -->  00:11:46.310
So that's what I meant when I said that we're going to have an overlap and that just means that we're

204

00:11:46.310  -->  00:11:53.690
going to have to deal with those errors in that other file and yeah will once we have theirs and we

205

00:11:53.690  -->  00:11:57.980
can then look at them and understand whether it's a corrupt record or it's just insufficient data.

206

00:11:58.160  -->  00:11:59.660
But this happens sometimes.

207

00:11:59.720  -->  00:12:04.610
So I'll put name again just say bad records.

208

00:12:04.610  -->  00:12:09.280
So basically this condition is only going to pick up requisite to shift to the right.

209

00:12:09.840  -->  00:12:10.560
OK.

210

00:12:10.820  -->  00:12:15.000
And here we're going to say good records.

211

00:12:15.050  -->  00:12:16.880
All right.

212

00:12:16.880  -->  00:12:20.920
Let's connect this here I'm going to say good records.

213

00:12:21.320  -->  00:12:22.510
Looks good.

214

00:12:22.550  -->  00:12:24.650
And here we are going to see better records.

215

00:12:24.680  -->  00:12:27.870
Let's create a new file here delimited.

216

00:12:28.330  -->  00:12:28.960
OK.

217

00:12:28.980  -->  00:12:30.100
Browse.

218

00:12:30.510  -->  00:12:41.710
So we might even just copy that saves time and we'll call it bad records.

219

00:12:41.810  -->  00:12:46.590
Select it takes Hell-Fire call names home.

220

00:12:46.600  -->  00:12:47.540
Yep that's good.

221

00:12:47.690  -->  00:12:51.900
That's all good looking good mappings looking good.

222

00:12:52.340  -->  00:12:59.110
And D-B All right this the fun part of create a new connection table.

223

00:12:59.540  -->  00:13:04.060
So what are you going to call table row fake names.

224

00:13:04.060  -->  00:13:05.490
OK.

225

00:13:05.770  -->  00:13:06.430
Whoops.

226

00:13:06.430  -->  00:13:08.990
15 0 9 0 9.

227

00:13:09.290  -->  00:13:12.800
As we usually do in identity.

228

00:13:13.200  -->  00:13:21.190
Well this is going to be row number and then int identity.

229

00:13:22.220  -->  00:13:22.640
All right.

230

00:13:22.670  -->  00:13:23.420
Good.

231

00:13:23.900  -->  00:13:26.290
So create the table check the mappings.

232

00:13:26.390  -->  00:13:27.380
Looks good.

233

00:13:27.740  -->  00:13:29.130
All right here.

234

00:13:29.150  -->  00:13:32.260
I got to fix this up.

235

00:13:32.750  -->  00:13:34.230
Default called page code page.

236

00:13:34.230  -->  00:13:35.210
True.

237

00:13:35.210  -->  00:13:37.440
All right so this is all ready to go.

238

00:13:37.460  -->  00:13:41.130
Let's save it and let's launch it.

239

00:13:42.260  -->  00:13:46.460
And I might just zoom in a little bit so we see how we going.

240

00:13:46.520  -->  00:13:47.780
And so far so good.

241

00:13:47.780  -->  00:13:51.500
We've got some insufficient data piling up here some bad records.

242

00:13:51.500  -->  00:13:58.410
Which only includes Rose shifted to the right and the ones shipped to left here.

243

00:13:58.460  -->  00:14:04.180
So as you remember there's about 100000 rows here we're about just past half way.

244

00:14:04.190  -->  00:14:07.050
This is actually an interesting way to structure your data flow.

245

00:14:07.100  -->  00:14:12.000
Everything going Dallam is straight through and into the writes bed records.

246

00:14:12.230  -->  00:14:14.170
And then we go we actually have an error.

247

00:14:14.180  -->  00:14:18.470
So we got that far eighty five thousand and something happened here.

248

00:14:18.740  -->  00:14:20.970
All right so what happened let's have a look.

249

00:14:21.320  -->  00:14:25.550
Pat package execution is go to execution results.

250

00:14:25.970  -->  00:14:27.660
And so we've got the warnings.

251

00:14:27.680  -->  00:14:30.220
Here's the arrow.

252

00:14:30.530  -->  00:14:31.100
There you go.

253

00:14:31.100  -->  00:14:32.050
So what does it say here.

254

00:14:32.050  -->  00:14:35.570
Flood Plus flood file source outputs.

255

00:14:35.960  -->  00:14:40.740
So the truncation road disposition on failed because truncation occurred.

256

00:14:40.970  -->  00:14:46.250
And so that it tells you that the column was the address column.

257

00:14:46.250  -->  00:14:52.610
All right well let's go back and fix this up before we fix it up though.

258

00:14:52.610  -->  00:14:57.470
One thing we have to do is because this failed we have to go to our database

259

00:15:00.060  -->  00:15:05.340
which is here and find this file so refresh fake names.

260

00:15:05.360  -->  00:15:06.030
OK.

261

00:15:06.440  -->  00:15:10.250
So I looked up thousand rows and now we know it failed so we're going to have to redo it.

262

00:15:10.250  -->  00:15:17.640
So right away let's get rid of the dot in this file We're going to truncate table and execute.

263

00:15:17.640  -->  00:15:24.840
So we got rid of the data in the file so it was in the table if we select the â‚¬2000 is nothing because

264

00:15:24.900  -->  00:15:27.720
obviously we're going to upload we want we don't want duplicate.

265

00:15:27.730  -->  00:15:29.220
Very important to do that.

266

00:15:29.220  -->  00:15:30.330
All right cool.

267

00:15:30.330  -->  00:15:33.360
So that is going to have to be rerun.

268

00:15:33.510  -->  00:15:36.390
We know that the problem is in the address column.

269

00:15:36.810  -->  00:15:41.560
So let's go ahead and open this up.

270

00:15:41.560  -->  00:15:48.390
We remember that it's flat file connection manager one let's find it here and here we're going to have

271

00:15:48.390  -->  00:15:55.440
to go to advanced address and change this to let's say 5000.

272

00:15:55.590  -->  00:15:58.260
Now at the same time I wouldn't share an extra trick here.

273

00:15:58.260  -->  00:16:02.820
We know that address can be 5000 can even be a thousand symbols.

274

00:16:02.820  -->  00:16:03.960
That's just ridiculous.

275

00:16:03.960  -->  00:16:06.610
It can be a proper address something is wrong.

276

00:16:06.840  -->  00:16:15.660
So we're going to add a next condition into our bad record so bad records are here.

277

00:16:15.760  -->  00:16:22.060
We're going to say that we want a thing with the address which is too long to also be considered bad

278

00:16:22.070  -->  00:16:22.590
record.

279

00:16:22.740  -->  00:16:30.390
So here we're going to add another condition we're going to say or Lenn of as find that column.

280

00:16:30.660  -->  00:16:31.850
So we don't have to type it up.

281

00:16:31.860  -->  00:16:34.890
Address right is greater.

282

00:16:34.920  -->  00:16:38.490
Let's say what's reasonable for an address 10 20 30 maybe 100.

283

00:16:38.490  -->  00:16:41.850
So you think over 200 symbols for analysis definitely wrong.

284

00:16:41.910  -->  00:16:44.620
And we want to exclude it so click OK.

285

00:16:44.790  -->  00:16:53.020
So what will happen will happen now is that the you know we need to update the source and the connection

286

00:16:53.020  -->  00:16:53.330
manager.

287

00:16:53.330  -->  00:16:53.960
Ok cool.

288

00:16:53.970  -->  00:16:57.020
So we want to just make sure that everything is good.

289

00:16:57.120  -->  00:16:57.630
All right.

290

00:16:57.630  -->  00:17:03.180
So what will happen now is that the comb will be read or that record will be read by the flat file source

291

00:17:03.180  -->  00:17:03.430
.

292

00:17:03.630  -->  00:17:04.830
It will go past this.

293

00:17:04.830  -->  00:17:09.400
It won't go past is here we go into the air so it won't add up and up in the database.

294

00:17:09.510  -->  00:17:14.430
And that is just an example of how you can add your own conditions into these conditional splits.

295

00:17:14.430  -->  00:17:17.160
You might want to take that address and actually put into different file.

296

00:17:17.160  -->  00:17:23.820
You can also do that you can add any conditions that you like that are governed by the knowledge you

297

00:17:23.820  -->  00:17:24.900
have of the data set.

298

00:17:25.080  -->  00:17:25.870
So that's all good.

299

00:17:25.890  -->  00:17:32.920
Let's go ahead and save that and run it again and hopefully this time it will run better.

300

00:17:32.970  -->  00:17:34.410
So once again let's zoom in

301

00:17:38.010  -->  00:17:41.580
and we're coming near the end so there we go.

302

00:17:41.580  -->  00:17:43.910
Everything looks good.

303

00:17:43.980  -->  00:17:44.580
Awesome.

304

00:17:44.670  -->  00:17:48.590
So ninety nine thousand seven hundred thirty one five bad records.

305

00:17:48.630  -->  00:17:52.550
And we can probably find our very long address in here as well.

306

00:17:52.650  -->  00:17:58.290
So before we do that let's go and do the main thing we have to do we have to stop the debugging process

307

00:17:58.290  -->  00:17:59.140
.

308

00:17:59.190  -->  00:18:03.860
Now we have to go to control flow and disable is doubtful to us.

309

00:18:03.870  -->  00:18:06.350
And we actually should give it a name probably.

310

00:18:07.170  -->  00:18:09.010
But I won't do that now.

311

00:18:09.060  -->  00:18:15.440
So now if I go to fake names There's my daughter which is good.

312

00:18:15.810  -->  00:18:23.970
And now let's go quickly have a look at what happened here and now says upload errors.

313

00:18:24.060  -->  00:18:27.170
So this is all bad records.

314

00:18:27.510  -->  00:18:29.520
So way here should be the very long address.

315

00:18:29.520  -->  00:18:29.970
There it is.

316

00:18:29.970  -->  00:18:33.140
Remember those and around 85000 So there's a long address.

317

00:18:33.300  -->  00:18:40.590
What happened here just a lot of spaces just some some problem occurred and a lot of spaces ended up

318

00:18:40.590  -->  00:18:45.240
in this column and that's why it's so very easy to fix just get rid of the spaces.

319

00:18:45.360  -->  00:18:50.220
Once again you do need to verify these all these things if you're going to make sure you put the data

320

00:18:50.220  -->  00:18:55.590
back in then these ones some some shifts occurred and so on.

321

00:18:55.980  -->  00:19:00.570
Like we do talked about Tech's qualifiers a lot before sort of won't go back to the files you want to

322

00:19:00.600  -->  00:19:01.860
investigate each one separately.

323

00:19:01.860  -->  00:19:06.050
Go back to the whole file and you find that row number understand what happened.

324

00:19:06.540  -->  00:19:08.540
And insufficient data.

325

00:19:08.550  -->  00:19:15.180
So here we've got quite a lot of rows which includes both insufficient data and corrupted records shifted

326

00:19:15.180  -->  00:19:17.010
to the left.

327

00:19:17.460  -->  00:19:20.000
And once again you might.

328

00:19:20.040  -->  00:19:22.090
You know you've got to you've got the numbers here.

329

00:19:22.110  -->  00:19:28.920
So actually some of them don't have the numbers like this one actually doesn't have a number and you

330

00:19:28.920  -->  00:19:30.750
can and you can Silversea it for them.

331

00:19:30.750  -->  00:19:33.210
And what happened or send it back to the correct person.

332

00:19:33.300  -->  00:19:40.650
But basically this is our e t l phases 1 and 2 done as you could see we had a few errors and we were

333

00:19:40.680  -->  00:19:42.640
able to deal with them properly.

334

00:19:42.670  -->  00:19:49.020
Ok so I trust you went well with that homework and I look forward to seeing you back inside the course

335

00:19:49.020  -->  00:19:49.090
.

336

00:19:49.140  -->  00:19:51.180
Until next time happy analyzing
