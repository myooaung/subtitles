WEBVTT
1

00:00:05.580 --> 00:00:06.500

Welcome back everyone.



2

00:00:06.540 --> 00:00:10.430

For the solution to machine learning interview question number seven.



3

00:00:10.500 --> 00:00:15.320

So this question was just in general describe how the support vector machine or SVM algorithm works.



4

00:00:15.330 --> 00:00:18.780

So let's go ahead and give a brief overview of how it works.



5

00:00:19.810 --> 00:00:21.160

So support vector machine.



6

00:00:21.160 --> 00:00:26.920

What it does it attempts to find a hyperplane that separates classes by maximizing the margin.



7

00:00:27.040 --> 00:00:31.580

So we can see here a very simple example of support vector classification.



8

00:00:31.600 --> 00:00:36.520

So here we have some red squares and blue circles that we're trying to classify.



9

00:00:36.730 --> 00:00:43.690

So we end up doing is we define a hyperplane along these two them mentions and then we find these margins



10

00:00:43.750 --> 00:00:49.090

are trying to maximize the margin basically trying to get as much space as we can between these two



11

00:00:49.090 --> 00:00:50.000

classes.



12

00:00:50.750 --> 00:00:56.270

The filled in points in this diagram are what we call the support vectors and those are ones against



13

00:00:56.270 --> 00:00:56.840

that decision.



14

00:00:56.840 --> 00:01:01.730

Hyperplane where off the optimal hyperplane we have these margins and that's where we make our decision.



15

00:01:01.730 --> 00:01:07.580

So if we have a new point depending on where it lies on the hyperplane that's where we're going to classify



16

00:01:07.580 --> 00:01:07.810

it.



17

00:01:07.970 --> 00:01:13.730

So you can see here clearly if we have something with a low X-1 value and a low X-2 value that falls



18

00:01:13.730 --> 00:01:15.780

on the other side of that max margin.



19

00:01:15.800 --> 00:01:21.470

So that will be classified as a Red Square and vice versa something really high X1 value and a really



20

00:01:21.470 --> 00:01:25.270

high X to value is going to fall on the other side of the other margin.



21

00:01:25.430 --> 00:01:27.590

And then there will be classified as a blue circle.



22

00:01:27.710 --> 00:01:33.680

So those filled end points the ones that rest against that margin or what is actually called the support



23

00:01:33.680 --> 00:01:37.960

vector because it's essentially supporting that margin.



24

00:01:37.990 --> 00:01:42.340

So here we're actually showing linear classification but remember that support vector machines can perform



25

00:01:42.340 --> 00:01:44.120

nonlinear classification.



26

00:01:44.410 --> 00:01:50.320

So support vector machines the employee what's called the kernel trick which can map linear non separable



27

00:01:50.380 --> 00:01:55.210

inputs into a higher dimension where they become more easily separable and you can check out lots of



28

00:01:55.210 --> 00:02:00.910

great visualizations online and the resources in your guidebook to visualize how you can view something



29

00:02:00.910 --> 00:02:03.440

in a higher dimension in order to separate it.



30

00:02:03.620 --> 00:02:04.900

OK I hope that was helpful.



31

00:02:04.900 --> 00:02:06.780

Thanks everyone and I'll see you at the next lecture.



