1
00:00:05,560 --> 00:00:08,670
Welcome everyone to the solution for machine learning question number three.

2
00:00:09,500 --> 00:00:14,000
So this question was asking how does a decision tree decide on its splits so what is the criteria for

3
00:00:14,000 --> 00:00:15,050
a split point.

4
00:00:16,520 --> 00:00:21,440
So in general decision tree can use the information game side on the splitting points or the splitting

5
00:00:21,440 --> 00:00:22,400
criteria.

6
00:00:22,400 --> 00:00:24,580
And that also involves using entropy.

7
00:00:24,800 --> 00:00:29,390
So let's give a brief overview of how this works and if you want more information that's more detail

8
00:00:29,390 --> 00:00:30,650
than this brief overview.

9
00:00:30,770 --> 00:00:34,700
You can check out the resources in the guidebook.

10
00:00:34,850 --> 00:00:39,410
So the decision tree is built in a top down fashion where we have that root node at the top and then

11
00:00:39,410 --> 00:00:41,140
it branches down to other nodes.

12
00:00:41,240 --> 00:00:45,110
But the question that we're trying to answer here is how do you choose which attributes to split at

13
00:00:45,110 --> 00:00:46,030
each node.

14
00:00:46,310 --> 00:00:51,230
And the answer is to find the feature that best splits the target class into the purest possible children

15
00:00:51,230 --> 00:00:53,350
notes.

16
00:00:53,400 --> 00:00:58,950
So this measure of purity is called the information and it represents the expected amount of information

17
00:00:59,250 --> 00:01:05,610
that would be needed to specify whether a new instance should be classified 0 or 1 or in this case whatever

18
00:01:05,650 --> 00:01:07,190
Clora classification you're doing.

19
00:01:07,320 --> 00:01:10,950
Maybe you're classifying things since I'm male or female cats or dogs.

20
00:01:11,070 --> 00:01:11,730
Cetera.

21
00:01:12,000 --> 00:01:18,270
So we want to find the amount that this information is represented the expected amount information that

22
00:01:18,270 --> 00:01:26,490
we need to specify that sort of classification given whatever example ended up reaching that node So

23
00:01:26,580 --> 00:01:29,250
entropy on the other hand is a measure of impurity.

24
00:01:29,250 --> 00:01:32,210
So it's basically the opposite of the information.

25
00:01:32,490 --> 00:01:37,160
And it's defined for a binary class with values a B as the following.

26
00:01:37,170 --> 00:01:44,280
The probability of a Times the log probability of a minus probability belonging to b times the log probability

27
00:01:44,280 --> 00:01:44,870
of B.

28
00:01:45,000 --> 00:01:49,060
And if you plot this out eventually you get a curve that looks something like this.

29
00:01:50,840 --> 00:01:57,050
So what ends up happening is you compare the entropy before and after the split and from that you can

30
00:01:57,050 --> 00:02:02,960
measure information gain or basically how much information gains how much information is being gained

31
00:02:03,020 --> 00:02:05,470
by doing the split using that particular feature.

32
00:02:05,750 --> 00:02:11,630
And so this information gain can be calculated as the entropy before the split minus the entropy after

33
00:02:11,630 --> 00:02:12,530
the split.

34
00:02:12,980 --> 00:02:19,760
So overall we are trying to do is figure out what splitting point is going to separate these inputs

35
00:02:19,940 --> 00:02:21,850
best into their two classes.

36
00:02:21,850 --> 00:02:27,350
That's the overall idea of information gain information gain and entropy basically give you the mathematics

37
00:02:27,680 --> 00:02:30,060
of how you can do that formally.

38
00:02:30,050 --> 00:02:34,970
There's also other things like GINI index as far as other splitting criteria you could use and you can

39
00:02:34,970 --> 00:02:38,900
check out the resources in the Guidebook for more information on those.

40
00:02:38,900 --> 00:02:40,880
Thanks everyone and I'll see you at the next lecture.

