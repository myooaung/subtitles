WEBVTT

00:00.600 --> 00:04.740
Hello and welcome back to the course on deep learning today we're talking about Max pooling and we've

00:04.740 --> 00:07.320
got some very exciting slides coming up ahead.

00:07.440 --> 00:10.890
And even a special surprise at the very end of the tutorial.

00:10.980 --> 00:12.390
So let's get started.

00:12.390 --> 00:15.820
The first question is what is pulling and why do we need it.

00:15.990 --> 00:20.710
Well to answer that question let's have a look at these images and these images we've got a cheetah.

00:20.730 --> 00:23.610
In fact is the same exact cheetah on the first image.

00:23.610 --> 00:29.610
That image is positioned properly and the it is looking straight at you on the second image.

00:29.610 --> 00:30.600
It's a bit rotated.

00:30.600 --> 00:32.550
And the third image a bit squashed.

00:32.730 --> 00:39.960
And the thing here is that we want the neural network to be able to recognize the cheetah in every single

00:39.960 --> 00:41.390
one of these images.

00:41.400 --> 00:45.030
In fact this is just one sheet of what if we have lots of different shooters.

00:45.030 --> 00:47.200
Here's a cheetah Here's a cheetah.

00:47.340 --> 00:50.440
Here's another cheetah his Ashira his a cheetah.

00:50.550 --> 00:55.680
And here's a cheetah and we want the neural network to recognize all of these Shearer's as cheaters

00:56.250 --> 00:59.400
and how can it do that.

00:59.730 --> 01:04.470
If they're all looking in different directions they're all in different parts of the image they're like

01:04.470 --> 01:08.780
their faces are positioned in different parts of the image somebody is on the right hand side somebody

01:08.780 --> 01:10.950
is in the left corner somebody is in the middle.

01:10.950 --> 01:14.250
They're all a bit different and the texture is a little bit different.

01:14.250 --> 01:16.140
The lighting is a bit different.

01:16.140 --> 01:21.570
There's lots of little differences and so if the neural network looks for exactly a certain feature

01:21.750 --> 01:29.640
for instance a distinctive feature of the cheetah is the tears that are on its face going from the eyes

01:29.640 --> 01:35.610
or the sheer the shadows that look like tears the texture of the pattern that is going from its eyes

01:35.610 --> 01:40.770
down it's on the sides of its nose and looks like tears that's a distinctive feature of the Cheetah.

01:40.830 --> 01:48.600
But if it's looking for that feature which it learned from certain cheetahs in an exact location or

01:48.600 --> 01:53.310
an exact shape or form or texture it will never find these other shooters.

01:53.400 --> 02:01.350
So we have to make sure that our neural network has a property called spatial invariance meaning that

02:01.380 --> 02:10.110
it doesn't care where the features are can not not so much as an itch which part of the image because

02:10.320 --> 02:13.770
we are we've kind of taken that into consideration with our map.

02:13.770 --> 02:21.210
We are poor we are convolutional there but it doesn't have to care if the features are a bit tilted

02:21.240 --> 02:26.460
if the features are a bit different in texture if the features are a bit closer or features or a bit

02:26.730 --> 02:30.150
further apart relative to relative to each other.

02:30.150 --> 02:37.170
So if the feature itself is a bit distorted our neural network has to have some level of flexibility

02:37.380 --> 02:42.610
to be able to still find that feature and that is what pooling is all about.

02:42.630 --> 02:44.890
So let's have a look at how pooling works.

02:45.120 --> 02:51.060
Here's our feature map so we've already done our convolution and we've completed that part and now we're

02:51.060 --> 02:52.610
working with the convolutional there.

02:52.620 --> 02:53.850
Now we're going to apply pooling.

02:53.850 --> 02:54.630
So how does it work.

02:54.630 --> 02:56.500
We're going to be applying box pooling.

02:56.610 --> 03:01.500
There's several different types of it complies mean pooling Max pulling some pulling and we'll come

03:01.490 --> 03:03.410
in on those towards the end of the store.

03:03.480 --> 03:10.980
But for now we're just applying Max pooling so we take a box of two by two pixels like that and again

03:10.980 --> 03:14.960
it doesn't have to be two by two you can choose any size of box and again we'll comment on that towards

03:14.960 --> 03:21.570
and end Tauriel and you place it in the top left hand corner and you find the maximum value in that

03:21.570 --> 03:26.250
box and then you record only that value and you disregard the other three.

03:26.250 --> 03:29.040
So in your box you have four values you just disregard three.

03:29.040 --> 03:31.770
You only keep one the maximum which is one in this case.

03:31.770 --> 03:36.180
Then you move your box to the right by stride you select the stride once again.

03:36.180 --> 03:42.140
So here we slide the stride of two and that's what you normally like you can say like this try to one

03:42.150 --> 03:42.960
you can select.

03:42.960 --> 03:47.880
So there are overlapping boxes you can select any kind of strike that you like even three if you want

03:48.750 --> 03:52.380
but we're selecting a stride of two here and that's what is commonly used.

03:52.410 --> 03:57.890
And then you repeat repeat the process you record the maximum here if you cross over and doesn't matter.

03:57.900 --> 04:00.040
You just keep continue doing what you're doing.

04:00.060 --> 04:05.590
So you still record the maximum here Zero here the maximum is four.

04:05.590 --> 04:11.320
Here are the maximums to here the maximum is 1 0 1 0 2 and then 1.

04:11.340 --> 04:13.940
So as you can see a few things happened.

04:13.950 --> 04:18.840
First of all we still were able to preserve the features right.

04:19.040 --> 04:23.700
The maximal numbers they represent because we know how they can BlueShield their works.

04:23.700 --> 04:28.590
We know that the maximal or the large numbers in your feature map they're present where you actually

04:28.590 --> 04:31.470
found the closest similarity to feature.

04:31.590 --> 04:38.220
But by then pulling these features we are first of all getting rid of 75 percent of the information

04:38.220 --> 04:46.050
that is not the feature which is which is not the important things that we're looking out for because

04:46.150 --> 04:49.600
we're just of three pixels out of four.

04:49.650 --> 04:51.540
So we're only getting 25 percent.

04:51.650 --> 05:00.380
And then also because we are taking the maximum of the pixels that we or the values that we.

05:00.710 --> 05:04.130
We are therefore accounting for any distortion.

05:04.130 --> 05:12.770
So for instance two images in which for example the cheater's tears on the eyes are in one image there

05:12.770 --> 05:16.500
a bit to the left or a bit rotated to the left and another one there a bit.

05:16.520 --> 05:22.090
And are how they're supposed to be or how we like if we take one as the bases and another one their

05:22.100 --> 05:23.640
bits rotate to the left.

05:23.640 --> 05:26.510
The feet the puled feature will be exactly the same.

05:26.510 --> 05:32.840
So you can see here if we are talking about the cheater's tears then let's say this is the four and

05:32.840 --> 05:35.990
this is where it was here then if it was a bit rotated.

05:35.990 --> 05:38.220
So for instance the four ended up over here.

05:38.330 --> 05:44.120
Then when we are doing the pooling we're still going to get the same puled feature map and that's kind

05:44.120 --> 05:46.310
of the principle behind it.

05:46.350 --> 05:52.310
It's a very rough explanation again intuitive explanation but that's the point of pooling that we're

05:52.310 --> 06:00.230
still being able to preserve the features and moreover account for their possible spatial or textural

06:00.230 --> 06:02.200
or other kind of distortions.

06:02.360 --> 06:07.340
And in addition to all of that we are reducing the size so there's another benefit.

06:07.340 --> 06:12.890
So we've got to we're preserving the features we're introducing spatial invariants we're reducing the

06:12.890 --> 06:21.230
size by 75 percent which is huge which is really going to help us in terms of processing and moral moreover

06:21.440 --> 06:27.470
another benefit of pooling is we are reducing the number of parameters so we are reducing again by 75

06:27.470 --> 06:32.170
percent or reducing number of parameters that are going to go into our final Lares of the neural network

06:32.630 --> 06:35.220
and therefore we're preventing overfitting.

06:35.240 --> 06:42.520
It is a very important benefit of pooling that we're removing information and that is a good thing.

06:42.530 --> 06:50.600
That is a good thing because that way our model won't be able to over fit onto that information because

06:50.630 --> 06:54.440
especially because that information is not real Remember like at the very start we were talking about

06:54.890 --> 07:00.620
even for human says humans it's important to see exactly the features rather than all the other noise

07:00.620 --> 07:02.720
that is coming into our eyes.

07:02.720 --> 07:09.010
Well same thing for neural networks they by disregarding the unnecessary non-important formation we're

07:09.020 --> 07:12.150
helping with preventing of overfitting.

07:12.440 --> 07:13.010
So there we go.

07:13.010 --> 07:14.550
That is what pulling is about.

07:14.570 --> 07:21.440
And the question here is of course why WiMax pooling right there's lots of different types of pooling

07:21.650 --> 07:26.590
and you know why why a stride of two why a size of two by two pixels Lots of all these things.

07:26.720 --> 07:33.920
And on that note I'd like to introduce you to this lovely research paper called evaluation of pooling

07:33.920 --> 07:40.190
operations in convolutional architectures for object recognition by Dominic Scherrer from University

07:40.190 --> 07:41.130
of born.

07:41.140 --> 07:47.500
There's the link and the beauty about this paper is that it's very very simple very straightforward

07:47.510 --> 07:53.240
So if you've never read a research paper before what you'd like to give it a go this is a great place

07:53.240 --> 07:54.370
to start it's very short.

07:54.380 --> 07:55.340
Only 10 pages.

07:55.340 --> 07:56.840
Very easy to read.

07:57.020 --> 08:03.740
And plus the benefit is that now that we've discussed convolution and pooling you will be totally comfortable

08:03.740 --> 08:07.000
with everything that they're talking about in this paper in you.

08:07.070 --> 08:11.880
This is a great way to actually reinforce your knowledge so I highly recommend checking this paper out.

08:11.870 --> 08:17.990
I'll take 20 minutes to read it and you can even skip part 2 which is called related work if it feels

08:17.990 --> 08:21.140
a bit far fetched or alienating just don't read that part.

08:21.260 --> 08:23.670
Go straight to from part 1 to part 3.

08:23.870 --> 08:29.530
And one thing that you do need to know about this paper they talk about a concept called subsampling

08:30.210 --> 08:33.170
while subsampling is basically average pooling.

08:33.170 --> 08:37.340
So remember how Here we were taking we we're taking the maximum.

08:37.340 --> 08:43.190
So in our squarer taking the maximum value there's a concept called Mean pooling or some pulling some

08:43.190 --> 08:48.530
pulling as you just some of these values up average pooling or mean pooling you take the average value

08:48.590 --> 08:53.840
out of all of these and subsampling is kind of like a generalization of men pooling.

08:53.840 --> 09:00.790
It's it's a more kind of generalized approach to taking the average of of these values.

09:00.800 --> 09:05.450
And you can read a bit more about in the paper but otherwise just think of it as average pooling when

09:05.450 --> 09:06.540
you're reading a paper.

09:06.860 --> 09:11.150
And so that's where you can get some additional information on this topic and now kind of let's recap

09:11.180 --> 09:12.260
where have we gotten to.

09:12.260 --> 09:14.380
So there is our input image.

09:14.810 --> 09:18.900
Then we apply the convolution operation and we get the conclusion.

09:19.010 --> 09:24.200
And now to each of those feature maps that we get we've applied the pooling layer.

09:24.230 --> 09:30.530
So we've got we've done these two steps evolution and pooling and now we're going to do something very

09:30.530 --> 09:32.000
fun something exciting.

09:32.150 --> 09:40.280
We're going to experiment with this so this is a screenshot I took from a tool created by Adam hardly

09:40.280 --> 09:48.080
from what back when he was at Ryerson University of computer science and now he's at Carnegie Mellon

09:48.260 --> 09:49.670
I think doing his page.

09:50.030 --> 09:53.100
And a great tool so let's open up let's have a look.

09:53.210 --> 09:57.450
So you can find that you can actually find it through Google you have to know your role.

09:57.470 --> 10:05.150
It's as well it's just hard to find because there's no text here as we were just this year I'll start

10:05.450 --> 10:08.320
Reierson dossier and then this stuff in.

10:08.470 --> 10:11.960
And basically this is exactly what we're doing.

10:11.960 --> 10:20.690
But visualize So here you need to draw a number so say I draw on before and this tool will put the number

10:20.690 --> 10:21.290
four here.

10:21.290 --> 10:22.770
That's your image.

10:22.910 --> 10:26.590
In our first step then this is the convolution step.

10:26.740 --> 10:27.050
Right.

10:27.050 --> 10:32.540
And this is the pooling step and also pooling by the way is also called downsampling So pulling an downsampling

10:32.540 --> 10:33.840
are the same things.

10:33.920 --> 10:37.200
So you can see it's applied convolution then it's applied pooling.

10:37.460 --> 10:39.140
And you can see how it exactly works.

10:39.140 --> 10:44.240
You can see what kind of convolutions that it has applied or what kind of filters it is applied what

10:44.240 --> 10:44.970
they look like.

10:45.080 --> 10:47.490
What features is looking out for.

10:47.780 --> 10:53.330
And then it's applied pooling so it's reducing the size and you can see here that this is important.

10:53.330 --> 11:01.040
So you can see that this is the convolved image and this is the puled image and you can still see the

11:01.040 --> 11:01.730
same features.

11:01.730 --> 11:05.750
It's just less information but same features right features are preserved.

11:05.750 --> 11:08.060
That's the important part.

11:08.300 --> 11:14.120
And moreover if you know if all four was a bit too kind of like rotator boot to the side it would still

11:14.120 --> 11:16.960
be able to pick up very similar puled Lares.

11:17.000 --> 11:19.760
And then after that it's got more layers we haven't talked about that yet.

11:19.760 --> 11:26.820
So then he's got another convolutional a convolutional lair here which we actually won't have.

11:27.050 --> 11:30.730
And then he has another pool there but he's basically just repeating that same process.

11:30.950 --> 11:34.740
And then after that this is what we're going to be talking further down in the course.

11:34.880 --> 11:37.640
He's got the fully connected letters and so on.

11:38.030 --> 11:39.830
But you can definitely play around with that.

11:39.830 --> 11:47.860
So if I delete that you like ephedra or A7 you will see that it actually tells you that the guess is

11:47.860 --> 11:49.480
it guesses that this is a seven.

11:49.510 --> 11:52.940
And the second guess the second likelihood is three.

11:52.990 --> 11:56.380
So you can draw some some challenging things and see if it can pick them up.

11:56.380 --> 12:02.780
So let's say if I draw something that looks like a 0 but it's not a finished 0 will it pick it up this

12:02.790 --> 12:03.670
time didn't pick it up.

12:03.670 --> 12:08.500
Looks like a 9 to that to the image under-fire kind of like finished like that.

12:08.500 --> 12:11.390
So now it thinks it's a 0 or a 9.

12:11.620 --> 12:15.760
And you can see over there what's lighting up the 0 with an eye but we'll talk about that part for the

12:15.760 --> 12:16.370
dot.

12:16.600 --> 12:20.040
Let's do one more let's say like like 8.

12:20.150 --> 12:22.830
I think it's pretty hard for this now.

12:22.840 --> 12:23.720
Picked up an 8.

12:23.740 --> 12:25.880
So you can see that goes in turn 8.

12:25.900 --> 12:31.480
And then like after that it stops being recognizable the stops be making sense to us humans.

12:31.480 --> 12:32.080
Right.

12:32.110 --> 12:34.300
These features that it's working with.

12:34.510 --> 12:39.070
But at the same time it is correctly recognizing that it's innate.

12:39.070 --> 12:45.030
So definitely play around with that you can draw a smiley face see what happens then looks like a three

12:45.030 --> 12:51.060
to this to this tool because the tool is obviously trained up only on digits from 0 tonight.

12:51.080 --> 12:53.150
So it has to recognize something.

12:53.150 --> 12:59.500
There are of those and it recognizes a three it's like in life when you when you see something like

12:59.500 --> 13:07.420
a type of fruit that you've never seen before like a custard apple or something and you think that's

13:07.870 --> 13:13.540
it's like it's it's a pear because you've never actually seen one before you don't know what to classify

13:13.540 --> 13:18.820
it as same thing here so it hasn't actually trained on smiley faces and that's why it's thinks it's

13:18.820 --> 13:20.240
a tree it's the tree.

13:20.440 --> 13:25.720
So there you go it's a very powerful powerful tool it'll be helpful for you to play out of it actually

13:26.080 --> 13:29.380
when you put your mouse over a pixel pixel that will show.

13:29.380 --> 13:36.880
It shows you where the feature detector was to pick up that pixel so you can see where those pixels

13:36.880 --> 13:43.120
are coming from and also so you can see how the filter was kind of like going through the image exactly

13:43.120 --> 13:47.860
how we talked about and of course and here you can see you can see the pooling you can see that the

13:47.860 --> 13:58.090
pulling is done with the pulling is done with a little square size of two by two and you can see that

13:58.150 --> 14:03.690
it's a stride of two as well just as we discussed in today's tutorial.

14:03.910 --> 14:09.190
So there you go play or have a play around with that and I hope you enjoyed today's session.

14:09.190 --> 14:10.570
I look forward to seeing you next time.

14:10.570 --> 14:12.420
And until then enjoy deep learning.
