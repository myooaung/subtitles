WEBVTT

00:00.240 --> 00:03.210
All right here we go let's implement this class.

00:03.240 --> 00:11.210
So just to make sure everybody understands what we're about to implement is both the C and and the the

00:11.400 --> 00:17.640
in the same class and that's why the name we're going to give to that class is going to be convolutional

00:18.510 --> 00:22.290
or we're going to call it can't be for more simplicity.

00:22.290 --> 00:25.090
All right let's build that Canvey E-Class.

00:25.140 --> 00:27.010
Here we go back in Python.

00:27.450 --> 00:33.090
So to create a class in Python We start with class then we give a name to that class and as we just

00:33.090 --> 00:42.480
said we are going to call that count the 8 4 C and we see the part of our AI that will see the input

00:42.570 --> 00:47.130
images in reality and we'll reconstruct them in a dream.

00:47.340 --> 00:52.950
And this is exactly what we will build what we will make happen in this class.

00:52.950 --> 00:59.650
So Canvey class and then it's going to take as input just the object varry role.

00:59.760 --> 01:03.560
And that's because we're not inheriting from any class.

01:03.570 --> 01:04.260
All right.

01:04.410 --> 01:12.000
And then of course Collon And here we go for the first method which as always is the init method which

01:12.000 --> 01:20.630
will initialize all the parameters and the variables of the future can be instances of this class.

01:20.640 --> 01:21.120
Right.

01:21.240 --> 01:27.180
So let's actually say that in a comment so that we can structure this code the best way and so that

01:27.300 --> 01:30.440
you can visualize clearly what we're doing.

01:30.750 --> 01:41.040
So let's say indeed that what we're about to do now is about initializing all the parameters and the

01:41.420 --> 01:47.170
variables of the can be a class.

01:47.510 --> 01:56.600
And here we go with the first method which is the in its method spelt like this as always between two

01:56.900 --> 02:00.060
double underscores and now get ready.

02:00.070 --> 02:03.180
This method is going to take a lot of arguments.

02:03.320 --> 02:05.110
So let's list them one by one.

02:05.300 --> 02:08.300
No worries they will be very simple to understand.

02:08.570 --> 02:13.420
So the first one is as always self which will correspond to the object.

02:13.640 --> 02:21.470
Then the second one is going to be Zed size which as you might guess is going to be the size of the

02:21.470 --> 02:28.850
latent vector which is remember at the center of the variational our encoder which will be composed

02:28.850 --> 02:37.540
of 1024 elements and from which the variational are encoder will reconstruct input images.

02:37.850 --> 02:44.480
So let's go back to by then and right now in the arguments we can specify a default value but it doesn't

02:44.480 --> 02:51.110
really matter what we input here because at some point we will input 1024 because we're implementing

02:51.110 --> 02:56.780
the exact same architecture as in the article with the 1024 elements here.

02:56.780 --> 03:04.160
So let's just give any default value and we're going to give 32 then the next argument is going to be

03:04.280 --> 03:11.030
the batch size which is going to be the size of two different batches of inputs and target because of

03:11.030 --> 03:16.790
course we're doing better learning mean that we're learning on batches and inputs and talking as opposed

03:16.790 --> 03:19.250
to single input into it.

03:19.430 --> 03:25.780
So again we can specify a default value here and well we can just give the default value of 1 so far.

03:25.910 --> 03:31.850
But of course at some point we will give another value when we start badgering or you know training

03:31.850 --> 03:32.960
on batches.

03:33.140 --> 03:40.070
Then third argument is going to be the inevitable you know the one that is always here which is the

03:40.070 --> 03:46.870
learning rates and same as the default value will just give or point 0 or 1.

03:47.120 --> 03:49.850
We will give the real value of the learning rate later.

03:50.000 --> 03:58.310
Then the next argument is going to be the case l tolerance which is a parameter we'll use to compute

03:58.460 --> 04:06.150
the Caylus because I remind that the last will use to train the Wii will be the sum of two losses.

04:06.260 --> 04:12.860
The first one is the classic mean square error plus and the second one is the K L us which stands for

04:12.920 --> 04:20.960
cool back liberalists and this K L tolerance will be of course a parameter of this Caylus and as a default

04:20.960 --> 04:31.160
value will give 0.5 then three more arguments to go the next one is is training which is the mode either

04:31.160 --> 04:32.650
equal to false.

04:32.720 --> 04:38.360
If we are in inference mode and true if of course we are in training mode.

04:38.660 --> 04:45.800
And so by default we're all set to false because naturally by default we want to do inference but as

04:45.800 --> 04:50.490
soon as we want to train we will said that of course equal to true.

04:50.960 --> 04:57.500
Then the next argument is going to be real use and that's for divorce rules cope of tense or flow because

04:57.510 --> 05:04.880
in a sense of flow we work with verbal scopes which is basically a container of variables and the reuse

05:05.000 --> 05:10.250
variable here says whether or not you're going to reuse the variable scope.

05:10.430 --> 05:15.770
And this is again a boolean equal to false or true false means of course that you're not going to reuse

05:15.980 --> 05:18.970
the variable scope and Trumans that you're going to reuse it.

05:19.160 --> 05:26.330
And for R V and here well by default we're just going to sell it equal to false.

05:26.480 --> 05:26.950
Right.

05:26.960 --> 05:35.060
And then final argument here of this in a method which is the GP you know which is again a boolean equal

05:35.060 --> 05:41.210
to false or true false means that we're not going to use a GP for the train and Trumans that indeed

05:41.210 --> 05:42.340
we're going to use one.

05:42.400 --> 05:49.490
And by default we're going to set that equal as well to force our right and that's it for the arguments

05:49.580 --> 05:51.140
of this method.

05:51.140 --> 05:58.930
So now let's introduce an initialize as we said the parameters and variables of the economy A-Class.

05:59.090 --> 06:05.960
And so now very simply we're going to create some object variables for each of the arguments we have

06:05.960 --> 06:06.500
here.

06:06.530 --> 06:13.520
Indeed these are only arguments but we want to create some object variables as well which will be exactly

06:13.520 --> 06:15.070
the same arguments here.

06:15.230 --> 06:20.810
And to which we're going to initialize the values given in the arguments here.

06:20.810 --> 06:23.740
When we create the country A-Class.

06:23.760 --> 06:30.300
So let's do this let's just take them one by one and let's add a cell first because indeed by putting

06:30.300 --> 06:37.310
self first we specify that these variables are foibles of the objects you know specific to the object

06:37.660 --> 06:42.940
which are the future instances become the class that will create later.

06:43.010 --> 06:46.010
So the size of the latent vector will be equal to.

06:46.010 --> 06:51.350
Of course the value of the argument given when we create the object.

06:51.380 --> 06:53.720
So make sure you understand the difference here.

06:53.720 --> 06:55.800
This is the variable of the object.

06:55.880 --> 06:59.690
And this is the value of the argument provided here.

06:59.820 --> 07:01.700
Then let's move on to the next one.

07:01.820 --> 07:03.180
But size.

07:03.230 --> 07:06.050
So we're going to do exactly the same now.

07:06.320 --> 07:13.070
Self taught that size equals budget sized argument given here.

07:13.100 --> 07:22.280
Then again same thing well learning rate we go that's for the third object verbal self that learning

07:22.280 --> 07:24.480
rate equals learning rate.

07:24.560 --> 07:31.470
The argument provided here then same of course for the K L tolerance the parameter we'll use for our

07:31.550 --> 07:32.840
Caylus.

07:32.840 --> 07:33.680
So here we go.

07:33.710 --> 07:36.450
Self that K L tolerance.

07:36.530 --> 07:40.830
The object variable which we initialized to K L tolerance.

07:41.000 --> 07:45.630
The argument here and then same is training.

07:45.830 --> 07:49.720
The training mode whether we are in training mode or inference mode.

07:49.910 --> 07:57.950
So here we go again self that is training the visual object which will be initialized to training.

07:57.980 --> 07:59.290
The argument here.

07:59.630 --> 08:05.480
And then lastly because we actually won't need a variable object for this one but we do need a variable

08:05.480 --> 08:08.440
object for the reuse variable.

08:08.450 --> 08:10.250
So here we go again.

08:10.250 --> 08:17.660
Self does reuse the variable object will be initialized to reuse the argument.

08:17.690 --> 08:23.740
And now that's where we can create the tense of two variables COBE and to create one.

08:23.870 --> 08:29.560
We need to start with with then since this is an event structure by tend to flow.

08:29.600 --> 08:35.180
Well we need to call tensor flow which has the shock at T.F. and then from tensor of flow we're going

08:35.180 --> 08:43.110
to get the variable scope function which will exactly create the variable scope.

08:43.110 --> 08:50.090
And now in some parenthesis we need to as you can see specify the name of that scope and it has to be

08:50.090 --> 08:54.920
entered in quotes and the name we're going to give to that variable scope is going to be.

08:55.040 --> 09:02.510
Well you know the scope of all the variables attached to the convolutional the immoral.

09:02.510 --> 09:06.870
So we're just going to call this you know can the A B.

09:07.130 --> 09:13.560
And then that's where the reuse argument and also object variable will come into play.

09:13.820 --> 09:20.330
Because as you can see reuse is actually an argument of the tense of the variable scope.

09:20.480 --> 09:27.530
And so now be careful there will be three things to distinguish the reuse argument here which is the

09:27.530 --> 09:36.470
argument of the sense of variable scope function which we will initialize to the re-use variable of

09:36.470 --> 09:37.490
the object.

09:37.490 --> 09:45.700
So I'm going to say here self that reuse which I'm going to copy and paste here and the self-direct

09:45.720 --> 09:50.390
reuse is equal to the reuse argument provided here.

09:50.460 --> 09:52.060
When we create the object.

09:52.080 --> 09:52.360
Right.

09:52.360 --> 09:56.810
So I hope I said enough for you to not get lost in all this but here we go.

09:56.820 --> 10:01.180
The variables go is ready so we don't forget to add the cone here.

10:01.230 --> 10:08.100
As I just did and then now inside the tense of a variable scope this is when our last argument will

10:08.100 --> 10:09.220
come into play.

10:09.240 --> 10:15.380
The GP mode because in the whether you have or not a GP you you will have the option to use it.

10:15.780 --> 10:18.120
So let's offer that option right away.

10:18.180 --> 10:27.990
The way we're going to do this is with an if if not GP you mode meaning if JBU mode is not equal to

10:27.990 --> 10:33.090
true meaning basically we're going to use our Sibiu if not JBU mode.

10:33.210 --> 10:35.560
Then what are we going to do now.

10:35.670 --> 10:41.220
Well if we're going to use our Sibiu we're going to specify this but we need to tell that to tens of

10:41.220 --> 10:45.810
flow when it is specified intensively that indeed we're going to use our Sibiu.

10:45.990 --> 10:52.950
And the way you can do that with tens of flow is with with again and then T F You know I'm calling the

10:52.940 --> 10:57.180
intensive the library again from which I'm going to get this time.

10:57.210 --> 11:05.640
The device function inside which I'm going to enter in quotes slash CPQ you zero.

11:05.750 --> 11:06.090
Right.

11:06.090 --> 11:13.140
This is a code to specify that we're going to use our Sibiu if we don't have a GP you like kuda for

11:13.260 --> 11:19.400
the training or even the inference except that for the inference you definitely don't need a GP.

11:19.570 --> 11:28.770
All right then let's not forget the Cullen and inside we can provide some luggin info just to give some

11:28.950 --> 11:36.260
extra information saying that indeed our model is using the CPE.

11:36.360 --> 11:40.980
These are just some extra useful information but not compulsory of course.

11:41.220 --> 11:49.080
And then now however the thing that we have to do is to initiate the building of the graph which we

11:49.080 --> 11:57.070
do by calling the build graph method which is exactly going to be the next method we will build to build

11:57.070 --> 12:03.810
the whole architecture of the convolutional the model and also the training operations.

12:03.810 --> 12:04.970
All right perfect.

12:05.060 --> 12:11.420
Then we're going to get in the other condition whether we are in GP mode.

12:11.640 --> 12:18.300
That is when you are equal to true and which we can get with a simple else because this is the complementary

12:18.300 --> 12:19.060
condition.

12:19.170 --> 12:21.400
So else here and inside.

12:21.630 --> 12:27.930
Well in that condition we'll have directly the GP you Tenterfield device so we don't have to do another

12:27.930 --> 12:29.180
with the device.

12:29.190 --> 12:37.020
GP you but instead we're just going to get the new luggin info which will be this time exactly the same

12:37.380 --> 12:47.670
but replacing CPQ by GP you and then again we will initiate the building of the graph by calling our

12:47.790 --> 12:53.940
build graph method which will build in the next tutorial or you know in the next couple of tutorials

12:54.300 --> 12:56.300
because this is going to be a big method.

12:56.430 --> 13:01.820
And so that's done for this complimentary condition where we are in GP mode.

13:01.880 --> 13:09.090
Now the last thing we need to do to finish is to introduce a last object foible of our economy class

13:09.330 --> 13:19.750
which is self that it session with some parenthesis and which will be used to initialize the future

13:19.750 --> 13:26.440
tense of session that will run for either the inference or the training of our model.

13:26.470 --> 13:30.280
That's the way we do things with tons of low intensity sessions.

13:30.310 --> 13:32.610
You will see that later on in the code.

13:32.950 --> 13:36.350
So that's it for this first method.

13:36.460 --> 13:42.220
And now get ready for the next one because this will be the big method inside which will build the whole

13:42.310 --> 13:46.450
architecture of the convolutional variational are anchored to model.

13:46.480 --> 13:49.810
So get some good energy from this because we have a lot to do.

13:49.810 --> 13:51.450
So I'll see you after a little break.

13:51.490 --> 13:54.020
And until then enjoy artificial intelligence.
