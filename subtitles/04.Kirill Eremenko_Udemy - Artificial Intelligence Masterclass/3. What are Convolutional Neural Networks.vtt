WEBVTT

00:00.450 --> 00:02.910
Hello and welcome back to the course on deep learning.

00:02.910 --> 00:06.850
Today we're kicking off convolutional neural networks is going to be exciting.

00:06.870 --> 00:08.540
Let's dive straight into it.

00:08.550 --> 00:10.860
We're going to start off with an image.

00:10.860 --> 00:13.230
What do you see when you look at this image.

00:13.510 --> 00:19.410
Do you see a person looking at you or do you see a person looking to the right you can see that your

00:19.410 --> 00:25.790
brain is struggling is struggling to adjust if you look to the right side of the image.

00:25.800 --> 00:29.170
Just look at the right border of the image you'll see a person looking to the right.

00:29.220 --> 00:33.190
If you look at the left border of the image you'll see a person looking at you.

00:33.660 --> 00:42.720
And this just proves that what our brain is looking for when we see things is features depending on

00:42.720 --> 00:45.930
the features that it sees depending on the features that you process.

00:46.110 --> 00:48.570
You categorize things in certain ways.

00:48.690 --> 00:53.750
So when you look on the right side of the image you see certain features of a person looking to the

00:53.750 --> 00:59.880
right because they're closer to your center of focus and therefore your brain classifies it as a person

00:59.880 --> 01:00.900
looking to the right.

01:00.960 --> 01:06.750
When you look to the left side of the image you see more features of a person looking at you and therefore

01:06.750 --> 01:09.540
your brain classifies it as such.

01:09.540 --> 01:11.190
So let's have a look at another one.

01:11.190 --> 01:12.800
This is a very famous image.

01:12.870 --> 01:16.210
You probably have already seen it but what you see here.

01:16.780 --> 01:23.780
So some people will say that they see a young lady wearing a dress looking away.

01:23.790 --> 01:30.160
Some people say they see an old lady wearing a scarf on her head looking down.

01:30.210 --> 01:36.210
So I'm going to point this out and you'll see that will become very obvious so this is the face of the

01:36.210 --> 01:37.440
young lady looking away.

01:37.440 --> 01:40.370
She's looking into the distance as her coat.

01:40.380 --> 01:44.890
That's her hair that's her real feather in her hair and on the other hand.

01:44.940 --> 01:53.100
This is the head of the old lady looking down her nose her mouth that's her chin that's the scarf on

01:53.100 --> 01:55.720
her head and she's looking down.

01:55.740 --> 02:01.920
So as you can see two in one and depending on which features your brain picks up it will switch between

02:02.580 --> 02:06.840
classifying each image as one or the other.

02:06.840 --> 02:13.890
The oldest one of these allusions recorded in the printed work is this one.

02:13.890 --> 02:15.210
It's the duck or the rabbit.

02:15.210 --> 02:16.930
So is this a duck or is this a rabbit.

02:16.950 --> 02:18.360
Another example.

02:18.360 --> 02:22.460
And now I'm going to show an image which will just for a second.

02:22.450 --> 02:29.060
Just look at it and see what what what motions or what kind of experience visual experience you go through.

02:29.070 --> 02:31.110
So what do you see.

02:31.110 --> 02:37.590
Do you feel like a bit not dizzy but a little bit dazzled like your brain is trying to try and understand

02:37.590 --> 02:45.420
what it is what it is like it's trying to is jumping between her eyes up and down eyes and this is a

02:45.420 --> 02:52.260
classic example of when there are certain features where it could be this it could be that but your

02:52.260 --> 02:53.820
brain cannot decide.

02:54.060 --> 03:02.910
And because both seem plausible and so basically all these examples illustrate to us how the brain works

03:02.910 --> 03:10.230
that it produces a certain features on an image or on whatever you see in real life and it classifies

03:10.230 --> 03:10.920
that assertion.

03:10.920 --> 03:16.080
You probably have been in situations when you look over your shoulder quickly and you see something

03:16.080 --> 03:20.740
you think it's I don't know if it's like a a ball.

03:20.750 --> 03:22.220
But it turns out to be a cat.

03:22.230 --> 03:26.790
Or you think it's a it's a car but turns out to be a shadow or things like that because you don't have

03:26.790 --> 03:30.910
enough time to process those features or you don't have enough features to classify things as such.

03:31.200 --> 03:38.670
And this is for me it's very interesting because what we're going to be doing with neural networks with

03:38.790 --> 03:44.010
notional neural networks is very similar and you'll find that the way that computers are going to be

03:44.010 --> 03:49.110
producing images is going to be extremely similar to the way we are processing images so it is very

03:49.110 --> 03:53.540
valuable to understand and just kind of remember these things that this is how we do it.

03:53.550 --> 03:58.590
And I'm going to take this lady off your screen because she's probably already freaking out by now.

03:58.590 --> 04:00.900
So here's something different.

04:00.900 --> 04:07.830
Here's an experiment an experiment done on computers on convolutional neural networks so we're slowly

04:07.830 --> 04:11.080
moving now from humans to computers.

04:11.310 --> 04:18.450
And this slide is from a told by Geoffrey Hinton and here you have basically describes an experiment

04:18.450 --> 04:24.400
that he had done on some conventional neural networks that he had trained up.

04:24.420 --> 04:29.520
So here you see three images and we're going to go through them with left to right and see how you would

04:29.520 --> 04:31.800
classify them and then see how they're computer classified.

04:31.800 --> 04:35.070
So on the left what do you think this is.

04:35.400 --> 04:37.650
You probably said cheetah and you will be right.

04:37.650 --> 04:41.700
And this is what the computer said so and the right right away right off the bat we're going to learn

04:41.700 --> 04:47.930
how to read these images because if you're going to go deep into call convolutional neural networks

04:48.150 --> 04:53.430
no pun intended if you're going to start learning more and more about and using them you'll see a lot

04:53.430 --> 04:54.000
of these.

04:54.030 --> 05:01.000
So and I've actually seen people read them incorrectly so here at the top Shida is what it actually

05:01.000 --> 05:01.420
is.

05:01.420 --> 05:07.870
So that's the actual correct label of the image that's what's the label of the images regardless of

05:07.870 --> 05:09.080
any processing.

05:09.220 --> 05:11.160
And the computer vision.

05:11.710 --> 05:19.840
And then here are the guess's the top four or five sometimes guesses of the algorithm and they're given

05:19.840 --> 05:26.020
the probabilities so the computer said or the neural networks said cheetah leopard Snow Leopard or Egyptian

05:26.020 --> 05:27.360
cat can be one of the four.

05:27.490 --> 05:29.060
And cheetah has the highest vote.

05:29.080 --> 05:34.720
And throughout this part of the Course you understand what these votes mean and how they are derived.

05:34.780 --> 05:36.690
But for now it's pretty intuitive right.

05:37.060 --> 05:40.650
It's a cheetah in reality and the neural network guessed right.

05:40.660 --> 05:44.630
It said with a hyper ability about like 95 99 percent.

05:45.850 --> 05:46.780
Then the second one.

05:46.810 --> 05:51.020
What do you think does it that is that it is a bullet train.

05:51.250 --> 05:57.970
And the electric was able to distinguish between bullet train passenger car subway train electric locomotive.

05:57.970 --> 05:59.330
Those are the top choices of course.

05:59.350 --> 06:05.440
It had many more options these neural networks learned to distinguish from not just four categories

06:05.440 --> 06:08.700
from dozens thousands of categories at the same time.

06:08.710 --> 06:10.710
So those are the four options that it picked.

06:10.870 --> 06:12.710
And so there's will train at its will.

06:12.750 --> 06:13.290
So what did you think.

06:13.290 --> 06:17.160
The last one is very.

06:17.290 --> 06:18.500
There are a couple of options.

06:18.500 --> 06:25.030
It's not very clear what is it could be a frying pan could be a magnifying glass it could be even maybe

06:25.240 --> 06:30.490
a pair of scissors some might say while the neural network said it was a pair of scissors.

06:30.700 --> 06:32.550
But you can see how you can go wrong here.

06:32.560 --> 06:35.370
First of all it's not a very clear image.

06:35.470 --> 06:41.710
And also you can see that the probabilities are not as clear here.

06:41.710 --> 06:47.980
So the neural network was a bit confused a bit indecisive just as we are so I said Scissors was a high

06:48.010 --> 06:53.440
possibility but then it had hand-glass which it actually was with not not so far away on the second

06:53.440 --> 06:55.710
place and frying pan stethoscope.

06:55.870 --> 07:01.570
So basically here you can see that scissors was its first guess but the correct option was number two

07:01.570 --> 07:03.010
and that's why it's highlighted in red.

07:03.250 --> 07:07.000
So there we go those That's what neural networks are already capable of.

07:07.000 --> 07:08.830
And this is actually quite an old slide.

07:08.830 --> 07:10.540
This was several years ago.

07:10.600 --> 07:15.820
Now they're even better and you will see that from the practical application that you will be coding

07:15.820 --> 07:16.720
together had lunch.

07:16.870 --> 07:18.380
But now let's try to sound a bit better.

07:18.380 --> 07:23.700
What convenance or convolutional neural networks actually are and why are they gaining so much popularity.

07:23.920 --> 07:31.280
And they actually are gaining popularity so you can see here a Google Trends comparison I did just yesterday.

07:31.690 --> 07:38.590
Here you can see that conventional illusional neural networks are even taking over artificial neural

07:38.740 --> 07:43.210
networks so a massive increase.

07:43.210 --> 07:49.480
And this is going to keep going that way because it is a very important field that that is where all

07:50.080 --> 07:52.480
the things happen such as like self-driving cars.

07:52.480 --> 07:59.290
How do they recognize people on the road how to recognize stop signs and things like that how do how

07:59.290 --> 08:07.630
does Facebook is Facebook able to tag images or people in images and not only just like remember previously

08:07.930 --> 08:14.190
years ago you had to type people yourself then it would recognize faces you had to add the names.

08:14.200 --> 08:18.320
And now it just recognizes the faces and adds the names at the same time.

08:18.550 --> 08:26.000
Well that is what convolutional neural networks are capable of speaking on Facebook.

08:26.110 --> 08:34.660
If Jeffrey Hinton is the godfather of artificial neural networks and deep learning then yalla Coon is

08:34.780 --> 08:39.110
the grandfather of convolutional neural networks.

08:39.110 --> 08:42.400
That lagoon is a student of Jeffrey Hinton's.

08:42.580 --> 08:45.480
And in fact here you can see them together.

08:45.670 --> 08:53.890
And Jeffrey Hinton now is pioneering de-planing at Google young lagoon is the director of Facebook artificial

08:53.890 --> 08:56.940
intelligence research and also professor at NYU.

08:56.950 --> 09:02.620
So we're slowly aware of this part of the core slowly we're building up this way.

09:02.620 --> 09:10.720
These names are this kind of picture of the profiles of the people who are driving this field and next

09:10.900 --> 09:16.630
in the next couple of parts will get to know about a few more and we'll have this whole Mafia as they

09:16.630 --> 09:22.270
call themselves or you can call them mafia or conspiracy of deep learning and you'll learn a bit more

09:22.270 --> 09:24.080
about how this whole field developed.

09:24.430 --> 09:27.240
Yeah it's just these are just some great great people.

09:27.400 --> 09:35.320
And so cool back in the 80s and the 90s made significant contributions to the field of convolutional

09:35.320 --> 09:36.240
neural networks.

09:36.280 --> 09:44.260
And as you'll see throughout this course has been able to develop or help the world develop something

09:44.290 --> 09:46.530
so extremely powerful.

09:46.600 --> 09:51.340
So moving on to how can illusional neural networks work.

09:51.370 --> 09:56.090
You have an input it's very simple it's very straightforward so they have an input image.

09:56.110 --> 10:02.620
It goes through the illusional neural network and you have an label so it classifies that image as something

10:03.910 --> 10:06.620
like a Cheeto or a bullet train or something else.

10:06.730 --> 10:10.720
Now kind of like going into a bit more detail.

10:10.840 --> 10:18.850
For instance you can after your own effort has been trained up on uncertain images on certain classified

10:18.850 --> 10:23.350
images or categorized images prior that have been Cairos prior.

10:23.660 --> 10:29.470
After that you can give it let's say a neural network has been trained up to recognize facial expressions

10:29.470 --> 10:30.260
emotions.

10:30.460 --> 10:37.960
You can give it a face of a smiling person not just a face like a drawing of a face like this but actual

10:37.960 --> 10:39.280
face of a person smiling.

10:39.400 --> 10:44.840
And I'll tell you that that person is happy and you can get a face of a person that's frowning.

10:44.850 --> 10:47.170
I'll tell you that that person is sad.

10:47.220 --> 10:48.520
It can recognize these emotions.

10:48.520 --> 10:54.040
And as you can see that's already very powerful in terms of so many different applications just this

10:54.430 --> 10:58.150
one example you can think of right away.

10:58.420 --> 11:03.730
And in both cases Ill give you a operability so it won't say you know if we're 100 percent the person's

11:03.940 --> 11:12.190
happy or sad it will be 99 or 98 or maybe 80 percent when it's unclear of what's going on and just like

11:12.190 --> 11:16.560
we are right sometimes we can mistake things for what they're not.

11:16.600 --> 11:23.560
Or sometimes we can sometimes it's just not clear if the person is smiling or frowning or if it's if

11:23.560 --> 11:30.040
it's a dog or a cat or if it's a train or a bullet train right sometimes we don't have is we haven't

11:30.040 --> 11:35.920
seen enough features in all goes down to features because that's how we process visual information as

11:35.920 --> 11:38.540
we saw from the start of this tutorial.

11:38.570 --> 11:44.080
So how does a neural network neural network able to recognize these features.

11:44.080 --> 11:50.670
Well it all starts at the very basic level you have let's say you have an image you have two images.

11:50.740 --> 11:56.130
One is a black and white image of two by two pixels and one is a colored image of two by two pixels

11:56.470 --> 12:04.630
while neural networks leverage the fact that the black and white image is a two dimensional array.

12:04.630 --> 12:09.590
So the way we see it right now on the left is just the visual representation.

12:09.600 --> 12:11.080
I said some kind of picture.

12:11.170 --> 12:13.810
And for simplicity's sake is just a two way to picture.

12:14.050 --> 12:19.870
But in computer terms it's actually a two dimensional array with every single one of those pixels having

12:19.870 --> 12:22.070
a value between 0 and 55.

12:22.330 --> 12:27.620
So that's eight bits of information to the public to the power of eight is 256.

12:27.640 --> 12:32.040
So therefore the values are from 0 to 255 and that's intensity of the color.

12:32.200 --> 12:38.200
And in this case the color white so 0 will be completely black pixel 255 will be a completely white

12:38.200 --> 12:44.490
pixel and between them you have the grayscale range of possible options for this pixel.

12:44.590 --> 12:49.950
And based on that information computers are able to then work off the image.

12:49.960 --> 12:55.270
And that's kind of like the starting point that any image is actually has a digital representation has

12:55.270 --> 12:56.420
a digital form.

12:56.560 --> 13:03.400
And those are just basically ones and zeros that form a number 0 to 255 for every single pixel and that's

13:03.400 --> 13:04.200
what the computer works.

13:04.200 --> 13:08.230
If it doesn't actually work with you know colors or anything it works with the ones and zeros at the

13:08.230 --> 13:08.730
end of the day.

13:08.740 --> 13:12.780
That's as kind of like the foundation of it all.

13:13.330 --> 13:17.070
And in a color image is actually a three dimensional array.

13:17.170 --> 13:21.900
You've got blue pixel you're going to blue Larry Green and Red Llyr.

13:22.080 --> 13:29.710
And and that says for RGV red green blue and each one of those colors has its own intensity.

13:29.710 --> 13:36.950
So basically a pixel has three three values assigned to it.

13:36.970 --> 13:40.810
Each one of them is between 0 and 256 255.

13:41.350 --> 13:48.280
And therefore you can find out what's this image what color exactly this pixel is.

13:48.280 --> 13:53.460
By combining those three values and again computers are going to be working with that.

13:53.470 --> 13:59.430
So that's the foundation of it all that's the red channel the green channel the blue channel.

13:59.470 --> 14:08.510
And finally let's have a look at for instance an example of a very trivial example of a smiling face.

14:08.770 --> 14:09.550
In computer terms.

14:09.550 --> 14:17.680
If we just really simplify things instead of having from 0 to 255 and having those values just so that

14:17.680 --> 14:25.660
we can understand things better and really grasp the concepts we're going to say zero is is white one

14:25.660 --> 14:26.530
is black.

14:26.530 --> 14:26.740
Right.

14:26.740 --> 14:33.400
So we're just going to simplify things to the extreme and you will see that that image can be represented

14:33.400 --> 14:33.870
like that.

14:33.970 --> 14:39.310
So the reason why we've brought this up is because we go into all of our intuition Stroh's we get structure

14:39.310 --> 14:45.040
on images like this which are very simple but at the same time then all those concepts can translate

14:45.040 --> 14:50.450
back to the 0 to 256 range of values and everything applies the same way there.

14:50.680 --> 14:54.870
And the steps are we're going to be going through if these images are the optimal one volution.

14:54.880 --> 14:56.760
Step number two max pooling.

14:56.770 --> 15:02.510
Step number three flattening and step number a full connection and I can imagine that probably all of

15:02.510 --> 15:09.830
these words mean much to you at the moment but by the end of this section of the course you will understand

15:09.950 --> 15:13.890
them in great detail and exactly what they're doing.

15:13.910 --> 15:15.970
So we'll get started in the next tutorial.

15:15.980 --> 15:24.350
For now the additional reading that you might want to look into is a young Lukens original paper that

15:24.590 --> 15:28.140
gave rise to an emotional neural networks.

15:28.140 --> 15:31.540
It's called gradient based learning applied to documentary cognition.

15:31.610 --> 15:34.500
You may have seen this image before floating around the Internet.

15:34.580 --> 15:40.940
It is from that paper so if you want to go back to the very beginnings of how it all happened where

15:40.940 --> 15:46.360
it all came from this is the paper to look into and I look forward to seeing the next tutorial.

15:46.370 --> 15:48.230
Until then enjoy deep learning.
