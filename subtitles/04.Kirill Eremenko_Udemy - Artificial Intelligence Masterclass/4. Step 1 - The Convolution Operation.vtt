WEBVTT

00:00.640 --> 00:05.680
Hello and welcome back to the course on deep learning in the press the Tauriel we found out what convolutional

00:05.750 --> 00:07.240
neural networks are all about.

00:07.300 --> 00:11.040
And today we're going to dive into Step 1 convolution.

00:11.050 --> 00:18.480
So this is the convolution function and we try to stay away from mathematics and keep things intuitive.

00:18.490 --> 00:25.060
But I couldn't help but share this for formula of you because it is so simple a convolution is basically

00:25.060 --> 00:31.390
a combined integration of the two functions and it shows you how one function modifies the other of

00:31.430 --> 00:36.310
mortifies the shape of the other and if you've done any signal processing or electrical engineering

00:36.310 --> 00:41.930
or a profession where signal processing is required you would have inevitably come across a conclusion

00:41.970 --> 00:42.340
function.

00:42.340 --> 00:44.040
It is quite popular now.

00:44.060 --> 00:49.430
Once again we're going to keep the mathematics lights or keep them separate.

00:49.450 --> 00:56.140
And if you'd like to get into the math behind the convolutional neural networks a great additional read

00:56.470 --> 01:04.960
is Introduction to convolutional neural networks by Jensine Wu who is a professor at Nanjing University

01:04.960 --> 01:05.640
in China.

01:05.770 --> 01:12.730
This paper was published literally days ago like five or six days ago and it is oriented specifically

01:12.730 --> 01:17.650
at people who are starting out at beginners who are getting to know convolutional neural networks so

01:18.170 --> 01:22.220
the mathematics there should be accessible actually e-mailed.

01:22.390 --> 01:30.730
Professor Johnson woo and yeah he said his whole goal is to make or break the complex things down so

01:30.730 --> 01:33.310
that people who are new to this field can understand.

01:33.310 --> 01:40.630
And also he mentioned that he's got some materials available on his home page so if you yourself if

01:40.630 --> 01:47.170
you just remove the last two parts and you just go to like Slash W.J. X to that part that's his home

01:47.170 --> 01:52.330
page and you'll be able to find more additional tutorials and materials which haven't been published

01:52.330 --> 01:59.060
as papers but said he uses them in his tutorials so you might find those useful so browse around there

01:59.080 --> 02:05.080
if you'd like to get an introduction into the mathematics behind coalitional neural networks and kind

02:05.080 --> 02:08.290
of build a solid base around that area.

02:08.470 --> 02:12.480
But we're going to move on and we're going to talk about the convolution.

02:12.490 --> 02:17.110
So what is a solution in intuitive terms here on the left.

02:17.110 --> 02:21.640
We've got an input image as we discussed that's how we're going to look at images just ones and zeros

02:21.640 --> 02:25.010
to simplify things and you can see the smiley face there.

02:25.030 --> 02:28.690
Then we've got a feature detector so feature detectors a three by three Matrix.

02:28.690 --> 02:30.100
Does it have to be three by three.

02:30.100 --> 02:31.870
No it doesn't.

02:31.870 --> 02:35.570
Alex net I think uses seven by seven.

02:35.800 --> 02:41.360
And then some other one of those other famous ones uses like five by five feature detectors.

02:41.590 --> 02:48.190
They can be different but usually you'll see that they are three by three and they are you know reasons

02:48.190 --> 02:52.100
to make them three by three so we're going to stick to the conventional way.

02:52.120 --> 02:57.460
Having a three by three feature detector also the feature detectors called these are important terms

02:57.460 --> 02:58.660
because you might come across them.

02:58.660 --> 03:04.030
There are many different terms for the feature detector but the most common ones are feature detector

03:04.060 --> 03:09.490
or Iike might hear it being called kernel or you might hear it being called Filter.

03:09.490 --> 03:14.710
So in this course we're going to be using either filter or feature detector interchangeably but just

03:14.710 --> 03:23.290
bear in mind that it has those names and a coalition operation is signified by an X in a circle.

03:23.620 --> 03:31.150
Just as you saw in the formulas before and here what happens is on an intuitive level or just think

03:31.150 --> 03:34.910
of it in terms of what is actually happening in the background rather than the mathematics.

03:34.960 --> 03:40.610
Well you take this feature detector or filter and you put it on your image like you see on the left.

03:40.690 --> 03:48.730
So you cover the for instance in this case the top left corner nine pixels in the top left corner and

03:48.760 --> 03:58.870
you basically multiply each value by its value so respect to value so the top 0 by top left value by

03:58.870 --> 04:05.130
the top left value then basically is in position of a 1 one by position about 1 1 position number or

04:05.170 --> 04:08.620
0 1 0 1 0 2 by 0 2 and so on.

04:08.620 --> 04:13.360
So it's element wise multiplication on these matrices.

04:13.360 --> 04:16.640
And then you add up the results so in this case nothing matches up.

04:16.640 --> 04:19.910
So it's always either 0 0 0 or by 1.

04:19.930 --> 04:21.250
So the result is zero.

04:21.420 --> 04:26.530
And here you can see that one of them matched up one on the left matched up.

04:26.560 --> 04:28.070
And therefore we've got a 1 here.

04:28.070 --> 04:30.840
Nothing matched up nothing matched up nothing matched up.

04:30.840 --> 04:32.080
Then we move on to the next throw.

04:32.080 --> 04:38.560
So and the step at which we're moving this whole filter is called the stride.

04:38.560 --> 04:40.520
So here we have a stride of one pixel.

04:40.520 --> 04:45.650
So here you can see again something matched up the bottom right corner matched up against stride but

04:45.650 --> 04:50.790
a bottom one in the middle matched up here top right on match up the nothing measure.

04:50.910 --> 04:53.760
The stride is one you can change the stride.

04:54.280 --> 04:58.510
You can make it one two you're going to get three whatever you like.

04:58.780 --> 05:02.750
The Eventually the one that works well is usually at two.

05:02.750 --> 05:04.210
So that's what people stick to.

05:04.520 --> 05:09.470
And we'll we'll talk about what the stride is towards the end of this tutorial.

05:09.470 --> 05:14.120
So here we've got so we're matching up suits you were here you can see we've got two because two of

05:14.120 --> 05:17.230
them matched up and so on and so on.

05:17.240 --> 05:24.760
So on there we go there's another one that matched up there we go and we're done.

05:24.780 --> 05:27.730
So what's what have we created.

05:27.750 --> 05:28.360
Right.

05:28.350 --> 05:31.770
A couple of important things here.

05:31.920 --> 05:38.190
The image on the right is called a feature map also has several terms it also can be called sometimes

05:38.820 --> 05:40.480
it can Vold feature.

05:40.950 --> 05:46.230
So in your blog and volution operation operator to something it doesn't become convoluted it becomes

05:46.230 --> 05:47.010
convolved.

05:47.070 --> 05:54.710
And yes sometimes I like I think to myself in the wrong way but it's the correct term is convolved is

05:54.760 --> 05:59.160
a kind of old feature or it can also be called the activation map but we're going to be calling it a

05:59.160 --> 06:06.250
feature map in this course so it can be called any one of those things and what have we done here.

06:06.270 --> 06:09.860
Well as you can see we've reduced the size of the image.

06:09.870 --> 06:15.420
That's number one and that's the important thing I wanted to mention about your input image and the

06:15.420 --> 06:17.190
feature text and the stride.

06:17.190 --> 06:19.970
If you have a stride of one you can see the image reduced a bit.

06:19.980 --> 06:24.510
But if you have a right to the image is going to produce more so the feature feature is going to be

06:24.510 --> 06:25.370
even smaller.

06:25.560 --> 06:33.900
And that's a very important function of the feature detector of this whole convolution step is to make

06:33.900 --> 06:43.890
the image smaller because that'll be it'll be easier to process it and it'll be just faster rule and

06:46.050 --> 06:52.440
you'll be just foster because imagine like here we've got a what a seven by seven image but imagine

06:52.440 --> 07:00.780
if you have a proper photo right or you have like a 256th on a 56 pixel image that's it's a huge number

07:00.780 --> 07:03.790
of pixels I Chona 56 squared.

07:04.370 --> 07:07.070
Or like let's say you have a 300 but 300 pixels so.

07:07.080 --> 07:13.800
So we don't get confused with the RG B 256 has to say like we have a 300 300 image in terms of size

07:13.800 --> 07:14.660
and pixels.

07:14.730 --> 07:22.590
Then you have 300 square number of pixels that's a huge number and therefore feature detectors will

07:23.310 --> 07:27.520
reduce the size of the image and therefore stride of two is actually beneficial.

07:27.690 --> 07:29.940
But then the question is do we lose information.

07:29.940 --> 07:34.370
Are we losing information when we're applying the feature detector.

07:34.470 --> 07:40.530
Well some information we are losing of course because we have less values and of resulting matrix.

07:40.650 --> 07:45.900
But at the same time the purpose of the feature detector is to detect certain features certain parts

07:45.900 --> 07:48.100
of the image that are integral.

07:48.570 --> 07:53.100
And so for instance if you think about it this way like the feature detector has a certain pattern on

07:53.100 --> 07:57.900
it the highest number in your feature map is when that pattern matches up.

07:57.900 --> 08:04.770
In fact the highest number you can get is in an all simplified example is when the feature is that it

08:04.770 --> 08:10.500
matches exactly and you can see if that number four we have in our feature map that's exactly.

08:10.500 --> 08:16.860
So if you look at it here that's exactly where this feature detector because there's only four ones

08:16.860 --> 08:21.410
and it matched perfectly so you can see this this part over here.

08:21.420 --> 08:23.200
So the feature was detected here.

08:23.400 --> 08:32.280
And as we discussed at the very start of this section that it features is how we see things is how we

08:32.370 --> 08:33.030
recognize it.

08:33.050 --> 08:36.150
We don't look at every single pixel.

08:36.180 --> 08:42.030
So to speak in what we see on an image or in real life we don't look at every single picture we look

08:42.030 --> 08:42.690
at features.

08:42.690 --> 08:52.020
We look at the nose the hats the the feather the eyes or the little black marks under the cheater's

08:52.650 --> 08:57.400
eyes to distinguish between a cheetah and a leopard or the shape of the train.

08:57.420 --> 09:02.580
We don't to distinguish between a bullet train and normal train and so on so we don't look at everything

09:02.580 --> 09:08.060
we look at features and that's what we're preserving and that's what the feature map helps us preserve.

09:08.060 --> 09:15.420
Actually that's what it allows us to bring forward and get rid of all of the unnecessary things that

09:15.490 --> 09:16.410
you want as humans.

09:16.410 --> 09:24.150
We don't process so much information going into your eyes that at any given time like gigabytes of information

09:24.240 --> 09:31.320
if you look at every single dot if not terabytes of information going into eyes per second and still

09:31.350 --> 09:36.960
we're able to proceed because we get rid of what is unnecessary only focus on the important features

09:36.960 --> 09:42.050
features that are important to us and that is exactly what the feature does.

09:42.210 --> 09:51.060
So now moving on this is our input image and you create a feature map so the front one let's say the

09:51.060 --> 09:54.090
front one is the one we just created but then how come there's many of them.

09:54.240 --> 10:00.210
But we create multiple feature maps because we use different filters.

10:00.240 --> 10:00.540
Right.

10:00.570 --> 10:05.370
And that's another way that we preserve lots of the information so we don't just have one feature map

10:05.820 --> 10:12.300
we look for certain features and then or basically the network decides through its training.

10:12.300 --> 10:16.680
And this is something we'll discuss towards the end of the section through his training it decides which

10:17.340 --> 10:23.340
features are important for certain types or certain categories and it looks for them and therefore will

10:23.340 --> 10:26.000
have different filters and we'll talk about filters just now.

10:26.130 --> 10:32.250
But basically Ill apply these filters so to get this feature map it applied a filter like the one we

10:32.250 --> 10:36.210
saw but then to get this feature and apply a different field to get this feature up or apply a different

10:36.210 --> 10:37.760
filter and so on.

10:38.340 --> 10:43.580
And so basically it just creates these feature maps.

10:43.590 --> 10:49.990
And actually that's why personally I think the term feature detector is better than filters so remember

10:50.000 --> 10:55.040
over here we have this filter which we also can call a feature detector.

10:55.040 --> 10:59.380
Well actually the word feature detector I think is better suited.

10:59.430 --> 11:03.350
And the reason for that is that's what the purpose is right.

11:03.350 --> 11:06.440
We don't want to just we don't want to just filter out our image.

11:06.450 --> 11:10.170
But even though that's a whole that's the same same just a question of terminology.

11:10.170 --> 11:11.940
But basically we want to detect features.

11:11.940 --> 11:12.200
All right.

11:12.210 --> 11:19.620
In this in this lair we're going to our in this feature map we've detected where certain features are

11:19.740 --> 11:24.180
in the image and this feature map we've detected where certain other features are where a certain specific

11:24.180 --> 11:25.280
feature is located.

11:25.360 --> 11:31.320
Now this feature map will be detected where a certain other feature is located on the image.

11:31.380 --> 11:33.350
So that's that's what we're doing.

11:33.360 --> 11:40.650
And let's have a look at a couple of examples So here we're using and this is from Gilpatrick their

11:40.690 --> 11:41.580
documentation.

11:41.670 --> 11:49.230
It's a free like of kind of tool like paint and you can use it to adjust your images or work with your

11:49.230 --> 11:49.490
images.

11:49.500 --> 11:56.430
But basically they have some valuable examples in their documentation and here they have a picture of

11:56.430 --> 11:59.750
the Taj Mahal and you can choose which filter you want to apply.

11:59.840 --> 12:06.080
So if you download this program and you upload a photo into it and then you can actually start a conversion

12:06.090 --> 12:12.540
matrix and apply filters and you will see that these things these English matrices actually applied

12:12.540 --> 12:15.180
in image processing and design and so on.

12:15.180 --> 12:17.100
So let's have a look at what we get what we get so.

12:17.160 --> 12:22.920
So if we apply this filter five in the middle minus 1 1 1 1 1 one minus 1 you can see that it sharpens

12:22.920 --> 12:23.990
the image.

12:24.090 --> 12:28.840
And so this is it's quite intuitive if you think of it.

12:28.950 --> 12:36.240
So 5 is the pixel of the main pixel like in the middle of the of the filter or the feature detector

12:36.540 --> 12:37.860
and then minus one minus one.

12:37.860 --> 12:44.990
I just want to see kind of like reduces the pixels around it in a in an intuitive sense.

12:46.110 --> 12:46.930
Then blur.

12:47.000 --> 12:53.730
So basically takes C equal significant gives equal significance to all of the pixels around all the

12:53.730 --> 12:59.000
one in the center and therefore it combines them together and you get a blur edge and hands.

12:59.010 --> 13:03.840
So here you can see that minus one and one and then you get zeros right.

13:03.840 --> 13:11.070
So you did delete to remove the pixels around the main one in the middle and you only keep this one

13:11.070 --> 13:15.440
at a minus one and it gives you an edge and this was a bit harder to understand how it works.

13:16.260 --> 13:20.640
Like probably harder just to think intuitively edge detect.

13:20.640 --> 13:23.310
Right so this one probably makes more sense.

13:23.310 --> 13:25.790
Right you take that middle one.

13:25.800 --> 13:28.350
You reduce the middle one.

13:28.960 --> 13:36.100
The Probably like the strength of the middle pixel and then you look for the ones you look for.

13:36.360 --> 13:41.920
These ones you see increase the strength of the ones around them.

13:42.030 --> 13:43.850
So you have the ones there.

13:44.520 --> 13:50.370
Yeah so that's that gives you like an edge takes and you can see which you get there and boss another

13:50.370 --> 13:50.640
one.

13:50.640 --> 13:58.120
So the key here is that it's symmetrical and you can see the image becomes asymmetrical as well.

13:58.120 --> 14:03.490
So you got like that kind of feeling that it's standing out towards you.

14:03.780 --> 14:08.880
And that's what you get when you have like minuses here and plus here again this is very this is getting

14:08.910 --> 14:13.680
a bit technical now but at least we can get some kind of intuitive understand lizards go quickly through

14:13.680 --> 14:14.100
them again.

14:14.100 --> 14:20.710
So there's sharpen there's blur there's edge in hands there's an edge detect there's boss.

14:20.830 --> 14:27.290
And so as you can see these are great examples of the same image but we're getting feature maps.

14:27.300 --> 14:31.680
So we use different feature detectors to get different feature maps of the same image.

14:31.830 --> 14:39.900
And therefore now we have lots of the lots of versions of this image where in each one we've tried to

14:39.900 --> 14:44.850
detect certain things these terms are not applicable to us.

14:44.860 --> 14:49.790
There is said like a boss is probably not applicable to us in terms of convolutional neural networks

14:50.040 --> 14:51.600
but aged detect that's important.

14:51.590 --> 14:58.490
We want to detect the edges edge enhance probably not blue or sharpen so certain things like edgy text

14:58.490 --> 15:05.100
are probably the most important one for our type of work and in terms of understanding computers they

15:05.100 --> 15:06.490
will decide for themselves.

15:06.540 --> 15:08.960
Neural networks will decide for itself what's important what's not.

15:08.960 --> 15:12.840
And it probably won't be even recognizable to the human eye.

15:12.840 --> 15:14.840
You won't be able to understand what those features mean.

15:14.850 --> 15:16.730
But the computer will decide.

15:16.740 --> 15:24.030
And that's the beauty of neural networks that they can process so many different things and understand

15:24.060 --> 15:30.660
without even having that intuition without having that explanation why they will understand which features

15:30.660 --> 15:37.350
are important to them whether we have a name for them or not that that's a whole that's an irrelevant

15:37.350 --> 15:39.790
question for the artificial neural network.

15:39.930 --> 15:41.150
And my favorite one.

15:41.220 --> 15:50.670
Here's a image of Geoffrey Hinton from Geoffrey Hinton passed through one of these filters.

15:50.880 --> 15:52.990
All right so that brings us to the end of the data Tauriel.

15:53.010 --> 15:55.410
I hope you enjoyed learning about convolution.

15:55.410 --> 16:03.120
The key takeaway is that convolution the primary purpose of evolution is to find features in your image

16:03.480 --> 16:09.780
using the feature detector put them into a feature map and by having them in a future map it still preserves

16:09.780 --> 16:16.200
the spatial relationships between pixels which is very important for us to you know because if they

16:16.200 --> 16:19.160
are completely jumbled up then we have we've lost the pattern.

16:19.290 --> 16:25.050
And at the same time it's important to understand that most of the time the features a neural network

16:25.050 --> 16:32.370
will detect and use to recognize certain images and Klaas's will mean nothing to humans but nevertheless

16:32.400 --> 16:32.960
they work.

16:33.060 --> 16:34.360
And that's what evolution is.

16:34.380 --> 16:36.220
And I look forward to seeing you next Tauriel.

16:36.240 --> 16:37.920
Until then enjoy deep learning.
