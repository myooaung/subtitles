WEBVTT
1
00:00:00.570 --> 00:00:03.950
Let's discuss ways to avoid congestion.

2
00:00:03.980 --> 00:00:11.210
The main mechanism that we'll discuss here is a W read or weighted random early detection w rate is

3
00:00:11.210 --> 00:00:13.800
a way to avoid congestion.

4
00:00:13.880 --> 00:00:21.110
But before we discuss w rate let's look at the problem cues on routers and switches are finite.

5
00:00:21.140 --> 00:00:27.860
In other words they can only hold or buffer a certain number of packets if there's a burst of traffic

6
00:00:28.100 --> 00:00:30.200
and the buffers are overrun.

7
00:00:30.200 --> 00:00:37.090
In other words there are more packets arriving than can be transmitted and buffered by a router with

8
00:00:37.100 --> 00:00:37.920
switch.

9
00:00:38.300 --> 00:00:43.470
It will started dropping packets when the queue folds up.

10
00:00:43.780 --> 00:00:46.660
All new packets arriving will be dropped.

11
00:00:46.660 --> 00:00:52.750
That's called tailed drop as an analogy think of a bucket.

12
00:00:53.120 --> 00:00:57.380
The bucket is filling up with water or packets.

13
00:00:57.530 --> 00:01:03.220
Once the bucket is full or in the case of a rod or a switch the queue is full.

14
00:01:03.230 --> 00:01:05.950
Any new packets that arrive are dropped.

15
00:01:07.170 --> 00:01:10.990
Because there's no space to buffer them or hold them in memory.

16
00:01:11.190 --> 00:01:20.400
Now when tail drop is used it results in wasted bandwidth especially when using TCE P here's an example

17
00:01:20.400 --> 00:01:27.590
of what happens when tailed drop is used and you've got lots of TCB flows the 100 percent is 100 percent

18
00:01:27.590 --> 00:01:35.480
utilization of an interface the y axis is utilization of an interface with 100 percent indicated by

19
00:01:35.480 --> 00:01:40.170
this line x axis is time.

20
00:01:40.230 --> 00:01:48.860
So what happens is if multiple flows start sending traffic and tell drop occurs at this point packets

21
00:01:48.860 --> 00:01:51.350
from all flows are dropped.

22
00:01:51.380 --> 00:01:58.450
Now what happens with TTP is that when packets are dropped the TTP senders slow down.

23
00:01:58.480 --> 00:02:06.040
In other words they back off they slow down and then they slowly increase the window size again to increase

24
00:02:06.040 --> 00:02:07.910
the speed of forwarding.

25
00:02:08.050 --> 00:02:13.540
So what happens is the utilization of interface goes down because the three centers back off.

26
00:02:13.630 --> 00:02:19.270
In other words they slow down they then increase they would decide to increase the number of packets

27
00:02:19.270 --> 00:02:22.810
that they are transmitting before getting an acknowledgement.

28
00:02:22.930 --> 00:02:29.950
But when the buffers are full again packets are dropped from all these flows including any new flows

29
00:02:30.430 --> 00:02:36.600
that start sending traffic so in this case we have four senders backing off or slowing down.

30
00:02:36.750 --> 00:02:41.400
Again they increase their window size and increase the number of packets that they can transmit before

31
00:02:41.400 --> 00:02:47.360
getting an acknowledgement and eventually it gets to the point where the buffers of a router or a switch

32
00:02:47.360 --> 00:02:48.710
are full again.

33
00:02:48.950 --> 00:02:53.260
Packets from all flows are dropped so they all slowed down.

34
00:02:53.510 --> 00:02:59.850
So the problem is is when the bucket is full packets from multiple flows are being received there's

35
00:02:59.870 --> 00:03:01.630
no space to buffer them.

36
00:03:01.990 --> 00:03:09.470
So packets are dropped from all the flows all centers back off at the same time and then increase speed

37
00:03:09.560 --> 00:03:11.240
at the same time.

38
00:03:11.500 --> 00:03:17.720
C end up having what's called a global synchronization where multiple centres are increasing their window

39
00:03:17.720 --> 00:03:19.050
size at the same time.

40
00:03:19.870 --> 00:03:25.610
They're slowing down at the same time increasing their speed at the same time slowing down at the same

41
00:03:25.610 --> 00:03:27.860
time and so forth and so on.

42
00:03:27.860 --> 00:03:33.260
Over time you never get full utilization of the interface.

43
00:03:33.300 --> 00:03:41.760
Now the idea with w red and congestion avoidance is you randomly drop packets from multiple flows before

44
00:03:42.270 --> 00:03:50.070
the queue folds up so in other words before the bucket is full or the cube is full you are ready dropping

45
00:03:50.100 --> 00:03:59.220
packets from flows but you do that randomly so you might drop a packet from flow one which means flow

46
00:03:59.220 --> 00:04:07.230
one will slow down but while center one is slowing down send it to is increasing its speed because its

47
00:04:07.230 --> 00:04:08.480
packets haven't been dropped.

48
00:04:09.860 --> 00:04:14.710
So while one host is slowing down another one is increasing its speed.

49
00:04:14.720 --> 00:04:20.600
This happens randomly so you've got some hosts increasing their speed and some slowing down at the same

50
00:04:20.600 --> 00:04:29.050
time instead of all of them slowing down and all of them speeding up at the same time so Cisco uses

51
00:04:29.050 --> 00:04:37.510
w red which introduces this randomness to allow better utilization of an interface interfaces bandwidth

52
00:04:38.080 --> 00:04:44.230
because some are slowing down and some are speeding up at the same time which in aggregate gives you

53
00:04:44.230 --> 00:04:50.760
a better utilization of the interface so the idea with W rate is you have a minimum threshold and a

54
00:04:50.760 --> 00:04:56.730
maximum threshold these valleys are below the size of the full queue.

55
00:04:57.940 --> 00:05:05.240
So the idea is when the average queue size or average queue depth is below the minimum threshold.

56
00:05:05.280 --> 00:05:12.730
Note packets have dropped when the average queue depth goes above the minimum threshold but is below

57
00:05:12.730 --> 00:05:14.510
the maximum threshold.

58
00:05:14.560 --> 00:05:22.580
We have random drops of packets but when it goes over the maximum threshold we have full drops of a

59
00:05:22.580 --> 00:05:25.510
traffic CLOs.

60
00:05:25.530 --> 00:05:33.060
The reason why we have W as in weighted random early detection is you can weight this based on different

61
00:05:33.060 --> 00:05:41.220
classes so you can have different maximum thresholds for different traffic classes.

62
00:05:41.260 --> 00:05:49.690
You may want to start dropping all FCP traffic before you drop HDP traffic so you can create a different

63
00:05:49.690 --> 00:05:56.830
minimum and maximum threshold so that certain traffic types are tailed dropped or fully dropped before

64
00:05:56.830 --> 00:06:06.280
other traffic times that can be based as an example on IP precedents or DCP so the idea with w red is

65
00:06:06.280 --> 00:06:11.680
we started dropping packets before the queue is full.

66
00:06:11.680 --> 00:06:19.360
We are avoiding congestion by pre selecting which packets get dropped and typically only want to drop

67
00:06:19.680 --> 00:06:26.680
DCP packets because TTP flows will read transmit so randomly dropping packets instead of tail dropping

68
00:06:26.680 --> 00:06:29.850
them avoids global synchronization.

69
00:06:30.160 --> 00:06:35.800
Different TTP flows are increasing their speed while others are slowing down so you get better utilization

70
00:06:35.800 --> 00:06:37.770
of a link.

71
00:06:37.970 --> 00:06:44.880
You also ensure that there is buffer space left for your voice packets so you will set your maximum

72
00:06:44.880 --> 00:06:53.290
threshold low enough so that FCP packets are fully dropped while ensuring that they still space left

73
00:06:53.290 --> 00:06:55.660
in the buffer for voice traffic.

74
00:06:57.150 --> 00:07:01.760
So in summary we have multiple quality of service mechanisms.

75
00:07:01.920 --> 00:07:04.220
We have classification and mocking.

76
00:07:04.470 --> 00:07:11.890
We have policing shaping and remarking we have congestion management or scheduling tools and we have

77
00:07:11.890 --> 00:07:18.670
a link specific tools such as link fragmentation and into leaving the issue a course is only an introduction

78
00:07:18.670 --> 00:07:20.260
to quality of service.

79
00:07:20.290 --> 00:07:25.930
Have a look at the quality of service s or indeed guide for more information about quality of service

80
00:07:25.960 --> 00:07:32.110
and good examples of how to apply quality of service on physical switches and routers.
