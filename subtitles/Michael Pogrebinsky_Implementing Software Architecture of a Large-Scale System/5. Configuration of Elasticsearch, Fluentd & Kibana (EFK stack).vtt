WEBVTT
1
00:00:03.470 --> 00:00:05.600
OK, so the instance has started.

2
00:00:05.660 --> 00:00:06.770
Let's connect to that.

3
00:00:13.600 --> 00:00:19.130
OK, so the instance has connected, so let's start our work now, let's go to our project directly

4
00:00:20.140 --> 00:00:22.050
Docker demos.

5
00:00:23.980 --> 00:00:29.950
So now we have this zero six logging that this is where we need to go.

6
00:00:30.340 --> 00:00:32.490
This is data logging demonstrations.

7
00:00:33.250 --> 00:00:34.060
So let's go there.

8
00:00:39.120 --> 00:00:47.460
Now, apart from Dorothy and vinegar composed by Hamilton, we also have undergone there's an additional

9
00:00:47.460 --> 00:00:48.360
thing that we do.

10
00:00:49.110 --> 00:00:51.200
So let's go through them one by one.

11
00:00:51.210 --> 00:00:55.860
So let's first look at our environment and so our environment find the right?

12
00:00:55.860 --> 00:00:56.540
Absolutely no.

13
00:00:56.940 --> 00:01:00.690
It remains the same as it was in the previous demonstration.

14
00:01:01.650 --> 00:01:04.850
Now let's open Docker compose one.

15
00:01:05.850 --> 00:01:11.490
So here we have added a few components, so accordingly we have added.

16
00:01:12.990 --> 00:01:18.810
Docker volumes, we went to this for Docker volume with we have added over volumes for ElasticSearch

17
00:01:19.290 --> 00:01:22.290
and fluent components to store their data.

18
00:01:23.040 --> 00:01:24.630
Now let's go through those components.

19
00:01:24.630 --> 00:01:28.440
So the first one is fluent so fluently.

20
00:01:28.800 --> 00:01:35.250
We need to basically capture all the log messages that are coming to Docker drivers.

21
00:01:35.550 --> 00:01:43.920
Driver will send all these messages to fluently, so fluently will filter bars and do all those things

22
00:01:44.070 --> 00:01:48.390
with the messages, and it will pass on those messages to the log collector.

23
00:01:48.960 --> 00:01:49.890
And in this case?

24
00:01:51.090 --> 00:01:53.880
Fluently will itself act as a local actor.

25
00:01:54.850 --> 00:01:57.490
So that is where our messages are going to go.

26
00:01:58.120 --> 00:02:05.140
So the configuration that we are going to see now is actually for this fluid lock collected.

27
00:02:07.260 --> 00:02:14.090
So here we have taken an image of fluidity, and we have customized it a bit, and I'll show you what

28
00:02:14.100 --> 00:02:21.210
the customization that we have done, it's a very simple customization and rest of the important configuration

29
00:02:21.210 --> 00:02:25.050
over here is that it takes a configuration file.

30
00:02:25.410 --> 00:02:27.270
So let me see that.

31
00:02:27.690 --> 00:02:32.870
So this is pretty much what is there for fluidity Docker configuration.

32
00:02:33.690 --> 00:02:39.590
There is nothing special going on over here, except that we need to see what's there in fluent durcan

33
00:02:39.630 --> 00:02:43.290
file and what's there in fluent image.

34
00:02:43.620 --> 00:02:48.030
So let's first go to Docker directly and inside that.

35
00:02:48.360 --> 00:02:53.610
Let's go to fluidity where we have Docker file for fluid image.

36
00:02:55.050 --> 00:02:57.510
So here we have done a very simple thing.

37
00:02:57.510 --> 00:03:03.060
We have added certain fluidity plugins to the base fluid image.

38
00:03:04.150 --> 00:03:06.970
And these plugins are not useful for this demonstration.

39
00:03:07.510 --> 00:03:10.630
They will be useful for the final setup that we will have.

40
00:03:11.230 --> 00:03:18.160
It is basically to pass exceptions and present them and to store them in a much better format and to

41
00:03:18.160 --> 00:03:19.560
do some parsing of messages.

42
00:03:19.710 --> 00:03:25.280
So for that, we have a configuration file also.

43
00:03:26.260 --> 00:03:29.680
So this is the fluid or con configuration file.

44
00:03:30.040 --> 00:03:35.500
It's a little more complex file than what we are going to use for this demonstration.

45
00:03:35.530 --> 00:03:38.860
This will be useful for our final setup so you can take a look at it.

46
00:03:39.310 --> 00:03:43.490
You will have to go through fluently documentation to understand this fully.

47
00:03:44.080 --> 00:03:49.780
But if you want to understand how fluent works, then this particular demonstration would be good enough.

48
00:03:50.230 --> 00:03:54.400
You will just concentrate on the bare minimum functionality of fluency.

49
00:03:55.030 --> 00:04:00.550
So we have certain plugins to flaw in the image, and the second thing that we have done is we have

50
00:04:00.550 --> 00:04:08.140
created a fluent configuration file which will tell our fluid the instance who how to read the messages

51
00:04:08.140 --> 00:04:13.960
that are coming to fluently through Docker drivers or Docker driver who will send messages to friendly

52
00:04:14.140 --> 00:04:14.650
collector.

53
00:04:15.010 --> 00:04:20.800
So this configuration file will then fluidity how to pass them, how to filter the messages and stuff

54
00:04:20.800 --> 00:04:21.280
like that.

55
00:04:22.520 --> 00:04:29.990
It will also tell where it needs to pass on those messages, so let's go ahead and see the actual flu

56
00:04:29.990 --> 00:04:32.810
and the files that we are using configuration files.

57
00:04:33.200 --> 00:04:36.260
So let's go to movies directly

58
00:04:39.410 --> 00:04:39.740
here.

59
00:04:39.740 --> 00:04:48.500
If we see flu and the flu and call this the one that we're using for the current demonstration, it

60
00:04:48.500 --> 00:04:49.370
is pretty simple.

61
00:04:49.910 --> 00:04:55.820
It says that anything that is coming on board to foldable to fall is the source.

62
00:04:56.180 --> 00:04:59.390
So this is the work that we will have to provide to Dr. Driver.

63
00:04:59.870 --> 00:05:05.210
We'll have to tell the driver that this is where our flu and the local actor is listening.

64
00:05:05.510 --> 00:05:11.810
So anything that comes to this port, it will treat it as a source for a lot and that will be passed

65
00:05:12.290 --> 00:05:12.640
to us.

66
00:05:12.650 --> 00:05:20.240
Think that we we're defined by MedStar stars or anything that is coming out of this source will and

67
00:05:20.570 --> 00:05:21.910
to this particular thing.

68
00:05:21.920 --> 00:05:23.260
And what does this say?

69
00:05:23.270 --> 00:05:25.940
This is that whatever is coming in here?

70
00:05:26.360 --> 00:05:28.470
Copy that to this particular story.

71
00:05:29.240 --> 00:05:34.310
This is one store that we have provided, and it has also listed another two.

72
00:05:34.340 --> 00:05:41.930
So another story is basically the studio so fluently on its studio will print anything that is coming

73
00:05:41.930 --> 00:05:42.310
to it.

74
00:05:42.620 --> 00:05:48.800
So anytime you want to see what is coming to Florida, you can always look at the flu and the doctor

75
00:05:48.800 --> 00:05:51.110
logs, so it will be available over there.

76
00:05:52.640 --> 00:05:58.250
The main thing that is happening over here is that any log messages that is coming to this flu and will

77
00:05:58.250 --> 00:06:01.880
be sent to this store and that store type is ElasticSearch.

78
00:06:02.270 --> 00:06:08.870
And we have given where this ElasticSearch is located and how this log should be formatted.

79
00:06:09.530 --> 00:06:12.530
So a very simple configuration or typical configuration.

80
00:06:13.430 --> 00:06:15.680
This should be good enough for us to get going.

81
00:06:16.280 --> 00:06:19.150
So we have this configuration for fluidity.

82
00:06:20.610 --> 00:06:28.140
Now, let's look at the configuration for ElasticSearch, but before we go there, let's look at the

83
00:06:28.770 --> 00:06:36.850
Docker configuration that our services or web component are going to send these log messages to the

84
00:06:36.900 --> 00:06:38.220
floor and the log collector.

85
00:06:39.030 --> 00:06:43.530
So for that, let's go down to some service.

86
00:06:44.130 --> 00:06:46.050
So let's see, this web application is there.

87
00:06:46.800 --> 00:06:54.710
What we have done over here is that we did a configuration file logging and we have specified drivers

88
00:06:54.710 --> 00:07:00.450
as fluently and we have provided the address where this fluidity is located.

89
00:07:00.450 --> 00:07:02.580
So it is there on this machine itself.

90
00:07:03.360 --> 00:07:10.470
And this is where this fluidity does the port one which it is supposed to send these logs.

91
00:07:10.920 --> 00:07:11.160
No.

92
00:07:11.160 --> 00:07:16.500
Similarly, let's look at some of the service so that circuitry service to get this service.

93
00:07:16.950 --> 00:07:22.280
Also, we have done the same thing that we have added this logging configuration.

94
00:07:22.320 --> 00:07:31.430
This will allow this Docker container or gateway service to send its history output as a log to fluently

95
00:07:32.340 --> 00:07:34.380
so that that's a simple configuration.

96
00:07:34.380 --> 00:07:42.960
So now we understand how all the log messages will be sent from any service using Docker logging driver

97
00:07:43.470 --> 00:07:44.850
to fluently.

98
00:07:45.270 --> 00:07:52.230
Now we have also seen that we have instructed fluidity, which is basically this whole thing, this

99
00:07:52.230 --> 00:07:56.880
particular log collector, how to and where to send this log messages.

100
00:07:56.880 --> 00:08:00.870
So we have said that we need to send it to ElasticSearch.

101
00:08:01.530 --> 00:08:05.520
So now let's go to ElasticSearch configuration.

102
00:08:09.650 --> 00:08:12.170
It's actually up so that we go all the way up.

103
00:08:12.830 --> 00:08:16.250
So this is ElasticSearch configuration.

104
00:08:16.580 --> 00:08:23.420
Here we are directly getting image that is available in L.A. You are not customizing this image and

105
00:08:23.600 --> 00:08:23.830
we.

106
00:08:24.590 --> 00:08:26.660
So then barometers over here.

107
00:08:26.870 --> 00:08:32.990
The only one which is of importance over here is that we have disable security to false.

108
00:08:33.680 --> 00:08:38.570
This introduction should be able to do, but in our case, we have kept it to false.

109
00:08:39.110 --> 00:08:45.770
We are assuming that within our internet, within our backing, all the services can access ElasticSearch.

110
00:08:45.860 --> 00:08:47.630
Server services need to access it.

111
00:08:48.290 --> 00:08:53.540
And we do not want to use adjectives or SSL for that.

112
00:08:54.290 --> 00:09:03.080
Now this will start on four nine two zero zero and it will be in the network in which all services are

113
00:09:03.080 --> 00:09:03.500
working.

114
00:09:04.790 --> 00:09:11.360
And we have mapped it to a volume where any data that is being stored in ElasticSearch will be permanently

115
00:09:11.360 --> 00:09:13.340
stored on this volume.

116
00:09:14.060 --> 00:09:19.700
We have now also added another configuration restart unless stop.

117
00:09:21.110 --> 00:09:23.960
And same thing, we are down to Florida also.

118
00:09:24.380 --> 00:09:30.860
So wherever we have these critical services without which our services won't work, we have for them

119
00:09:30.860 --> 00:09:32.630
as a restart on this storm.

120
00:09:32.630 --> 00:09:35.570
So we live, we manually stop these containers.

121
00:09:36.050 --> 00:09:42.800
They will be stopped if they get stopped because machine has restarted or for some reason, the container

122
00:09:42.800 --> 00:09:43.310
has crashed.

123
00:09:43.700 --> 00:09:46.460
Then Dover will restart the containers.

124
00:09:48.110 --> 00:09:51.780
So now this is how we will get all the data in ElasticSearch.

125
00:09:51.800 --> 00:09:54.440
We do not need to do a whole lot of configuration.

126
00:09:55.250 --> 00:09:58.100
The basic configuration of ElasticSearch is enough.

127
00:09:58.880 --> 00:10:03.980
And then the last thing that we need to do is that we need to configure.

128
00:10:05.150 --> 00:10:13.320
First, we need to bring up a container with Cabana because we will use Cabana, as are access to ElasticSearch.

129
00:10:13.320 --> 00:10:17.840
So Cabana will be providing some way to access ElasticSearch.

130
00:10:18.410 --> 00:10:21.200
Once we start Cabana, we'll do some configuration there.

131
00:10:21.210 --> 00:10:28.130
But just to dart cabana container, we just need to make it aware of where ElasticSearch is located

132
00:10:28.730 --> 00:10:29.330
in this case.

133
00:10:29.330 --> 00:10:33.200
Also, we are using the image provided by Docker registry.

134
00:10:33.500 --> 00:10:34.940
So we are not customizing it.

135
00:10:35.480 --> 00:10:39.440
It is running on some port, which is what we here five six zero one.

136
00:10:39.890 --> 00:10:46.460
And this is the important thing that we have provided to given the configuration that we're ElasticSearch

137
00:10:46.460 --> 00:10:47.060
is located.

138
00:10:48.150 --> 00:10:52.140
And apart from that, we have added statements like depends on.

139
00:10:52.890 --> 00:10:58.200
So if we are trying to bring up Cubana, given it will not work unless ElasticSearch is dead.

140
00:10:58.590 --> 00:11:01.710
So we have added this depends on configuration.

141
00:11:01.710 --> 00:11:05.430
Similarly, we have this depends on configuration for all of the services.

142
00:11:05.790 --> 00:11:11.730
So that say, this load balancer web is that it won't it will be useless without replication.

143
00:11:11.730 --> 00:11:15.150
So we have provided this configuration depends on that.

144
00:11:15.540 --> 00:11:21.900
So similarly, we have added this configuration to all our services Docker services.

145
00:11:22.410 --> 00:11:26.850
So you can take a look at these configuration, but this is pretty much what we have it.

146
00:11:29.470 --> 00:11:36.070
So we are done with the configuration part now, it's the time to actually start other applications,

147
00:11:36.070 --> 00:11:37.240
so let's go ahead and do that.
