WEBVTT
1
00:00:01.490 --> 00:00:05.510
So these are some choices of open source products that we can have.

2
00:00:05.540 --> 00:00:08.470
There are more products, but these are some popular choices.

3
00:00:09.630 --> 00:00:18.090
Let's first start with log agent and log collector to log agents, responsibility is to transfer logs

4
00:00:18.090 --> 00:00:19.620
to a log collector.

5
00:00:20.340 --> 00:00:22.890
And these logging inside installed on the machine.

6
00:00:24.010 --> 00:00:32.620
So we can either have flu India over there, we can have log status light, and we can also delegate

7
00:00:32.620 --> 00:00:41.620
this job to Docker containers or Docker containers, they provide a driver which can transfer these

8
00:00:41.770 --> 00:00:45.280
log files, which are coming on Docker standard output.

9
00:00:45.290 --> 00:00:53.830
It can transfer that standard output to fluent the log collector so that fluently and Docker.

10
00:00:54.190 --> 00:01:03.130
There is an integration that is already in place and work that integration does is it eliminates the

11
00:01:03.130 --> 00:01:06.580
need for installing agent on each machine.

12
00:01:07.060 --> 00:01:09.900
If all are components, they are Docker ized.

13
00:01:09.980 --> 00:01:14.110
If they're Docker containers, then we can make use of this Docker driver.

14
00:01:14.740 --> 00:01:18.790
There's a log agent, so that's a big convenience for us.

15
00:01:18.970 --> 00:01:27.910
If we can somehow use glue and then we will not have to install agent on our containers and that will

16
00:01:27.910 --> 00:01:29.300
be a big convenience for us.

17
00:01:29.320 --> 00:01:35.190
So this is a compelling reason for us to consider fluidity over logs.

18
00:01:35.200 --> 00:01:35.590
Dash.

19
00:01:37.400 --> 00:01:43.910
Now, if you look at fluent in lockstep there, they are both good products, and the advantage of Lock

20
00:01:43.910 --> 00:01:50.570
Stash is that it is part of Evilkiss Tech E for ElasticSearch Alpha Log, Stash and give or given up.

21
00:01:50.900 --> 00:01:54.650
So they all work seamlessly, so that's a big plus for large stash.

22
00:01:55.280 --> 00:02:01.520
But if you look at blue deep, it has also very good integration to ElasticSearch and they're absolutely

23
00:02:01.520 --> 00:02:02.150
no issues.

24
00:02:02.870 --> 00:02:10.010
So that advantage of log stash that it is part of ElasticSearch stack really doesn't stand that much.

25
00:02:10.670 --> 00:02:19.480
So the benefit that we are getting by using fluently as a local actor along with Docker Driver is logging

26
00:02:19.480 --> 00:02:19.700
in.

27
00:02:20.000 --> 00:02:24.740
That's a very compelling case for using Fluent Log Collector.

28
00:02:25.430 --> 00:02:29.090
So we are going to use fluently as a log collector.

29
00:02:29.720 --> 00:02:34.280
Now this local actor can transform our logs, it can pass them, it can.

30
00:02:34.820 --> 00:02:37.400
We can filter our logs and we can do various stuff.

31
00:02:37.400 --> 00:02:45.800
And once we have done that, we can actually store that log and do a log storage now from our log storage.

32
00:02:45.830 --> 00:02:54.770
We expect that these storage should be permanent so that even databases qualify for logs, storage or

33
00:02:54.770 --> 00:02:56.150
database has a problem.

34
00:02:56.720 --> 00:03:04.400
The fact that databases are not only used for read and write of data, but also to modify data so they

35
00:03:04.400 --> 00:03:07.580
come with the overhead of managing transactions.

36
00:03:07.940 --> 00:03:13.610
But in case of log storage, we do not have any requirement of modifying data.

37
00:03:14.180 --> 00:03:16.100
We only want to read data.

38
00:03:16.970 --> 00:03:24.620
So the overhead of writing data and transactions is something which is not good for us, and that is

39
00:03:24.710 --> 00:03:30.280
going to impede the performance of our storage because these logs will come at a very high volume.

40
00:03:30.680 --> 00:03:37.970
We want a storage which can store the logs or the log records at a very high throughput.

41
00:03:38.540 --> 00:03:43.610
So our teams are not a suitable choice for providing a very high rate throughput.

42
00:03:44.150 --> 00:03:51.530
So ElasticSearch and Solr, which are search engines, they are pretty suitable for this purpose because

43
00:03:51.530 --> 00:03:59.720
the way they are designed for storing data that is not mutable and we can very quickly search any data

44
00:04:00.020 --> 00:04:04.250
through ElasticSearch and solar now between ElasticSearch and solar.

45
00:04:04.610 --> 00:04:11.420
These are two popular products, but ElasticSearch has become immensely popular, so I have chosen ElasticSearch

46
00:04:11.420 --> 00:04:12.050
over Soledad.

47
00:04:12.770 --> 00:04:20.300
But if you look at ElasticSearch and solar, they are based on Sam Lucene engine, so their inner working

48
00:04:20.300 --> 00:04:21.520
is pretty much the same.

49
00:04:21.530 --> 00:04:27.080
The core is in the way they manage the cluster and all that stuff.

50
00:04:27.500 --> 00:04:33.770
How do they manage multiple instances that BYOD is going to be different and that is where the differences

51
00:04:33.770 --> 00:04:34.220
can be.

52
00:04:34.550 --> 00:04:40.040
Nevertheless, because ElasticSearch is so popular and so that is not that popular, ElasticSearch is

53
00:04:40.040 --> 00:04:40.730
our choice.

54
00:04:41.860 --> 00:04:50.050
Now, once we have decided to work with ElasticSearch and fluently, the major decision for us is salt

55
00:04:50.320 --> 00:04:55.240
because these are sort of functional components in our system.

56
00:04:55.570 --> 00:04:58.000
This is where we are going to do a lot of configuration.

57
00:04:58.300 --> 00:05:05.020
Now did the last part that we need is logging another tech spot and we need that because we want a proper

58
00:05:05.020 --> 00:05:07.300
UI to analyze the logs.

59
00:05:07.300 --> 00:05:12.480
So let's say if you have an IBM as you have a choice of working with just skin.

60
00:05:13.090 --> 00:05:20.020
But if you're working with a school, will have to write queries and we will have to be working to a

61
00:05:20.020 --> 00:05:22.690
command line interface which will not present any other boards.

62
00:05:23.050 --> 00:05:25.540
But we want capability more than that.

63
00:05:25.900 --> 00:05:32.020
We want something which can create those queries for us and can also provide us reports.

64
00:05:32.770 --> 00:05:36.730
So as far as open source goes, we have popular choices over here.

65
00:05:36.730 --> 00:05:41.380
Like Kibwana and Gryffindor, Splunk is another popular tool.

66
00:05:41.740 --> 00:05:45.100
But there will be license requirement for Splunk.

67
00:05:45.520 --> 00:05:48.400
So what we are going to use over here is Cabana.

68
00:05:48.460 --> 00:05:51.610
And if you want to add grandfather to it, I have tried that.

69
00:05:51.610 --> 00:05:53.290
It's perfectly fine.

70
00:05:53.560 --> 00:06:00.310
It can be easily integrated, but as we are not going to do too much of analytics, Cabana is just fine

71
00:06:00.310 --> 00:06:01.090
for our purpose.

72
00:06:01.690 --> 00:06:10.380
So our tech choice will be cabana ElasticSearch fluently along with Docker driver as I'm logging.
