1
00:00:00,120 --> 00:00:04,320
Now it's the time to start other applications, so let's go ahead and do that.

2
00:00:08,680 --> 00:00:14,650
So this will pull the ElasticSearch image from Docker registry.

3
00:00:15,630 --> 00:00:20,190
And then it will be the images that are related to ElasticSearch.

4
00:00:20,760 --> 00:00:24,900
It will be given an image, it will be fluent image.

5
00:00:25,050 --> 00:00:30,810
Right now it has started building, flew in the image and then it will start all the containers one

6
00:00:30,810 --> 00:00:32,550
by one once it has all the images.

7
00:00:33,000 --> 00:00:38,460
It will start the container, so we will wait till it starts all the containers.

8
00:00:39,710 --> 00:00:45,170
In the meantime, I'll post the video and we will return back once oil continues on a.

9
00:00:49,150 --> 00:00:51,880
There is some kind of time out message.

10
00:00:52,480 --> 00:00:56,560
Let me just check if our machine configuration is fine.

11
00:01:00,880 --> 00:01:06,760
OK, machine looks fine, it does you do standard for that school back.

12
00:01:08,410 --> 00:01:10,690
So just try to restart this.

13
00:01:10,690 --> 00:01:12,280
Hopefully this time it will start.

14
00:01:19,860 --> 00:01:25,470
There are too many containers to start, so looks like there was some time out because of that.

15
00:01:26,670 --> 00:01:28,500
Times out of then, I'll start again.

16
00:01:29,030 --> 00:01:32,280
I haven't seen this area before, but let's see how it goes.

17
00:01:34,650 --> 00:01:40,290
OK, looks like it has successfully created all the containers and all these containers would be starting.

18
00:01:41,070 --> 00:01:44,490
So let's just list down all the processes that are there right now.

19
00:01:45,390 --> 00:01:48,480
OK, so everything is up and on its way.

20
00:01:49,140 --> 00:01:52,250
We can just check one of those services.

21
00:01:52,250 --> 00:01:54,120
So let's just check Gateway service.

22
00:02:00,500 --> 00:02:03,560
OK, so it is starting, it's going to take time.

23
00:02:03,830 --> 00:02:10,310
So I'm going to pass this over here, and once this system is up, we will again start.

24
00:02:10,310 --> 00:02:11,930
The video will resume from there.

25
00:02:17,500 --> 00:02:21,700
OK, so get this service has started, it has taken a little less than three minutes.

26
00:02:23,560 --> 00:02:25,060
Let's look at some of the service.

27
00:02:25,060 --> 00:02:26,860
Let's have order service.

28
00:02:27,370 --> 00:02:32,680
So there are some log messages on this gateway service.

29
00:02:33,190 --> 00:02:38,680
Similarly, we expect to see certain log messages on order service as well.

30
00:02:39,340 --> 00:02:42,550
These are all bootstrap messages when these services are coming up.

31
00:02:43,120 --> 00:02:49,360
They are emitting some log messages which are going into the log as well as on Docker Studio.

32
00:02:50,020 --> 00:02:56,170
So whatever is coming on Docker is TD-LTE is being redirected to fluently.

33
00:02:56,590 --> 00:03:02,830
So when we are logging, we need to make sure that not only the log of our log that is logging those

34
00:03:02,830 --> 00:03:08,980
messages to log once, but it is also logging them on stdout because here we are using Docker driver,

35
00:03:09,370 --> 00:03:12,370
which will redirect this message on our studio to fluently.

36
00:03:12,730 --> 00:03:15,640
So now we want to check all these messages that are coming out.

37
00:03:16,300 --> 00:03:22,150
These bootstrap messages of these services, if they are reaching to fluently log collected or not.

38
00:03:22,660 --> 00:03:26,320
So to do that, let's connect to flew in the container.

39
00:03:30,680 --> 00:03:32,030
I think the spelling is wrong.

40
00:03:32,270 --> 00:03:33,680
OK, now it should be OK.

41
00:03:34,190 --> 00:03:40,520
OK, so these are the messages on fluent becomes Well, why do we have messages over here?

42
00:03:40,520 --> 00:03:46,200
Just let's take a quick look at that, and then we will go back to these log messages.

43
00:03:46,200 --> 00:03:48,890
So we had this fluent durcan.

44
00:03:49,370 --> 00:03:56,630
So we said that any message that is coming to who indeed should go to ElasticSearch and should also

45
00:03:56,630 --> 00:04:00,020
go to standard out of this fluently.

46
00:04:00,800 --> 00:04:08,660
So this fluency daemon is logging out all these messages on its container studio.

47
00:04:08,680 --> 00:04:10,820
So that is what we are looking at right now.

48
00:04:11,210 --> 00:04:19,280
So if we look at these log messages carefully, so we see this that there is this message from Gateway

49
00:04:19,280 --> 00:04:25,850
service, then there is this message from inventory service.

50
00:04:26,120 --> 00:04:27,980
This one is from military service.

51
00:04:28,760 --> 00:04:32,280
Then similarly, we have this message from the service.

52
00:04:33,650 --> 00:04:36,710
And then the next one is admin service.

53
00:04:38,900 --> 00:04:41,270
Then order a product service.

54
00:04:43,100 --> 00:04:48,390
So that we have messages from all services coming to this event.

55
00:04:48,410 --> 00:04:51,560
Messages from that would be coming here.

56
00:04:52,670 --> 00:04:58,700
So all these messages are reaching Fluent Element, that integration is pretty good.

57
00:04:59,090 --> 00:05:05,780
Now what we need to check is these messages, which are reaching fluency if they are also reaching ElasticSearch.

58
00:05:06,290 --> 00:05:14,810
So to do that, check, we will access Cabana and that Cabana will connect to ElasticSearch.

59
00:05:15,200 --> 00:05:20,840
And if we can see these log messages over there, then we know this, that these messages are reaching

60
00:05:20,840 --> 00:05:21,680
ElasticSearch.

61
00:05:22,070 --> 00:05:27,980
And if we do see them over there, then we will try to do some full text search of these messages just

62
00:05:27,980 --> 00:05:32,090
to see how we can analyze these log messages on ElasticSearch.

63
00:05:33,050 --> 00:05:41,240
So in order to help with our investigation of these log messages, let's do one thing let's create some

64
00:05:41,240 --> 00:05:48,380
orders through our system, which will touch several other services, and we will try to see whether

65
00:05:48,380 --> 00:05:52,730
all these messages we can see through given in ElasticSearch.

66
00:05:52,730 --> 00:05:54,560
So let's create some order.

67
00:05:55,160 --> 00:05:57,530
So for that, we will connect to our system.

68
00:05:58,230 --> 00:05:59,630
Let's take this IP address.

69
00:05:59,630 --> 00:06:06,830
Let's connect to our load balancer of the application, which is running on zero, which is the default

70
00:06:06,830 --> 00:06:07,160
port.

71
00:06:08,120 --> 00:06:12,740
So right now, if we bring these services?

72
00:06:14,170 --> 00:06:15,610
They just see if they are all up.

73
00:06:17,640 --> 00:06:17,970
OK.

74
00:06:18,000 --> 00:06:20,580
They are all up databases.

75
00:06:21,510 --> 00:06:23,880
OK, suppose this database is dead.

76
00:06:24,300 --> 00:06:27,460
So looks like our system is good in good shape.

77
00:06:27,480 --> 00:06:30,420
Let's go to data if there is any broader data right now.

78
00:06:32,180 --> 00:06:35,120
There is no data, so let's create some data.

79
00:06:37,340 --> 00:06:38,760
Every couple of seconds.

80
00:06:40,830 --> 00:06:48,390
OK, now that the data is created, let's check for further details that stood at seems to relate will

81
00:06:48,390 --> 00:06:49,830
get some data is created.

82
00:06:49,830 --> 00:06:51,870
We can now go ahead and create some orders.

83
00:06:52,800 --> 00:06:57,000
Let's go to products, so let's select this this quarter to.

84
00:06:58,950 --> 00:07:00,300
That said, this two part.

85
00:07:02,120 --> 00:07:03,010
Go to cart.

86
00:07:03,560 --> 00:07:08,900
Then let's create order in as we have this order.

87
00:07:09,590 --> 00:07:12,170
Let's create one more order for that matter.

88
00:07:13,460 --> 00:07:14,720
Let's take some of the order.

89
00:07:14,840 --> 00:07:16,670
So let's take this product number nine.

90
00:07:18,440 --> 00:07:20,870
Let's stick two units of this.

91
00:07:24,100 --> 00:07:25,150
Let's give orders.

92
00:07:27,070 --> 00:07:33,850
OK, so we have two orders in the system, one for Test Voter two and the other one for this product

93
00:07:33,850 --> 00:07:34,270
line.

94
00:07:35,740 --> 00:07:39,610
Let's go ahead and check this in our cabana.

95
00:07:39,700 --> 00:07:46,720
So we want to go to Cabana, we can go to monitoring and this will tell us that you are in fact given

96
00:07:46,720 --> 00:07:48,100
us will collect this log in.

97
00:07:48,100 --> 00:07:55,210
Cabana is trying to connect to our workstation at five six zero one four.

98
00:07:55,510 --> 00:08:03,370
This board will be enabled by default through our firewall, so we'll have to go to our Firewall and

99
00:08:03,740 --> 00:08:16,390
UPC network firewall and we will have to enable this, or we will have to edit the firewall rule, which

100
00:08:16,390 --> 00:08:19,270
is go ending our default network.

101
00:08:20,080 --> 00:08:20,620
So.

102
00:08:25,060 --> 00:08:25,450
Yeah.

103
00:08:25,510 --> 00:08:32,050
So there's the rules, so here we have had this four five six zero one, so I'm going to add that.

104
00:08:34,880 --> 00:08:36,410
And they did let me save this.

105
00:08:37,420 --> 00:08:44,590
This should take a few seconds for this all to be updated once it is updated.

106
00:08:45,220 --> 00:08:48,700
Then we should be able to connect to Cuba now.

107
00:08:49,630 --> 00:08:54,340
Looks like it was there in Brussels and for that matter, this has connected.

108
00:08:55,150 --> 00:08:56,230
OK, so that's good.

109
00:08:57,520 --> 00:09:00,520
Now we can connect to ElasticSearch.

110
00:09:01,820 --> 00:09:07,850
So for that, we will go to discover now because we are coming here for the first time, it will ask

111
00:09:07,850 --> 00:09:09,650
us to create an index better.

112
00:09:10,730 --> 00:09:13,730
So when we go to create Index Britain.

113
00:09:14,910 --> 00:09:22,590
We see this that there are there is one index which is already available over here.

114
00:09:22,890 --> 00:09:24,090
And what is that index?

115
00:09:24,510 --> 00:09:30,250
Index is nothing, but it's a database in ElasticSearch, so databases in ElasticSearch are called as

116
00:09:30,270 --> 00:09:30,930
indexes.

117
00:09:31,740 --> 00:09:36,990
Now this is one index created by fluently on this particular date.

118
00:09:36,990 --> 00:09:38,760
So there's the index name.

119
00:09:39,480 --> 00:09:47,820
Now we'll have to tell Kebano which index we are interested in, so we can probably select multiple

120
00:09:47,820 --> 00:09:50,180
indexes over here, so we will give it a pattern.

121
00:09:50,700 --> 00:09:54,180
So we are interested in indexes created by floor.

122
00:09:55,140 --> 00:09:58,410
So that is what we have specified over here for when these start.

123
00:09:58,710 --> 00:10:00,690
So all indexes created by fluidity.

124
00:10:01,200 --> 00:10:03,840
And that is what we are going to select.

125
00:10:05,290 --> 00:10:12,580
So here the timeframe is at time standards, the only choice of creative expression, so this index

126
00:10:12,910 --> 00:10:13,510
is created.

127
00:10:13,960 --> 00:10:20,230
Now if we go back again to discover, we should be actually be able to connect to that index, which

128
00:10:20,230 --> 00:10:22,120
has our log messages.

129
00:10:23,080 --> 00:10:25,300
So these are log messages.

130
00:10:25,330 --> 00:10:26,170
Let me.

131
00:10:27,340 --> 00:10:28,600
Hide this chart.

132
00:10:30,280 --> 00:10:36,410
Okay, so this chart isn't it did so these log messages right now, what we see?

133
00:10:36,430 --> 00:10:38,260
They are in raw form.

134
00:10:39,220 --> 00:10:47,280
What we see over here is that there are certain features in these messages that were passed by fluently.

135
00:10:47,620 --> 00:10:55,230
So whatever feels it was able to make sense of it has created them as separate fields over here and

136
00:10:55,240 --> 00:10:57,340
the rest are big.

137
00:10:57,520 --> 00:11:04,320
Log method, which is actually coming out of our application, is stored under this log feed.

138
00:11:04,330 --> 00:11:09,130
So there are various views over here and we can even see them on the left panel.

139
00:11:09,640 --> 00:11:16,150
So if we do not want to see it disappear, we want to see this in a structured fashion.

140
00:11:16,150 --> 00:11:22,110
So let's say we do not want to see this containerized keyboard and there are many other fields like

141
00:11:22,120 --> 00:11:22,420
that.

142
00:11:22,690 --> 00:11:26,020
You want to just select the fields that we are interested in.

143
00:11:26,440 --> 00:11:29,080
Then we can go ahead and do that selection over here.

144
00:11:29,710 --> 00:11:34,560
So one thing that we are interested in is container name you.

145
00:11:35,950 --> 00:11:42,760
So here we will be shown the container names, then we are interested in the actual log messages which

146
00:11:42,760 --> 00:11:45,960
are coming under the lobby so that select that.

147
00:11:46,390 --> 00:11:54,280
So this is very much like the log messages that we are getting from our application.

148
00:11:54,970 --> 00:11:59,590
Now let's see if we did create any order.

149
00:11:59,860 --> 00:12:09,880
So for that, we can do full text search and I can see processed order because this is something that

150
00:12:09,880 --> 00:12:13,450
I know comes in log messages when an order is created.

151
00:12:14,200 --> 00:12:15,070
So order.

152
00:12:15,070 --> 00:12:24,550
So this is not this two times on two different times, and these are the log messages.

153
00:12:24,550 --> 00:12:32,350
So once we have created an order of product name, we quantity two.

154
00:12:32,860 --> 00:12:39,670
And once we have created order for this product to with quantity one.

155
00:12:40,810 --> 00:12:46,270
So this is how we can do a full text search of the messages.

156
00:12:46,600 --> 00:12:49,810
One more search, let's say we can do is we can take this.

157
00:12:51,490 --> 00:12:51,800
Broader.

158
00:12:52,870 --> 00:12:55,240
And we can actually search for this.

159
00:12:56,320 --> 00:13:01,510
There are this desperate number to figure it out in our services.

160
00:13:02,050 --> 00:13:09,940
So this will give us the results and we can see this event to get a service product service, even our

161
00:13:09,940 --> 00:13:11,650
web application process this.

162
00:13:12,670 --> 00:13:19,960
So wherever, whichever service, whatever process this test product, you will be able to see those

163
00:13:19,990 --> 00:13:20,890
log messages.

164
00:13:21,490 --> 00:13:30,520
So this kind of full text search we can do, we can do some search on these text fields also.

165
00:13:30,580 --> 00:13:34,540
So not excuse these fields that we have isolated.

166
00:13:34,540 --> 00:13:37,540
So let's say these container name is one such feed.

167
00:13:37,870 --> 00:13:44,350
So if you just want to search in container name so we can say container name.

168
00:13:46,540 --> 00:13:52,390
And then we can give you a container name, so let's say verb is what I'm interested in.

169
00:13:53,850 --> 00:14:01,020
OK, so here there's going to search this only in this container name, so I'm getting now all the log

170
00:14:01,020 --> 00:14:09,240
messages that have come out of this container of it name web, which is our web application.

171
00:14:09,570 --> 00:14:15,600
So like this, we can actually quickly analyze are log messages.

172
00:14:15,870 --> 00:14:18,810
So there are two very powerful things which are happening over here.

173
00:14:19,170 --> 00:14:24,840
One, we are able to do full text search on our log messages that are getting logged.

174
00:14:25,410 --> 00:14:32,580
And the other big thing that is happening is that we don't have to go to individual machines to do search

175
00:14:32,580 --> 00:14:33,720
on these log messages.

176
00:14:34,050 --> 00:14:41,730
All of them, they come to a centralized place and we can see them together at one place and we can

177
00:14:41,730 --> 00:14:42,480
search them.

178
00:14:43,020 --> 00:14:49,770
So this is how we do logging and log analysis in a large scale system.
