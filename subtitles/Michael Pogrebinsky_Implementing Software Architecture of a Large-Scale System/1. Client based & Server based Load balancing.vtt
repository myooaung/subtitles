WEBVTT
1
00:00:02.070 --> 00:00:06.120
Now that we have simplified our claims, let's turn our attention to the next problem.

2
00:00:06.780 --> 00:00:12.360
I have clients still have one more problem of dealing with multiple instances of this over that they

3
00:00:12.360 --> 00:00:13.200
are connecting to.

4
00:00:14.100 --> 00:00:19.380
So we dealt with this problem partly for our internal services.

5
00:00:19.380 --> 00:00:24.300
So let's say this gateway service and disorder service, when they were connecting to other services,

6
00:00:25.020 --> 00:00:30.750
they could deal with multiple instances with the help of discovery service or discovery service, had

7
00:00:30.750 --> 00:00:35.500
information of all these services and for each service, what all instances are there?

8
00:00:35.520 --> 00:00:36.750
That information was there.

9
00:00:36.750 --> 00:00:43.830
Indeed, discovery service and all the services which needed that information could fetch that information

10
00:00:43.830 --> 00:00:45.720
from the discovery service.

11
00:00:46.200 --> 00:00:52.710
And once they come to know that let's get reservist has to call authorization service, then it knows

12
00:00:52.710 --> 00:00:57.390
that there are two instances of authorization service so it can decide which.

13
00:00:58.620 --> 00:01:04.530
Instance, it would like to call at a particular incident, so that job is done by a load balance,

14
00:01:04.580 --> 00:01:10.460
and we discussed that we are using ribbon load balancer over here, although we partly discuss we left

15
00:01:10.470 --> 00:01:15.960
a discussion for this time and now is the right time to discuss that.

16
00:01:16.440 --> 00:01:20.580
But before we get there, let's discuss this problem in the entirety.

17
00:01:21.210 --> 00:01:23.190
So we have a problem over here.

18
00:01:23.220 --> 00:01:29.480
We know this that we can solve through discovery service, but we still have problem for other clients.

19
00:01:29.480 --> 00:01:36.660
So let's say our browser climb and mobile client of their to connect to gateway service or if they have

20
00:01:36.660 --> 00:01:39.060
to connect to this web application.

21
00:01:39.750 --> 00:01:45.630
So the problem is letter browser clients want to connect to their application, then which instance

22
00:01:45.630 --> 00:01:46.560
it should connect to.

23
00:01:47.010 --> 00:01:53.670
Similarly, for mobile client and for web application when they're connecting to gateway service, which

24
00:01:53.670 --> 00:01:57.120
gateway service instance they should connect to.

25
00:01:57.510 --> 00:01:58.830
So that is still a problem.

26
00:01:59.340 --> 00:02:07.980
They will need some sort of guidance as to what all instances are present on this oversight and which

27
00:02:07.980 --> 00:02:10.950
instance they should call at a particular incident.

28
00:02:11.900 --> 00:02:18.690
OK, so the solution to this problem is that we introduce another component in between.

29
00:02:19.230 --> 00:02:26.640
So let's say for our web application, when our browser is trying to access our web application there,

30
00:02:26.640 --> 00:02:32.130
we can introduce a reverse proxy load balancer in between.

31
00:02:32.490 --> 00:02:39.420
So what this reverse proxy load balancer will do is that client now needs to know only about the load

32
00:02:39.420 --> 00:02:40.440
balancer in between.

33
00:02:40.740 --> 00:02:47.730
And this law, Balancer will proxy the request to these instances behind the load balancer so it can

34
00:02:47.730 --> 00:02:53.610
choose whichever instance of this web application it needs to call for a particular request.

35
00:02:54.240 --> 00:02:59.400
So similarly, for our mobile clients and for our web application, when it is acting as a client of

36
00:02:59.400 --> 00:03:06.450
Gateway Service there, we can introduce this load balancer in between and this load balancing work

37
00:03:06.450 --> 00:03:10.110
proxy, the request to the Gateway service instances.

38
00:03:10.740 --> 00:03:16.980
So these are con server side load balancing because your clients are not aware of their calling any

39
00:03:16.980 --> 00:03:24.420
load balancer, they just call a particular instance which can routing requests to the right backend

40
00:03:24.420 --> 00:03:30.180
so it instant so they they are not aware of if they are being load balance or their requests are being

41
00:03:30.180 --> 00:03:30.900
load balanced.

42
00:03:31.740 --> 00:03:36.690
But there are other kind of load balancers, data calls, client side load balancers.

43
00:03:36.690 --> 00:03:44.550
They are different from server side load balancer in the sense that your client itself is aware of multiple

44
00:03:44.550 --> 00:03:52.860
instances present for on this oversight, and it decides on its own which instance it is going to make

45
00:03:52.860 --> 00:03:53.520
a call to.

46
00:03:54.390 --> 00:04:01.020
So let's say this product service, it has got two instances it has registered itself it Yureka service.

47
00:04:01.530 --> 00:04:09.000
So here this particular ribbon client to this discovery service gets out of these two instances of product

48
00:04:09.000 --> 00:04:09.450
service.

49
00:04:09.780 --> 00:04:11.880
So then it has to call the product service.

50
00:04:11.880 --> 00:04:17.040
It can choose any of those instances, and it can make that call.

51
00:04:17.850 --> 00:04:20.760
So this is something we will see how it is implemented.

52
00:04:20.970 --> 00:04:26.970
But at this point, we only need to be aware of two things that either we can introduce oversight,

53
00:04:26.970 --> 00:04:32.520
load balancers or we have this option of client side load balancer.

54
00:04:32.520 --> 00:04:38.640
So the added benefit of plain side load balancing is that there is no extra job in between.

55
00:04:38.670 --> 00:04:42.590
So that said, this web application client has to CalDigit the service.

56
00:04:42.600 --> 00:04:46.560
It will be proxy through this server side load balancer.

57
00:04:46.560 --> 00:04:49.770
So that is one network hub in between.

58
00:04:50.160 --> 00:04:56.820
But in case of plain side load balancers, they can directly connect to these service instances.

59
00:04:56.820 --> 00:05:03.300
There is no network hop in between, so it's relatively faster, and that makes a good solution for

60
00:05:03.390 --> 00:05:04.260
server side.

61
00:05:04.380 --> 00:05:09.990
So internally, for microservices, it's a good solution because here the code is in our control.

62
00:05:10.410 --> 00:05:17.670
We can write the code to go to discovery service, fetch the only instance information and then these

63
00:05:17.880 --> 00:05:20.880
internal load balancer can make use of that information.

64
00:05:21.390 --> 00:05:27.840
But when our clients are, they're outside of our system, we have no control over them.

65
00:05:28.890 --> 00:05:35.160
Then it makes sense to have server side load balancer because we do not want that complexity to go to

66
00:05:35.160 --> 00:05:35.930
the line site.

67
00:05:36.390 --> 00:05:41.220
We want that complexity to remain on server side so that we can take control of that.

68
00:05:41.520 --> 00:05:46.080
So this is where server side load balancers, they become useful.

69
00:05:47.280 --> 00:05:53.490
Now the next decision that we need to make over here, once we decided to use the server side load balancer

70
00:05:53.490 --> 00:05:57.750
in plain sight load balancer, which load balancer we should use.

71
00:05:58.180 --> 00:06:03.610
So far, so let's say load balancers, we have multiple choices, but two popular choices are Engine

72
00:06:03.610 --> 00:06:04.780
X and Apache.

73
00:06:05.020 --> 00:06:10.990
In fact, what I would like to mention over here is that if the load is extremely high in that world,

74
00:06:11.020 --> 00:06:16.230
that is typically high for customer facing application components.

75
00:06:16.230 --> 00:06:22.210
So let's add this gateway service and this web application will face external clients.

76
00:06:22.540 --> 00:06:29.740
So here, if it's a huge large size application, then the load on the load balancers can be extremely

77
00:06:29.740 --> 00:06:30.010
high.

78
00:06:30.220 --> 00:06:36.160
So there we will not go for software base load balancers that actually we will have to go for hardware

79
00:06:36.190 --> 00:06:37.450
base load balances.

80
00:06:37.810 --> 00:06:43.960
But in this system that we are making over here, we cannot get hardware to base load balancer.

81
00:06:43.960 --> 00:06:48.970
So we are going to stick to software base load balances and there are choices.

82
00:06:49.210 --> 00:06:52.270
And in Zen about these are two very popular choices.

83
00:06:52.630 --> 00:07:00.580
Now among these two choices engine is much better choice because Indian X, due to its asynchronous

84
00:07:00.670 --> 00:07:08.080
request handling model, it handles large number of requests much more efficiently than Apache Web Server.

85
00:07:08.710 --> 00:07:11.320
So engine is a much better reverse proxy.

86
00:07:11.320 --> 00:07:17.080
So there's this theory was proxy that we are going to use as a load balancer for our external facing

87
00:07:17.080 --> 00:07:17.620
claims.

88
00:07:18.690 --> 00:07:26.550
Now, for internal clients of these microservices clients there, we can use this Netflix Robin Load

89
00:07:26.550 --> 00:07:27.030
Balancer.

90
00:07:27.030 --> 00:07:33.330
The reason for using this is we are already using Netflix unique the service we're using Netflix get

91
00:07:33.370 --> 00:07:38.490
the service because we are already working with Spring of Java Spring Framework.

92
00:07:38.850 --> 00:07:39.840
So here.

93
00:07:40.170 --> 00:07:44.340
Netflix provided a ribbon load balancer internal load.

94
00:07:44.340 --> 00:07:51.360
Balancer becomes an automatic choice for us and the reason we have chosen Client Side Load Balancer.

95
00:07:51.360 --> 00:07:57.690
We're already discussed that the communication between client and so it becomes much more efficient

96
00:07:57.690 --> 00:07:59.460
if you use Klein side load balance.

97
00:08:00.000 --> 00:08:06.780
The only thing that we need to handle is the complexity of knowing all these services through discovery

98
00:08:06.780 --> 00:08:09.300
service, and we have seen that how we can handle that.

99
00:08:10.140 --> 00:08:12.270
So this is the approach that we are going to take.

100
00:08:12.660 --> 00:08:20.550
So now next, what we are going to do is we are going to implement and ICS for our web application and

101
00:08:20.850 --> 00:08:26.990
get this service, and we will also see a little bit remaining stuff on Netflix.

102
00:08:27.040 --> 00:08:28.170
Robin Load Balancer.
