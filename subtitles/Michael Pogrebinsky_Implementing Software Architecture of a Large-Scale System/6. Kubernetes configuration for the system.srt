1
00:00:01,100 --> 00:00:06,410
OK, so we have already created Kubernetes cluster, and the other thing that we have done so far is

2
00:00:07,010 --> 00:00:14,650
that we have uploaded all our Docker images to Google Container Registry, so all that is done.

3
00:00:14,660 --> 00:00:18,650
Now the next thing that we need to do is we need to look at the configuration.

4
00:00:18,650 --> 00:00:24,860
So I've connected to the brain machine where we have been working our workstation.

5
00:00:25,880 --> 00:00:30,940
So let's go to our project crew directly there.

6
00:00:31,730 --> 00:00:37,280
We will go into Kubernetes directly and here we have certain scripts.

7
00:00:37,850 --> 00:00:42,560
Plus, there are certain configuration files which are in config directly.

8
00:00:42,980 --> 00:00:43,940
So let's look at them.

9
00:00:45,020 --> 00:00:46,820
That's what's going to config directly.

10
00:00:48,440 --> 00:00:49,310
Let's see what's there.

11
00:00:49,760 --> 00:00:57,950
So there are further five directories in this EMV directly data directly monitor service use and scalar.

12
00:00:57,950 --> 00:00:59,330
So these are different components.

13
00:00:59,330 --> 00:01:02,930
Some of them are application components in some of them are not.

14
00:01:02,930 --> 00:01:08,650
So let's say environment directly does not have any component related configuration.

15
00:01:08,660 --> 00:01:13,970
It has environment related configuration, which will be applied to all of the components.

16
00:01:14,420 --> 00:01:17,660
So data we have database filter components and monitor.

17
00:01:17,660 --> 00:01:24,140
We have components related to observability where we have log in components like ElasticSearch, yaga

18
00:01:25,040 --> 00:01:28,520
not given up and fluently.

19
00:01:28,850 --> 00:01:35,870
Similarly, we have yaga for tracing and dramedies for monitoring in service.

20
00:01:36,230 --> 00:01:38,480
We have got all these services that we have.

21
00:01:39,380 --> 00:01:46,180
Our functional business services in UAV have their application, single page application and scalar

22
00:01:46,190 --> 00:01:46,910
in scalar.

23
00:01:46,910 --> 00:01:52,280
We have configuration to scale our system.

24
00:01:52,550 --> 00:02:00,260
So one by one, we will look at these this configuration and try to understand how Kubernetes configuration

25
00:02:00,260 --> 00:02:00,710
is done.

26
00:02:00,740 --> 00:02:07,790
We will not look into each and every configuration, but we will look at all the representative configuration.

27
00:02:07,790 --> 00:02:10,390
So first, let's start with environment variable.

28
00:02:10,400 --> 00:02:14,360
So let's go into environment variables.

29
00:02:16,890 --> 00:02:21,330
So here we have a certain configuration files.

30
00:02:21,690 --> 00:02:31,490
One thing I'll do is I'll switch to my local desktop where I have these configuration files and here

31
00:02:31,490 --> 00:02:35,490
different is Vector, so it will be easily visualized over here.

32
00:02:35,700 --> 00:02:39,320
OK, so we'll go to config directly in this zero.

33
00:02:39,690 --> 00:02:45,430
We directly the first file that we have over here is Namespaces Yemen.

34
00:02:46,770 --> 00:02:50,430
So this is generally in Kubernetes.

35
00:02:50,430 --> 00:02:57,090
You will divide your application into different namespaces depending upon which team is working on what

36
00:02:57,090 --> 00:02:57,660
component.

37
00:02:58,050 --> 00:03:07,830
So let's say you have a team which works on services so you will create a namespace for them.

38
00:03:08,100 --> 00:03:14,850
So this is a namespace service that there isn't really any too much configuration over here other than.

39
00:03:20,560 --> 00:03:29,000
What we are seeing over here is that we want to create it namespace and the name of that namespaces

40
00:03:29,440 --> 00:03:30,080
service.

41
00:03:30,520 --> 00:03:31,930
So that's all we are saying over here.

42
00:03:31,960 --> 00:03:34,360
It's a pretty straightforward configuration file.

43
00:03:34,840 --> 00:03:41,680
So similarly, for other components, a letter via a team which manages our databases that installation

44
00:03:41,680 --> 00:03:46,720
their operations so we will create a separate namespace data for them.

45
00:03:47,290 --> 00:03:53,530
The reason I have created these names business for myself because it's a large system and it really

46
00:03:53,530 --> 00:03:57,580
becomes difficult to visualize all of these components together.

47
00:03:57,580 --> 00:04:07,660
So if I can separate them out and see them individually as a group, then that improves the maintenance

48
00:04:07,660 --> 00:04:10,380
part the way I can deal with these systems.

49
00:04:10,380 --> 00:04:16,810
So that's my reason, and that is very much the reason for different teams because they do not want

50
00:04:16,810 --> 00:04:20,920
to look at the components that are being maintained by other teams.

51
00:04:20,930 --> 00:04:23,530
So that's the reason for having namespaces.

52
00:04:24,640 --> 00:04:30,040
So how do we apply these namespaces to Kubernetes cluster?

53
00:04:30,700 --> 00:04:31,870
It is simple.

54
00:04:31,880 --> 00:04:35,940
What we need to do is we take this CubeSat.

55
00:04:36,160 --> 00:04:37,510
Come on now.

56
00:04:38,950 --> 00:04:42,670
The way to get CubeSat command is let's go to our workstations.

57
00:04:42,670 --> 00:04:44,380
So if you go to.

58
00:04:47,740 --> 00:04:49,690
Kubernetes is directly there.

59
00:04:49,990 --> 00:04:52,270
Like I said, there are certain skip scripts.

60
00:04:52,690 --> 00:04:57,010
So here there is one script called GCP install cubes he didn't attach.

61
00:04:57,340 --> 00:05:01,690
So let's install queue obsidian.

62
00:05:02,950 --> 00:05:10,450
This is our Kubernetes command line interface that we will use for our scripts to work, and we can

63
00:05:10,450 --> 00:05:14,410
directly issue commands to cubicle to a cluster.

64
00:05:15,580 --> 00:05:22,930
So this is how I think we will go over here which services should be restarted?

65
00:05:23,710 --> 00:05:27,070
I think we'll go with the default option, whatever it is there.

66
00:05:27,080 --> 00:05:29,260
So I'm just going to hear over here.

67
00:05:29,890 --> 00:05:30,400
So I.

68
00:05:35,070 --> 00:05:40,260
So this short installed capacity, and again, I'll go with the default option.

69
00:05:40,790 --> 00:05:41,730
It's quite with that.

70
00:05:43,480 --> 00:05:50,440
OK, so that then let's see if you can install the OK Uchitelle is now installed.

71
00:05:54,340 --> 00:05:57,100
It is got installed in user bin.

72
00:05:59,800 --> 00:06:04,530
So now this will help us issuing commands to Kubernetes.

73
00:06:04,720 --> 00:06:11,740
What we do is, let's say we want to apply that namespace configuration to Kubernetes.

74
00:06:12,220 --> 00:06:15,070
So what we will do is we will set you up still apply.

75
00:06:15,070 --> 00:06:21,290
Miners have config and we will give it defiance instead.

76
00:06:21,350 --> 00:06:27,490
In the end, we directly and I think that also starts with zero.

77
00:06:28,630 --> 00:06:28,960
Yeah.

78
00:06:28,960 --> 00:06:30,100
So that's the namespace.

79
00:06:30,100 --> 00:06:31,900
Well, so this is what we are going to do.

80
00:06:32,560 --> 00:06:37,150
The connection to the server host was, if you did, you specify the right poster board.

81
00:06:37,150 --> 00:06:43,750
So there is one thing which I missed and that is how do I tell this CubeSat, come on, which cluster

82
00:06:43,750 --> 00:06:44,650
to operate on?

83
00:06:45,040 --> 00:06:47,550
So we will correct this for for that.

84
00:06:47,560 --> 00:06:50,980
What we will do is we will go to Kubernetes cluster.

85
00:06:54,150 --> 00:06:59,040
Well, we're here the first one, the default one is gustatory click that we will reach to the cluster

86
00:06:59,040 --> 00:07:02,910
and over here we have to copy this.

87
00:07:03,360 --> 00:07:05,190
You have to click this connect.

88
00:07:06,330 --> 00:07:13,830
Button and menu item, and we have to copy this command, so there's the command to connect to a Kubernetes

89
00:07:13,830 --> 00:07:14,310
cluster.

90
00:07:15,540 --> 00:07:16,650
So we will copy this.

91
00:07:16,950 --> 00:07:20,520
Let's go and copy paste it over here and execute this.

92
00:07:23,380 --> 00:07:29,380
So now on a workstation machine, it understands which cluster to connect to.

93
00:07:29,740 --> 00:07:36,730
So let's try executing this namespace configuration, let's try to apply them.

94
00:07:42,790 --> 00:07:46,630
So one by one, it has created all the namespaces.

95
00:07:47,470 --> 00:07:53,560
Now this was pretty simple and straightforward to create these names faces, let's do one more thing.

96
00:07:54,520 --> 00:08:02,140
Let's apply a configuration file after that, and then we will talk about what was there in the configuration

97
00:08:02,140 --> 00:08:02,410
file.

98
00:08:02,830 --> 00:08:09,070
And if you see this, I have named these files with in a certain alphanumeric order.

99
00:08:09,070 --> 00:08:14,830
So the namespace file will starting with zero and this file is starting with one.

100
00:08:15,310 --> 00:08:18,730
And that means we want to execute namespace file first.

101
00:08:18,730 --> 00:08:23,320
And after that, we want to execute config maps because there is a dependency.

102
00:08:23,830 --> 00:08:29,770
This config map is will try to create environment variables, and these environment variables will be

103
00:08:29,770 --> 00:08:32,050
for different name spaces.

104
00:08:32,440 --> 00:08:35,920
So there is a dependency over here, so we have to follow the sequence.

105
00:08:36,280 --> 00:08:42,220
And that is why these directories are named like that, not just these files, but even these directories

106
00:08:42,580 --> 00:08:43,630
that just apply this.

107
00:08:45,010 --> 00:08:54,370
OK, so this has applied the config file that you see that there is an automation available with us

108
00:08:54,730 --> 00:08:57,040
to do this whole thing in one shot.

109
00:08:57,370 --> 00:09:04,610
But I'm doing it in a phased manner just to let you know what we can expect from the automation.

110
00:09:04,630 --> 00:09:07,360
What is it that automation going to provide us over here?

111
00:09:07,370 --> 00:09:09,640
So that's the reason I'm not running this group.

112
00:09:10,000 --> 00:09:11,530
Otherwise, we have this escape.

113
00:09:12,250 --> 00:09:13,120
The name is.

114
00:09:15,090 --> 00:09:16,070
Cube Deploy.

115
00:09:20,160 --> 00:09:23,670
So we have a script to actually execute this command, so.

116
00:09:24,650 --> 00:09:26,450
And that comes over here.

117
00:09:26,810 --> 00:09:28,990
So cubes, it'll apply minus.

118
00:09:29,240 --> 00:09:32,010
So there is some automation over here, we will talk about that.

119
00:09:32,630 --> 00:09:38,460
It will become easier to understand this is the ones we know actually behind the scenes.

120
00:09:38,480 --> 00:09:39,740
What exactly do you want to do?

121
00:09:40,310 --> 00:09:48,650
So let's look at this config map file that we just applied.

122
00:09:48,660 --> 00:09:56,750
So here we have a configuration and it says that for namespace service, we have created a config called

123
00:09:56,750 --> 00:09:58,610
service config and we are calling this.

124
00:09:58,790 --> 00:10:05,240
So there's config because we want this config to be used by US services and that's why the namespaces

125
00:10:05,450 --> 00:10:06,140
service.

126
00:10:06,860 --> 00:10:10,820
So here we have put all the environment variables in.

127
00:10:10,820 --> 00:10:15,920
If you remember in Docker configuration, we had data and we file for Docker compose.

128
00:10:16,580 --> 00:10:23,150
So whatever environment variables we had over there, we have put the same environment variables over

129
00:10:23,150 --> 00:10:23,480
here.

130
00:10:24,470 --> 00:10:29,780
So where we are supposed to find admin service, where it is located there.

131
00:10:29,850 --> 00:10:35,780
Also, this is located so close up, whereas is the database what is a key space name for Cassandra

132
00:10:35,780 --> 00:10:36,290
database?

133
00:10:36,680 --> 00:10:39,260
What is the hostname for Postgres database?

134
00:10:39,650 --> 00:10:44,030
So all those environment variables that we have seen so far is nothing new over here.

135
00:10:44,450 --> 00:10:48,560
All that is that in this config mapped or YAML file.

136
00:10:48,950 --> 00:10:59,030
Similarly, for that application, we have this web config, which is dead in namespace UI and the environment

137
00:10:59,030 --> 00:11:02,180
variables that we need are listed under that configuration.

138
00:11:02,630 --> 00:11:04,460
It's a Yamal configuration.

139
00:11:04,860 --> 00:11:07,730
It's a standard way of writing Yemen files.

140
00:11:08,690 --> 00:11:15,680
And the difference from the Docker data and we file is that there we were using notation that led to

141
00:11:15,680 --> 00:11:18,980
service was equal to this environment variable.

142
00:11:19,370 --> 00:11:21,830
And here we are using Coolen format.

143
00:11:22,400 --> 00:11:29,930
The other thing which is critical with YAML files is that the amount of spaces that we are using over

144
00:11:29,930 --> 00:11:34,790
here, those spaces should be according to the convention.

145
00:11:34,790 --> 00:11:37,760
They should have the right amount of indentation.

146
00:11:38,480 --> 00:11:42,710
And the other thing is that they should not have any tabs.

147
00:11:43,040 --> 00:11:46,760
So if you have any tabs in your YAML file, it will not work.

148
00:11:47,000 --> 00:11:53,240
So that's a very common mistake to not make that if you want your Kubernetes configuration to work.

149
00:11:54,110 --> 00:12:03,950
So similarly, we have environment variables for Cassandra and Cassandra config, then for fluently

150
00:12:04,970 --> 00:12:08,480
config, we have configuration, which is slightly different.

151
00:12:08,900 --> 00:12:15,860
What we have done is, as you would have if you remember in Docker, we were supplying a configuration

152
00:12:15,860 --> 00:12:20,910
file for flu and then we were supplying that at the right time.

153
00:12:20,930 --> 00:12:25,880
The reason was that if we are to change anything in the configuration, we should be able to easily

154
00:12:25,880 --> 00:12:26,420
do that.

155
00:12:26,960 --> 00:12:35,870
So instead of providing any file to Kubernetes for fluid configuration, we have provided fluid configuration

156
00:12:35,870 --> 00:12:40,100
file as an environment variable that that's the way we can look at it.

157
00:12:40,550 --> 00:12:43,550
And this is how we have put it over here.

158
00:12:43,550 --> 00:12:50,840
So this is standard Kubernetes configuration that that that we have used this part.

159
00:12:51,140 --> 00:12:57,650
And from here, this is just the view copy pasted are fluently on file.

160
00:12:58,100 --> 00:13:03,950
So this is specific to flu in this or whatever you are seeing over here, the highlighted push and this

161
00:13:03,950 --> 00:13:05,120
is specific to flu.

162
00:13:05,120 --> 00:13:14,810
And so whatever configuration we need to hear, the only change that we have made is that the host information

163
00:13:15,200 --> 00:13:21,860
we have said that this only flu and whatever you are collecting, it has to be dumped to ElasticSearch

164
00:13:21,860 --> 00:13:23,030
Typekit ElasticSearch.

165
00:13:23,030 --> 00:13:31,250
We haven't made any change over there, but we will have to change this hostname depending upon configuration.

166
00:13:31,250 --> 00:13:36,410
So we will see this why we have named this ElasticSearch post as ElasticSearch.

167
00:13:37,280 --> 00:13:43,670
But this is something that we'll have to have, according to our configuration, will have to change.

168
00:13:43,670 --> 00:13:45,140
This will ever take care of this.

169
00:13:45,800 --> 00:13:50,330
So similarly for Prometheus, also, we were using a configuration file.

170
00:13:50,720 --> 00:13:59,780
Here we have used their configuration file as an environment variable and this is being supplied to

171
00:14:00,170 --> 00:14:07,520
Prometheus config as a data file called Prometheus toward why, amid much the same bit we have, we

172
00:14:07,530 --> 00:14:08,300
were de-conflict.

173
00:14:08,690 --> 00:14:17,270
And from here we have this entire Prometheus YAML file that we have copy pasted over here.

174
00:14:18,740 --> 00:14:24,170
So this is the only complexity we have over here in terms of.

175
00:14:24,210 --> 00:14:29,210
Of how we are inputting the configuration files, but it gives us a lot of flexibility.

176
00:14:29,810 --> 00:14:33,470
If you see it a couple of times, it is not that complex.

177
00:14:33,920 --> 00:14:39,710
But the other part where we are supplying environment variables, that is pretty straightforward.

178
00:14:40,940 --> 00:14:48,170
So that is how we create vs supply environment variables to go when it is cluster.

179
00:14:49,220 --> 00:14:54,920
The other thing that we have over here is that we have this secret map.

180
00:14:55,400 --> 00:15:03,530
So if you want to supply any password so we can use this secret configuration here.

181
00:15:03,650 --> 00:15:07,820
We can provide the password here.

182
00:15:07,830 --> 00:15:10,580
I have encoded them as base64.

183
00:15:10,940 --> 00:15:22,370
So from a security perspective, it's a good practice to apply your passwords separately from your environment

184
00:15:22,370 --> 00:15:22,860
variables.

185
00:15:22,880 --> 00:15:25,220
We could have done this in an environment variable itself.

186
00:15:25,220 --> 00:15:32,120
So these two Postgres user inputs guess password we could have created as environment variables, but

187
00:15:32,120 --> 00:15:33,050
we haven't done that.

188
00:15:33,230 --> 00:15:35,990
We are using this secret map.

189
00:15:36,380 --> 00:15:41,390
The reason is that when we see this on UI, it won't show us the password over there.

190
00:15:41,390 --> 00:15:46,760
So once we apply it, anyone who is going through the system, looking at the configuration, they will

191
00:15:46,760 --> 00:15:49,220
not know what actually was the password.

192
00:15:49,220 --> 00:15:56,900
So once we apply it, we can just remove these files and this will be stored in Gujaratis configuration

193
00:15:57,260 --> 00:16:03,290
and nobody will be able to see them through their eyes as to what the passwords were.

194
00:16:03,590 --> 00:16:06,800
OK, so that's the reason we are using secrets.

195
00:16:07,070 --> 00:16:13,160
It is very much similar to the config map of environment variables that we have just created.

196
00:16:14,660 --> 00:16:18,200
The last thing is over here is resources.

197
00:16:18,920 --> 00:16:26,120
So how much resource a particular application should consume is something listed over here.

198
00:16:27,310 --> 00:16:31,180
So this kind of configuration is called as limited range.

199
00:16:31,390 --> 00:16:40,450
Here we specify that any workloads that we will launch as part of namespace service, they should be

200
00:16:40,450 --> 00:16:48,850
subjected to certain limits and those limits can be put on, let's say, sibiu and memory.

201
00:16:48,860 --> 00:16:53,770
So these are the two important hardware resources that we want to control.

202
00:16:54,340 --> 00:17:04,450
We do not want any component to consume an indiscriminate share of memory or CPU, so we apply certain

203
00:17:04,450 --> 00:17:04,810
limits.

204
00:17:05,240 --> 00:17:06,010
You know the thing?

205
00:17:06,280 --> 00:17:08,170
So there is this part.

206
00:17:09,970 --> 00:17:16,780
Default, so this is really the hard limit here you are saying we do not want a particular component

207
00:17:17,410 --> 00:17:19,330
on which this limited range will apply.

208
00:17:19,600 --> 00:17:28,060
It should not consume more than one CPU and it should not consume more than 768 and beat memory.

209
00:17:29,380 --> 00:17:32,350
If it is me or if it is, maybe you can check that.

210
00:17:33,960 --> 00:17:41,160
For me, the this works, and I consider it as 768 megabytes, but it can be slightly higher and they're

211
00:17:41,490 --> 00:17:46,080
not sure what am I really stands for.

212
00:17:46,500 --> 00:17:50,370
It should be close to that, but that's that's where it should be.

213
00:17:50,850 --> 00:17:51,210
OK.

214
00:17:51,340 --> 00:18:01,530
So similarly, there is another thing over here that when we are requesting these resources for a component

215
00:18:01,530 --> 00:18:10,080
in this namespace, we are providing a guidance over here that this container will should we expect

216
00:18:10,080 --> 00:18:15,120
it to occupy or consume, point to fire off the CPU.

217
00:18:15,720 --> 00:18:20,790
And we expect it to consume 256 bit of memory.

218
00:18:21,300 --> 00:18:30,990
So these are what we expect and these are what we what we are saying is limits that it should not consume

219
00:18:30,990 --> 00:18:31,700
more than that.

220
00:18:31,700 --> 00:18:39,660
So if it consumes more than that, then that particular component will be killed by Kubernetes and then

221
00:18:39,660 --> 00:18:45,570
it will be restarted again with this hope that the next time they will not consume so this this can

222
00:18:45,570 --> 00:18:51,300
be used for, let's say, in case there is a memory leak and some component disk continues to hog more

223
00:18:51,300 --> 00:18:52,020
and more memory.

224
00:18:52,530 --> 00:18:54,540
So it really becomes useful over there.

225
00:18:54,990 --> 00:19:05,340
Similarly, if there are some dead threads which are consuming CPU unnecessarily or some process is

226
00:19:05,340 --> 00:19:09,680
hung is, for whatever reason, is unnecessarily consuming CPU.

227
00:19:09,690 --> 00:19:18,360
So these limits can be useful or whether these requests are useful for Kubernetes in scheduling your

228
00:19:20,280 --> 00:19:20,880
container.

229
00:19:20,900 --> 00:19:26,670
So it knows that this container will need this much of CPU and as much of memory.

230
00:19:27,030 --> 00:19:34,050
It can look at the different nodes and what capacity they have, and accordingly, it can schedule the

231
00:19:34,530 --> 00:19:36,180
containers or parts over there.

232
00:19:36,190 --> 00:19:39,300
So we will look at what parts and containers are over here.

233
00:19:39,540 --> 00:19:45,750
We already understand where containers are, but I have told you that boards are an encapsulation over

234
00:19:45,750 --> 00:19:53,250
those containers so they can be seen as a group of containers working together for the same goal.

235
00:19:53,580 --> 00:19:59,130
OK, so the point over here is that we can allocate some resources.

236
00:19:59,160 --> 00:20:01,620
So how do we apply that to another?

237
00:20:01,920 --> 00:20:06,030
These are four different files that we can.

238
00:20:06,480 --> 00:20:11,850
We need to apply this configuration to Kubernetes cluster the way.

239
00:20:11,850 --> 00:20:17,640
The easiest way to do that is that we have some automation over here, which is secure deployed.

240
00:20:19,320 --> 00:20:29,220
We can let this script know which particular configuration file we want to apply, and we have seen

241
00:20:29,220 --> 00:20:29,910
that already.

242
00:20:30,180 --> 00:20:30,540
OK.

243
00:20:30,900 --> 00:20:33,750
This is my local system, so I'm not going to do this over here.

244
00:20:34,170 --> 00:20:36,090
Let's go to our workstation.

245
00:20:36,660 --> 00:20:41,220
So this is where we used our earlier configuration.

246
00:20:41,220 --> 00:20:42,270
If you see this, we did.

247
00:20:42,270 --> 00:20:50,730
This cubes Ctrl applied minus F and we directly applied one particular configuration, right?

248
00:20:51,160 --> 00:20:56,060
Now we want to do this for a group will have to do this for that many files.

249
00:20:56,060 --> 00:20:57,270
So we don't want to do that.

250
00:20:57,750 --> 00:20:59,310
Let's use some automation.

251
00:20:59,310 --> 00:21:04,410
We have a script with us which will help us doing this.

252
00:21:04,680 --> 00:21:09,960
We need to just point this to the directory where all the files are.

253
00:21:10,290 --> 00:21:17,420
So in this case, I've given it this zero e and B directly and only files which are there in this particular

254
00:21:17,880 --> 00:21:18,450
directly.

255
00:21:18,930 --> 00:21:20,100
They will be applied.

256
00:21:20,370 --> 00:21:23,940
I can write this apply command over here.

257
00:21:24,180 --> 00:21:25,200
That's the default.

258
00:21:26,190 --> 00:21:28,830
So even if I do not write, that will be applied.

259
00:21:29,130 --> 00:21:35,070
In case I want to delete this configuration, then I can choose this extra parameter delete over yet.

260
00:21:35,460 --> 00:21:44,010
But if I just want to apply it, I can either provide this parameter applied or I can execute it without

261
00:21:44,010 --> 00:21:47,520
typing any apply because it is the default.

262
00:21:47,520 --> 00:21:49,230
So I'm going to run the script now.

263
00:21:52,070 --> 00:21:59,540
So what this is saying is that it is executing the namespace YAML file and that namespace monitor is

264
00:21:59,540 --> 00:22:00,190
unchanged.

265
00:22:00,260 --> 00:22:07,610
So this is unchanged because we already created these namespaces and there are no differences right

266
00:22:07,610 --> 00:22:07,880
now.

267
00:22:08,360 --> 00:22:14,000
If, let's say we add something to it, then that will get a blackbird because the script or configuration

268
00:22:14,000 --> 00:22:15,230
is exactly the same.

269
00:22:15,630 --> 00:22:21,260
So Kubernetes doesn't have to change, doesn't have to do any change to the existing configuration.

270
00:22:21,980 --> 00:22:25,130
Now, similar thing happened with the config file.

271
00:22:26,090 --> 00:22:30,800
It says that it is unchanged, unchanged, unchanged because we have already created this and there

272
00:22:30,800 --> 00:22:32,540
are new changes in config map.

273
00:22:32,960 --> 00:22:39,020
If I make any changes to convict map and I execute this script, then we will see that the configuration

274
00:22:39,020 --> 00:22:39,920
got a blank.

275
00:22:40,490 --> 00:22:45,680
And something similar to what we are seeing for Secrets Map because we haven't created that yet.

276
00:22:46,160 --> 00:22:48,530
So this card applied got created.

277
00:22:49,070 --> 00:22:52,520
Similarly, limit range got created.

278
00:22:52,520 --> 00:23:01,190
So does the fact we are used to deploy script to execute this cube.

279
00:23:01,220 --> 00:23:08,100
Ctrl Apply Minus have commands on all of the files, which are there in zero EMV directly.

280
00:23:08,690 --> 00:23:11,060
So that's a small automation we have.

281
00:23:11,360 --> 00:23:16,730
There are a few more things about this automation, and we will talk about that as we move along.

282
00:23:20,000 --> 00:23:26,240
Now, let's see the outcome of this conflict map that we're obliged to be go to.

283
00:23:27,320 --> 00:23:35,760
When it is injured menu, then secrets and conflict maps is where we can see this configuration, so

284
00:23:35,760 --> 00:23:43,730
we can see this, that there is a Kassandra conflict and that got applied under namespace data.

285
00:23:43,730 --> 00:23:44,870
So which means two things.

286
00:23:45,230 --> 00:23:48,190
One is the data namespace and all these names.

287
00:23:48,200 --> 00:23:49,700
Besides that we are seeing over here.

288
00:23:50,180 --> 00:23:51,140
They got created.

289
00:23:51,500 --> 00:23:55,190
And the other thing is that this Cassandra config got created.

290
00:23:56,270 --> 00:23:58,880
So let's see what is there inside that.

291
00:23:59,950 --> 00:24:07,360
So we see this it has got this data and under data, it has got these environment variables, and so

292
00:24:07,960 --> 00:24:11,440
what should be the replication factor, what should be schemas heat instance?

293
00:24:11,950 --> 00:24:17,830
We have talked about this when we discussed Cassandra, so we are not going to discuss them again over

294
00:24:17,830 --> 00:24:18,070
here.

295
00:24:19,940 --> 00:24:24,920
The only point I'm making what we hear is that whatever the environment, variables that we're put in

296
00:24:24,920 --> 00:24:29,060
are config mapped or YAML file, they are over here.

297
00:24:29,600 --> 00:24:36,710
We can ignore some of these config maps over here, you know, veo and created those config maps.

298
00:24:36,710 --> 00:24:42,770
The ones that we have created are so did that auto generated for each namespace.

299
00:24:43,770 --> 00:24:50,640
The ones that we have created, so let's say we have created this fluid, the configuration states over

300
00:24:50,640 --> 00:24:50,910
here.

301
00:24:52,970 --> 00:25:00,470
So if you look at here under data, we have this environment variable called fluid darkened and it has

302
00:25:00,470 --> 00:25:01,790
got this entire.

303
00:25:03,410 --> 00:25:08,720
File that we have copy pasted in our configuration, so similarly from its configuration would have

304
00:25:08,720 --> 00:25:09,470
got created.

305
00:25:10,100 --> 00:25:15,680
And if we look at the service config, we did see that was there, the secret entity.

306
00:25:15,680 --> 00:25:17,560
So I think I clicked on secret.

307
00:25:17,570 --> 00:25:18,230
I'm going back.

308
00:25:19,490 --> 00:25:20,150
So for.

309
00:25:21,990 --> 00:25:26,400
There's a secret contract for service namespace if we see this.

310
00:25:26,880 --> 00:25:33,870
It has got Postgres password and Postgres user and like I said, here those are the values of those

311
00:25:33,870 --> 00:25:36,000
environment variables, password and user.

312
00:25:36,000 --> 00:25:37,410
They are not visible to us.

313
00:25:37,740 --> 00:25:41,190
So this is this how you can enforce security.

314
00:25:41,190 --> 00:25:49,290
You can keep your password and user user IDs secure by using secret config, so administrators will

315
00:25:49,290 --> 00:25:50,330
not be able to see this.

316
00:25:50,340 --> 00:25:57,750
Only the person who applied this configuration had that particular file would have access to that configuration.

317
00:25:58,800 --> 00:25:59,130
OK.

318
00:25:59,340 --> 00:26:01,830
Similarly, just this service config.

319
00:26:02,970 --> 00:26:07,830
So for services, all these environment variables that we saw they got applied or would give.

320
00:26:09,490 --> 00:26:17,200
So with that, we have actually created all these environment variables for our WHO when it is cluster.

321
00:26:17,500 --> 00:26:24,490
So now this cluster is aware of all these environment variables that we have created, all these three

322
00:26:24,490 --> 00:26:31,180
nodes which will run, they will have access to those environment variables so that one part is done.

323
00:26:32,080 --> 00:26:35,500
Now, the next part that we have to do is that we have to.

324
00:26:37,860 --> 00:26:39,870
Create workloads, so.

325
00:26:41,160 --> 00:26:45,030
When we create a component, there are actually two parts to that.

326
00:26:45,060 --> 00:26:48,540
One is the load balance of power to that.

327
00:26:48,540 --> 00:26:49,590
So if we.

328
00:26:52,110 --> 00:26:54,360
Take you to this particular figure.

329
00:26:54,720 --> 00:26:59,440
So let's say if you have to call this get for service from this web application.

330
00:27:00,270 --> 00:27:10,440
So in our Docker environment, we used Engine X to reach to any of these gateway service instances of

331
00:27:10,440 --> 00:27:10,620
this.

332
00:27:10,620 --> 00:27:11,750
Can we give us of Islam?

333
00:27:12,030 --> 00:27:13,620
Goal is to get this of history.

334
00:27:14,730 --> 00:27:20,220
Now, if we were to reach to any of these instances through this and Gen X load balancing.

335
00:27:21,230 --> 00:27:29,530
Now over here, when it is white, says this load balancer out of the box, what it provides us is called

336
00:27:29,710 --> 00:27:31,130
service was that service.

337
00:27:31,130 --> 00:27:33,620
We can see it as a reverse proxy.

338
00:27:33,620 --> 00:27:35,930
So strictly speaking, it's a reverse proxy.

339
00:27:36,170 --> 00:27:38,240
You can also operate as a load balancer.

340
00:27:38,990 --> 00:27:47,480
So it will provide us that load balancer and go when it is called set as a service and all the actual

341
00:27:47,870 --> 00:27:52,130
component instances it calls them as workloads.

342
00:27:52,700 --> 00:27:59,150
So let's say if you are talking about product service, then our product service instances, they will

343
00:27:59,150 --> 00:28:05,150
be cordless workloads in Kubernetes and if we put a load balancer somewhere in between.

344
00:28:05,150 --> 00:28:08,960
So let's say this gateway service has to call this product service.

345
00:28:09,380 --> 00:28:15,890
Then there are so many instances of product service, so it needs some sort of reverse proxy in between

346
00:28:16,280 --> 00:28:25,740
that it can call as a single point of contact and that there was proxy can decide which instance it

347
00:28:25,910 --> 00:28:29,960
needs to decide which instance to make a call.

348
00:28:30,080 --> 00:28:37,430
So this is load balancing or strictly speaking, this is the best proxy job over here, which is also

349
00:28:37,430 --> 00:28:38,840
doing load balancing.

350
00:28:39,260 --> 00:28:42,320
So this is something that Kubernetes will provide us.

351
00:28:42,320 --> 00:28:50,750
So and Kubernetes calls this part as a service, and these actual component instances it calls them

352
00:28:51,110 --> 00:28:51,740
will do.

353
00:28:52,640 --> 00:28:56,810
So let's remember that and let's go to our Kubernetes cluster.

354
00:28:57,120 --> 00:28:58,160
We see this over here.

355
00:28:59,240 --> 00:29:00,340
Kubernetes engine menu.

356
00:29:00,770 --> 00:29:04,400
There is workload part over here right now.

357
00:29:04,400 --> 00:29:05,210
It will be empty.

358
00:29:05,480 --> 00:29:12,890
There is nothing over here and then there are services in part, which is also empty.

359
00:29:13,940 --> 00:29:20,870
So now the next thing that we are going to do is we are going to create these services and we are going

360
00:29:20,870 --> 00:29:23,810
to create these component instances.

361
00:29:24,110 --> 00:29:26,990
So all of these component instances we have to create.

362
00:29:26,990 --> 00:29:33,260
So we will look at these configuration one by one, we will look at the representative configuration.

363
00:29:33,260 --> 00:29:38,960
We will not be able to go to each and every one of them, but we can definitely look at the representative

364
00:29:38,960 --> 00:29:39,650
configuration.

365
00:29:39,650 --> 00:29:43,670
So let's look at the configuration.

366
00:29:43,670 --> 00:29:45,140
Let's go to config directly.

367
00:29:46,140 --> 00:29:47,510
OK, so let's go to.

368
00:29:49,170 --> 00:29:52,980
The data directory first, what components do we have over here?

369
00:29:53,400 --> 00:29:56,430
We have Cassandra was we are behind you.

370
00:29:56,700 --> 00:29:57,350
And there it is.

371
00:29:57,370 --> 00:30:00,720
So these are the four different components over here.

372
00:30:01,290 --> 00:30:05,700
But before we go into these stateful components, let's go to some stateless components.

373
00:30:05,700 --> 00:30:09,400
So let's say let's go to this service directly here.

374
00:30:09,420 --> 00:30:10,340
What do we have here?

375
00:30:10,350 --> 00:30:13,620
We have admin service configuration authorization service gateway.

376
00:30:13,620 --> 00:30:16,490
So this inventory service, order, service and products.

377
00:30:16,500 --> 00:30:17,970
And so these configuration are that.

378
00:30:18,330 --> 00:30:19,710
Let's go to any one of them.

379
00:30:20,460 --> 00:30:22,200
Let's go to product service.

380
00:30:22,980 --> 00:30:24,090
What do we have over here?

381
00:30:24,300 --> 00:30:27,110
So there are two parts to this configuration.

382
00:30:27,120 --> 00:30:30,150
First part is service configuration.

383
00:30:30,160 --> 00:30:33,000
This is Kubernetes service that load balancer part.

384
00:30:34,200 --> 00:30:38,040
So here what we are saying is that this belongs to namespace.

385
00:30:39,120 --> 00:30:41,970
So this and this is not Kubernetes service.

386
00:30:42,000 --> 00:30:48,240
This is namespace service, how we are saying that this is Kubernetes service because we are creating

387
00:30:48,240 --> 00:30:51,270
this configuration of kind service.

388
00:30:51,270 --> 00:30:55,320
So that's why it is a service or a load balancer kind of configuration.

389
00:30:55,620 --> 00:31:01,440
It is there in the namespace service and it has the name of this configuration is product service.

390
00:31:01,980 --> 00:31:08,340
And this and this, the under spec is the specification for this service, which does it what it is

391
00:31:08,340 --> 00:31:09,030
supposed to do.

392
00:31:09,750 --> 00:31:13,730
So it does it that you are supposed to provide a Port 80.

393
00:31:14,100 --> 00:31:21,870
And this should accept all the DCP requests and whatever TCB requests are coming to port it, it should

394
00:31:21,870 --> 00:31:23,550
be directed to this target.

395
00:31:23,550 --> 00:31:25,040
Port exhilarated zero.

396
00:31:25,590 --> 00:31:29,790
So it is supposed to roll out all the requests to this target port.

397
00:31:30,750 --> 00:31:34,590
And then there is a small configuration over here, which it's dense.

398
00:31:35,130 --> 00:31:42,720
When you are routing a request, then press for that particular component instance, which is dead on

399
00:31:42,720 --> 00:31:43,620
the same host.

400
00:31:44,190 --> 00:31:50,940
If it is not available on the same host, then try some host, which is there in the same zone.

401
00:31:51,330 --> 00:31:58,770
And if the that particular if the component instance is not available, beckoned instance is not available

402
00:31:58,770 --> 00:32:02,610
in the same zone, then try to look for in the same region.

403
00:32:02,850 --> 00:32:08,280
And if it is not available in the region, also then go to anywhere, wherever it is available.

404
00:32:08,910 --> 00:32:15,630
So this is a slight amount of optimisation that we have done over here because we are running a regional

405
00:32:15,630 --> 00:32:16,500
cluster over here.

406
00:32:16,770 --> 00:32:25,200
Remember, we have the nord's of our cluster in three different zones, all these three nodes that we

407
00:32:25,200 --> 00:32:25,440
have.

408
00:32:27,300 --> 00:32:33,180
These are they're in three different zones, so that's why we put this optimization, but we can run

409
00:32:33,300 --> 00:32:36,060
without this also the above.

410
00:32:38,380 --> 00:32:41,290
Configuration is basic minimum configuration.

411
00:32:42,170 --> 00:32:45,190
OK, so that is so this configuration, who entered the service.

412
00:32:45,940 --> 00:32:48,370
Now let's talk about the workload part.

413
00:32:49,660 --> 00:32:54,010
And yet we are providing the workload definition.

414
00:32:54,460 --> 00:33:00,760
You're saying that this workload is off type deployment or deployment as a special kind of workload.

415
00:33:01,450 --> 00:33:04,360
It creates parts for now.

416
00:33:04,360 --> 00:33:06,790
Let's just see parts as containers.

417
00:33:07,180 --> 00:33:12,220
And then I will tell you that part is not just a container, it is a set of container.

418
00:33:13,600 --> 00:33:19,180
OK, so in the absence of any definition for a board, let's just look at part as a container.

419
00:33:19,810 --> 00:33:28,420
So the deployment kind what it tells that you should start a certain set of boards to fulfill a request

420
00:33:28,810 --> 00:33:30,460
and two days.

421
00:33:30,670 --> 00:33:37,150
This replica configuration, we can tell how many boards we want to create or how many containers we

422
00:33:37,150 --> 00:33:37,810
want to create.

423
00:33:37,930 --> 00:33:46,090
If I say this as this will, when this configuration will be applied, this will create 100 such instances,

424
00:33:46,240 --> 00:33:53,140
100 parts or 100 containers of this of some of its core products over.

425
00:33:53,160 --> 00:33:58,110
So this these boards are they have a name or products of his parts.

426
00:33:58,800 --> 00:34:00,010
Any name would have been given.

427
00:34:00,670 --> 00:34:06,640
So under this theme, this deployment will be created and because it is a deployment, deployment means

428
00:34:06,940 --> 00:34:09,820
a set of boards, generally stateless boards.

429
00:34:10,210 --> 00:34:18,460
It is not used for stateful components, so deployment is a set of stateless parts and services are

430
00:34:18,460 --> 00:34:18,910
stateless.

431
00:34:18,910 --> 00:34:23,080
So we can say that we want 100 replicas of that.

432
00:34:23,410 --> 00:34:28,980
What we have done over here is we have just said just create one replica over here.

433
00:34:28,990 --> 00:34:31,480
I could have said I could have chosen any other number.

434
00:34:32,080 --> 00:34:33,070
It is good enough.

435
00:34:33,430 --> 00:34:39,700
I have chosen a number that I want to start with and we can go to higher number of instances and we

436
00:34:39,700 --> 00:34:43,150
will do so by the virtue of auto scaling.

437
00:34:43,160 --> 00:34:45,370
So we are not coding it over here.

438
00:34:45,520 --> 00:34:50,050
We can hardcoded to whatever number we want, but we are not doing that over here.

439
00:34:51,280 --> 00:34:54,460
We are starting with some minimum number of instances.

440
00:34:54,790 --> 00:34:57,820
And then we will scale it up, according to the law.

441
00:34:58,960 --> 00:35:06,160
So we will see this in some case, we will see we will modify to, let's say, three and we will see

442
00:35:06,160 --> 00:35:12,070
that we will get those number of instances when we apply this configuration.

443
00:35:12,550 --> 00:35:13,330
Then let's see.

444
00:35:13,360 --> 00:35:14,290
What do we have next?

445
00:35:15,220 --> 00:35:21,190
Next, we have is a strategy when we are going to update this.

446
00:35:21,370 --> 00:35:22,900
What sort of update it should be.

447
00:35:23,110 --> 00:35:30,880
So we are saying when we are building this component with a newer version of the Docker images, then

448
00:35:30,880 --> 00:35:37,870
you should follow rolling update strategy, which means that the removal of one old version instance

449
00:35:38,200 --> 00:35:45,940
add new version instance and then repeat that process till you have all removed all the old instances

450
00:35:45,940 --> 00:35:50,020
and you are left with only instances with newer version.

451
00:35:50,020 --> 00:35:57,790
So that's for Kubernetes agreed, and we will see that how that works, and all these things are important

452
00:35:57,790 --> 00:36:02,970
because they ultimately become important during your operation.

453
00:36:02,980 --> 00:36:09,130
So these are Kubernetes features that are being provided to us and are important for any architect,

454
00:36:09,130 --> 00:36:15,640
because if you are architecting a system, you will have to ensure that how you are, how this system

455
00:36:15,640 --> 00:36:17,770
will be operated in the production.

456
00:36:18,340 --> 00:36:24,100
So although these operations will be carried out by the administrator team, but architects need to

457
00:36:24,520 --> 00:36:32,500
know what kind of work Operation Steam is doing in the operations because that is how you will architect

458
00:36:32,500 --> 00:36:33,330
your application.

459
00:36:33,340 --> 00:36:41,260
You will need to know that if Operation Steam is following rolling update strategy, that means that

460
00:36:41,260 --> 00:36:46,930
at any given point in time, you can have two versions running for same components.

461
00:36:46,930 --> 00:36:48,430
Or, let's say, here it is, product service.

462
00:36:48,760 --> 00:36:56,170
It is possible that two different versions would be running at the same time when we are doing this

463
00:36:56,170 --> 00:36:56,920
rolling upgrade.

464
00:36:56,930 --> 00:37:03,460
So let's say if we have 1000 instances and we are doing this rolling update, this update is not going

465
00:37:03,460 --> 00:37:04,120
to be quick.

466
00:37:04,330 --> 00:37:11,530
So for a long time, we will be having two different versions at the same time serving our customer

467
00:37:11,530 --> 00:37:11,980
requests.

468
00:37:11,980 --> 00:37:16,150
So when we detect our application, we need to be aware of that fact.

469
00:37:16,630 --> 00:37:22,330
So that is the reason these things are very important for architects as well, and they need to take

470
00:37:22,330 --> 00:37:24,730
care of that right from the beginning.

471
00:37:26,080 --> 00:37:30,910
OK, so then how does Kubernetes create a particular container?

472
00:37:31,330 --> 00:37:36,550
That is the portion that we are going to see over here and that is under this part spec.

473
00:37:38,040 --> 00:37:40,890
Let's skip init containers for a moment.

474
00:37:41,190 --> 00:37:45,300
Let's go to containers first under containers.

475
00:37:45,840 --> 00:37:53,540
We are providing this information that Kubernetes is supposed to create a container with a name products

476
00:37:53,540 --> 00:37:55,380
service container as part of this part.

477
00:37:55,390 --> 00:37:59,370
So this part will have this container product service container.

478
00:38:00,120 --> 00:38:07,560
And what image it should have that is being given by this particular configuration that up here, we

479
00:38:07,560 --> 00:38:13,110
have certain variables over here that we will need to modify.

480
00:38:13,110 --> 00:38:14,730
So we can't execute this.

481
00:38:15,090 --> 00:38:17,850
We can't apply this product.

482
00:38:17,850 --> 00:38:26,040
So this start Yamal as it is because we haven't put something, we haven't substituted the value of

483
00:38:26,760 --> 00:38:34,110
this image registry port and we have just bought this as a placeholder over here because this image

484
00:38:34,110 --> 00:38:38,460
registry part can change depending upon what environment you are working on.

485
00:38:38,850 --> 00:38:44,020
So we are going to modify this of such variables.

486
00:38:44,040 --> 00:38:49,410
We are going to substitute such variables to our automation before we apply these files.

487
00:38:50,010 --> 00:38:58,290
This kind of thing we did not do in our namespace is in our config map spec because there we did not

488
00:38:58,290 --> 00:38:59,550
need any Docker image.

489
00:38:59,970 --> 00:39:06,660
But here we need Docker image and we want this the ability to change the port and without affecting

490
00:39:06,660 --> 00:39:07,730
our configuration file.

491
00:39:07,740 --> 00:39:12,450
So we have put a placeholder variable over here, which we will substitute later.

492
00:39:12,960 --> 00:39:17,850
So here we cannot directly say cubical apply minus of product.

493
00:39:17,850 --> 00:39:22,050
So this start Yemen without substituting the actual value.

494
00:39:22,050 --> 00:39:23,460
And what do we want to put over here?

495
00:39:23,790 --> 00:39:31,770
We want to put something like this over here, which tells this particular configuration what is the

496
00:39:32,430 --> 00:39:35,190
actual part of our

497
00:39:38,610 --> 00:39:44,070
part of the image from where we can get the vendor school in?

498
00:39:44,070 --> 00:39:45,820
It can actually get the registry.

499
00:39:45,840 --> 00:39:50,730
So this is what we want to port for image registry port.

500
00:39:51,450 --> 00:40:00,000
So this is the the complete part of that image in Google Container Registry, and we also want to substitute

501
00:40:00,300 --> 00:40:02,360
this Revision ID with Lindsey Vonn.

502
00:40:03,180 --> 00:40:10,230
We can all support latest because we haven't given any versions to the core base that we have, so we

503
00:40:10,230 --> 00:40:12,270
can use latest polls over here.

504
00:40:12,270 --> 00:40:13,260
So that belonged to Luke.

505
00:40:13,740 --> 00:40:19,230
So let's just undo this and get back to what we had initially with yet.

506
00:40:19,830 --> 00:40:27,540
So this is how we have this is how the configuration file initially is at runtime when we are executing

507
00:40:27,540 --> 00:40:34,890
this script, that script will read this this particular variable as an environment variable that we

508
00:40:34,890 --> 00:40:42,060
will supply to our deployment script and it will substitute this environment variable over here and

509
00:40:42,060 --> 00:40:44,280
then it will apply this configuration.

510
00:40:45,330 --> 00:40:52,740
OK, so that was about these environment variables that need to be substituted over here.

511
00:40:54,490 --> 00:40:59,620
So let's get back to our container definition, so for this container, we're told what is the name?

512
00:41:00,190 --> 00:41:04,180
Where to get the image from any arguments that we need to supply.

513
00:41:04,660 --> 00:41:12,340
And we are saying that if the image, every time we are recreating this container, it should check

514
00:41:13,480 --> 00:41:17,080
whether there is a new image available in the container registry.

515
00:41:17,590 --> 00:41:20,530
So we have said this image put policy as always.

516
00:41:20,920 --> 00:41:25,270
Then we are saying that these containers should run at port eight zero zero.

517
00:41:25,840 --> 00:41:32,320
Then we are saying that this should mount create volume mounts for defiance.

518
00:41:32,350 --> 00:41:39,250
Now, if you remember, we created volumes in Docker, so it has exactly the same concept over yet.

519
00:41:39,880 --> 00:41:46,740
We need to keep these files in certain volumes, which are outside of these parts, because if these

520
00:41:46,750 --> 00:41:50,080
boards die, we will lose these log files.

521
00:41:50,080 --> 00:41:58,060
So these volumes, they give us a way of specifying that certain locations within our containers in

522
00:41:58,060 --> 00:42:06,010
certain files, they should be actually created on volume ones and not inside the container.

523
00:42:06,010 --> 00:42:12,880
So exactly the same component, same concept that we saw in Docker containers.

524
00:42:12,880 --> 00:42:19,810
So there's nothing new over here, except the fact that we will need to specify over here where that

525
00:42:19,810 --> 00:42:21,970
volume on disk created in this case.

526
00:42:22,120 --> 00:42:28,570
We have said that this volume mount should be created on this particular node itself, so this is a

527
00:42:28,570 --> 00:42:30,940
way of keeping it as a way of specifying this.

528
00:42:30,940 --> 00:42:35,080
Yet I have said that I do not want this to be permanent space.

529
00:42:35,950 --> 00:42:42,760
So here it was not critical for me to store these documents, but for in case of database, we will

530
00:42:42,760 --> 00:42:51,640
see this will have to provide a more robust configuration for these volumes to these volumes are related

531
00:42:51,640 --> 00:43:00,580
to these volumes and we will see this a better way of specifying these volumes in case of stateful components.

532
00:43:00,580 --> 00:43:05,530
So that that's one critical difference you can see from stateful components between stateful components

533
00:43:06,100 --> 00:43:13,090
and stateless components, which we are defining as part of deployment kind of communities.

534
00:43:13,450 --> 00:43:13,720
OK.

535
00:43:14,620 --> 00:43:17,020
So that's the web.

536
00:43:17,110 --> 00:43:21,580
That's pretty much all the basics for creating a container.

537
00:43:21,610 --> 00:43:23,830
Now there are certain advanced things over here.

538
00:43:24,370 --> 00:43:30,940
How does Kubernetes know that the container, which it has started, is actually healthy?

539
00:43:31,270 --> 00:43:37,960
So for that, we have provided this liveness pro configuration or disk configuration will do this after

540
00:43:37,960 --> 00:43:39,150
an initial delay.

541
00:43:39,160 --> 00:43:45,460
So once it starts the container, it will wait for 180 seconds and then it will send an ADP request

542
00:43:45,940 --> 00:43:50,950
to the spot status on the Sport Edge zero eight zero.

543
00:43:51,580 --> 00:44:00,220
So this status is it will send a request to this container on this so and so astutely requested to install

544
00:44:00,220 --> 00:44:01,300
part in port.

545
00:44:01,690 --> 00:44:09,460
And if it gets 200 response or any response, which is less than 400 or 300, which doesn't mean any

546
00:44:09,460 --> 00:44:09,730
error.

547
00:44:10,000 --> 00:44:12,400
So let's say 200 is okay.

548
00:44:12,410 --> 00:44:13,750
Two hundred one is created.

549
00:44:13,750 --> 00:44:21,430
So if it gets its kind of responses, it will understand that the container is live and it is working

550
00:44:21,430 --> 00:44:26,560
fine if it is not giving any responsibility after three tries.

551
00:44:26,590 --> 00:44:28,870
We can configure that I configured that.

552
00:44:29,260 --> 00:44:35,440
I'm using the number of reiterates that it will do as the default, which is three.

553
00:44:35,710 --> 00:44:37,030
So first, try three times.

554
00:44:37,300 --> 00:44:44,650
And if this container is not alive, if it is not giving good responses and it will kill the container

555
00:44:44,650 --> 00:44:46,420
and it will try to recreate it.

556
00:44:46,690 --> 00:44:51,010
So that's a brilliant feature that Kubernetes is providing us over here.

557
00:44:51,430 --> 00:44:53,270
Similarly, we have this readiness group.

558
00:44:53,650 --> 00:44:58,150
It is similar to Liveness, Brooke, but it has got a different function here.

559
00:44:58,180 --> 00:45:08,890
We will send in request to the same and import, but we are starting this right after 60 seconds because

560
00:45:08,890 --> 00:45:14,950
it is possible that just after 60 seconds are within 60 seconds, this would have come up and we do

561
00:45:14,950 --> 00:45:20,710
not want to wait till one or two seconds to determine whether it is alive or not.

562
00:45:21,010 --> 00:45:26,500
So in case this readiness probe fails, this is not going to kill the container.

563
00:45:26,620 --> 00:45:28,200
They're not going to remove the container.

564
00:45:28,210 --> 00:45:38,110
All it means is that services should not direct any request to this container because it is not ready.

565
00:45:38,620 --> 00:45:45,490
Once this container gets a favorable response, it will change the status to ready, and after that,

566
00:45:45,490 --> 00:45:49,640
only a service can send a request to this particular container.

567
00:45:49,780 --> 00:45:52,560
So this is something that we have defined over here.

568
00:45:52,570 --> 00:45:53,070
This is this.

569
00:45:53,130 --> 00:46:00,660
Service, which is supposed to redirect only requests to these containers that we are defining as part

570
00:46:00,660 --> 00:46:01,950
of broad definition.

571
00:46:03,450 --> 00:46:10,260
So this is when a readiness probe is important, whether a service should allow the request to that

572
00:46:10,260 --> 00:46:12,050
or not is decided by this group.

573
00:46:12,570 --> 00:46:18,900
Whether a health service should kill this container is decided by liveness groups who will have to put

574
00:46:19,320 --> 00:46:22,200
both of these groups look at.

575
00:46:22,200 --> 00:46:23,550
Both of them are important for us.

576
00:46:24,300 --> 00:46:28,660
Then the last thing that we have put over here is topological spread constraints.

577
00:46:28,660 --> 00:46:38,280
So if let's have this particular and as part of this broad definition, if we create three boards and

578
00:46:38,280 --> 00:46:46,020
we have three zones, then we want these three parts to be spread on and spread over these three zones.

579
00:46:46,440 --> 00:46:53,220
So what we have done over here because we have created three different hosts for our cluster.

580
00:46:53,310 --> 00:47:00,630
If you see this, this particular cluster has got if I show you this in compute engine.

581
00:47:03,770 --> 00:47:10,580
We've got three different hosts over here, so they are in three different zone, the Zone C, A and

582
00:47:10,580 --> 00:47:16,760
B, so we want these product service instances where they were being created.

583
00:47:17,120 --> 00:47:18,810
They should be evenly spread.

584
00:47:19,340 --> 00:47:23,480
So we have provided these topological constraints over here.

585
00:47:23,480 --> 00:47:31,580
So competitors can't do a job of spreading evenly, spreading these product service boards that we are

586
00:47:31,580 --> 00:47:32,500
creating or looking at.

587
00:47:33,560 --> 00:47:42,050
So what we saw over here is that we created, we thought, Kubernetes how to create a container, so

588
00:47:42,350 --> 00:47:47,570
asked her to create only one container as part of this for definition.

589
00:47:47,570 --> 00:47:55,070
So in this case, this part and one container inside that so here part is as good as one container because

590
00:47:55,070 --> 00:48:01,700
it contains only one container inside this and that sort of Berkshire container part should really have

591
00:48:01,700 --> 00:48:09,140
only one container inside that, but there are cases where we will need more containers inside apart.

592
00:48:10,700 --> 00:48:15,860
And I'll tell you when we need that, let's go.

593
00:48:15,890 --> 00:48:19,640
Let's take the case of you a web application.

594
00:48:20,390 --> 00:48:26,690
And if you remember in that application, I told you there are two parts one of the dynamic request

595
00:48:26,690 --> 00:48:31,460
part and the other one is static request part.

596
00:48:31,820 --> 00:48:34,670
So I told you that static request part.

597
00:48:34,940 --> 00:48:42,350
We want to handle two Engine X, which is a reverse proxy and dynamic request Part B one to handle two

598
00:48:42,620 --> 00:48:44,300
Python Django applications.

599
00:48:44,300 --> 00:48:51,470
So for our web application, we actually need two containers working together in those two containers

600
00:48:51,470 --> 00:48:55,040
working together form side one application.

601
00:48:55,040 --> 00:49:05,510
So here when we are creating a web application bar over here, then we are saying that aspart of containers

602
00:49:05,750 --> 00:49:13,670
we are we are providing you two containers, one for static content and is the definition for that or

603
00:49:14,240 --> 00:49:16,400
that container we are to get image from.

604
00:49:16,670 --> 00:49:17,660
What are the ports?

605
00:49:17,720 --> 00:49:19,340
What are the environment variables?

606
00:49:19,610 --> 00:49:23,750
We can, by the way, provide some environment variables override them over here.

607
00:49:24,230 --> 00:49:32,030
So very much in Docker type like we can override some of the environment variables in compose, file

608
00:49:32,030 --> 00:49:33,050
docker compose file.

609
00:49:33,800 --> 00:49:39,200
Here we can do similar stuff in Kubernetes Yamal configuration files.

610
00:49:39,740 --> 00:49:46,850
So this is one container definition as part of this part, and this is the second container as part

611
00:49:46,850 --> 00:49:52,400
of this, this particular web application port.

612
00:49:52,400 --> 00:49:58,400
So this web application part has got two containers running in it, and that's where it makes sense

613
00:49:58,400 --> 00:50:06,230
to have ports running in, not to ports, to containers running in the same ports.

614
00:50:06,240 --> 00:50:10,490
We create three parts of our web application.

615
00:50:10,500 --> 00:50:18,890
Then these three ports will have six containers three for responding to static requests and three port

616
00:50:19,220 --> 00:50:22,670
T containers with us wanting to dynamic request.

617
00:50:23,000 --> 00:50:27,470
So that's give that should give you an idea of what a board is.

618
00:50:27,470 --> 00:50:29,150
Port otherwise is a container.

619
00:50:29,630 --> 00:50:33,990
But we noticed that a port can be a collection of containers as well.

620
00:50:34,040 --> 00:50:39,050
So now hopefully you understand what a part is, OK?

621
00:50:39,230 --> 00:50:48,140
And one more thing that within a port, any container can refer to the other container as local ports,

622
00:50:48,140 --> 00:50:51,770
so that that's another set of information whenever you need that.

623
00:50:52,220 --> 00:50:52,520
OK.

624
00:50:52,910 --> 00:51:01,190
So without making it more complicated, I have explained to you how we have created product service,

625
00:51:01,190 --> 00:51:11,030
port and product service to I told you how to create product service service, which is basically the

626
00:51:11,030 --> 00:51:18,200
reverse proxy or load balancing for the service and a deployment which is actually a set of cards that

627
00:51:18,200 --> 00:51:20,730
we can get how many ports we want to create.

628
00:51:20,750 --> 00:51:24,110
We can specify here how many ports I want.

629
00:51:25,550 --> 00:51:34,310
So that's the way to create component instances and services in Kubernetes.

630
00:51:34,850 --> 00:51:38,660
So that is the kind of configuration we are provided in.

631
00:51:38,660 --> 00:51:42,530
All, the configuration went over here that absolutely similar.

632
00:51:43,400 --> 00:51:48,940
So also, this configuration files are simple, even monitoring part the same.

633
00:51:48,950 --> 00:51:50,450
But let's first go to data.

634
00:51:50,750 --> 00:51:54,290
Let's just understand how this is different from our services part.

635
00:51:54,920 --> 00:52:00,620
So much of the configuration is exactly the same here, so this part is exactly the same.

636
00:52:00,950 --> 00:52:02,780
Now let's go to the work part.

637
00:52:07,370 --> 00:52:12,860
This is the only change over here, not the only change, but the fundamental change that instead of

638
00:52:12,860 --> 00:52:20,000
defining a deployment over here, we are defining a state full set for deployment was a set of parts

639
00:52:20,000 --> 00:52:21,740
and these parts should be stateless.

640
00:52:22,220 --> 00:52:29,060
But if we want to create a state for parts which will be the case in case of any database, then instead

641
00:52:29,060 --> 00:52:35,840
of deployment, we will create stateful set and this state will set the way it is and fullest that when

642
00:52:35,840 --> 00:52:42,620
we create volumes for it, it will create a separate volume for each of the board.

643
00:52:43,470 --> 00:52:48,380
So and that is important for the database instances relative in this case.

644
00:52:48,800 --> 00:52:50,480
We have three replicas over here.

645
00:52:50,750 --> 00:52:53,000
All of them will store their own data.

646
00:52:53,510 --> 00:53:00,560
So this this data should be separate for all these boards so they can't work on the same data.

647
00:53:01,580 --> 00:53:05,290
This is a distributed database, and each instance will have its own set of data.

648
00:53:05,300 --> 00:53:13,160
So that's where this stateful set becomes important and it will create three separate replicas.

649
00:53:13,160 --> 00:53:17,270
But they will all be stateful, meaning they'll have their own identities.

650
00:53:17,720 --> 00:53:24,590
So we will see that it provides a stable identity to each Kassandra instance that it will create.

651
00:53:25,130 --> 00:53:29,510
So it will name them as Cassandra zero Cassandra one Cassandra two.

652
00:53:29,510 --> 00:53:33,950
Like that, and we can refer to these names.

653
00:53:34,310 --> 00:53:42,890
But in case of stateless instances, it won't give any such conventional naming to the boards.

654
00:53:43,370 --> 00:53:49,340
It can give any name to that, and we will see that we are supposed to routing the request to the service.

655
00:53:49,340 --> 00:53:51,320
And so this can lead to any instance.

656
00:53:51,920 --> 00:53:53,840
But in case of step, for instance.

657
00:53:53,840 --> 00:53:56,000
So this should not lead to any instance.

658
00:53:56,360 --> 00:54:03,230
We want the capability of the ability to be able to reach to a specific instance that is something which

659
00:54:03,230 --> 00:54:05,300
is important for one set.

660
00:54:05,630 --> 00:54:07,850
So those are the kind of differences that are there.

661
00:54:08,150 --> 00:54:15,140
So just remember this that if you are to create a state full application, then you need stateful set.

662
00:54:15,710 --> 00:54:20,750
So replicas help you by creating that many replicas over here.

663
00:54:20,750 --> 00:54:27,780
So we want 100 instances of Cassandra, then we can change this to 100.

664
00:54:28,370 --> 00:54:36,440
So that's the power of Kubernetes that you can create any number of instances with just a simple configuration

665
00:54:36,440 --> 00:54:37,910
in an automated fashion.

666
00:54:38,900 --> 00:54:43,640
So how you create containers, what we get there is absolutely no difference.

667
00:54:43,970 --> 00:54:47,270
We also have liveness, probably here.

668
00:54:47,990 --> 00:54:49,880
We have a really nice global widget.

669
00:54:50,180 --> 00:54:52,430
So there is absolutely no difference over here.

670
00:54:52,760 --> 00:54:57,980
We can provide environment to this, to this envy from.

671
00:54:58,400 --> 00:55:05,270
So I think I forgot to tell you this in services component that if you want access to any environment

672
00:55:05,270 --> 00:55:12,680
variables that we have specified in our conflict map, then this is the way to do that.

673
00:55:13,070 --> 00:55:19,130
And if you want to directly define any environment variables over here, then we can do so.

674
00:55:19,700 --> 00:55:26,270
So all the other things are here happening in pretty much the same way we did in Docker compose the

675
00:55:26,270 --> 00:55:27,920
way we created containers over there.

676
00:55:28,490 --> 00:55:30,260
That's what we have done over here.

677
00:55:30,590 --> 00:55:36,620
In fact, I have created these configuration files by looking at the Docker compose file only.

678
00:55:36,920 --> 00:55:39,470
So that is where I have derived this configuration.

679
00:55:39,710 --> 00:55:40,100
Yes.

680
00:55:40,520 --> 00:55:45,920
You'll have to adjust it in Kubernetes format, but that's something you will have to do.

681
00:55:46,430 --> 00:55:46,760
OK.

682
00:55:47,090 --> 00:55:57,080
So these volume claim templates here we are saying that create a disk space for each node.

683
00:55:57,470 --> 00:56:05,240
Offsite is one GB, which can be used by our Kassandra container.

684
00:56:05,240 --> 00:56:06,140
So we are creating.

685
00:56:06,140 --> 00:56:12,620
We are giving a template for creating volumes over here and the volumes that this template will create

686
00:56:13,160 --> 00:56:16,760
will be used by these volumes.

687
00:56:17,210 --> 00:56:26,150
So anything that can handle containers is writing in Lib Kassandra directory will go to this particular

688
00:56:26,150 --> 00:56:34,870
volume mount, and this volume mount is linked to the volumes that will be created by this volume clip

689
00:56:34,880 --> 00:56:35,360
template.

690
00:56:35,370 --> 00:56:37,370
So that's the automation we have put over here.

691
00:56:38,150 --> 00:56:45,260
So that's pretty much the configuration for all of the containers over here.

692
00:56:45,470 --> 00:56:46,820
That is slight difference over here.

693
00:56:46,910 --> 00:56:48,770
Let it progress.

694
00:56:49,340 --> 00:56:51,380
We have not created any stateful set.

695
00:56:51,380 --> 00:56:58,900
We have created a board over here because we do not need four or five six instances of post-crash.

696
00:56:59,060 --> 00:57:03,050
One instance is good enough, so we have directly created part over here.

697
00:57:03,320 --> 00:57:06,260
Then the rest of the definition is exactly the same.

698
00:57:07,390 --> 00:57:07,690
OK.

699
00:57:07,970 --> 00:57:11,290
You can take a look at a detailed look at these components for redress on top.

700
00:57:11,770 --> 00:57:16,900
We have created the continent in the same way we have just created any part.

701
00:57:17,320 --> 00:57:21,400
We have not created any volumes over here because everything will be in cash.

702
00:57:21,760 --> 00:57:30,220
If we lose this, we should be able to recreate or repopulate this cash, although we have said that

703
00:57:30,220 --> 00:57:31,300
we want to persist.

704
00:57:31,450 --> 00:57:34,700
But in this particular configuration, we have not done that.

705
00:57:34,750 --> 00:57:38,230
Maybe later on, I'll do that.

706
00:57:38,980 --> 00:57:43,870
So but for Cassandra and progress, I have created separate volumes.

707
00:57:44,110 --> 00:57:47,950
So that will give you an idea if you want to do it for readers and every time you.

708
00:57:48,880 --> 00:57:50,710
That's the way to go about it.

709
00:57:51,910 --> 00:57:59,980
Similarly, we have created parts for that influence who indeed we have created a demons and demons

710
00:57:59,980 --> 00:58:03,720
that is slightly different from other things.

711
00:58:03,730 --> 00:58:04,630
I'll come to demons.

712
00:58:05,290 --> 00:58:09,640
First, let me tell you that let's go to something else.

713
00:58:10,090 --> 00:58:10,990
Let's say Yegor.

714
00:58:11,710 --> 00:58:13,750
So Yegor had three components.

715
00:58:14,230 --> 00:58:15,610
So you got agent?

716
00:58:16,150 --> 00:58:18,700
Yeah, agent will be called by our services.

717
00:58:18,700 --> 00:58:22,000
So we have created service load balancer for that.

718
00:58:22,570 --> 00:58:26,980
Then we have created a demand set for Yegor agent.

719
00:58:27,220 --> 00:58:34,800
And I'll tell you what, why we have created a demand demon set for it and why we have not created a

720
00:58:34,840 --> 00:58:37,810
deployment like we have created for services.

721
00:58:38,530 --> 00:58:42,760
So much of the definition is seems so far Yegor connected.

722
00:58:43,630 --> 00:58:51,280
This is where all your agents were dumped, dead logs or whatever they says that they have collected.

723
00:58:51,790 --> 00:58:58,390
And for that, we have created a service and then we have created a bark which will handle the workload

724
00:58:58,390 --> 00:58:58,810
part.

725
00:58:59,210 --> 00:59:02,440
So this will be created is pretty much the same.

726
00:59:02,800 --> 00:59:06,880
And then we have Yegor query, which just takes care of the UI.

727
00:59:07,150 --> 00:59:08,800
So does the service part of that?

728
00:59:09,130 --> 00:59:15,090
And then the this is workload part of Yegor query.

729
00:59:15,520 --> 00:59:21,040
So for that, we have just created a single park and we have to create multiple park multiple replicas

730
00:59:21,040 --> 00:59:21,400
of that.

731
00:59:21,400 --> 00:59:23,080
Then we can use deployment.

732
00:59:24,160 --> 00:59:27,190
Now we have created a demon sec.

733
00:59:27,440 --> 00:59:29,590
So think of this as deployment.

734
00:59:30,010 --> 00:59:39,430
It's just that this demon said what it will do is it will ensure that we have only one replica on each

735
00:59:39,430 --> 00:59:39,790
node.

736
00:59:40,240 --> 00:59:43,900
So all these different nodes that are there three nodes.

737
00:59:44,440 --> 00:59:51,310
So what this will make sure is that it will create each one is going to be created.

738
00:59:51,310 --> 00:59:58,700
Yeager isn't as a demon hack, so one agent will be available on each note fluently also.

739
00:59:58,720 --> 00:59:59,530
That is the case.

740
59:59.950 --> 1:00:07.060
We will have that demon's head will make available one fluidly running on each node.

741
1:00:07.390 --> 1:00:08.650
Now all the parts.

742
1:00:08.650 --> 1:00:13.060
So let's say we are running 10 different parts on this particular node.

743
1:00:13.420 --> 1:00:14.890
They need only one agent.

744
1:00:15.160 --> 1:00:19.390
We don't need to create the agent in each part.

745
1:00:19.390 --> 1:00:20.950
So we have 10 boards over here.

746
1:00:21.280 --> 1:00:24.850
We don't need to put agent containers within those boards.

747
1:00:25.270 --> 1:00:26.630
That will be a duplication.

748
1:00:26.650 --> 1:00:31.270
We just need them at the node level or the host level.

749
1:00:31.570 --> 1:00:35.140
So that is bit demon's head becomes useful.

750
1:00:35.380 --> 1:00:40.420
It creates boards and at the node level.

751
1:00:40.420 --> 1:00:48.540
So one part for each and that is what we want from our Yego region and flew in depart.

752
1:00:48.550 --> 1:00:52.600
So that's something that Kubernetes provides us and we have used it over here.

753
1:00:53.860 --> 1:00:59.140
So this is how the entire configuration is being already looked at environment.

754
1:00:59.410 --> 1:01:03.220
I looked at data monitor service until we looked at.

755
1:01:03.220 --> 1:01:04.690
There's nothing special about it.

756
1:01:05.650 --> 1:01:09.280
Then the last one is scalar, no scalar.

757
1:01:09.550 --> 1:01:13.240
We have provider configuration for auto scaling.

758
1:01:13.600 --> 1:01:14.560
So let's look at this.

759
1:01:14.950 --> 1:01:21.520
So this is scalar four, or we should really call.

760
1:01:21.520 --> 1:01:24.400
This has horizontal part or auto scalar.

761
1:01:25.000 --> 1:01:30.520
So because it will horizontally scale a service and this is something that we need for our stateless

762
1:01:30.520 --> 1:01:32.630
components for full component.

763
1:01:32.650 --> 1:01:33.630
We have Cassandra.

764
1:01:34.030 --> 1:01:37.960
We have created a fixed number of instances.

765
1:01:38.440 --> 1:01:46.660
If we have to increase them, we do not want that to be increased as part of auto scaling because we

766
1:01:46.660 --> 1:01:53.530
discussed this during Cassandra setup that we can't adjust the number of containers dynamically so we

767
1:01:53.530 --> 1:01:54.760
can do that dynamically.

768
1:01:54.760 --> 1:02:00.010
But it can be a very dynamic decision that after five minutes, we weren't five in.

769
1:02:00.250 --> 1:02:06.370
Now, if the next 10 minutes we want, then it can be that kind of decision with stateful components.

770
1:02:06.770 --> 1:02:08.750
He can certainly change them once.

771
1:02:09.260 --> 1:02:15.830
Right, and if that is going to be the lower profile for some time because it takes time for database

772
1:02:15.830 --> 1:02:21.650
to rebalance data before that, we do not want to disturb the configuration of our databases.

773
1:02:21.920 --> 1:02:26.390
So we do not use auto scaling for them so that we will do manual skilling.

774
1:02:26.390 --> 1:02:30.110
And I'll show you that how to do that when it is will help us in doing that.

775
1:02:30.380 --> 1:02:31.640
But if you want to set up.

776
1:02:33.000 --> 1:02:41.730
Auto scaling for stateless components that can be done by Cuban by providing this kind horizontal bar.

777
1:02:41.770 --> 1:02:50.160
Auto can here, what we have said is that it should be attached to a of kind deployment.

778
1:02:50.550 --> 1:02:53.700
And the name of that deployment is kit vessel his parts.

779
1:02:54.060 --> 1:03:00.640
It is saying that at any given time, this auto scales should maintain at least one replica, and if

780
1:03:00.640 --> 1:03:05.340
load increases, then it should go up to three replicas.

781
1:03:05.850 --> 1:03:08.310
And how does it know that the Lord has increased?

782
1:03:08.730 --> 1:03:12.810
The hefty CPU utilization increases above 50 percent.

783
1:03:13.260 --> 1:03:19.260
Then there will be calls that the Lord is going up and the audio's killer will act accordingly.

784
1:03:19.260 --> 1:03:22.290
It should increase the number of nodes.

785
1:03:22.530 --> 1:03:29.310
And according to this definition, if the Lord is wearing down, then it can even reduce the number

786
1:03:29.310 --> 1:03:30.030
of instances.

787
1:03:30.330 --> 1:03:34.170
But it won't go below many replicas when it is going up.

788
1:03:34.350 --> 1:03:39.420
It won't go above Max, so we can provide any number of instances over here.

789
1:03:39.420 --> 1:03:46.920
We can say 10 over here and we can even see 3000 if you have that much of hardware and that many requests

790
1:03:46.920 --> 1:03:50.880
that you are planning to cater in accordingly, you can adjust these parameters.

791
1:03:51.690 --> 1:03:53.400
Direct CPU utilization.

792
1:03:53.640 --> 1:03:55.270
You wouldn't generally put 50.

793
1:03:55.320 --> 1:04:02.040
Maybe you will put something like 70, but I put this as 50 so that I can show you this in the demonstration

794
1:04:02.040 --> 1:04:06.840
that when we put load and if you go over 50, then the auto scaling will happen.

795
1:04:07.680 --> 1:04:10.460
OK, so that's auto scaling part.

796
1:04:10.470 --> 1:04:17.130
We have created this auto scanner for all our stateless services that we want to auto skip, and that

797
1:04:17.130 --> 1:04:19.770
also includes heart valve application.

798
1:04:20.700 --> 1:04:26.790
OK, so that is the configuration part now.

799
1:04:26.970 --> 1:04:37.920
Next, what we will do is we will look into how we can deploy these components, so we have created

800
1:04:37.920 --> 1:04:38.460
a cluster.

801
1:04:39.600 --> 1:04:47.340
We have applauded all the images to our Docker file, sorry, Docker registry.

802
1:04:47.910 --> 1:04:53.700
Now these three things are done container registry set is done, Kubernetes cluster setup is done and

803
1:04:53.700 --> 1:04:56.130
we have application configuration in place.

804
1:04:56.910 --> 1:05:02.280
The next thing that we are going to do is we are actually going to deploy our system right.

805
1:05:02.790 --> 1:05:08.880
And then we will see how this system is ensuring higher reliability to us if something goes down.

806
1:05:09.180 --> 1:05:12.220
How does it react to that if law goes down?

807
1:05:12.240 --> 1:05:14.820
How does it react to that with the airport scaling?

808
1:05:15.210 --> 1:05:21.390
And if there is any bug in our system, and if you have to do an upgrade in a production system in a

809
1:05:21.390 --> 1:05:24.600
life system, then how Kubernetes is going to help us with that.

810
1:05:25.200 --> 1:05:31.440
So these are very important things that architects need to worry about when it is fortunately provides

811
1:05:31.440 --> 1:05:38.240
us all this solution to this out of the box and in the next session, we are going to be looking to

812
1:05:38.240 --> 1:05:38.550
do that.
