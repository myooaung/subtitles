WEBVTT
1
00:00:03.020 --> 00:00:11.020
In this video I'm going to talk to you about eigenvalues and I can vectors or more generally I can decomposition.

2
00:00:11.090 --> 00:00:18.200
I will provide an algebraic and a geometric interpretation of I can vectors and eigenvalues you will

3
00:00:18.200 --> 00:00:25.880
see how to do all this stuff in Python of course and you will be introduced to this concept of diagonal

4
00:00:25.880 --> 00:00:27.170
ization.

5
00:00:27.170 --> 00:00:32.810
I can do composition is one of the most important concepts in linear algebra.

6
00:00:32.840 --> 00:00:40.430
It's a central operation to many areas of statistics machine learning data compression multivariate

7
00:00:40.430 --> 00:00:46.790
signal processing and so on and so if you aren't really familiar with I can be composition or I can

8
00:00:46.790 --> 00:00:51.260
vectors then this video is going to be super exciting.

9
00:00:51.260 --> 00:00:57.670
All right so let me begin by saying that I can be composition is defined only four square matrices.

10
00:00:57.670 --> 00:01:03.950
So all the matrices when you're talking about I can be composition have to be m by m so the same number

11
00:01:03.950 --> 00:01:06.200
of rows as columns.

12
00:01:06.200 --> 00:01:12.500
There is another D composition called these singular value decomposition and that works for any size

13
00:01:12.500 --> 00:01:19.700
Matrix m by n where M does not equal N and I'm going to talk about these singular value decomposition

14
00:01:19.790 --> 00:01:27.680
in a later video so the idea of ion the competition is to represent a matrix or to extract out of a

15
00:01:27.680 --> 00:01:33.560
matrix a set of eigenvalues and associated ion vectors.

16
00:01:33.560 --> 00:01:41.750
So for an m by m matrix there is going to be m ion vectors and a corresponding number of eigenvalues

17
00:01:42.110 --> 00:01:43.450
and these all come in pairs.

18
00:01:43.490 --> 00:01:49.770
So this is the eigenvalues that's associated with this specific ion vector and so on.

19
00:01:50.390 --> 00:01:54.540
But what our ion vectors and eigenvalues and what do they mean.

20
00:01:54.560 --> 00:02:00.530
Well let's start this discussion by thinking about what happens when you multiply a matrix by a vector

21
00:02:00.920 --> 00:02:03.890
and I already discussed this in the previous video.

22
00:02:03.890 --> 00:02:12.470
The answer is that you get another vector so A times V equals vector W and we can plot V and W on the

23
00:02:12.470 --> 00:02:14.750
same plot and that might look something like this.

24
00:02:14.750 --> 00:02:20.960
So perhaps vector V so this would of course be for a two dimensional vector and a two by two matrix

25
00:02:20.960 --> 00:02:23.550
because we have a two dimensional plot here.

26
00:02:23.690 --> 00:02:28.780
So vector V might look something like this in vector W might look something like this.

27
00:02:28.790 --> 00:02:35.540
And so one of the main points of the previous video was that the effect of multiplying a matrix by a

28
00:02:35.540 --> 00:02:40.250
vector is that the Matrix will rotate and stretch or shrink that vector.

29
00:02:40.640 --> 00:02:43.750
So but the rotation is key for for this concept.

30
00:02:44.120 --> 00:02:50.990
So in nearly all cases nearly all pairs of matrices and vectors multiplying these two objects together

31
00:02:51.080 --> 00:02:58.790
is going to rotate the initial vector but it turns out that there is a small number of special vector

32
00:02:58.850 --> 00:03:06.830
matrix combinations such that when you multiply the matrix by the vector you actually get another vector

33
00:03:06.830 --> 00:03:08.620
that's all on the same line.

34
00:03:08.630 --> 00:03:12.640
So it looks just like the original vector V maybe it's a little bit longer.

35
00:03:12.650 --> 00:03:13.790
Maybe it's the same length.

36
00:03:13.790 --> 00:03:17.960
Maybe it's a little bit shorter but it's the same line.

37
00:03:17.960 --> 00:03:25.250
And when you find such a vector then that vector V is called an icon vector of this matrix A and to

38
00:03:25.250 --> 00:03:31.820
be clear there is nothing special about this vector on its own and there is nothing special about this

39
00:03:31.820 --> 00:03:33.900
matrix on its own.

40
00:03:34.220 --> 00:03:41.180
So vector V is not going to be an icon vector of some other matrix or it's unlikely to be an icon vector

41
00:03:41.180 --> 00:03:42.430
of some other matrix.

42
00:03:42.590 --> 00:03:49.660
It is a unique pairing of V and A that makes this special combination true.

43
00:03:50.150 --> 00:04:00.410
And because w vector w lies in the same line as vector V then the effect of matrix A on vector V is

44
00:04:00.410 --> 00:04:01.990
actually just scaling it.

45
00:04:02.020 --> 00:04:10.460
So it says if we take a single number and multiply that by the vector so matrix vector multiplication

46
00:04:10.790 --> 00:04:16.850
is acting just like scalar vector multiplication so that is really special.

47
00:04:16.860 --> 00:04:24.980
And now we can say I mean get rid of this middleman here we can say that lambda the equals a V.

48
00:04:25.130 --> 00:04:33.150
Again this is a special relationship between this specific lambda this specific scalar or single number.

49
00:04:33.170 --> 00:04:40.640
This specific vector and this specific matrix but when you can find a matrix and a vector and a scalar

50
00:04:40.670 --> 00:04:48.740
such that this equality holds such that this statement is true then this is called an icon vector of

51
00:04:48.740 --> 00:04:52.960
matrix A and this is the associated icon value.

52
00:04:53.000 --> 00:05:01.590
And this equation here is called the icon value equation OK so this is both a geometric and an algebraic

53
00:05:01.620 --> 00:05:04.990
interpretation of eye candy composition.

54
00:05:05.010 --> 00:05:11.760
Now here I'm only showing you one I can value and one I can vector but I mentioned in the previous slide

55
00:05:11.970 --> 00:05:19.320
that I can do composition actually gives a full set of M I can vectors and M eigenvalues.

56
00:05:19.380 --> 00:05:26.190
So this is just for one of those so we can rewrite this equation in matrix form instead of in Matrix

57
00:05:26.190 --> 00:05:29.700
scalar vector form and that's going to look something like this.

58
00:05:29.710 --> 00:05:32.390
So we have this matrix A.

59
00:05:32.400 --> 00:05:34.680
So this is a m by m matrix.

60
00:05:34.710 --> 00:05:42.780
This is a matrix of ion vectors so each I can vector is in a column of this matrix and you see the same

61
00:05:43.140 --> 00:05:47.400
matrix repeated over here and then this is a capital lambda.

62
00:05:47.400 --> 00:05:53.620
This is a matrix of eigenvalues where the eigenvalues are in the diagonal.

63
00:05:53.760 --> 00:06:00.750
So this is the matrix version of the eigenvalues equation that I showed in the previous slides.

64
00:06:00.780 --> 00:06:07.350
Now this matrix here is a diagonal matrix as I will show you in a moment and therefore I can the composition

65
00:06:07.350 --> 00:06:13.980
is also sometimes called diagonal ization because the idea is that you are transforming this matrix

66
00:06:14.100 --> 00:06:21.240
A which is likely to be a dense matrix into a sparse matrix like this and a diagonal matrix that has

67
00:06:21.240 --> 00:06:25.380
all zeros and the eigenvalues on the diagonal.

68
00:06:25.380 --> 00:06:32.970
Now because these matrices are all square the icon vector vectors matrix is square and it's also full

69
00:06:32.970 --> 00:06:37.680
rank and that means that each icon vector is independent of each other.

70
00:06:37.680 --> 00:06:45.000
I can vector now there's a few small exceptions to this which I talk about more in my full course on

71
00:06:45.000 --> 00:06:45.770
linear algebra.

72
00:06:45.780 --> 00:06:51.960
It's a little bit outside the scope of this lecture but it's OK for now we can assume it's generally

73
00:06:51.960 --> 00:06:56.410
safe to assume that the ion vectors matrix is in vertical.

74
00:06:56.430 --> 00:07:04.830
It has an inverse and that means that we can actually isolate matrix A on the left and get this equality

75
00:07:04.830 --> 00:07:11.330
here v lambda v inverse and now we can also make pictures of this.

76
00:07:11.340 --> 00:07:12.790
So that would look something like this.

77
00:07:12.780 --> 00:07:14.880
So here we take some matrix A.

78
00:07:14.880 --> 00:07:19.510
This is just some you know it's just a bunch of random numbers that I've generated and I took its eye

79
00:07:19.570 --> 00:07:26.520
candy composition and that gave me two matrices the matrix of ion vectors where each column of this

80
00:07:26.520 --> 00:07:33.780
matrix contains an icon vector and this is the diagonal matrix of the eigenvalues where each diagonal

81
00:07:33.810 --> 00:07:39.990
element has the icon value associated with each column of the icon vector.

82
00:07:40.080 --> 00:07:43.910
So that means you know this icon value here.

83
00:07:43.980 --> 00:07:47.450
This is the second to last diagonal element.

84
00:07:47.490 --> 00:07:54.840
This is the corresponding icon value for this column of this matrix or this I can vector right here

85
00:07:55.430 --> 00:07:58.850
and then here we have this same v vector.

86
00:07:58.860 --> 00:08:07.190
So the matrix of icon vectors but it's the inverse what I'm going to do now in Python is show you some

87
00:08:07.190 --> 00:08:10.650
of these matrices and I can be competition.

88
00:08:10.670 --> 00:08:12.950
So let's start by creating a matrix.

89
00:08:12.950 --> 00:08:14.340
I'll call this em.

90
00:08:14.480 --> 00:08:18.840
I'm going to first generate this to be random numbers.

91
00:08:18.850 --> 00:08:20.890
I won't even random integers.

92
00:08:20.900 --> 00:08:26.120
Let's go from minus five to plus six and let's make this.

93
00:08:26.120 --> 00:08:31.910
Of course this has to be a five by five matrix but I'm actually going to set this initially to be a

94
00:08:31.910 --> 00:08:33.410
non square matrix.

95
00:08:33.410 --> 00:08:36.740
This just show you what happens okay.

96
00:08:36.770 --> 00:08:42.050
So I'm going to write I vowels and I Vex.

97
00:08:42.050 --> 00:08:45.480
So these are gonna be two outputs from the NUM pi.

98
00:08:45.530 --> 00:08:54.770
Lin Algebra II function which is going to compute the I the composition on matrix M and now we get an

99
00:08:54.800 --> 00:09:00.080
error and the error message says that the dimensions of the array must be squared.

100
00:09:00.080 --> 00:09:06.020
So essentially this is telling us that it cannot compute the eye candy composition because this is not

101
00:09:06.080 --> 00:09:07.250
a square matrix.

102
00:09:08.200 --> 00:09:08.500
Okay.

103
00:09:08.540 --> 00:09:15.230
So now I'm actually also going to do something else I'm going to multiply this matrix by its transpose

104
00:09:16.790 --> 00:09:20.960
and that's essentially going to guarantee that we get real value.

105
00:09:21.020 --> 00:09:24.050
I can do composition instead of a complex value.

106
00:09:24.080 --> 00:09:26.720
I can do composition again.

107
00:09:26.750 --> 00:09:34.020
There's a theory there's a reason for this but it's a bit outside the scope of this short video.

108
00:09:34.070 --> 00:09:34.290
OK.

109
00:09:34.310 --> 00:09:40.070
So now we have these eigenvalues and ion vectors and be nice to look at these and see what they look

110
00:09:40.070 --> 00:09:40.340
like.

111
00:09:40.340 --> 00:09:46.940
So I'm going to draw a couple of axes here so P L T that subplots.

112
00:09:47.540 --> 00:09:54.830
Let's do it one by three layout so I'm gonna show the original matrix the I can vectors and then the

113
00:09:54.830 --> 00:09:56.340
eigenvalues.

114
00:09:56.540 --> 00:10:06.170
So let's see x 0 that I am show em and that's probably a good idea to put a title on this set title

115
00:10:06.620 --> 00:10:15.320
I'll call this the matrix not capital the Matrix that's the movie from the 90s lowercase matrix and

116
00:10:15.320 --> 00:10:25.310
let's see now we need X 1 is going to be I am show let's show the eigenvalues matrix so I vowels and

117
00:10:25.370 --> 00:10:39.030
then this gets a title of eigenvalues and then we want to plot I am show the I again vectors like this.

118
00:10:39.110 --> 00:10:49.790
So now we do X 2 and set title I again value x vectors.

119
00:10:50.030 --> 00:10:55.970
This is interesting we get an error let's see what this error says it says invalid dimensions for image

120
00:10:55.970 --> 00:10:56.750
data.

121
00:10:56.750 --> 00:11:03.040
So we're having a hard time or Python is having a difficult time generating an image of the eye again

122
00:11:03.090 --> 00:11:03.960
values.

123
00:11:04.070 --> 00:11:08.760
So then we actually start just by commenting out this line.

124
00:11:09.010 --> 00:11:09.340
Okay.

125
00:11:09.350 --> 00:11:15.930
And now we see the matrix we see a matrix of ion vectors and what's going on with this eigenvalues.

126
00:11:16.070 --> 00:11:17.090
Let's have a look at these.

127
00:11:17.090 --> 00:11:26.390
I'm going to print them out so print I vowels and actually let me also type uh P L T that shows we don't

128
00:11:26.390 --> 00:11:29.670
get this extra output text here.

129
00:11:29.910 --> 00:11:30.190
Okay.

130
00:11:30.200 --> 00:11:39.530
So it looks like the eye vowels the output of the eye function is one two three four five elements and

131
00:11:39.530 --> 00:11:42.800
it's just a vector and that actually makes sense.

132
00:11:42.800 --> 00:11:48.730
So we get five eigenvalues that come out of this five by five matrix.

133
00:11:48.830 --> 00:11:52.620
So let's look at the the doc string the health text here.

134
00:11:52.910 --> 00:12:01.220
This says that the output is going to be the eigenvalues in an array.

135
00:12:01.550 --> 00:12:01.850
Okay.

136
00:12:01.850 --> 00:12:05.630
And so what we want to do is is plot this as a matrix.

137
00:12:05.630 --> 00:12:13.010
So we want to convert this into a diagonal matrix and you will recall from the video earlier in this

138
00:12:13.010 --> 00:12:15.710
section about special matrices how to do that.

139
00:12:15.710 --> 00:12:24.140
So I'm going to use P that Di egg and that's going to create a diagonal matrix or I should say of full

140
00:12:24.140 --> 00:12:29.840
matrix so a square matrix where the all the elements are zeros and the diagonal elements correspond

141
00:12:29.840 --> 00:12:35.920
to the vector that was input it into the dialogue function OK.

142
00:12:35.940 --> 00:12:42.980
And so again this is called diagonal ization because we are transforming this matrix into a matrix that

143
00:12:42.980 --> 00:12:48.640
contains only diagonal elements or only non-zero elements on the diagonal.

144
00:12:48.830 --> 00:12:55.460
And the transformation matrix to get us from the original matrix into this diagonal matrix is the matrix

145
00:12:55.520 --> 00:12:57.630
of ion vectors.

146
00:12:57.680 --> 00:13:03.110
Now there's one more quick thing that I would like to do before closing off this video and that is to

147
00:13:03.170 --> 00:13:08.840
illustrate the algebraic interpretation of ion vectors and eigenvalues.

148
00:13:08.840 --> 00:13:13.490
So I'm going to compute the matrix times and I can vector.

149
00:13:13.550 --> 00:13:23.240
So let's say m times I Vex and I'm going to do not all of the ion vectors just let's just take the first

150
00:13:23.240 --> 00:13:23.480
one.

151
00:13:23.480 --> 00:13:30.760
So this is gonna be the first ion vector so the first column and then so this is a matrix times the

152
00:13:30.820 --> 00:13:37.170
I can vector should be I vectors and then I'm gonna write L V for lambda V.

153
00:13:37.340 --> 00:13:39.010
And that is simply a scalar.

154
00:13:39.020 --> 00:13:41.320
So I vowels.

155
00:13:41.590 --> 00:13:50.030
And then it's just gonna be the first element times this same I again vectors like this.

156
00:13:50.780 --> 00:13:51.610
Oh right.

157
00:13:51.620 --> 00:13:53.180
And then I'm going to print both of these.

158
00:13:53.200 --> 00:13:58.310
So print M V and then print L V.

159
00:13:58.580 --> 00:14:01.480
And now you see that these two results are exactly the same.

160
00:14:01.490 --> 00:14:04.780
In other words multiplying this matrix.

161
00:14:04.780 --> 00:14:12.530
So this is a five by five matrix and the matrix times this vector is exactly the same as a single number

162
00:14:12.680 --> 00:14:14.760
times the same vector.

163
00:14:14.870 --> 00:14:17.520
And that is pretty special it's pretty wild.

164
00:14:17.660 --> 00:14:25.940
And that is the algebraic definition or the meaning of iron composition in this video.

165
00:14:25.950 --> 00:14:33.060
I introduced you to the algebraic and geometric interpretations of ion vectors and eigenvalues and I

166
00:14:33.060 --> 00:14:37.970
also introduced you to the idea of diagonal ization.

167
00:14:38.100 --> 00:14:44.070
Don't go too far away because in the next video there's going to be a really interesting and insightful

168
00:14:44.070 --> 00:14:51.390
exercise that's going to reveal some interesting properties of ion d composition so I will see you soon.
