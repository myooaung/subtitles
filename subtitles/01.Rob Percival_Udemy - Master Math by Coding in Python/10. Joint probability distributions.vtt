WEBVTT
1
00:00:03.730 --> 00:00:09.760
So far in this section of the course all of the probability distributions that we've been creating were

2
00:00:09.790 --> 00:00:10.810
one dimensional.

3
00:00:10.810 --> 00:00:14.100
They were based on one variable in this video.

4
00:00:14.100 --> 00:00:20.530
You are going to see how to extend the probability distribution to two dimensional so this is called

5
00:00:20.560 --> 00:00:23.230
a joint probability distribution.

6
00:00:23.230 --> 00:00:30.670
It's when you are looking at data distributions over two separate variables and along the way in this

7
00:00:30.670 --> 00:00:36.400
video you're also going to learn a little bit more about seaborne and a bit more about pandas including

8
00:00:36.820 --> 00:00:37.830
importing data.

9
00:00:37.840 --> 00:00:45.350
In this case text data so CSB or comma separated values data from the disk into python.

10
00:00:45.400 --> 00:00:47.020
Using pandas.

11
00:00:47.020 --> 00:00:53.550
So let's jump immediately into Python we are going to be using num pi.

12
00:00:53.590 --> 00:00:54.000
Matt.

13
00:00:54.010 --> 00:01:00.480
Plot lib and Seabourn and in the exercises we will also get to using pandas.

14
00:01:00.520 --> 00:01:05.890
So what I'm going to do is start by creating a two dimensional distribution.

15
00:01:05.890 --> 00:01:11.640
So I'm going to do that by creating two sets of variables or two variables of random numbers.

16
00:01:11.670 --> 00:01:21.670
So let's add the first one to be just random numbers Gaussian distributed and then on the y axis I'm

17
00:01:21.670 --> 00:01:27.070
actually going to set this to be very similar except this is going to be X squared.

18
00:01:27.670 --> 00:01:31.230
So here we have our variable X and our variable Y.

19
00:01:31.230 --> 00:01:37.060
And now the question is what is the joint probability distribution of x and y.

20
00:01:37.330 --> 00:01:44.860
So what is the probability that a given data point will have some value within some range in X and also

21
00:01:44.920 --> 00:01:46.000
in Y.

22
00:01:46.420 --> 00:01:52.670
So to examine this we are going to plot a two dimensional histogram so hist to D.

23
00:01:53.140 --> 00:02:00.800
So that's X come away and then I will specify the number of beans to be 30.

24
00:02:01.090 --> 00:02:01.800
So let's see.

25
00:02:01.820 --> 00:02:05.830
And then I'm gonna put an x axis label.

26
00:02:05.830 --> 00:02:08.730
So the X axis label is going to be x.

27
00:02:08.740 --> 00:02:16.990
So that's actually just the function x and then the y axis label is going to be X squared.

28
00:02:16.990 --> 00:02:19.030
So I'll use a little bit of latex coating here.

29
00:02:19.050 --> 00:02:21.720
So X karat too.

30
00:02:22.000 --> 00:02:23.980
And let's see what this thing looks like.

31
00:02:26.050 --> 00:02:29.380
So here we have our two dimensional distribution.

32
00:02:29.500 --> 00:02:33.670
And actually it's really dominated by these small values here.

33
00:02:33.670 --> 00:02:41.800
So I'm going to add another optional input to hist 2D and that is v Max for the maximum color.

34
00:02:41.980 --> 00:02:44.620
And let's set it to 10 for example.

35
00:02:44.620 --> 00:02:47.020
So this is starting to look better.

36
00:02:47.110 --> 00:02:49.090
So how do you interpret this plot.

37
00:02:49.120 --> 00:02:54.400
Well this is very similar to the histogram that we've been looking at before.

38
00:02:54.430 --> 00:03:00.880
The main difference is that we have a separate histogram for each variable so you can see the distribution

39
00:03:00.910 --> 00:03:04.150
over X and the distribution over X squared.

40
00:03:04.150 --> 00:03:10.150
Now of course all these values are positive here or at least non negative because there is no value

41
00:03:10.180 --> 00:03:11.480
for X squared.

42
00:03:11.710 --> 00:03:14.160
That can possibly be negative.

43
00:03:14.470 --> 00:03:20.380
And as you saw a couple of videos ago when we created probability distributions of those mathematical

44
00:03:20.380 --> 00:03:26.110
functions X squared has a large concentration of values towards zero.

45
00:03:26.110 --> 00:03:28.650
So in this case that's going to be on the bottom.

46
00:03:28.660 --> 00:03:33.670
Now you remember when we were looking at the histogram of data just for X squared.

47
00:03:33.670 --> 00:03:39.370
That plot looks something like this at this kind of exponential decay indicating that most values were

48
00:03:39.370 --> 00:03:40.870
small close to zero.

49
00:03:41.020 --> 00:03:44.680
And that's what you see going along the y axis here.

50
00:03:44.710 --> 00:03:50.180
Now the thing is that there's actually three distributions that you can extract from this plot.

51
00:03:50.230 --> 00:03:57.010
There's the distributions over the x axis the distributions over the y axis and the joint distribution

52
00:03:57.010 --> 00:03:59.390
which is what you were looking at here.

53
00:03:59.470 --> 00:04:05.590
So we can actually make this plot be a little clearer we can make this be more interpretable by also

54
00:04:05.590 --> 00:04:08.230
plotting what's called the marginal distributions.

55
00:04:08.230 --> 00:04:15.490
So that would be the distributions when ignoring one of the dimensions and to do that I'm going to switch

56
00:04:15.490 --> 00:04:23.620
to seaborne so I'm going to write S and S for seaborne that joint plot and let's make a joint plot of

57
00:04:24.040 --> 00:04:33.220
X comma Y and BLT that show and let's see what this looks like so what are we looking at here.

58
00:04:33.220 --> 00:04:41.060
So each of these dots shows a data point on the x axis and on the y axis and what you see here on the

59
00:04:41.060 --> 00:04:44.120
side and on top is the distribution.

60
00:04:44.170 --> 00:04:47.800
It's called the marginal distributions over the two dimensions.

61
00:04:47.800 --> 00:04:54.170
So this up here is the distribution over X which is the the function x.

62
00:04:54.310 --> 00:04:58.240
So this would be the distribution completely ignoring variable Y.

63
00:04:58.450 --> 00:05:05.970
And here on the side you see the distribution of Y completely ignoring X or marginal over x.

64
00:05:06.040 --> 00:05:06.270
Okay.

65
00:05:06.280 --> 00:05:10.000
So now I want to spend a moment making this plot look a little bit nicer.

66
00:05:10.000 --> 00:05:18.790
So the first thing that I'm going to do is activate the seaborne visualization set parameters with S.A.

67
00:05:18.880 --> 00:05:20.590
dot set.

68
00:05:20.810 --> 00:05:25.490
So now you see it looks a little different it's the same data of course but the histogram looks different

69
00:05:25.490 --> 00:05:29.090
here and you get this you know this sort of white grid here it looks a little bit nicer.

70
00:05:29.870 --> 00:05:33.980
So this is a scatter plot because we see all the individual dots.

71
00:05:33.980 --> 00:05:40.400
And if we look at the dock string or the help file for S.A. s Joint plot you can see that there's a

72
00:05:40.400 --> 00:05:44.380
couple of different kinds of plots that we can generate.

73
00:05:44.390 --> 00:05:49.300
So for example we can have Reg which stands for regression.

74
00:05:49.300 --> 00:05:54.610
It'll plot a regression line and there's a couple of different options and KDE and hex.

75
00:05:54.620 --> 00:05:56.020
I'm going to show you these three.

76
00:05:56.090 --> 00:05:59.790
So Reg Katie and hex so let's start with Reg.

77
00:05:59.810 --> 00:06:04.520
I'm going to say kind equals Reg again that stands for regression.

78
00:06:04.740 --> 00:06:11.750
And what Seabourn is actually doing is computing the regression line between x and y and plotting that

79
00:06:11.750 --> 00:06:15.110
regression line along with some uncertainty measure.

80
00:06:15.110 --> 00:06:21.020
Now in this particular case for this example there isn't actually an interesting linear relationship

81
00:06:21.020 --> 00:06:22.730
between X and Y.

82
00:06:22.730 --> 00:06:27.770
And so the regression line in fact doesn't really make sense for this particular dataset but I just

83
00:06:27.770 --> 00:06:29.430
wanted to illustrate it to you.

84
00:06:29.570 --> 00:06:36.230
So then we have KDE e and this one draws a kernel density estimation.

85
00:06:36.230 --> 00:06:43.400
So you see instead of seeing all the individual dots you see these ISO contours indicating the density

86
00:06:43.520 --> 00:06:50.300
of the plots in different areas or the data in different areas and then also change the histogram to

87
00:06:50.300 --> 00:06:52.790
be a kernel density estimation.

88
00:06:52.790 --> 00:06:58.990
So it's a little bit smoother but it's still fundamentally the same data that's shown before.

89
00:06:59.000 --> 00:06:59.230
Okay.

90
00:06:59.240 --> 00:07:00.450
And then scatter.

91
00:07:00.800 --> 00:07:04.480
But that is actually the default if you don't type anything.

92
00:07:04.580 --> 00:07:09.770
I would also like to change the color of these so I'm going to add another optional input here to say

93
00:07:09.800 --> 00:07:19.430
color equals and I'll specify RG b. I like to have a bit of red not so much green and quite a bit of

94
00:07:19.490 --> 00:07:26.150
blue that makes for a very nice color I think now what would you do if you wanted to have a scatter

95
00:07:26.150 --> 00:07:29.360
plot and a kernel density estimation.

96
00:07:29.480 --> 00:07:33.740
Let's say you wanted both of these because you think that each of them looks nice.

97
00:07:33.800 --> 00:07:42.860
So in seaborne you can add a method to the S.A. joint plot function that's called plot underscore joint.

98
00:07:42.860 --> 00:07:48.160
And here I'm going to specify S.A. that K D E plot.

99
00:07:48.260 --> 00:07:55.520
So now this is going to produce a kernel density estimation plot that gets plotted on top of the plot

100
00:07:55.550 --> 00:07:57.890
that's already here.

101
00:07:57.890 --> 00:08:05.660
And so now you see all the individual data points as a scatter plot and you see the density estimation

102
00:08:05.780 --> 00:08:06.860
on top.

103
00:08:07.220 --> 00:08:10.930
And I think the last thing I will do is add the x and y labels.

104
00:08:10.940 --> 00:08:12.490
Let me go up here.

105
00:08:12.980 --> 00:08:16.710
Copy and paste.

106
00:08:17.600 --> 00:08:18.890
And there you go.

107
00:08:18.890 --> 00:08:25.910
So now this graph and this graph show fundamentally the same thing it's the same data.

108
00:08:26.000 --> 00:08:31.460
However I think you agree that this is not only a little bit nicer to look at.

109
00:08:31.460 --> 00:08:37.190
It's also a little bit more informative in particular because we have the overlay of the individual

110
00:08:37.190 --> 00:08:45.830
data points with the kernel density and we have these marginal histogram on top and on the side the

111
00:08:45.890 --> 00:08:49.300
exercise for this video has three parts.

112
00:08:49.310 --> 00:08:54.620
So first of all you want to import this file called data that CSB.

113
00:08:54.800 --> 00:09:00.920
This data comes along in the zip file where you download all the code for this section of the course.

114
00:09:00.950 --> 00:09:06.900
So import this data file and you can import using Python or using pandas.

115
00:09:06.920 --> 00:09:08.180
I recommend pandas.

116
00:09:08.180 --> 00:09:15.630
It's actually a little bit easier to read in a CSP file in pandas compared to just in like raw python.

117
00:09:15.860 --> 00:09:22.490
And then you want to show a joint distribution and joint probability distribution along with the marginals.

118
00:09:22.490 --> 00:09:28.260
So that's very similar to what we just did in the in python a few moments ago.

119
00:09:28.400 --> 00:09:32.750
And then you will see when you look at these data there's gonna be some clusters and then basically

120
00:09:32.750 --> 00:09:37.790
you just want to look at the plot and interpret the number of clusters that are in the data.

121
00:09:37.820 --> 00:09:42.770
And this is just by visual inspection we're not going to be applying any machine learning techniques

122
00:09:42.770 --> 00:09:44.960
or categorization or clustering algorithms.

123
00:09:44.960 --> 00:09:50.900
So just based on your visual inspection determine the number of spatial clusters that are present in

124
00:09:50.960 --> 00:09:52.280
the data.

125
00:09:52.280 --> 00:09:56.820
Now I'm going to give you a hint for importing this data file.

126
00:09:56.990 --> 00:10:00.410
So if you don't want the hint if you want to figure it out on your own then.

127
00:10:00.440 --> 00:10:05.050
Now is your last chance to pause the video because here comes the hint.

128
00:10:05.930 --> 00:10:11.400
So the hint is to use PD pendants dot read see V all right.

129
00:10:11.420 --> 00:10:19.710
So now you can pause the video and now I'm going to switch to Python and show you my solution so let's

130
00:10:19.710 --> 00:10:23.350
start with a new cell down here.

131
00:10:23.520 --> 00:10:24.880
I'm going to import the data.

132
00:10:24.880 --> 00:10:26.040
Let's call it data.

133
00:10:26.040 --> 00:10:31.670
So this is going to be PD read C S Vs C STV.

134
00:10:31.890 --> 00:10:36.480
Again this is the way to import a C S V file in pandas.

135
00:10:36.480 --> 00:10:38.670
You can also do it in raw Python.

136
00:10:38.670 --> 00:10:41.060
It requires several extra lines of code.

137
00:10:41.310 --> 00:10:45.900
But if that was your preferred solution then of course that's totally fine.

138
00:10:45.930 --> 00:10:48.570
So let's see the data file is called data.

139
00:10:48.590 --> 00:10:54.100
That C S V and let's just immediately take a look at what this dataset looks like.

140
00:10:54.740 --> 00:10:55.010
OK.

141
00:10:55.050 --> 00:11:00.170
So there's already a problem here and I hope that you've figured out what this problem is.

142
00:11:00.240 --> 00:11:03.270
So the real data is it looks basically like this.

143
00:11:03.290 --> 00:11:05.730
So we have two columns of data.

144
00:11:06.300 --> 00:11:11.240
However there are not actually seventy four rows.

145
00:11:11.490 --> 00:11:13.890
In fact there are seventy five rows of data.

146
00:11:13.890 --> 00:11:20.400
This is the first row of data and this function by default or erroneously I should say considered the

147
00:11:20.400 --> 00:11:25.980
first row in data file to be the labels for the two columns.

148
00:11:26.010 --> 00:11:31.380
So pandas interpreted this first column to have this label and the second column to have this label

149
00:11:31.710 --> 00:11:34.550
which means we're actually losing one row in the data.

150
00:11:34.890 --> 00:11:35.430
So let's see.

151
00:11:35.460 --> 00:11:45.420
So therefore we can write header equals none and now we get just default header names of 0 and 1.

152
00:11:45.530 --> 00:11:52.580
And I am going to specify that the names will be called X and Y.

153
00:11:52.580 --> 00:11:52.850
Okay.

154
00:11:52.850 --> 00:11:59.180
Now if you tried to run this and you get an error about the file not being found or Python was unable

155
00:11:59.180 --> 00:12:04.930
to locate the file then it's probably the case that you were just in the wrong file.

156
00:12:04.940 --> 00:12:11.390
So if you look at the address bar up here you will see the name of the folder where you are living on

157
00:12:11.390 --> 00:12:15.710
your computer or on the server if you're working on Python online.

158
00:12:15.980 --> 00:12:21.590
So as long as this file is in this folder then it should be readable.

159
00:12:21.620 --> 00:12:21.890
All right.

160
00:12:21.890 --> 00:12:29.240
So now we've successfully read in these data and now I'm just going to make a plot so S.A. that joint

161
00:12:29.810 --> 00:12:30.720
plot.

162
00:12:30.980 --> 00:12:35.640
And now we have to specify the columns in data that we want to draw.

163
00:12:35.660 --> 00:12:36.690
The plot up.

164
00:12:36.710 --> 00:12:46.130
So it's going to be data X and we call this like a dictionary data y and let's actually just draw it

165
00:12:46.130 --> 00:12:49.780
like this and see how it looks and I'll get rid of this here.

166
00:12:50.940 --> 00:12:51.200
Okay.

167
00:12:51.230 --> 00:12:52.640
So already this is pretty interesting.

168
00:12:52.640 --> 00:12:59.500
You can see all these dots and it's pretty clear that there are three clusters one two three clusters.

169
00:12:59.540 --> 00:13:01.700
So that's kind of the end of this assignment.

170
00:13:01.700 --> 00:13:05.770
I'd want to spend a few moments making this look a little bit nicer.

171
00:13:05.870 --> 00:13:12.200
So instead of this being a scatter plot on its own I'm going to say kind equals KDE so I'm going to

172
00:13:12.200 --> 00:13:15.080
make this a kernel density estimation.

173
00:13:15.590 --> 00:13:22.310
So there you see the histogram is the marginal distributions and you see the ISO contours showing where

174
00:13:22.310 --> 00:13:24.460
the clusters of the data are.

175
00:13:24.500 --> 00:13:30.140
Now this is already pretty interesting from a machine learning perspective because when you look at

176
00:13:30.140 --> 00:13:37.860
the marginal histogram you don't actually see that there are three separate clusters in this dataset.

177
00:13:37.880 --> 00:13:44.210
So if I gave you these data and you just looked at histogram of x and y and you didn't actually look

178
00:13:44.210 --> 00:13:50.690
at the plot of the data X by Y so there's joint probability distribution you would actually most likely

179
00:13:50.690 --> 00:13:52.000
misinterpret the data.

180
00:13:52.010 --> 00:13:58.250
You would probably come to the wrong conclusion about the data and that is an example of the importance

181
00:13:58.340 --> 00:14:02.090
of visualizing data as much as possible.

182
00:14:02.120 --> 00:14:02.330
OK.

183
00:14:02.360 --> 00:14:04.420
So there's a couple more things I want to do here.

184
00:14:04.430 --> 00:14:11.480
I want to show you the another optional input called levels and that shows that controls the number

185
00:14:11.480 --> 00:14:12.640
of ISO contours.

186
00:14:12.650 --> 00:14:16.090
So for example found right levels equals two.

187
00:14:16.310 --> 00:14:22.370
Then you can see that we just get to ISO contours so let's see two is definitely too small.

188
00:14:22.370 --> 00:14:23.450
We can also do 20.

189
00:14:23.450 --> 00:14:24.700
I'm sure that's gonna be OK.

190
00:14:24.710 --> 00:14:26.020
Doesn't look so bad actually.

191
00:14:26.030 --> 00:14:31.040
But I think probably somewhere around 5 is a pretty good range.

192
00:14:31.040 --> 00:14:32.780
I think that's pretty reasonable.

193
00:14:32.990 --> 00:14:33.300
Okay.

194
00:14:33.350 --> 00:14:36.490
But now I also want to see all the individual points.

195
00:14:36.520 --> 00:14:43.430
So I'm going to write plot underscore joint and then S.A. start scatter plot.

196
00:14:43.460 --> 00:14:50.240
So this is kind of the opposite of what I did up here where I first drew the scatter plot and then put

197
00:14:50.240 --> 00:14:53.240
the kernel density estimation on top here.

198
00:14:53.300 --> 00:14:57.400
I'm gonna draw the kernel density estimation and then the scatter plot on top.

199
00:14:57.410 --> 00:15:02.300
So the dots on top of that and I think this looks pretty nice.

200
00:15:02.320 --> 00:15:09.970
So I'm going to call this the successful completion of this exercise in this video.

201
00:15:09.980 --> 00:15:17.600
You learned how to create and interpret two dimensional histogram is which can be normalized to probability

202
00:15:17.630 --> 00:15:24.650
distributions and you also learned more about creating nice looking plots in seaborne and importing

203
00:15:24.650 --> 00:15:27.360
data from the disk using pend us.
