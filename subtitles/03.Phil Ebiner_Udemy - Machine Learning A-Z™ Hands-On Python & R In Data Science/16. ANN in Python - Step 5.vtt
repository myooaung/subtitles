WEBVTT
1
00:00:00.150 --> 00:00:01.620
Hello, my friends, welcome back.

2
00:00:01.740 --> 00:00:08.730
And mostly welcome to part for making the predictions and evaluating the moral and idea of the previous

3
00:00:08.730 --> 00:00:09.190
material.

4
00:00:09.240 --> 00:00:15.120
I actually asked you to do a little homework, which is right here, and which consisted of using your

5
00:00:15.120 --> 00:00:20.520
hÃ©nin and moral to predict if the customer with the following information will leave.

6
00:00:20.640 --> 00:00:21.960
Yes or no, the bank.

7
00:00:22.290 --> 00:00:23.350
So I hope you did.

8
00:00:23.370 --> 00:00:25.860
Well, you actually had all the tools to do it.

9
00:00:26.130 --> 00:00:29.010
And that's something we did before in part three classification.

10
00:00:29.280 --> 00:00:30.990
So I'm sure you smashed this.

11
00:00:31.080 --> 00:00:32.050
Let's see about that.

12
00:00:32.080 --> 00:00:34.800
Let's implement the solution together.

13
00:00:35.340 --> 00:00:35.630
All right.

14
00:00:35.640 --> 00:00:39.290
So I left this code cell here to enter the solution, but this is just too common.

15
00:00:39.300 --> 00:00:40.800
So let's just remove it.

16
00:00:41.460 --> 00:00:45.000
And now how do we complete successfully that homework?

17
00:00:45.180 --> 00:00:51.210
Well, of course, we need to get first are aid and moral from which we're gonna call a new method.

18
00:00:51.330 --> 00:00:54.930
No different than the ad method or the fit method.

19
00:00:55.410 --> 00:00:55.650
Right.

20
00:00:55.680 --> 00:00:59.100
Now, of course, we need to call the predict method, right.

21
00:00:59.280 --> 00:01:00.450
Absolutely no trap.

22
00:01:00.750 --> 00:01:03.390
We call this Brigg method to predict if yes.

23
00:01:03.460 --> 00:01:06.870
Know the customer with the following information will leave the bank.

24
00:01:07.470 --> 00:01:07.830
All right.

25
00:01:07.860 --> 00:01:12.000
And now, since this is a method, I'm going to add some parenthesis here.

26
00:01:12.330 --> 00:01:17.460
Let me actually scroll down, you know, in case you're uncomfortable with the border at the bottom.

27
00:01:17.700 --> 00:01:17.970
All right.

28
00:01:17.980 --> 00:01:19.320
To predict then.

29
00:01:19.410 --> 00:01:19.680
OK.

30
00:01:19.740 --> 00:01:22.170
So you have all the information to predict method.

31
00:01:22.200 --> 00:01:24.750
But we know exactly what to predict.

32
00:01:24.900 --> 00:01:27.900
This is given in the instructions of the homework.

33
00:01:28.260 --> 00:01:30.050
We have to enter these informations.

34
00:01:30.330 --> 00:01:32.640
But there are few things to pay attention to.

35
00:01:32.910 --> 00:01:34.130
And there are actually three things.

36
00:01:34.140 --> 00:01:39.420
That's why I really wanted to give you this homework, because I wanted to see if you could pay attention

37
00:01:39.420 --> 00:01:42.990
to three important things to include inside that BRIC method.

38
00:01:43.500 --> 00:01:49.710
Let's start with the most essential one, which is the double pair of square brackets.

39
00:01:49.980 --> 00:01:50.280
Right.

40
00:01:50.310 --> 00:01:57.450
It's very important to remember that any input of the predict method must be to the array, whether

41
00:01:57.450 --> 00:02:00.000
it is the test set to predict.

42
00:02:00.060 --> 00:02:06.570
And in symbol of outcomes, foreign and symbol of observations or whether it is a single prediction.

43
00:02:06.780 --> 00:02:12.840
Well, anything has to be in a double pair of square brackets, which therefore makes a 2D array.

44
00:02:12.960 --> 00:02:17.580
Basically, the format expected by the break method is always to the array.

45
00:02:18.210 --> 00:02:19.590
Okay, so that was the first thing.

46
00:02:19.800 --> 00:02:24.540
Then inside this to the array, we're going to enter well, the different informations here.

47
00:02:25.110 --> 00:02:31.500
And that leads me to mention the second important thing which had to pay attention to, which is about

48
00:02:31.500 --> 00:02:33.000
that very well here.

49
00:02:33.050 --> 00:02:36.720
Geography, France, according to you.

50
00:02:36.870 --> 00:02:41.520
Do we have to enter, as you know, disperse information here for the geography variable?

51
00:02:41.730 --> 00:02:45.720
Do we have to enter the string France or do we have to enter something else?

52
00:02:46.020 --> 00:02:49.140
Well, of course we have to enter something else, and that's something else.

53
00:02:49.290 --> 00:02:52.850
Are the values of the dummy variable, right?

54
00:02:52.920 --> 00:02:55.200
That's the second thing you had to do correctly.

55
00:02:55.290 --> 00:02:59.580
And therefore, now we need to check what was the encoding for France?

56
00:02:59.790 --> 00:03:05.310
Well, remember, if we have a look at our matrix of features X right above, you know, in part one

57
00:03:05.310 --> 00:03:06.360
day will be pricing.

58
00:03:06.540 --> 00:03:11.220
So this is the matrix of features X, the whole matrix containing all the customers.

59
00:03:11.430 --> 00:03:16.920
So in order to know what France corresponds to, you know, in terms of encoding, we just have to have

60
00:03:16.920 --> 00:03:24.030
a look at the first observation before one HUTZ encoding was applied, because indeed that first observation

61
00:03:24.060 --> 00:03:25.170
corresponds to France.

62
00:03:25.560 --> 00:03:31.230
And so now we just need to compare friends here to the one Hutz, including resulting from what we did

63
00:03:31.230 --> 00:03:31.680
here.

64
00:03:31.770 --> 00:03:38.760
And, well, we can see that the first row here contains one zero zero as the values of the dummy variables,

65
00:03:38.880 --> 00:03:42.660
and therefore France was encoded indeed into one zero zero.

66
00:03:42.810 --> 00:03:49.440
So the dummy variable values for the France country and the geography variable is indeed one zero zero.

67
00:03:49.470 --> 00:03:55.380
And that's exactly what we have to enter here as the first parameter.

68
00:03:55.630 --> 00:03:56.310
So let's do this.

69
00:03:56.340 --> 00:03:59.340
Let's enter one zero zero.

70
00:03:59.640 --> 00:04:00.540
And there we go.

71
00:04:00.630 --> 00:04:05.180
Basically, that enters that first value of the first parameter geography.

72
00:04:06.150 --> 00:04:06.540
All right.

73
00:04:06.630 --> 00:04:09.930
And then all the rest is easy for the credit score.

74
00:04:09.930 --> 00:04:10.500
We will enter.

75
00:04:10.500 --> 00:04:10.980
Indeed.

76
00:04:11.130 --> 00:04:12.010
Six hundred.

77
00:04:12.710 --> 00:04:15.120
Then let's see the gender male.

78
00:04:15.180 --> 00:04:19.170
So remember, male was encoded as one and female was encoded at zero.

79
00:04:19.230 --> 00:04:22.800
So here in order to enter the male gender, we need to enter one.

80
00:04:23.340 --> 00:04:25.200
All right, then, 40 years old.

81
00:04:25.230 --> 00:04:26.790
Very simply, we enter 40.

82
00:04:27.390 --> 00:04:29.610
Then tenure three years.

83
00:04:29.820 --> 00:04:31.440
We enter three here.

84
00:04:31.980 --> 00:04:34.530
Then balance sixty thousand dollars.

85
00:04:34.620 --> 00:04:37.320
So we enter sixty thousand.

86
00:04:37.770 --> 00:04:40.180
Then let's see number of products too.

87
00:04:40.560 --> 00:04:42.690
So two then.

88
00:04:42.810 --> 00:04:44.670
Does this customer have a credit card?

89
00:04:44.850 --> 00:04:45.450
Yes.

90
00:04:45.840 --> 00:04:49.620
So one because one corresponds to yes and zero corresponds to no.

91
00:04:50.100 --> 00:04:51.750
Is this customer an active member?

92
00:04:51.870 --> 00:04:52.380
Yes.

93
00:04:52.680 --> 00:04:55.920
So one again, an estimated salary.

94
00:04:55.950 --> 00:04:57.870
Finally, fifty thousand dollars.

95
00:04:58.110 --> 00:04:59.820
So our last parameter value.

96
00:05:00.450 --> 00:05:03.680
Is fifty thousand dollars OK?

97
00:05:04.290 --> 00:05:04.810
Yes.

98
00:05:04.950 --> 00:05:05.430
Oh, good.

99
00:05:05.940 --> 00:05:06.540
Excellent.

100
00:05:06.810 --> 00:05:08.820
And now I have a question for you.

101
00:05:09.090 --> 00:05:14.770
Do you think we're done with this prediction, you know, using the Pyhrric method with all these informations?

102
00:05:15.420 --> 00:05:18.180
And the answer to that is no.

103
00:05:18.240 --> 00:05:24.840
And that leads me to the third thing you had to pay attention to, which is the fact that remember to

104
00:05:24.840 --> 00:05:34.260
predict method should be called arnd observations on which the same scaling was applied as in the training.

105
00:05:34.590 --> 00:05:41.190
And since we trained our artificial neural network with the scaled values, you know, the scaled values

106
00:05:41.190 --> 00:05:48.240
of the features, well, the predict method has to be called on to these observations to which the same

107
00:05:48.240 --> 00:05:49.980
scaling was applied.

108
00:05:50.340 --> 00:05:55.500
And that was the third thing you must have not forgotten, which is the fact that you have to apply

109
00:05:55.500 --> 00:05:59.760
your essay object here to scale that single observation.

110
00:06:00.150 --> 00:06:00.500
Right.

111
00:06:00.570 --> 00:06:01.810
That's superimportant.

112
00:06:01.950 --> 00:06:03.690
Make sure to pay attention to this.

113
00:06:03.990 --> 00:06:07.080
Check if some scaling was applied during the training.

114
00:06:07.230 --> 00:06:08.430
And yes, it is the case here.

115
00:06:08.470 --> 00:06:11.340
And anyway, it is always the case for neural networks.

116
00:06:11.610 --> 00:06:13.050
And therefore, in the predict method.

117
00:06:13.320 --> 00:06:16.170
Well, we need to scale that single observation.

118
00:06:16.320 --> 00:06:19.860
And the way to do this is, of course, by calling our SC object.

119
00:06:20.430 --> 00:06:20.690
Yes.

120
00:06:20.700 --> 00:06:23.370
This one from which we're going to go.

121
00:06:23.430 --> 00:06:30.120
Be careful not to fit transform because the fit transform is used to remember, get the mean and standard

122
00:06:30.120 --> 00:06:35.040
deviation of the values and training set in order to fit your scalar to the training set.

123
00:06:35.220 --> 00:06:41.190
But then for the test set, we only need to call the transfer method because if we fitted again the

124
00:06:41.190 --> 00:06:44.370
scalar, well, that would cause some information like it.

125
00:06:44.560 --> 00:06:48.520
You know, I explained this in part one, David preprocessing check it out again if you need.

126
00:06:48.750 --> 00:06:55.050
But remember that on the test set or on new observations on which you deploy your model in production,

127
00:06:55.260 --> 00:06:57.630
you can only apply the transform method.

128
00:06:58.020 --> 00:07:00.850
And that's what we're going to call here, transform.

129
00:07:01.440 --> 00:07:01.980
There we go.

130
00:07:01.980 --> 00:07:07.830
Which has to take as input the whole observation in these double pair of square brackets.

131
00:07:08.070 --> 00:07:08.430
All right.

132
00:07:08.850 --> 00:07:09.420
Perfect.

133
00:07:09.960 --> 00:07:10.710
Good, good, good.

134
00:07:10.740 --> 00:07:12.660
So basically, that's it.

135
00:07:12.960 --> 00:07:14.140
Now we can run that cell.

136
00:07:14.190 --> 00:07:15.930
Now we can get our prediction.

137
00:07:16.200 --> 00:07:23.040
But remember that when compiling are an end to, you know, an optimizer, a lost function and a matrix.

138
00:07:23.280 --> 00:07:29.640
Remember that in the output of our artificial new network, we chose a sigmoid activation function,

139
00:07:29.970 --> 00:07:36.930
which therefore will return this prediction in the form of a probability, meaning that instead of getting

140
00:07:36.990 --> 00:07:42.820
the final outcome, one or zero, whether the customer left or stayed in the bank, while we're going

141
00:07:42.820 --> 00:07:47.520
to get the probability that this customer leaves the bank.

142
00:07:47.760 --> 00:07:51.720
But you'll see it will be very easy to get the final prediction, one or zero.

143
00:07:51.780 --> 00:07:54.480
But first, let me show you what we get with this prediction.

144
00:07:54.480 --> 00:07:58.630
So we're going to put all this into a print, right?

145
00:07:58.890 --> 00:08:01.830
All this into a third pair of parenthesis.

146
00:08:02.220 --> 00:08:11.010
Now, let me play that cell and we get that that the predicted probability that this customer leaves

147
00:08:11.010 --> 00:08:16.500
the bank is all point O four point O 38 O point O four.

148
00:08:17.100 --> 00:08:22.890
And therefore, it is predicted that this customer has a very low chance to leave the bank.

149
00:08:23.340 --> 00:08:26.850
And if you don't want the outcome in the form of a probability.

150
00:08:26.940 --> 00:08:31.140
Well, the trick to convert this into the final prediction is very easy.

151
00:08:31.620 --> 00:08:32.790
You just need to adhere.

152
00:08:32.920 --> 00:08:39.150
You know, just before the last parenthesis, the larger symbol and then both point five.

153
00:08:39.450 --> 00:08:40.140
Why is that?

154
00:08:40.560 --> 00:08:45.210
That's because, you know, all this, you know, and and predict the Nancy transform, then all the

155
00:08:45.210 --> 00:08:48.750
information is of the customers up to here returns.

156
00:08:48.810 --> 00:08:49.590
Exactly.

157
00:08:49.710 --> 00:08:51.570
The predicted probability.

158
00:08:52.020 --> 00:08:58.680
And here we choose a threshold of open five to say that if that predicted probability is larger than

159
00:08:58.710 --> 00:08:59.400
open five.

160
00:08:59.640 --> 00:09:02.700
Well, we will consider the final result to be one.

161
00:09:02.910 --> 00:09:08.070
Right, because the predicted probability that the outcome is one is larger than open five, meaning

162
00:09:08.070 --> 00:09:11.730
that there is more than 50 percent chance that the predicted outcome is one.

163
00:09:11.820 --> 00:09:13.200
So we'll consider it to be one.

164
00:09:13.230 --> 00:09:18.960
And however, if the predicted probability that the customer leaves the bank is below open five.

165
00:09:19.080 --> 00:09:21.420
Well, we will consider it to be zero.

166
00:09:21.600 --> 00:09:26.070
Of course, you can choose a different value of the threshold, especially when you have critical outcome,

167
00:09:26.070 --> 00:09:27.750
you know, for a critical decision.

168
00:09:28.050 --> 00:09:31.150
And in that case, you can, for example, increase the threshold.

169
00:09:31.200 --> 00:09:33.990
But here, let's just be the default value upon five.

170
00:09:34.230 --> 00:09:36.340
This totally makes sense for our case study.

171
00:09:36.960 --> 00:09:42.180
And therefore, now if we re execute this sale, we will, of course, get the final outcome, which

172
00:09:42.180 --> 00:09:45.660
will be, of course, zero or false, you know, false.

173
00:09:45.780 --> 00:09:48.630
We should not say goodbye to that customer or false.

174
00:09:48.630 --> 00:09:51.090
You know, the customer won't leave the bank.

175
00:09:51.120 --> 00:09:53.040
In other words, it will stay in the bank.

176
00:09:53.130 --> 00:09:55.110
So good, good news for the bank.

177
00:09:55.170 --> 00:09:59.790
But anyway, I just wanted to show you how to use your artificial neural network to.

178
00:09:59.870 --> 00:10:05.150
Predict the outcome of a single observation, meaning a single customer, remember three things.

179
00:10:05.330 --> 00:10:10.420
First, you have to enter your information in a two D array with a double pair of square brackets.

180
00:10:10.700 --> 00:10:16.400
Then you need to be careful with the dummy variable values here instead of entering the string input

181
00:10:16.400 --> 00:10:17.900
for that category call variable.

182
00:10:18.170 --> 00:10:23.600
And then the third thing, remember to apply scaling from your essy object because your artificial newel

183
00:10:23.600 --> 00:10:26.450
network was trained with scaled values.

184
00:10:27.110 --> 00:10:28.520
Okay, great.

185
00:10:28.640 --> 00:10:29.020
All right.

186
00:10:29.020 --> 00:10:32.300
So now let's finish this implementation in a flashlight.

187
00:10:32.360 --> 00:10:36.830
You know, the last two sales we have, by the way, I gave you some important notes here so that you

188
00:10:36.830 --> 00:10:37.460
can remember.

189
00:10:37.520 --> 00:10:38.870
That's basically what I explained.

190
00:10:39.170 --> 00:10:42.230
But anyway, now we have two selves to go.

191
00:10:42.320 --> 00:10:47.060
The first one is, you know, that cell, which I know very well where we predict the test that results

192
00:10:47.090 --> 00:10:52.130
by displaying next to each other the vector of predictions, widespread bread and a vector of real results,

193
00:10:52.130 --> 00:10:52.850
white test.

194
00:10:53.090 --> 00:10:57.040
So we're going to do this most efficiently by juggling with our two kids.

195
00:10:57.200 --> 00:11:02.780
And finally saying we will make the confusion matrix to get the final accuracy on the test set.

196
00:11:03.380 --> 00:11:03.650
All right.

197
00:11:03.650 --> 00:11:04.880
Let's do this efficiently.

198
00:11:04.940 --> 00:11:07.670
So we're gonna go back into our machinery.

199
00:11:07.700 --> 00:11:09.940
Is it for there, you know, to juggle with our toolkit?

200
00:11:10.340 --> 00:11:15.610
So I'm clicking this shortcut here to get the original base of the folder machinery A to Z.

201
00:11:16.220 --> 00:11:20.450
Then I'm just gonna go, you know, into point three classification to take any more all at stake,

202
00:11:20.630 --> 00:11:23.890
you know, logistic regression, for example, than Python.

203
00:11:24.260 --> 00:11:29.990
Then I can open this implementation, which contains indeed a lot of tools, you know, which we can

204
00:11:30.020 --> 00:11:36.560
you do with classification, as we are doing right now with our N.N. And now I'm just gonna scroll down

205
00:11:36.560 --> 00:11:41.900
and get, you know, the final sales, which will do exactly what we're about to do now with our and

206
00:11:41.900 --> 00:11:48.830
then first to display next to each other the vector of predictions and the vector of real results.

207
00:11:49.070 --> 00:11:50.330
So let's get that cell.

208
00:11:50.690 --> 00:11:55.130
Let's base that inside a new code cell right here.

209
00:11:55.610 --> 00:12:03.080
But remember that now, since our classifier, which is no longer called classifier, but a n n returns

210
00:12:03.160 --> 00:12:05.600
the predictions in the form of probabilities.

211
00:12:05.930 --> 00:12:11.540
Well, we just have to do a little something here, which is to, of course, convert are predicted

212
00:12:11.540 --> 00:12:16.700
probabilities which are in spread into predicted binary outcomes, zero or one.

213
00:12:16.910 --> 00:12:21.530
And the trick to do that is exactly the same as the trick we used here.

214
00:12:21.860 --> 00:12:30.170
It is, of course, to update y pred the following way by setting it equal to, well, the boolean result

215
00:12:30.440 --> 00:12:31.880
of weather y press.

216
00:12:32.040 --> 00:12:40.760
You know, the predicted probability is larger than 4.5 so that if Y spread is between zero and open

217
00:12:40.760 --> 00:12:44.960
five, then this new Y print will become zero because this won't be true.

218
00:12:45.260 --> 00:12:48.440
And if Wipro is larger than open five, then this will be true.

219
00:12:48.500 --> 00:12:50.900
And therefore Wipro will be equal to one.

220
00:12:51.170 --> 00:12:51.500
All right.

221
00:12:51.530 --> 00:12:55.520
And we'll get therefore the final predicted binary outcomes, zero or one.

222
00:12:56.120 --> 00:12:57.410
And then the rest is the same.

223
00:12:57.530 --> 00:12:58.370
All this is good.

224
00:12:58.790 --> 00:13:04.550
So let's play that cell and we'll get indeed displayed next to each other.

225
00:13:04.790 --> 00:13:10.070
First on the left, the vector of predictions y pred and on the right effect of real results.

226
00:13:10.250 --> 00:13:11.410
Why test?

227
00:13:11.780 --> 00:13:14.090
And now we don't have all the results displayed.

228
00:13:14.170 --> 00:13:15.890
That's because we have a lot of observations.

229
00:13:16.340 --> 00:13:19.460
But, you know, we can already see that the predictions look pretty good.

230
00:13:19.790 --> 00:13:22.370
That first customer of the test said be careful.

231
00:13:22.400 --> 00:13:24.440
That's all the customers of the test said.

232
00:13:24.620 --> 00:13:30.350
Well, that first customer in reality stayed in the bank and was predicted, indeed to stay in the bank.

233
00:13:30.680 --> 00:13:33.290
However, that second customer actually left.

234
00:13:33.320 --> 00:13:38.330
In reality, the bank but W predicted not to was predicted to stay in the bank.

235
00:13:38.810 --> 00:13:44.630
Then the third customer stayed in reality in the bank and was predicted to stay in the bank as well.

236
00:13:44.960 --> 00:13:50.180
And then for these three last customers of the test said, well, they in reality stayed in the bank

237
00:13:50.300 --> 00:13:52.640
and were predicted to stay indeed in the bank.

238
00:13:52.670 --> 00:13:54.340
So the results look really good.

239
00:13:54.650 --> 00:14:01.640
But the real way to check this is with our confusing metrics and therefore here in our logistic regression

240
00:14:01.640 --> 00:14:03.750
tool, you know, code template.

241
00:14:03.950 --> 00:14:10.310
Well, we just have to scroll down a little bit more to find the code for the confusing matrix and also

242
00:14:10.460 --> 00:14:12.290
the computation of the accuracy.

243
00:14:12.680 --> 00:14:13.760
So let's just get this.

244
00:14:14.090 --> 00:14:17.380
Then let's just copy that into a new code cell.

245
00:14:17.900 --> 00:14:18.850
This just pasted.

246
00:14:19.040 --> 00:14:24.980
And now are you ready to get the final accuracy of your very first artificial neural network on the

247
00:14:24.980 --> 00:14:25.670
test set?

248
00:14:25.780 --> 00:14:26.070
Right.

249
00:14:26.270 --> 00:14:29.630
Meaning on new customer on which the model wasn't trained.

250
00:14:29.960 --> 00:14:31.490
Well, let's check this out right now.

251
00:14:31.520 --> 00:14:32.720
Let's play that cell.

252
00:14:32.900 --> 00:14:34.910
And very good.

253
00:14:35.150 --> 00:14:38.930
We get an accuracy over 86 percent.

254
00:14:39.050 --> 00:14:42.860
That's really good because it means that out of 100 customers.

255
00:14:43.200 --> 00:14:48.380
Well, eighty six were predicted correctly to either stay in or leave the bank.

256
00:14:48.650 --> 00:14:51.620
And we can actually see here the details of these predictions.

257
00:14:52.070 --> 00:14:57.470
We had 1520 correct predictions that the customer stays in the bank.

258
00:14:57.980 --> 00:14:59.590
Then we had 203.

259
00:14:59.800 --> 00:15:02.350
Correct predictions that the customer leaves the bank.

260
00:15:02.710 --> 00:15:07.150
Then we have 75 incorrect predictions that the customer leaves the bank.

261
00:15:07.510 --> 00:15:12.040
And 202 incorrect predictions that the customer stays in the bank.

262
00:15:12.640 --> 00:15:14.080
So anyway, that looks pretty good.

263
00:15:14.110 --> 00:15:17.590
Accuracy of 86 percent is a very decent accuracy.

264
00:15:17.890 --> 00:15:23.590
Of course, I challenge you to beat that, you know, to at least get one or two extra percent of accuracy.

265
00:15:23.950 --> 00:15:28.250
But I actually experimented in myself, and it will be pretty hard to beat this.

266
00:15:28.270 --> 00:15:30.100
So don't waste too much time on this.

267
00:15:30.400 --> 00:15:36.190
Plus, I rather Anchorage's you to check out this free cause that we have on artificial new network

268
00:15:36.190 --> 00:15:41.680
for regression, because I'd really like you to do anything you want with artificial neural networks,

269
00:15:41.680 --> 00:15:49.090
whether it is to do classification for either a binary outcome or a non binary outcome or regression.

270
00:15:49.330 --> 00:15:49.660
Right.

271
00:15:49.780 --> 00:15:55.280
With this course plus the other free course, you'll know how to do anything with artificial new networks.

272
00:15:55.510 --> 00:15:57.640
So that's rather my recommendation.

273
00:15:57.880 --> 00:16:01.120
And now, of course, I want to say a final congratulations.

274
00:16:01.380 --> 00:16:07.090
You completed a very advanced branch of machine learning so you can really be proud of your progress.

275
00:16:07.450 --> 00:16:08.800
And if you're not too overwhelmed.

276
00:16:09.010 --> 00:16:14.020
Well, it's stunned to reach an even higher level with convolutional neural networks.

277
00:16:14.290 --> 00:16:17.350
So as soon as you feel ready for it will join us.

278
00:16:17.440 --> 00:16:22.510
Carol and I in the next section to tackle convolutional neural networks.

279
00:16:22.870 --> 00:16:23.650
And until then.

280
00:16:23.790 --> 00:16:24.970
And Joy machine learning.
