WEBVTT
1

00:00:00.690  -->  00:00:03.190
Hello welcome back to the course on machine learning.

2

00:00:03.330  -->  00:00:09.490
In today's Tauriel I'm going to show you my solution of the challenge that I threw at you last.

3

00:00:09.740  -->  00:00:15.450
So in the previous tutorial we had the challenge to calculate the posterior probability of somebody

4

00:00:15.450  -->  00:00:21.540
being a person that drives to work and given that they are placed in a position where we are placing

5

00:00:21.630  -->  00:00:24.530
the new observation for our daughter said.

6

00:00:24.660  -->  00:00:29.830
So basically what is the likelihood of that new observation or presenting a person who drives to work

7

00:00:29.840  -->  00:00:30.040
.

8

00:00:30.330  -->  00:00:35.240
And the way we each calculate is using the Bayes Theorem which is right in front of us.

9

00:00:35.440  -->  00:00:36.710
Now we're going to walk through it.

10

00:00:36.800  -->  00:00:41.250
We're going to calculate the probability then we calculate the marginal likelihood and then we're going

11

00:00:41.250  -->  00:00:45.400
to calculate likelihood and we can compare along the way.

12

00:00:45.420  -->  00:00:47.250
If you got the same results.

13

00:00:47.430  -->  00:00:48.770
So let's go through it.

14

00:00:49.290  -->  00:00:50.500
So there's our data set.

15

00:00:50.520  -->  00:00:55.290
And now let's move to the left makes MySpace and the first thing we're going to calculate is the prior

16

00:00:55.290  -->  00:01:00.150
probability the prior probability this kind of two ways to think about it so the first way to think

17

00:01:00.150  -->  00:01:06.050
about it is if I just randomly select a person from our data set right now.

18

00:01:06.270  -->  00:01:11.340
So not including grade automatically then you datapoint if I randomly select a person from there what

19

00:01:11.340  -->  00:01:14.910
is the likelihood of them being a person who drives to work.

20

00:01:14.910  -->  00:01:15.360
Right.

21

00:01:15.480  -->  00:01:20.190
So that'll be just the number of the answer to that is the number of green does or the total number

22

00:01:20.190  -->  00:01:20.840
of dots.

23

00:01:21.150  -->  00:01:27.360
The other way to think about it is if I just randomly throw a new data point into our data set right

24

00:01:27.360  -->  00:01:33.540
just randomly and without knowing anything about their age or salary then just knowing all of this prior

25

00:01:33.540  -->  00:01:38.490
information that we have the green dots and the red dots What is the likelihood of that person that

26

00:01:38.490  -->  00:01:43.050
we're adding or is there a likelihood to be a person who drives to work.

27

00:01:43.170  -->  00:01:49.200
Again we don't have is very simple because we don't have any other choice but to calculate the probability

28

00:01:49.200  -->  00:01:54.510
and assign the probability just based on what we know and that is just to take the green dots the 20

29

00:01:54.540  -->  00:01:59.130
green dots divide by the total number of dots here and assign that as a probability.

30

00:01:59.130  -->  00:02:03.260
So we don't have any other choice and therefore that's what it's calculated as.

31

00:02:03.300  -->  00:02:09.000
So the probability of somebody being a person who drives to work or a random Daut selected out of our

32

00:02:09.000  -->  00:02:15.030
existing dots being a person who drives to work is the number of drivers which is 20 divided by total

33

00:02:15.030  -->  00:02:16.310
duration which is 30.

34

00:02:16.330  -->  00:02:18.110
So 20 or 30.

35

00:02:18.420  -->  00:02:20.930
So that was the prior probability we've done that.

36

00:02:20.940  -->  00:02:23.120
Next one is a marginal likelihood.

37

00:02:23.220  -->  00:02:29.070
So let's go ahead and calculate that and you'll find that the marginal likelihood is actually going

38

00:02:29.070  -->  00:02:31.910
to be exactly the same as in the previous tutorial.

39

00:02:31.920  -->  00:02:33.410
And we'll talk about this separately.

40

00:02:33.540  -->  00:02:39.100
So again we're going to draw a circle around our observation which remove observations.

41

00:02:39.100  -->  00:02:40.540
It's not in the way.

42

00:02:40.780  -->  00:02:42.800
We're going to shade in this area.

43

00:02:42.900  -->  00:02:49.230
And so now the marginal likelihood is the question What is the likelihood of if I just pick a random

44

00:02:49.230  -->  00:02:52.330
dot from our dataset just randomly.

45

00:02:52.410  -->  00:02:54.710
What is the likelihood that I'm going to pick one out of here.

46

00:02:54.710  -->  00:03:01.860
So what was the reason why we put X here it is because what is the likelihood of me picking a observation

47

00:03:02.010  -->  00:03:08.960
that exhibits features similar to the features of that point that we are adding to our data set.

48

00:03:08.970  -->  00:03:12.930
So the point we're adding to that is that we've just removed it is over there and we've agreed that

49

00:03:12.960  -->  00:03:21.000
any dot inside the circle is deemed to be similar to that data or in other words deemed to be exhibiting

50

00:03:21.000  -->  00:03:22.570
similar features.

51

00:03:22.650  -->  00:03:28.130
So similar age and similar salary to that dot and therefore that's what we're calculating.

52

00:03:28.140  -->  00:03:33.060
So X is very simple we just need to calculate the number of similar observations the number of objects

53

00:03:33.060  -->  00:03:38.460
that actually fall in here which is four divide by the total number observations which are 30 so that

54

00:03:38.460  -->  00:03:45.630
will give us the likelihood of a new dot falling here or the likelihood of if we just pick out a random

55

00:03:45.630  -->  00:03:51.210
dot from our data set right now then the likelihood of it being one of these is for over 30.

56

00:03:51.230  -->  00:03:51.690
There we go.

57

00:03:51.780  -->  00:03:53.020
Four or three.

58

00:03:53.370  -->  00:03:58.890
All right so that is our marginal likelihood done and now we're going to move on just the likelihood

59

00:03:59.280  -->  00:04:05.310
and this time is going to be the likelihood of somebody exhibiting the features of X or being similar

60

00:04:05.310  -->  00:04:11.760
to the data point that we're adding given that we're only looking at people who are driving to work

61

00:04:11.780  -->  00:04:12.100
.

62

00:04:12.420  -->  00:04:14.020
So let's have a look at that.

63

00:04:14.730  -->  00:04:21.000
Here's our data set and again we're going to draw the circle around our data point take it out and then

64

00:04:21.480  -->  00:04:22.600
add that shading.

65

00:04:22.620  -->  00:04:28.230
So now the question is given that we only dealing with people who drive to work what is the likelihood

66

00:04:28.380  -->  00:04:33.100
that if we pick one of them that that person will be exhibiting features similar to x.

67

00:04:33.420  -->  00:04:38.150
So because we're only dealing with the people who drive to work we can forget about the red dots.

68

00:04:38.180  -->  00:04:42.720
There are other shedded there faded out and now we're only dealing with the green dots.

69

00:04:42.720  -->  00:04:48.200
So the question is given that we're selecting a random point out of all the people that drive.

70

00:04:48.210  -->  00:04:53.390
So this vertical bar drives means given that a person drives to work.

71

00:04:53.400  -->  00:04:59.130
So we circled around him point out of these what is the likelihood that they will exhibit features similar

72

00:04:59.130  -->  00:05:07.080
to X which we agreed is the same as they fall inside the circle and the likelihood of that is one over

73

00:05:07.080  -->  00:05:08.940
the total number of green dots.

74

00:05:08.970  -->  00:05:10.260
So there we go.

75

00:05:10.260  -->  00:05:15.850
P of x given that they drive to work is the number of similar observation and on those who walk.

76

00:05:15.970  -->  00:05:21.690
So inside here is one similar meaning similar to our new points that were added and then divided by

77

00:05:21.690  -->  00:05:25.110
the total number of walkers and that's 20.

78

00:05:25.110  -->  00:05:29.220
So one over 20 that is our likelihood.

79

00:05:29.220  -->  00:05:29.880
There we go.

80

00:05:29.880  -->  00:05:33.980
So now we can plug these into the formula calculate the posterior probability.

81

00:05:34.020  -->  00:05:40.140
So it's going to be one over 20 times 21:30 two hours before with 30 and it's 0.25.

82

00:05:40.290  -->  00:05:42.360
So 25 percent.

83

00:05:42.390  -->  00:05:43.090
So there you go.

84

00:05:43.090  -->  00:05:49.760
That was step two all of our naive base algorithm or the based classifier.

85

00:05:49.830  -->  00:05:55.410
Hopefully you were able to fall long and also that I hope that you had chance to perform that exercise

86

00:05:55.410  -->  00:06:00.210
on your own and you got a similar result and that's it for today.

87

00:06:00.210  -->  00:06:01.880
I look forward to seeing you next time.

88

00:06:01.890  -->  00:06:03.720
And until then in machine learning
