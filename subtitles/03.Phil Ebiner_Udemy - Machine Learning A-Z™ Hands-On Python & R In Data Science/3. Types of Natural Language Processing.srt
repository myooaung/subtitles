1
00:00:00,870 --> 00:00:04,410
Hello and welcome back to the course on deep natural language processing.

2
00:00:04,530 --> 00:00:07,650
And today we're going to talk about the types of natural language processing.

3
00:00:08,310 --> 00:00:10,740
So we've got to then diagrams here.

4
00:00:10,960 --> 00:00:13,140
We've got a Ben diagram of two circles in it.

5
00:00:13,610 --> 00:00:23,970
And we are going to look at the different areas of natural language processing that are going to come

6
00:00:23,970 --> 00:00:24,580
up in discourse.

7
00:00:25,080 --> 00:00:29,250
So on the left, we've got natural language processing overall.

8
00:00:29,640 --> 00:00:33,240
And this refers to the whole circle on the left.

9
00:00:33,660 --> 00:00:38,520
So the reason why we've called in just this green part is because that's the non overlapping part.

10
00:00:38,550 --> 00:00:43,020
So we know that anything in here is just natural language processing.

11
00:00:43,110 --> 00:00:46,080
We've followed with disregard to the second circle.

12
00:00:46,320 --> 00:00:50,700
But natural language processing is indeed everything that is in this first circle.

13
00:00:51,370 --> 00:00:54,630
Then we've got on the right deep learning.

14
00:00:54,690 --> 00:01:01,410
So these are all algorithms that have something to do with neural networks, deep learning.

15
00:01:01,860 --> 00:01:04,770
Basically, anything that's called a deep learning algorithm falls in here.

16
00:01:04,800 --> 00:01:07,920
They don't have to be natural language processing.

17
00:01:07,950 --> 00:01:09,960
They can be classification.

18
00:01:10,590 --> 00:01:11,610
They can be anything.

19
00:01:11,700 --> 00:01:12,540
So they can be.

20
00:01:12,720 --> 00:01:14,070
That's deep learning here.

21
00:01:14,160 --> 00:01:19,380
And natural language processing is any algorithm, any model that has something to do with processing

22
00:01:19,380 --> 00:01:24,090
of natural language into machine terms.

23
00:01:25,320 --> 00:01:28,800
And then finally, in the overlap, we have deep MLP.

24
00:01:29,220 --> 00:01:35,910
So these are models which have to do with natural language processing, but also which are deep learning

25
00:01:35,910 --> 00:01:37,680
models, which are neural network models.

26
00:01:38,200 --> 00:01:42,030
And so that's the part that we're going to be aiming for.

27
00:01:42,390 --> 00:01:49,800
But it's also very good to have visibility of all three, because in this course we will be talking

28
00:01:49,800 --> 00:01:52,380
about some models that fall just in here.

29
00:01:52,500 --> 00:01:54,030
And then we'll be talking about models here.

30
00:01:54,330 --> 00:02:00,360
And it'll be good to compare and see how the world has changed over time and why these models are often

31
00:02:00,360 --> 00:02:01,440
better than these models.

32
00:02:02,760 --> 00:02:10,320
And the other thing to note here is that the size of these diagrams is not reflective of the importance

33
00:02:10,380 --> 00:02:12,900
or the volumes of these different fields.

34
00:02:12,920 --> 00:02:20,190
So I just said circles of the same size simply because we want a visual representation of of the overlap

35
00:02:20,190 --> 00:02:21,300
and that these fields exist.

36
00:02:21,750 --> 00:02:24,090
But don't take this size into account.

37
00:02:24,150 --> 00:02:26,220
It's not to scale at all.

38
00:02:27,210 --> 00:02:35,880
And finally, there is a another part, another part of this event diagram, which is very important

39
00:02:35,880 --> 00:02:36,330
to us.

40
00:02:36,780 --> 00:02:45,270
And it is this part of a here a sub section of the deep and LP called sequence to sequence.

41
00:02:45,330 --> 00:02:50,700
So sequence to sequence models are the most cutting edge, the most powerful models that exist right

42
00:02:50,730 --> 00:02:52,860
now for natural language processing.

43
00:02:52,890 --> 00:02:55,290
And that's what we're going to be looking at.

44
00:02:56,310 --> 00:03:00,900
So as you'll see throughout this course, we will make our way through the national language processing

45
00:03:00,900 --> 00:03:02,850
side of things in too deep an LP.

46
00:03:02,850 --> 00:03:05,370
And then we will go into sequence to sequence.

47
00:03:05,650 --> 00:03:07,410
It'll be a fun and exciting journey.

48
00:03:08,310 --> 00:03:13,410
And the other thing that I wanted to mention is you will also notice that throughout this course, even

49
00:03:13,410 --> 00:03:17,450
though it's focused on Chadbourne, so we won't be talking about just chat bots.

50
00:03:17,760 --> 00:03:24,810
We'll be looking at different examples of how these models from here and from here and from here can

51
00:03:24,810 --> 00:03:29,130
be applied to different things because the applications are huge.

52
00:03:29,190 --> 00:03:33,180
We can or we can apply them in our natural neural machine.

53
00:03:33,180 --> 00:03:37,100
Translation We can apply them in image captioning.

54
00:03:37,110 --> 00:03:42,120
We can apply them in speech recognition, questions and answers.

55
00:03:42,340 --> 00:03:43,950
Summarization, lots and lots of models.

56
00:03:43,950 --> 00:03:47,100
So we will be looking at different ones.

57
00:03:47,940 --> 00:03:49,290
And they will be of different types.

58
00:03:49,560 --> 00:03:54,330
So this map will come in handy as we go through the course and it will be popping up here and there.

59
00:03:54,600 --> 00:04:00,120
So I think it was very important for us to set the foundation right.

60
00:04:00,180 --> 00:04:01,560
So that now we're ready to proceed.

61
00:04:02,030 --> 00:04:07,020
And I can't wait to see you on the next material and until then, enjoy and deep and natural language

62
00:04:07,020 --> 00:04:07,680
processing.
