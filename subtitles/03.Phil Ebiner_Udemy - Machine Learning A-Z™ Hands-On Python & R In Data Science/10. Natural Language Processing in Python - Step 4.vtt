WEBVTT
1
00:00:00.150 --> 00:00:00.890
Hello my friends.

2
00:00:00.890 --> 00:00:01.770
Welcome back.

3
00:00:01.770 --> 00:00:05.940
Are you ready to finish and complete that cleaning of all our reviews.

4
00:00:05.940 --> 00:00:06.600
Let's do this.

5
00:00:06.600 --> 00:00:09.180
So just to recap on what we did so far.

6
00:00:09.180 --> 00:00:14.830
We made this follow up to you know treat each review separately and clean each of them separately.

7
00:00:14.970 --> 00:00:21.500
And the first thing we did for each of these reviews was to replace all these non letters by spaces.

8
00:00:21.510 --> 00:00:24.900
And basically all the punctuation by spaces.

9
00:00:24.900 --> 00:00:28.860
Then we turned all the letters into lowercase.

10
00:00:28.860 --> 00:00:34.400
So all these capital letters were turned into lowercase and finally we split it.

11
00:00:34.500 --> 00:00:40.620
Each review into its different words because now we were about to proceed with stemming which consist

12
00:00:40.740 --> 00:00:44.580
of simplifying each word by the root of the word.

13
00:00:44.580 --> 00:00:51.690
So for example Luft will be replaced by love and I remind that it's very important to do this to optimize

14
00:00:51.780 --> 00:00:57.720
the dimensionality of the sparse matrix which will be created through the next step with the bag of

15
00:00:57.720 --> 00:00:58.540
words moral.

16
00:00:58.560 --> 00:01:04.050
Indeed we will create that sparse matrix where each column is a word among all the different words of

17
00:01:04.050 --> 00:01:05.910
our different reviews after the cleaning.

18
00:01:06.180 --> 00:01:08.970
And therefore we need to simplify to the maximum.

19
00:01:09.150 --> 00:01:12.300
Well the different words that are going to be in this parse matrix.

20
00:01:12.330 --> 00:01:17.340
So it's very very important to apply stemming and that's what we're about to do right now.

21
00:01:17.340 --> 00:01:17.640
All right.

22
00:01:17.670 --> 00:01:21.000
So remember we imported this poorest demo class.

23
00:01:21.030 --> 00:01:24.000
That's exactly the class that will apply stemming.

24
00:01:24.000 --> 00:01:29.490
And so now the first thing we'll do is actually create an object of this class which we will call p

25
00:01:29.580 --> 00:01:33.800
s for you know poorest DMA in poorest demo is a particular type of stem.

26
00:01:33.800 --> 00:01:38.310
You can check it out online but that's basically the classic way of applying stemming.

27
00:01:38.310 --> 00:01:44.480
So P.S. And now we will just call the class Potter stem nerd.

28
00:01:44.580 --> 00:01:45.330
Perfect.

29
00:01:45.480 --> 00:01:49.250
Then adding some parenthesis and we don't have to enter any parameters.

30
00:01:49.380 --> 00:01:51.750
So let me actually scroll down a bit.

31
00:01:51.750 --> 00:01:52.350
All right.

32
00:01:52.380 --> 00:01:53.920
This will be easier for you.

33
00:01:54.310 --> 00:02:00.690
So Boris stammer now we have our object so basically we have our tool to apply the stemming and therefore.

34
00:02:00.780 --> 00:02:06.300
Well the next step will be exactly to apply stemming to this particular review we're dealing with right

35
00:02:06.300 --> 00:02:09.390
now inside this full loop iterating all the reviews.

36
00:02:09.390 --> 00:02:14.610
So the way we're going to do this because you know we have to place them to each of the words inside

37
00:02:14.610 --> 00:02:20.370
this review and the words have already been gathered separately by splitting this review.

38
00:02:20.370 --> 00:02:27.300
And therefore what we're going to do now is first well update our review again to become this time a

39
00:02:27.300 --> 00:02:34.590
list of all these separate words coming from the split but stamped you know after we applied stemming

40
00:02:34.770 --> 00:02:35.160
on them.

41
00:02:35.730 --> 00:02:40.500
And so now the question is how are we going to apply stemming to each of the words of the review.

42
00:02:40.500 --> 00:02:45.170
Well we're going to do that of course with a single row for loop as I like to call it.

43
00:02:45.210 --> 00:02:50.440
You know a full loop inside the same row which is you know usually applied to lists.

44
00:02:50.580 --> 00:02:53.790
And since now we actually have a list of the words in the reviews.

45
00:02:53.790 --> 00:02:55.580
Thanks to this step in here.

46
00:02:55.620 --> 00:03:01.140
Well we can totally apply this single rule for loop to iterate through all the words of the review and

47
00:03:01.140 --> 00:03:03.500
apply stemming to each of them.

48
00:03:03.510 --> 00:03:05.360
So let's actually start with this for loop.

49
00:03:05.460 --> 00:03:12.450
We're going to start with four which will iterate through all the word you know so word is just a iterator

50
00:03:12.450 --> 00:03:15.710
variable that will be equal to the different words of the review.

51
00:03:15.780 --> 00:03:19.770
So forward then in review.

52
00:03:19.820 --> 00:03:20.120
Right.

53
00:03:20.130 --> 00:03:23.040
Because review is now a list of different words.

54
00:03:23.070 --> 00:03:29.460
So it will iterate through all the different words of this review and then we will add something which

55
00:03:29.460 --> 00:03:34.710
is probably something you will see for the first time if you're new to Python but here after a single

56
00:03:34.710 --> 00:03:41.440
row for loop we can actually add a condition to omit some of the words we are iterating through.

57
00:03:41.550 --> 00:03:44.000
And according to you what do we want to commit.

58
00:03:44.010 --> 00:03:46.920
You know what do we want not to include in the full loop.

59
00:03:46.920 --> 00:03:48.510
Well that's of course.

60
00:03:48.510 --> 00:03:51.260
Remember them the stop words.

61
00:03:51.330 --> 00:03:51.680
Right.

62
00:03:51.690 --> 00:03:57.690
Remember we want to get rid of all the words that won't help us or you know that won't help the machine

63
00:03:57.690 --> 00:04:01.710
learning model to understand whether a review is positive or negative.

64
00:04:01.800 --> 00:04:04.530
And these include all the articles like the.

65
00:04:04.960 --> 00:04:10.020
And like an apple we would just keep Apple for example and even all the pronouns.

66
00:04:10.020 --> 00:04:17.760
You know like I you he she we you know then they all these words give us absolutely no hint to figure

67
00:04:17.760 --> 00:04:19.910
out whether review is positive or negative.

68
00:04:20.130 --> 00:04:23.070
And therefore we want to get rid of all these tough words.

69
00:04:23.070 --> 00:04:29.460
And that's again for the same purpose as stemming it is to simplify the final sparse matrix which will

70
00:04:29.460 --> 00:04:35.190
contain all the different words of all our reviews into columns so we not only want to simplify the

71
00:04:35.190 --> 00:04:40.080
different versions of words in the branches of words by only keeping their root but also we want to

72
00:04:40.080 --> 00:04:45.480
get with all the stop words in order not to include them in the sparse matrix and a way to do this.

73
00:04:45.500 --> 00:04:50.640
You know the way to omit these words when iterating through the different words in the review is by

74
00:04:50.640 --> 00:04:56.040
just adding f here and then and not you know you will understand after I finished this.

75
00:04:56.040 --> 00:05:05.740
So let me just write it if not word in the set off then I'm going to call the stop word module here.

76
00:05:05.750 --> 00:05:11.540
You know this stopwatch here from which I'm gonna get all the English stop words because you know our

77
00:05:11.540 --> 00:05:17.390
reviews are in English and the way to do this is to add here words and then in parentheses because that's

78
00:05:17.390 --> 00:05:18.050
a function.

79
00:05:18.050 --> 00:05:19.960
And then in quote English.

80
00:05:20.550 --> 00:05:21.150
OK.

81
00:05:21.290 --> 00:05:23.680
So we clearly understand what this means.

82
00:05:23.720 --> 00:05:30.050
It means that if the word of the review you know we're dealing with right now in this for loop if this

83
00:05:30.050 --> 00:05:38.540
word is not in the set you know the symbol of all the English stop word well we will consider it in

84
00:05:38.540 --> 00:05:41.450
this for loop and meaning we will apply the stemming.

85
00:05:41.450 --> 00:05:48.080
However if this word is in all these Stoppard's list well we want to include it in this for loop and

86
00:05:48.080 --> 00:05:52.780
therefore we won't apply the stem into it and therefore it won't be in the future sparse matrix.

87
00:05:52.880 --> 00:05:57.700
So you see the trick pretty cool but so far we only have the for loop and we don't know what we're gonna

88
00:05:57.710 --> 00:06:00.600
do for each of these words so we have to specify it now.

89
00:06:00.680 --> 00:06:06.010
And remember we have to specify this before the for loop because that's a single row for loop.

90
00:06:06.050 --> 00:06:11.750
And so what we're going to specify is of course that we want to apply the stemming to each of these

91
00:06:11.870 --> 00:06:14.680
words in the review which are not just upwards.

92
00:06:14.750 --> 00:06:17.600
And so now the question is how do we apply this timing.

93
00:06:17.810 --> 00:06:23.030
Well remember we just created our poorest demo object so we're going to start with this calling our

94
00:06:23.030 --> 00:06:29.720
object from which we're gonna call a specific method which is exactly the stem method that will apply

95
00:06:29.720 --> 00:06:30.580
to stemming.

96
00:06:30.710 --> 00:06:36.170
And since it has method and adding some parentheses and now I'm sure you guessed perfectly what's inside

97
00:06:36.350 --> 00:06:38.720
these Parentheses you know what must be inside.

98
00:06:38.720 --> 00:06:40.530
And that's of course our word.

99
00:06:40.660 --> 00:06:41.110
Right.

100
00:06:41.120 --> 00:06:44.450
Our word on which we want to apply stemming and now.

101
00:06:44.450 --> 00:06:46.980
There you go my friends all this line of code.

102
00:06:47.120 --> 00:06:54.380
Apply this timing to all the words in your review except the stop words except all the non relevant

103
00:06:54.380 --> 00:06:58.910
words that are not helpful to predict whether a review is positive or negative.

104
00:06:58.940 --> 00:06:59.550
Great.

105
00:06:59.570 --> 00:07:00.770
So that's a good step down.

106
00:07:00.770 --> 00:07:07.100
Now you know how to replace Deming to a review and now since we actually have are different words in

107
00:07:07.100 --> 00:07:12.080
the review into a list we will just join them back together because you know we actually had to do this

108
00:07:12.260 --> 00:07:17.210
in order to easily apply this Deming to all the words thanks to this full loop but now that it's done

109
00:07:17.210 --> 00:07:22.970
we will just join these words back together to get the original format of the review you know as a string

110
00:07:23.270 --> 00:07:29.600
and therefore the way to do this is to well you know update our review variable again by setting it

111
00:07:29.660 --> 00:07:35.990
equal to well the junction of these different words after we applied stemming to them and the way to

112
00:07:35.990 --> 00:07:43.850
do this is by calling the join function which takes us input exactly well our list you know the review

113
00:07:43.880 --> 00:07:49.520
which contains a list of the different words after stemming was applied to them and however if we join

114
00:07:49.520 --> 00:07:54.950
them this way this will you know stick the words together and we will end up with one word that makes

115
00:07:54.950 --> 00:07:55.770
no sense.

116
00:07:55.790 --> 00:08:02.030
So in order to separate these words by a space you know as an eclectic string or text well we just looked

117
00:08:02.030 --> 00:08:09.140
at here in quotes and then inside of quotes we add a space and then separating this with the join review

118
00:08:09.350 --> 00:08:10.560
by a dot.

119
00:08:10.610 --> 00:08:10.870
All right.

120
00:08:10.880 --> 00:08:18.430
So this will not only join your review but also adding space between each word of your review.

121
00:08:18.440 --> 00:08:18.920
All right.

122
00:08:19.400 --> 00:08:19.880
So good.

123
00:08:19.880 --> 00:08:21.580
Now you know how to do this as well.

124
00:08:21.590 --> 00:08:24.290
And finally we have a final step here.

125
00:08:24.290 --> 00:08:25.570
I'm sure you guess what it is.

126
00:08:25.580 --> 00:08:29.970
Otherwise please press pause to just finish this cell implementation.

127
00:08:29.970 --> 00:08:31.250
But that's pretty obvious.

128
00:08:31.310 --> 00:08:35.340
All we did here was a transformation on a single review.

129
00:08:35.420 --> 00:08:41.030
And thanks to this for looking out all the different reviews of our data set will be transformed and

130
00:08:41.030 --> 00:08:43.550
will be cleaned and essentially will be simplified.

131
00:08:43.790 --> 00:08:49.940
But now remember we have this corpus here that was initialized as an empty list and we want to add all

132
00:08:49.940 --> 00:08:55.850
these client reviews into the corpus because that's what will be expected by the method of the class

133
00:08:55.940 --> 00:08:58.690
that will create the bag of words model.

134
00:08:58.820 --> 00:09:03.210
And therefore we must absolutely now add each review to the corpus.

135
00:09:03.320 --> 00:09:11.810
And the way to do this is by taking our corpus list and then call the append function to append indeed

136
00:09:12.020 --> 00:09:17.060
the review and that's it my friends we are done with the cleaning of the texts.

137
00:09:17.060 --> 00:09:18.960
So now we're going to execute this.

138
00:09:18.960 --> 00:09:19.910
You know I think we deserve it.

139
00:09:19.910 --> 00:09:22.390
That was quite a long cell implementation.

140
00:09:22.490 --> 00:09:23.140
So let's do this.

141
00:09:23.140 --> 00:09:25.610
However my runtime actually stopped.

142
00:09:25.610 --> 00:09:31.650
So I have to restore it by clicking You know runtime and then restart runtime I will re execute the

143
00:09:31.650 --> 00:09:36.200
two for sales and this one and we'll make sure that everything works correctly.

144
00:09:36.200 --> 00:09:37.080
All right.

145
00:09:37.100 --> 00:09:37.880
All good here.

146
00:09:37.880 --> 00:09:38.730
Let's do this.

147
00:09:38.870 --> 00:09:45.420
Let's first re-employ the libraries done imported dataset done as well.

148
00:09:45.420 --> 00:09:46.790
And now let's see.

149
00:09:46.810 --> 00:09:49.410
And let's hope we didn't make any mistake.

150
00:09:49.410 --> 00:09:54.940
Let's play this cell cleaning all the texts all the reviews and it seems to be all good.

151
00:09:54.960 --> 00:09:57.360
And yes this is what we're supposed to get.

152
00:09:57.360 --> 00:09:58.120
Perfect.

153
00:09:58.140 --> 00:10:04.380
So here it downloaded the you know stop words package from this path containing all the anti-gay data

154
00:10:04.770 --> 00:10:10.770
and also it's unzipped this zip file containing all the stoppers and perfect and then of course it applied

155
00:10:10.860 --> 00:10:15.900
all this cleaning process to each of the reviews and adding them to the final chorus.

156
00:10:15.930 --> 00:10:21.750
Perfect so now now it is time for the next essential step when doing sentiment analysis.

157
00:10:21.750 --> 00:10:27.240
It will be to create the bag of words model which will consist basically of creating this past matrix

158
00:10:27.510 --> 00:10:31.310
containing now all the words of the reviews after they were cleaned.

159
00:10:31.410 --> 00:10:35.640
So we will take all the different words of all the reviews will put them in different columns of the

160
00:10:35.640 --> 00:10:41.580
sparse matrix and then that will be actually our future matrix of features which we will combine to

161
00:10:41.580 --> 00:10:47.280
the dependent variable vector containing all the binary outcomes to train our future machinery model

162
00:10:47.280 --> 00:10:53.040
which will be a need based model to learn the text and understand whether the reviews are positive or

163
00:10:53.040 --> 00:10:54.060
negative.

164
00:10:54.060 --> 00:10:58.540
So I can't wait to proceed to this next step creating the bag of words model with you.

165
00:10:58.540 --> 00:11:00.530
And until then enjoy machine learning.
