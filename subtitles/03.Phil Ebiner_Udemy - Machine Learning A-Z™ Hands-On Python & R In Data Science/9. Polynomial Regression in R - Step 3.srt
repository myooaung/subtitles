1

00:00:00,360  -->  00:00:02,810
Hello and welcome to this are to Tauriel.

2

00:00:02,820  -->  00:00:08,280
So in the previews tutorials we made our first two steps of building or pulling of the regression model

3

00:00:08,670  -->  00:00:13,680
which were to preprocess the data and actually that was really simple because we just needed to import

4

00:00:13,680  -->  00:00:20,430
the data set and select the columns of interest and then we fully to morals to our data set the linear

5

00:00:20,430  -->  00:00:23,230
regression model and the polynomial regression model.

6

00:00:23,250  -->  00:00:28,560
So we build that in our regression model as a reference of comparison of the polynomial regression model

7

00:00:28,560  -->  00:00:29,660
that we also built.

8

00:00:29,880  -->  00:00:34,650
And speaking of comparison and this tutorial we are going to visualize the graphic results of these

9

00:00:34,650  -->  00:00:39,390
two models and therefore we're going to make two plots here one plot for each model where we're going

10

00:00:39,390  -->  00:00:42,450
to see the real observations and the predictions.

11

00:00:42,600  -->  00:00:47,790
And it's this toil that you're going to be convinced of how more powerful the polynomial regression

12

00:00:47,790  -->  00:00:50,750
model is compared to the linear regression.

13

00:00:50,970  -->  00:00:55,200
So right now let's write the code to visualize those results.

14

00:00:55,440  -->  00:01:01,710
So we're going to do this with GG plus two in case you didn't follow the linear regression tutorials

15

00:01:01,800  -->  00:01:02,700
on our.

16

00:01:02,760  -->  00:01:07,830
I'm just going to write a line to install the GGP to package I'm not going to install it just in case

17

00:01:07,830  -->  00:01:13,830
you don't have it and to check that you need to go to the packages here and check if you have the GDP

18

00:01:13,880  -->  00:01:14,860
to package here.

19

00:01:14,940  -->  00:01:19,110
And so if you don't find it in this list here you need to install it to install it.

20

00:01:19,110  -->  00:01:20,200
It's real simple.

21

00:01:20,220  -->  00:01:21,580
You just need to type here.

22

00:01:21,600  -->  00:01:30,000
Install that package just press enter here and then in quotes you enter the name of the package which

23

00:01:30,000  -->  00:01:31,350
is GGP up.

24

00:01:31,710  -->  00:01:36,810
And then you just need to select this line and execute a Islamic person commander control plus enter

25

00:01:36,810  -->  00:01:37,060
.

26

00:01:37,200  -->  00:01:41,030
And this will install the G-G to package without any issue.

27

00:01:41,190  -->  00:01:46,080
I'm not going to do it because mine is already installed but you can trust me it will work perfectly

28

00:01:46,100  -->  00:01:46,210
.

29

00:01:46,320  -->  00:01:50,100
So I'm going to put that as comment by pressing command shift policy.

30

00:01:50,100  -->  00:01:51,050
All right.

31

00:01:51,240  -->  00:01:55,690
And now we can start to visualize the linear regression results.

32

00:01:55,740  -->  00:02:01,980
So as you can see in the packages here the Juji party package is not selected here so I'm going to need

33

00:02:02,340  -->  00:02:03,380
to select here.

34

00:02:03,480  -->  00:02:08,900
So either I can take care or the better way is to automate the selection of this package.

35

00:02:08,970  -->  00:02:15,510
Thanks to the script and to do this we just need to add the line library and in parenthesis the name

36

00:02:15,510  -->  00:02:17,430
of the package with no quotes.

37

00:02:17,460  -->  00:02:19,880
So just gg plot to here this way.

38

00:02:19,980  -->  00:02:23,770
And when this line will be executed actually we can check it right now.

39

00:02:23,850  -->  00:02:26,040
As you can see G.G. but it is not selected.

40

00:02:26,250  -->  00:02:27,400
I'm executing this line.

41

00:02:27,450  -->  00:02:28,770
And now it's selected.

42

00:02:29,130  -->  00:02:34,330
OK so now that our GOT library is selected Let's start building the plot.

43

00:02:34,470  -->  00:02:39,180
So we're going to do exactly like in simple in our regression we're going to use the G-G plot function

44

00:02:39,720  -->  00:02:42,660
and then we're going to add the different components in the graph.

45

00:02:42,660  -->  00:02:47,390
So first we will add the real observation points thanks to the GM point function.

46

00:02:47,580  -->  00:02:50,400
And then we're going to add the predictions component.

47

00:02:50,430  -->  00:02:52,730
Thanks to the GM line function.

48

00:02:52,900  -->  00:02:57,650
Then we're going to add a title to the plus things to Juji title and then a label to the x axis with

49

00:02:57,660  -->  00:03:01,240
X lab and labeled the y axis with y lab.

50

00:03:01,260  -->  00:03:06,550
So very simple exactly like before we are going to make this graph step by step.

51

00:03:06,930  -->  00:03:09,290
OK so let's start with the first step.

52

00:03:09,390  -->  00:03:18,430
The first step is just to type here DZIEDZIC plot with parenthesis and that will initiate the plot.

53

00:03:18,490  -->  00:03:24,330
And now remember we need to add a plus here and that's where we start to add the different components

54

00:03:24,330  -->  00:03:24,690
.

55

00:03:24,690  -->  00:03:31,220
So the first component is the real observation points and we are plotting them with the GM point function

56

00:03:31,220  -->  00:03:31,260
.

57

00:03:31,260  -->  00:03:37,050
So let's add here GM point GM underscore point actually here it is.

58

00:03:37,110  -->  00:03:39,710
And we can put the arguments in the parenthesis.

59

00:03:39,970  -->  00:03:43,680
OK so the first argument remember is the aesthetic function.

60

00:03:43,800  -->  00:03:50,040
So that's in this function that we will input the x coordinates of our observation points as well as

61

00:03:50,040  -->  00:03:51,500
the y coordinates.

62

00:03:51,540  -->  00:03:53,070
So let's do this.

63

00:03:53,130  -->  00:03:55,450
He asks for a set function.

64

00:03:55,500  -->  00:04:03,450
So it this a static function we need to put the X go tonight and the y coordinates of all or 10 observation

65

00:04:03,450  -->  00:04:04,170
points.

66

00:04:04,170  -->  00:04:06,060
So let's see what these coordinates are.

67

00:04:06,090  -->  00:04:07,940
Let's have a look at our data set.

68

00:04:07,980  -->  00:04:13,380
So our 10 observation points are characterized by their levels and their salaries.

69

00:04:13,380  -->  00:04:20,400
The x coordinates corresponds to the independent variable that is the level column here and our y coordinates

70

00:04:20,400  -->  00:04:25,140
will be our 10 salary's here associated to these 10 levels here.

71

00:04:25,140  -->  00:04:28,960
So in short the x coordinates are the independent variable values.

72

00:04:29,040  -->  00:04:33,780
That is the 10 levels here and the y coordinates are the dependent variable values.

73

00:04:33,780  -->  00:04:35,730
That is the tensor is here.

74

00:04:36,000  -->  00:04:37,900
OK so let's end with that.

75

00:04:38,160  -->  00:04:44,530
So X here is level and Y is salary.

76

00:04:44,550  -->  00:04:51,870
However since we did not specify that the data is dataset here our data set we need to specify where

77

00:04:51,870  -->  00:05:00,650
we are taking the levels and the salaries and to specify that we need to add here dataset $ So that's

78

00:05:00,990  -->  00:05:06,310
our understands that we are taking the levels of our dataset dataset here.

79

00:05:06,440  -->  00:05:11,710
So it's going to be the same for why we're going to specify that we're taking the salaries of the column

80

00:05:11,730  -->  00:05:14,910
salary in our data sets this way.

81

00:05:14,900  -->  00:05:15,620
Perfect.

82

00:05:15,930  -->  00:05:22,710
And now we can add another argument because it's a static function was the first argument of this geom

83

00:05:22,700  -->  00:05:23,700
point function.

84

00:05:23,750  -->  00:05:30,000
And remember we can add a second argument which we will add because we want to add a color to our points

85

00:05:30,260  -->  00:05:34,730
then make distinction between the real observation points and the predictions.

86

00:05:34,820  -->  00:05:36,910
And so we're going to pick the red color.

87

00:05:36,920  -->  00:05:44,070
So here I'm going to add the color argument and set it equal to red in quotes.

88

00:05:44,060  -->  00:05:44,410
All right.

89

00:05:44,400  -->  00:05:49,020
And now let's not forget to close the parenthesis at the GM point function because this parenthesis

90

00:05:49,010  -->  00:05:53,790
was for the aesthetic function and now we are all fine.

91

00:05:53,880  -->  00:05:54,350
Great.

92

00:05:54,360  -->  00:05:58,380
And now let's add the second component which are the predictions.

93

00:05:58,440  -->  00:06:02,590
So I'm going to add a plus here and adds my second component here.

94

00:06:02,730  -->  00:06:08,210
So the second component is as I just said predictions and we are going to add these predictions component

95

00:06:08,510  -->  00:06:10,520
with the GM line function.

96

00:06:10,580  -->  00:06:13,270
So exactly like we did in simple in our regression.

97

00:06:13,560  -->  00:06:19,040
So Jim line here cheer him on the score line and then parenthesis of course.

98

00:06:19,130  -->  00:06:24,800
And again we're going to take the a static function combined to a caller.

99

00:06:24,810  -->  00:06:31,260
So I'm just going to copy all this right and paste it in my GM line function.

100

00:06:31,250  -->  00:06:31,630
All right.

101

00:06:31,690  -->  00:06:33,990
Now of course we'll change a few things.

102

00:06:34,050  -->  00:06:40,920
So first let's start with the simplest let's change a color we're going to pick a blue color for predictions

103

00:06:40,920  -->  00:06:41,780
.

104

00:06:41,780  -->  00:06:42,560
Here we go.

105

00:06:42,690  -->  00:06:48,310
And now what we need to change are the coordinates of our prediction points.

106

00:06:48,420  -->  00:06:54,290
So the x coordinates of our prediction points are still going to be the levels themselves because we're

107

00:06:54,300  -->  00:06:58,530
just predicting the salaries of the 10 levels that we have in our dataset.

108

00:06:58,520  -->  00:07:02,860
So here we obviously need to take the ONLY levels that we have in our dataset.

109

00:07:03,140  -->  00:07:06,680
So we keep here data set dollar level.

110

00:07:06,930  -->  00:07:12,550
But then for the y coordinates of course something is going to change here because by taking data set

111

00:07:12,560  -->  00:07:16,940
dollar salary here we're taking the real salaries of our 10 levels.

112

00:07:17,000  -->  00:07:20,750
That is the salaries that are in the salary column of our data set here.

113

00:07:21,240  -->  00:07:26,130
So of course we need to remove this and replace it by something else.

114

00:07:26,250  -->  00:07:28,240
And what is this something else going to be.

115

00:07:28,400  -->  00:07:33,920
Well of course it's going to be the predictions of the salaries of the 10 levels according to the linear

116

00:07:33,930  -->  00:07:39,700
regression model and to get these predictions we are going to use of course to predict function.

117

00:07:39,930  -->  00:07:45,240
And so actually that's exactly the same as in simple in our regression in this pretty function we first

118

00:07:45,240  -->  00:07:47,340
need to specify the regressors.

119

00:07:47,510  -->  00:07:52,850
So the regressors is called Lin rag because you know we're playing the linear regression results and

120

00:07:52,860  -->  00:07:55,860
our linear regression model was called Lin rag.

121

00:07:55,940  -->  00:08:01,880
That's our regressors leading right here and now the second argument I remember is new data.

122

00:08:01,980  -->  00:08:04,320
So new data here.

123

00:08:04,500  -->  00:08:08,380
And that's actually the data points we want to make predictions on.

124

00:08:08,510  -->  00:08:14,990
So very simply that our data set because we want to get the predictions of the salaries of the 10 levels

125

00:08:15,060  -->  00:08:16,090
of our dataset.

126

00:08:16,160  -->  00:08:19,790
So here are putting the dataset there.

127

00:08:20,000  -->  00:08:20,770
Perfect.

128

00:08:20,850  -->  00:08:26,270
So we're good because we already inputted the blue color for our predictions.

129

00:08:26,430  -->  00:08:27,260
Great.

130

00:08:27,260  -->  00:08:31,900
And now let's complete this graph very quickly by adding a titles of plus here.

131

00:08:32,100  -->  00:08:37,100
And then you know we used to G.G. title function to add a title.

132

00:08:37,130  -->  00:08:40,550
Can you see how it's simple it's starting to get really intuitive now.

133

00:08:40,560  -->  00:08:45,420
You know we were planning the real observation points with the GM point function then the predictions

134

00:08:45,410  -->  00:08:51,710
with the GM line function and now a title with the DG title function well everything will seem easier

135

00:08:51,720  -->  00:08:53,060
and easier for you.

136

00:08:53,460  -->  00:09:01,340
So for the title we're going to add azen but truth or bluff you know just to get a funny name to our

137

00:09:01,350  -->  00:09:01,980
problem.

138

00:09:02,250  -->  00:09:07,710
And we're going to specify here that we are applauding the linear regression results so we'll just specify

139

00:09:07,710  -->  00:09:11,820
here linear regression.

140

00:09:11,900  -->  00:09:12,710
All right.

141

00:09:12,720  -->  00:09:13,960
So that's it for the title.

142

00:09:13,980  -->  00:09:17,590
And now let's add an X label and a white label.

143

00:09:17,600  -->  00:09:25,140
So for the X label we're going to add something here X lab parenthesis in quotes and then level because

144

00:09:25,130  -->  00:09:38,190
our x axis will contain the levels and then plus y lab parenthesis quotes and salary and done the linear

145

00:09:38,180  -->  00:09:44,780
regression results are ready to be plotted so let's not wait anymore and let's immediately have a look

146

00:09:44,800  -->  00:09:45,050
.

147

00:09:45,300  -->  00:09:47,120
So I'm going to select all this.

148

00:09:47,370  -->  00:09:50,400
I don't need to select this because plot is already important.

149

00:09:50,690  -->  00:09:57,800
And now let's press commander control press enter to execute and hear other linear regression results

150

00:09:57,800  -->  00:09:57,930
.

151

00:09:57,950  -->  00:10:01,320
So let's zoom on it and let's interpretes great.

152

00:10:01,380  -->  00:10:03,650
OK so what is the first thing to understand here.

153

00:10:03,920  -->  00:10:09,230
Well the most important thing to understand is definitely that we need to make the distinction between

154

00:10:09,240  -->  00:10:12,620
the real observation points are the red points here.

155

00:10:12,620  -->  00:10:19,430
Each one correspond to one specific level and the real salary associated to this level on the y axis

156

00:10:19,430  -->  00:10:19,930
here.

157

00:10:20,120  -->  00:10:25,790
And then we have our predictions on this slide that is that for each level let's say for example the

158

00:10:26,270  -->  00:10:31,510
level 5 when we project this level 5 here on this straight line here.

159

00:10:31,580  -->  00:10:38,040
This point is actually our prediction point and we can get the predicted salary by projecting this point

160

00:10:38,030  -->  00:10:41,050
here on the y axis this way.

161

00:10:41,220  -->  00:10:44,590
And so we get a little less than $250000.

162

00:10:44,700  -->  00:10:44,950
OK.

163

00:10:44,960  -->  00:10:49,520
So that's the first thing to understand the red points are the real observation points and the points

164

00:10:49,520  -->  00:10:52,260
on this blue straightline are the prediction points.

165

00:10:52,430  -->  00:10:52,910
Okay.

166

00:10:53,000  -->  00:10:58,520
Now the second important thing to understand is that our prediction results is actually a straight line

167

00:10:58,520  -->  00:10:58,710
.

168

00:10:58,860  -->  00:11:03,780
And the fact that it's a straight line is due to a particular reason it's that the linear regression

169

00:11:03,770  -->  00:11:07,100
model is obviously a linear model.

170

00:11:07,310  -->  00:11:11,990
Each time you build a linear model in two dimensions you'll get a straight line.

171

00:11:12,170  -->  00:11:17,090
And I'm highlighting this because the next model we're going to visualize the results is going to be

172

00:11:17,100  -->  00:11:22,550
the polynomial regression my role and this model turns out to be a non linear regression model and you

173

00:11:22,550  -->  00:11:25,290
will see that it will not be a straight line anymore.

174

00:11:25,670  -->  00:11:27,410
And now let's give some interpretation.

175

00:11:27,440  -->  00:11:33,290
So first of all we can see that this linear regression model represented by this blue straight line

176

00:11:33,290  -->  00:11:34,840
here is not fitting.

177

00:11:34,860  -->  00:11:40,680
Our dear said very well because as you can see for some observation points the prediction is actually

178

00:11:40,670  -->  00:11:43,330
pretty far from the real observation.

179

00:11:43,350  -->  00:11:46,390
That's the case with this point and Zimpher this point as well.

180

00:11:46,580  -->  00:11:48,670
And this point and especially this one.

181

00:11:48,750  -->  00:11:50,630
Let's have a look at this point for example.

182

00:11:50,690  -->  00:11:59,510
While this point is the real observation point it corresponds to a 10 level and a 1 million dollar salary

183

00:11:59,510  -->  00:11:59,920
.

184

00:11:59,930  -->  00:12:02,260
So it's definitely the salary of the CEO.

185

00:12:02,300  -->  00:12:04,220
And so that's the real salary.

186

00:12:04,250  -->  00:12:08,870
And now if you want to get the predicted salary for this particular observation points that represents

187

00:12:08,870  -->  00:12:09,940
the CEO.

188

00:12:09,950  -->  00:12:15,680
What we need to do is project this point on this blue straight line here that is our linear regression

189

00:12:15,680  -->  00:12:18,180
model to get actually the prediction point.

190

00:12:18,200  -->  00:12:24,110
And now to get the predicted salary of the CEO we need to project again this prediction point onto the

191

00:12:24,120  -->  00:12:27,110
y axis that contains all the salaries.

192

00:12:27,500  -->  00:12:35,130
And so we obtained that the predicted salary of the CEO is actually $620000 according to our linear

193

00:12:35,250  -->  00:12:36,630
regression model.

194

00:12:36,650  -->  00:12:41,120
So imagine we're negotiating with a future employee that is about to be hired.

195

00:12:41,300  -->  00:12:44,000
And that was the CEO in its previous company.

196

00:12:44,000  -->  00:12:49,040
Imagine how furious this person will be if we tell this person that we believe it's bluffing because

197

00:12:49,040  -->  00:12:55,610
we think its salary is around $600000 whereas its previous salary was in reality one million dollars

198

00:12:55,620  -->  00:12:55,770
.

199

00:12:55,760  -->  00:12:58,680
The negotiation would probably turn really bad.

200

00:12:58,940  -->  00:13:05,270
So that's a first example of how this model can give poor results that can have a very negative impact

201

00:13:05,450  -->  00:13:09,490
on the situation like the negotiation we are having right now.

202

00:13:09,530  -->  00:13:16,110
So let's see if the negotiation would actually turn bad for our real situation that is this future input

203

00:13:16,130  -->  00:13:21,860
is about to be hired and that it has a 6.5 level and that is negotiating its salary by saying that its

204

00:13:21,870  -->  00:13:25,860
previous salary in the previous company was a hundred and sixty OK.

205

00:13:26,030  -->  00:13:31,470
Well let's see the 6.5 level corresponds to this level nearly.

206

00:13:31,670  -->  00:13:37,040
And when we project this level to our regression model that is this blue straight line here and if you

207

00:13:37,040  -->  00:13:42,100
project Again this point on the salary excess we get a predicted salary.

208

00:13:42,380  -->  00:13:44,300
Well it's more than $300000.

209

00:13:44,300  -->  00:13:45,650
Definitely so.

210

00:13:45,650  -->  00:13:50,600
Actually we're way above what this employee said its previous salary was.

211

00:13:50,610  -->  00:13:56,690
So actually in this situation in our real situation that negotiation would turn well for us but still

212

00:13:56,780  -->  00:14:02,120
we want to get the accurate prediction and clearly to do so we need to improve the model and make a

213

00:14:02,120  -->  00:14:07,940
non-linear model which will fit much better the observation point here that is that we will make some

214

00:14:07,940  -->  00:14:12,650
kind of a curve that will approach much better all the read observation points here.

215

00:14:12,870  -->  00:14:19,490
So let's do this let's close the linear regression results and lets start to visualize the polynomial

216

00:14:19,490  -->  00:14:25,610
regression results and you're going to see now how easy it is to go from the linear regression results

217

00:14:25,620  -->  00:14:33,830
to the polynomial regression results because what will simply do here is you know select this and paste

218

00:14:33,900  -->  00:14:38,300
it here and now we will see how we only need to change very few things.

219

00:14:38,300  -->  00:14:46,170
So as usual let's start with the simplest let's replace linear are here by polynomial OK.

220

00:14:46,370  -->  00:14:47,690
And now what do we need to change.

221

00:14:47,750  -->  00:14:51,310
OK so do we need to change something in the genome point function.

222

00:14:51,310  -->  00:14:55,070
No of course because we want to keep the same real observations.

223

00:14:55,140  -->  00:14:56,250
So that's OK.

224

00:14:56,470  -->  00:14:59,620
And then do we need to change something in the genome line function.

225

00:14:59,620  -->  00:15:06,910
Of course yes because here we were predicting the salaries of our 10 levels in our data set according

226

00:15:06,900  -->  00:15:08,750
to our linear regression model.

227

00:15:08,980  -->  00:15:11,450
So according to you what do we need to change here.

228

00:15:11,520  -->  00:15:12,370
Very simply.

229

00:15:12,460  -->  00:15:18,890
Well actually we just need to change the aggressor in the function and instead of taking DeLynn Raggatt

230

00:15:18,900  -->  00:15:25,010
which is the linear aggressor we're going to take the pulling on the repressor that we call POLLI rack

231

00:15:25,480  -->  00:15:26,260
and that's it.

232

00:15:26,470  -->  00:15:31,290
That's actually all we need to do to visualize the pulling on the regression results and you'll see

233

00:15:31,290  -->  00:15:34,020
that in the next sections it will actually be the same.

234

00:15:34,020  -->  00:15:41,230
We will only need to change a regress or two plus the new graphic results of our future regressors.

235

00:15:41,320  -->  00:15:42,700
So that's very nice.

236

00:15:42,700  -->  00:15:46,000
We're actually ready right now to visualize the putting on the results.

237

00:15:46,090  -->  00:15:47,950
So let's do this without waiting.

238

00:15:47,950  -->  00:15:54,310
I'm going to select this and press command and control press and to execute.

239

00:15:54,930  -->  00:15:55,990
And here it is.

240

00:15:55,990  -->  00:15:59,460
As you can see this is not a straight line anymore.

241

00:15:59,710  -->  00:16:02,200
Let's zoom on the graph.

242

00:16:02,270  -->  00:16:02,890
All right.

243

00:16:02,880  -->  00:16:08,860
So as I just mentioned the first reflex to have as a machine or any scientists is that this is not a

244

00:16:08,860  -->  00:16:10,280
linear model anymore.

245

00:16:10,300  -->  00:16:15,870
And by the way congratulations you just made your very first non-linear model.

246

00:16:16,210  -->  00:16:19,490
We're going to see plenty of other non-linear models in this course.

247

00:16:19,620  -->  00:16:20,970
But this is your first one.

248

00:16:21,100  -->  00:16:22,830
So congratulations.

249

00:16:22,840  -->  00:16:30,120
So as you can see it's not a straight line it's a curve and we can immediately see that the curve is

250

00:16:30,370  -->  00:16:34,050
approaching much better all the read observation points.

251

00:16:34,060  -->  00:16:37,240
And especially for the CEO here the CEO wouldn't get mad.

252

00:16:37,240  -->  00:16:43,300
Now if we negotiated with him it's future salary in a new company because now the prediction is much

253

00:16:43,300  -->  00:16:45,240
closer to the obsession point.

254

00:16:45,510  -->  00:16:54,000
And let's check our employee that is about to be hired and that has a 6.5 level while 6.5 is around

255

00:16:54,000  -->  00:16:54,690
here.

256

00:16:55,020  -->  00:17:02,320
And when we project 6.5 on our Paul Newman regression model represented by this blue curve here we get

257

00:17:02,590  -->  00:17:06,390
a predictive salary here I'm projecting the point on the curve.

258

00:17:06,630  -->  00:17:13,380
Back again on the salary access and we get actually a salary that is coming much closer to the salary

259

00:17:13,380  -->  00:17:17,710
mentioned by disputer employee which is around 160 k here.

260

00:17:17,720  -->  00:17:22,320
Well we don't get the accurate prediction here because that's what we're going to do in the next tutorial

261

00:17:22,350  -->  00:17:22,510
.

262

00:17:22,740  -->  00:17:27,250
But definitely this model is getting much better the set.

263

00:17:27,310  -->  00:17:32,980
And now just for fun let's add a new degree to see how this model can still be much improved and almost

264

00:17:32,970  -->  00:17:37,190
passing by all the points very accurately as we add more degrees.

265

00:17:37,360  -->  00:17:38,110
So let's check it out.

266

00:17:38,130  -->  00:17:40,840
Let's close this and let's add a new degree.

267

00:17:40,840  -->  00:17:49,420
So very simply what we're going to do is add a new degree here by copying this line pasted here and

268

00:17:49,410  -->  00:17:55,030
we're going to add a new column in our data dataset level 4 that will correspond to our original in

269

00:17:55,040  -->  00:17:57,900
the been invaluable level and the power for.

270

00:17:58,120  -->  00:18:05,350
And so therefore here we need to compute it this way by taking the fourth power of level there.

271

00:18:05,590  -->  00:18:11,600
And now let's execute this line to add the level 4 column in our data sets.

272

00:18:11,620  -->  00:18:14,470
Now you can check to see it here level for perfect.

273

00:18:14,530  -->  00:18:20,470
And now let's reset this to rebuild our new poll on the regression model with this fourth degree now

274

00:18:20,470  -->  00:18:20,510
.

275

00:18:20,560  -->  00:18:24,610
So executing new polynomial regression will all created.

276

00:18:24,760  -->  00:18:26,650
And now let's have a look at the results.

277

00:18:26,670  -->  00:18:31,770
So these are the previous results corresponding to a polynomial regression model with a third degree

278

00:18:31,790  -->  00:18:31,900
.

279

00:18:31,990  -->  00:18:34,670
And now let's look at what happens with fourth degree.

280

00:18:34,710  -->  00:18:37,900
So I'm going to select this and execute.

281

00:18:37,890  -->  00:18:44,560
And here are the polynomial regression results for a polynomial regression model with a fourth degree

282

00:18:44,580  -->  00:18:44,890
.

283

00:18:45,180  -->  00:18:45,520
OK.

284

00:18:45,520  -->  00:18:51,340
So as you can see we can zoom on it if you want as you can see the line is actually strictly passing

285

00:18:51,340  -->  00:18:53,250
by all the red opposition points.

286

00:18:53,260  -->  00:18:56,560
And now this year would be even happier with negotiation.

287

00:18:56,640  -->  00:19:03,270
Or should I say even less furious because the prediction now is actually almost the same as a real observation

288

00:19:03,280  -->  00:19:03,770
point.

289

00:19:03,790  -->  00:19:08,980
That is the predictive salary it's almost the same as the real salary.

290

00:19:09,490  -->  00:19:10,120
OK.

291

00:19:10,380  -->  00:19:16,810
And same for 6.5 level employee when we project this 6.5 level here on the curve.

292

00:19:16,990  -->  00:19:22,020
And then projecting again on the y axis that is the salary access we get a value around what he said

293

00:19:22,030  -->  00:19:23,820
that is 160 k.

294

00:19:23,970  -->  00:19:28,140
And for those of you who are interested in having a more continuous curve here like within and by then

295

00:19:28,300  -->  00:19:33,240
I will add the code for that job in the our file providing in the section you can check it out for fun

296

00:19:33,240  -->  00:19:33,510
.

297

00:19:33,630  -->  00:19:38,590
And this is them all over again to use to get the accurate prediction of the previous salary of this

298

00:19:38,590  -->  00:19:44,160
new employee that is about to be hired and we will compare it to the salary that he pretended to have

299

00:19:44,290  -->  00:19:50,370
in its previous company and eventually tell our final verdict whether it's truth or bluff.

300

00:19:50,380  -->  00:19:52,940
So I look forward to doing that with you in the next tutorial.

301

00:19:52,990  -->  00:19:54,910
And until then enjoy machine learning.
