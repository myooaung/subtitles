1
00:00:00,300 --> 00:00:07,190
Hello my friends and welcome to this new practical activity on multiple linear regression.

2
00:00:07,200 --> 00:00:12,210
So in this new section we're going to learn together how to build a multiple in our regression model

3
00:00:12,510 --> 00:00:16,640
on the same data set that was introduced by Carol in the previous lecturers.

4
00:00:16,710 --> 00:00:22,330
And just before we start I just want to make sure that everyone here is on the same page.

5
00:00:22,350 --> 00:00:28,200
This is the whole machine learning it is that folder containing all the code and data sets and right

6
00:00:28,200 --> 00:00:31,860
before this or I give you again the link to this folder.

7
00:00:32,100 --> 00:00:34,050
So make sure to connect to that link.

8
00:00:34,050 --> 00:00:39,780
And now we should be on the same page ready to start this new machinery model which is of course in

9
00:00:39,780 --> 00:00:46,020
part two regression and now we're going to go of course to multiple in our regression folder and we're

10
00:00:46,020 --> 00:00:49,310
going to start with Python to implement this model.

11
00:00:49,350 --> 00:00:49,930
All right.

12
00:00:50,010 --> 00:00:56,970
So this is the data set and this is the Python implementation in IP Wendy format which you can either

13
00:00:56,970 --> 00:01:00,600
open with Google collaboratively or Jupiter notebook.

14
00:01:00,600 --> 00:01:06,240
Make sure you also have the folder downloaded on your machine so that you can indeed get these files.

15
00:01:06,240 --> 00:01:06,510
All right.

16
00:01:06,510 --> 00:01:11,220
So before we start implementation let me just explain again what this dataset is about.

17
00:01:11,220 --> 00:01:18,540
So remember a venture capital is fund hired you as a data scientist to train a machine learning model

18
00:01:18,540 --> 00:01:24,900
and actually a multiple in our regression model to understand the correlations between these features

19
00:01:24,900 --> 00:01:32,100
which are the spend in R and D administration and marketing as well as the state and the profit of what

20
00:01:32,250 --> 00:01:34,170
of 50 startups.

21
00:01:34,170 --> 00:01:39,240
So in this dataset it's very important to understand that each row corresponds to a certain startup

22
00:01:39,540 --> 00:01:40,810
and for each startup.

23
00:01:40,920 --> 00:01:47,370
Well you data scientists collected the following data are bent administration spend marketing spend

24
00:01:47,460 --> 00:01:55,080
and the state of these trips and of course their profit because the goal for this V.C. fund is to figure

25
00:01:55,080 --> 00:01:58,860
out in which startup to invest based on these informations.

26
00:01:58,860 --> 00:02:03,240
So these are all information that we already know from 50 startups.

27
00:02:03,240 --> 00:02:08,040
And therefore if you managed to train a machinery model that can understand well these correlations

28
00:02:08,310 --> 00:02:14,730
well for the next door app you'll be able to deploy this model on these features to predict what sort

29
00:02:14,730 --> 00:02:17,070
of profit this new star might generate.

30
00:02:17,070 --> 00:02:17,640
Okay.

31
00:02:17,760 --> 00:02:21,750
So for this fund you definitely want to build an accurate model.

32
00:02:21,780 --> 00:02:22,200
All right.

33
00:02:22,200 --> 00:02:27,570
And now we can start the implementation but before we start I would like you to figure out what are

34
00:02:27,570 --> 00:02:30,540
going to be the first steps of this implementation.

35
00:02:30,540 --> 00:02:32,580
You know before I show it to you.

36
00:02:32,580 --> 00:02:32,820
All right.

37
00:02:32,820 --> 00:02:37,980
So first I hope that the first thing that came to your mind is that indeed the first step is the data

38
00:02:38,080 --> 00:02:39,060
repricing phase.

39
00:02:39,270 --> 00:02:43,320
And remember in a data pricing phase we start by empowering the libraries.

40
00:02:43,350 --> 00:02:44,290
That's for sure.

41
00:02:44,400 --> 00:02:47,730
Then we're going to import the data set that's even more for sure.

42
00:02:47,730 --> 00:02:52,380
And then we will split the dataset between the training set and the test set because indeed we want

43
00:02:52,380 --> 00:02:58,110
to train separately are moral and evaluate its performance on a separate test.

44
00:02:58,110 --> 00:02:58,390
Okay.

45
00:02:58,390 --> 00:03:04,230
So that's always required but then is there something else that we have to do here.

46
00:03:04,230 --> 00:03:09,910
Well to answer this question let's have a look at the cons one by one starting with oranges.

47
00:03:10,110 --> 00:03:14,040
So oranges spend is an American column you know containing numerical values.

48
00:03:14,040 --> 00:03:19,290
And when we scroll down you know we can't scroll down because there are only 50 observations corresponding

49
00:03:19,290 --> 00:03:23,060
to 50 strips and we can see that here there is no missing data.

50
00:03:23,070 --> 00:03:24,360
So all good.

51
00:03:24,360 --> 00:03:30,510
Then second column the administration spend all the spending administration like paying employees salaries

52
00:03:30,540 --> 00:03:31,560
or anything else.

53
00:03:32,070 --> 00:03:35,370
So this column is once again numerical with numerical values.

54
00:03:35,400 --> 00:03:38,610
And there is once again no missing data.

55
00:03:38,730 --> 00:03:39,270
Perfect.

56
00:03:39,300 --> 00:03:45,780
So so far are three steps of the day would be pressing template argued the next one column in marketing

57
00:03:45,780 --> 00:03:46,440
spend.

58
00:03:46,500 --> 00:03:49,860
Well same numerical column with no missing data.

59
00:03:50,190 --> 00:03:51,110
Oh good.

60
00:03:51,120 --> 00:03:56,250
And now this column you know the last feature I noticed once again that all the features are in the

61
00:03:56,250 --> 00:04:00,780
first columns and the dependent variable which you want to predict in the last column.

62
00:04:00,780 --> 00:04:07,110
So back to this state's future what reflex Do you have in your mind now you should have the reflex if

63
00:04:07,110 --> 00:04:10,440
you paid attention to parts one they would be pressing.

64
00:04:10,440 --> 00:04:17,040
Basically the question I'm asking now is do we need to apply a certain tool of our data repressing toolkit

65
00:04:17,340 --> 00:04:20,580
which would built in part 1 into this dataset.

66
00:04:21,060 --> 00:04:24,100
Well here the answer is obviously yes.

67
00:04:24,240 --> 00:04:28,470
Because indeed this state column is not numerical.

68
00:04:28,470 --> 00:04:35,010
It actually has some categories it has three categories which are New York California and Florida.

69
00:04:35,010 --> 00:04:39,510
And therefore that's exactly the same situation as in part one data processing.

70
00:04:39,510 --> 00:04:45,330
There is no order relationship between these three states New York California and Florida.

71
00:04:45,930 --> 00:04:52,350
And therefore we will have to apply one HUD encoding to that state column and therefore we'll have to

72
00:04:52,350 --> 00:04:55,290
grab a tool of our data pricing toolkit.

73
00:04:55,290 --> 00:05:01,930
And that's why I prepared it here in order to indeed one hot and cold that category called variable

74
00:05:01,960 --> 00:05:03,200
the state variable.

75
00:05:03,280 --> 00:05:03,950
All right.

76
00:05:04,060 --> 00:05:05,340
And then the profit is fine.

77
00:05:05,350 --> 00:05:06,940
It is numerical.

78
00:05:06,940 --> 00:05:09,760
And besides there is once again no missing data.

79
00:05:09,790 --> 00:05:12,470
So that's what you know you must do first.

80
00:05:12,490 --> 00:05:15,020
You need to have a look at your data set.

81
00:05:15,070 --> 00:05:17,940
If it is not too long you can check that there is no missing data.

82
00:05:17,980 --> 00:05:19,120
Like we just did.

83
00:05:19,120 --> 00:05:25,990
If it is too long then I recommend to apply your data pricing tool that handles missing data and deploy

84
00:05:25,990 --> 00:05:30,940
it on this data set and then you must check if any feature is categorical.

85
00:05:30,940 --> 00:05:33,070
And here we could check that very easily.

86
00:05:33,070 --> 00:05:34,270
The state is getting a.

87
00:05:34,270 --> 00:05:40,060
So we're going to apply our one hot encoding tool of our data repressing toolkit on the state column

88
00:05:40,630 --> 00:05:47,010
and then of course we will apply all the rest of the three essential steps of our data processing template

89
00:05:47,020 --> 00:05:52,150
and once again we will do that in a flashlight because this is a template where we only have one thing

90
00:05:52,150 --> 00:05:55,030
to change which is the name of the dataset.

91
00:05:55,060 --> 00:05:55,720
Are you ready.

92
00:05:55,870 --> 00:05:56,780
Let's do this.

93
00:05:56,800 --> 00:06:01,420
Let's start implementing are multiple linear regression model.

94
00:06:01,810 --> 00:06:04,650
So I just double clicked on it if you like Google collaborate.

95
00:06:04,660 --> 00:06:09,610
Feel free to open this link with me open with Google laboratory and if you don't like Google collaboratively

96
00:06:09,640 --> 00:06:14,890
that's totally fine you can open this file with Jupiter no book but from your folder which you downloaded

97
00:06:14,980 --> 00:06:16,090
on your machine.

98
00:06:16,090 --> 00:06:16,680
All right.

99
00:06:16,750 --> 00:06:17,670
Choose your favorite.

100
00:06:17,680 --> 00:06:19,070
And here we go.

101
00:06:19,150 --> 00:06:23,310
Let's implement are multiple in our regression model.

102
00:06:23,560 --> 00:06:24,090
All right.

103
00:06:24,100 --> 00:06:31,290
So first remember that this file is an read only mode which means that we can't modify it.

104
00:06:31,360 --> 00:06:37,750
But no worries we're going to create a copy right away by going to file here and then click Save a copy

105
00:06:37,960 --> 00:06:38,920
and drive.

106
00:06:38,920 --> 00:06:45,520
This will as you can see create a copy in which we will be able to reemployment this multiple in our

107
00:06:45,520 --> 00:06:52,000
regression mill from scratch because indeed I remind that this course is an action based course in which

108
00:06:52,060 --> 00:06:54,500
I want you to take action as much as you can.

109
00:06:54,580 --> 00:06:59,180
And therefore we are going to reemployment this whole model from scratch together step by step.

110
00:06:59,200 --> 00:07:04,300
And I really want you to code with me at the same time so that you know the practical skill can really

111
00:07:04,300 --> 00:07:06,190
be well integrated in your head.

112
00:07:06,410 --> 00:07:07,050
OK.

113
00:07:07,150 --> 00:07:07,900
So let's do this.

114
00:07:07,900 --> 00:07:14,530
Let's first start by removing all the code sales here and only the code sales not the text sales because

115
00:07:14,890 --> 00:07:20,860
I want to keep that well highlighted structure for this implementation.

116
00:07:20,950 --> 00:07:23,630
So here I am just removing all the code sales.

117
00:07:23,800 --> 00:07:24,430
There we go.

118
00:07:24,460 --> 00:07:25,620
And perfect.

119
00:07:25,630 --> 00:07:29,260
So this is the whole structure of this implementation we can have a look at it here.

120
00:07:29,410 --> 00:07:37,060
And indeed that's why you know I wanted to brainstorm on the dataset with you first before showing you

121
00:07:37,060 --> 00:07:41,580
the structure in order to make you think what we must do in the data repricing phase.

122
00:07:41,590 --> 00:07:46,160
And as we said we need for us to import the libraries that import the data set.

123
00:07:46,180 --> 00:07:46,810
That's for sure.

124
00:07:46,810 --> 00:07:47,980
And then here we go.

125
00:07:47,980 --> 00:07:54,640
We need to encode the categorical data and more specifically that state column which contains needs

126
00:07:54,640 --> 00:07:56,140
three categories.

127
00:07:56,140 --> 00:07:59,340
And then of course we split the dataset into the training center and test it.

128
00:07:59,350 --> 00:08:00,160
That's a must.

129
00:08:00,400 --> 00:08:06,510
And that will close the data repricing phase and we will all be ready to start training while first

130
00:08:06,520 --> 00:08:11,120
building and and training the multiple in our regression model on the training set.

131
00:08:11,290 --> 00:08:16,720
And by doing this our model will understand the correlations between all these bands of you know those

132
00:08:16,720 --> 00:08:19,480
strips and they're generated profit.

133
00:08:19,480 --> 00:08:26,140
And so there we go we will get a smart model which we will be able to use on new observations.

134
00:08:26,140 --> 00:08:30,340
And that's exactly what we'll do as a last step here to predict the test that results.
