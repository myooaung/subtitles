1
00:00:00,180 --> 00:00:01,230
All right let's do this.

2
00:00:01,230 --> 00:00:05,310
Let us begin our implementation of the natural language processing.

3
00:00:05,370 --> 00:00:12,660
Well you know branch of machinery but more specifically of an MLP model made for sentiment analysis.

4
00:00:12,660 --> 00:00:12,940
All right.

5
00:00:12,960 --> 00:00:17,120
So as usual we're going to start as much efficiently as we can.

6
00:00:17,130 --> 00:00:22,830
We're going to use our data processing template which I've of course prepared for this implementation

7
00:00:23,070 --> 00:00:28,110
which contains you know the code to import the libraries and import the dataset.

8
00:00:28,140 --> 00:00:30,180
So let's quickly start with the libraries here.

9
00:00:30,180 --> 00:00:31,390
I'm going to take them.

10
00:00:31,440 --> 00:00:37,530
I'm going to paste that right here in a new coat cell to indeed import the essential libraries you know

11
00:00:37,530 --> 00:00:38,820
just in case we need them.

12
00:00:38,850 --> 00:00:43,740
It doesn't mean that we will necessarily use all of them but at least we have them in case we need them.

13
00:00:43,740 --> 00:00:44,460
OK.

14
00:00:44,580 --> 00:00:47,900
Then in point of dataset let's create a new code.

15
00:00:48,000 --> 00:00:54,250
And now according to you do I have to take all the lines of code here or just this one to get the data

16
00:00:54,250 --> 00:00:55,110
set.

17
00:00:55,110 --> 00:01:00,420
Well as you might guess now we're going to do some different kind of data processing and therefore we'll

18
00:01:00,420 --> 00:01:07,320
just take this line of code to indeed import the reviews inside still a data set variable but then you

19
00:01:07,320 --> 00:01:11,790
will see that there will be a certain work needed before creating these two features.

20
00:01:11,790 --> 00:01:16,230
We will indeed create these two features at some point you know the matrix of features and the debate

21
00:01:16,230 --> 00:01:17,760
in vivo but not now.

22
00:01:17,760 --> 00:01:18,790
This is too early.

23
00:01:18,810 --> 00:01:22,460
We will have to clean the text first and prepare the bag of words model.

24
00:01:22,470 --> 00:01:27,750
And in fact we will create these two entities the matrix of features and it had been invaluable vector

25
00:01:28,110 --> 00:01:31,130
in the cell where we create the bag over tomorrow.

26
00:01:31,130 --> 00:01:31,490
Okay.

27
00:01:31,710 --> 00:01:39,480
So let's just take this for now the data set and back into our MLP implementation let us base that right

28
00:01:39,480 --> 00:01:45,990
here and now indeed we have to adapt this a little because now we're not dealing with a C as we fail

29
00:01:46,020 --> 00:01:52,110
we're dealing with a T as we fail with a feature as meaning the texts and the binary variable 0 or 1

30
00:01:52,410 --> 00:01:55,660
are separated by a tab instead of a comma.

31
00:01:55,680 --> 00:02:00,920
So first thing first let us replace this data set by the right name.

32
00:02:00,930 --> 00:02:04,810
You notice that I even included the extension because we'll have to change it.

33
00:02:04,860 --> 00:02:06,890
So the name of our dataset.

34
00:02:06,930 --> 00:02:08,470
Let's have a look again.

35
00:02:08,610 --> 00:02:12,910
Is restaurant reviews dot TSB.

36
00:02:12,980 --> 00:02:13,670
All right.

37
00:02:13,680 --> 00:02:15,570
So that's exactly what we'll replace here.

38
00:02:15,600 --> 00:02:21,320
Restaurant underscore reviews Dot T.

39
00:02:21,360 --> 00:02:21,790
S..

40
00:02:22,060 --> 00:02:22,690
Okay.

41
00:02:22,780 --> 00:02:30,370
And now since it is a T as we will have to add some extra parameters to specify that indeed we are dealing

42
00:02:30,370 --> 00:02:33,610
with a T as we felt instead of comma separated value.

43
00:02:33,650 --> 00:02:34,410
Yes.

44
00:02:34,660 --> 00:02:34,930
All right.

45
00:02:34,930 --> 00:02:39,750
And the way to do this is just to add one parameter here which is delimiter.

46
00:02:39,820 --> 00:02:40,630
All right.

47
00:02:40,630 --> 00:02:43,860
For which the default value is actually the comma.

48
00:02:43,900 --> 00:02:50,170
Meaning that the default data set that we can import with this read on this course is V isn't easy as

49
00:02:50,170 --> 00:02:50,450
V.

50
00:02:50,770 --> 00:02:56,890
But you know we can also use this read on this course as V function to import a t as we file and that's

51
00:02:56,890 --> 00:02:58,690
exactly what we're about to do now.

52
00:02:59,050 --> 00:03:04,360
But the way to specify that we're dealing with a T as we file is to enter the following value for this

53
00:03:04,420 --> 00:03:11,240
delimiter parameter which is in quotes this slash here backslash and T.

54
00:03:11,260 --> 00:03:11,680
All right.

55
00:03:11,680 --> 00:03:13,060
That's the value of the delimiter.

56
00:03:13,060 --> 00:03:18,680
You should enter to specify that your dataset is a T as you file but then that's not all we need to

57
00:03:18,760 --> 00:03:20,350
add one final parameter.

58
00:03:20,350 --> 00:03:27,350
A very important one when you're working with Dex I'm gonna show you something now in not this data

59
00:03:27,350 --> 00:03:33,070
set because we couldn't see the whole reviews but I'm gonna show you the whole dataset inside the folder

60
00:03:33,160 --> 00:03:38,000
machinery it is that which you could download once again in the article right before this trial.

61
00:03:38,050 --> 00:03:39,650
So let's open it.

62
00:03:39,700 --> 00:03:43,820
Let's go into parts of an MLP then MLP again and by phone.

63
00:03:43,870 --> 00:03:45,660
And that's the whole dataset.

64
00:03:45,760 --> 00:03:51,850
So I'm on Mac here so I'm going to open it with a classic text editor like text edit perfect we just

65
00:03:51,850 --> 00:03:53,920
need to have a look at the text quickly.

66
00:03:54,040 --> 00:03:55,000
There we go.

67
00:03:55,090 --> 00:04:02,470
And now I'm just gonna do a command or control F to find something which is a double quotes just like

68
00:04:02,470 --> 00:04:02,620
that.

69
00:04:02,650 --> 00:04:02,980
Okay.

70
00:04:03,730 --> 00:04:08,830
And as we see we can see that we have many double quotes within the text.

71
00:04:08,830 --> 00:04:09,700
All right.

72
00:04:09,730 --> 00:04:16,170
And in order to process this the right way you know when our machinery models learn how to read text.

73
00:04:16,330 --> 00:04:20,340
Well we'll have to say to our model to ignore the double quotes.

74
00:04:20,560 --> 00:04:26,260
Otherwise you know if you don't do it this can cause some processing or passing errors which you want

75
00:04:26,260 --> 00:04:29,330
to avoid you know because this can lead to an execution error.

76
00:04:29,350 --> 00:04:35,320
So I always recommend to add this quoting parameter and set its value to three which means actually

77
00:04:35,410 --> 00:04:38,070
no quotes or you know ignore the quote.

78
00:04:38,170 --> 00:04:40,990
So that indeed you can be free from processing errors.

79
00:04:40,990 --> 00:04:42,820
You can see there are many quotes.

80
00:04:42,820 --> 00:04:43,180
Right.

81
00:04:43,330 --> 00:04:48,010
So we're just going to ignore all of them as if you know there are just some different characters in

82
00:04:48,010 --> 00:04:49,030
the texts.

83
00:04:49,030 --> 00:04:49,460
All right.

84
00:04:49,480 --> 00:04:51,540
So that's all I wanted to show you.

85
00:04:51,580 --> 00:04:58,600
So now let's close this and let's go back to our implementation and to add this final parameter we need

86
00:04:58,600 --> 00:05:06,040
to add here quoting equals and the value of this coding parameter to ignore all the double quotes is

87
00:05:06,250 --> 00:05:06,970
three.

88
00:05:07,000 --> 00:05:07,630
All right.

89
00:05:07,720 --> 00:05:08,610
And now perfect.

90
00:05:08,890 --> 00:05:15,640
That's how you import correctly a TSB file which should be the format of a data set separating text

91
00:05:15,790 --> 00:05:18,430
and a binary outcome like 0 1.

92
00:05:18,430 --> 00:05:22,420
That's the classic way to proceed with sentiment analysis.

93
00:05:22,430 --> 00:05:23,200
So there we go.

94
00:05:23,260 --> 00:05:27,130
Well actually let's imported data set to make sure everything's all right.

95
00:05:27,130 --> 00:05:29,710
So we're going to click this folder here.

96
00:05:29,710 --> 00:05:36,610
Then it's going to take a little time you know a few seconds to connect this notebook to a runtime to

97
00:05:36,640 --> 00:05:43,480
enable file browsing but in a second and we should see that upload button here to indeed upload.

98
00:05:43,480 --> 00:05:44,290
There we go.

99
00:05:44,380 --> 00:05:45,420
The set.

100
00:05:45,460 --> 00:05:46,750
So let's click it.

101
00:05:46,900 --> 00:05:49,160
And now please find your machinery.

102
00:05:49,180 --> 00:05:54,070
It is that folder on your machine which you had to download either in the previous tutorial or at the

103
00:05:54,070 --> 00:05:55,730
beginning of each section.

104
00:05:55,740 --> 00:05:56,860
So now let's go inside.

105
00:05:56,860 --> 00:06:00,390
Let's go once again into port seven natural language processing.

106
00:06:00,460 --> 00:06:06,850
Then this section then python and then restaurant reviews the TSC let's click open.

107
00:06:06,850 --> 00:06:08,000
Let's click Okay.

108
00:06:08,080 --> 00:06:12,580
And now we're going to have that data set inside the notebook.

109
00:06:12,580 --> 00:06:12,870
All right.

110
00:06:12,880 --> 00:06:13,250
Perfect.

111
00:06:13,250 --> 00:06:18,010
So now let's run the sales first this cell where we import libraries.

112
00:06:18,010 --> 00:06:19,750
So simple one.

113
00:06:19,750 --> 00:06:23,010
And now this cell where we import the dataset.

114
00:06:23,080 --> 00:06:25,110
Let's do this let's make sure everything goes well.

115
00:06:25,120 --> 00:06:26,950
And there we go.

116
00:06:26,950 --> 00:06:29,080
Now we have the dataset ready.

117
00:06:29,080 --> 00:06:32,710
So that means we're ready for the next step cleaning the text.

118
00:06:32,740 --> 00:06:35,890
That's an essential step in natural language processing.

119
00:06:36,210 --> 00:06:41,010
I will show you all the techniques to make your text as clean as possible.

120
00:06:41,080 --> 00:06:43,780
And we will do all this in the next tutorial.

121
00:06:43,780 --> 00:06:45,580
Until then enjoy machine learning.
