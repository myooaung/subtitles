WEBVTT
1
00:00:00.630 --> 00:00:04.800
Hello and welcome back to the course on deep learning today we're talking about Max pooling and we've

2
00:00:04.800 --> 00:00:07.380
got some very exciting slides coming up ahead.

3
00:00:07.500 --> 00:00:10.930
And even a special surprise at the very end of the tutorial.

4
00:00:11.010 --> 00:00:12.440
So let's get started.

5
00:00:12.450 --> 00:00:15.860
The first question is what is pooling and why do we need it.

6
00:00:16.050 --> 00:00:19.650
Well to answer that question let's have a look at these images on these images.

7
00:00:19.650 --> 00:00:20.780
We've got a cheetah.

8
00:00:20.790 --> 00:00:23.680
In fact it is the same exact cheetah on the first image.

9
00:00:23.680 --> 00:00:29.640
That image is positioned properly and that she is looking straight at you on the second image.

10
00:00:29.640 --> 00:00:30.660
It's a bit rotated.

11
00:00:30.660 --> 00:00:32.710
And the third image a bit squashed.

12
00:00:32.790 --> 00:00:40.020
And the thing here is that we want the neural network to be able to recognize the cheetah in every single

13
00:00:40.020 --> 00:00:41.450
one of these images.

14
00:00:41.460 --> 00:00:43.230
In fact this is just one cheetah.

15
00:00:43.230 --> 00:00:45.070
What if we have lots of different shooters.

16
00:00:45.090 --> 00:00:46.120
Here's a cheetah.

17
00:00:46.180 --> 00:00:47.250
He is a cheetah.

18
00:00:47.400 --> 00:00:53.130
Here's another cheetah his Ashira his Ishida cheetah and he a cheetah and we want the neural network

19
00:00:53.130 --> 00:01:01.110
to recognize all of these shooters as cheaters and how can it do that if they're all looking in different

20
00:01:01.110 --> 00:01:06.300
directions they're all in different parts of the image they're like their faces are positioned in different

21
00:01:06.300 --> 00:01:10.080
parts of the image somebody is on the right hand side somebody in the left corner or somebody in the

22
00:01:10.080 --> 00:01:10.700
middle.

23
00:01:11.010 --> 00:01:14.280
They're all a bit different and the texture is a little bit different.

24
00:01:14.280 --> 00:01:16.200
The lighting is a bit different.

25
00:01:16.200 --> 00:01:21.600
There's lots of little differences and so if the neural network looks for exactly a certain feature

26
00:01:21.810 --> 00:01:29.700
for instance a distinctive feature of the cheetah is the tears that are on its face going from the eyes

27
00:01:29.700 --> 00:01:35.310
or the sheer The Shadow shadows that look like tears the texture of the pattern that is going from its

28
00:01:35.310 --> 00:01:40.890
eyes down it's on the sides of its nose and looks like tears that's a distinctive feature of the Cheetah.

29
00:01:40.890 --> 00:01:48.660
But if it's looking for that feature which it learned from certain cheetahs in an exact location or

30
00:01:48.660 --> 00:01:53.370
an exact shape or form or texture it will never find these other shooters.

31
00:01:53.460 --> 00:02:01.410
So we have to make sure that our neural network has a property called spatial invariance meaning that

32
00:02:01.440 --> 00:02:10.170
it doesn't care where the features are again not not so much as itch which part of the image because

33
00:02:10.520 --> 00:02:16.460
we're we've kind of taken that into consideration with our map we are poor with our convolutional there

34
00:02:16.800 --> 00:02:23.400
but it doesn't have to care if the features are a bit tilted if the features are a bit different in

35
00:02:23.400 --> 00:02:29.940
texture if the features are a bit closer of features or a bit further apart relative to relative to

36
00:02:29.940 --> 00:02:30.210
each other.

37
00:02:30.210 --> 00:02:37.230
So if the feature itself is a bit distorted our neural network has to have some level of flexibility

38
00:02:37.410 --> 00:02:39.930
to be able to still find that feature.

39
00:02:40.050 --> 00:02:42.690
And that is what pooling is all about.

40
00:02:42.690 --> 00:02:45.140
So let's have a look at how pooling works.

41
00:02:45.180 --> 00:02:51.090
Here's our feature map so we've already done our convolution and we've completed that part and now we're

42
00:02:51.090 --> 00:02:52.680
working with the convolutional there.

43
00:02:52.680 --> 00:02:53.880
Now we're going to apply pooling.

44
00:02:53.880 --> 00:02:54.690
So how does it work.

45
00:02:54.690 --> 00:02:56.420
We're going to be applying back pooling.

46
00:02:56.670 --> 00:03:01.640
There's several different types of play complies mean pooling Max pooling some pooling and will comment

47
00:03:01.710 --> 00:03:03.440
on those towards the end of the story.

48
00:03:03.540 --> 00:03:11.040
But for now we're just applying Max pooling so we take a box of two by two pixels like that and again

49
00:03:11.040 --> 00:03:15.020
it doesn't have to be two by two you can choose any size of box and again will comment on that towards

50
00:03:15.030 --> 00:03:21.900
and is Tauriel and you place it in the top left hand corner and you find the maximum value in that box

51
00:03:21.900 --> 00:03:26.310
and then you record only that value and you disregard the other three.

52
00:03:26.310 --> 00:03:30.600
So in your box you have four values you just disregard three you only keep one the maximum which is

53
00:03:30.600 --> 00:03:31.830
one in this case.

54
00:03:31.830 --> 00:03:36.210
Then you move your box to the right by stride you select the stride once again.

55
00:03:36.210 --> 00:03:41.850
So here we slide to stride of two and that's what you normally psyched you can say like the stride of

56
00:03:41.850 --> 00:03:42.880
one you can select.

57
00:03:42.990 --> 00:03:47.940
So there are overlapping boxes you can select any kind of strike that you like even three if you want

58
00:03:48.770 --> 00:03:52.440
but we're selecting a stride of two here and that's what is commonly used.

59
00:03:52.470 --> 00:03:57.660
And then you repeat the repeat the process you record that maxim here if you cross over and doesn't

60
00:03:57.660 --> 00:04:00.080
matter you just keep continue doing what you're doing.

61
00:04:00.090 --> 00:04:05.690
So you still record the maximum here 0 here the maximum is four.

62
00:04:05.700 --> 00:04:11.380
Here are the maximums to here the maximum is 1 0 1 or 2 and then 1.

63
00:04:11.400 --> 00:04:13.970
So as you can see a few things happened.

64
00:04:13.980 --> 00:04:18.890
First of all we still were able to preserve the features right.

65
00:04:19.080 --> 00:04:23.730
The maximum numbers they represent because we know how the conclusion Lehre works.

66
00:04:23.730 --> 00:04:28.650
We know that the maximal or the large numbers in your feature map they represent where you actually

67
00:04:28.650 --> 00:04:31.480
found the closest similarity to a feature.

68
00:04:31.650 --> 00:04:38.250
But by then pooling these features we are first of all getting rid of 75 percent of the information

69
00:04:38.250 --> 00:04:46.110
that is not the feature which is which is not the important things that we're looking out for because

70
00:04:46.220 --> 00:04:49.410
we're just really three pixels out of four.

71
00:04:49.710 --> 00:04:51.510
So we're only getting 25 percent.

72
00:04:51.510 --> 00:05:00.260
And and then also because we are taking the maximum of the pixels that we or the values that we have

73
00:05:00.770 --> 00:05:04.160
we are therefore accounting for any distortion.

74
00:05:04.160 --> 00:05:12.810
So for instance two images in which for example the cheater's tears on the eyes are in one image there

75
00:05:12.830 --> 00:05:16.550
a bit to the left or a bit rotated to the left and another one there a bit.

76
00:05:16.580 --> 00:05:22.100
And are how they're supposed to be or how we like if you take one as the bases and another one there

77
00:05:22.100 --> 00:05:23.800
are bits rotate to the left.

78
00:05:24.060 --> 00:05:26.570
The puled feature will be exactly the same.

79
00:05:26.570 --> 00:05:32.900
So you can see here if we are talking about the cheater's tears then let's say this is the four and

80
00:05:32.900 --> 00:05:36.050
this is where it was here then if it was a bit rotated.

81
00:05:36.050 --> 00:05:38.270
So for instance the four ended up over here.

82
00:05:38.390 --> 00:05:44.180
Then when we are doing the pooling we're still going to get the same pool feature map and that's kind

83
00:05:44.180 --> 00:05:46.270
of the principle behind it.

84
00:05:46.430 --> 00:05:52.340
It's a very rough explanation again intuitive explanation but that's the point of pooling that we're

85
00:05:52.340 --> 00:06:00.290
still being able to preserve the features and moreover account for their possible spatial or textural

86
00:06:00.290 --> 00:06:02.330
or other kind of distortions.

87
00:06:02.420 --> 00:06:07.370
And in addition to all of that we are reducing the size so there's another benefit.

88
00:06:07.370 --> 00:06:13.520
So we've got we're preserving the features we're introducing spatial invariants we're reducing the size

89
00:06:13.520 --> 00:06:19.700
by 75 percent which is huge which is really going to help us in terms of processing.

90
00:06:19.870 --> 00:06:25.970
And moreover another benefit of pooling is we are reducing the number of parameters so we're reducing

91
00:06:26.690 --> 00:06:31.370
again by 75 percent or reducing number of parameters that are going to go into our final Lares of the

92
00:06:31.370 --> 00:06:35.270
neural network and therefore we're preventing overfitting.

93
00:06:35.300 --> 00:06:42.580
It is a very important benefit of pooling that we're removing information and that is a good thing.

94
00:06:42.590 --> 00:06:50.660
That is a good thing because that way our model won't be able to over fit onto that information because

95
00:06:50.690 --> 00:06:54.500
especially because that information is not well and remember like at the very start we're talking about

96
00:06:54.950 --> 00:07:00.650
even for human as humans it's important to see exactly the features rather than all this other noise

97
00:07:00.650 --> 00:07:02.520
that is coming into our eyes.

98
00:07:02.780 --> 00:07:09.070
Well same thing for neural networks they by disregarding the unnecessary non-important formation we're

99
00:07:09.080 --> 00:07:12.470
helping with preventing of overfitting.

100
00:07:12.500 --> 00:07:14.590
So there we go that is what pooling is about.

101
00:07:14.600 --> 00:07:21.500
And the question here is of course why WiMax pooling right there's lots of different types of pooling

102
00:07:21.710 --> 00:07:26.780
and a wide wide stride of too wide a size of two by two pixels lots of all these things.

103
00:07:26.780 --> 00:07:33.980
And on that note I'd like to introduce you to this lovely research paper called evaluation of pooling

104
00:07:33.980 --> 00:07:40.250
operations in convolutional architectures for object recognition by Dominic Scherrer from University

105
00:07:40.250 --> 00:07:41.100
of Bonn.

106
00:07:41.180 --> 00:07:47.540
There is the link and the beauty about this paper is that it's very very simple very straightforward

107
00:07:47.550 --> 00:07:51.530
So if you've never read a research paper before what you'd like to give it a go.

108
00:07:51.530 --> 00:07:54.440
This is a great place to start it's very short.

109
00:07:54.440 --> 00:07:55.400
Only 10 pages.

110
00:07:55.400 --> 00:07:56.810
Very easy to read.

111
00:07:57.080 --> 00:08:03.170
And plus the extra benefit is that now that we've discussed convolution and pooling you will be totally

112
00:08:03.170 --> 00:08:07.040
comfortable with everything that they're talking about in this paper in you.

113
00:08:07.100 --> 00:08:11.880
This is a great way to actually reinforce and also I highly recommend checking this paper out.

114
00:08:11.930 --> 00:08:18.050
I'll take 20 minutes to read it and you can even skip part 2 which is called related work if it feels

115
00:08:18.050 --> 00:08:19.880
a bit farfetched or alienating.

116
00:08:19.880 --> 00:08:21.230
Just don't read that part.

117
00:08:21.290 --> 00:08:23.950
Go straight to from part 1 to part 3.

118
00:08:24.020 --> 00:08:29.600
And one thing that you do need to know about this paper they talk about a concept called subsampling

119
00:08:30.360 --> 00:08:33.230
which is subsampling is basically average pooling.

120
00:08:33.230 --> 00:08:36.260
So remember how Here we were taking.

121
00:08:36.280 --> 00:08:37.400
We're taking the maximum.

122
00:08:37.400 --> 00:08:43.250
So in our squarer taking the maximum value there's a concept called Mean pooling or some pulling some

123
00:08:43.250 --> 00:08:48.590
pulling as you just some of these values up average pooling or mean pooling you take the average value

124
00:08:48.650 --> 00:08:53.890
out of all of these and subsampling is kind of like a generalization of men pooling.

125
00:08:53.900 --> 00:09:00.840
It's it's a more kind of generalized approach to taking the average of of these values.

126
00:09:00.860 --> 00:09:05.480
And you can read a bit more about in the paper but otherwise just think of it as average pooling when

127
00:09:05.480 --> 00:09:06.620
you're reading a paper.

128
00:09:06.920 --> 00:09:11.180
And so that's where you can get some additional information on this topic and now kind of let's recap

129
00:09:11.210 --> 00:09:12.310
where have we gotten to.

130
00:09:12.320 --> 00:09:14.440
So there is our input image.

131
00:09:14.870 --> 00:09:18.960
Then we applied the convolution operation and we got the conclusion.

132
00:09:19.070 --> 00:09:24.230
And now to each of those feature maps that we get We've applied the Pullinger.

133
00:09:24.260 --> 00:09:30.590
So we've got we've done these two steps evolution and pooling and now we're going to do something very

134
00:09:30.590 --> 00:09:32.160
fun something exciting.

135
00:09:32.220 --> 00:09:40.340
We're going to experiment with this so this is a screenshot I took from a tool created by Adam Harley

136
00:09:40.340 --> 00:09:48.140
from way back when he was at Ryerson University of computer science and now he's at Carnegie Mellon

137
00:09:48.320 --> 00:09:49.750
I think doing his page.

138
00:09:50.060 --> 00:09:53.150
And a great tool so let's open up let's have a look.

139
00:09:53.270 --> 00:09:55.780
So you can find it you can actually find it through Google.

140
00:09:55.780 --> 00:09:57.500
You have to know your role.

141
00:09:57.500 --> 00:10:03.790
It's as it's just hard to find it through Google because there's no text here as we were just this year.

142
00:10:03.930 --> 00:10:08.350
I'll see start Reierson dossier and this stuff.

143
00:10:08.510 --> 00:10:14.820
And basically this is exactly what we're doing but visualize So here you need to draw a number so say

144
00:10:14.820 --> 00:10:21.330
I draw number four and this tool will put the number four here.

145
00:10:21.340 --> 00:10:22.960
That's your image.

146
00:10:22.960 --> 00:10:26.620
In our first step then this is the convolution step.

147
00:10:26.800 --> 00:10:27.100
Right.

148
00:10:27.100 --> 00:10:30.390
And this is the pooling step and also pooling by the way is also called downsampling.

149
00:10:30.390 --> 00:10:33.770
So pulling and downsampling are the same things.

150
00:10:33.930 --> 00:10:39.190
So you can see it's applied convolution then it's applied pooling and you can see how it exactly works.

151
00:10:39.190 --> 00:10:44.290
You can see what kind of convolutions that it has applied or what kind of filters it is applied what

152
00:10:44.290 --> 00:10:45.020
they look like.

153
00:10:45.130 --> 00:10:47.630
What features is looking out for.

154
00:10:47.830 --> 00:10:53.340
And then it's applied pooling so it's reducing the size and you can see here that this is important.

155
00:10:53.380 --> 00:11:01.090
So you can see that this is the convolved image and this is the puled image and you can still see the

156
00:11:01.090 --> 00:11:05.830
same features is just less information but same features right features are preserved.

157
00:11:05.830 --> 00:11:08.110
That's the important part.

158
00:11:08.350 --> 00:11:14.170
And moreover if you know if all four was a bit too kind of like rotated a bit to the side it would still

159
00:11:14.170 --> 00:11:16.960
be able to pick up very similar pool Lares.

160
00:11:17.050 --> 00:11:19.810
And then after that it's got more letters we haven't talked about that yet.

161
00:11:19.810 --> 00:11:26.840
So then he's got another convolutional a convolutional lair here which we actually won't have.

162
00:11:27.130 --> 00:11:30.730
And then he has another poor lair but he's basically just repeating that same process.

163
00:11:31.000 --> 00:11:34.880
And then after that this is what we're going to be talking further down in the course.

164
00:11:34.910 --> 00:11:37.610
He's got the fully connected Lares and so on.

165
00:11:38.080 --> 00:11:39.880
But you can definitely play around with that.

166
00:11:39.880 --> 00:11:47.890
So if I delete that you like if I draw a 7 you will see that it actually tells you that the guess is

167
00:11:47.890 --> 00:11:49.410
a guess is that this is a 7.

168
00:11:49.570 --> 00:11:52.850
And the second guess the second likelihood is three.

169
00:11:53.050 --> 00:11:56.440
So you can draw some some challenging things and see if it can pick them up.

170
00:11:56.440 --> 00:12:02.680
So let's say if I draw something that looks like a 0 but it's not a finished 0 will it pick it up this

171
00:12:02.770 --> 00:12:03.730
time didn't pick it up.

172
00:12:03.730 --> 00:12:06.190
Looks like a 9 to that to the image.

173
00:12:06.190 --> 00:12:08.550
What if I kind of like finish it like that.

174
00:12:08.560 --> 00:12:14.430
So now it thinks it's a 0 or a 9 and you can see over there what's lighting up the 0.

175
00:12:14.460 --> 00:12:16.600
But we'll talk about that part for the doubt.

176
00:12:16.720 --> 00:12:20.030
Do one more let's say like like 8.

177
00:12:20.260 --> 00:12:23.780
I think it's pretty hard for this now picked up an 8.

178
00:12:23.800 --> 00:12:29.590
So you can see that goes into an 8 and then like after that it stops being recognizable the stops be

179
00:12:29.590 --> 00:12:31.570
making sense to us humans.

180
00:12:31.570 --> 00:12:32.150
Right.

181
00:12:32.170 --> 00:12:34.390
These features that it's working with.

182
00:12:34.570 --> 00:12:38.710
But at the same time it is correctly recognizing that it's an 8.

183
00:12:39.100 --> 00:12:42.540
So definitely play around with that you can draw a smiley face.

184
00:12:42.550 --> 00:12:43.460
What happens then.

185
00:12:44.310 --> 00:12:50.070
Looks like a three to this to this tool because the tool is obviously trained up only on digits from

186
00:12:50.070 --> 00:12:50.950
0 to nine.

187
00:12:51.120 --> 00:12:58.530
So it has to recognize something there are those and recognizes a three it's like in life when you when

188
00:12:58.530 --> 00:13:05.700
you see something like a type of fruit that you've never seen before like a custard apple or something

189
00:13:06.120 --> 00:13:12.570
and you think that's it's like it's it's a pear because you've never actually seen one before you don't

190
00:13:12.570 --> 00:13:18.210
know what to classify it as same thing here so it hasn't actually trained on smiley faces and that's

191
00:13:18.210 --> 00:13:20.480
why it's thinks it's a tree as a tree.

192
00:13:20.490 --> 00:13:25.770
So there you go it's a very powerful powerful tool it'll be helpful for you to play around of it actually

193
00:13:26.130 --> 00:13:29.430
when you put your mouse over a pixel pixel that will show.

194
00:13:29.430 --> 00:13:36.930
It shows you where the feature detector was to pick up that pixel so you can see where those pixels

195
00:13:36.930 --> 00:13:43.170
are coming from and also so you can see how the filter was kind of like going through the image exactly

196
00:13:43.170 --> 00:13:47.910
how we talked about and of course and here you can see you can see the pooling you can see that the

197
00:13:47.910 --> 00:13:58.140
pulling is done with the pulling is done with a little square size of two by two and you can see that

198
00:13:58.200 --> 00:14:03.730
it's a stride of two as well just as we discussed in today's tutorial.

199
00:14:03.960 --> 00:14:09.240
So there go play or have a play around with that and I hope you enjoyed today's session.

200
00:14:09.240 --> 00:14:10.610
I look forward to seeing you next time.

201
00:14:10.620 --> 00:14:12.470
And until then enjoy deep learning.
