WEBVTT
1
00:00:00.060 --> 00:00:04.050
- One of the hardest operational problems to solve

2
00:00:04.050 --> 00:00:09.010
in a micro-services architecture is evaluating call chains

3
00:00:09.010 --> 00:00:14.040
and aggregating logging associated to those call chains.

4
00:00:14.040 --> 00:00:18.020
When an issue arises in a micro-services architecture,

5
00:00:18.020 --> 00:00:22.060
it can become very difficult to see all of the moving parts,

6
00:00:22.060 --> 00:00:25.080
especially when you consider that your calls

7
00:00:25.080 --> 00:00:29.060
spin multiple virtual machines or containers,

8
00:00:29.060 --> 00:00:32.060
and separate sessions.

9
00:00:32.060 --> 00:00:35.060
The good news is that solving these problems

10
00:00:35.060 --> 00:00:38.070
can be relatively straightforward,

11
00:00:38.070 --> 00:00:41.070
but you need to plan for those operations early

12
00:00:41.070 --> 00:00:44.050
in your build process.

13
00:00:44.050 --> 00:00:48.010
A unified approach early on in the process

14
00:00:48.010 --> 00:00:52.030
will prevent serious rework once you realize the value

15
00:00:52.030 --> 00:00:56.020
of these principles in your overall architecture.

16
00:00:56.020 --> 00:01:00.050
I would strongly recommend you take this advice seriously,

17
00:01:00.050 --> 00:01:03.040
and plan for unification on these topics

18
00:01:03.040 --> 00:01:06.020
across your organization.

19
00:01:06.020 --> 00:01:09.010
We will start our discussion with logging.

20
00:01:09.010 --> 00:01:11.020
You will find that having quality logging

21
00:01:11.020 --> 00:01:16.000
throughout your API calls will be critical to not only

22
00:01:16.000 --> 00:01:19.030
evaluate the day-to-day operations of your system,

23
00:01:19.030 --> 00:01:22.020
but they become very useful in troubleshooting,

24
00:01:22.020 --> 00:01:26.040
maintenance, investigations, and other general tasks

25
00:01:26.040 --> 00:01:28.030
of your system.

26
00:01:28.030 --> 00:01:30.060
The issue of logging, however,

27
00:01:30.060 --> 00:01:33.000
becomes significantly noisier

28
00:01:33.000 --> 00:01:36.020
in a micro-services environment.

29
00:01:36.020 --> 00:01:40.020
Part of the issue is simply the larger volume of artifacts

30
00:01:40.020 --> 00:01:45.030
in the system, but also because of the agile nature

31
00:01:45.030 --> 00:01:48.050
that is bred from this architecture.

32
00:01:48.050 --> 00:01:51.020
You often have various functional teams

33
00:01:51.020 --> 00:01:53.050
building different services.

34
00:01:53.050 --> 00:01:56.080
As such, each of these teams may end up developing

35
00:01:56.080 --> 00:02:01.050
different logging strategies, as well as formatting.

36
00:02:01.050 --> 00:02:04.050
While the lack of unification of log data

37
00:02:04.050 --> 00:02:09.000
may not seem like a big deal, the reality is that

38
00:02:09.000 --> 00:02:11.060
as you move to a distributed system

39
00:02:11.060 --> 00:02:16.000
there's an increased need to have some sort of convergence

40
00:02:16.000 --> 00:02:18.020
in your logging behaviors.

41
00:02:18.020 --> 00:02:22.030
As the system size grows, you may find yourself

42
00:02:22.030 --> 00:02:25.040
moving from traditional file-system based logging

43
00:02:25.040 --> 00:02:27.080
to log aggregators.

44
00:02:27.080 --> 00:02:30.080
These log aggregators make uniformity

45
00:02:30.080 --> 00:02:35.030
that much more critical, so that you can coalesce them

46
00:02:35.030 --> 00:02:39.000
and scan them more easily.

47
00:02:39.000 --> 00:02:41.050
Part of making logging more powerful

48
00:02:41.050 --> 00:02:45.030
in a distributed environment is the ability to determine

49
00:02:45.030 --> 00:02:49.020
the actual flow, not only through your service,

50
00:02:49.020 --> 00:02:51.090
but through the system as a whole.

51
00:02:51.090 --> 00:02:54.020
There is a solution for this need,

52
00:02:54.020 --> 00:02:57.040
and it's often called tracing.

53
00:02:57.040 --> 00:03:00.020
Tracing is based on the concept of creating

54
00:03:00.020 --> 00:03:03.010
a unique token, called a trace,

55
00:03:03.010 --> 00:03:07.050
and using that trace in all internal logging events

56
00:03:07.050 --> 00:03:09.060
for that call stack.

57
00:03:09.060 --> 00:03:11.070
By embedding this value in all

58
00:03:11.070 --> 00:03:13.080
of the logging and timing output

59
00:03:13.080 --> 00:03:17.010
for all of the services involved.

60
00:03:17.010 --> 00:03:21.080
Each service uses the trace, and then passes it downstream

61
00:03:21.080 --> 00:03:24.060
to all of the service calls it makes.

62
00:03:24.060 --> 00:03:28.050
Each of those, in turn, do the same.

63
00:03:28.050 --> 00:03:30.080
There are several different strategies

64
00:03:30.080 --> 00:03:33.080
for moving the trace ID from service to service,

65
00:03:33.080 --> 00:03:37.070
but the important part is that the trace ID exists

66
00:03:37.070 --> 00:03:41.040
in all of the log messaging, for all services

67
00:03:41.040 --> 00:03:45.030
throughout the system for a given call stack.

68
00:03:45.030 --> 00:03:48.040
By leveraging this strategy, you can aggregate

69
00:03:48.040 --> 00:03:51.060
a set of log messages and timings

70
00:03:51.060 --> 00:03:54.080
when looking at call metrics and behavior.

71
00:03:54.080 --> 00:03:58.090
Determining the behavior from a single client interaction

72
00:03:58.090 --> 00:04:02.020
through a system in a micro-services architecture

73
00:04:02.020 --> 00:04:07.010
is hard, but tracing makes this problem much simpler.

74
00:04:07.010 --> 00:04:10.080
If you structure your log messages in a unified manner,

75
00:04:10.080 --> 00:04:14.050
and include the trace, you will see a huge benefit

76
00:04:14.050 --> 00:04:17.000
when the need arises.

