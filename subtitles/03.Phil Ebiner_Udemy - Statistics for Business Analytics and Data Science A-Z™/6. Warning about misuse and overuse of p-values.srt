1
00:00:00,540 --> 00:00:02,940
Hello and welcome back to the Course also to sticks.

2
00:00:02,970 --> 00:00:08,940
Today we're going to have a very sick tutorial we're going to be exploring the issue of misuse and overuse

3
00:00:08,970 --> 00:00:10,370
of p values.

4
00:00:10,410 --> 00:00:13,870
So let's have a look at what's going on here.

5
00:00:13,950 --> 00:00:17,830
So it all kind of started for me with this video.

6
00:00:17,830 --> 00:00:24,840
I was doing some research about p values for this course and I read like I stumbled on this video.

7
00:00:24,840 --> 00:00:28,620
It's by seeker by the way Seeker is a great great channel.

8
00:00:28,650 --> 00:00:32,030
You can find lots of really interesting videos about science and stuff like that.

9
00:00:32,750 --> 00:00:39,540
But this one talks about how scientists manipulate research with p value and it talks about that you

10
00:00:39,540 --> 00:00:41,940
know all these things that we've discussed in the course.

11
00:00:42,180 --> 00:00:47,970
You've probably noticed like very mechanical very straightforward and it's just mathematics is just

12
00:00:47,970 --> 00:00:55,110
basically basic calculations that you need to perform in order to reject a hypothesis and come up and

13
00:00:55,170 --> 00:00:58,870
therefore prove some kind of theory or something.

14
00:00:58,980 --> 00:01:04,440
We're afraid a five point ninety five percent degree of confidence or 5 percent or 99 percent degree

15
00:01:04,440 --> 00:01:05,730
of confidence is something that.

16
00:01:06,000 --> 00:01:13,740
And that's that can be a problem that sometimes people will take that's those those mathematics and

17
00:01:14,040 --> 00:01:21,090
actually you know do research and just just rely on the P-value and then therefore prove that their

18
00:01:21,090 --> 00:01:25,740
research is statistically significant and just basically to push that research out and get it published

19
00:01:25,770 --> 00:01:27,140
as quickly as possible.

20
00:01:27,210 --> 00:01:33,060
And because in the science community unfortunately it's really about the publications like the more

21
00:01:33,060 --> 00:01:40,510
publications you have the more kind of credibility you have and the very a reputation in the community.

22
00:01:40,530 --> 00:01:41,780
It's about publication.

23
00:01:41,810 --> 00:01:42,980
Most of the time.

24
00:01:43,190 --> 00:01:50,160
And so that can be a problem and the thing is that P-value doesn't actually tell you everything it's

25
00:01:50,160 --> 00:01:55,170
not the end game for research but that's how research is taking.

26
00:01:55,200 --> 00:01:57,260
And that's what we're going to be talking about a little bit today.

27
00:01:57,330 --> 00:01:58,890
So check out this video.

28
00:01:58,890 --> 00:02:03,390
If you just search for how scientists manipulate research with P-value will give you a quick overview

29
00:02:03,390 --> 00:02:04,430
of the problem.

30
00:02:04,440 --> 00:02:07,700
Then there's this article published in Nature.

31
00:02:08,060 --> 00:02:12,090
I think it's Yechiel 14 Birgeneau news on Izzo.

32
00:02:12,660 --> 00:02:19,260
I'm not sure how to pronounce it correctly but it basically talks about the same thing that there are

33
00:02:19,260 --> 00:02:25,190
so many papers going out about P-value like which used P-value.

34
00:02:25,410 --> 00:02:27,360
And we'll we'll come back in a second.

35
00:02:27,360 --> 00:02:32,970
I just wanted to point out like what an impact this article had is a few of these articles but what

36
00:02:32,970 --> 00:02:40,100
an impact it had is it was sighted it was I quote tweeted nine thousand eight hundred twenty five times

37
00:02:40,110 --> 00:02:45,290
it's called mention and tonight blogs on turn to pay Facebook pages.

38
00:02:45,320 --> 00:02:47,770
Hundred and Fifty three Google plus users.

39
00:02:47,820 --> 00:02:52,150
And so this is this exact article by Regina news.

40
00:02:52,380 --> 00:02:53,710
So it's huge.

41
00:02:53,850 --> 00:02:55,020
It made a huge impact.

42
00:02:55,050 --> 00:02:57,600
And in fact it's not this one.

43
00:02:57,600 --> 00:03:05,500
In fact here you'll see that American I think is American Statistical statistics Association.

44
00:03:05,580 --> 00:03:11,280
They actually published a paper kind of not directly in response to that article but if you search news

45
00:03:11,370 --> 00:03:16,290
here you'll see that it's actually here that that they mention that this article was published and had

46
00:03:16,290 --> 00:03:17,420
a huge impact.

47
00:03:17,430 --> 00:03:27,120
And so this this is a comment from the American statistics Association about how indeed is this is a

48
00:03:27,120 --> 00:03:29,890
problem that scientists are using.

49
00:03:30,090 --> 00:03:36,510
P-value to manipulate research but kind of to get the results that they want to sometimes even manipulate

50
00:03:36,510 --> 00:03:41,820
research and I just wanted to go through this so this is kind of the overview of that is is a thing.

51
00:03:41,820 --> 00:03:42,980
This is a real thing.

52
00:03:43,260 --> 00:03:48,960
And now I'm going to we're going to go through like what exactly does it mean that why why can we just

53
00:03:48,960 --> 00:03:50,880
use P-value as we've discussed in the scores.

54
00:03:50,880 --> 00:03:56,290
Why don't we just like isn't P-value like it sounds from what we've discussed sounds like P-value is

55
00:03:56,330 --> 00:04:01,140
the real thing it's it's pretty it's pretty solid it's just math and so on.

56
00:04:01,500 --> 00:04:07,610
And that that would have been kind of like the case but I just wanted to find this here somewhere.

57
00:04:07,980 --> 00:04:12,840
So let's just read this part of this decision as I've pointed out put it to a number of measures that

58
00:04:12,840 --> 00:04:17,580
might help us avoid the trap of thinking of our results as a significant or not significant for example

59
00:04:17,870 --> 00:04:22,940
coming things that researchers should always report effect sizes and confidence intervals.

60
00:04:23,100 --> 00:04:29,690
These convey what a P-value does not the magnitude and the relative importance of an effect.

61
00:04:29,800 --> 00:04:36,360
And so that's kind of like the key to the thing that P-value is they don't actually look at the magnitude

62
00:04:36,360 --> 00:04:36,950
of an effect.

63
00:04:36,960 --> 00:04:40,250
And relative importance but this kind of like focus on the magnets.

64
00:04:40,800 --> 00:04:48,120
What that means is that in as if you've seen we we can prove for instance that if P-value that something

65
00:04:48,120 --> 00:04:51,690
has increased or something has decreased but we don't actually say by how much.

66
00:04:51,690 --> 00:04:56,960
How much has it increased or how much has decreased we just say oh yes the number of households in five

67
00:04:56,960 --> 00:05:01,340
has has increased or has decreased and that's pretty that's great.

68
00:05:01,340 --> 00:05:06,680
But what we need to be doing is we need to be actually see I need to be checking.

69
00:05:06,680 --> 00:05:07,010
All right.

70
00:05:07,010 --> 00:05:12,740
So is it something that's valuable to us to know that it's increased What is it what are we taking that

71
00:05:12,740 --> 00:05:17,900
is increased compared to is it we just checking that has increased to some arbitrary value that is not

72
00:05:17,900 --> 00:05:23,150
going to be valuable to or in our case in this case like research into the population of the world.

73
00:05:23,150 --> 00:05:29,060
But in our case to make the business objective that we were trying to fulfill so if that has increased.

74
00:05:29,060 --> 00:05:33,710
Is that sufficient or do we need to actually see the effect do we need to be comparing to the previous

75
00:05:33,710 --> 00:05:38,170
value or do it just sound like a set of sort of benchmark and compare to that and things like that.

76
00:05:38,180 --> 00:05:39,600
We need to actually see.

77
00:05:39,620 --> 00:05:41,120
All right what is going on.

78
00:05:41,130 --> 00:05:43,070
And here's an example.

79
00:05:43,070 --> 00:05:46,180
They have a look on line.

80
00:05:46,230 --> 00:05:48,160
So here a great article by the way.

81
00:05:48,170 --> 00:05:51,830
Definitely read it but I'm just going to look at a few like comments here.

82
00:05:51,940 --> 00:05:57,620
So prime example is their tendency to deflect attention from the actual size of the effect.

83
00:05:57,620 --> 00:06:02,580
Last year for example a study of more than 19000 people showed that.

84
00:06:02,600 --> 00:06:07,370
Who those who meet their spouses on line are less likely to divorce.

85
00:06:07,370 --> 00:06:15,160
So the P-value there was less than Point 2 percent and more likely to have marital satisfaction P-value

86
00:06:15,170 --> 00:06:20,020
is less than Point 1 percent than than those who meet off line.

87
00:06:20,180 --> 00:06:26,670
And so there's the link to the article that might have sounded impressive but the effects were actually

88
00:06:26,670 --> 00:06:27,630
tiny effects were tiny.

89
00:06:27,650 --> 00:06:33,350
The meeting online the divorce from right from Point 67 percent to down to five point ninety six percent

90
00:06:34,040 --> 00:06:35,620
and barely budged.

91
00:06:35,630 --> 00:06:39,480
Happiness from five point forty eight to five point sixty four and seven point scale.

92
00:06:39,530 --> 00:06:44,970
So that's kind of like that's the issue here that you know it sounds pretty cool.

93
00:06:45,000 --> 00:06:46,010
19000.

94
00:06:46,010 --> 00:06:52,790
That's huge sample and it sounds you know like the P-value sound pretty significant but as it says here

95
00:06:53,420 --> 00:06:58,920
basically there go so that deflects that deflects these these formulas.

96
00:06:58,940 --> 00:07:05,600
I think the was Pompeius like these mega statements they deflect attention from what's actually going

97
00:07:05,600 --> 00:07:11,030
on there or like let's say one of those things that we talked about like a drug that increases attention

98
00:07:11,030 --> 00:07:13,610
span like you might say oh yes it increases attention.

99
00:07:13,610 --> 00:07:15,260
Is this clinically proven.

100
00:07:15,260 --> 00:07:20,380
You might find on a bottle is clinically proven that this drug increase increases attention span.

101
00:07:20,620 --> 00:07:26,630
Well you know from 99 and the confidence in the level that we used was ninety nine percent confidence

102
00:07:26,630 --> 00:07:27,070
level.

103
00:07:27,230 --> 00:07:28,100
So that's pretty cool.

104
00:07:28,100 --> 00:07:31,230
But how much does it increase their attention span.

105
00:07:31,400 --> 00:07:34,580
Does it increase it by $0.00 1 percent.

106
00:07:34,580 --> 00:07:41,780
Well in that case I'm not spending $20 on your natural medicine that's going to help me increase my

107
00:07:41,780 --> 00:07:44,420
attention span by 0.7 percent or 1 percent.

108
00:07:44,420 --> 00:07:48,020
So that's kind of the underlying issue of magnitude.

109
00:07:48,170 --> 00:07:50,950
And in a business sense we always have to think about.

110
00:07:50,960 --> 00:07:51,290
OK.

111
00:07:51,290 --> 00:07:51,680
Yes.

112
00:07:51,680 --> 00:07:56,720
Maybe the amount of money that customers are spending in our store has increased.

113
00:07:56,720 --> 00:08:04,220
We can prove that but by how much has it increased by how can we actually see that that is the case.

114
00:08:04,220 --> 00:08:10,430
And one final thing that I wanted to mention is they talk in this article about frequentist frequences

115
00:08:10,460 --> 00:08:17,150
frequentist statistics which were just what we've been talking about all along which were created by.

116
00:08:17,510 --> 00:08:23,600
Well if you want to look at an alternative and they also mentioned so if you look for these.

117
00:08:23,600 --> 00:08:29,960
So they talk about Bayesian inference and Bayesian statistics versus frequence of official statistics.

118
00:08:30,170 --> 00:08:36,200
And if you'd like to learn more about Bayesian statistics and Bayesian inference and have some real

119
00:08:36,200 --> 00:08:42,230
world examples about about this issue in even a bit more detail and you're looking for a good book to

120
00:08:42,230 --> 00:08:47,270
read I just wanted to recommend a book called Signal and the noise why so many predictions fail by Nate

121
00:08:47,270 --> 00:08:47,910
Silver.

122
00:08:47,990 --> 00:08:55,640
And this talks a lot about Bayesian inference and how it is different to frequences statistics.

123
00:08:55,700 --> 00:09:01,640
The thing is that Bayesian inference as you'll see from the article it's requires kind of some subjective

124
00:09:01,670 --> 00:09:07,280
input at the start it's like what is our starting point and is it subjective whereas what we've been

125
00:09:07,280 --> 00:09:09,980
discussing is is our objective.

126
00:09:10,010 --> 00:09:17,630
And if you use it right I believe that if you use p values and hypothesis test scores and all these

127
00:09:17,630 --> 00:09:24,770
things T-test Elissa's when discussing if you use them correctly then like you are less likely to fall

128
00:09:24,770 --> 00:09:28,670
into a trap like this but Bayesian inference is just a whole different story.

129
00:09:28,670 --> 00:09:33,440
So if you want to learn more about that just maybe read this article and find out you can check out

130
00:09:33,440 --> 00:09:36,540
that book single and always great book on data science as well.

131
00:09:36,710 --> 00:09:41,840
And the other thing I wanted to mention to kind of like finish off to this tutorial is that so here

132
00:09:41,840 --> 00:09:47,870
they mention that Cumming's coming things that researchers should always report effect sizes and confidence

133
00:09:47,870 --> 00:09:49,040
intervals.

134
00:09:49,040 --> 00:09:50,170
These convey values.

135
00:09:50,180 --> 00:09:55,480
You know that's what people always do NOT Magnuson and relative importance and effect.

136
00:09:55,490 --> 00:10:00,190
So the good news is that in this course in the next section pretty much we're going to be talking about

137
00:10:00,460 --> 00:10:08,860
confidence intervals and there's some additional tool for you to be able to not only understand it if

138
00:10:08,860 --> 00:10:14,740
there is an effect but also understand what kind of magnet should this effect potentially has.

139
00:10:15,010 --> 00:10:22,750
And yes it will cover that off in the next section and hopefully you got some kind of insights about

140
00:10:23,080 --> 00:10:29,440
potential warnings of values that is lost to discuss here is.

141
00:10:29,530 --> 00:10:32,470
Lots of debate as you can see it's a big thing in the community.

142
00:10:32,560 --> 00:10:39,700
All these researchers are using pure values all over like in all these universities and all these publications

143
00:10:40,270 --> 00:10:46,810
at the same time they are growing concern about their overuse of values and you might find articles

144
00:10:46,810 --> 00:10:54,220
about that you know that huge percentage of all published research is actually false simply because

145
00:10:54,430 --> 00:10:57,340
you know the issues that are underlying here.

146
00:10:57,550 --> 00:11:02,260
So it's just something to know it's of course we're not researchers and we're not going to be just running

147
00:11:02,260 --> 00:11:04,930
toward to get our publications done.

148
00:11:04,930 --> 00:11:10,240
And again I'm not saying that all research has to do that but it's not it's not even a even a concern

149
00:11:10,240 --> 00:11:10,650
for us.

150
00:11:10,660 --> 00:11:16,520
We just want to do business analytics and we want to make sure our results is significant.

151
00:11:16,540 --> 00:11:19,960
So be aware of these problems that potentially exist.

152
00:11:19,970 --> 00:11:24,670
And again if you read this article you will find to just search for scientific method statistical errors

153
00:11:24,670 --> 00:11:30,650
and go find it and you'll find that there's actually there's some estimates of you know what.

154
00:11:30,670 --> 00:11:34,080
What if you value 1 percent means like what are the percent.

155
00:11:34,090 --> 00:11:38,440
What is the likelihood of things that that actually went wrong there and 5 percent is on.

156
00:11:38,560 --> 00:11:45,040
But if you always keep in mind the cause and effect like a good example is if you use you can actually

157
00:11:45,360 --> 00:11:52,450
I think there's some example of that some of you linked the behavior of drugs and earthquakes that you

158
00:11:52,450 --> 00:11:58,840
know that frogs can actually predict earthquakes and that research has proven P-value as as as you'd

159
00:11:58,840 --> 00:11:59,650
expect.

160
00:11:59,740 --> 00:12:07,210
And you know it's kind of ridiculous unless and this is like some some weird connection between frogs

161
00:12:07,210 --> 00:12:08,110
and earthquakes.

162
00:12:08,110 --> 00:12:10,090
Otherwise it sounds like ridiculous things.

163
00:12:10,110 --> 00:12:14,350
If as long as you don't try to prove ridiculous things as long as there's a cause and effect is actual

164
00:12:14,350 --> 00:12:19,500
causality and you're always keeping the magnitude of the effect in mind as well.

165
00:12:19,690 --> 00:12:25,450
I think these are a great tool to use and this whole hypothesis testing statistical significance which

166
00:12:25,450 --> 00:12:30,580
we've been doing is great because people understand it and because it gives you that backing and even

167
00:12:30,580 --> 00:12:36,670
this article says that P-value as they were they weren't just designed they weren't designed to prove

168
00:12:36,670 --> 00:12:43,210
the research all the time all the way but they were indeed designed to check to do some initial checks

169
00:12:43,210 --> 00:12:46,560
to understand OK which way should we start thinking in which direction.

170
00:12:46,780 --> 00:12:50,870
So in terms of our purpose I think it's it's a good tool to have.

171
00:12:50,890 --> 00:12:51,580
Good to know.

172
00:12:51,580 --> 00:12:58,660
And again because people now know it and understand it it's definitely an important tool to have in

173
00:12:58,660 --> 00:13:05,620
your arsenal and apply it so that you can rely on the results that you're finding.

174
00:13:05,620 --> 00:13:08,880
And the business can also rely on those results.

175
00:13:09,130 --> 00:13:16,400
So we hope hopefully enjoyed this little excursion into the world of warnings about values and so forth.

176
00:13:16,570 --> 00:13:18,160
So then I'd be analyzing.
