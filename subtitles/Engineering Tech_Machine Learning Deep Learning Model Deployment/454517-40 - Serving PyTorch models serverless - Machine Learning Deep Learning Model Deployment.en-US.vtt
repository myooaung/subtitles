WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:02.520
We'll now create a serverless,

00:00:02.520 --> 00:00:07.810
risky pay for the Python model using the Google Cloud Function.

00:00:08.750 --> 00:00:11.220
It the time of this recording,

00:00:11.220 --> 00:00:15.900
Google Cloud supports 1.00 one verse unoccupied touch to currently,

00:00:15.900 --> 00:00:20.310
1.7 is the latest sooner to downgrade.

00:00:20.310 --> 00:00:25.880
Pipe dot John Gould collapse to 1.01 and also elect to downgrade dark,

00:00:25.880 --> 00:00:28.890
dark vision to 0.2.2.

00:00:28.930 --> 00:00:37.380
So let's do that in the text classifier python IPython notebook that we created earlier.

00:00:37.720 --> 00:00:45.305
And after that, you run the entire file and then download dow pi term dictionary.

00:00:45.305 --> 00:00:47.960
So this tape is same as before.

00:00:47.960 --> 00:00:53.250
Only thing is we have downgraded Pi torch to 1.0.1 worsen.

00:00:53.500 --> 00:00:58.160
After importing touch, you can verify the pie charts worsen.

00:00:58.160 --> 00:01:01.500
It has to be 1.0.1.

00:01:01.720 --> 00:01:08.360
Now Go to Google Cloud and creative bucket and upload the text classifier,

00:01:08.360 --> 00:01:14.460
Python, dictionary file and TF-IDF model pickle file without bucket.

00:01:20.290 --> 00:01:24.210
And then had to Google Cloud Function

00:01:27.310 --> 00:01:32.450
and create a new function for the pipe yardsticks classifier.

00:01:32.450 --> 00:01:36.005
You look to Lord our dictionary first.

00:01:36.005 --> 00:01:44.460
And then the TF-IDF vectors major DOP declared though Python neural network class.

00:01:45.580 --> 00:01:49.020
And then load the dictionary.

00:01:49.600 --> 00:01:53.720
And then the rest of the code is similar to what you've done

00:01:53.720 --> 00:01:57.930
for TensorFlow and psychic LAN.

00:01:58.990 --> 00:02:04.080
You just need to update the code where you do the prediction.

00:02:05.440 --> 00:02:08.060
If the value at index 0 is higher,

00:02:08.060 --> 00:02:09.440
it's a negative sentiment.

00:02:09.440 --> 00:02:12.515
If devaluate index one inside it's a positive sentiment,

00:02:12.515 --> 00:02:16.460
and then return that sentiment in the requirements.txt unit.

00:02:16.460 --> 00:02:18.845
To define all the dependencies.

00:02:18.845 --> 00:02:21.635
We need the Google Cloud Storage liability,

00:02:21.635 --> 00:02:27.320
scikit-learn for the TF-IDF modern requests library NumPy port

00:02:27.320 --> 00:02:28.760
Python's will have to specify

00:02:28.760 --> 00:02:33.650
their download directory path for the 1.0.1 verges on any worse than

00:02:33.650 --> 00:02:39.440
higher than this currently doesn't work. After that you deploy.

00:02:39.440 --> 00:02:46.700
And then I'll copy the HTTP URL and go to Postman and predictor.

00:02:46.700 --> 00:02:48.830
So the sentiment is positive,

00:02:48.830 --> 00:02:51.635
it is coming from the pipe serverless function.

00:02:51.635 --> 00:02:54.200
If I change this to a negative sentence will get

00:02:54.200 --> 00:02:57.425
a negative sentiment prediction from Python.

00:02:57.425 --> 00:03:04.200
Two, this is how we can create a serverless RISD pay for Python arch models.
