1
00:00:00,630 --> 00:00:07,270
In this lecture, I'll be talking about High Availability, if you're going to run your cluster in production,

2
00:00:07,270 --> 00:00:13,720
You're going to want to have all your master services in a high availability set up. This set up looks like

3
00:00:13,720 --> 00:00:19,100
this, you're going to cluster "etcd", at least you're going to run three "etcd" the nodes.

4
00:00:19,360 --> 00:00:23,730
If you just run one and "etcd" fails then Kubernetes is not working anymore.

5
00:00:23,800 --> 00:00:31,370
So, you need at least three nodes for high availability. You're going to replicate your API service with a load balancer and

6
00:00:31,370 --> 00:00:35,480
you're going to run multiple instances of the scheduler and the controllers.

7
00:00:35,710 --> 00:00:37,360
Only one of them will be the leader,

8
00:00:37,360 --> 00:00:39,700
the other ones are going to be on standby.

9
00:00:40,180 --> 00:00:45,380
Here is an overview of the "etcd" clusters that are typically run. 

10
00:00:45,430 --> 00:00:46,760
You can run one, you don't have high availability.

11
00:00:46,840 --> 00:00:47,730
You can run three.

12
00:00:47,830 --> 00:00:49,240
This is typical set up.

13
00:00:49,240 --> 00:00:55,280
Or if you start getting a really big cluster then you're going to run five "etcd" nodes.

14
00:00:55,370 --> 00:01:00,120
So, this is then how an architecture looks like with high visibility.

15
00:01:00,190 --> 00:01:06,370
If you take a look at the top left, "kubectl" is now going to connect to a load balancer. So, are the Kubernetes nodes, 

16
00:01:06,370 --> 00:01:09,150
they will also going to connect to this load balancer.

17
00:01:09,490 --> 00:01:14,480
This load balancer will then go to the rest of the interfaces on either "Master 1" or "Master 2".

18
00:01:14,570 --> 00:01:22,450
Typically, if you don't go for high availability, you're going to want three nodes. Every node is unique,

19
00:01:22,660 --> 00:01:28,400
so you just have to spin up multiple master nodes with the same image or the same software.

20
00:01:28,400 --> 00:01:32,510
The rest the API will communicate with "etcd" not shown on this graph.

21
00:01:33,040 --> 00:01:38,350
But then, you also have the components that make changes to the API like the scheduler

22
00:01:38,350 --> 00:01:39,430
and the controller manager.

23
00:01:39,820 --> 00:01:44,320
You can only have one active scheduler and one active control manager.

24
00:01:44,470 --> 00:01:51,130
That's why on "Master 2" and on any other masters you will see that they are great out, they are on standby.

25
00:01:52,660 --> 00:01:57,730
You also have a "kubelet" installed on your masters and you can also have "monit", which will then monitor "kupelets".

26
00:01:57,930 --> 00:02:02,000
A cluster like minikube doesn't really need HA.

27
00:02:02,130 --> 00:02:04,450
It's only a one note cluster.

28
00:02:04,680 --> 00:02:11,040
If you are going to use a production cluster on AWS, kops can do the heavy lifting for you. 

29
00:02:11,040 --> 00:02:13,050
If you are running on another cloud platform,

30
00:02:13,050 --> 00:02:17,780
have a look at the kube deployment tools for that platform.

31
00:02:17,800 --> 00:02:24,630
Kubeadmin is a tool that is in alpha, but it's very promising that it can set up a cluster for you.

32
00:02:24,630 --> 00:02:26,860
If you are on a platform without a tooling.

33
00:02:26,910 --> 00:02:29,940
Have a look at this URL to implement it yourself.

34
00:02:30,820 --> 00:02:35,660
In the next demo, I'll show you how to modify the kops set up to run multiple master nodes.
