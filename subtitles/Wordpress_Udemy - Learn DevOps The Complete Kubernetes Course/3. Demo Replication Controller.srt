1
00:00:00,600 --> 00:00:09,310
In this demo I'm going to show you how to horizontally scale a pod with the Replication Controller.

2
00:00:09,400 --> 00:00:13,080
I've just started my minikube Kubernetes cluster again.

3
00:00:13,070 --> 00:00:17,280
So, if I type, "kubectl get nodes", "get pod" or "get node"

4
00:00:17,730 --> 00:00:23,350
Then I can see minikube is ready

5
00:00:23,400 --> 00:00:31,710
I have the YAML file in the "Kubernetes-course/Replication Controller/helloworld-repl-controller.yml"

6
00:00:31,730 --> 00:00:35,740
I'm going to create this

7
00:00:39,380 --> 00:00:49,660
"replicationcontroller 'helloworld-controller' created". So, let's have a look "kubectl get pods".

8
00:00:49,870 --> 00:00:55,060
You can now see that this replication controller created 2 pods.

9
00:00:55,060 --> 00:00:56,280
Now we have a "helloworld-controller-[randomstring]"

10
00:00:56,290 --> 00:01:02,290
because a name should be unique.

11
00:01:02,740 --> 00:01:05,660
And then a second one also with a unique name.

12
00:01:05,680 --> 00:01:10,480
So, these ones are now creating, it needs to pull the image again, so they can take some time.

13
00:01:10,620 --> 00:01:14,600
So, let's describe one of them, so we need to use now this name.

14
00:01:14,650 --> 00:01:19,200
"kubeclt describe pod"

15
00:01:19,380 --> 00:01:20,070
and then the name

16
00:01:23,010 --> 00:01:27,280
So, this uses the replication controller and it's still the same demo.

17
00:01:27,620 --> 00:01:32,860
Let's just wait a few seconds now until the image is pulled.

18
00:01:32,870 --> 00:01:39,890
Now, the image has been pulled and I have the two pods running.

19
00:01:39,960 --> 00:01:46,300
You can see that now a horizontally scaled my pod, I have multiple instances running.

20
00:01:46,440 --> 00:01:51,900
If I have multiple nodes those instances could be running over multiple nodes and we could put a service.

21
00:01:51,930 --> 00:01:58,950
In front of that, a load balancer, that will make these multiple pods accessible 

22
00:01:58,950 --> 00:02:00,970
to other software or customers.

23
00:02:01,060 --> 00:02:07,840
If one of those pods crashes if one of those underlying nodes crashes, then the controller will automatically

24
00:02:07,900 --> 00:02:10,230
reschedule the pods.

25
00:02:10,300 --> 00:02:19,440
So, let me just remove one of those pods and then we're going to see that the replication controller is

26
00:02:19,440 --> 00:02:21,110
just going to create a new pod.

27
00:02:21,150 --> 00:02:26,700
It will see that this pod is gone and it will reschedule a new one.

28
00:02:26,940 --> 00:02:34,730
So you can see here now this pod is terminating and 11 seconds ago a new pod is already running.

29
00:02:34,800 --> 00:02:40,800
The controller will always make sure that the correct amount of pods is running.

30
00:02:40,820 --> 00:02:45,140
I can also scale those pods just using the "kubectl" command.

31
00:02:45,280 --> 00:02:54,940
I can do "kubectl scale" and I can save replicas equal to four instead of two and it can again pass the

32
00:02:55,000 --> 00:03:00,430
YAML file or I can just specify the full name of this replication controller.

33
00:03:00,730 --> 00:03:04,250
I'm just going to show it first with the file name.

34
00:03:06,620 --> 00:03:10,550
"replicationcontroller 'helloworld-controller' scaled".

35
00:03:11,900 --> 00:03:18,830
Now, you can see it is creating four pods because we did the scaling operation and under way to use

36
00:03:18,830 --> 00:03:27,020
"kubectl scale"-- First let's get the name of the replicator controller, we can abbreviate this by "rc"

37
00:03:27,020 --> 00:03:37,620
It is the "helloworld-controller" and we can say, "kubectl scale --replicas=1" only, maybe, 1 replica

38
00:03:38,480 --> 00:03:45,110
and then we can say, "rc/helloworld-controller" and then it's going to scale it again.

39
00:03:45,110 --> 00:03:53,570
So, if you do again "kubectl get pods", you will see now, three of them have been terminated and only one of them is

40
00:03:53,570 --> 00:03:58,050
now running. Again, to reiterate what I said during the theory,

41
00:03:58,370 --> 00:04:01,400
this you can only horizontally scale.

42
00:04:01,400 --> 00:04:02,830
So, this is horizontal scaling.

43
00:04:02,840 --> 00:04:06,710
You can only horizontally scale when your pod is stateless.

44
00:04:06,710 --> 00:04:11,350
If you have stateful pods then you will not be able to do this.

45
00:04:11,780 --> 00:04:15,930
If you want to know how to create stateless applications have a look at the 12factor app.

46
00:04:16,070 --> 00:04:22,430
Have a look at my other courses. If you are really sure that you have a stateful application, you will just

47
00:04:22,430 --> 00:04:26,200
have to be a little bit more patient, because I would be explaining stateful pods

48
00:04:26,390 --> 00:04:34,770
later on in the course. If you want just to delete this controller, "kubectl delete  rc/helloworld-controller"

49
00:04:34,890 --> 00:04:38,960
and then the controller is deleted.

50
00:04:39,420 --> 00:04:47,110
And the last pod is not terminating. These scaling operations are all saved in Kubernetes itself

51
00:04:47,310 --> 00:04:51,610
as a backend ETCD where it saves all those settings, like number of replicas.

52
00:04:51,640 --> 00:04:56,540
You don't always need to have those in the YAML files.

53
00:04:56,680 --> 00:04:58,090
It's easy to have them in YAML,

54
00:04:58,090 --> 00:05:02,840
because then you'll have your state easily available to you in files.

55
00:05:02,840 --> 00:05:08,410
And you can do testing and you can put those things in version control but it's not a necessity.
