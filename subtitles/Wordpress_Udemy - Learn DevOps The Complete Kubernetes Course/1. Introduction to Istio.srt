1
1

00:00:00,240  -->  00:00:01,293
<v Edward>In the next section,</v>
2

2

00:00:01,293  -->  00:00:03,493
I'm going to be talking about microservices.
3

3

00:00:04,753  -->  00:00:06,390
Kubernetes makes it easy to deploy
4

4

00:00:06,390  -->  00:00:08,173
a lot of diverse applications.
5

5

00:00:09,040  -->  00:00:11,050
Those applications can be monoliths
6

6

00:00:11,050  -->  00:00:13,810
that don't have anything to do with each other,
7

7

00:00:13,810  -->  00:00:16,320
or microservices, small services
8

8

00:00:16,320  -->  00:00:18,113
that make up one application.
9

9

00:00:19,290  -->  00:00:23,060
The microservices architecture is increasingly popular.
10

10

00:00:23,060  -->  00:00:24,947
This approach allows developers to split up
11

11

00:00:24,947  -->  00:00:28,163
the application in multiple independent parts.
12

12

00:00:29,260  -->  00:00:31,690
Having to manage microservices can put
13

13

00:00:31,690  -->  00:00:34,223
an operational strain on the engineering team.
14

14

00:00:36,330  -->  00:00:39,780
Here's an example of two monolith applications.
15

15

00:00:39,780  -->  00:00:41,340
On the left, we have a client.
16

16

00:00:41,340  -->  00:00:42,940
That client connects to a load balancer,
17

17

00:00:42,940  -->  00:00:45,130
the load balancer goes to an Ingress controller,
18

18

00:00:45,130  -->  00:00:46,840
and the Ingress controller, depending on
19

19

00:00:46,840  -->  00:00:49,740
the host name, for example, will redirect the client
20

20

00:00:49,740  -->  00:00:52,113
to application one or application two.
21

21

00:00:53,860  -->  00:00:55,390
Application one has its own database,
22

22

00:00:55,390  -->  00:00:57,030
application two has its own database,
23

23

00:00:57,030  -->  00:00:58,750
so these applications don't have
24

24

00:00:58,750  -->  00:01:01,070
anything to do with each other.
25

25

00:01:01,070  -->  00:01:02,810
They are independent from each other.
26

26

00:01:02,810  -->  00:01:05,653
They could be two completely different applications.
27

27

00:01:06,820  -->  00:01:10,570
Now, sometimes, you have one application
28

28

00:01:10,570  -->  00:01:12,400
that is divided into two parts,
29

29

00:01:12,400  -->  00:01:16,115
and those applications will communicate with each other,
30

30

00:01:16,115  -->  00:01:18,090
like in this diagram.
31

31

00:01:18,090  -->  00:01:21,750
App one and App two communicate with each other.
32

32

00:01:21,750  -->  00:01:24,856
Maybe App one needs some data from Database two.
33

33

00:01:24,856  -->  00:01:27,350
So we have one application, and that
34

34

00:01:27,350  -->  00:01:29,950
application is divided into two parts,
35

35

00:01:29,950  -->  00:01:32,350
and they need information from each other.
36

36

00:01:32,350  -->  00:01:33,770
This is probably the start of
37

37

00:01:33,770  -->  00:01:35,653
using microservice architecture.
38

38

00:01:36,580  -->  00:01:38,070
When using the microservice approach,
39

39

00:01:38,070  -->  00:01:40,260
we'll start with maybe one, two services,
40

40

00:01:40,260  -->  00:01:41,770
and then, when the project grows,
41

41

00:01:41,770  -->  00:01:43,660
when more people come on board,
42

42

00:01:43,660  -->  00:01:46,170
you can split applications in multiple parts,
43

43

00:01:46,170  -->  00:01:50,120
or you can add smaller services to your application.
44

44

00:01:50,120  -->  00:01:52,140
At some point, it will look like this,
45

45

00:01:52,140  -->  00:01:54,990
where you then have multiple services
46

46

00:01:54,990  -->  00:01:56,690
multiple parts of your application
47

47

00:01:57,550  -->  00:01:59,720
that are on, and that communicate with each other
48

48

00:01:59,720  -->  00:02:02,510
to then deliver something to the client.
49

49

00:02:02,510  -->  00:02:03,980
You see here that there's lots of traffic
50

50

00:02:03,980  -->  00:02:06,540
between the applications, between the microservices,
51

51

00:02:06,540  -->  00:02:08,320
so they need each other to be able
52

52

00:02:08,320  -->  00:02:09,903
to serve the client.
53

53

00:02:11,084  -->  00:02:13,260
At this point, we can talk about a service mesh.
54

54

00:02:13,260  -->  00:02:15,600
We have all these microservices talking
55

55

00:02:16,498  -->  00:02:17,620
to each other in the form of a mesh,
56

56

00:02:17,620  -->  00:02:19,650
so this is the term that is used for that.
57

57

00:02:19,650  -->  00:02:21,660
It's called Service Mesh.
58

58

00:02:21,660  -->  00:02:24,410
This can bring some new issues that we need to resolve.
59

59

00:02:25,930  -->  00:02:29,700
Between the microservices, you often have no encryption,
60

60

00:02:29,700  -->  00:02:32,400
unless you implement this in every single application.
61

61

00:02:33,360  -->  00:02:35,640
There's no retries, no failover.
62

62

00:02:35,640  -->  00:02:37,560
The communication is often true http,
63

63

00:02:38,950  -->  00:02:41,080
and when the request fails, it will often just
64

64

00:02:41,080  -->  00:02:43,110
show an error, it will not try again,
65

65

00:02:43,110  -->  00:02:45,723
or try a replica of that application.
66

66

00:02:47,080  -->  00:02:49,490
Again, unless you all write this manually
67

67

00:02:49,490  -->  00:02:50,503
in your application.
68

68

00:02:51,490  -->  00:02:53,860
There's no intelligent load balancing.
69

69

00:02:53,860  -->  00:02:56,370
The Ingress controller will deplete load balance
70

70

00:02:56,370  -->  00:02:58,230
based on route dropping.
71

71

00:02:58,230  -->  00:03:01,150
If a bond communicates up to in Kubernetes,
72

72

00:03:01,150  -->  00:03:02,700
then it will go to a service.
73

73

00:03:02,700  -->  00:03:06,400
The service will again use routing to send traffic
74

74

00:03:06,400  -->  00:03:07,660
to the different pods.
75

75

00:03:07,660  -->  00:03:09,650
So there's no intelligent load balancing.
76

76

00:03:09,650  -->  00:03:11,521
It doesn't recheck the latency that it has
77

77

00:03:11,521  -->  00:03:13,120
over different pods.
78

78

00:03:13,120  -->  00:03:15,753
It just routes it using a simple algorithm.
79

79

00:03:16,740  -->  00:03:18,396
There's no routing decisions that you can make
80

80

00:03:18,396  -->  00:03:21,300
so the routing is still very simple.
81

81

00:03:21,300  -->  00:03:22,720
You can make some routing decisions
82

82

00:03:22,720  -->  00:03:24,558
in the ingress controller, but then once
83

83

00:03:24,558  -->  00:03:26,770
you are between the applications,
84

84

00:03:26,770  -->  00:03:28,870
there is no decisions that are being made.
85

85

00:03:29,900  -->  00:03:30,980
There's also no metrics.
86

86

00:03:30,980  -->  00:03:32,320
There's no logs, there's no traces
87

87

00:03:32,320  -->  00:03:34,510
of the communications between the applications,
88

88

00:03:34,510  -->  00:03:35,810
between the microservices.
89

89

00:03:37,290  -->  00:03:38,500
There's no access control.
90

90

00:03:38,500  -->  00:03:41,080
Every applicant communicates with another app.
91

91

00:03:41,080  -->  00:03:43,020
If you want access control, you have to implement that
92

92

00:03:43,020  -->  00:03:45,460
yourself in your microservices.
93

93

00:03:45,460  -->  00:03:47,960
So to implement all these features, it will take
94

94

00:03:47,960  -->  00:03:50,990
a lot of effort to implement those in all your
95

95

00:03:50,990  -->  00:03:52,193
different microservices.
96

96

00:03:53,280  -->  00:03:57,474
So one solution is to add a proxy to every single
97

97

00:03:57,474  -->  00:04:00,610
application, to every single microservice.
98

98

00:04:00,610  -->  00:04:02,963
This is called a sidecar deployment.
99

99

00:04:04,120  -->  00:04:06,535
Now, instead of communicating directly
100

100

00:04:06,535  -->  00:04:10,470
to the apps, you will communicate through the sidecar,
101

101

00:04:10,470  -->  00:04:12,930
through the proxy and this proxy can have
102

102

00:04:12,930  -->  00:04:16,843
some features to solve some of our problems.
103

103

00:04:18,080  -->  00:04:19,410
For example, it can have now
104

104

00:04:19,410  -->  00:04:21,240
encryption between applications.
105

105

00:04:21,240  -->  00:04:24,130
That sidecar will run next to every container
106

106

00:04:24,130  -->  00:04:25,290
that we have.
107

107

00:04:25,290  -->  00:04:27,120
So the communication between the sidecars
108

108

00:04:27,120  -->  00:04:30,220
can have encryption, enabling encryption
109

109

00:04:30,220  -->  00:04:32,833
for our communications between our microservices.
110

110

00:04:33,770  -->  00:04:36,310
You can also have retries when a connection fails.
111

111

00:04:36,310  -->  00:04:38,200
So let's say that you do a Git request.
112

112

00:04:38,200  -->  00:04:40,863
You might want to be able to retry that Git request
113

113

00:04:40,863  -->  00:04:44,016
rather than just having it to fail.
114

114

00:04:44,016  -->  00:04:47,260
It can also now have intelligent load balancing
115

115

00:04:47,260  -->  00:04:49,550
rather than just do range routing,
116

116

00:04:49,550  -->  00:04:51,270
you might take into account the latency
117

117

00:04:51,270  -->  00:04:54,060
for example that you have with one replica
118

118

00:04:54,060  -->  00:04:56,103
that is lower than your replica.
119

119

00:04:57,480  -->  00:04:59,440
You can also add a management interface
120

120

00:04:59,440  -->  00:05:01,178
so the management interface can push changes
121

121

00:05:01,178  -->  00:05:04,003
to these sidecar processes.
122

122

00:05:04,950  -->  00:05:06,511
At that point, you can make routing decisions
123

123

00:05:06,511  -->  00:05:09,412
for example, you can deploy multiple versions
124

124

00:05:09,412  -->  00:05:12,720
of let's say, app three and then have some of the traffic
125

125

00:05:12,720  -->  00:05:16,660
routed to a newer version for AB testing.
126

126

00:05:16,660  -->  00:05:19,110
You could route a certain percentage to a new version
127

127

00:05:19,110  -->  00:05:22,980
of app three, so you can make complex routing decisions.
128

128

00:05:22,980  -->  00:05:25,060
You can also have metrics, logs, and traces.
129

129

00:05:25,060  -->  00:05:27,120
Because the sidecars can keep logs and they
130

130

00:05:27,120  -->  00:05:30,829
can keep metrics and traces from all the communications
131

131

00:05:30,829  -->  00:05:33,225
and you could get all this.
132

132

00:05:33,225  -->  00:05:36,500
And the sidecars can also have access control.
133

133

00:05:36,500  -->  00:05:38,819
So route, for example, can access app three
134

134

00:05:38,819  -->  00:05:40,749
who has access to it.
135

135

00:05:40,749  -->  00:05:43,060
You maybe need a valid certificate to be able
136

136

00:05:43,060  -->  00:05:45,260
to access this application so that
137

137

00:05:45,260  -->  00:05:49,570
external applications can just access our application
138

138

00:05:49,570  -->  00:05:50,973
within our service mesh.
139

139

00:05:53,350  -->  00:05:55,000
This brings us to Istio and this is
140

140

00:05:55,000  -->  00:05:57,020
the architecture diagram of Istio.
141

141

00:05:57,020  -->  00:05:59,550
It's very similar to what I just showed you.
142

142

00:05:59,550  -->  00:06:02,933
Istio uses the envoy proxy for a sidecar deployment.
143

143

00:06:04,760  -->  00:06:07,270
It's a very efficient proxy, very lightweight
144

144

00:06:07,270  -->  00:06:10,330
that you can then include in your pods.
145

145

00:06:10,330  -->  00:06:12,497
If you have app one which is a microservice,
146

146

00:06:12,497  -->  00:06:16,250
you can have this as a container in your pod
147

147

00:06:16,250  -->  00:06:18,820
and next to this container, you will have
148

148

00:06:18,820  -->  00:06:21,880
an envoy proxy within that pod that will deal
149

149

00:06:21,880  -->  00:06:23,960
with all the communication.
150

150

00:06:23,960  -->  00:06:27,180
So the envoys will communicate with each other.
151

151

00:06:27,180  -->  00:06:30,480
You can do this encrypted with authentication
152

152

00:06:30,480  -->  00:06:33,810
so that only those apps within the service mesh
153

153

00:06:33,810  -->  00:06:36,980
can communicate with each other and not outside apps.
154

154

00:06:36,980  -->  00:06:38,932
And you can have policy checks, telemetry.
155

155

00:06:38,932  -->  00:06:41,420
So you can get all your metrics and you can get
156

156

00:06:41,420  -->  00:06:43,613
some insights of your traffic.
157

157

00:06:44,850  -->  00:06:47,950
You will have your configuration data pushed
158

158

00:06:47,950  -->  00:06:49,790
from a central application, pushed from your
159

159

00:06:49,790  -->  00:06:51,970
Istio so all the configuration decisions
160

160

00:06:51,970  -->  00:06:53,832
are made centrally and then pushed throughout
161

161

00:06:53,832  -->  00:06:56,053
your envoy proxies.
162

162

00:06:56,960  -->  00:06:58,850
And citadel, on the right here,
163

163

00:06:58,850  -->  00:07:03,190
can also provide TLS certs for every envoy proxy.
164

164

00:07:03,190  -->  00:07:06,040
You can then also have authentication using certificates.
165

165

00:07:07,070  -->  00:07:09,157
This is all managed by the control plane API
166

166

00:07:09,157  -->  00:07:11,520
which allows for central management
167

167

00:07:11,520  -->  00:07:13,263
of this service mesh.
168

168

00:07:14,720  -->  00:07:17,240
So once you start using microservices,
169

169

00:07:17,240  -->  00:07:19,882
when you have a service mesh, Istio is a great solution
170

170

00:07:19,882  -->  00:07:23,230
to get a whole new feature set ready
171

171

00:07:23,230  -->  00:07:25,950
then implementing this on the app level.
172

172

00:07:25,950  -->  00:07:27,920
In the next demo, I will show you how to
173

173

00:07:27,920  -->  00:07:30,483
deploy Istio to your Kubernetes Cluster.
