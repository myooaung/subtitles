WEBVTT
1
00:00:00.980 --> 00:00:03.180
Hello everyone and welcome to this letter.

2
00:00:03.840 --> 00:00:05.060
I write this letter.

3
00:00:05.090 --> 00:00:10.320
We're going to dig a little bit deeper and understand how convolution and the other networks work.

4
00:00:10.410 --> 00:00:11.000
OK.

5
00:00:11.210 --> 00:00:17.330
In the previous section we discussed how can we build one single neurone mathematically and we learn

6
00:00:17.360 --> 00:00:22.790
how can we build a couple of neurones connected to each other is to build a very small artificial neural

7
00:00:22.790 --> 00:00:23.730
network OK.

8
00:00:23.900 --> 00:00:29.440
By building by building in different layers input layer in layers and out quickly.

9
00:00:29.630 --> 00:00:30.480
OK.

10
00:00:30.580 --> 00:00:30.840
All right.

11
00:00:30.860 --> 00:00:32.200
Now to the fun part.

12
00:00:32.600 --> 00:00:34.320
So what are we going to do here.

13
00:00:34.370 --> 00:00:41.630
We're going open our neural network which is a kind of you know like we built before and this network

14
00:00:41.690 --> 00:00:42.900
generates an output.

15
00:00:42.950 --> 00:00:43.320
Okay.

16
00:00:43.340 --> 00:00:49.000
And in our specific example we have a tolga class zero indicates not smiling.

17
00:00:49.010 --> 00:00:55.120
That means that the you know the image that's fed to the network generates a label of zero indicates

18
00:00:55.130 --> 00:00:58.230
that that person or that image is not smiling at the moment.

19
00:00:58.400 --> 00:01:00.240
One indicates Smiley.

20
00:01:00.390 --> 00:01:01.040
Right.

21
00:01:01.440 --> 00:01:02.360
Okay.

22
00:01:02.510 --> 00:01:07.850
So simply put what we could do here which is you know what kind of make sense.

23
00:01:07.880 --> 00:01:13.300
Why don't we just take all these images that we had in here which is a taining data.

24
00:01:13.610 --> 00:01:19.780
Just put them and feed them directly to our network or our input here to generate our of the class.

25
00:01:19.900 --> 00:01:20.160
OK.

26
00:01:20.210 --> 00:01:21.660
Why don't we do this.

27
00:01:22.040 --> 00:01:25.770
Simply put the network performance we're going to be terrible.

28
00:01:25.790 --> 00:01:27.890
We are kind of allowed to do you can do it.

29
00:01:27.910 --> 00:01:30.830
But you know with the performance would be terrible.

30
00:01:31.050 --> 00:01:31.360
All right.

31
00:01:31.400 --> 00:01:34.910
And that's why we need one of convolution and you got a network.

32
00:01:35.150 --> 00:01:37.290
We need something to be done here.

33
00:01:37.450 --> 00:01:38.200
OK.

34
00:01:38.510 --> 00:01:44.750
To extract all quality features out of these images which is you know very important concept.

35
00:01:44.770 --> 00:01:49.710
I'm going to be discussing great now if so will quality feature detection or feature detectors.

36
00:01:49.850 --> 00:01:50.890
Let's take a look.

37
00:01:51.260 --> 00:01:56.000
So again what we're discussing here is I wanted to build a specific type of fission you're a network

38
00:01:56.360 --> 00:02:01.340
vehicle convolution and you get a network which is really powerful in image classification would feature

39
00:02:01.340 --> 00:02:02.390
detection.

40
00:02:02.390 --> 00:02:07.800
So let's see how can we build our fission Confucianism network from scratch.

41
00:02:08.510 --> 00:02:13.750
So what happened is what we do with that we take our images which is again a bunch of smiley or none

42
00:02:13.760 --> 00:02:14.970
smiling faces.

43
00:02:15.200 --> 00:02:21.130
We pass these images to what we call a layered so called convolution and they key.

44
00:02:21.500 --> 00:02:26.790
So when you see convolution layered that means just a bunch think of it as a bunch of filters.

45
00:02:26.850 --> 00:02:27.470
OK.

46
00:02:28.000 --> 00:02:32.690
I'm going to discuss what they mean by crinolines what they mean by feature detectors in the next in

47
00:02:32.690 --> 00:02:33.420
the next lecture.

48
00:02:33.560 --> 00:02:37.220
He'd have want to give you an idea of the overall network and then going to dig a little bit deeper

49
00:02:37.220 --> 00:02:42.440
into different layers to understand what do you mean by each one on its own.

50
00:02:42.680 --> 00:02:49.270
So I can see here convolution that where it consists first of all the collet kernels or feature detectors

51
00:02:49.300 --> 00:02:49.840
layer.

52
00:02:50.030 --> 00:02:50.630
Okay.

53
00:02:50.780 --> 00:02:51.840
Simply put.

54
00:02:52.160 --> 00:02:59.960
What happens is we apply these feature detectors on our image to detect or to pain specific layers of

55
00:02:59.960 --> 00:03:02.320
specific features out of this image.

56
00:03:02.400 --> 00:03:03.090
OK.

57
00:03:03.530 --> 00:03:07.280
And what we do afterwards we use what we call the pooling layer.

58
00:03:07.520 --> 00:03:15.420
Okay this pulling layer objective is to simply reduce the size of these features into a smaller size.

59
00:03:15.470 --> 00:03:16.360
Okay.

60
00:03:16.370 --> 00:03:23.810
And after we do this afternoon do the max pooling layer or the pulling layer we flatten of this basically

61
00:03:23.840 --> 00:03:30.140
images into a certain kind of you know like one single layer and that will be ready to be fed or to

62
00:03:30.140 --> 00:03:35.420
be imported to our fissioning or network which are simple fishing you know that we discussed before

63
00:03:35.510 --> 00:03:40.160
in the past this network by the way is well fully connected are efficient your network.

64
00:03:40.310 --> 00:03:40.840
OK.

65
00:03:41.150 --> 00:03:46.100
I still don't understand this might seem like a token like a little bit overwhelming but all what I

66
00:03:46.100 --> 00:03:51.700
wanted to do here the one understand here is that we can not use it fully connected artificial neural

67
00:03:51.700 --> 00:03:54.970
networks here to just classify images.

68
00:03:55.070 --> 00:03:56.690
OK what we need to do with that.

69
00:03:56.690 --> 00:04:01.520
We need to pain or to apply certain confusion and layers beforehand okay.

70
00:04:01.760 --> 00:04:04.720
We need to apply a convolution or feature detectors layer.

71
00:04:04.760 --> 00:04:08.480
I'm going to discuss that in a lot more details in the future in future next lecture.

72
00:04:08.870 --> 00:04:12.730
And then what you will call a pooling or Max pruning layer that three deuces.

73
00:04:12.740 --> 00:04:19.730
This basically features into smaller values that we can feed directly to our network then them can use

74
00:04:19.730 --> 00:04:23.820
it to classify the image into either smiling or smiling.

75
00:04:23.910 --> 00:04:24.450
OK.

76
00:04:24.670 --> 00:04:25.300
All right.

77
00:04:25.340 --> 00:04:30.470
Again if you guys are not following over all don't worry about it here there's just a quick overview

78
00:04:30.530 --> 00:04:34.580
of all how it came from China and what works in the next election.

79
00:04:34.580 --> 00:04:37.850
We're going to dig a little bit deeper into what you mean by this layer.

80
00:04:37.910 --> 00:04:42.210
What do you mean by next late next pulling or pulling and what they mean by flattening.

81
00:04:42.350 --> 00:04:45.950
And then we're going to go ahead to shoot in our book and start coding right away.

82
00:04:46.250 --> 00:04:49.220
I hope you guys enjoy their lecture and see you in the next lecture.
