WEBVTT
1
00:00:00.490 --> 00:00:03.680
Hello everyone and welcome this lecture and this lecture.

2
00:00:03.730 --> 00:00:08.850
We're going to discuss a very kind of buzz word nowadays where a college diploma.

3
00:00:09.050 --> 00:00:16.840
OK so deep learning is mainly a subset of machine learning that utilizes multi layer artificial neural

4
00:00:16.840 --> 00:00:17.400
network.

5
00:00:17.600 --> 00:00:20.940
Okay so let's take a look at a kind of a graphical representation.

6
00:00:21.250 --> 00:00:22.610
It's where guests can see here.

7
00:00:23.080 --> 00:00:28.660
We have artificial intelligence or I which is all a kind of them that can be the mother of everything.

8
00:00:28.690 --> 00:00:28.900
OK.

9
00:00:28.930 --> 00:00:34.090
Which is how can we mimic our human intelligence within artificial intelligence.

10
00:00:34.090 --> 00:00:36.680
There is machine learning which a subset of it.

11
00:00:36.840 --> 00:00:37.630
Okay.

12
00:00:37.900 --> 00:00:40.090
And then within it there is deep learning.

13
00:00:40.220 --> 00:00:46.890
Okay which is specifically trying to teach what call a proficient you know networks in a deep fashion.

14
00:00:47.050 --> 00:00:47.780
OK.

15
00:00:48.040 --> 00:00:52.930
I'm going to tell you exactly what they mean by fashion to you know do different tasks.

16
00:00:52.930 --> 00:00:56.650
We can use it to perform regression and can use it to perform classification.

17
00:00:56.650 --> 00:00:58.720
We can do tons of tons of things with it.

18
00:00:58.970 --> 00:01:03.980
Actually in this like in this course we're going to take kind of a dig a little deeper.

19
00:01:04.030 --> 00:01:10.960
We're going to use the planning to actually classify different faces into let's say smiling happy faces

20
00:01:10.990 --> 00:01:14.920
or let's say frowning faces for instance.

21
00:01:15.580 --> 00:01:19.990
So this is simply how we build our what we call a deep neural network.

22
00:01:19.990 --> 00:01:27.490
We have these black dots it's what call neurones which is simply trying to mimic how our human neurones

23
00:01:27.490 --> 00:01:30.730
works how our biological insurance works.

24
00:01:31.450 --> 00:01:37.300
So we simply take a look at our neurones our biological neurones and we try to copy them.

25
00:01:37.300 --> 00:01:43.330
We try to mimic them and we connect them together in this kind of a structured format and in a kind

26
00:01:43.330 --> 00:01:48.990
of qualifiable input layer we have what I call the opiate or the targets which is our opaquely.

27
00:01:49.240 --> 00:01:52.020
And then he we have seen visible quality hidden layers.

28
00:01:52.060 --> 00:01:55.490
Again please don't beat Nogi Don't be intimidated.

29
00:01:55.690 --> 00:02:01.260
It's very very simple and I'm going to discuss that in in way more details in the next in the next section

30
00:02:01.330 --> 00:02:04.720
when we discuss you know when they can take a look at the practical applications politically or any

31
00:02:05.290 --> 00:02:08.670
this just the quick overview what do you mean by it why it's called deep.

32
00:02:08.890 --> 00:02:12.600
We call it deep because here we have more than one hidden layers.

33
00:02:12.910 --> 00:02:19.100
So we have like hundreds maybe thousands of neurones here in these kind of different layers and we connect

34
00:02:19.120 --> 00:02:20.640
them in this fashion.

35
00:02:20.920 --> 00:02:25.270
And that's what we call it you know when we say deplaning or right again deep learning it's kind of

36
00:02:25.270 --> 00:02:29.840
a subset of machine learning which is a subset of artificial intelligence.

37
00:02:29.840 --> 00:02:30.350
All right.

38
00:02:30.480 --> 00:02:31.600
Okay.

39
00:02:32.320 --> 00:02:34.080
So which Stickney should we use.

40
00:02:34.160 --> 00:02:34.720
Okay that's.

41
00:02:34.720 --> 00:02:36.900
Again it's a very kind of you know car like.

42
00:02:37.080 --> 00:02:37.410
OK.

43
00:02:37.410 --> 00:02:38.500
Important question.

44
00:02:38.780 --> 00:02:41.020
And let's take a look at what Dick Meeks.

45
00:02:41.020 --> 00:02:46.540
Do we have available right now when it comes to classification which comes to aggression when it comes

46
00:02:46.540 --> 00:02:48.130
to clustering.

47
00:02:48.170 --> 00:02:51.120
So coastal classification we have discrete outputs.

48
00:02:51.180 --> 00:02:51.420
OK.

49
00:02:51.450 --> 00:02:56.710
So our outputs for example are discrete let's say for operators let's say 0 1.

50
00:02:56.930 --> 00:02:57.490
Okay.

51
00:02:57.670 --> 00:03:01.090
Then we can use classification exemplars of that.

52
00:03:01.090 --> 00:03:03.780
We can use or we call a support vector machines.

53
00:03:03.820 --> 00:03:11.020
Actually going to have an example like in piki study on support of the machines we have one a Navy base.

54
00:03:11.110 --> 00:03:12.580
We have random force.

55
00:03:12.670 --> 00:03:18.280
We have canniest neighbours and we have all kind of logistic regression which is again useful classification

56
00:03:18.280 --> 00:03:19.740
purposes.

57
00:03:20.080 --> 00:03:24.020
Again guys please bear in mind that this course is not a full blown machine.

58
00:03:24.050 --> 00:03:30.730
And of course this course is kind of a subset of the entire Python you know beginning to pro masterclass

59
00:03:31.150 --> 00:03:36.550
and the overall objective is to give you kind of you all look like three case studies you know that

60
00:03:36.550 --> 00:03:39.760
teaches you the basics of foundation of machine learning.

61
00:03:39.760 --> 00:03:45.490
If you're interested please go ahead and you know maybe discover another deep specific machine learning

62
00:03:45.490 --> 00:03:51.310
course may be full blown 20 or 30 hours machine learning course but here we're just going to take kind

63
00:03:51.310 --> 00:03:55.900
of a sample of some of these classification and aggression techniques to give you an idea of what do

64
00:03:55.900 --> 00:04:02.920
you mean by machine learning in general and how can we use it in your in a Python programming format.

65
00:04:02.950 --> 00:04:09.590
So again when we do classification that means we have our output is discrete or discrete or categories.

66
00:04:09.880 --> 00:04:16.130
So if we have let's say outputs let's say 0 or 1 then we can use classification to perform this the

67
00:04:16.590 --> 00:04:18.830
next categories we'll call it aggression.

68
00:04:19.210 --> 00:04:25.420
So if I were alpert is in a continuous format let's say You for example predicting let's say the temperature

69
00:04:25.480 --> 00:04:31.270
of a room or expecting let's say or predicting the revenue expect revenue and actually have an example

70
00:04:31.270 --> 00:04:32.720
on revenue predictions.

71
00:04:33.040 --> 00:04:37.580
Then we can go ahead and use that aggression we can you simply new aggression.

72
00:04:37.750 --> 00:04:42.760
We have multiple linear regression and we have more quality polynomial regression.

73
00:04:42.930 --> 00:04:47.530
Said different categories in this course will get our media focussed on the simple linear regression

74
00:04:47.620 --> 00:04:49.040
as an example for the Gresh.

75
00:04:50.350 --> 00:04:53.040
The techniques will kill a clustering.

76
00:04:53.230 --> 00:04:55.550
Which is we don't have label data.

77
00:04:55.600 --> 00:04:58.450
We don't have any rebuilded at all we just feed the data in there.

78
00:04:58.450 --> 00:05:03.970
And you know the machine or the algorithm you just try to find clusters or try to find categories or

79
00:05:03.970 --> 00:05:08.790
categorize the data on its own try to find patterns within the data.

80
00:05:08.860 --> 00:05:11.650
An example of that is it market segmentation.

81
00:05:11.980 --> 00:05:17.470
So if you wanted for example to Lawrence let's say a marketing campaign we can use market segmentation

82
00:05:17.830 --> 00:05:21.850
to define the market or to divide the to customers in different segments.

83
00:05:21.940 --> 00:05:28.990
Let's say for example you know like laker humans for instance or customers that like for example these

84
00:05:28.990 --> 00:05:34.180
specific type of courses for instance we're going to launch a marketing strategy for them and that's

85
00:05:34.180 --> 00:05:36.860
how we do it when it comes to clustering.

86
00:05:36.980 --> 00:05:37.420
OK.

87
00:05:37.600 --> 00:05:43.530
Or you know I'm an unsupervised fashion and executive there's war college kids means kloster.

88
00:05:44.000 --> 00:05:46.170
Ah it's okay.

89
00:05:46.180 --> 00:05:50.620
And that's kind of an overview of the different you know the meets again what I'm going to discuss all

90
00:05:50.620 --> 00:05:55.810
these techniques in this course he'll get a focussed focus on you know is simple of a support that can

91
00:05:55.810 --> 00:06:02.600
machines and simple it aggression and also going to cover an example for deplaning in this course.

92
00:06:02.660 --> 00:06:04.810
Let's recap what we have covered so far.

93
00:06:04.900 --> 00:06:10.840
We this lectures we give an overview of what they mean by deep learning which is again you know like

94
00:06:10.840 --> 00:06:15.640
deep you know networks are kind of inspired by the human brain and we call it deep because we build

95
00:06:15.640 --> 00:06:17.470
these networks in in deep passion.

96
00:06:17.470 --> 00:06:20.490
We have different neurones connected in different layers.

97
00:06:20.670 --> 00:06:23.630
We had discussed that in a much more details moving forward.

98
00:06:24.110 --> 00:06:30.840
And then in the next sections end which technique will we use can be categorized either to classification.

99
00:06:30.840 --> 00:06:35.720
So if your output is either let's say Zealand one we can use classification n can you suppose we were

100
00:06:35.720 --> 00:06:36.460
to machines.

101
00:06:36.460 --> 00:06:39.970
Now you've been Zen and forest genius neighbours and so on.

102
00:06:40.080 --> 00:06:45.090
The question came in the use of our LP this continuous in a way clustering.

103
00:06:45.100 --> 00:06:49.910
If you don't have any Lieben dear if we'll have any liebert data we can just use unsupervised learning.

104
00:06:50.050 --> 00:06:53.430
We can use the key alchemies closeting to cluster a word.

105
00:06:53.440 --> 00:06:56.930
They are right and this very much all for this lecture.

106
00:06:56.950 --> 00:07:00.500
I hope you guys enjoy it and see you in the future lectures.
