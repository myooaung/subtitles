WEBVTT
1
00:00:03.530 --> 00:00:05.950
So let's take a look at the model evaluation.

2
00:00:06.070 --> 00:00:06.550
OK.

3
00:00:06.800 --> 00:00:08.310
So now we're in the model.

4
00:00:08.330 --> 00:00:11.420
We wanted to test that more than in reality.

5
00:00:11.420 --> 00:00:17.260
So going to expose a model to data that the model hasn't seen before during the training and that's

6
00:00:17.260 --> 00:00:22.680
a key essence in testing any machine learning or the cloning model.

7
00:00:22.880 --> 00:00:25.930
So let's take a look at our model here.

8
00:00:26.090 --> 00:00:28.370
So let's assume again let's go back to our two classes.

9
00:00:28.380 --> 00:00:29.590
We have the blue classes here.

10
00:00:29.600 --> 00:00:36.380
We have the red classes and we have kind of two features on the x axis and Y axis and we separated these

11
00:00:36.380 --> 00:00:40.340
two classes using what we call the maximum margin hyperlinked.

12
00:00:40.700 --> 00:00:46.460
Okay which is the line which is the support in machine learning technique has been able to separate

13
00:00:46.490 --> 00:00:48.060
these two classes.

14
00:00:48.150 --> 00:00:50.660
Okay so the point is.

15
00:00:50.690 --> 00:00:54.290
Okay so now we've changed our model now the model is good looks perfect.

16
00:00:54.290 --> 00:00:55.400
Now we want to test it.

17
00:00:55.470 --> 00:00:56.110
OK.

18
00:00:56.390 --> 00:01:02.160
The key element that we do not use data that we have use doing training to test our model.

19
00:01:02.250 --> 00:01:02.580
Okay.

20
00:01:02.600 --> 00:01:04.210
We don't simply do this.

21
00:01:04.460 --> 00:01:04.730
Why.

22
00:01:04.730 --> 00:01:07.690
Because in general these models are kind of trained.

23
00:01:07.790 --> 00:01:11.170
They have been trained to to use specific datasets.

24
00:01:11.180 --> 00:01:14.050
We generally don't use a teeling data to test or model.

25
00:01:14.120 --> 00:01:20.100
We actually use another datasets or call testing data to test our model and see if classifies our data

26
00:01:20.190 --> 00:01:22.840
set into again malignant or benign is.

27
00:01:22.940 --> 00:01:27.110
So that's where we use it actually best thing beta which is kind of data that the model hasn't seen

28
00:01:27.110 --> 00:01:29.760
before during training.

29
00:01:29.870 --> 00:01:34.090
Let's test our model to see if we can actually generalize classifies or model or not.

30
00:01:34.110 --> 00:01:34.450
Okay.

31
00:01:34.550 --> 00:01:36.160
So that's how we evaluate our model.

32
00:01:36.280 --> 00:01:36.980
Okay.

33
00:01:37.490 --> 00:01:43.320
So one of the key features or out of the are one of the key objectives of our machine learning Meeks

34
00:01:43.450 --> 00:01:50.280
means that we want these models to generalise the deed which is what we mean by a model generalisation

35
00:01:50.660 --> 00:01:59.240
that we win at the machine learning strategy to not train or to not seen a model specifically for this

36
00:01:59.240 --> 00:02:00.330
training dataset.

37
00:02:00.440 --> 00:02:06.890
We want the model to be general to basically look at most of the images moving forward of lets say cancer

38
00:02:07.400 --> 00:02:12.830
data or images and tell us if it's malignant or benign even if the images hasn't been seen before or

39
00:02:12.890 --> 00:02:13.760
during training.

40
00:02:13.990 --> 00:02:14.250
OK.

41
00:02:14.270 --> 00:02:18.560
And that's basically what how can we effectively use machine only these techniques sort of strategies

42
00:02:18.590 --> 00:02:19.350
in real life.

43
00:02:19.390 --> 00:02:20.120
Right.

44
00:02:20.690 --> 00:02:27.860
So this model actually if our support machine was able to classify or maybe put the hydroplane in here

45
00:02:28.260 --> 00:02:30.970
that can tell us okay this model is kind of generalized.

46
00:02:31.910 --> 00:02:41.180
However we can as well try a boundary in a way that simply or is specifically designed to fit our training

47
00:02:41.220 --> 00:02:41.880
dataset.

48
00:02:42.050 --> 00:02:42.650
Okay.

49
00:02:42.710 --> 00:02:48.170
And in this case what we call the model is that over a fitted model would mean that the model has learned

50
00:02:48.230 --> 00:02:51.050
all the characteristics out of only the training.

51
00:02:51.230 --> 00:02:58.120
Okay so if we expose the model again to some testing beta actually this model might be my work better

52
00:02:58.160 --> 00:03:00.340
the generalized model would be working better.

53
00:03:00.410 --> 00:03:00.810
OK.

54
00:03:01.010 --> 00:03:06.620
And that's one of the key elements one which you would model that we want a model to be as general as

55
00:03:06.620 --> 00:03:07.900
possible.

56
00:03:08.150 --> 00:03:15.910
So it could classifiers Again future images that hasn't been seen during training moving forward.

57
00:03:16.110 --> 00:03:17.690
OK.

58
00:03:18.110 --> 00:03:19.640
So how can we evaluate our model.

59
00:03:19.670 --> 00:03:22.260
So we simply use what call the confusion matrix.

60
00:03:22.280 --> 00:03:26.200
We're going to use going to see how can we implemented using Python.

61
00:03:26.540 --> 00:03:32.420
So all we're going to do is we simply wanted to kind of look at one matrix that tells us okay this is

62
00:03:32.420 --> 00:03:35.970
the results of our testing or or two.

63
00:03:36.050 --> 00:03:43.250
OK so what we do is that we call that matrix where he rose show the predictions and other columns.

64
00:03:43.260 --> 00:03:44.740
It sure the true classes.

65
00:03:44.840 --> 00:03:45.380
Okay.

66
00:03:45.590 --> 00:03:52.730
So this is kind of the LP of the model output of the guests of the model the columns can tell us a class

67
00:03:52.760 --> 00:03:58.680
which is kind of the true prediction or the true value of our target class.

68
00:03:58.730 --> 00:03:59.530
OK.

69
00:04:00.380 --> 00:04:00.790
Okay.

70
00:04:00.830 --> 00:04:07.180
So if the prediction if for example our model or our thaine model told us Okay this cancer is malignant

71
00:04:07.190 --> 00:04:08.540
for example.

72
00:04:08.920 --> 00:04:12.040
And the two class told us as well it's malignant then were good.

73
00:04:12.050 --> 00:04:13.120
That means it's true.

74
00:04:13.280 --> 00:04:18.780
We're going to put kind of a summary here of the number of samples their predictions had to match the

75
00:04:18.780 --> 00:04:19.960
chore of the class.

76
00:04:20.090 --> 00:04:28.580
OK well what if for instance the predictions for example said the year the patient is negative for instance

77
00:04:29.080 --> 00:04:32.150
and the true class was negative which means that the patient is good.

78
00:04:32.180 --> 00:04:33.650
You know he doesn't have cancer.

79
00:04:33.860 --> 00:04:39.230
That means if the prediction said that he doesn't have cancer in the true class said he actually the

80
00:04:39.230 --> 00:04:41.220
patient didn't have cancer then it would good.

81
00:04:41.250 --> 00:04:46.190
They're going to put other total numbers of classes here that has been classified correctly.

82
00:04:46.520 --> 00:04:51.740
So simply if some of the number of elements in here with the elements in here that will tell us the

83
00:04:51.740 --> 00:04:56.700
overall number of truly classified semples in a very simple form.

84
00:04:57.020 --> 00:05:02.730
However if for instance our prediction told us the.

85
00:05:02.780 --> 00:05:06.370
Patient has cancer for example which is kind of positive.

86
00:05:06.570 --> 00:05:10.110
However our class was negative.

87
00:05:10.250 --> 00:05:10.750
OK.

88
00:05:10.880 --> 00:05:13.760
That means the city's Fourth prediction that means something went wrong.

89
00:05:13.910 --> 00:05:15.260
However it's not that severe.

90
00:05:15.260 --> 00:05:16.420
I'm going to show you that later.

91
00:05:16.520 --> 00:05:18.210
I'm going to show you after the recovery.

92
00:05:18.280 --> 00:05:23.760
This element but again this this kind of misclassify class which means the prediction was off compared

93
00:05:23.780 --> 00:05:24.540
to our to.

94
00:05:24.570 --> 00:05:25.690
That's.

95
00:05:25.830 --> 00:05:26.370
All right.

96
00:05:26.570 --> 00:05:27.650
The next element is.

97
00:05:27.680 --> 00:05:33.290
Okay what if for instance our machine learning model predicts there our predictions were negative and

98
00:05:33.290 --> 00:05:34.510
the Took less was positive.

99
00:05:34.590 --> 00:05:38.100
Okay that means against misclassified or a fourth classified.

100
00:05:38.150 --> 00:05:43.130
And that means that the number of elements in here and the number of elements in here that would tell

101
00:05:43.130 --> 00:05:47.080
us the overall number of misclassified samples right.

102
00:05:47.680 --> 00:05:47.970
Okay.

103
00:05:47.990 --> 00:05:49.340
Now to a very important point.

104
00:05:49.370 --> 00:05:56.900
So we have what we call a type 1 error and type 2 type 1 error indicates that the prediction was tell

105
00:05:56.900 --> 00:05:59.590
us that the patient has a disease.

106
00:05:59.600 --> 00:06:06.400
However for the two class he actually didn't which is again of course it's it's still an error but again

107
00:06:06.750 --> 00:06:07.580
type 1 error.

108
00:06:07.640 --> 00:06:07.940
Why.

109
00:06:07.940 --> 00:06:09.220
Because the patient is still fine.

110
00:06:09.230 --> 00:06:10.000
He's still looking.

111
00:06:10.190 --> 00:06:12.600
We said he might have something but he didn't go.

112
00:06:12.710 --> 00:06:19.290
However for type 2 that's a big problem and we wanted to avoid this at all costs specially if it's a

113
00:06:19.400 --> 00:06:21.450
life threatening disease like cancer.

114
00:06:21.740 --> 00:06:26.570
So here if we have our true class said it's positive that the patient had cancer.

115
00:06:26.750 --> 00:06:30.260
But we said no on our machine learning model said the patient is fine.

116
00:06:30.260 --> 00:06:31.370
The patient is okay.

117
00:06:31.400 --> 00:06:32.240
This is a big problem.

118
00:06:32.240 --> 00:06:34.240
That's what I call a pipe to air.

119
00:06:34.340 --> 00:06:34.790
Okay.

120
00:06:34.880 --> 00:06:38.070
And we want again to avoid this classification at all costs.

121
00:06:38.110 --> 00:06:39.230
Right.

122
00:06:39.260 --> 00:06:41.480
And that's all what we have for demandingly evaluation.

123
00:06:41.510 --> 00:06:45.070
Let's look at the Jupiter book and let's see how can we believe it or not.

124
00:06:45.290 --> 00:06:47.760
So let's take a look at how can we evaluate what model.

125
00:06:48.710 --> 00:06:50.030
So let's recap.

126
00:06:50.030 --> 00:06:55.190
So what we did so far is that we just seen a model so we use the fix method when our object is we see

127
00:06:55.340 --> 00:06:59.320
this code model and we use the taining data exchange and whity.

128
00:06:59.410 --> 00:06:59.900
OK.

129
00:07:00.170 --> 00:07:02.100
So now it's a time to actually evaluate them on.

130
00:07:02.200 --> 00:07:02.530
OK.

131
00:07:02.600 --> 00:07:08.990
So let's improve let's evaluate the first step is we're going to use our object as we see underscored

132
00:07:08.990 --> 00:07:18.830
model getting use again with the Predict method to predict our or to run kind of AB evaluation on our

133
00:07:18.830 --> 00:07:19.580
teen model.

134
00:07:19.940 --> 00:07:23.210
But in this time which is really important that we're not going to positively team.

135
00:07:23.270 --> 00:07:27.450
We're talking about the testing data which has data that has never seen before.

136
00:07:27.500 --> 00:07:33.830
So you know X underscores test that simply our call this should be uppercase X and this could test an

137
00:07:33.830 --> 00:07:34.750
organ to do that.

138
00:07:34.750 --> 00:07:37.700
Basically this method should be turned back out.

139
00:07:37.770 --> 00:07:41.660
We're going to call it why predict okay they'll give me that prediction.

140
00:07:41.760 --> 00:07:42.410
OK.

141
00:07:42.620 --> 00:07:43.400
That's a first step.

142
00:07:43.400 --> 00:07:48.120
So let's start this consistent successfully and why predict supposed to be our prediction.

143
00:07:48.140 --> 00:07:51.510
Actually it's they can look at it so right rate is going to be here.

144
00:07:51.560 --> 00:07:52.770
And let's take a look at it.

145
00:07:52.850 --> 00:07:56.780
It's actually going to show it showed me it's really a pretty interesting ad showing me all of them

146
00:07:56.780 --> 00:08:00.870
at once which is you know would scanner makes sense I'm going to show you why later.

147
00:08:00.980 --> 00:08:04.160
Which is simply telling me that the model you know is not team.

148
00:08:04.160 --> 00:08:06.940
That means that the model is literally like useless.

149
00:08:06.980 --> 00:08:07.400
OK.

150
00:08:07.520 --> 00:08:09.790
And we'll see how can we actually improve the model moving forward.

151
00:08:10.070 --> 00:08:11.120
So let's keep going.

152
00:08:11.150 --> 00:08:14.110
So I'm going to do it going to plot a confusion matrix.

153
00:08:14.150 --> 00:08:14.780
Okay.

154
00:08:15.280 --> 00:08:23.910
So there's a confusing me to just give you one one stop shop of all the matrix that shows all the curricular

155
00:08:23.900 --> 00:08:27.410
sify temples and the misclassify temple as well.

156
00:08:27.420 --> 00:08:27.820
All right.

157
00:08:28.100 --> 00:08:28.580
So that's right.

158
00:08:28.580 --> 00:08:38.300
Confusion and underscoring matrix and then what we need to do is that we need to specify compare our

159
00:08:38.600 --> 00:08:41.780
true value versus the predicted that.

160
00:08:42.130 --> 00:08:47.700
So our true value is simply why discourse test which is simply this is the true target value sorry.

161
00:08:48.110 --> 00:08:52.650
And we have our values or our predictions we'll call it underscored.

162
00:08:52.670 --> 00:08:54.010
Predict.

163
00:08:54.350 --> 00:08:56.660
And simply this we're going to turn.

164
00:08:56.690 --> 00:08:57.220
Let's see.

165
00:08:57.320 --> 00:08:58.290
Let's see.

166
00:08:58.550 --> 00:08:59.350
Let's try it.

167
00:08:59.390 --> 00:09:02.900
Okay so then we have our coffee Matrix now one of you with a confusing matrix.

168
00:09:02.950 --> 00:09:08.660
So going to use this keyboard and again interview our confuser matrix you going to use a heat map in

169
00:09:08.660 --> 00:09:17.780
our seaborne library to get a sense of heat map and we're going to do going to see em which is simply

170
00:09:17.780 --> 00:09:23.780
our value is suppose to be the matrix and actually let's start on it first without any anything.

171
00:09:23.780 --> 00:09:24.630
So we're going to do.

172
00:09:24.790 --> 00:09:29.990
So you can assure me this is our matrix which is doesn't show simply any values any counts here which

173
00:09:29.990 --> 00:09:31.220
is basically useless.

174
00:09:31.250 --> 00:09:35.160
So going to do you we're going to need to show the innovation going on at an additional equal equals

175
00:09:35.180 --> 00:09:37.980
2 which has shown me the natural value.

176
00:09:38.000 --> 00:09:39.450
Now it makes sense.

177
00:09:39.470 --> 00:09:46.300
So what we can see here from the confusion matrix that simply we have zero correctly classified templates

178
00:09:46.300 --> 00:09:47.440
for the first class.

179
00:09:47.440 --> 00:09:54.440
So we have 40 samples are mis classified which is really terrible evaluation.

180
00:09:54.610 --> 00:09:55.590
All right.

181
00:09:56.210 --> 00:09:58.390
So that's pretty much how can we evaluate our models.

182
00:09:58.490 --> 00:10:02.540
Obviously we haven't done a little bit a lot of stuff maybe a little bit wrong.

183
00:10:02.790 --> 00:10:03.920
We should improve the model.

184
00:10:04.020 --> 00:10:06.540
I'm going to show you in the next step how can we improve the model.

185
00:10:06.570 --> 00:10:08.650
I hope you guys enjoyed it and see you in the next section.
