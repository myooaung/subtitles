1
00:00:00,930 --> 00:00:02,290
Welcome back everyone.

2
00:00:02,490 --> 00:00:07,260
In this lecture we're going to again take a look at the previous movie reviews dataset that we've already

3
00:00:07,380 --> 00:00:10,080
explored using text classification techniques.

4
00:00:10,530 --> 00:00:15,700
Let's now apply sentiment analysis and see how that compares at discovering the labels.

5
00:00:15,720 --> 00:00:18,790
Let's open up a notebook and get started OK.

6
00:00:18,790 --> 00:00:26,740
Let's begin by importing numb pies and PPI and importing pandas as PD and then we're going to do is

7
00:00:26,800 --> 00:00:33,400
read in the as we file and underneath the text files folder depending on where you have it save on your

8
00:00:33,400 --> 00:00:34,330
computer.

9
00:00:34,330 --> 00:00:41,290
There is the movie's review that TSC file raising movie reviews that TSB not movie reviews too.

10
00:00:41,650 --> 00:00:48,190
And then since this is tab separated we need to indicate that by saying SGP and then separator is backslash

11
00:00:48,190 --> 00:00:48,920
T.

12
00:00:49,180 --> 00:00:55,300
So we've already seen this dataset again we can check it out with head and we see we have labels and

13
00:00:55,390 --> 00:01:01,510
as well as the reviews and we can also do a quick check to make sure there are no blank records so we

14
00:01:01,510 --> 00:01:07,510
can do here is say the F drop N A and then say in place is equal to true.

15
00:01:07,510 --> 00:01:14,380
So that's going to drop anything that is missing and then we can also remove single strings by creating

16
00:01:14,380 --> 00:01:23,270
a list called blanks and then iterating through the data frame for every index label and review in D

17
00:01:23,270 --> 00:01:33,480
F it or tuples we'll do what we did last time we'll check if the actual type of the review is equal

18
00:01:33,480 --> 00:01:44,670
to a string then we'll say if that review is a space go ahead and grab its index position by saying

19
00:01:44,670 --> 00:01:51,980
blanks and append that index position then we can check out blanks and see if we have any blanks.

20
00:01:52,050 --> 00:01:57,090
So looks like we do have quite a few blanks so we're gonna do is we'll go ahead and drop those simply

21
00:01:57,090 --> 00:02:06,150
by saying the F drop and then pass in those blanks index positions and then say in-place antithetical

22
00:02:06,150 --> 00:02:06,950
to true.

23
00:02:07,230 --> 00:02:08,090
Okay.

24
00:02:08,310 --> 00:02:15,030
So we can now check out our label counts simply by saying the F label value counts and we should have

25
00:02:15,120 --> 00:02:18,970
after that process nine hundred and sixty nine of each label.

26
00:02:19,110 --> 00:02:26,370
So let's go ahead now and import sentiment analysis and create the essay the object will say from an

27
00:02:26,400 --> 00:02:31,040
L T.K. that sentiment dot Vader.

28
00:02:31,220 --> 00:02:33,420
Notice now I don't need to download that Vader.

29
00:02:33,420 --> 00:02:36,060
You only have to do that once in the previous lecture.

30
00:02:36,060 --> 00:02:44,420
Then we're going to import sentiment intensity analyzer and create the essay the object from sentiment

31
00:02:44,600 --> 00:02:45,650
intensity analyzer.

32
00:02:45,650 --> 00:02:53,470
I'm just using tapped autocomplete here and then we'll go ahead and use sd to append a compound score

33
00:02:53,980 --> 00:03:01,690
as a column so just as before we say D F scores we'll go ahead and grab our review column and then we'll

34
00:03:01,690 --> 00:03:10,330
apply a lambda expression simply by saying lambda taken that review and then call essay The polarity

35
00:03:10,330 --> 00:03:13,450
scores on that particular review.

36
00:03:13,480 --> 00:03:17,410
So this is the line that's gonna take the longest to run because it's performing that polarity score

37
00:03:17,410 --> 00:03:19,390
analysis on every single review.

38
00:03:19,720 --> 00:03:26,800
But once we have the scores we can simply grab a compound off of that basically the value for compound

39
00:03:27,400 --> 00:03:34,780
by saying grab that score is dictionary and then apply lambda and then for that dictionary simply grab

40
00:03:34,780 --> 00:03:37,960
back the compound value.

41
00:03:38,140 --> 00:03:42,970
So we run that and then if we check up the head of our data frame at this point we have our scores dictionary

42
00:03:43,060 --> 00:03:48,040
we have the compound value let's go ahead and convert this compound value into a label either negative

43
00:03:48,040 --> 00:03:53,830
or positive by simply saying the following grabbed the compound value.

44
00:03:53,900 --> 00:04:00,260
It's actually saying this is our comp score or predicted label.

45
00:04:00,450 --> 00:04:10,490
However we want to label it but will say compound apply and we'll say lambda and then we'll say score.

46
00:04:10,490 --> 00:04:13,550
Passed in return positive.

47
00:04:13,550 --> 00:04:20,590
If the score is greater than or equal to zero else return negative.

48
00:04:20,600 --> 00:04:24,610
And the reason we choose P Os and energy is because that matches the labels here.

49
00:04:24,650 --> 00:04:29,660
Which is then going to allow us to actually use cycle learn to calculate things like accuracy precision

50
00:04:29,660 --> 00:04:30,840
and recall.

51
00:04:31,190 --> 00:04:32,200
So we run this whip.

52
00:04:32,240 --> 00:04:39,420
Let's make sure we have valid syntax so pause if there we go.

53
00:04:39,470 --> 00:04:39,980
There we go.

54
00:04:39,980 --> 00:04:42,330
Okay so fix that little type of there.

55
00:04:42,500 --> 00:04:47,060
And if you check out the head of the your frame at this point you should build see a comp score with

56
00:04:47,060 --> 00:04:49,710
the predicted value and the label.

57
00:04:49,850 --> 00:04:55,730
So right off the bat it looks like it's matching the first couple first five the compound score is working.

58
00:04:55,730 --> 00:05:03,070
Let's go ahead and compare it across the entire data frame so we will say from a scalar that metrics

59
00:05:03,520 --> 00:05:10,570
import will improve accuracy score classification report and then the confusion matrix.

60
00:05:10,570 --> 00:05:15,420
So run those and let's just check our accuracy remember our accuracy score.

61
00:05:15,460 --> 00:05:20,480
If we were randomly guessing if a movie review was positive or negative would be around 50 percent.

62
00:05:20,620 --> 00:05:24,950
So hopefully we're performing better than 50 percent otherwise then we're no we're not performing that

63
00:05:24,950 --> 00:05:26,070
in the random guessing.

64
00:05:26,350 --> 00:05:33,630
So we're going to compare our label column to our calculated compound Score Column so it looks like

65
00:05:33,720 --> 00:05:37,100
overall accuracy is around 64 percent.

66
00:05:37,170 --> 00:05:43,010
That's definitely not as good as our ATF IDF analysis with our train model from earlier.

67
00:05:43,110 --> 00:05:46,180
But keep in mind we're not really doing any sort of training step.

68
00:05:46,230 --> 00:05:51,150
We're essentially just importing this Vader sentiment analyzer and hoping that it works well enough

69
00:05:51,300 --> 00:05:56,280
on existing text data and you should also note that if you read some of these reviews there's a lot

70
00:05:56,280 --> 00:05:59,760
of sarcasm in the reviews which is again really hard to detect.

71
00:05:59,970 --> 00:06:08,250
So let's finish us off by also checking out our classification report on DFA label and the F Com Score.

72
00:06:08,250 --> 00:06:10,020
I'm simply just going to copy and paste these in

73
00:06:12,720 --> 00:06:14,100
so again.

74
00:06:14,140 --> 00:06:19,500
Looks like we're getting not so great precision and definitely not great recall on negative and we can

75
00:06:19,500 --> 00:06:21,290
see the F1 scores for both.

76
00:06:21,360 --> 00:06:22,480
Again negative reviews.

77
00:06:22,490 --> 00:06:28,350
Those tend to be often sarcastic and that's really hard to detect for any machine learning algorithm.

78
00:06:28,530 --> 00:06:34,690
And then let's also point out our confusion matrix in case that interest us and we can see here the

79
00:06:34,690 --> 00:06:39,910
supporting instances and the non supporting instances so it looks like Vader couldn't really judge the

80
00:06:39,910 --> 00:06:45,430
movie reviews very accurately and this demonstrates one of the biggest challenges incent him analysis

81
00:06:45,670 --> 00:06:48,160
really understanding human semantics.

82
00:06:48,160 --> 00:06:53,980
Many of the reviews had positive things to say about a movie reserving final judgment to just the very

83
00:06:53,980 --> 00:06:54,980
last sentence.

84
00:06:55,060 --> 00:06:58,870
So even a negative review can highlight positive things.

85
00:06:58,870 --> 00:07:03,610
Maybe saying oh the actors were really good in this movie but the script was horrible leading to a bad

86
00:07:03,610 --> 00:07:04,360
movie.

87
00:07:04,390 --> 00:07:10,580
That sort of dichotomy within a single review can be really hard for something like Vader to the text.

88
00:07:10,600 --> 00:07:16,990
And sometimes it takes something more robust like TFA IDF in order to create your own sort of classification

89
00:07:16,990 --> 00:07:21,050
models specifically for a positive versus negative sentiment analysis.

90
00:07:21,130 --> 00:07:25,680
So keep that in mind whenever you're exploring sentiment analysis of your own datasets.

91
00:07:25,870 --> 00:07:30,880
Coming up next we're going to test your full understanding on not just sentiment analysis but semantic

92
00:07:30,880 --> 00:07:34,390
word vectors as well with a project in the next lecture.

93
00:07:34,390 --> 00:07:36,420
We'll have an overview of that assessment.

94
00:07:36,460 --> 00:07:37,130
Let's get started.

95
00:07:37,500 --> 00:07:38,380
I'll see at the next lecture.

