1

00:00:00,750  -->  00:00:06,630
Hello welcome back to the course of machine learning in the breeze tutorial we talked about the hierarchical

2

00:00:06,630  -->  00:00:10,760
clustering the intuition behind it and how it works.

3

00:00:10,800  -->  00:00:16,020
But at the same time we didn't quite understand what the whole purpose of H.C. wasn't what the benefit

4

00:00:16,110  -->  00:00:22,380
of it was yes we went from a huge amount of classers where every single point or data element was considered

5

00:00:22,380  -->  00:00:27,600
a cluster and then to one big cluster but as a result and now we have one huge costs are what's what's

6

00:00:27,600  -->  00:00:28,800
the point of all of it.

7

00:00:28,950  -->  00:00:31,300
How do we get to the result we want.

8

00:00:31,300  -->  00:00:36,450
The actual clustering so I can Kamins For instance we would have two or three closer's.

9

00:00:36,450  -->  00:00:39,680
How do we get to that right number of clusters.

10

00:00:39,690  -->  00:00:44,070
So this is where the Dinda Gram's come in and they will help us understand everything.

11

00:00:44,070  -->  00:00:45,960
So let's get straight into it.

12

00:00:45,960  -->  00:00:51,750
So here I've got a chart on the left which contains six points and on the right of the go to another

13

00:00:51,750  -->  00:00:54,500
chart we're going to use this chart to create a Dendron Graham.

14

00:00:54,540  -->  00:00:59,670
Now I know it might sound a bit confusing at first especially because we haven't talked about that diagrams

15

00:00:59,970  -->  00:01:02,720
but through creating one we will learn what they are.

16

00:01:02,820  -->  00:01:10,590
So first off just to make things a bit more legible I'm going to add the points at the bottom so that

17

00:01:10,590  -->  00:01:13,250
they're a bit bigger so you can see them better.

18

00:01:13,320  -->  00:01:14,740
And so there they are.

19

00:01:14,800  -->  00:01:18,500
There they are just listed on the bottom on the vertical axis.

20

00:01:18,500  -->  00:01:21,450
We've got Euclidean distances and it'll all make sense just now.

21

00:01:21,480  -->  00:01:26,340
So we're going to now go through the H.C. algorithm and slowly create those clusters.

22

00:01:26,400  -->  00:01:30,110
So to start off with every single point is an individual cluster.

23

00:01:30,210  -->  00:01:32,760
Right so every single one of these points is an individual cluster.

24

00:01:32,760  -->  00:01:37,410
Next what we're going to do is we're going to find the two closest points which are these two and put

25

00:01:37,410  -->  00:01:38,640
them into one cluster.

26

00:01:38,640  -->  00:01:41,700
So that's our step too in our algorithm.

27

00:01:41,700  -->  00:01:42,270
So there we go.

28

00:01:42,270  -->  00:01:44,310
That's the two closest points.

29

00:01:44,310  -->  00:01:47,460
And now we're putting them into one cluster.

30

00:01:47,460  -->  00:01:54,150
Now what we want to do on this diagram here on the ground is we want to somehow signify that these were

31

00:01:54,150  -->  00:02:00,490
indeed the two closest points because the DNA gram is kind of like the memory of the AC algorithm.

32

00:02:00,570  -->  00:02:03,590
Going to remember every single step that we were performing.

33

00:02:03,750  -->  00:02:06,120
So there they are those two boys P2 and P3.

34

00:02:06,150  -->  00:02:11,670
How do we signify that we've just connected them and that they were the closest well to connect them

35

00:02:11,680  -->  00:02:13,690
would use like a horizontal line.

36

00:02:13,770  -->  00:02:17,850
But then where would we put it would you put at the very bottom would we put a bit higher.

37

00:02:18,000  -->  00:02:19,920
What's going to determine the distance.

38

00:02:19,920  -->  00:02:22,320
How high are we going to places like.

39

00:02:22,470  -->  00:02:29,040
So this line is actually placed this height actually has a meaning this height is the median distance

40

00:02:29,040  -->  00:02:29,950
between them.

41

00:02:30,090  -->  00:02:36,930
And it also represents the computed dissimilarity between the two points are the two clusters.

42

00:02:36,930  -->  00:02:39,510
And what that means is the further away two points are.

43

00:02:39,510  -->  00:02:42,220
So for instance P2 is that far away from P3.

44

00:02:42,420  -->  00:02:47,230
And this could be a variable for us it could be the age of a person.

45

00:02:47,370  -->  00:02:47,630
Right.

46

00:02:47,640  -->  00:02:52,440
And this variable could be for instance the salary of a person.

47

00:02:52,560  -->  00:02:52,870
Right.

48

00:02:52,890  -->  00:02:57,760
Or this variable could be how long a person has been in the company and this.

49

00:02:57,840  -->  00:03:00,680
This variable could be the salary of the person.

50

00:03:00,760  -->  00:03:01,530
Or something like that.

51

00:03:01,530  -->  00:03:09,420
So basically we can see that P2 and P3 are they have that distance between them whereas P2 and P4 have

52

00:03:09,420  -->  00:03:15,150
a greater distance between them and that means that these two points P2 and P3 they have a certain dissimilarity

53

00:03:15,150  -->  00:03:21,060
which is measured by the distance between them so the distance represents the dissimilarity between

54

00:03:21,060  -->  00:03:26,280
the two points and P2 and before also have a dissimilarity and its greater because you can see that

55

00:03:26,280  -->  00:03:27,180
the distance is greater.

56

00:03:27,180  -->  00:03:33,350
So lets say if this was age and this was salary these two points even though they are not identical

57

00:03:33,390  -->  00:03:38,570
they are less dissimilar in terms of age and salary than P2 and P4.

58

00:03:38,580  -->  00:03:43,110
And again these variables are just arbitrary just calling arbitrary variables that could be anything

59

00:03:43,110  -->  00:03:45,880
else and this data set could not be complete.

60

00:03:45,890  -->  00:03:52,240
It could be a machines it could be CERN observations from nature and pretty much anything.

61

00:03:52,530  -->  00:03:57,470
The point here is that they are further away two points are the more dissimilar they are.

62

00:03:57,480  -->  00:04:03,480
And that is been measured or captured in identity Gramp by the height of this bar how high we're setting

63

00:04:03,470  -->  00:04:03,810
it.

64

00:04:03,870  -->  00:04:07,300
And then the bar itself just shows us that we connected P2 and P3.

65

00:04:07,320  -->  00:04:07,560
All right.

66

00:04:07,560  -->  00:04:09,730
So that's our first step in the Denver ground.

67

00:04:10,020  -->  00:04:16,890
Next we're going to move on and we're going to proceed to the next step in our shelter and we can perform

68

00:04:16,890  -->  00:04:17,950
step three.

69

00:04:17,970  -->  00:04:22,980
So we're going to find in the next two closest clusters and connect them.

70

00:04:22,980  -->  00:04:27,380
So here we've got all each each point out of these four is a cluster.

71

00:04:27,370  -->  00:04:28,680
Then we've got this cluster.

72

00:04:28,710  -->  00:04:31,290
Now we need to find the two closest are all of them.

73

00:04:31,440  -->  00:04:37,700
And let's say or from what we see these two other closest So let's outline them.

74

00:04:37,950  -->  00:04:38,610
There we are.

75

00:04:38,610  -->  00:04:40,170
And so now they form their own cluster.

76

00:04:40,170  -->  00:04:43,050
Now we want to point that out in the den trigram as well.

77

00:04:43,050  -->  00:04:46,720
So again we're going to places vertical or horizontal line again.

78

00:04:46,740  -->  00:04:49,710
How high do we place it to replace it.

79

00:04:49,700  -->  00:04:51,920
Higher or lower than this line.

80

00:04:52,080  -->  00:04:59,010
Well we agreed that this vertical axis represents the Euclidean distance and Euclidean distance represents

81

00:04:59,130  -->  00:05:02,960
the dissimilarity between two of our observations.

82

00:05:02,970  -->  00:05:09,480
So here we can see that P5 and P-Six are actually further apart than between three and that is of course

83

00:05:09,660  -->  00:05:17,070
natural because if P5 and P-Six were closer then in the in the previous step we wouldn't have put two

84

00:05:17,070  -->  00:05:21,340
and three in one closer we would have put P5 and six in one cluster remember.

85

00:05:21,360  -->  00:05:24,600
We're always looking for the closest and then we're moving on to the next step.

86

00:05:24,600  -->  00:05:31,290
So between B-3 we're the closest and that's why this distance is such P5 and D6 are further apart from

87

00:05:31,290  -->  00:05:34,130
each other than P2 and P3 so the distance has to be greater.

88

00:05:34,350  -->  00:05:39,960
And that's why we're going to show that on the diagram you can see that this bar is set higher.

89

00:05:39,990  -->  00:05:40,740
All right.

90

00:05:40,800  -->  00:05:46,370
And the next step is to again repeat step 3 so we're going to look among these.

91

00:05:46,500  -->  00:05:49,770
All of these clusters of which are the closest.

92

00:05:49,770  -->  00:05:50,670
So there we go.

93

00:05:50,670  -->  00:05:54,230
So this one is the was the closest I'm going to back here.

94

00:05:54,270  -->  00:06:00,480
This cluster is closer to this cluster containing other closer and pretty much out of all the distances

95

00:06:00,480  -->  00:06:01,200
between the clusters.

96

00:06:01,200  -->  00:06:06,280
This is the lowest again a lot here is determined by how you measure distances.

97

00:06:06,280  -->  00:06:13,260
You can see that the distance between before and this cluster is quite close to this distance.

98

00:06:13,320  -->  00:06:17,010
But so we're going to say that this distance is the last.

99

00:06:17,010  -->  00:06:17,310
All right.

100

00:06:17,310  -->  00:06:22,020
So what do we do next is we combine these clusters into one cluster.

101

00:06:22,020  -->  00:06:23,740
There's that there it is.

102

00:06:23,740  -->  00:06:24,870
So now we have one cluster.

103

00:06:24,870  -->  00:06:29,280
Now we need to represent that somehow here so what we just did is we took this cluster that we have

104

00:06:29,430  -->  00:06:32,220
to be connected with P1.

105

00:06:32,220  -->  00:06:39,690
So again we're going to draw a line and we're going to draw vertical lines here again and was once again

106

00:06:39,740  -->  00:06:47,340
in the distance here from P1 to the top of here represents the dissimilarity between that cluster that

107

00:06:47,340  -->  00:06:47,860
we had.

108

00:06:47,880  -->  00:06:51,350
And what's the point that we connected it to.

109

00:06:51,360  -->  00:06:53,500
All right so now let's connect.

110

00:06:53,760  -->  00:06:54,270
Let's find.

111

00:06:54,270  -->  00:07:00,390
What's the next step next step again is step three and we're going to look out of one two three clusters

112

00:07:00,390  -->  00:07:01,980
that we have which are the closest.

113

00:07:01,980  -->  00:07:05,030
Well this is before and it's the closest to these.

114

00:07:05,280  -->  00:07:06,390
Again there it is.

115

00:07:06,390  -->  00:07:08,170
We're expanding that cluster.

116

00:07:08,190  -->  00:07:13,020
Now we're going to represent on the Denver Gramp as you can see the line is about the same height as

117

00:07:13,020  -->  00:07:18,030
this previous line because the distance between P1 and this cluster was about the same as the distance

118

00:07:18,030  -->  00:07:20,150
between four and five and six.

119

00:07:20,250  -->  00:07:22,760
Maybe this one was a bit greater.

120

00:07:22,920  -->  00:07:28,040
Sometimes it's hard to tell and that's why we have algorithms that's why machines do it for us.

121

00:07:28,050  -->  00:07:34,560
One of the reasons that's what our datagram look so far and our final step is to combine these two remaining

122

00:07:34,560  -->  00:07:39,030
clusters because by default they are going to be the closest since there are no other clusters.

123

00:07:39,030  -->  00:07:42,750
So we are going to combine them and represent that on Adinda gram.

124

00:07:42,780  -->  00:07:48,810
So here the hotline is very high because the distance dissimilarity was very high between these two

125

00:07:48,810  -->  00:07:49,530
clusters.

126

00:07:49,830  -->  00:07:50,470
And there we go.

127

00:07:50,580  -->  00:07:56,020
So that is how we construct our DNA Graham slowly from the bottom up is being constructed.

128

00:07:56,250  -->  00:08:02,370
And at the end we've got that one cluster or so all of this is one cluster and that is what I mean when

129

00:08:02,370  -->  00:08:07,070
I say that the underground contains the memory of the hierarchical clustering algorithm.

130

00:08:07,110  -->  00:08:12,330
So you can just by looking at the Denver grammar understand in which order these classes were formed

131

00:08:13,020  -->  00:08:19,470
and here I've got an example so this is the actual example generated by computer generated by an algorithm

132

00:08:19,830  -->  00:08:22,380
showing us the hierarchical clustering.

133

00:08:22,380  -->  00:08:28,320
So we've got the points here and we've got the pentagram over here so this is what it actually looks

134

00:08:28,320  -->  00:08:29,280
like.

135

00:08:29,280  -->  00:08:34,470
All right so now we know how dense the Grahams are constructed in the next tutorial we will learn how

136

00:08:34,470  -->  00:08:42,270
to use them to enhance our or actually execute our hierarchical clustering algorithm.

137

00:08:42,270  -->  00:08:43,200
So there we go.

138

00:08:43,200  -->  00:08:45,660
Hope you enjoyed today's tutorial are forcing you next time.

139

00:08:45,660  -->  00:08:47,490
And until then in Germany learning
