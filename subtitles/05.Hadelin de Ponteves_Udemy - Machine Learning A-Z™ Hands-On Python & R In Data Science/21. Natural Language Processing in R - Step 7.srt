1

00:00:00,270  -->  00:00:02,450
Hello and welcome to this art to Tauriel.

2

00:00:02,700  -->  00:00:08,550
So so far we've been doing a great deal of simplification for Corpus and therefore for future sparse

3

00:00:08,550  -->  00:00:09,670
matrix features.

4

00:00:09,900  -->  00:00:16,050
But we can still do better and doing better is what we'll do in this tutorial and it's a new step of

5

00:00:16,050  -->  00:00:18,990
thinking process that is called Stenning.

6

00:00:19,020  -->  00:00:20,240
So what is timing.

7

00:00:20,550  -->  00:00:24,470
Well Stenning is about getting the root of each word.

8

00:00:24,480  -->  00:00:30,870
For example if you look at the first review we have this love word here and the root of this word would

9

00:00:30,870  -->  00:00:32,250
be love.

10

00:00:32,580  -->  00:00:35,510
So what is the purpose of getting the root of the word.

11

00:00:35,730  -->  00:00:41,100
Well it's of course still related to our goal to reduce the total number of words that will be in our

12

00:00:41,100  -->  00:00:46,950
future sparse matrix of features and we can do this by taking the route of the words because whether

13

00:00:46,950  -->  00:00:50,770
we have loved or love or will love or loving.

14

00:00:50,970  -->  00:00:54,210
Well this actually means the same thing for algorithm.

15

00:00:54,480  -->  00:00:59,670
And not only it means the same thing but also it gives the same hint whether the review is positive

16

00:00:59,730  -->  00:01:00,700
or negative.

17

00:01:00,780  -->  00:01:04,730
So we don't really need to have some different tenths of one same verb.

18

00:01:04,890  -->  00:01:07,470
And we don't really need to have evaded words.

19

00:01:07,470  -->  00:01:09,330
We just need the root of the words.

20

00:01:09,390  -->  00:01:15,090
And that will be perfectly enough for machine classification model to train on the future sparse matrix

21

00:01:15,090  -->  00:01:20,370
of features that therefore will contain only the roots of the words and you can imagine how we will

22

00:01:20,370  -->  00:01:23,610
considerably reduce the final total number of words.

23

00:01:23,610  -->  00:01:28,650
That is the final total number of columns in the sparse matrix of features because of course by only

24

00:01:28,650  -->  00:01:31,580
keeping the roots of the different versions of the same word.

25

00:01:31,710  -->  00:01:37,260
Well of course that simplifies it very well and therefore it considerably reduces the final total number

26

00:01:37,260  -->  00:01:38,340
of words.

27

00:01:38,340  -->  00:01:42,770
So that's the I mean that's also a very important step in natural language processing.

28

00:01:42,960  -->  00:01:48,540
You will most of the time apply stemming to your text whether you are working with reviews or articles

29

00:01:48,540  -->  00:01:50,900
or books or HMO pages.

30

00:01:51,050  -->  00:01:56,070
Well for any kind of text it really helped your machine learning algorithm to do an even better job

31

00:01:56,070  -->  00:01:58,020
for your classification problem.

32

00:01:58,020  -->  00:02:02,580
So let's do it for our reviews and it is still going to be very simple.

33

00:02:02,610  -->  00:02:04,450
We will do another copy paste here.

34

00:02:04,470  -->  00:02:11,040
So I will actually copy this line because we only needed two parameterless the corpus and a function

35

00:02:11,040  -->  00:02:12,830
that will perform this timing.

36

00:02:12,840  -->  00:02:20,610
So based here and I will replace remove punctuation by the appropriate function to proceed to systemin

37

00:02:20,850  -->  00:02:24,990
which is this term capital D document.

38

00:02:25,010  -->  00:02:25,850
Here it is.

39

00:02:25,920  -->  00:02:30,720
That's the function we use to perform stemming on all the reviews of our corpus.

40

00:02:30,900  -->  00:02:32,400
So let's check it out.

41

00:02:32,490  -->  00:02:35,250
Let's select this line right now.

42

00:02:35,250  -->  00:02:42,460
Our first review is well loved place and you'll see that after stymieing love becomes love.

43

00:02:42,750  -->  00:02:47,100
All right so let's execute now press command and control us and to to execute.

44

00:02:47,100  -->  00:02:47,890
Here we go.

45

00:02:47,950  -->  00:02:48,830
New corpus.

46

00:02:48,820  -->  00:02:49,730
Updated.

47

00:02:49,770  -->  00:02:53,610
And now let's have a look at the first review of this new corpus.

48

00:02:53,820  -->  00:02:59,590
So I'm pressing the bar here to get this line of code and now pressing enter.

49

00:02:59,670  -->  00:03:00,860
And here we go.

50

00:03:00,930  -->  00:03:01,550
Wow.

51

00:03:01,590  -->  00:03:08,230
Love and place so loved was replaced by love because the root of luffed is love.

52

00:03:08,280  -->  00:03:08,980
All right.

53

00:03:09,180  -->  00:03:12,980
So and that's the center all the reviews in all the other reviews.

54

00:03:13,020  -->  00:03:15,730
The words were replaced by their roots.

55

00:03:15,810  -->  00:03:18,140
So that's done for this new step.

56

00:03:18,240  -->  00:03:21,080
And actually we are almost done with the cleaning process.

57

00:03:21,090  -->  00:03:25,830
We have one final step and we will do this final step in the next tutorial until then.

58

00:03:25,850  -->  00:03:26,930
And so machine learning
