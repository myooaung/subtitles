1
00:00:00,450 --> 00:00:06,150
Hello and welcome to this almost final tutorial of the Part 1 data processing.

2
00:00:06,150 --> 00:00:11,320
I look forward to being well-prepared with our data to start making our machine learning models.

3
00:00:11,340 --> 00:00:12,510
It's gonna be very fun.

4
00:00:12,510 --> 00:00:16,320
We just have to hold on for two more tutorials and then we're good to go.

5
00:00:16,350 --> 00:00:16,680
Okay.

6
00:00:16,710 --> 00:00:21,590
So today we're gonna talk about feature scaling which is very important in machine learning.

7
00:00:21,600 --> 00:00:23,540
I'm going to explain why right now.

8
00:00:23,610 --> 00:00:27,340
So I'm gonna go to Google Sheets to find our data set.

9
00:00:27,360 --> 00:00:28,420
And here it is.

10
00:00:28,500 --> 00:00:33,000
Let's explain what is feature scaling and why we need to do it okay.

11
00:00:33,000 --> 00:00:39,210
So as you can see we have these two columns age and salary that contains numerical numbers.

12
00:00:39,210 --> 00:00:41,670
Let's just focus on the age and the salary.

13
00:00:41,670 --> 00:00:49,200
You notice that the variables are not on the same scale because the age are going from twenty seven

14
00:00:49,200 --> 00:00:56,130
to 50 and the salary is going from 40 K to like 90 K.

15
00:00:56,460 --> 00:01:01,690
So because this age variable in the salary variable don't have the same scale.

16
00:01:01,800 --> 00:01:05,700
This will cause some issues in your machinery models.

17
00:01:05,700 --> 00:01:06,510
And why is that.

18
00:01:06,510 --> 00:01:12,030
It's because you're machine learning models a lot of machinery models are based on what is called the

19
00:01:12,030 --> 00:01:13,560
Euclidean distance.

20
00:01:13,560 --> 00:01:17,790
If you remember that back from high school the Euclidean distance between two data points between two

21
00:01:17,790 --> 00:01:22,000
points is the square root of the sum of the squared coordinates.

22
00:01:22,080 --> 00:01:26,710
Well actually here it's the same we have two variables age and salary.

23
00:01:26,790 --> 00:01:32,940
So you can picture age as the x coordinate and the salary as the y coordinate and in the machine learning

24
00:01:32,940 --> 00:01:39,870
models equations some Euclidean distances between observation points for example this one and this one

25
00:01:40,380 --> 00:01:43,770
are computed based on these two coordinates.

26
00:01:43,770 --> 00:01:50,400
And actually since the salary has a much wider range of values because it's going from zero to 100 k

27
00:01:51,270 --> 00:01:58,050
the Euclidean distance will be dominated by the salary because for example if we take two observations

28
00:01:58,050 --> 00:02:05,820
for example the this one the ninth one and the third one well the Euclidean distance will compute the

29
00:02:05,820 --> 00:02:09,540
difference between this salary and this salary.

30
00:02:09,540 --> 00:02:10,330
So let's computed.

31
00:02:10,350 --> 00:02:12,740
That's about okay.

32
00:02:12,770 --> 00:02:24,410
So this minus this one as you can see this is 31000 if you put that in square okay that's it up square

33
00:02:24,860 --> 00:02:26,070
that gives this.

34
00:02:26,150 --> 00:02:29,820
And now let's take for the same two observations the ages.

35
00:02:29,960 --> 00:02:35,120
So let's compute equals 48 minus.

36
00:02:35,140 --> 00:02:36,330
It was this one right.

37
00:02:36,340 --> 00:02:38,090
Twenty seven K.

38
00:02:38,120 --> 00:02:39,260
That's the difference.

39
00:02:39,260 --> 00:02:44,790
And now let's take the square equals this square.

40
00:02:45,080 --> 00:02:52,880
441 so you can see very clearly how this square difference dominates this square difference.

41
00:02:53,210 --> 00:02:56,630
And that's because these two variables are not on the same scale.

42
00:02:56,630 --> 00:03:01,970
So you know in the machine learning equations it will be like this doesn't exist because it will be

43
00:03:01,970 --> 00:03:03,490
dominated by this.

44
00:03:03,500 --> 00:03:09,860
So that's why we absolutely need to put the variables on the same scale that is that we are going to

45
00:03:09,860 --> 00:03:14,760
transform these two variables and they're going to have values in the same range.

46
00:03:14,930 --> 00:03:18,090
For example they're going to have values from minus one to plus one here.

47
00:03:18,170 --> 00:03:20,130
And same here minus one two plus one.

48
00:03:20,330 --> 00:03:27,110
So that we don't get this sort of problem with a huge number here dominating a smaller number here.

49
00:03:27,110 --> 00:03:30,170
So that eventually the smaller number doesn't exist.

50
00:03:30,200 --> 00:03:35,780
There are several ways of scaling your data a very common one is the standardization which means that

51
00:03:35,960 --> 00:03:42,350
for each observation and each feature you withdraw the mean value of all the values of the feature and

52
00:03:42,350 --> 00:03:44,540
you divided by the standard deviation.

53
00:03:44,570 --> 00:03:50,390
So that's a first type of features caning and another type is normalization which means that you subtract

54
00:03:50,540 --> 00:03:56,330
your observation feature X by the minimum value of all the feature values and you divide it by the difference

55
00:03:56,330 --> 00:04:00,740
between the maximum of your feature values and the minimum of your feature values.

56
00:04:00,770 --> 00:04:03,190
Don't worry if you're not very comfortable with the mathematics here.

57
00:04:03,200 --> 00:04:08,440
But what you need to understand is that we are putting of variables in the same range in the same scale

58
00:04:08,780 --> 00:04:12,210
so that no variable is dominated by the other.

59
00:04:12,250 --> 00:04:12,490
Okay.

60
00:04:12,500 --> 00:04:13,540
So let's do it right now.

61
00:04:13,550 --> 00:04:17,900
Anyway you're going to see how the variables are going to be transformed you're going to see how they

62
00:04:17,900 --> 00:04:23,540
go from having large and very different values to small and same values.

63
00:04:23,600 --> 00:04:31,400
So let's move on to our So here we are r and now that you understand feature scaling let's apply it

64
00:04:31,460 --> 00:04:38,960
to the training set and the test set here we will just write two lines of code which are so the first

65
00:04:38,960 --> 00:04:41,520
line is training set.

66
00:04:41,540 --> 00:04:43,510
So the training sets already exists right.

67
00:04:43,540 --> 00:04:48,950
It's this one the training set as you can see it's not scale these are.

68
00:04:48,950 --> 00:04:57,610
It contains the raw values so training set equals and simply now we're going to write scale

69
00:05:01,150 --> 00:05:02,800
and then training set.

70
00:05:03,490 --> 00:05:10,180
That's all that scales your training set is integrate and same for the test set we will copy this line

71
00:05:11,700 --> 00:05:20,870
based it here and we will change training into test and here as well OK.

72
00:05:20,900 --> 00:05:24,380
So here I just wrote this there is something important to understand.

73
00:05:24,530 --> 00:05:28,430
This will be the feature scaling block of code that we will be using in our template.

74
00:05:28,880 --> 00:05:34,240
However let us see what happens when I select this code and execute it.

75
00:05:34,550 --> 00:05:38,450
So let's select this execute okay.

76
00:05:38,600 --> 00:05:41,140
As you can see here I obtained two errors.

77
00:05:41,210 --> 00:05:46,220
Aaron code means X must be numeric for the training set and the test set.

78
00:05:46,330 --> 00:05:48,520
Can you guess what the problem is.

79
00:05:48,520 --> 00:05:50,040
The problem is that okay.

80
00:05:50,050 --> 00:05:52,100
Well it tells us what the problem is.

81
00:05:52,180 --> 00:05:55,330
It tells us that X must be numeric but what does that mean.

82
00:05:56,490 --> 00:06:01,650
Well first what is this X X is for this line of code the training set and for this line of code the

83
00:06:01,650 --> 00:06:02,390
test.

84
00:06:02,460 --> 00:06:06,030
So let's forget the test set for a second and let's focus on the training set.

85
00:06:06,030 --> 00:06:10,310
So X is a train set and it says that the training set must be numeric.

86
00:06:10,440 --> 00:06:12,310
So let's look at our training sets.

87
00:06:12,450 --> 00:06:13,290
Okay.

88
00:06:13,320 --> 00:06:15,720
Well the training set looks numeric right.

89
00:06:15,750 --> 00:06:20,700
Here we have numeric values numeric values family values numeric values but no actually there are two

90
00:06:20,700 --> 00:06:23,740
columns that don't have numeric values.

91
00:06:23,850 --> 00:06:25,950
It's this one the country.

92
00:06:25,950 --> 00:06:27,810
And this one purchased.

93
00:06:27,990 --> 00:06:29,020
And you remember why.

94
00:06:29,730 --> 00:06:34,740
Well it's because before we had the country written in text and the Bruges column written in text with

95
00:06:34,770 --> 00:06:36,000
yes or no.

96
00:06:36,000 --> 00:06:40,700
And we changed that by putting the categories as factors.

97
00:06:40,800 --> 00:06:42,370
That's what we did here.

98
00:06:42,390 --> 00:06:51,420
As you remember dataset country equals factor of the different levels and labels and a factor in R is

99
00:06:51,420 --> 00:06:53,640
not a numeric number.

100
00:06:53,640 --> 00:06:57,000
And when you apply the scale here X must be numeric.

101
00:06:57,000 --> 00:07:04,590
That means that all the columns in X that is the training set must be numeric so this time we are going

102
00:07:04,590 --> 00:07:08,710
to exclude the categories from the feature scaling.

103
00:07:08,770 --> 00:07:11,890
We're not going to apply feature scaling on those columns.

104
00:07:11,890 --> 00:07:13,170
So that's very simple.

105
00:07:13,170 --> 00:07:20,250
All we need to do is to take the columns we're interested in which are well the indexes of the column

106
00:07:20,250 --> 00:07:24,770
we want to scale which are indexes so index is in our start at 1.

107
00:07:24,770 --> 00:07:27,320
So that's 1 2 3.

108
00:07:27,330 --> 00:07:30,020
So that's the second and third index.

109
00:07:30,060 --> 00:07:36,690
We want to take to scale the age and the salary columns so 2 and 3 Let's input it.

110
00:07:36,760 --> 00:07:41,530
We need to specify here two column three and that gets what we want.

111
00:07:42,010 --> 00:07:52,070
So now I'm going to copy this copy paste it here here and here.

112
00:07:52,120 --> 00:07:52,540
All right.

113
00:07:52,540 --> 00:07:53,620
And now it's ready.

114
00:07:53,620 --> 00:07:58,670
Let's have a look at the training set and the test sets and not scale that scale.

115
00:07:58,780 --> 00:08:00,100
Let's go back to our code.

116
00:08:00,220 --> 00:08:01,340
Let's select this.

117
00:08:01,840 --> 00:08:08,380
And now we shouldn't get an error command and control percentage to execute.

118
00:08:08,380 --> 00:08:09,150
Here we go.

119
00:08:09,160 --> 00:08:10,620
It executed properly.

120
00:08:10,720 --> 00:08:13,230
And now let's look at the training set.

121
00:08:13,570 --> 00:08:14,590
All scaled properly.

122
00:08:14,590 --> 00:08:15,210
Perfect.

123
00:08:15,580 --> 00:08:19,250
And the test set all scaled properly.

124
00:08:19,250 --> 00:08:19,760
Perfect.

125
00:08:19,760 --> 00:08:26,180
Now our data is ready to offer a good precision and good accuracy and a fast work of the machine learning

126
00:08:26,180 --> 00:08:32,890
models and by that I mean that the machine learning models will converge rapidly OK.

127
00:08:32,900 --> 00:08:34,310
So that's it for feature scaling.

128
00:08:34,310 --> 00:08:41,300
Now you know how to apply for just getting to your data in Python and R congratulations and mostly congratulations

129
00:08:41,330 --> 00:08:47,690
because we did all the required steps to prepare SSL data features getting what's the last one because

130
00:08:47,990 --> 00:08:53,150
the next tutorial will be about this data processing template and I will just explain how we are going

131
00:08:53,150 --> 00:08:55,370
to use it in our machining models.

132
00:08:55,370 --> 00:08:57,830
It's going to be very fast and practical.

133
00:08:57,950 --> 00:09:00,050
So we are done with the data processing.

134
00:09:00,050 --> 00:09:04,430
Congratulations you did the most difficult part and now it's time to have fun.

135
00:09:04,460 --> 00:09:08,450
It's time to start making the models and I can't wait to start them with you.

136
00:09:09,020 --> 00:09:11,060
So thank you for watching this tutorial.

137
00:09:11,060 --> 00:09:12,930
I look forward to seeing you on the next one.

138
00:09:12,950 --> 00:09:14,660
And until then enjoy machine learning.
