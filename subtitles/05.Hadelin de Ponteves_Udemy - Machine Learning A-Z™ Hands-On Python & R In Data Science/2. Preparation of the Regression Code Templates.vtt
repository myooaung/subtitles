WEBVTT
1
00:00:00.150 --> 00:00:06.270
Hello my friends and welcome to this new section where you will finally learn on how to evaluate your

2
00:00:06.270 --> 00:00:10.730
regression models and mostly on how to select the best one.

3
00:00:10.740 --> 00:00:17.190
All right so this is indeed a section that has been long awaited because indeed in this whole part two

4
00:00:17.190 --> 00:00:22.720
of regression we built many machinery models and now most of you must have the question.

5
00:00:22.740 --> 00:00:28.440
OK that's cool I have all these regression models in the toolkit but which one do I select which one

6
00:00:28.620 --> 00:00:31.050
should I apply for my dataset.

7
00:00:31.230 --> 00:00:34.500
And well I actually have some very good news for you.

8
00:00:34.560 --> 00:00:38.220
We will give the answer to this exact question in this tutorial.

9
00:00:38.340 --> 00:00:43.830
So I'm going to try to reveal everything in this same tutorials that you know this can be the ultimate

10
00:00:43.890 --> 00:00:50.160
tutorial of regression where you finally learn on how to use your regression took it the right way on

11
00:00:50.160 --> 00:00:52.570
your future data sets.

12
00:00:52.590 --> 00:00:59.430
So what I will do in this tutorial is I will introduce you to this toolkit that I have just made and

13
00:00:59.430 --> 00:01:06.300
which contains all the regression models we learned together into some very generic code templates by

14
00:01:06.300 --> 00:01:08.190
very generic code templates.

15
00:01:08.280 --> 00:01:15.270
I mean that you will be able to use these code templates on your future data set by having only one

16
00:01:15.270 --> 00:01:16.650
or two things to change.

17
00:01:16.650 --> 00:01:22.380
I made them as generic as possible so that they can be ready to deploy on your data sets and besides

18
00:01:22.770 --> 00:01:29.610
each of them contains at the end of the implementation the evaluation tool you know allowing to evaluate

19
00:01:29.610 --> 00:01:35.910
your model so that you can very easily and quickly compare the performance of each of them.

20
00:01:35.910 --> 00:01:41.580
In other words you know in short thanks to this tool kit you will be able to select the best model for

21
00:01:41.580 --> 00:01:48.090
your data set in a very short amount of time you know very very efficiently AND THAT'S EXACTLY WHAT

22
00:01:48.090 --> 00:01:49.040
I'LL PROVE TO YOU.

23
00:01:49.060 --> 00:01:51.680
YOU KNOW WHAT I'M GOING TO SHOW YOU IN DISTANCE oil.

24
00:01:51.750 --> 00:01:57.280
We're going to take a real world data set you know with several features and lots of observations.

25
00:01:57.330 --> 00:02:03.510
I will deploy each of the regression models of the toolkit on this dataset and you will see how quickly

26
00:02:03.540 --> 00:02:09.300
and efficiently I managed to figure out the best model and that's actually the answer to the question

27
00:02:09.630 --> 00:02:11.550
How should I select the best model.

28
00:02:11.550 --> 00:02:17.580
And the simple answer is try all your models try all your morals and just select the best one having

29
00:02:17.580 --> 00:02:23.460
the best performance results and that performance result is measured by of course the coefficient r

30
00:02:23.460 --> 00:02:25.950
squared or adjusted or squared.

31
00:02:25.980 --> 00:02:26.450
All right.

32
00:02:26.640 --> 00:02:27.480
So there we go.

33
00:02:27.480 --> 00:02:31.950
Let me introduce you to this tool kit and then let's proceed to the demo.

34
00:02:32.730 --> 00:02:36.230
But first let's make sure everyone here is on the same page.

35
00:02:36.240 --> 00:02:40.680
This is a new folder no different than the whole machine learning.

36
00:02:40.680 --> 00:02:43.190
It is a folder containing 10 parts.

37
00:02:43.200 --> 00:02:48.270
This is a new folder where you will get you know that regression tool kit containing all the regression

38
00:02:48.270 --> 00:02:48.800
models.

39
00:02:48.870 --> 00:02:54.240
And then when we tackle Part Three that classification tool kit with all the classification models and

40
00:02:54.240 --> 00:02:57.260
mostly you know this is the model selection folder.

41
00:02:57.270 --> 00:03:02.460
This is the folder you will want to use when you want to deploy either your regression models or your

42
00:03:02.460 --> 00:03:08.100
classification models on your dataset in order to quickly and efficiently select the best one.

43
00:03:08.130 --> 00:03:13.380
Why do we need to do this only for regression and classification and not the other branches of machine

44
00:03:13.380 --> 00:03:14.070
learning.

45
00:03:14.070 --> 00:03:20.070
Well that's because you will see that from port for each of the branch will contain only two machinery

46
00:03:20.070 --> 00:03:20.570
models.

47
00:03:20.610 --> 00:03:25.620
And for each of these branch out from Part Four you will see that it will be very clear which one to

48
00:03:25.620 --> 00:03:25.950
choose.

49
00:03:26.040 --> 00:03:28.530
I will tell you exactly which one you must choose.

50
00:03:28.530 --> 00:03:33.890
But here for regression and classification Well we have many machinery models for each branch.

51
00:03:33.930 --> 00:03:40.500
So you need this model selection folder in order to have this toolkit both for classification and regression

52
00:03:40.710 --> 00:03:44.250
so that you can efficiently select your best machinery model.

53
00:03:44.250 --> 00:03:44.850
All right.

54
00:03:44.910 --> 00:03:45.540
So there we go.

55
00:03:45.540 --> 00:03:50.240
Make sure to connect to that link that link was provided just before this tutorial in the article.

56
00:03:50.340 --> 00:03:51.600
And now there we go.

57
00:03:51.680 --> 00:04:00.090
Let's enter this regression for there for moral selection and as you see it contains are five regression

58
00:04:00.090 --> 00:04:06.480
models that we studied in this part to you know multiple in our regression and I didn't include simple

59
00:04:06.480 --> 00:04:11.670
in the regression of course because now we will work with a real world data set with therefore several

60
00:04:11.670 --> 00:04:17.850
features then we have polynomial regression then support vector regression then decisions regression

61
00:04:17.940 --> 00:04:20.350
and of course random forest regression.

62
00:04:20.520 --> 00:04:28.350
And as I told you I made each of these implementations very generic so that you can deploy them on your

63
00:04:28.350 --> 00:04:35.160
future data set by having only one or two things to change assuming of course that your data set has

64
00:04:35.160 --> 00:04:41.790
a CSB format and contains all the features in the first columns and the dependent variable in the last

65
00:04:41.790 --> 00:04:42.230
column.

66
00:04:42.240 --> 00:04:44.850
That's really the essential condition.

67
00:04:44.940 --> 00:04:50.100
And then of course here I chose the dataset without missing values or categorical data.

68
00:04:50.100 --> 00:04:52.920
That's because I trust you will know how to handle this.

69
00:04:52.950 --> 00:04:55.350
Thanks to your data pricing tool kit.

70
00:04:55.380 --> 00:05:02.310
So this data set is quite classic but yet real world because can see it contains several features and

71
00:05:02.610 --> 00:05:07.830
many many observations actually almost 10000 observations if we scroll down.

72
00:05:07.860 --> 00:05:09.180
Yes almost 10000.

73
00:05:09.480 --> 00:05:10.090
All right.

74
00:05:10.090 --> 00:05:14.430
With as you can see only numerical values no categorical data in strings.

75
00:05:14.430 --> 00:05:16.270
And once again no missing data.

76
00:05:16.440 --> 00:05:21.930
And I chose such a data set so that you know we can make our code templates for each of our regression

77
00:05:21.930 --> 00:05:27.810
models 100 percent generic so that you only have to change the name of the dataset.

78
00:05:27.810 --> 00:05:28.190
All right.

79
00:05:28.530 --> 00:05:30.180
And now what is this data set about.

80
00:05:30.450 --> 00:05:36.600
Well that's a classic dataset from actually the UCI machinery in repertory which I encourage you to

81
00:05:36.600 --> 00:05:41.890
have a look because indeed it is a Web site that contains a lot of datasets on which you can practice.

82
00:05:41.910 --> 00:05:48.960
And this one is actually called combined cycle power plant and it consists of trying to predict this

83
00:05:49.050 --> 00:05:52.290
dependent variable which is actually an energy output.

84
00:05:52.290 --> 00:05:58.030
And don't worry you don't have to understand how energy works or how the physics of this dataset works.

85
00:05:58.050 --> 00:06:03.150
The only thing that you need to understand is that we want to predict this depend very well which turns

86
00:06:03.150 --> 00:06:04.740
out to be an energy output.

87
00:06:04.890 --> 00:06:11.670
And we are predicting this dependent variable with these four features here which are first the engine

88
00:06:11.670 --> 00:06:12.420
temperature.

89
00:06:12.480 --> 00:06:15.180
Second the exhaust vacuum.

90
00:06:15.180 --> 00:06:17.320
Third the ambient pressure.

91
00:06:17.370 --> 00:06:19.730
And fourth the relative humidity.

92
00:06:19.740 --> 00:06:22.200
All right so that's that's only what matters here.

93
00:06:22.200 --> 00:06:27.930
You have to see it as you know a general dataset where you have several features that you're going to

94
00:06:27.930 --> 00:06:31.030
use to predict that dependent variable.

95
00:06:31.080 --> 00:06:36.360
And as you can see as a condition you know in order to deploy or regression models on this data set

96
00:06:36.390 --> 00:06:42.660
in the future data you'll be working on is to have in the first columns the features and in the last

97
00:06:42.660 --> 00:06:44.430
column the dependent variable.

98
00:06:44.430 --> 00:06:44.730
All right.

99
00:06:44.730 --> 00:06:46.250
That's all that matters.

100
00:06:46.380 --> 00:06:52.620
If you have a dataset like that which has no missing data and no categorical data well you can deploy

101
00:06:52.890 --> 00:06:59.360
each and every single one of these regression models by just having to change the name of your dataset.

102
00:06:59.400 --> 00:07:04.610
And if your dataset has missing data or categorical data you just have to go to your data processing

103
00:07:04.650 --> 00:07:09.210
toolkit to take care of this and then you can deploy these models.

104
00:07:09.210 --> 00:07:10.050
All right.

105
00:07:10.050 --> 00:07:12.390
So now time for the demo.

106
00:07:12.510 --> 00:07:17.580
I'm going to show you how we're going to quickly and efficiently plug and play each of these regression

107
00:07:17.580 --> 00:07:18.300
templates.

108
00:07:18.450 --> 00:07:25.230
By only having to change the name of the dataset and then I'll show you how we will quickly identify

109
00:07:25.320 --> 00:07:30.090
and select the best regression more for this particular dataset.

110
00:07:30.090 --> 00:07:30.470
All right.

111
00:07:30.810 --> 00:07:31.830
Let's do this.

112
00:07:31.830 --> 00:07:38.580
So our first step here will be to create a copy of each of these files because these are all in read

113
00:07:38.580 --> 00:07:44.010
only mode because you know this folder was shared to you so since all of you will access it you can

114
00:07:44.010 --> 00:07:49.440
of course not modify it directly but in order to modify it you just need to create a copy in your drive

115
00:07:49.710 --> 00:07:54.810
and to do this well we can just do a right click here and then make a copy.

116
00:07:54.870 --> 00:07:58.760
So we're going to do this for each of the regression models here.

117
00:07:58.770 --> 00:08:02.600
Let's do this make a copy for multiple in our regression.

118
00:08:02.610 --> 00:08:07.190
Then make a copy then running for his regression make a copy.

119
00:08:07.230 --> 00:08:09.900
And finally support vector regression.

120
00:08:09.900 --> 00:08:11.880
And there we go.

121
00:08:11.880 --> 00:08:12.420
All right good.

122
00:08:12.420 --> 00:08:18.510
So we made a copy of each of these regression models and the copies should be either on your main drive

123
00:08:18.720 --> 00:08:21.590
or in this cool up notebooks folder.

124
00:08:21.810 --> 00:08:24.800
And well as you can see they are on my main drive.

125
00:08:24.960 --> 00:08:27.070
So you will actually very easily find them.

126
00:08:27.090 --> 00:08:34.020
And now what we're going to do is open each of these files in order to proceed with the demo.

127
00:08:34.020 --> 00:08:34.280
All right.

128
00:08:34.290 --> 00:08:37.680
So I opened first multiple linear regression.

129
00:08:37.680 --> 00:08:40.040
Then I'm going to open polynomial regression.

130
00:08:40.040 --> 00:08:47.220
You know in the same order as the one we used to build our regression models then support vector regression

131
00:08:48.270 --> 00:08:54.400
once again you can either open them with Google collaboratively or and notebook or even spider and eye

132
00:08:54.430 --> 00:08:59.310
contact because I also gave you the folder containing all these codes in the data set right before this

133
00:08:59.310 --> 00:09:01.200
tutorial in the Oracle.

134
00:09:01.200 --> 00:09:05.910
So then let us open decision trees and finally.

135
00:09:05.910 --> 00:09:08.730
Well random forest regression.

136
00:09:09.140 --> 00:09:10.030
All right.

137
00:09:10.260 --> 00:09:13.000
So actually let me put it like that.

138
00:09:13.170 --> 00:09:18.420
You know the same order support vector decision tree and random forest.

139
00:09:18.420 --> 00:09:18.690
All right.

140
00:09:18.690 --> 00:09:22.500
So now we have all our regression models open.

141
00:09:22.620 --> 00:09:27.870
I'm first going to show you the good templates one by one and then we will deploy them on the data set

142
00:09:28.020 --> 00:09:31.590
and I'll show you how to quickly figure out which one is the best model.

143
00:09:31.620 --> 00:09:32.260
All right.

144
00:09:32.400 --> 00:09:36.120
So starting with multiple in our regression let's see the different steps.

145
00:09:36.180 --> 00:09:38.300
So we start by importing the libraries.

146
00:09:38.340 --> 00:09:41.430
Of course that's the first step of the data progressing phase.

147
00:09:41.430 --> 00:09:43.060
Then we import the data set.

148
00:09:43.110 --> 00:09:48.900
And as you can see I made it super generic meaning that the only thing that you have to change is actually

149
00:09:48.900 --> 00:09:50.250
the name of your data set here.

150
00:09:50.280 --> 00:09:56.640
That's why I specified in capital letters that you can't miss it enter the name of your data set here

151
00:09:56.790 --> 00:09:59.180
and we will actually do that in a few minutes.

152
00:09:59.250 --> 00:10:04.470
Then here you have nothing to change of course because this automatically selects all the columns except

153
00:10:04.470 --> 00:10:10.260
the last one therefore your features and this automatically selects the last column meaning the dependent

154
00:10:10.260 --> 00:10:10.920
variable.

155
00:10:10.920 --> 00:10:16.100
All right then we split the dataset into the training set in a set of course here.

156
00:10:16.110 --> 00:10:19.870
That's very important to do this because since we want to select the best model.

157
00:10:19.890 --> 00:10:24.930
Well we need this to set in order to evaluate the performance of each of them in order to compare it

158
00:10:25.110 --> 00:10:26.510
and select the best one.

159
00:10:26.520 --> 00:10:27.870
So we have to do this step.

160
00:10:27.870 --> 00:10:28.870
Absolutely.

161
00:10:28.950 --> 00:10:34.460
Then once we have well the training set we will train our model on the training set.

162
00:10:34.770 --> 00:10:36.750
Then we will predict the test results.

163
00:10:36.750 --> 00:10:41.990
You know to have a look at the predictions and compare them to the real results in y test.

164
00:10:42.120 --> 00:10:46.240
And then finally we will evaluate the model performance in here.

165
00:10:46.350 --> 00:10:52.440
I don't want to scroll down now because we will discover together a bit later the code to evaluate a

166
00:10:52.440 --> 00:10:53.490
regression model.

167
00:10:53.530 --> 00:10:56.490
You know with the r squared coefficient.

168
00:10:56.490 --> 00:10:56.780
All right.

169
00:10:56.790 --> 00:11:01.380
So that's the code template for multiple linear regression.

170
00:11:01.380 --> 00:11:07.530
And as I told you and as you see it is super generic because for any of your future dataset provided

171
00:11:07.530 --> 00:11:12.600
that they have in the first columns the features and in the last column the dependent variable and also

172
00:11:12.600 --> 00:11:15.720
provided that they don't have missing data or categorical data.

173
00:11:15.720 --> 00:11:20.760
Well the only thing that you have to change within this code template is just to enter the name of your

174
00:11:20.760 --> 00:11:26.790
data set here and that's it by just doing this you will be able to evaluate your model with a relevant

175
00:11:26.790 --> 00:11:27.300
metric.

176
00:11:27.510 --> 00:11:28.210
All right.

177
00:11:28.290 --> 00:11:32.840
So now let's move on to the next code template pulling on your regression.

178
00:11:33.000 --> 00:11:33.350
Well here.

179
00:11:33.360 --> 00:11:34.070
That's the same.

180
00:11:34.070 --> 00:11:39.960
You know the same data repricing phase with first endpoint libraries then importing the data sets where

181
00:11:39.960 --> 00:11:44.910
you only have to enter the name of your dataset here and then splitting the data set into the training

182
00:11:44.910 --> 00:11:50.510
set and test set then of course we train the polynomial regression will on the training set.

183
00:11:50.540 --> 00:11:55.840
So that's exactly like what we did in this part to you know when we built it you recognize degree equals

184
00:11:55.920 --> 00:12:02.700
for you know that's exactly the same code then we predict some test results just to compare our predictions

185
00:12:02.760 --> 00:12:03.850
and the real results.

186
00:12:04.080 --> 00:12:09.850
And finally we will evaluate the mall performance and I will reveal very soon how to do that.

187
00:12:09.870 --> 00:12:10.130
Okay.

188
00:12:10.140 --> 00:12:12.210
So that's for polynomial regression.

189
00:12:12.210 --> 00:12:17.910
Once again very generic you just have to enter here the name of your data set and then this could template

190
00:12:17.970 --> 00:12:19.550
is ready to be deployed.

191
00:12:19.580 --> 00:12:22.140
All right then support vector regression.

192
00:12:22.140 --> 00:12:23.500
So here that's the same.

193
00:12:23.550 --> 00:12:29.760
First the data processing phase where we import the libraries then we import the data set but then remember

194
00:12:29.760 --> 00:12:34.420
we have to reshape our dependent variable vector Y because we have to features kill it.

195
00:12:34.470 --> 00:12:34.720
Right.

196
00:12:34.720 --> 00:12:35.990
Because we're doing regression.

197
00:12:36.030 --> 00:12:42.000
So the dependent variable vector has continuous numerical values and therefore as we are we need to

198
00:12:42.000 --> 00:12:43.900
scale the dependent variable vector.

199
00:12:43.890 --> 00:12:47.980
That's exactly the same as what we saw together when building that as our model.

200
00:12:48.120 --> 00:12:53.340
Then I added this of course in order to split the dataset into the training set and test set so that

201
00:12:53.340 --> 00:12:58.800
we can indeed evaluate the performance of the R and compare it to the other models.

202
00:12:58.800 --> 00:13:04.800
Then of course we have features killing compulsory for that as we are with remember are two scalar is

203
00:13:04.890 --> 00:13:10.260
one for the matrix of features and one for the dependent variable vector then we train of course as

204
00:13:10.290 --> 00:13:16.080
your model on the training set you know this very well we did it together then we proceed to test results

205
00:13:16.110 --> 00:13:20.940
just to compare and have an idea of how good are the predictions of new observations.

206
00:13:20.940 --> 00:13:27.810
And finally we will evaluate the model performance with our squared no worries we'll get to that very

207
00:13:27.810 --> 00:13:28.340
very soon.

208
00:13:28.680 --> 00:13:34.650
So that's where the as we are then for Decision Tree regression well exactly the same you know the data

209
00:13:34.770 --> 00:13:37.940
pricing phase first with no feature scaling right.

210
00:13:37.950 --> 00:13:40.680
Remember we don't need feature scaling for decision trees.

211
00:13:40.770 --> 00:13:45.570
So once again we only have to change the name of the dataset here then we split the data set into the

212
00:13:45.570 --> 00:13:49.950
training center set then we trained sedentary regression model on the training set.

213
00:13:50.040 --> 00:13:54.470
Exactly the same as we did in our implementation when we built it together.

214
00:13:54.480 --> 00:13:56.200
Then we predict the test results.

215
00:13:56.280 --> 00:14:01.800
In order to compare our predictions to the real results in my test and that's in order to have a first

216
00:14:01.800 --> 00:14:07.020
idea of the performance and then of course we will evaluate the all performance with our squared.

217
00:14:07.020 --> 00:14:12.360
And finally we have the exact same data repressing phase where we only have to enter the name of your

218
00:14:12.390 --> 00:14:17.550
data set here and then we train the random force regression more on the training set with the exact

219
00:14:17.550 --> 00:14:22.920
same implementation as how we did it together then we predict the test that results in order to get

220
00:14:22.920 --> 00:14:24.580
a first idea of the performance.

221
00:14:24.600 --> 00:14:27.810
And finally we evaluate the model performance.

222
00:14:27.810 --> 00:14:28.370
All right.

223
00:14:28.500 --> 00:14:34.590
So as I told you you have purely generic code templates which you can deploy for any of your future

224
00:14:34.590 --> 00:14:35.340
data sets.

225
00:14:35.340 --> 00:14:37.620
As long as they have first features and last.

226
00:14:37.680 --> 00:14:38.740
The dependent variable.

227
00:14:38.850 --> 00:14:43.500
And as long as they don't have missing data or categorical data in which case it's still fine you can

228
00:14:43.740 --> 00:14:46.710
use your data repressing toolkit but there you go.

229
00:14:46.740 --> 00:14:51.900
You have this code template and now I'm gonna show you how to evaluate your regression models using

230
00:14:51.900 --> 00:14:54.220
the r squared coefficient.

231
00:14:54.300 --> 00:14:56.010
All right so let's start with R squared.

232
00:14:56.010 --> 00:15:01.800
You know that final sale in each of the implementations evaluating the model performance.

233
00:15:01.860 --> 00:15:04.320
Let's see how we're going to do this.

234
00:15:04.320 --> 00:15:09.420
Well as I also want to train you on how to be independent in machine learning.

235
00:15:09.540 --> 00:15:15.180
Well we're gonna pretend once again that I actually have no idea on how to evaluate the more performance

236
00:15:15.450 --> 00:15:21.120
of regression models and therefore that I have to go to the documentation online to figure out how to

237
00:15:21.120 --> 00:15:21.560
do it.

238
00:15:21.570 --> 00:15:27.450
All right I'm just training you to be independent and quickly find an information whenever you need

239
00:15:27.450 --> 00:15:28.030
it.

240
00:15:28.050 --> 00:15:29.980
So let's go through a new tab.

241
00:15:30.430 --> 00:15:31.070
All right.

242
00:15:31.080 --> 00:15:32.310
And then let's just type.

243
00:15:32.310 --> 00:15:34.190
Because I'm gonna show you a trick actually.

244
00:15:34.470 --> 00:15:36.350
Let's just type psych it.

245
00:15:36.630 --> 00:15:38.040
Learn cycle here.

246
00:15:38.040 --> 00:15:44.180
Just take it learn and then let's go to the first link and you will be on the welcoming page of psyche

247
00:15:44.220 --> 00:15:49.200
learn which by the way looks super nice and then I'm going to show you something very interesting.

248
00:15:49.260 --> 00:15:52.980
I'm going to show you the whole API of the psychic here in library.

249
00:15:52.980 --> 00:15:59.640
You know the API is the whole library containing all the modules and inside all the functions and classes.

250
00:15:59.640 --> 00:16:05.400
All right so these are all the modules starting from the base one and the one I actually want to show

251
00:16:05.400 --> 00:16:13.710
you right now is the matrix module the matrix module which will find by scrolling down a bit scrolling

252
00:16:13.710 --> 00:16:17.670
down a bit more until we find em should find it very quickly.

253
00:16:17.670 --> 00:16:18.720
There we go.

254
00:16:18.720 --> 00:16:21.060
Psychic learn metrics.

255
00:16:21.090 --> 00:16:27.450
All right so as you might guess this is the module that contains all the metrics of machine learning

256
00:16:27.450 --> 00:16:34.260
models which therefore include classification models which will see in part 3 and what we are interested

257
00:16:34.260 --> 00:16:34.380
in.

258
00:16:34.380 --> 00:16:39.420
Now the regression models and in the regression models here are the metrics.

259
00:16:39.420 --> 00:16:40.040
Let's have a look.

260
00:16:40.560 --> 00:16:46.170
While you have many of them you have the explained variance score the max error the mean absolute error

261
00:16:46.380 --> 00:16:51.450
the means squared error the means squared look error you know you have many of them but the one we will

262
00:16:51.450 --> 00:16:58.740
use now after it kills intuition lecturer is of course the r squared the r squared core which is of

263
00:16:58.740 --> 00:17:03.430
course the coefficient of determination regressions core function.

264
00:17:03.450 --> 00:17:09.210
Okay so there is not just the r squared but that's still defined the r squared is fine you will perfectly

265
00:17:09.210 --> 00:17:14.550
be able to evaluate the performance and mostly compare the performances of your regression models to

266
00:17:14.550 --> 00:17:16.050
select the best one.

267
00:17:16.110 --> 00:17:23.940
So let's click this metric here and we will find well the name of the function which we will use.

268
00:17:23.940 --> 00:17:30.840
There you go to measure the error squared coefficient for each of our different regression models here.

269
00:17:30.960 --> 00:17:36.240
And that's exactly what you have at the end is less cell which I didn't want to reveal until now.

270
00:17:36.280 --> 00:17:43.320
That's indeed R2 score function which allows to evaluate the model performance of your regression model

271
00:17:43.650 --> 00:17:46.830
with the eyes squared coefficient of determination.

272
00:17:46.830 --> 00:17:53.820
All right so you have the same in each regression models you know R2 score right or two score here as

273
00:17:53.820 --> 00:17:54.060
well.

274
00:17:54.060 --> 00:17:59.390
That's exactly the same code actually because you know I made this code templates 100 percent generic.

275
00:17:59.730 --> 00:18:07.740
So there you go you have the R2 score function measuring the coefficient of determination meaning the

276
00:18:07.740 --> 00:18:08.660
r squared.

277
00:18:08.790 --> 00:18:13.130
And you know it's still in the assumption that I had no idea on how to implement the Ares credit score

278
00:18:13.140 --> 00:18:14.770
well here what did I do.

279
00:18:14.850 --> 00:18:21.750
I actually went to the examples and there you go I just took this line of code which clearly means that

280
00:18:21.900 --> 00:18:28.640
we're measuring the r squared chord between you know the vector of real results and your vector of predictions.

281
00:18:28.650 --> 00:18:29.900
So I just took this.

282
00:18:30.120 --> 00:18:35.310
And then of course I took this before in order to import of course the R2 scored function from the metrics

283
00:18:35.310 --> 00:18:36.750
module from cyclone.

284
00:18:36.750 --> 00:18:41.710
And so that's why you know in each implementation that's exactly what you see here.

285
00:18:41.760 --> 00:18:46.530
I import first artist core function from the Matrix module by second learn.

286
00:18:46.530 --> 00:18:51.820
And then I call this artists called function on the white test which contains the real results.

287
00:18:51.830 --> 00:18:57.720
You know the real values of the dependent variable in the test set and white bread containing the predictions

288
00:18:57.960 --> 00:19:00.000
of the same observations in the test.

289
00:19:00.270 --> 00:19:01.010
All right.

290
00:19:01.100 --> 00:19:06.570
That's only what you would have to do in order to figure out how to you know evaluate the model performance

291
00:19:06.570 --> 00:19:08.100
of regression models.

292
00:19:08.100 --> 00:19:08.600
Right.

293
00:19:08.610 --> 00:19:13.800
So that's why I really want you to have the reflex to look at the documentation and quickly find the

294
00:19:13.800 --> 00:19:15.380
information you need.

295
00:19:15.390 --> 00:19:15.810
All right.

296
00:19:15.810 --> 00:19:16.880
And now my friends.

297
00:19:16.890 --> 00:19:21.220
Time for the exciting step I'm talking of course about the demo.

298
00:19:21.630 --> 00:19:26.180
So let's just take a quick little break and we'll start directly in the next tutorial.
