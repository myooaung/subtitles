WEBVTT

00:06.670 --> 00:08.820
Hi welcome back.

00:08.810 --> 00:15.790
Now we're going to talk about different machine learning algorithms that help us solve our classification

00:15.790 --> 00:16.570
problem.

00:17.430 --> 00:23.710
Remember that we're talking about classification since we're not dealing with continuous bodies.

00:23.970 --> 00:27.270
Instead we're dealing with discrete bodies.

00:27.330 --> 00:31.450
This is fraudulent or not fraudulent transactions.

00:31.920 --> 00:39.810
In contrast continue spot use are for example a person's age weight or stuff like that.

00:39.900 --> 00:45.440
We're going to go over the problem you see in just two dimensions to illustrate this.

00:45.570 --> 00:48.830
But remember this could cover and dimensions.

00:49.090 --> 00:58.170
And instead of to the plot we would be working with hydroplanes one of the most popular algorithms is

00:58.170 --> 01:07.760
support but our machines are SBM SBM will try to answer which is the best line to split the two classes.

01:07.810 --> 01:14.980
The best line will be defined as the one that maximizes the probability of getting a new point covertly

01:15.070 --> 01:19.070
labeling it we all want that any new point.

01:19.120 --> 01:23.720
That's on the left side of the land that we're seeing to be green.

01:23.890 --> 01:32.230
And anyone on their right side to be red We will try to do this by maximizing the distance between the

01:32.230 --> 01:37.870
existing level points and that underline that we're defining.

01:38.000 --> 01:39.210
Now let's see.

01:39.230 --> 01:39.680
Come on.

01:39.680 --> 01:45.530
Machine learning I learned this also solves classification problems.

01:45.560 --> 01:49.470
Let's go off what's called decision trees.

01:49.880 --> 01:53.900
Let's go over it using just a simple example.

01:54.080 --> 01:56.850
Suppose that you have been offered a new job.

01:57.230 --> 01:59.700
You'll want to analyze the silo first.

02:00.010 --> 02:03.650
If the salary is not good they'll just refuse the job.

02:04.130 --> 02:09.470
But if it is good he'll still want to analyze other Bibles.

02:09.470 --> 02:15.410
If it's too far away from your house they'll probably not want to be stuck at traffic too much time

02:15.440 --> 02:18.980
every day so you'll just refuse the job.

02:19.730 --> 02:26.810
But if it does close enough from your house you will still want to analyze if it's a work place for

02:26.810 --> 02:28.080
you to go to.

02:28.640 --> 02:32.140
If it is a road work place you will accept the job.

02:32.390 --> 02:36.650
But if it isn't you'll just a few sit in a tree.

02:36.650 --> 02:41.870
You can see that there are terminal nodes and those nodes are swell.

02:42.170 --> 02:48.320
The terminal nodes are those jinglin and the determination can be accepting the job of refusing the

02:48.320 --> 02:55.610
job if you applied the solution just to our specific problem the output would be a fraudulent transaction

02:55.690 --> 03:03.590
or none fraudulently on suction and instead of finalizing if they offer a good salary we would be unlacing

03:03.590 --> 03:09.900
that's on sexual predators I suggest the user's IP location or home address.

03:10.380 --> 03:14.070
The entries can get to be very efficient.

03:14.150 --> 03:18.630
They will stop analyzing once they found a terminal node.

03:18.830 --> 03:24.220
The key to building agood decision tree is to find that good feature to place in each session.

03:24.330 --> 03:28.510
Note just a few more comments on the trees.

03:28.550 --> 03:33.810
They can be used to solve problems and classification problems.

03:33.860 --> 03:38.310
That means that we can work with the secret or continuous bodies.

03:38.600 --> 03:45.730
Trees also build recursively and they use Ghost functions to do that Gaunt's cause functions.

03:45.740 --> 03:52.820
Try to find the best bleet at each node so they can get faster to the solution and not waste time asking

03:52.820 --> 03:58.270
questions that won't get us any closer to reaching our domination node.

03:58.460 --> 04:03.930
There is also a technique called brewing that is used to avoid the overfit.

04:04.070 --> 04:10.610
Remember that the word feeding is when we are really good at predicting without Chernin data but not

04:10.610 --> 04:15.200
so good when we use testing or validation data.

04:15.290 --> 04:19.340
Another technique we could apply is called random forest.

04:19.370 --> 04:23.900
This is the usage of multiple decision trees at once.

04:23.900 --> 04:31.220
The same input is run over different decision trees that are created randomly as we already know the

04:31.220 --> 04:32.670
expected output.

04:32.720 --> 04:39.220
We can see which decision trees get to the best solution from the expected answer from all their random

04:39.240 --> 04:41.810
leak at once.

04:41.810 --> 04:50.090
If we have a new input that's not in our data we can go over the same decision trees we found were important

04:50.090 --> 04:51.990
to find that production.

04:52.010 --> 04:59.110
This can be really naive but it has proven to club really good experimental results.

04:59.180 --> 05:03.430
We believe in those later with our data set.

05:03.470 --> 05:08.860
This also uses a lot of the above fixing problems that the shells trees.

05:08.900 --> 05:18.950
And to cut another bubble or i'll from the skull KNM or gate nearest neighbors you add a new point.

05:18.950 --> 05:25.430
In our case there blackpoint it will give us a prediction saying that the point is blue or red based

05:25.520 --> 05:27.700
on the gate nearest point.

05:28.050 --> 05:30.940
We will need to define that number.

05:31.040 --> 05:33.280
For example k is free.

05:33.350 --> 05:40.800
We can draw the inner circle and Gunt to Bluepoint inside that circle on only one point.

05:40.850 --> 05:43.930
In that case the prediction would be blue.

05:44.240 --> 05:52.910
On the other hand if we chose K equals to 9 that would be the outer circle and then we would have only

05:52.910 --> 05:54.550
four blue and 5.

05:54.560 --> 06:04.440
But once the prediction in that case would be that the point is red it is said that CNN is not lazy.

06:04.970 --> 06:12.940
That means that he doesn't use that to try to come up with generalization from the rest of the world.

06:13.010 --> 06:18.870
It will always just look at the closest point to it to come up with a new label.

06:19.220 --> 06:26.300
This algorithm although it is really simple confront solutions to problems with multiple dimensions

06:26.570 --> 06:28.970
of multiple classes.

06:29.120 --> 06:36.800
It will always do it by selecting a number that we need to specify fundin the gay items that are closer

06:36.800 --> 06:41.780
to our new point counting to see which is the most frequent class.

06:41.900 --> 06:49.700
I'm just predicting that most frugal Plus a new label we have seen so far some of the most frequent

06:49.700 --> 06:56.330
classification algorithms and following this we will apply just a couple of them to try to solve our

06:56.330 --> 06:57.100
problem.

06:57.320 --> 07:04.310
Although we could play many more if you want to learn more of this I suggest you use this cheat sheet

07:04.310 --> 07:06.250
from sikat.

07:06.410 --> 07:13.400
It is not only a very complete list of many of the algorithms older but it will also help you find a

07:13.400 --> 07:16.090
suitable algorithm for your problem.

07:16.430 --> 07:22.010
Remember that you will always need to test this a measure of the results by yourself.

07:22.310 --> 07:29.020
Its recommendation will be based on the amount of data that you are bailable given that your general

07:29.060 --> 07:35.090
product or quantity or a discrete label and similar information.

07:35.180 --> 07:38.500
Hope you enjoy this and see you again in the next.
