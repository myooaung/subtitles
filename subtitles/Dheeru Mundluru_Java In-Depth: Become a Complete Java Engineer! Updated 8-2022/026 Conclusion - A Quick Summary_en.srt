1
00:00:01,020 --> 00:00:06,160
Hi there Ali we are done with this very long chapter.

2
00:00:06,160 --> 00:00:12,220
They look at some very sophisticated data structures that collections framework has to offer the framework

3
00:00:12,240 --> 00:00:14,170
concepts of class hierarchies.

4
00:00:14,220 --> 00:00:18,930
One of them is the collection hierarchy while the other is the mop hierarchy.

5
00:00:19,380 --> 00:00:25,710
So we discussed tons of data structures and after looking at so many of them it could be very confusing

6
00:00:25,860 --> 00:00:28,640
on when to use them are not a plan extent.

7
00:00:28,690 --> 00:00:29,910
Overwhelming too.

8
00:00:30,360 --> 00:00:36,200
So somebody let's focus only on the best parts of all the data structures that we studied.

9
00:00:36,570 --> 00:00:40,980
That is we will look at in what situations those data structures can be used.

10
00:00:41,070 --> 00:00:41,480
Right.

11
00:00:41,730 --> 00:00:43,630
That's the most important thing to understand.

12
00:00:43,920 --> 00:00:47,020
We should clearly understand when to use them.

13
00:00:48,180 --> 00:00:53,460
We started off with a collection interface and within the collection hierarchy we began with modalist

14
00:00:53,450 --> 00:00:55,280
list implementations.

15
00:00:55,290 --> 00:00:59,550
We said that let's come into play one sequence or positioning matters.

16
00:00:59,730 --> 00:01:04,879
So many of them a third big an index value as a barometer.

17
00:01:05,080 --> 00:01:10,620
We've also looked at our list which probably is the most commonly used data structure.

18
00:01:10,770 --> 00:01:17,580
It is basically a resizable implementation of an interface as it is based on an array.

19
00:01:17,610 --> 00:01:23,990
It allows faster random access to constant time complexity that is given an index number.

20
00:01:24,120 --> 00:01:30,780
You confessed the element and constant time appending elements are removing the last element also needs

21
00:01:30,810 --> 00:01:33,700
only constant time.

22
00:01:33,720 --> 00:01:40,470
Next we get a linked list which is a doubly linked list implementation of block list as well as a deck

23
00:01:40,470 --> 00:01:45,790
interface so it can be used as a list undef need it as their dictu.

24
00:01:45,930 --> 00:01:46,970
Hello Art Deco.

25
00:01:47,070 --> 00:01:51,450
It is recommended the use of a deck and you can use a linked list.

26
00:01:51,570 --> 00:01:56,440
If there would be frequent I normal operations during iteration.

27
00:01:56,460 --> 00:01:59,720
OK so that's when you would want to use a linked list.

28
00:02:00,690 --> 00:02:07,140
Next we look at Kure interface and we also looked at the sub interface deck on these interfaces come

29
00:02:07,140 --> 00:02:14,970
into play when fast head or tail manipulations Macker and we know that link list is one off their implementations

30
00:02:14,970 --> 00:02:16,370
.

31
00:02:16,380 --> 00:02:21,740
We looked at other Dec which is an odd implementation of a deck interface.

32
00:02:21,930 --> 00:02:28,290
All this keep in mind that the last name indicates the implementation how it is implemented.

33
00:02:28,440 --> 00:02:35,140
It is recommended to use an already installed on a linked list when it comes to Dec implementation underexpose

34
00:02:35,190 --> 00:02:41,310
fitful only for operations in constant time and even a linked list also has similar time complexity

35
00:02:41,310 --> 00:02:41,760
.

36
00:02:41,760 --> 00:02:48,480
But Java docs recommend using an added Deck as it is likely to be faster than a linked list than linked

37
00:02:48,480 --> 00:02:50,620
list is used as a queue.

38
00:02:50,820 --> 00:02:57,640
In fact according to one benchmark for large queues Arabic was found to be three times faster than English

39
00:02:57,640 --> 00:02:58,680
blessed.

40
00:02:58,680 --> 00:03:04,470
That's because with linked list we have to create an addition and not object with every newly added

41
00:03:04,470 --> 00:03:06,740
element.

42
00:03:06,760 --> 00:03:13,920
When actually get set interface which comes into play when uniqueness and fast lookups Magner we also

43
00:03:13,970 --> 00:03:15,310
duplicate some interfaces.

44
00:03:15,360 --> 00:03:20,400
Socket set unnavigable SEC the monkshood implementations.

45
00:03:20,520 --> 00:03:26,270
The first look that has set which is a hash table implementation of a set interface.

46
00:03:26,610 --> 00:03:33,110
We have seen the search is extremely fast when it comes to search insertion and deletion and they are

47
00:03:33,110 --> 00:03:35,010
supported in content.

48
00:03:35,490 --> 00:03:41,600
We also hope that an effective dollar item with sis always or we're right Hoshko matter when you all

49
00:03:41,600 --> 00:03:42,130
were right.

50
00:03:42,150 --> 00:03:44,500
Eclipse method.

51
00:03:44,580 --> 00:03:51,170
Next we'll have that link has set which Exton sun has set Hassid does not Pezzo insertion order due

52
00:03:51,180 --> 00:03:57,620
to its use of hash function self-preserving insertion order is a requirement then you need to use Menkhaus

53
00:03:57,710 --> 00:04:02,350
it as it has a doubly linked list or running through its entries.

54
00:04:02,430 --> 00:04:10,230
It is almost as fast as a set as it extends the Hosack nonfinite other elements will be sorted.

55
00:04:10,230 --> 00:04:11,950
Then we can use a reset.

56
00:04:12,720 --> 00:04:13,940
Recall the Cresset.

57
00:04:13,980 --> 00:04:19,829
Is it a red black tree beside implementation of unnavigable second duffus unresearched is also pretty

58
00:04:19,829 --> 00:04:21,290
fast on its supports.

59
00:04:21,310 --> 00:04:28,610
I remove n contains operations Vitt that got indeed lower the mic complexity.

60
00:04:28,620 --> 00:04:34,440
Next we look at the map interface which is the root of the map hierarchy and we looked at these three

61
00:04:34,440 --> 00:04:41,130
implementations hash map linked hash map on Prema the corresponding set implementations are also shown

62
00:04:41,130 --> 00:04:47,490
here just to highlight the fact that they in dentally use map implementations and we don't have to discuss

63
00:04:47,490 --> 00:04:54,710
the benefits of these map implementations as they are same as their set counterparts only notable addition

64
00:04:54,720 --> 00:05:00,810
is that linked hash map can also be used as an LRU cache.

65
00:05:00,900 --> 00:05:02,540
Probably this was not discussed.

66
00:05:02,730 --> 00:05:10,610
We know that linked Hachette extensor Hasek back has set actually extends the abstract class abstract

67
00:05:10,610 --> 00:05:11,300
set.

68
00:05:11,700 --> 00:05:15,980
Similarly trees it also extends the same class abstract set.

69
00:05:17,150 --> 00:05:23,760
And as expected the designers also kept things consistent for the map implementations so both hash map

70
00:05:23,820 --> 00:05:31,390
on Crea map extend the abstract class card abstract map but abstract set an abstract map are skeletal

71
00:05:31,390 --> 00:05:36,740
implementations of set and map interfaces as actively abstract set.

72
00:05:36,780 --> 00:05:43,170
Also expense abstract collection which is a skeleton implementation of the collection interface which

73
00:05:43,170 --> 00:05:46,740
is the root interface.

74
00:05:46,740 --> 00:05:54,300
Finally we also Lubet couple of algorithm classes and they are static utility classes just one was Arrius

75
00:05:54,720 --> 00:05:57,550
and it is used to manipulate plain address.

76
00:05:57,850 --> 00:06:00,730
We looked at several of its methods that we can see here.

77
00:06:00,890 --> 00:06:07,440
Like as list saut binary search NFU few others as this is probably the most commonly used method here

78
00:06:08,220 --> 00:06:12,630
undertakes Inari on iterate and set fixed size list.

79
00:06:12,630 --> 00:06:18,360
Since it is fixed size vs we cannot go from our normal operations on the return list.

80
00:06:18,720 --> 00:06:22,620
However we can perform the set operation as Abbasid on strict.

81
00:06:23,190 --> 00:06:25,090
So it is as list method.

82
00:06:25,290 --> 00:06:32,340
And in case you're wondering about how to convert an array into a set then one approach is to simply

83
00:06:32,340 --> 00:06:38,970
invoke the Hassett constructor which takes a collection of input and passed the list returned by this

84
00:06:39,060 --> 00:06:40,550
as list method.

85
00:06:41,130 --> 00:06:46,200
So there is no set method so you have to use this kind of an alternate deal.

86
00:06:46,200 --> 00:06:47,800
Another option is to use.

87
00:06:47,850 --> 00:06:54,810
I don't limit it from that Collections class adheres to Collections class which is used to manipulate

88
00:06:54,990 --> 00:06:58,320
the data structures that we have seen in this chapter.

89
00:06:58,320 --> 00:07:02,330
This class also includes methods like salt and binary search.

90
00:07:02,800 --> 00:07:09,090
However note that it does not help bottleful soc which was present in the race class.

91
00:07:09,090 --> 00:07:15,980
It was not included due to performance reasons as performing a battle of saut on an array is very efficient

92
00:07:16,170 --> 00:07:19,660
but performance would be poor when used with a list.

93
00:07:19,810 --> 00:07:29,280
OK and finally we looked at this particular item item 43 which says that if your method returns a collection

94
00:07:29,340 --> 00:07:35,700
or Inari and if the method does not how any did aggro return then it should return an empty collection

95
00:07:35,760 --> 00:07:39,160
on an empty ID but not and not of value.

96
00:07:39,460 --> 00:07:46,080
And we are told very briefly mention about this other simple item which is optimized judiciously.

97
00:07:46,080 --> 00:07:52,740
It tells us not to optimize prematurely and focus more on writing good programs that use good design

98
00:07:52,740 --> 00:07:54,390
principles.

99
00:07:54,380 --> 00:07:59,320
Good programs will allow us to optimize later if needed.

100
00:07:59,490 --> 00:08:00,670
So that's about it.

101
00:08:00,900 --> 00:08:05,670
I think that somebody colour's the best properties of each of the data structures that we have seen

102
00:08:05,670 --> 00:08:07,170
in this chapter.

103
00:08:07,170 --> 00:08:11,980
So memorize them and keep reviewing them in their resources section.

104
00:08:11,980 --> 00:08:18,960
I'm including a document that is taken from a site called big ole Chichi dot com and it includes algo

105
00:08:19,040 --> 00:08:24,450
to commit complexities of many other data structures too including the ones which we have seen in this

106
00:08:24,450 --> 00:08:25,520
chapter.

107
00:08:25,740 --> 00:08:27,280
So that's all your friends.

108
00:08:27,510 --> 00:08:28,760
So that's about it.

109
00:08:28,760 --> 00:08:32,020
And I hope you enjoyed learning about collection's framework.

110
00:08:32,280 --> 00:08:34,770
Thank you and good bye for now.

