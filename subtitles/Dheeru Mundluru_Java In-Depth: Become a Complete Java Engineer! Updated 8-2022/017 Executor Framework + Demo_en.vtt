WEBVTT
1
00:00:02.230 --> 00:00:03.010
Hi there.

2
00:00:03.040 --> 00:00:04.330
This is the De La Rue.

3
00:00:04.480 --> 00:00:06.910
Let's get started with the executive framework.

4
00:00:08.109 --> 00:00:11.410
What we saw so far is threadbare task approach.

5
00:00:11.770 --> 00:00:16.870
That is a task is created and is assigned to a newly created thread for execution.

6
00:00:17.730 --> 00:00:22.860
We also saw an alternative approach where a task is defined as part of the thread itself.

7
00:00:23.430 --> 00:00:26.310
So there's a close connection between task and threat.

8
00:00:26.850 --> 00:00:28.520
That is, for every new task.

9
00:00:28.530 --> 00:00:30.030
We have a new thread.

10
00:00:31.240 --> 00:00:34.030
And this works for only small scale applications.

11
00:00:34.980 --> 00:00:41.220
But it has limitations when used in large scale applications where large number of threads may be created.

12
00:00:42.770 --> 00:00:46.220
One limitation is threat creation and on costs.

13
00:00:46.790 --> 00:00:53.450
If there can be large number of threats, then creating threats can consume significant amount of resources.

14
00:00:53.960 --> 00:00:56.630
This cost also varies across platforms.

15
00:00:57.760 --> 00:01:01.750
And having large number of vulnerable threads can use a lot of memory.

16
00:01:03.070 --> 00:01:09.160
Another limitation of threadbare task is the instability of an application, and this is due to the

17
00:01:09.160 --> 00:01:12.550
lack of limit on how many threads can be created.

18
00:01:13.330 --> 00:01:18.490
On any given platform, there would be some threshold on the number of threads that can be created.

19
00:01:18.490 --> 00:01:22.980
And if this threshold is reached, we will most likely get an out of memory error.

20
00:01:23.820 --> 00:01:28.980
So creating large number of threats will not only consume a lot of memory, but can also result in out

21
00:01:28.980 --> 00:01:29.850
of memory error.

22
00:01:31.460 --> 00:01:36.530
So the solution for these limitations is the executive framework, which is also recommended by this

23
00:01:36.530 --> 00:01:41.570
effective Joe Biden, and it says prefer executors and tasks to threats.

24
00:01:42.140 --> 00:01:45.500
Using this framework, we will not deal with threats directly.

25
00:01:45.980 --> 00:01:49.070
They are inherently by the executive framework.

26
00:01:50.940 --> 00:01:57.210
Executive framework is essentially a very flexible and a powerful task execution framework.

27
00:01:58.510 --> 00:02:03.370
And it consists of a Q and a thread poll work.

28
00:02:03.370 --> 00:02:08.680
U is basically a queue containing all the tasks that need to be executed.

29
00:02:09.370 --> 00:02:14.140
And thread pull is simply a pull off threads that execute the tasks in the work.

30
00:02:14.140 --> 00:02:14.470
You.

31
00:02:15.340 --> 00:02:22.090
In this illustration, the symbol P represents a threat, and the task we know is the work that is.

32
00:02:22.090 --> 00:02:23.950
It implements the vulnerable interface.

33
00:02:24.490 --> 00:02:28.660
In fact, later we will also look at another type of task called callable.

34
00:02:29.470 --> 00:02:33.280
So in this framework, a third picks the next task from the CPU.

35
00:02:33.310 --> 00:02:37.870
It executes it and goes back to the pool waiting for another task.

36
00:02:38.380 --> 00:02:45.210
So thread is not terminated as soon as it finishes executing a task, like in the case of thread per

37
00:02:45.220 --> 00:02:46.120
task approach.

38
00:02:46.810 --> 00:02:52.060
It will go back to the pool so that it can be reused over and over again for new tasks.

39
00:02:53.010 --> 00:02:58.350
And these tadpoles can be of different types and you can specify what kind of threat you would like

40
00:02:58.350 --> 00:03:05.460
to create, and that decides things like how many threats the threat would have or how long the threats

41
00:03:05.460 --> 00:03:06.360
will be alive.

42
00:03:07.170 --> 00:03:09.810
And that's all essentially threat management.

43
00:03:10.500 --> 00:03:14.960
So we can specify what kind of threat pose we would like to have in our application.

44
00:03:14.970 --> 00:03:18.120
And we will soon look at a few commonly used threat pools.

45
00:03:19.570 --> 00:03:25.000
So the next question is how does the executive framework address the limitations of threat per task

46
00:03:25.000 --> 00:03:25.600
approach?

47
00:03:27.110 --> 00:03:30.710
First, as it was just mentioned once, thread pool is created.

48
00:03:30.740 --> 00:03:37.610
It has some fixed number of threads and they can be used readily without having to create a new thread

49
00:03:37.610 --> 00:03:39.920
for every new task to be executed.

50
00:03:40.460 --> 00:03:43.550
And that saves thread creation and taken costs.

51
00:03:44.180 --> 00:03:49.340
So a task would be executed immediately without having to wait for a newly created thread.

52
00:03:49.820 --> 00:03:52.610
So that leads to better responsiveness.

53
00:03:54.480 --> 00:04:00.000
And since we can have an upper limit on the number of threads that a thread pool can have, the other

54
00:04:00.000 --> 00:04:01.830
two limitations are also addressed.

55
00:04:02.190 --> 00:04:07.980
The third limitation was about instability, where we may end up with an out of memory error when there

56
00:04:07.980 --> 00:04:10.920
is no bound on the number of threads to be created.

57
00:04:12.660 --> 00:04:15.870
Now let's see how the executed framework is represented.

58
00:04:16.230 --> 00:04:18.420
Later, we will also do a very short demo.

59
00:04:18.990 --> 00:04:24.870
There is this interface called Executor, which represents the task execution framework, and it has

60
00:04:24.870 --> 00:04:28.260
one method execute, which takes a round table as input.

61
00:04:28.890 --> 00:04:31.410
So tasks are submitted via this method.

62
00:04:32.960 --> 00:04:37.520
This snippet shows how you can implement a threat per task executed.

63
00:04:38.400 --> 00:04:44.490
As you can see, it implements the executed interface and in the execute method a new thread is being

64
00:04:44.490 --> 00:04:46.650
spawned for every new task.

65
00:04:47.160 --> 00:04:49.680
So that's the thread per task executor.

66
00:04:50.500 --> 00:04:54.080
And this is how the client code would look like, as we can see.

67
00:04:54.100 --> 00:04:57.280
Two tasks are being submitted to the same executor.

68
00:04:59.140 --> 00:05:02.350
And here is how you would create a single threaded executed.

69
00:05:02.950 --> 00:05:06.250
That is a new thread is not created for the given task.

70
00:05:06.790 --> 00:05:10.960
We are directly invoking the run method on the run able instance.

71
00:05:11.470 --> 00:05:16.720
So here each task is executed sequentially as part of the caller thread itself.

72
00:05:17.430 --> 00:05:22.260
So what we are seeing here is a different type of prosecutor than what we saw in the previous slide

73
00:05:22.260 --> 00:05:24.390
with the threat per task executed.

74
00:05:25.920 --> 00:05:31.920
So essentially with this kind of a framework, we are able to decouple the submission from the actual

75
00:05:31.920 --> 00:05:33.540
task execution process.

76
00:05:34.230 --> 00:05:38.670
That means the task execution process can be customized as per our needs.

77
00:05:39.590 --> 00:05:41.720
Let's now look at other kinds of executor's.

78
00:05:43.160 --> 00:05:50.720
This class called executors from the package concurrent provides most of the executors that we will

79
00:05:50.720 --> 00:05:51.650
ever need.

80
00:05:51.680 --> 00:05:53.750
We are static factory methods.

81
00:05:55.220 --> 00:05:57.440
And here are some of the important methods.

82
00:05:57.470 --> 00:06:03.950
New fixed thread pool, new cast thread pool, new single thread executed a new scheduled thread pool.

83
00:06:04.610 --> 00:06:09.620
So these methods return executables with certain properties associated with them.

84
00:06:11.470 --> 00:06:16.480
And the executors returned by the first three methods implement the interface, execute the service

85
00:06:16.480 --> 00:06:22.510
which extends the executed interface and it is really very extensive as we will see later.

86
00:06:22.900 --> 00:06:26.860
So the return type of these three methods is an executed service.

87
00:06:28.370 --> 00:06:35.000
The last method returns an executor that implements scheduled executor service, which in turn extends

88
00:06:35.030 --> 00:06:36.200
executor service.

89
00:06:38.400 --> 00:06:44.580
Note that executioners written by these methods are instances of a class called Tadpole Executor, which

90
00:06:44.580 --> 00:06:47.250
is from the package jabber dot dot concurrent.

91
00:06:48.030 --> 00:06:54.510
And the last method actually returns an instance of a subclass of this class thread pull executed.

92
00:06:56.060 --> 00:07:02.600
And this class extends abstract executive service, which is a skeletal implementation of executed service.

93
00:07:03.540 --> 00:07:04.890
As specified earlier.

94
00:07:04.890 --> 00:07:11.010
We can use one of these methods as I executed the return address, the most common usage scenarios.

95
00:07:11.370 --> 00:07:17.160
And if you need more customized execution, then you can directly use thread, pull executed class and

96
00:07:17.160 --> 00:07:19.960
you can get more information on that by reading its API.

97
00:07:22.450 --> 00:07:27.820
Let's now briefly look at the attributes of the executors that are written by the methods in the previous

98
00:07:27.820 --> 00:07:28.240
slide.

99
00:07:28.540 --> 00:07:31.090
And let's begin with new fixed thread poll.

100
00:07:32.460 --> 00:07:39.990
As the name suggests, this method creates a fixed size pool where size is specified by the input parameter

101
00:07:39.990 --> 00:07:40.950
and threads.

102
00:07:41.670 --> 00:07:46.230
So the threat pool will have a maximum of threads that will be active.

103
00:07:47.990 --> 00:07:54.650
And the way it works is initially there will not be any threats, but as tasks are submitted, new threats

104
00:07:54.650 --> 00:07:56.510
will be created to execute them.

105
00:07:57.320 --> 00:07:59.900
And this continues until pool size is reached.

106
00:08:00.780 --> 00:08:06.780
Not that if pool size is not yet reached and if there is a new task, then a new threat is created to

107
00:08:06.780 --> 00:08:07.980
execute the task.

108
00:08:08.010 --> 00:08:10.080
Even if there is an idle threat.

109
00:08:11.610 --> 00:08:15.170
But once the pool size is reached, no new threats are created.

110
00:08:15.180 --> 00:08:22.440
And for any new task, either an idle threat is used or the task is cured until the threat becomes idle.

111
00:08:23.070 --> 00:08:28.290
So at any point of time, at most, any threats will be actively processing tasks.

112
00:08:30.130 --> 00:08:34.090
A new threat is added if an existing threat dies due to exception.

113
00:08:35.890 --> 00:08:40.750
And if you're dealing with a heavily loaded production server, then this is the method that you need

114
00:08:40.750 --> 00:08:41.530
to invoke.

115
00:08:43.150 --> 00:08:50.710
Not that full size is also reconfigurable by invoking set maximum pool size method from the class thread

116
00:08:50.710 --> 00:08:51.640
pool executed.

117
00:08:52.150 --> 00:08:56.800
But as mentioned earlier, new fixed thread pull method returns an executed service.

118
00:08:57.070 --> 00:09:01.180
So we need to cast it to thread pull executable for invoking this method.

119
00:09:03.040 --> 00:09:09.190
Now in the last slide, one of the methods was new single thread executor, and invoking that method

120
00:09:09.190 --> 00:09:16.510
is similar to creating a fixed Red Bull with a size of one, but with the constraint that the executor

121
00:09:16.510 --> 00:09:18.280
cannot be reconfigured.

122
00:09:18.700 --> 00:09:22.540
So the written executor will strictly have a single active thread.

123
00:09:24.390 --> 00:09:26.820
Next is new castrate method.

124
00:09:26.940 --> 00:09:33.060
And in this configuration tasks are not cured, just like in the case of thread per task policy.

125
00:09:33.960 --> 00:09:36.570
It means that there is no bond on threat creation.

126
00:09:38.600 --> 00:09:39.560
For a given task.

127
00:09:39.560 --> 00:09:42.350
If there is an idle threat, it will be reused.

128
00:09:42.770 --> 00:09:44.840
Otherwise, a new one will be created.

129
00:09:45.530 --> 00:09:51.920
Since an idle threat can be reused, it is definitely better than threat per task policy as the reusing

130
00:09:51.920 --> 00:09:54.620
threads would lead to better responsiveness.

131
00:09:56.220 --> 00:10:01.830
However, a threat can be idle for only 60 seconds, after which it will be terminated and removed from

132
00:10:01.830 --> 00:10:02.460
the cache.

133
00:10:03.440 --> 00:10:09.110
Note that in case of new fixed pool, there is no such restriction on how long the thread can be idle.

134
00:10:11.060 --> 00:10:13.400
And it's a good choice for a lightly loaded server.

135
00:10:13.760 --> 00:10:18.890
It's not preferred for heavily loaded applications, as recreation is unbounded here.

136
00:10:20.750 --> 00:10:27.560
The final method was new scheduled thread pool, which creates a fixed size threat pool that supports

137
00:10:27.560 --> 00:10:30.170
delayed and periodic task execution.

138
00:10:30.950 --> 00:10:37.670
For instance, you can schedule a task to run after a period of 60 seconds, so that's a delayed task.

139
00:10:38.210 --> 00:10:42.890
Similarly, you can also schedule a task to run once every hour periodically.

140
00:10:43.810 --> 00:10:45.010
So that's about it.

141
00:10:45.100 --> 00:10:52.600
We have learned how Executable Framework decouples task submission from task execution and this gives

142
00:10:52.600 --> 00:10:55.770
the flexibility to create different kinds of triples.

143
00:10:56.700 --> 00:10:58.830
We learned that for heavily loaded applications.

144
00:10:58.860 --> 00:11:05.220
New fixed rate pull is preferred, while four lightly loaded applications new cache thread pull is preferred.

145
00:11:05.910 --> 00:11:08.400
Now let's go ahead and do a very quick demo.

146
00:11:11.200 --> 00:11:17.650
For this demo, I created this new class called Knife Executable Indexer in our concurrency indexer

147
00:11:17.650 --> 00:11:18.340
package.

148
00:11:18.640 --> 00:11:23.800
So we are once again going to have our downloaded thread and the indexer thread and we are going to

149
00:11:23.800 --> 00:11:25.330
download the four web links.

150
00:11:25.780 --> 00:11:29.410
Now here we are going to create executables.

151
00:11:29.830 --> 00:11:33.700
So we are not going to deal with we are not going to create threads directly.

152
00:11:33.700 --> 00:11:34.130
Right?

153
00:11:34.150 --> 00:11:35.950
We are going to use executables.

154
00:11:36.280 --> 00:11:41.560
And the executed that we are going to create here is fixed thread pull executed and we are going to

155
00:11:41.560 --> 00:11:45.370
have separate executables for downloading and indexing.

156
00:11:45.370 --> 00:11:51.700
So we have these two executables downloader download executable and index index are executed and we

157
00:11:51.700 --> 00:11:58.120
are invoking the method new fixed thread pull from the executable class and we are passing a value of

158
00:11:58.120 --> 00:12:03.850
two, which means that at any given instance of time we will have to download our threads.

159
00:12:03.850 --> 00:12:11.560
And similarly within the indexer executor we'll have to indexer threads and the program itself, the

160
00:12:11.560 --> 00:12:18.430
class itself is called us now executable indexer, which means that there is some niceness in this class

161
00:12:18.730 --> 00:12:23.260
and it is very similar to the now indexer program which we have seen earlier.

162
00:12:23.500 --> 00:12:29.620
And the limitation with that particular class was that the indexer thread was waiting for the downloader

163
00:12:29.650 --> 00:12:36.370
thread to finish its downloading, and the way it was waiting was it was looping in a wide loop.

164
00:12:37.390 --> 00:12:43.750
So the limitation was that zip cycles were getting wasted and because of that we had an improvement.

165
00:12:43.750 --> 00:12:49.870
So we in the next lecture we created the Wait Notify Indexer, which was an improvement over the native

166
00:12:49.870 --> 00:12:50.590
indexer.

167
00:12:51.490 --> 00:12:54.100
But the wait notify index itself.

168
00:12:54.730 --> 00:13:00.070
The limitation with that is it does low level handshaking and that's why we are here looking at the

169
00:13:00.070 --> 00:13:01.210
executable framework.

170
00:13:01.330 --> 00:13:07.030
But even this program has the same limitation as an indexer where the CPU cycles are being wasted.

171
00:13:07.910 --> 00:13:09.990
And we will fix that in the next lecture.

172
00:13:10.010 --> 00:13:14.780
So, so here we are creating two executors download executor and indexer executor.

173
00:13:15.080 --> 00:13:19.490
And those are and those are fixed dreadful executors.

174
00:13:19.940 --> 00:13:27.170
And in the main method we are instantiating as usual and we are creating the for web blanks and we are

175
00:13:27.170 --> 00:13:31.100
adding it here into the queue and we are finally invoking a go method.

176
00:13:31.220 --> 00:13:38.810
And in the go method we are iterating through the list, through the queue of web links and we are passing

177
00:13:38.810 --> 00:13:39.860
each weblink.

178
00:13:40.160 --> 00:13:45.680
We are creating an instance of downloader and passing that web link and downloader is simply a task

179
00:13:45.680 --> 00:13:50.630
and we are passing it to the corresponding executor here download executor and we are doing the same

180
00:13:50.630 --> 00:13:54.740
with the indexer and we are going to iterate through all of the web links.

181
00:13:56.800 --> 00:13:58.060
So after that.

182
00:13:59.420 --> 00:14:07.130
We have these two downloader and the indexer threats and indexer tasks and the executor framework.

183
00:14:07.130 --> 00:14:07.730
Well.

184
00:14:08.570 --> 00:14:15.770
You know, the threats within the executive framework will take these tasks and then Bill will execute

185
00:14:15.770 --> 00:14:18.740
them and then we'll go back into the idle state.

186
00:14:18.740 --> 00:14:20.390
So we already know that.

187
00:14:20.930 --> 00:14:25.860
So here the downloader and index attacks are very similar to what we have seen earlier in the knife

188
00:14:25.880 --> 00:14:26.720
index program.

189
00:14:26.720 --> 00:14:33.770
So it's just the same code here, the downloader as downloading the web page and it is invoking the

190
00:14:34.130 --> 00:14:38.450
HTML page and the web link in the web link object and it is setting the HTML page.

191
00:14:38.540 --> 00:14:44.780
And the other thread is simply looping here until the HTML page has been downloaded.

192
00:14:44.780 --> 00:14:51.200
So as soon as this not equal to null is true, then we go ahead and index the HTML page.

193
00:14:51.230 --> 00:14:55.520
If not, we just keep looping here in this loop, wasting the CPU cycles.

194
00:14:55.820 --> 00:14:56.240
All right.

195
00:14:56.390 --> 00:15:03.950
And the only thing you might want to remember as the HTML within this HTML, within the Web class,

196
00:15:04.160 --> 00:15:06.800
HTML page is actually a volatile variable.

197
00:15:07.100 --> 00:15:11.270
And that gives the memory visibility advantage.

198
00:15:11.270 --> 00:15:18.980
So by doing so, the the indexer thread will be able to see the latest value of the HTML page as soon

199
00:15:18.980 --> 00:15:22.340
as the downloader downloader thread downloads the HTML page.

200
00:15:22.670 --> 00:15:24.230
So that's about it.

201
00:15:24.230 --> 00:15:26.270
So let me just go ahead and run this.

202
00:15:27.650 --> 00:15:28.370
Downloading?

203
00:15:28.370 --> 00:15:29.480
Not yet downloaded.

204
00:15:29.970 --> 00:15:30.710
Okay, we are done.

205
00:15:30.710 --> 00:15:33.410
So all of the four links have been indexed now.

206
00:15:33.740 --> 00:15:40.040
But as you can see, a lot of CPU cycles have been wasted in the form of looping here.

207
00:15:40.040 --> 00:15:41.660
So that's the disadvantage.

208
00:15:41.810 --> 00:15:47.960
Now, the program is still running, as you can see, and that's because the executor has to be shut

209
00:15:47.960 --> 00:15:48.440
down.

210
00:15:49.400 --> 00:15:55.460
And the reason we are unable to shut down is because those methods are not available in the executed

211
00:15:55.460 --> 00:15:56.280
interface.

212
00:15:56.300 --> 00:16:02.450
And for that, we need to use executor service, which we will use in the next in the next demo, in

213
00:16:02.450 --> 00:16:03.350
the next lecture.

214
00:16:03.770 --> 00:16:10.880
And along with that, we will also fix the limitation of wasting the CPU cycles, and we will be using

215
00:16:10.880 --> 00:16:13.760
other types like callable and future.

216
00:16:13.940 --> 00:16:15.860
And we will see that in the next lecture.

217
00:16:15.950 --> 00:16:17.240
So that's about it.

218
00:16:17.300 --> 00:16:17.870
Thank you.

219
00:16:17.870 --> 00:16:20.990
And this code will be available in the resources section.

