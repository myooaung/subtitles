1
00:00:00,590 --> 00:00:04,430
Hello and welcome back to the course on the deep natural language processing.

2
00:00:04,490 --> 00:00:07,070
And today we're talking about attention Mechanix.

3
00:00:07,250 --> 00:00:08,460
So let's have a look.

4
00:00:08,540 --> 00:00:11,280
This is where we stopped off previously.

5
00:00:11,300 --> 00:00:15,360
So we've got an encoder which is a recurrent neural network and we've got a decoder.

6
00:00:15,370 --> 00:00:20,460
Another recurrent neural network of the LSD and fashion.

7
00:00:20,660 --> 00:00:31,730
And so here what is happening is we're feeding in our input into our encoder one by one into these layers

8
00:00:31,790 --> 00:00:33,730
of neurons.

9
00:00:33,800 --> 00:00:44,600
And then at the end we have this representation of our whole input here which is of called the vector

10
00:00:44,600 --> 00:00:45,390
of meaning.

11
00:00:45,590 --> 00:00:51,040
So the whole meaning of our sentence is contained to it here and then we use that.

12
00:00:51,350 --> 00:00:58,800
So we use this layer now to decode our our whole neural network over here.

13
00:00:58,870 --> 00:01:05,690
So to basically come up with a response using a decoder to the questions are here was something like

14
00:01:05,690 --> 00:01:07,660
Did you like that last week.

15
00:01:07,880 --> 00:01:09,710
And the responses yes it was great.

16
00:01:10,010 --> 00:01:12,250
So that's what we have so far.

17
00:01:12,620 --> 00:01:19,430
And the kind of like the weak point of this whole architecture is exactly over here.

18
00:01:19,430 --> 00:01:26,030
So it's a great architecture it facilitates memory so we adding more and more information here so it's

19
00:01:26,060 --> 00:01:28,730
all kind of like accumulating.

20
00:01:28,730 --> 00:01:33,950
And then this vector meaning it has a lot of information has pretty much the whole sentence here.

21
00:01:33,980 --> 00:01:37,580
So it's it's great that we facilitates memory.

22
00:01:37,620 --> 00:01:49,340
However as you can imagine they first of all this is a fixed dimensional component of our network and

23
00:01:49,340 --> 00:01:57,020
it is representing a variable variable length component or variable length input so our input could

24
00:01:57,020 --> 00:02:02,950
be like a thousand words could be 10 words could be 100 words in every single case.

25
00:02:02,990 --> 00:02:08,370
It's all stored in this fix them actual representation and that's not ideal.

26
00:02:08,370 --> 00:02:17,130
So basically that's a lot of information to store here and moreover it doesn't really change depending

27
00:02:17,130 --> 00:02:22,150
on what type of sensor you once you have this architecture you might need it a longer sense is a short

28
00:02:22,150 --> 00:02:28,390
sentence and all the time it only has this facility in order to take care of the meaning of that information

29
00:02:29,010 --> 00:02:34,770
and then the other thing is that after that this meaning has to be carried through the whole of the

30
00:02:34,770 --> 00:02:42,030
decoder has to go all the way through the decoder has to carry a long we have it has to be able to maintain

31
00:02:42,030 --> 00:02:49,330
all of the information was here in this in this layer as it goes through the decoder.

32
00:02:49,440 --> 00:02:55,920
And words are pulled out of it's information is pulled out or like generated from it.

33
00:02:55,920 --> 00:03:04,950
So this approach is is OK for kind of short sentences short responses and questions but as they grow

34
00:03:04,950 --> 00:03:09,390
longer it becomes harder and harder for the network to do that.

35
00:03:09,540 --> 00:03:14,690
To be able to provide proper responses and maintain that mean.

36
00:03:14,820 --> 00:03:17,110
So that's what happens with Chad.

37
00:03:17,120 --> 00:03:23,310
But we're also going to quickly discuss what happens even in translation because we will see through

38
00:03:23,320 --> 00:03:31,620
all this tutorial that attention is a concept that is very very powerful in translation as well which

39
00:03:31,790 --> 00:03:40,220
sequences sequence networks can be used for and translation is a good analogy in translation.

40
00:03:40,620 --> 00:03:47,550
So the way it works is so here you've got the question you've got the sentence that should we want to

41
00:03:47,550 --> 00:03:51,420
translate so they say in English and you want to translate into French or some other language.

42
00:03:51,700 --> 00:03:53,810
It would be very simple.

43
00:03:53,820 --> 00:04:02,780
So you have like a very similar type of literate primitive simply and in translation like that analogy

44
00:04:02,780 --> 00:04:07,090
or the metaphor which I liked which I think it was.

45
00:04:07,190 --> 00:04:14,820
Christopher Manning from Stanford which I heard from him on one of his online lectures.

46
00:04:14,840 --> 00:04:17,650
The analogy is very powerful.

47
00:04:17,650 --> 00:04:25,340
What he says is that like if you're a translator and you take all the like you have an input word having

48
00:04:25,340 --> 00:04:31,460
just this one vector of meaning here is like reading the whole sentence that you need to translate and

49
00:04:31,460 --> 00:04:35,630
then closing your eyes at it like OK I got the whole sentence in my head I'm going to translate it all

50
00:04:35,630 --> 00:04:36,450
now.

51
00:04:36,920 --> 00:04:42,850
So translators don't work like even human translators don't recognize you like you've got the sentence.

52
00:04:42,880 --> 00:04:44,900
It might be long or short doesn't matter.

53
00:04:44,900 --> 00:04:49,640
You translate it a bit by bit then you look back then you kind of like OK you like you get to certain

54
00:04:49,650 --> 00:04:52,100
point and then you look at the sentence again and you keep going.

55
00:04:52,110 --> 00:05:01,200
So you have the luxury of looking back at what you have just so that is the Nalgene translation.

56
00:05:01,210 --> 00:05:04,230
And now we're going to start fixing this whole situation up.

57
00:05:04,240 --> 00:05:07,240
All right so we're going to look at a different sentence just makes it up again a sentence.

58
00:05:07,240 --> 00:05:09,450
How is your sister end of sentence.

59
00:05:09,490 --> 00:05:13,060
I didn't put the question mark just have some space but feel free to ask the question about another

60
00:05:13,060 --> 00:05:14,070
element.

61
00:05:14,080 --> 00:05:19,800
And then our network is going to attempt to answer with.

62
00:05:20,050 --> 00:05:20,860
Thank you.

63
00:05:20,860 --> 00:05:21,780
She is fine.

64
00:05:21,970 --> 00:05:23,170
And let's see how this plays out.

65
00:05:23,170 --> 00:05:29,100
So first word and then we feed it back in you then.

66
00:05:29,110 --> 00:05:31,170
Next word feedback thank you.

67
00:05:31,240 --> 00:05:35,680
And this is where we're going to start talking about attention so attention along this way actually

68
00:05:35,680 --> 00:05:40,150
was already here was already here when these words were generated we just didn't talk about it because

69
00:05:41,500 --> 00:05:48,060
like I wanted to get away from the start I wanted to look at components like further down the sequence.

70
00:05:48,070 --> 00:05:50,970
But the same principles apply here here everywhere.

71
00:05:51,340 --> 00:05:52,790
So what does a station do.

72
00:05:52,840 --> 00:06:01,570
Well basically before we have an output come in from here what happens is all of our input layers or

73
00:06:01,570 --> 00:06:09,940
all of the components of the encoder like I've highlighted that we hear and read are taken and then

74
00:06:11,110 --> 00:06:19,470
we're going to now look back at them so they were going to allow this stage or this component of the

75
00:06:19,470 --> 00:06:23,410
D-CT are to look at what was a producer like.

76
00:06:23,460 --> 00:06:30,120
Basically we're saying that the decoder has complete liberty to access any of the information that is

77
00:06:30,120 --> 00:06:36,000
available before not just information that was encoded into this picture meaning that it was passed

78
00:06:36,000 --> 00:06:37,840
on here was posted here and so on.

79
00:06:37,860 --> 00:06:46,620
It does indeed have that but now it also has I like a special VIP access to all the information that

80
00:06:46,620 --> 00:06:47,680
was available before.

81
00:06:47,850 --> 00:06:49,220
And how does this access work.

82
00:06:49,470 --> 00:07:00,420
Well through training the decoder will know which of these elements to pay the most attention.

83
00:07:00,450 --> 00:07:02,130
And the way it looks is like this.

84
00:07:02,130 --> 00:07:10,130
So for example it has learned to give weights of importance to these compounds.

85
00:07:10,230 --> 00:07:12,240
So let's draw these weights.

86
00:07:12,370 --> 00:07:14,370
There's five weights.

87
00:07:14,820 --> 00:07:20,390
The bigger the weight the more significant the more important is that component and the weight gain

88
00:07:20,400 --> 00:07:22,120
or the way that happens is through training.

89
00:07:22,150 --> 00:07:27,010
Become a bit more clear just now as soon as we get this out here.

90
00:07:28,290 --> 00:07:35,180
And so it knows these weights it knows that for this next output it needs to pay most weight on this

91
00:07:35,180 --> 00:07:35,810
component.

92
00:07:35,900 --> 00:07:39,940
And second most weight on this component third most weight on this compound these kookaburras don't

93
00:07:39,950 --> 00:07:40,630
really matter.

94
00:07:40,850 --> 00:07:47,190
And through a step a step which is called the soft back function which you won't get into now.

95
00:07:47,210 --> 00:07:53,360
But what happens is basically these ways we make sure the algorithm make sure that these weights add

96
00:07:53,360 --> 00:07:53,930
up to one.

97
00:07:53,930 --> 00:08:03,050
So this by the looks of that will be like a point of point six point point to point one and point zero

98
00:08:03,050 --> 00:08:04,360
five point zero or five.

99
00:08:04,580 --> 00:08:08,990
So just just for us so that it's easier to operate.

100
00:08:09,020 --> 00:08:14,840
And then what happens is we take these weights and we create a context.

101
00:08:14,870 --> 00:08:15,550
How do we create it.

102
00:08:15,560 --> 00:08:22,130
Well we take this weight and we multiply by this vector we may take this way multiply by this vector

103
00:08:22,850 --> 00:08:23,800
this way.

104
00:08:23,810 --> 00:08:24,710
By this one this way.

105
00:08:24,710 --> 00:08:25,650
By this one this way.

106
00:08:25,730 --> 00:08:33,680
So this context vector is a weighted sum of all of these contex actors or all of these layers in our

107
00:08:33,830 --> 00:08:35,570
recurrent neural network.

108
00:08:35,570 --> 00:08:42,590
And so now we have the Quantic sector which is predominantly comprised of this vector a bit less of

109
00:08:42,590 --> 00:08:43,400
this one.

110
00:08:43,420 --> 00:08:48,660
One haaf like quite significantly less of this one and less of this and tiny bit of these two.

111
00:08:48,980 --> 00:08:57,980
And then what we do with it's called the X factor is we it into this new layer of our decoder as an

112
00:08:57,980 --> 00:08:59,000
additional input.

113
00:08:59,000 --> 00:09:05,120
So now you have this input this input and this input range decoder and then we get the output which

114
00:09:05,120 --> 00:09:08,330
is she wants to make this and I think she's fine.

115
00:09:08,680 --> 00:09:10,310
OK so that's the mechanics.

116
00:09:10,310 --> 00:09:13,150
Now let's assess what just happened.

117
00:09:13,220 --> 00:09:14,410
Why.

118
00:09:14,630 --> 00:09:17,870
Why are these ways like the burning question that you have right now.

119
00:09:17,870 --> 00:09:23,010
I can feel it is why are the weights exactly like this.

120
00:09:23,170 --> 00:09:26,040
Well let's think about it.

121
00:09:26,470 --> 00:09:33,690
The decoder got is creating a sentence to tell us that this person that we've been asked about is fine.

122
00:09:33,940 --> 00:09:42,110
And in English it the pronoun will depend on the gender.

123
00:09:42,120 --> 00:09:42,360
Right.

124
00:09:42,370 --> 00:09:46,340
So if it's free it's a female person it's a she.

125
00:09:46,360 --> 00:09:48,700
If it's a male person it's going to be a.

126
00:09:48,820 --> 00:09:49,750
So thank you.

127
00:09:49,750 --> 00:09:50,510
He is fine.

128
00:09:50,510 --> 00:09:51,710
I think she is fine.

129
00:09:51,740 --> 00:09:59,190
The like the the point we have to understand here is that the meaning is the same.

130
00:09:59,590 --> 00:10:01,440
He is fine or she is fine.

131
00:10:01,540 --> 00:10:03,340
So that person is fine.

132
00:10:03,340 --> 00:10:05,850
So the meaning is absolutely identical.

133
00:10:05,850 --> 00:10:08,110
What's the D-CT and that's why.

134
00:10:08,110 --> 00:10:13,870
That's another hint and why it's called the de-code or so it's kind of decoding the meaning of what

135
00:10:13,930 --> 00:10:14,520
we want to.

136
00:10:14,530 --> 00:10:20,020
And so we know like decoding the meaning into words we know what we want to enhance or we're building

137
00:10:20,020 --> 00:10:21,560
what we want to answer.

138
00:10:21,850 --> 00:10:28,350
And now we're slowly decoding it into words so we want to say that that person is fine they're OK everything's

139
00:10:28,360 --> 00:10:28,870
great.

140
00:10:28,990 --> 00:10:33,310
So now we're slowly building it up and we go to a stage where we need to decide what pronoun to use

141
00:10:33,790 --> 00:10:37,180
and based on prior training we get this.

142
00:10:37,180 --> 00:10:41,830
Right now we're Remember the difference between training and application.

143
00:10:41,830 --> 00:10:43,480
Right now we're in application mode.

144
00:10:43,660 --> 00:10:49,570
But before there would have been like millions and millions or hundreds of thousands of iterations for

145
00:10:49,570 --> 00:10:53,570
training of this model and through training the

146
00:10:57,970 --> 00:11:05,740
model would have learned that when you want to decide a pronoun you need to find now or other pronouns

147
00:11:05,830 --> 00:11:07,300
in the question.

148
00:11:07,330 --> 00:11:12,610
So it's a very simplistic explanation of course it's all based on neurons and the model has no clue

149
00:11:12,610 --> 00:11:18,490
what a pronoun or a noun is it doesn't have the sign understanding of language constructs and so on

150
00:11:18,520 --> 00:11:25,160
but it intuitively learns these things through iterations iterations and we can call them pronouns nouns.

151
00:11:25,210 --> 00:11:26,430
The model doesn't care.

152
00:11:26,440 --> 00:11:33,790
It just knows that when there's when there's a decision to say he or she it needs to go back and find

153
00:11:33,790 --> 00:11:35,430
something like this.

154
00:11:35,770 --> 00:11:42,360
And so basically that's where this highway comes from because it needs to make informed decision then

155
00:11:42,370 --> 00:11:44,280
these are ways they don't matter as much.

156
00:11:44,280 --> 00:11:45,510
This is the pre-Roman one.

157
00:11:45,670 --> 00:11:54,190
But like I put them here just for illustration purposes and they can also impact this work right.

158
00:11:54,190 --> 00:11:55,270
So let's have a look.

159
00:11:55,270 --> 00:11:57,960
Why can this word impact this work.

160
00:11:58,150 --> 00:12:05,110
Well because we're trying to say that wherever they're talking about wherever the question is about

161
00:12:05,440 --> 00:12:11,590
that they are fine or that here fine or she is fine or it is fine if it's not that person.

162
00:12:12,670 --> 00:12:16,430
But this word is it's tallying us.

163
00:12:16,510 --> 00:12:18,570
How many of them are there for you.

164
00:12:18,590 --> 00:12:21,610
So yes Sister indeed is singular.

165
00:12:21,610 --> 00:12:30,650
But if we don't look at it like not only sister tells us about the number of people and number of subjects.

166
00:12:30,670 --> 00:12:32,400
Also this word tells us so.

167
00:12:32,620 --> 00:12:41,730
How are your sisters and brothers or how are your sister and brothers so that could have been a sentence.

168
00:12:41,830 --> 00:12:46,780
So in that case there would still be singular but this is this word would tell us that actually there's

169
00:12:46,780 --> 00:12:48,470
many people that were being lost.

170
00:12:48,490 --> 00:12:53,930
So in this case in that case that's why the.

171
00:12:53,950 --> 00:13:00,190
That's why the wait is important in that case if there are you know then this would have been thank

172
00:13:00,190 --> 00:13:00,360
you.

173
00:13:00,370 --> 00:13:01,100
Not she.

174
00:13:01,100 --> 00:13:03,760
But I think they are find something.

175
00:13:04,000 --> 00:13:06,190
So that's why they support it so it can have any impact.

176
00:13:06,190 --> 00:13:09,430
But in this case is just confirming that Sister singular good.

177
00:13:09,610 --> 00:13:12,040
So you didn't get additional information.

178
00:13:12,040 --> 00:13:15,940
Then why does this one have a not a significant weight.

179
00:13:15,970 --> 00:13:20,130
Why is it like it's small but it's still bigger than these two.

180
00:13:20,380 --> 00:13:21,550
Of why with this one.

181
00:13:21,580 --> 00:13:26,740
Well again for a similar reason that for example I'm not sure.

182
00:13:26,730 --> 00:13:33,720
Like I this is not very old like I I just put this here to illustrate purposes like I have a point.

183
00:13:34,150 --> 00:13:40,180
And the way I would interpret this if I saw something I guess I would say OK I meant maybe the network

184
00:13:40,180 --> 00:13:47,580
is sees this POS as important it's because it wants to make sure that there's nothing coming further

185
00:13:47,590 --> 00:13:53,820
so soon as it sees the U.S. It knows that there's no other subjects or other words again it could be.

186
00:13:53,830 --> 00:13:56,550
How are your sister and brothers.

187
00:13:56,590 --> 00:14:01,720
So but because it says the AOA as it knows that there's no one else saw it so therefore it nosiest and

188
00:14:01,750 --> 00:14:06,160
the confirmation that this singular female so they would go.

189
00:14:06,180 --> 00:14:09,240
That's the intention mechanism.

190
00:14:09,240 --> 00:14:13,360
Let's have another step to kind of concrete this stuff in.

191
00:14:13,770 --> 00:14:27,450
So next one is to fit in our response from the previous opponents and again we highlight our inputs.

192
00:14:27,550 --> 00:14:29,840
That's where our attention is going to be based.

193
00:14:30,220 --> 00:14:33,650
And then we look at the way it's to do something like this.

194
00:14:34,240 --> 00:14:41,140
And then we build the context Victor and from the context vector we feed in the input or the output

195
00:14:41,160 --> 00:14:48,820
that we feel in that context worked itself into as an input into this new way of the recurrent neural

196
00:14:48,820 --> 00:14:49,440
network.

197
00:14:49,600 --> 00:14:53,570
And so why is this important and now is going to be she is.

198
00:14:53,790 --> 00:14:54,760
That's what we're looking for.

199
00:14:54,760 --> 00:14:55,810
She is fine.

200
00:14:55,810 --> 00:14:57,120
So why is this important.

201
00:14:57,370 --> 00:15:04,110
Well you can pause the video and try to understand this yourself try to kind of assess this yourself.

202
00:15:04,300 --> 00:15:06,150
If not then one two three.

203
00:15:06,310 --> 00:15:11,820
This is my interpretation I would say well how is your sister.

204
00:15:11,830 --> 00:15:13,350
Because here everyone is.

205
00:15:13,440 --> 00:15:14,360
It's.

206
00:15:14,650 --> 00:15:20,020
Right now we're kind of deciding we want to say that these people are that person or this subject is

207
00:15:20,020 --> 00:15:25,720
fine or fine and we decide singular or plural so because this is singular it's going to be easier for

208
00:15:25,720 --> 00:15:30,010
us to say it's a singular same process here sister.

209
00:15:30,040 --> 00:15:33,170
So if it was how is your sisters.

210
00:15:33,190 --> 00:15:34,960
That would be problematic.

211
00:15:34,990 --> 00:15:36,920
But because it's incorrect.

212
00:15:37,180 --> 00:15:43,020
But that's you know like if this were sisters then this would have been our right.

213
00:15:43,030 --> 00:15:50,470
So they kind of linked in terms of singularity or singular or plural and therefore what you heard in

214
00:15:50,470 --> 00:15:53,590
terms of plural or singular and so here.

215
00:15:54,060 --> 00:15:59,370
Yes so that that does carry some kind of significance and it was similar to yours.

216
00:15:59,730 --> 00:16:00,060
OK.
