WEBVTT
1
00:00:00.330 --> 00:00:07.920
Welcome back in our previous session we download the data from Kaggle and follow by splitting our data

2
00:00:08.070 --> 00:00:14.640
in our local directory into training as well as validation in the training we have cats and dogs folder

3
00:00:15.000 --> 00:00:16.680
and then also in their validation.

4
00:00:16.680 --> 00:00:19.050
We also have cats and dog folder.

5
00:00:19.050 --> 00:00:22.130
Now the question that you might ask Is that why do we do that.

6
00:00:22.140 --> 00:00:27.330
Why don't we just leave them all in one big giant folder and zip through it.

7
00:00:27.930 --> 00:00:33.430
When you've training your CNN The reason is quite simple.

8
00:00:33.750 --> 00:00:38.360
When you're actually processing images they are quite large.

9
00:00:38.370 --> 00:00:48.750
Each image maybe two megabyte or even up to five megabytes depending on the score quality that you took

10
00:00:48.750 --> 00:00:51.290
the picture in or with.

11
00:00:51.510 --> 00:00:59.070
Now when you actually have two thousand of these pictures and you can quickly see how quickly this boy

12
00:00:59.070 --> 00:01:01.100
actually run now.

13
00:01:01.110 --> 00:01:03.390
Memory.

14
00:01:03.770 --> 00:01:10.690
And of course there's also the training portion the computation portion or the overheads involved it

15
00:01:10.700 --> 00:01:14.400
will run our memory very quickly two thousand pictures is not a lot.

16
00:01:14.420 --> 00:01:20.270
Quite often people work with ten thousand a hundred thousand pictures and you can quickly see that this

17
00:01:20.270 --> 00:01:22.320
is just not gonna work.

18
00:01:22.490 --> 00:01:26.240
You just don't have enough memory to actually process all of these.

19
00:01:26.240 --> 00:01:33.860
So what people have come up with is that they actually organize it into directory structure like this

20
00:01:34.280 --> 00:01:41.810
so that when you actually come around and start training all of your your your training your CNN with

21
00:01:41.840 --> 00:01:48.950
all the data then you have the proper directory structure to actually sample some of the data in batches

22
00:01:50.370 --> 00:01:54.540
instead of trying to A.C. is sorted out within your codes.

23
00:01:54.830 --> 00:01:55.180
Right.

24
00:01:55.250 --> 00:01:59.650
Let's get started with the definition of our CNN.

25
00:01:59.720 --> 00:02:00.830
This is our architecture.

26
00:02:00.830 --> 00:02:04.720
We are using cameras of course now from cameras.

27
00:02:04.750 --> 00:02:11.820
If you look at this we are importing layers from layers we are importing convolution 2D.

28
00:02:11.840 --> 00:02:17.840
We are also importing mechs pulling against 2D flatten and also dense.

29
00:02:17.840 --> 00:02:20.120
We talked about this into the session.

30
00:02:20.270 --> 00:02:26.750
If you know if you find that you're not familiar with them please go back and pull up the notes from

31
00:02:26.750 --> 00:02:27.400
carers.

32
00:02:27.410 --> 00:02:33.820
We are importing the models to actually define our CNN architecture right.

33
00:02:33.830 --> 00:02:40.330
So we instantiating a model is could two models adopt sequential so we're using a sequential model.

34
00:02:40.460 --> 00:02:40.730
Right.

35
00:02:40.760 --> 00:02:50.840
So the first line of code here basically say we are creating a convolution layer and we will for the

36
00:02:50.840 --> 00:02:58.270
Coalition layer we are applying 30 to futures or kernels and it's three by three in terms of the kernel

37
00:02:58.280 --> 00:03:05.650
size and also after that's done the player activation really activation layer.

38
00:03:06.710 --> 00:03:09.110
And also the input shape was defined earlier.

39
00:03:09.110 --> 00:03:17.270
Remember I defined rows and columns at as 128 by 128 and three here basically say is a channel of three

40
00:03:18.140 --> 00:03:25.450
which is our G.B. and then the follow by we are working with a makes pulling.

41
00:03:25.450 --> 00:03:25.650
OK.

42
00:03:25.660 --> 00:03:29.260
The next layer that we're adding is Max pulling two by two.

43
00:03:29.350 --> 00:03:30.930
Let me go back a little bit.

44
00:03:31.060 --> 00:03:32.230
Take a step back.

45
00:03:32.250 --> 00:03:37.690
Previously when we're looking at MLS data is the grayscale hence the channel is 1.

46
00:03:38.110 --> 00:03:44.830
But we're working with color pictures as you saw the picture earlier is in color.

47
00:03:44.830 --> 00:03:50.650
So for that you will have to actually while basically that is color it has to be an G.B..

48
00:03:50.770 --> 00:03:51.000
All right.

49
00:03:51.000 --> 00:03:53.190
So that's why the channel is tree here.

50
00:03:53.410 --> 00:03:53.590
Right.

51
00:03:53.590 --> 00:03:59.800
So we have two layers defined we have a convolution layer at the output of the convolution layer.

52
00:03:59.810 --> 00:04:05.890
There's an activation function being applied to it the next layer will be the max pulling layer and

53
00:04:05.890 --> 00:04:13.900
then we're applying a convolution another convolution this time 64 futures and the each of these shooters

54
00:04:13.900 --> 00:04:15.970
have a dimension of three by three.

55
00:04:16.000 --> 00:04:22.930
Again the output of this we apply in the rail to activation layer and then another Max pulling again

56
00:04:22.930 --> 00:04:31.330
to shrink the size followed by another convolution with 60 for a few to three by three matrix activation

57
00:04:31.330 --> 00:04:34.300
is really again another mixed pooling layer.

58
00:04:35.050 --> 00:04:45.330
Finally we applied the flatten function to convert our two by two matrix into where these treat is is

59
00:04:45.340 --> 00:04:52.900
two by two by how deep our channel is and then we flatten it followed by applying to densely connected

60
00:04:53.020 --> 00:04:59.860
layer of fully connected layer also called dense the first dense layer we apply really two to actually

61
00:05:00.550 --> 00:05:06.790
expedite the so-called processing basically convert or the negative value to zero and then we apply

62
00:05:06.820 --> 00:05:15.760
a sigmoid function because we have a binary decision here it's a cat or dog right that's it that's really

63
00:05:15.760 --> 00:05:22.750
our architecture for the CNN and we are defined or rather we print the model summary out to this screen

64
00:05:22.750 --> 00:05:31.000
here this is a very simple CNN the reason we chosen this is so that we can actually have a reasonable

65
00:05:31.000 --> 00:05:37.390
training timed for for learning purpose I don't want to be babysitting these a year well a day later

66
00:05:38.600 --> 00:05:46.540
if you when you start defining architecture that's quite deep it can take a week two weeks depending

67
00:05:46.540 --> 00:05:54.170
on the hardware that you have and also how much data you have and how deep the architecture recall that

68
00:05:54.200 --> 00:05:56.440
we let's quickly summarize this.

69
00:05:56.450 --> 00:06:01.160
This is a very simple architecture it's not based on anything it's just a very simple competition just

70
00:06:01.160 --> 00:06:07.550
so that we can actually get a really good few policy and an works record that our input image shape

71
00:06:07.550 --> 00:06:09.920
is 128 by 128.

72
00:06:10.090 --> 00:06:10.280
Right.

73
00:06:10.280 --> 00:06:13.930
This is after the Coalition first convolution layer.

74
00:06:13.940 --> 00:06:23.180
The output is now 126 by 126 because we have a three by three and we have 32 because the future is 32

75
00:06:23.810 --> 00:06:31.280
and then followed by a mix pulling layer to reduce the size because this is a mixed pool with two by

76
00:06:31.280 --> 00:06:33.890
two to heights and to work with.

77
00:06:33.980 --> 00:06:35.840
So basically destroyed is too.

78
00:06:35.870 --> 00:06:41.210
So basically half did followed by another convolution there again because it's three by three so you

79
00:06:41.210 --> 00:06:47.180
lose two for the height and with and we apply another 30 to future so that becomes sixty four makes

80
00:06:47.180 --> 00:06:51.070
pulling and on and on it goes right.

81
00:06:51.100 --> 00:06:52.790
So that's really the architecture.

82
00:06:52.990 --> 00:06:53.260
Right.

83
00:06:53.260 --> 00:06:57.370
The next thing of course we need to actually have an optimizer.

84
00:06:57.370 --> 00:06:59.860
So from carers were important optimizer.

85
00:06:59.860 --> 00:07:01.230
This is a binary decision.

86
00:07:01.240 --> 00:07:09.340
So we're using a binary cross entropy and the that we're using our immense prop followed by the measurement

87
00:07:09.760 --> 00:07:14.530
performance measured the matrix is accuracy which is HCC here.

88
00:07:14.590 --> 00:07:14.830
Right.

89
00:07:14.830 --> 00:07:18.910
Having done all that we of course need to compile our image.

90
00:07:18.910 --> 00:07:19.930
We haven't done that yet.

91
00:07:19.930 --> 00:07:21.950
We'll do that a little later.

92
00:07:22.140 --> 00:07:22.380
Sorry.

93
00:07:22.390 --> 00:07:26.270
That's the compile I should just highlight that that that part is the compilation.

94
00:07:27.370 --> 00:07:28.120
OK.

95
00:07:28.180 --> 00:07:28.650
Right.

96
00:07:28.660 --> 00:07:36.010
The next thing that we need to do is do some pre processing with our image recall that we talked about

97
00:07:36.010 --> 00:07:44.200
the neural network requires data or best workspace with data that's between 0 and 1 between minus 1

98
00:07:44.220 --> 00:07:45.530
and 1.

99
00:07:45.610 --> 00:07:50.330
And these images because they're color even grayscale as well.

100
00:07:50.410 --> 00:07:53.880
It will range from 0 2 to 5 5.

101
00:07:53.980 --> 00:07:59.470
So that's why we need to actually reskill them to between 0 and 1.

102
00:07:59.470 --> 00:08:07.850
So first of all we from carers we import pre processing image and specifically what we actually interested

103
00:08:07.850 --> 00:08:10.820
in is in image data generated.

104
00:08:11.530 --> 00:08:17.770
We're splitting our data into training and validation and in terms of the so-called reskilling we're

105
00:08:17.770 --> 00:08:18.740
doing here.

106
00:08:18.790 --> 00:08:21.640
This is the part here which is divided by 2 5 5.

107
00:08:21.640 --> 00:08:24.010
So that is between 0 and 1.

108
00:08:24.520 --> 00:08:33.120
So for the training data we call it train data generation and X underscore train on this call data Gen

109
00:08:33.430 --> 00:08:37.590
we are actually flow flow from directory.

110
00:08:37.590 --> 00:08:41.470
This is directly from Caris library.

111
00:08:41.470 --> 00:08:46.920
It has this function called flow from directory meaning as we need the data.

112
00:08:47.390 --> 00:08:49.330
Retrieved from the directory.

113
00:08:49.330 --> 00:08:50.160
This is really good.

114
00:08:50.170 --> 00:08:57.130
Instead of you having to actually write a full loop a for loop.

115
00:08:57.130 --> 00:08:59.500
This has already been done for you.

116
00:08:59.500 --> 00:09:07.080
So we are extracting the data from the training set folder and the target size is as we defined earlier

117
00:09:07.090 --> 00:09:09.090
128 by 128.

118
00:09:09.150 --> 00:09:11.610
Day 828 rows and 128 columns.

119
00:09:11.830 --> 00:09:22.040
And each time we can draw a batch of 40 samples and let the CNN train on it and the class more defined

120
00:09:22.040 --> 00:09:27.960
here is binary because we are working with binary decision whether it's a cat or dog.

121
00:09:28.120 --> 00:09:34.790
Right so that's really the two core using carer's flow from directory if you are not using from using

122
00:09:34.790 --> 00:09:39.040
carries you basically have to do a full loop to retrieve the number of pictures.

123
00:09:39.230 --> 00:09:39.500
Right.

124
00:09:39.500 --> 00:09:48.770
So we repeat the same with the validation this time round we specify the data folder being data backstroke

125
00:09:48.950 --> 00:09:56.890
backslash validation said again the target size is 128 by 128 batch size 14 class mode is 40.

126
00:09:56.910 --> 00:10:04.220
All right so that's really how we actually defined all of these and carers discover that is four thousand

127
00:10:04.220 --> 00:10:12.200
images and that's for the training that's the output from the train on the score data again here and

128
00:10:12.200 --> 00:10:18.260
found another thousand members five hundred four cards five hundreds of dogs that will be for the validation.

129
00:10:18.810 --> 00:10:19.150
OK.

130
00:10:19.180 --> 00:10:23.230
So the next portion really is to training where you start with the training.

131
00:10:23.230 --> 00:10:31.340
So for here we have epochs equal to 30 so are we allowing our CNN to see the data 30 times all of the

132
00:10:31.340 --> 00:10:32.940
data 30 times.

133
00:10:33.050 --> 00:10:39.410
And in terms of the fitting it's a little bit different from what we used to do we used to just use

134
00:10:39.410 --> 00:10:46.160
fit this time we're using fit generator because we are using the data generated from before which is

135
00:10:46.160 --> 00:10:49.580
flow from directory that image data generator.

136
00:10:49.580 --> 00:10:53.040
Essentially this image data generated does two things.

137
00:10:53.060 --> 00:10:57.970
One is a notice to reskilling part dividing the data to five five.

138
00:10:57.980 --> 00:10:59.360
That's the first part.

139
00:10:59.360 --> 00:11:10.130
Second part is that it from the data directory it draw the the samples for training OK.

140
00:11:10.170 --> 00:11:15.920
So what we have here with providing the training data and which is defined here.

141
00:11:15.930 --> 00:11:16.990
Training training data.

142
00:11:16.990 --> 00:11:17.220
Jane.

143
00:11:17.220 --> 00:11:18.470
Or train that again.

144
00:11:18.660 --> 00:11:22.120
And the steps but epoch is one hundred.

145
00:11:22.620 --> 00:11:26.090
The reason is one hundred is that we need to explain.

146
00:11:26.100 --> 00:11:32.020
Because the problem now is that Karissa does not know when it is.

147
00:11:32.040 --> 00:11:33.870
How do you count one epoch.

148
00:11:33.930 --> 00:11:38.190
We want to do 30 epoch but it doesn't know how many images that we have.

149
00:11:38.190 --> 00:11:39.740
So it does not know.

150
00:11:39.750 --> 00:11:43.090
So we need to define it for Karas.

151
00:11:43.110 --> 00:11:46.380
Remember we're drawing a batch size of 40.

152
00:11:46.440 --> 00:11:48.510
We have 4000 images.

153
00:11:48.510 --> 00:11:52.730
If we draw 40 at a time how many to how long would it take or how many.

154
00:11:52.810 --> 00:11:56.540
You know how many times how many iteration before you use up all the images.

155
00:11:56.540 --> 00:11:57.090
One hundred.

156
00:11:57.090 --> 00:11:57.880
Correct.

157
00:11:57.900 --> 00:12:02.420
That's where the hundreds steps comes in after one hundred steps.

158
00:12:02.430 --> 00:12:10.830
Meaning loops through every time we're drawing 40 then we have finished using all of the training data

159
00:12:11.160 --> 00:12:13.100
at least in the sample training data.

160
00:12:13.270 --> 00:12:17.410
Hence this will be count as one epoch.

161
00:12:17.430 --> 00:12:22.310
This is to let carers know how to actually count epoch and for the epochs.

162
00:12:22.320 --> 00:12:24.690
Is it called the epochs which is 30 here.

163
00:12:24.690 --> 00:12:31.440
Validation is could develop validate again which we created here and the validation steps is equal to

164
00:12:31.860 --> 00:12:33.100
50.

165
00:12:33.210 --> 00:12:33.530
All right.

166
00:12:33.540 --> 00:12:38.150
So this is the actual training.

167
00:12:38.310 --> 00:12:46.530
You notice that the so-called accuracy starts at 55 percent validation is higher and it ended around

168
00:12:46.530 --> 00:12:55.410
98 percent accuracy but validation basically stopped rising plateau around seventy seven to seventy

169
00:12:55.410 --> 00:12:57.050
nine percent.

170
00:12:57.130 --> 00:13:01.730
All right let me run through a few more lines of codes before we look at the result.

171
00:13:02.380 --> 00:13:08.400
Now start history is basically where we actually running this training we store into this variable call

172
00:13:08.430 --> 00:13:09.300
Hage.

173
00:13:09.300 --> 00:13:12.900
This is to allow us to extract a few important values.

174
00:13:12.900 --> 00:13:15.700
One is the accuracy of the training.

175
00:13:15.720 --> 00:13:22.320
The other one is the validation accuracy which is what this first two line is followed by the history

176
00:13:23.280 --> 00:13:27.030
of the loss on training loss and the validation loss.

177
00:13:27.030 --> 00:13:33.460
So we're storing all of these valuable variables so that we can actually plot it later.

178
00:13:33.460 --> 00:13:33.660
Right.

179
00:13:33.690 --> 00:13:42.620
So this line of code basically to allow us to actually draw the x axis the hypoxia basically is defined

180
00:13:42.620 --> 00:13:51.320
by range starting with 1 and the length of the HCC the length of the accuracy which is defined here.

181
00:13:51.320 --> 00:13:58.160
And so if we have run 30 epochs it means that we will have 30 accuracy values.

182
00:13:58.250 --> 00:14:03.860
So literally we are telling the epochs or story in the epochs there will be a range from one all the

183
00:14:03.860 --> 00:14:12.070
way to thirty thirty one thirty here in this case instead of twenty nine so we'd take the length which

184
00:14:12.070 --> 00:14:13.710
is 30 and then plus 1.

185
00:14:13.800 --> 00:14:15.440
Remember python.

186
00:14:15.600 --> 00:14:22.180
I want to generate this this range which is a list and will start with the last value of minus one.

187
00:14:22.210 --> 00:14:29.020
The last value here because it study 1 minus 1 meaning it will stop the number at 30 right we're plotting

188
00:14:29.020 --> 00:14:37.510
this coup using met plot lip plotting the epochs which is the x value followed by the accuracy and blue

189
00:14:37.510 --> 00:14:45.910
dots and we label this training accuracy where plotting the validation accuracy and the access to epochs

190
00:14:46.180 --> 00:14:53.140
the Y will be the validation accuracy and the line will be green and we call this tied to training and

191
00:14:53.140 --> 00:14:55.960
validation accuracy and then plot the legend as well.

192
00:14:55.990 --> 00:14:57.910
So this is the first chart here.

193
00:14:57.970 --> 00:15:04.480
The blue dot as defined here is the training accuracy as you can see the more times that it sees the

194
00:15:04.480 --> 00:15:09.880
data the accuracy improve as it goes but of course when you're actually training on your network or

195
00:15:09.880 --> 00:15:18.190
any machine learning for that matter you are interested in whether it is accurate out of sample in the

196
00:15:18.190 --> 00:15:20.020
test set.

197
00:15:20.020 --> 00:15:21.970
In this case we are not touching the test set.

198
00:15:21.970 --> 00:15:26.620
We just want to validate it before we move on to a test set.

199
00:15:26.620 --> 00:15:32.080
So for now because we're tuning our model so we're interested only to see the validation and you can

200
00:15:32.080 --> 00:15:36.120
see that the validation as I mentioned earlier the plateau.

201
00:15:36.350 --> 00:15:39.130
It is not rising any further.

202
00:15:39.130 --> 00:15:47.740
What that really means is that after about five epoch that's it our model has already learned all the

203
00:15:47.740 --> 00:15:54.280
characteristics or the capacity has already been reached in terms of learning the nuances of the training

204
00:15:54.280 --> 00:15:55.750
data.

205
00:15:55.750 --> 00:15:59.860
So after that anything beyond that is basically all fitting.

206
00:15:59.860 --> 00:16:00.280
All right.

207
00:16:00.280 --> 00:16:07.990
It's not able to predict the pictures as accurate I'll cite of sample using the validation data that

208
00:16:07.990 --> 00:16:09.390
we've created.

209
00:16:09.580 --> 00:16:13.770
The second picture is to plot the lost the first one is accuracy.

210
00:16:13.780 --> 00:16:19.000
The second one is lost again plotting training loss vs. validation loss.

211
00:16:19.090 --> 00:16:25.210
The blue dot will be our training loss the Green Line will be our validation lost.

212
00:16:25.230 --> 00:16:25.540
OK.

213
00:16:25.570 --> 00:16:27.240
So that's the second picture here.

214
00:16:27.250 --> 00:16:36.220
As you can see the vet within in the training lost it continued to drop but the validation loss drop

215
00:16:36.520 --> 00:16:40.500
until around 5th epoch and after that it just plateau.

216
00:16:40.510 --> 00:16:48.030
In fact the area started going up and the reason for that is very simple is because it's all fitting.

217
00:16:48.030 --> 00:16:49.070
That's one.

218
00:16:49.090 --> 00:16:51.470
And it's just not able to generalize.

219
00:16:51.460 --> 00:16:58.810
That's the second reason when it comes to data that has not seen before it's just not able to predict

220
00:16:58.940 --> 00:17:06.690
really is over fitting the training data that's really how you actually run all training on CNN.

221
00:17:06.690 --> 00:17:08.030
It's a very simple model.

222
00:17:08.040 --> 00:17:12.750
It's really quick and allows you to get up to speed very very quickly.

223
00:17:13.260 --> 00:17:19.780
Now one other thing though is that after you finish training you are happy with your model.

224
00:17:19.800 --> 00:17:20.400
What do you do.

225
00:17:20.400 --> 00:17:23.460
Do you actually have to run training every single time.

226
00:17:23.460 --> 00:17:26.450
The simple answer to that is no you don't.

227
00:17:26.460 --> 00:17:29.170
Then the next question is can I save my model.

228
00:17:29.310 --> 00:17:33.570
And I'm sure you know the answer by now is yes you can.

229
00:17:33.570 --> 00:17:36.980
And this is how Kerry's made it really simple.

230
00:17:37.320 --> 00:17:44.940
It's just model dot save within the bracket and a process fee you name you provide a name for your model

231
00:17:45.030 --> 00:17:52.560
we call it cards underscore and underscore dogs don't hedge five so that we can retrieve it later and

232
00:17:52.560 --> 00:17:58.890
start forecasting and infer from our picture whether it is a cat or dog.

233
00:17:59.190 --> 00:17:59.400
Right.

234
00:17:59.430 --> 00:18:06.620
So that's pretty much the end of this lesson on how to train your CNN provided a few more links there

235
00:18:06.630 --> 00:18:08.460
for you to actually get started.

236
00:18:08.520 --> 00:18:09.670
If you want more materials.

237
00:18:09.680 --> 00:18:15.630
Feel free to refer to those and if you can see that there's only a nice coat of cells a little bit more

238
00:18:15.630 --> 00:18:20.460
in terms of the number of line of code but you can see that once you actually play around with this

239
00:18:20.460 --> 00:18:26.430
a little bit more you will get comfortable with it and you realize that cross has made your life very

240
00:18:26.430 --> 00:18:27.720
very easy.

241
00:18:27.720 --> 00:18:28.880
With that I'm going to stop.

242
00:18:28.950 --> 00:18:30.270
Thank you once again for watching.
