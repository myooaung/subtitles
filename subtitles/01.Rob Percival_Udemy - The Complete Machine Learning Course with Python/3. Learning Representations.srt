1
00:00:00,880 --> 00:00:01,930
Welcome back.

2
00:00:02,060 --> 00:00:07,950
And the last Listen we talk about the difference between classical programming and machine learning.

3
00:00:08,080 --> 00:00:14,590
And we talked about the fact that the machine has this portion which it learns from the data without

4
00:00:14,590 --> 00:00:16,690
rules being provided to it.

5
00:00:16,690 --> 00:00:22,120
So in this lesson we're going to go into how does the machine learning algorithm actually learn how

6
00:00:22,120 --> 00:00:24,420
does it do the learning itself.

7
00:00:24,430 --> 00:00:28,580
So there are three basic ingredients that's that are needed.

8
00:00:28,600 --> 00:00:33,310
The first one is that you do provide you do need to provide training data.

9
00:00:33,310 --> 00:00:35,860
Now copious amount of data lots.

10
00:00:35,880 --> 00:00:42,460
In other words and you also have targeted or examples of expected output.

11
00:00:42,460 --> 00:00:46,810
I mentioned previously cards it could be dogs it could be pandas.

12
00:00:46,870 --> 00:00:55,150
Basically the idea here is really it has something to learn towards so-called goal that is actually

13
00:00:55,290 --> 00:01:01,850
blending towards a look go based learning so you provide the answer and you provide the raw data it

14
00:01:01,900 --> 00:01:09,070
learn a representation of it and in it's different from human from the machine learning algorithm point

15
00:01:09,070 --> 00:01:13,560
of view is Justice's statistical representation zero.

16
00:01:13,630 --> 00:01:21,280
And one's in other words the third ingredient is that is needed or you need to provide is what's called

17
00:01:21,310 --> 00:01:27,710
a performance measurement a book a way of measuring to check the accuracy of the model.

18
00:01:27,730 --> 00:01:35,410
Now this performance measurement or The Matrix provides the feedback to make the adjustment.

19
00:01:35,410 --> 00:01:39,450
Another word for the adjustment part really is actually the learning part.

20
00:01:40,120 --> 00:01:46,060
So you can think of it this way it's a little bit like a while like adults but most of the time we think

21
00:01:46,060 --> 00:01:53,800
of it as a young child learn is that you give them a picture of one and you ask them what this picture

22
00:01:53,800 --> 00:01:54,880
represent.

23
00:01:54,880 --> 00:01:57,350
If they say one they got it right.

24
00:01:57,470 --> 00:01:57,860
Okay.

25
00:01:57,870 --> 00:02:03,820
If they say two then they've got it wrong then you correct them and say the answer to that actually

26
00:02:03,820 --> 00:02:07,810
is one they'll learn to actually correct themselves.

27
00:02:08,110 --> 00:02:09,340
So what have you done.

28
00:02:09,520 --> 00:02:12,420
What you have done is that you provide some training data.

29
00:02:12,430 --> 00:02:19,690
Of course you initially trained them on the examples of digits 1 to 10 and then you give them the answer

30
00:02:19,720 --> 00:02:27,370
as you were teaching them 1 2 3 or the way to 10 and after that a way to measure the performance of

31
00:02:27,370 --> 00:02:32,650
course and the measure of performance is slightly different in the machine learning well is that it

32
00:02:32,650 --> 00:02:40,720
uses specific algorithm to tell and formed the software or the script that it is correct or incorrect

33
00:02:40,810 --> 00:02:46,990
but in the human world the parents or the teacher inform the child whether it is correct or incorrect

34
00:02:47,350 --> 00:02:52,430
based on the understanding and the knowledge of the teacher.

35
00:02:52,620 --> 00:03:02,250
So this feedback loops allow the learner to continue to learn and that's the key part of the ingredients

36
00:03:02,270 --> 00:03:09,750
that's needed to provide to him that any machine learning algorithm to learn from the data.

37
00:03:09,860 --> 00:03:14,650
Now this is from Charlotte Chollet is actually a Google researcher.

38
00:03:14,790 --> 00:03:22,880
He's the creator of a deep learning library called Kerry's hugely popular second most popular after

39
00:03:22,880 --> 00:03:33,860
tens of flow tens of law is provided or open source by Google and his employer and terrorists is another

40
00:03:33,920 --> 00:03:36,860
deep learning architecture.

41
00:03:36,860 --> 00:03:44,750
Or you can call it library if you like or to kid for you to actually write the algorithm to conduct

42
00:03:45,140 --> 00:03:53,560
deep learning now this is what a state machine learning model transforms its input data into meaningful

43
00:03:53,590 --> 00:04:01,510
outputs a process that is learned from exposure to known examples of inputs and outputs.

44
00:04:01,510 --> 00:04:07,770
Therefore the central problem in machine learning and deep learning is to meaningfully transform data.

45
00:04:08,380 --> 00:04:15,820
Another was to learn useful representations of the input data at hand representations that get us closer

46
00:04:15,820 --> 00:04:17,520
to the expected output.

47
00:04:18,930 --> 00:04:27,420
So the idea really is that you are learning from the data input and also the output and continuously

48
00:04:27,420 --> 00:04:34,520
learn from the mistakes and you can generalize with examples that you have not seen before.

49
00:04:34,560 --> 00:04:40,650
Let me give you some example of what it looks like to look at representations.

50
00:04:40,650 --> 00:04:42,900
I'm going to give you two example.

51
00:04:42,900 --> 00:04:52,260
One example is one of regression and another example is one of classification regression for some of

52
00:04:52,260 --> 00:04:52,610
you.

53
00:04:52,620 --> 00:05:00,900
You would have been exposed to it in either high school or a level or university's undergraduate courses.

54
00:05:00,900 --> 00:05:02,880
It is populates frequently

55
00:05:05,600 --> 00:05:12,950
covered in graduate courses and when you're working with regression you are basically working with numerical

56
00:05:12,950 --> 00:05:20,350
data whereas if you are dealing with classical classification problems you are dealing with categorical.

57
00:05:20,350 --> 00:05:28,550
It could be binary 0 and 1 yes or no or categorical it could be in the forms or different country names

58
00:05:29,330 --> 00:05:32,240
UK you as China Japan.

59
00:05:32,250 --> 00:05:39,770
That's categorical it's not continuous in the form of a real no other example or categorical.

60
00:05:39,770 --> 00:05:45,340
It could be the letters A B C D or the way to disease or death situation.

61
00:05:45,350 --> 00:05:48,350
You have 26 categories.

62
00:05:48,350 --> 00:05:58,100
So let's look at the example of regression now if you just ignore that line for now if you are given

63
00:05:58,160 --> 00:06:03,140
a data that looks like there's many basically a whole bunch of dots.

64
00:06:03,770 --> 00:06:07,920
You are asked to use x to predict Y.

65
00:06:07,940 --> 00:06:10,010
The question is how would you do that.

66
00:06:10,250 --> 00:06:18,350
Now if you look at it without that line there you probably will have a general heuristic understanding

67
00:06:18,420 --> 00:06:26,750
or an appreciation that as the value X goes up the value Y goes up.

68
00:06:26,750 --> 00:06:34,640
Now where by in the situation of regression the line of best fit which is that solid blue line data

69
00:06:34,850 --> 00:06:41,140
is drawn to represent the underlying relationship between X and Y.

70
00:06:41,150 --> 00:06:43,120
Now it's not going to be perfect.

71
00:06:43,130 --> 00:06:47,580
The reason is not gonna be perfect is because number one there's a lot of noise.

72
00:06:47,990 --> 00:06:50,390
So that's why there is actually a line there.

73
00:06:50,390 --> 00:06:53,510
This is what script let's call linear regression.

74
00:06:53,960 --> 00:07:02,630
And if you remove all the dots if you are given any number or sample of angst it could be also a new

75
00:07:02,630 --> 00:07:10,670
data then it will be able to predict what y is with some certain level of confidence fairly accurate

76
00:07:11,180 --> 00:07:14,160
because that line is the line of best fit.

77
00:07:14,330 --> 00:07:20,880
It is learned by using what's called sums of squares of errors.

78
00:07:20,900 --> 00:07:23,930
For now we don't need to dwell too into that.

79
00:07:23,960 --> 00:07:31,820
The basic idea is that it's trying to minimize the errors so you can just quickly very quickly appreciate

80
00:07:31,820 --> 00:07:39,260
and understand that that line is line of best fit it is drawn there because it minimize the errors relative

81
00:07:39,260 --> 00:07:43,020
to all the other lines that you can draw.

82
00:07:43,760 --> 00:07:44,030
Right.

83
00:07:44,060 --> 00:07:46,860
So this really an example of representations.

84
00:07:46,970 --> 00:07:50,540
This is in this case this is a linear regression.

85
00:07:50,600 --> 00:07:55,280
So what about an example of classification.

86
00:07:55,280 --> 00:08:03,110
Now this is an example of deep learning CNN has standards for convolution or neural network which is

87
00:08:03,110 --> 00:08:05,410
a really fancy term.

88
00:08:05,420 --> 00:08:09,230
In the real world an element is actually computer vision.

89
00:08:09,230 --> 00:08:11,420
How computer sees the world.

90
00:08:11,810 --> 00:08:15,410
Now specifically this picture it's a layer of five.

91
00:08:15,650 --> 00:08:18,680
Okay I know that we haven't talk about what layers are for now.

92
00:08:18,680 --> 00:08:20,230
Just take my word for it.

93
00:08:20,300 --> 00:08:28,070
This is how the computers see the world in layer 5 of the deep learning neural network or deep neural

94
00:08:28,070 --> 00:08:37,170
network you can see that is just patterns you can't exactly decipher what it is but that's basically

95
00:08:37,410 --> 00:08:44,430
how the computer designed for the world and how to decipher the actual imagery is that is actually presented

96
00:08:44,430 --> 00:08:45,870
to it to learn.

97
00:08:46,200 --> 00:08:52,470
You can just imagine that if there are many layers involved here it's basically learning layer upon

98
00:08:52,500 --> 00:09:00,270
layer years different representation of the world the first layer could be just straight lines corners

99
00:09:01,280 --> 00:09:08,950
the next could be diagonals lines and the third layer could be circle the 4th and 5th and on and on

100
00:09:08,970 --> 00:09:15,990
start to actually decipher and learn more complex structures and patterns such as waves as you can see

101
00:09:15,990 --> 00:09:17,670
here there are a whole lot of.

102
00:09:18,330 --> 00:09:23,190
There are no words to describe this pattern some of them looks like feathers some of them look like

103
00:09:23,190 --> 00:09:27,310
the picture of the ocean some of them just looks like petty few.

104
00:09:27,390 --> 00:09:33,030
So there's really a lot of representation there's no way to tell what these are but this is an example

105
00:09:33,030 --> 00:09:38,340
of the features that they extracted and a representation of the world.

106
00:09:39,690 --> 00:09:42,540
So for now I'm going to stop here.

107
00:09:42,540 --> 00:09:49,470
So in this lesson what you've learned really is how this computer sees the world is an example of learning

108
00:09:49,470 --> 00:09:51,440
representations from data.

109
00:09:51,600 --> 00:09:56,220
Not that we're going to be able to understand it from a human perspective but this is how it helps the

110
00:09:56,250 --> 00:09:59,340
computer to actually make sense of the world.

111
00:09:59,640 --> 00:10:03,400
Whereas the picture before is for regression for the.

112
00:10:03,410 --> 00:10:11,030
For this computer vision it's little bit more complicated but the purpose ultimately at the end of the

113
00:10:11,040 --> 00:10:19,470
day is for us from the perspective of this lesson is to understand that computer sees it from its statistical

114
00:10:19,530 --> 00:10:21,150
representation patterns.

115
00:10:21,640 --> 00:10:21,960
OK.

116
00:10:21,960 --> 00:10:24,780
With that I'm going to stop the next lesson.

117
00:10:24,780 --> 00:10:31,000
We're going to go into what is deep learning and look at a little bit of the structure of.

118
00:10:31,110 --> 00:10:34,760
What does it mean by deep learning thank you once again.
