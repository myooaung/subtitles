1
00:00:05,680 --> 00:00:12,970
To placement groups in a way that you can control how IWC deploys your ISA to instances and places them

2
00:00:13,300 --> 00:00:17,620
within your availability zones or across availability zones.

3
00:00:18,130 --> 00:00:23,110
Now the best way to get started with this is to look at the different options we have for how we can

4
00:00:23,110 --> 00:00:24,310
control that placement.

5
00:00:25,150 --> 00:00:28,960
Now, the first type of placement group is called a cluster placement group.

6
00:00:29,410 --> 00:00:34,630
Now this PAX instance is within and availability zone closely together.

7
00:00:35,080 --> 00:00:40,870
Now, when I say closely within an availability zone, of course, and availability zone is one or more

8
00:00:40,870 --> 00:00:41,710
data centers.

9
00:00:42,220 --> 00:00:48,340
Now, if we want to achieve really low latency better than you can, if your instances were perhaps

10
00:00:48,460 --> 00:00:54,400
randomly deployed within that easy, then we might want to make sure that they're really close, like

11
00:00:54,400 --> 00:00:57,220
they're in the same rack or they're in adjacent racks.

12
00:00:57,460 --> 00:01:00,580
So there's a very short physical distance between them.

13
00:01:00,940 --> 00:01:03,760
And that will mean that we can achieve even lower latency.

14
00:01:04,210 --> 00:01:06,820
So that's what a cluster placement group aims to do.

15
00:01:07,120 --> 00:01:11,290
This enables your workloads to achieve very low latency.

16
00:01:11,680 --> 00:01:17,140
And this is really good for tightly coupled workloads where you have nodes, no communication.

17
00:01:17,290 --> 00:01:19,910
And that's typical of HPC applications.

18
00:01:19,930 --> 00:01:22,060
High performance computing applications.

19
00:01:22,510 --> 00:01:28,570
So I've highlighted a few words there which are really useful to remember because these can come up

20
00:01:28,570 --> 00:01:29,590
in exam questions.

21
00:01:30,070 --> 00:01:32,590
The next type is a partitioned placement group.

22
00:01:32,890 --> 00:01:39,820
This spreads your instances across logical partitions so that the groups of instances in one partition

23
00:01:39,970 --> 00:01:44,920
do not share the underlying hardware with groups of instances in another partition.

24
00:01:45,340 --> 00:01:51,580
So this is where you want to ensure that if one of these partitions within an availability zone or across

25
00:01:51,580 --> 00:01:57,760
availability zones fails, then you still have a group of instances that are in another partition,

26
00:01:57,940 --> 00:01:59,260
which should still be running.

27
00:01:59,620 --> 00:02:06,190
This strategy is often used for distributed and replicated workloads, and examples are Hadoop, Cassandra

28
00:02:06,190 --> 00:02:07,030
and Kafka.

29
00:02:07,450 --> 00:02:14,500
So by distributed and replicated, we mean that we have all nodes of our application in different places

30
00:02:14,860 --> 00:02:17,380
and we might be replicating data between them.

31
00:02:17,860 --> 00:02:23,950
So each cluster of those nodes may have the same or a portion of the overall data.

32
00:02:24,580 --> 00:02:31,360
And if we lose one of those clusters, so a partition fails in the data center, we still have another

33
00:02:31,360 --> 00:02:33,310
copy or multiple other copies.

34
00:02:33,580 --> 00:02:39,490
The last type of placement group we have is a spread placement group, and here us is making sure that

35
00:02:39,490 --> 00:02:43,720
every instance of your application is on different underlying hardware.

36
00:02:44,230 --> 00:02:46,900
Now, to make this easier, we're going to visualize it now.

37
00:02:47,530 --> 00:02:49,840
So firstly, we have our cluster placement group.

38
00:02:50,140 --> 00:02:55,360
As you can see, we only have one availability zone here, and we've created the cluster placement group

39
00:02:55,630 --> 00:03:01,150
and our nodes of that application are all very close together, which means that when they're trying

40
00:03:01,150 --> 00:03:06,040
to send communications to each other, they can do so with extremely low latency.

41
00:03:06,340 --> 00:03:11,560
So we have low network latency and high free for inter node communications.

42
00:03:12,340 --> 00:03:14,530
Next, we have the Partition Placement Group.

43
00:03:14,950 --> 00:03:20,950
As you can see, the partitions can be within an availability zone or across availability zones, and

44
00:03:21,000 --> 00:03:26,380
IWC is going to make sure that these partitions on separate underlying hardware.

45
00:03:26,800 --> 00:03:33,010
So if the underlying hardware of one partition fails, then the other politicians should not be affected.

46
00:03:33,250 --> 00:03:37,540
In other words, each of these partitions will be in a separate WC rack.

47
00:03:37,960 --> 00:03:43,270
Now, your partitions can be in multiple places up to seven per availability zone.

48
00:03:43,480 --> 00:03:50,290
Lastly, we have a spread placement group and here each of all instances is in a separate WC rack.

49
00:03:50,470 --> 00:03:56,260
So the underlying hardware that that instance is running on is in a completely separate rack, and therefore

50
00:03:56,260 --> 00:04:00,370
the failure of that rack is not going to affect any of the other instances.

51
00:04:00,670 --> 00:04:05,560
Now lastly, let's look at a few use cases, so we understand how we might use this in the real world.

52
00:04:06,010 --> 00:04:10,720
So we have cluster placement groups, partition and then spread placement groups, and let's look at

53
00:04:10,720 --> 00:04:14,890
some use cases and match them to these particular types of placement group.

54
00:04:15,520 --> 00:04:21,280
So firstly, we have an application that is tightly coupled and it requires very low latency and high

55
00:04:21,280 --> 00:04:23,800
network throughput between instances.

56
00:04:24,250 --> 00:04:27,370
In that case, of course, we'd want to use a cluster placement group.

57
00:04:28,090 --> 00:04:34,660
Next, we have a distributed and replicated NoSQL database that requires separate hardware for node

58
00:04:34,660 --> 00:04:35,230
groups.

59
00:04:35,770 --> 00:04:39,100
In that case, that's going to be a partition placement group.

60
00:04:39,880 --> 00:04:44,890
And then lastly, we have a small number of critical instances that must be kept separate from each

61
00:04:44,890 --> 00:04:45,160
other.

62
00:04:45,640 --> 00:04:48,460
Well, then you would, of course, use a spread placement group.

63
00:04:48,790 --> 00:04:50,740
So that's the theory behind placement groups.

64
00:04:50,980 --> 00:04:55,510
Actually deploying a placement group is very simple in the easy to management console.

65
00:04:55,630 --> 00:05:00,340
When you're configuring an instance that you're launching, you choose to either add it to an existing

66
00:05:00,340 --> 00:05:02,570
placement group or create a new one.

67
00:05:02,800 --> 00:05:04,600
If you create a new one, you give it a name.

68
00:05:04,890 --> 00:05:07,830
Choose the type of placement group, and that's all you need to do.

