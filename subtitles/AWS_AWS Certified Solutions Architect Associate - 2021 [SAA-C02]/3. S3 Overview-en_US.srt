1
00:00:02,220 --> 00:00:02,640
Hi guys.

2
00:00:02,640 --> 00:00:09,180
We're gonna start this section on Amazon S3 with an overview of what the service is so Amazon S3

3
00:00:09,180 --> 00:00:16,920
is the simple storage service and it's an object storage system that is accessed over the Internet through

4
00:00:17,010 --> 00:00:19,320
a public endpoint.

5
00:00:19,440 --> 00:00:27,690
Now S3 is an object storage system and that means you upload your files as objects and objects

6
00:00:27,690 --> 00:00:33,170
are stored in buckets and a bucket is just essentially a container for objects.

7
00:00:33,180 --> 00:00:39,690
Now it's a flat namespace but you can mimic what you would typically think of as folders in a file system

8
00:00:40,170 --> 00:00:49,220
by creating folders within the bucket which essentially just changes the URL so it's a public service.

9
00:00:49,360 --> 00:00:56,890
You can access over the public internet and if you have two instances they will also go out via an Internet

10
00:00:56,890 --> 00:01:01,500
gateway to the public end point for Amazon S3.

11
00:01:01,540 --> 00:01:05,850
The exception to that is if you configure S3 Gateway endpoints.

12
00:01:06,070 --> 00:01:13,210
If you remember from our VPC section we talked about VPC endpoints and S3 Gateway endpoint is one of

13
00:01:13,210 --> 00:01:20,620
those types of endpoint where you can create an entry in a route table to an interface which takes you

14
00:01:20,620 --> 00:01:24,250
out to Amazon S3 over a private connection.

15
00:01:24,250 --> 00:01:30,370
So that's the other way that you can access S3 which is useful for if you want to protect your

16
00:01:30,370 --> 00:01:36,220
traffic from the public Internet or if you want instances in subnets which don't have Internet access

17
00:01:36,220 --> 00:01:41,940
to be able to access S3 as you know you can do that for other services as well.

18
00:01:42,190 --> 00:01:49,460
So back over two buckets there's a couple of different types of URL that you can use to access your

19
00:01:49,460 --> 00:01:50,170
buckets.

20
00:01:50,390 --> 00:01:58,340
So the first one here is known as a virtual hosted style you are ill in which you actually have the

21
00:01:58,340 --> 00:02:00,950
bucket as part of the URL.

22
00:02:00,950 --> 00:02:06,200
Now there's some slight variances in the year or else depending on the region so you should look up

23
00:02:07,320 --> 00:02:13,800
this on the Amazon Web site to identify a couple of variations that you need to know in case you get

24
00:02:13,800 --> 00:02:16,800
some kind of tricky question on the exam.

25
00:02:16,800 --> 00:02:24,210
Now the other format is known as a path style your URL which instead it starts with S3 and then you

26
00:02:24,210 --> 00:02:25,560
get the region.

27
00:02:25,680 --> 00:02:27,380
You have the region in both your URLs.

28
00:02:27,540 --> 00:02:32,130
Here it's at the beginning and then you have slash and your bucket name and then your objects names

29
00:02:32,130 --> 00:02:34,640
will come after that in the first type of your URL.

30
00:02:34,700 --> 00:02:39,320
The buckets at the beginning but then you'd still have slash in the object name at the end.

31
00:02:40,690 --> 00:02:43,450
So an object is made up of a few attributes.

32
00:02:43,500 --> 00:02:46,290
There's the key which is the name that you assign to the object.

33
00:02:46,290 --> 00:02:53,830
The version I.D. a value which is the content that you're actually storing some metadata some resources

34
00:02:54,340 --> 00:03:00,940
and access control information and we're going to go over each of these in more detail later within

35
00:03:00,940 --> 00:03:03,160
this section.

36
00:03:03,190 --> 00:03:08,730
So for now I just want to head over to the console and we're gonna have a quick overview of S3.

37
00:03:08,950 --> 00:03:15,850
So I've recently visited it so I just selected S3 from my list there and I already have one bucket

38
00:03:15,850 --> 00:03:16,150
here.

39
00:03:16,150 --> 00:03:22,120
So if I head into that bucket we can see some of the objects that we've previously uploaded and we can

40
00:03:22,120 --> 00:03:26,770
easily just go in and choose another file to upload.

41
00:03:26,770 --> 00:03:32,170
We can also see the properties where you've got versioning and access logging.

42
00:03:32,170 --> 00:03:38,340
You can create a static website out of S3 and you can configure logging and encryption and we're going

43
00:03:38,340 --> 00:03:41,920
to go over all of this stuff within this section.

44
00:03:41,950 --> 00:03:44,100
You can also prevent objects from being deleted.

45
00:03:44,110 --> 00:03:50,890
You can configure tags, you can enable transfer acceleration for faster uploads, and then you can configure

46
00:03:50,890 --> 00:03:58,780
event notifications, and you can even configure that the person who requests access to an object actually

47
00:03:58,780 --> 00:04:04,580
pays for that request.

48
00:04:04,620 --> 00:04:11,340
We then have permissions and in here we can see that there's an option to block public access

49
00:04:11,990 --> 00:04:20,190
and then there's the access control list bucket policies that you can configure and then cross origin

50
00:04:20,190 --> 00:04:22,420
resource sharing configurations.

51
00:04:22,500 --> 00:04:25,160
And again we're going to go over all this within this section.

52
00:04:25,170 --> 00:04:30,570
I just wanted to show you around a little bit before we get a bit deeper into S3.

53
00:04:30,750 --> 00:04:35,980
So backup in the console here you can just create new buckets.

54
00:04:35,990 --> 00:04:43,340
Now remember that S3 is a global namespace and this is somewhat something which people often get confused

55
00:04:43,340 --> 00:04:43,670
about.

56
00:04:43,670 --> 00:04:48,470
So it's a global service which means you see global up here in the top right hand corner.

57
00:04:48,470 --> 00:04:52,640
You don't see a region and you can't select a region.

58
00:04:52,640 --> 00:04:56,990
However when you come to create a bucket you'll notice that there is an option for a region.

59
00:04:57,250 --> 00:05:04,070
And that's because your data will be stored within a region so the namespace is global.

60
00:05:04,130 --> 00:05:09,200
So if I try to type a bucket name I know that that bucket is likely to.

61
00:05:09,200 --> 00:05:13,220
So if I just try to call it you know bucket1 and click next.

62
00:05:13,280 --> 00:05:17,510
There's no chance that I'm going to get that bucket and that's not just because someone's got it here

63
00:05:17,510 --> 00:05:17,990
in Sydney.

64
00:05:17,990 --> 00:05:21,260
That means that someone could have that name somewhere in the world.

65
00:05:21,560 --> 00:05:27,920
So it has to be you the name has to be unique globally but the data is stored within the region that

66
00:05:27,920 --> 00:05:28,930
you specify.

67
00:05:29,480 --> 00:05:37,220
So I could then try and find a bucket name for instance DCT bucket 29 saying let's see if that's available

68
00:05:37,700 --> 00:05:44,750
and that's okay so I can create a bucket and you can configure these various settings and we're just

69
00:05:44,750 --> 00:05:48,860
gonna be free of these for now and create the bucket.

70
00:05:48,860 --> 00:05:56,190
And it's as simple as that and then you can go into your bucket and upload so to upload an object you

71
00:05:56,190 --> 00:06:04,460
just click on Add files and then you can choose your file and click next to go through and see some

72
00:06:04,460 --> 00:06:09,730
of the options so you can specify permissions access for other accounts.

73
00:06:09,740 --> 00:06:15,200
Again all of this is going to be covered in detail later on and then you get the storage classes so

74
00:06:15,200 --> 00:06:21,170
you can see that there are several different storage classes available here and it's a good thing to

75
00:06:21,170 --> 00:06:29,420
go and click on the learn more link and if you scroll a bit further down this page we get to see all

76
00:06:29,420 --> 00:06:31,210
these different storage classes.

77
00:06:31,430 --> 00:06:37,140
So in this chart you can see the durability.

78
00:06:37,140 --> 00:06:44,190
So this is really the likelihood that an object is going to become corrupted or lost.

79
00:06:44,190 --> 00:06:49,270
So very very high durability This is 11 nines durability here.

80
00:06:49,410 --> 00:06:51,210
Then you've got the availability.

81
00:06:51,210 --> 00:06:59,640
So this really corresponds to the uptime of the system in other words access to your objects and then

82
00:06:59,700 --> 00:07:06,690
you can see the number of availability zones which your data is replicated across so your data is replicated

83
00:07:06,690 --> 00:07:14,280
within Amazon S3 into multiple facilities within a region and in this case three facilities for the

84
00:07:14,280 --> 00:07:15,630
standard storage class.

85
00:07:16,080 --> 00:07:21,900
And then you can see in some cases there's a minimum storage duration a minimum billable object's size

86
00:07:22,650 --> 00:07:24,240
and other attributes.

87
00:07:24,240 --> 00:07:26,580
So have a look for these classes.

88
00:07:26,670 --> 00:07:32,880
This seems to be more than all the time Amazon is introducing different options for different use cases

89
00:07:33,300 --> 00:07:36,360
and you can see the use cases under designed for here.

90
00:07:36,540 --> 00:07:43,020
So there's obviously the standard here which if you are frequently accessing data may work out well

91
00:07:44,310 --> 00:07:50,610
if you want to lower costs then you might go to infinite frequently accessed which then means that you

92
00:07:50,610 --> 00:07:57,240
get slightly less availability but for a slightly lower cost and then there's some more options there

93
00:07:57,240 --> 00:08:03,210
are even going down to where you only have one availability zone and intelligent tiering is interesting

94
00:08:03,210 --> 00:08:07,100
because this is where you don't know the use cases for your data.

95
00:08:07,110 --> 00:08:14,900
So it means that it's going to move it really between different tiers and so you're going to benefit

96
00:08:14,900 --> 00:08:21,300
from different tiers of storage depending on how you start accessing that data and that might change

97
00:08:21,300 --> 00:08:22,600
over time.

98
00:08:22,770 --> 00:08:29,160
Then further down we have glacier and deep archive and deep archive is really what glacier used to be

99
00:08:29,160 --> 00:08:36,630
where you could only access the data in it within a treat with a retrieval time of about 12 hours whereas

100
00:08:36,630 --> 00:08:41,160
now you can actually access it much more quickly but you pay a bit more so.

101
00:08:41,370 --> 00:08:47,380
Think of glacier as the archive service and will cover in more detail later in the section.

102
00:08:48,630 --> 00:08:54,360
And then the last one here which is even gone to not recommended sign on it is the reduced redundancy

103
00:08:54,360 --> 00:08:55,260
storage.

104
00:08:55,470 --> 00:09:03,390
And this has sort of lowered your ability as you can see than any of the others and it looks like that

105
00:09:03,390 --> 00:09:04,790
sort of phasing that one out

106
00:09:08,280 --> 00:09:09,870
so back in the console.

107
00:09:10,020 --> 00:09:16,650
Once you've configured all these settings you can then just go down you can choose encryption you can

108
00:09:16,650 --> 00:09:23,700
select you can add metadata to this object so you can say that's going to expire into certain certain

109
00:09:23,700 --> 00:09:24,970
timeframe.

110
00:09:25,110 --> 00:09:27,730
You can put content type in there.

111
00:09:28,170 --> 00:09:34,820
You can add tags so then you can just click upload and that will upload your object

112
00:09:39,150 --> 00:09:43,710
so another way that you might want to access S3 is via the command line.

113
00:09:43,920 --> 00:09:55,010
And if you don't have the fly installed on your machine you can just go to search for a W.S. Klein install

114
00:09:57,150 --> 00:10:02,550
and I think that should bring up the link so installing the AWS CLI so I going to 

115
00:10:02,550 --> 00:10:04,320
follow the procedures for Mac.

116
00:10:04,380 --> 00:10:09,660
You might be on Windows or Linux so just go through and install the client.

117
00:10:09,870 --> 00:10:16,560
And once you've done that we can go over to a command prompt and we can actually run the AWS CLI tools.

118
00:10:16,920 --> 00:10:24,140
So if you if you just run aws it will tell you that you need to specify some some more information.

119
00:10:24,300 --> 00:10:33,360
You can do aws help and it will list lots of the come up come online options that you can use

120
00:10:38,840 --> 00:10:43,510
and then you can do aws S3 help and do the same.

121
00:10:43,520 --> 00:10:49,160
And we can starts going through the help file and seeing the options that are available to us so we

122
00:10:49,160 --> 00:10:54,050
can see available Command said the cp for copy, ls for list and so on.

123
00:10:54,080 --> 00:10:59,540
So you've got all these different options and I'll just hit you to get out of there and what I want

124
00:10:59,530 --> 00:11:04,690
to do now is just list the files in my bucket naturally before I do that.

125
00:11:04,730 --> 00:11:09,650
I just want to remind you that if you have just set up your command line you're going to have to run

126
00:11:09,740 --> 00:11:11,650
aws configure.

127
00:11:11,920 --> 00:11:14,700
So this is where and we've done this earlier in the course.

128
00:11:14,700 --> 00:11:20,330
You remember you ran aws configure you need to put in your access key I.D. your secret access

129
00:11:20,330 --> 00:11:25,310
key and then even you can specify your region that's optional.

130
00:11:26,120 --> 00:11:31,190
I'm just gonna come online out of that because I've already configured mine so we can now run AWS

131
00:11:31,190 --> 00:11:39,300
s3 la and we'll see our buckets and then if I want to see inside the bucket I can do a

132
00:11:39,350 --> 00:11:49,270
aws s3 ls and then I do s3:// and the bucket name and now we can see the objects

133
00:11:49,270 --> 00:11:57,280
in the bucket and if we want to copy something into the bucket so I've got a file called cookbook on

134
00:11:57,280 --> 00:12:04,170
my machine here and I just want to copy that up into S3 and let's put it in our new bucket

135
00:12:14,840 --> 00:12:24,250
so this is a maybe a 30 MB file it's taking a few seconds to copy that one up and we can see some

136
00:12:24,260 --> 00:12:25,490
status information

137
00:12:30,760 --> 00:12:37,960
so the files are loaded and if we now do an aws s3 ls and I'm gonna put in the name the bucket

138
00:12:43,280 --> 00:12:48,710
now we can see we've got the cookbook file and if we want to we can quite easily just remove that file

139
00:13:02,470 --> 00:13:08,210
and if we want less command again now it's gone so that's it guys for the overview.

140
00:13:08,210 --> 00:13:13,250
I just wanted to show you around S3 and we're going to go into lots more detail and lots of the

141
00:13:13,250 --> 00:13:17,050
options you saw in the console there and more throughout the rest of this section.

