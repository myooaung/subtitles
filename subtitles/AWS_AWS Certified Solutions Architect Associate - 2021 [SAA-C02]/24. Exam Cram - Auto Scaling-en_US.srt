1
00:00:02,480 --> 00:00:08,570
So moving on to auto scaling, auto scaling dynamically and automatically ensures the correct number of

2
00:00:08,660 --> 00:00:10,930
instances for your application.

3
00:00:11,000 --> 00:00:15,260
And it does so through what are called auto scaling groups so you create a collection of EC2

4
00:00:15,260 --> 00:00:22,070
instances in an auto scaling group and it automatically horizontally scales your instances, launches

5
00:00:22,160 --> 00:00:29,720
and terminates instances that's scaling out launching, and scaling in terminating. Auto scaling is triggered

6
00:00:29,720 --> 00:00:33,800
by events and performance scaling actions.

7
00:00:33,800 --> 00:00:39,530
It's a region specific service and it can span multiple Availability Zones within the region.

8
00:00:39,530 --> 00:00:41,420
There's no cost to using auto scaling.

9
00:00:41,420 --> 00:00:47,610
You just pay for whatever EC2 instances get provisioned. You can attach your ALBs to your ASGs.

10
00:00:47,730 --> 00:00:54,060
You can attach target groups to your ASG and that means you can include instances behind an ALB.

11
00:00:54,080 --> 00:00:56,540
and also in an NLB as well.

12
00:00:56,540 --> 00:01:00,040
The ELBs have to be in the same region as the auto skaling groups.

13
00:01:00,050 --> 00:01:06,980
The launch configuration is the template that you use to create new instances so it defines the instance

14
00:01:06,980 --> 00:01:13,040
family and type the AMI to use, the key pair, the security groups to use when an instance is launched

15
00:01:13,160 --> 00:01:14,390
from auto scaling.

16
00:01:14,390 --> 00:01:17,570
You can't edit a launch configuration.

17
00:01:17,570 --> 00:01:19,170
Definitely an exam question.

18
00:01:19,250 --> 00:01:24,500
Just watch out for where you need to make some kind of modification to the instances in your auto scaling

19
00:01:24,500 --> 00:01:24,980
group.

20
00:01:25,040 --> 00:01:27,830
And remember you can't go in and change the launch configuration.

21
00:01:27,830 --> 00:01:29,290
You've got to create a new one.

22
00:01:29,300 --> 00:01:33,840
You can also use your launch configuration with multiple auto scaling groups.

23
00:01:33,860 --> 00:01:40,670
Now these are the scaling options so you have maintain you have manual scheduled and dynamic the maintain

24
00:01:40,790 --> 00:01:43,420
ensures the required number of instances of running.

25
00:01:43,490 --> 00:01:47,750
So you might say I want four instances to be running at all times and it would just make sure that

26
00:01:47,750 --> 00:01:49,580
four instances are running.

27
00:01:49,580 --> 00:01:56,600
You then have manual where you can just manually change the desired capacity, scheduled adjusts the amount

28
00:01:56,600 --> 00:01:58,970
of instances for specific dates or times.

29
00:01:58,980 --> 00:02:05,420
So watch out for exam questions where they say for instance an organization has noticed that when people

30
00:02:05,420 --> 00:02:08,660
log on at 9:00 in the morning or the system slow down.

31
00:02:08,660 --> 00:02:12,200
Well you can then schedule that just before 9:00.

32
00:02:12,200 --> 00:02:18,260
You can boot up or launch a series of EC2 instances to make sure that the load is catered for in

33
00:02:18,260 --> 00:02:23,030
that busy period at the beginning of the day and then terminate them later in the day, and dynamic is

34
00:02:23,030 --> 00:02:25,050
where it dynamically responds.

35
00:02:25,220 --> 00:02:29,170
So there can be a bit of a lag which is why for instance you might want to use a scheduled.

36
00:02:29,180 --> 00:02:34,250
In that use case I just mentioned because with the dynamic it will only respond when the systems are

37
00:02:34,280 --> 00:02:40,630
already slowing down and a threshold perhaps to see utilization has reached a certain threshold.

38
00:02:40,640 --> 00:02:46,460
We then have the scaling types that you associate with a dynamic scaling policies so you have target

39
00:02:46,460 --> 00:02:47,390
tracking.

40
00:02:47,390 --> 00:02:55,460
In this case it's where you want to keep your CPU usage or your memory usage or your network usage at

41
00:02:55,460 --> 00:02:56,600
a specific level.

42
00:02:56,630 --> 00:03:01,430
So you say well I would like to see that my instances are being used properly so I want to make sure

43
00:03:01,430 --> 00:03:08,720
that 70 percent CPU across all my instances and so a target tracking will try and keep that utilization

44
00:03:08,720 --> 00:03:09,840
at that level.

45
00:03:10,130 --> 00:03:17,350
Simple scaling is more where it adjusts to a specific event that happens so you reach a certain threshold.

46
00:03:17,450 --> 00:03:23,810
The CPU hits 80 percent right now launch a new instance when it drops down below a certain percentage

47
00:03:23,810 --> 00:03:27,430
in the in the aggregate usage of your EC2 instances.

48
00:03:27,480 --> 00:03:35,180
See then it might terminate an instance and the step scaling policy can make different adjustments

49
00:03:35,750 --> 00:03:37,900
based on the size of the alarm breach.

50
00:03:37,910 --> 00:03:44,060
You can also scale based on the number of messages in a simple queue service (SQS) queue.

51
00:03:44,150 --> 00:03:49,820
Now this is something that can come up in an exam question for the SAA-C02 and what you do actually

52
00:03:49,820 --> 00:03:55,790
to configure this is you create a custom metric that's sent to cloudwatch that measures the number

53
00:03:55,790 --> 00:03:58,610
of messages in the queue per EC2 instance.

54
00:03:58,610 --> 00:04:03,950
So you say if a certain number of messages are in the queue and you kind of divide that by the number

55
00:04:03,950 --> 00:04:08,780
of instances you've got available then you know that you can work out a kind of threshold which is a

56
00:04:08,780 --> 00:04:14,600
level at which you feel you need to launch an additional instance to handle the amount of messages in

57
00:04:14,600 --> 00:04:20,840
that queue and you do that for a target tracking policy that scales based on that custom metric.

58
00:04:20,870 --> 00:04:26,570
So for instance AWS recommend that you can create a custom metric called a backlog per instance and

59
00:04:26,570 --> 00:04:31,610
that tracks not just the number of messages in the queue but the number available for retrieval.

60
00:04:31,640 --> 00:04:36,980
The actual metric that you can base this off is SQS metric approximate number of messages.

61
00:04:36,980 --> 00:04:42,050
So the termination policies these are the policies that control how your instance is terminated.

62
00:04:42,050 --> 00:04:46,970
So which instances are terminated first when a scaling event occurs.

63
00:04:47,060 --> 00:04:53,120
There is a default policy and their options are configuring your own customized termination policies.

64
00:04:53,120 --> 00:04:59,090
The default policies designed to help ensure the instances span the availability zones for HA and

65
00:04:59,090 --> 00:05:00,850
it's kept very generic and flexible.

66
00:05:00,860 --> 00:05:08,370
Now what do you just look on the AWS Web site search for EC2 auto scaling termination policy and

67
00:05:08,380 --> 00:05:14,380
just try and understand the logic behind the default termination policy and what the other termination

68
00:05:14,380 --> 00:05:19,540
policies are that are available with easy to auto scaling. You can also define instance protection and

69
00:05:19,540 --> 00:05:26,380
that stops auto scaling from scaling in and terminating specific instances. Auto scaling performs rebalancing

70
00:05:26,530 --> 00:05:31,210
when it finds the number of instances across sizes are not balanced so that's something that it will

71
00:05:31,210 --> 00:05:37,600
do automatically when auto scaling rebalances it launches new instances into the AZs that have the fewest

72
00:05:37,720 --> 00:05:43,810
instances first and then it starts terminating instances in AZs that have more instances.

73
00:05:43,810 --> 00:05:48,640
So that means it launches instances first then it terminates so it tries to make sure your application

74
00:05:48,640 --> 00:05:54,940
is available rather than ensuring that it's the most cost effective by not having too many instances

75
00:05:54,940 --> 00:06:01,510
running an imbalance may occur due to something like you've moved a availability zone a subnet you've

76
00:06:01,510 --> 00:06:08,340
terminated instances there are capacity issues on AWS or spot has terminated an instance.

77
00:06:08,350 --> 00:06:15,430
We then have health checks by default EC2 Auto Scaling uses the EC2 status checks.

78
00:06:15,430 --> 00:06:22,170
You can also choose to use ELB health checks and custom health checks when you use ELB health

79
00:06:22,170 --> 00:06:29,160
checks these are in addition to the EC2 status checks so you'll always use status checks but you can additionally

80
00:06:29,160 --> 00:06:32,940
use health checks when you configure that and it's a best practice that you use.

81
00:06:32,970 --> 00:06:34,460
ELB health checks as well.

82
00:06:34,470 --> 00:06:39,660
Any health check failure will return an unhealthy status and the instance will be terminated.

83
00:06:39,660 --> 00:06:43,830
So when you have ELB health checks it means that an instance is marked as unhealthy.

84
00:06:43,830 --> 00:06:50,610
If the ELB reports it is out of service a healthy instance is entering into the in-service date and

85
00:06:50,610 --> 00:06:54,140
when an instance is marked as unhealthy it gets scheduled for replacement.

86
00:06:54,210 --> 00:06:58,870
If connection draining is enabled auto scaling waits for in-flight requests to complete or time

87
00:06:58,870 --> 00:07:01,310
out before terminating instances.

88
00:07:01,350 --> 00:07:07,230
So there's a grace period to make sure that open connections are completed before the instances of the

89
00:07:07,260 --> 00:07:13,380
terminated. So unlike AZ rebalancing when instances are terminated because they're unhealthy.

90
00:07:13,380 --> 00:07:14,750
It happens first.

91
00:07:14,880 --> 00:07:21,000
So remember with the AZ rebalancing it will add additional instances and when they've been added successfully

92
00:07:21,000 --> 00:07:26,670
it then terminates the instances in another availability zone to try and keep you at the number of instances

93
00:07:26,670 --> 00:07:27,120
you want.

94
00:07:27,270 --> 00:07:32,460
However with unhealthy instances they're just terminated immediately and then also scaling attempts

95
00:07:32,460 --> 00:07:33,780
to launch a new instance.

96
00:07:33,810 --> 00:07:39,330
You can suspend and resume scaling processes for your auto scaling groups and you might do this when

97
00:07:39,330 --> 00:07:45,960
you need to investigate configuration problem or some kind of issue so that the screening process isn't

98
00:07:45,960 --> 00:07:51,690
invoked because otherwise you might find that auto scaling is trying to replace the instance that you've

99
00:07:51,690 --> 00:07:53,250
taken off line to work on.

100
00:07:53,250 --> 00:07:58,560
You can also manually remove instances from the ASG and put it into a standby state that's used for

101
00:07:58,560 --> 00:08:02,910
performing updates changes troubleshooting and so there's a thing called the cooldown period and that's

102
00:08:02,910 --> 00:08:07,830
a configurable setting for the also scrolling group that ensures that it doesn't launch or terminate

103
00:08:07,920 --> 00:08:14,130
additional instances before previous activity has taken effect so previous scaling activity and the

104
00:08:14,130 --> 00:08:16,500
default value for that is 300 seconds.

105
00:08:16,500 --> 00:08:23,130
The warm up period is the period of time in which a newly created instance launched by ASG using step

106
00:08:23,130 --> 00:08:29,700
scaling is not considered towards the ASG metrics onto monitoring basic monitoring sends metrics

107
00:08:29,700 --> 00:08:36,180
to cloud watch about EC2 instances every five minutes and that's free and then detailed can be enabled

108
00:08:36,480 --> 00:08:38,370
every one minute and that's chargeable.

109
00:08:38,370 --> 00:08:41,440
Now if the launch configuration's created from the console.

110
00:08:41,460 --> 00:08:43,560
Basic monitoring is enabled by default.

111
00:08:43,560 --> 00:08:49,470
However if you create the launch configuration from the CLI detailed monitoring of EC2 instances is enabled

112
00:08:49,470 --> 00:08:50,580
by default.

113
00:08:50,820 --> 00:08:52,440
So that's it for this exam cram.

114
00:08:52,440 --> 00:08:57,120
There's a lot of information there but I hope that you've retained some of that because this is definitely

115
00:08:57,480 --> 00:08:59,070
a big subject for the exam.

116
00:08:59,080 --> 00:09:03,030
Both ELB and auto scaling are definitely very prominent in the exam.

