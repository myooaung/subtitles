WEBVTT
1
00:00:05.160 --> 00:00:05.640
Hi, guys.

2
00:00:05.690 --> 00:00:11.250
In this lesson, we're going to have a look at some of the different options for easy to auto scaling

3
00:00:11.250 --> 00:00:11.970
policies.

4
00:00:12.690 --> 00:00:17.430
So the first one I'm going to cover is the target tracking SkyTeam policy.

5
00:00:17.430 --> 00:00:19.800
This is one of the dynamics guiding policies.

6
00:00:20.370 --> 00:00:25.740
So in this case, you can see that we have an auto scanning group and within that auto scanning group,

7
00:00:25.740 --> 00:00:27.510
we have four instances.

8
00:00:28.170 --> 00:00:35.250
Now we're using this metric the ESG average CPU utilization, and it's specified as 60.

9
00:00:36.120 --> 00:00:43.110
Now we have a variety of different metrics being reported here, but the average is over 60.

10
00:00:43.470 --> 00:00:45.300
It's actually seventy one point five.

11
00:00:45.600 --> 00:00:49.440
So that means that off the cloud watchers reported this information.

12
00:00:49.800 --> 00:00:57.120
The auto scanning group will know that it needs to add an instance to try and get that average CPU utilization

13
00:00:57.390 --> 00:00:59.730
back to 60 percent or under.

14
00:01:00.210 --> 00:01:05.370
Now remember the instance metrics are not counted until the warm up time has expired.

15
00:01:05.580 --> 00:01:11.220
When using target tracking, IWC recommends scaling of metrics with a one minute frequency.

16
00:01:11.310 --> 00:01:13.680
We then have another dynamic scaling policy.

17
00:01:13.680 --> 00:01:16.950
This is simple scaling with simple scaling.

18
00:01:16.950 --> 00:01:24.540
The auto scaling group has an alarm set to some metrics like CPU, in this case greater than or equal

19
00:01:24.540 --> 00:01:26.010
to 60 percent.

20
00:01:26.910 --> 00:01:32.820
Now, let's say the auto scaling group is reporting that the average CPU is 70 percent.

21
00:01:33.390 --> 00:01:40.500
Then the alarm goes off and auto scaling responds by launching two instances into the auto scanning

22
00:01:40.500 --> 00:01:40.830
group.

23
00:01:40.980 --> 00:01:47.550
It will then wait 300 seconds before allowing another scaling activity, and then things start again.

24
00:01:47.700 --> 00:01:51.120
Then we have the dynamic scaling policy called step scaling.

25
00:01:51.570 --> 00:01:58.230
In this case, the auto scaling group has an alarm set to CPU greater than or equal to 60 percent.

26
00:01:58.770 --> 00:02:06.630
The CPU metrics are reporting the aggregate usage of 70 percent, so the alarm goes off and launches

27
00:02:06.630 --> 00:02:09.480
to see two instances so very much like before.

28
00:02:10.230 --> 00:02:13.470
But what if the alarm breach is greater?

29
00:02:14.010 --> 00:02:19.110
So now we can have a threshold that says that if the alarm breach is greater, like it's 80 percent

30
00:02:19.350 --> 00:02:22.350
rather than 70 launch for instances.

31
00:02:22.710 --> 00:02:29.700
So we know the size of the alarm breach is going to determine how many EC2 instances are launched.

32
00:02:29.970 --> 00:02:33.580
Next, we have scheduled scaling with scheduled scaling.

33
00:02:33.600 --> 00:02:40.950
We can define a time at which the auto scaling group is going to scale and how many instances we want

34
00:02:40.950 --> 00:02:45.240
it to scale by, and the auto scaling group will launch those instances.

35
00:02:45.720 --> 00:02:51.870
Now you often see exam questions that say that there's been a big slowdown in an application when F1

36
00:02:51.870 --> 00:02:53.820
logs on at 9am in the morning.

37
00:02:54.330 --> 00:02:55.350
So what could you do?

38
00:02:55.380 --> 00:03:02.430
Well, we know when the demand is coming, so why not schedule the shining policy to add some instances

39
00:03:02.820 --> 00:03:03.840
845?

40
00:03:03.840 --> 00:03:06.270
And that gives them time to come into operation.

41
00:03:06.510 --> 00:03:11.760
And then when F1 logs in at work at 9am, then there's not going to be so much of a slowdown or none

42
00:03:11.760 --> 00:03:15.300
at all, hopefully when we define our schedule scaling policy.

43
00:03:15.420 --> 00:03:22.050
We need to specify the desired the men and the max instances, the desired attempts to maintain the

44
00:03:22.050 --> 00:03:22.950
desired count.

45
00:03:22.950 --> 00:03:24.390
So here we might specify.

46
00:03:24.420 --> 00:03:24.990
15.

47
00:03:24.990 --> 00:03:28.260
It's going to try and make sure that 15 instances are running.

48
00:03:28.890 --> 00:03:32.270
The minimum instances is the minimum that can ever run.

49
00:03:32.280 --> 00:03:36.810
We don't ever want to go below this amount, and the maximum is the absolute max.

50
00:03:36.810 --> 00:03:44.460
So you won't get a scale out past 25 instances and you can see then we have a recurrence of every day

51
00:03:44.850 --> 00:03:50.100
and a start time of and we have a date and then we have a specific time.

52
00:03:50.340 --> 00:03:53.580
So those are the key scaling policies that come up in the exam.

53
00:03:53.730 --> 00:03:57.450
You may see predictive scaling and that's we'll see in the console.

54
00:03:57.630 --> 00:04:04.110
And what it is is it's a way that IWC is able to predict what's going to happen and then actually launch

55
00:04:04.110 --> 00:04:08.190
instances at the right times based on prior event history.

56
00:04:08.820 --> 00:04:10.030
So that's it for the ferry.

57
00:04:10.050 --> 00:04:14.640
Let's get back sort of hands on and see how we can allow Stickley scale our application.

