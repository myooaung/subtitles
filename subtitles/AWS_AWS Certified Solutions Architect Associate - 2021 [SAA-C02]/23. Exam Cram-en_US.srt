1
00:00:05,360 --> 00:00:09,710
Welcome to the exam, cram for Amazon as free, so we've is free.

2
00:00:09,740 --> 00:00:15,620
You can store any type of file files can be anywhere from zero bytes to five terabytes.

3
00:00:15,950 --> 00:00:22,280
There is virtually unlimited storage available as free as a universal namespace of bucket names must

4
00:00:22,280 --> 00:00:26,720
be unique globally, but you have to create your buckets within a specific region.

5
00:00:27,230 --> 00:00:32,480
It's therefore best practice to create your buckets in regions that are physically closest to your end

6
00:00:32,480 --> 00:00:34,340
users, and that will reduce latency.

7
00:00:34,910 --> 00:00:37,640
There's no hierarchy for objects within the buckets.

8
00:00:38,240 --> 00:00:45,290
S3 delivers strong read off the right consistency, so with buckets, files get stored in buckets and

9
00:00:45,290 --> 00:00:48,020
the bucket can be viewed as a container for the objects.

10
00:00:48,380 --> 00:00:54,860
It's a flat container of objects with no hierarchy, but you can use an object, key name or prefix

11
00:00:55,040 --> 00:00:56,180
to mimic folders.

12
00:00:56,810 --> 00:01:03,350
You've got 100 buckets per account by default as a limit, but you can store unlimited objects in your

13
00:01:03,350 --> 00:01:03,920
buckets.

14
00:01:04,130 --> 00:01:08,210
You cannot create nested buckets, or a bucket will never go inside another bucket.

15
00:01:09,020 --> 00:01:16,280
Objects are the files that you upload as free as free supports any file type, and each objects is stored

16
00:01:16,280 --> 00:01:18,680
and retrieved by a unique key.

17
00:01:19,220 --> 00:01:24,200
Objects remain in the region in which they're stored unless you set up replication.

18
00:01:24,800 --> 00:01:27,740
Permissions can be defined on objects at any time.

19
00:01:28,400 --> 00:01:33,860
The storage class is set at the object level, and here are the storage classes.

20
00:01:33,860 --> 00:01:35,910
So this is something for you to review.

21
00:01:35,930 --> 00:01:37,490
I'm not going to go through them all.

22
00:01:37,700 --> 00:01:43,460
We've been through them quite extensively in the course, but you need to understand the various features

23
00:01:43,670 --> 00:01:48,200
and use cases for each of these different storage classes before you sit the exam.

24
00:01:48,620 --> 00:01:53,660
We then have different types of policies that we can apply IAM policies and bucket policies.

25
00:01:54,230 --> 00:01:56,930
I am policies, identity based policies.

26
00:01:57,260 --> 00:02:01,370
The principle is not defined within an IAM policy.

27
00:02:01,730 --> 00:02:06,140
Bucket policies are resource based policies with bucket policies.

28
00:02:06,350 --> 00:02:14,180
They can only be attached to Amazon S3 buckets and both use the same IWC access policy language.

29
00:02:14,630 --> 00:02:16,730
We then have access control lists.

30
00:02:17,060 --> 00:02:19,970
These are a legacy access control mechanism.

31
00:02:20,880 --> 00:02:27,230
IWC will generally recommend using S3 bucket policies or IAM policies rather than ACLs.

32
00:02:27,890 --> 00:02:34,310
They can be attached to a bucket or directly to an object, and you get limited options for the grantees

33
00:02:34,310 --> 00:02:35,900
and the permissions that you can apply.

34
00:02:36,020 --> 00:02:39,830
Nowhere near the power of a JSON based IAM policy.

35
00:02:40,730 --> 00:02:42,870
So when should you use each use?

36
00:02:42,890 --> 00:02:48,020
I am policies if you need to control access to AWB services other than as free.

37
00:02:48,560 --> 00:02:53,660
If you have numerous free buckets, each with different permissions requirements I am policies will

38
00:02:53,660 --> 00:03:00,560
turn out to be a lot easier to manage or if you prefer to keep access control policies in the IAM environment,

39
00:03:01,250 --> 00:03:02,530
use bucket policies.

40
00:03:02,540 --> 00:03:09,860
If you want a simple way to grant cross account access to S3 without using IAM roles, or if your IM

41
00:03:09,860 --> 00:03:15,990
policies are reaching the size limits, you might prefer to keep access control policies in as free

42
00:03:16,650 --> 00:03:17,690
as free versioning.

43
00:03:17,960 --> 00:03:22,640
Versioning is a means of keeping multiple variants of an object in the same buckets.

44
00:03:23,180 --> 00:03:29,150
You use versioning to preserve, retrieve and restore every version of the object stored in your S3

45
00:03:29,150 --> 00:03:30,860
buckets and versioning.

46
00:03:30,860 --> 00:03:36,590
Enable buckets will enable you to recover objects from accidental deletion or overrides.

47
00:03:37,400 --> 00:03:44,120
There are two types of actions with lifecycle management transition actions and expiration actions.

48
00:03:44,360 --> 00:03:46,610
Remember the supported transitions?

49
00:03:46,880 --> 00:03:48,520
I'm not going to go through each of these.

50
00:03:48,530 --> 00:03:51,410
I'm just going to put them up on the screen for you to read through.

51
00:03:51,980 --> 00:03:57,200
And perhaps the easiest way to remember this or to understand it is to use the diagram on the right

52
00:03:57,230 --> 00:03:57,830
hand side.

53
00:03:58,190 --> 00:04:04,340
We then have the unsupported transition so you can't transition from any storage class to S3.

54
00:04:04,340 --> 00:04:06,110
That's a quite a simple one to remember.

55
00:04:06,500 --> 00:04:13,910
Any storage class to reduce redundancy intelligence hearing to S3 Standard, i.e. one zone item, S3

56
00:04:13,910 --> 00:04:15,830
Standard, IEEE or intelligent tearing.

57
00:04:16,220 --> 00:04:20,900
And again, if you understand the diagram on the right hand side, that would be an easy way to remember.

58
00:04:21,350 --> 00:04:27,710
Moving on to multifactor authentication delete this adds an MFA requirement for changing the versioning

59
00:04:27,710 --> 00:04:31,610
state of a bucket or permanently deleting an object version.

60
00:04:31,610 --> 00:04:38,180
And that's what bucket owners the X aims at MFA request header must be included in the above requests.

61
00:04:38,750 --> 00:04:45,740
The second factor of authentication is generated by a hardware device or software program like a authenticator

62
00:04:45,740 --> 00:04:49,850
app such as the Google Authenticator app that we've used in this course.

63
00:04:50,240 --> 00:04:53,360
It does require versioning to be enabled on the bucket.

64
00:04:54,260 --> 00:04:57,050
Versioning can be enabled by bucket owners.

65
00:04:57,050 --> 00:05:04,450
The root accounts AWG account that created the bucket and authorised IAM uses MFA deletes because.

66
00:05:04,540 --> 00:05:10,750
Be enabled by the bucket owner only, what about protected API access with MFA?

67
00:05:11,170 --> 00:05:14,380
This is used to enforce another authentication factor.

68
00:05:14,530 --> 00:05:18,610
An MFA code when accessing resources and not just as free.

69
00:05:19,240 --> 00:05:26,590
It's enforced using the aid of U.S. multifactor auth age key in a bucket policy for S3 encryption.

70
00:05:26,590 --> 00:05:30,280
We went over the options available in quite a bit of detail in the lessons.

71
00:05:30,760 --> 00:05:37,870
So you remember this SC S3, that's when you're using s freeze existing encryption key for a two five

72
00:05:37,870 --> 00:05:46,090
six encryption SC C is where you're uploading your own as to five six encryption key, which is free

73
00:05:46,090 --> 00:05:47,200
then uses for U.

74
00:05:48,010 --> 00:05:54,670
S. CMS is where you're using K keys and client side is where you have your own encryption keys and you're

75
00:05:54,670 --> 00:05:56,080
managing the encryption as well.

76
00:05:56,320 --> 00:05:57,850
There's no encryption happening on.

77
00:05:58,480 --> 00:06:02,260
You're doing it before you upload your object's default.

78
00:06:02,260 --> 00:06:08,350
Encryption is a way to set the default encryption behavior for unnecessary buckets after you enable

79
00:06:08,350 --> 00:06:09,370
default encryption.

80
00:06:09,760 --> 00:06:12,430
All new objects will be encrypted when they're uploaded.

81
00:06:12,850 --> 00:06:19,390
The objects are encrypted using server side encryption, and S3 encrypts objects before saving them

82
00:06:19,390 --> 00:06:22,360
the disk and decrypt them when they're being downloaded.

83
00:06:23,860 --> 00:06:29,920
There's no change to the encryption of objects that existed in the bucket before the default encryption

84
00:06:30,130 --> 00:06:30,970
was enabled.

85
00:06:32,010 --> 00:06:34,020
We then have event notifications.

86
00:06:34,530 --> 00:06:39,720
This is where he sends notifications when an event happens in an buckets.

87
00:06:40,230 --> 00:06:49,500
The destinations include S.A., iSCSI and Lambda multiple upload uploads, objects and parts independently

88
00:06:49,680 --> 00:06:57,690
in parallel and in any order it's performed using the multiple upload API and it's recommended for objects

89
00:06:57,690 --> 00:06:59,460
above 100 megabytes.

90
00:07:00,060 --> 00:07:06,630
And it can be used for objects from five megabytes up to the maximum file size, which is five terabytes,

91
00:07:07,110 --> 00:07:11,070
and it has to be used for any objects larger than five gigabytes.

92
00:07:12,510 --> 00:07:14,490
Next, we have transfer acceleration.

93
00:07:14,820 --> 00:07:20,460
This is a way of improving the performance of transfers of files, and it leverages the cloud front

94
00:07:20,640 --> 00:07:21,750
edge locations.

95
00:07:22,350 --> 00:07:28,830
You can accelerate uploads of objects over long distances, so you're reducing latency transfer.

96
00:07:28,830 --> 00:07:34,890
Acceleration is as secure as a direct uploads as free, and you're charged only if there's a benefit

97
00:07:34,890 --> 00:07:40,380
in the transfer time you need to enable transfer acceleration on the S3 bucket.

98
00:07:40,860 --> 00:07:43,800
It cannot be disabled after that, but only suspended.

99
00:07:45,020 --> 00:07:51,650
The free copy API is where you can copy objects up to five gigabytes, and it can be used to generate

100
00:07:51,650 --> 00:07:54,830
additional copies of objects rename objects.

101
00:07:55,160 --> 00:07:58,340
Changed the storage class or encryption at rest status.

102
00:07:58,610 --> 00:08:02,540
Or move the objects between IWC locations and regions.

103
00:08:03,110 --> 00:08:05,480
You can also change the object metadata.

104
00:08:06,230 --> 00:08:11,630
Server access logging provides detailed records for the requests that are made to a bucket.

105
00:08:11,960 --> 00:08:17,600
The information that is logged includes the request to the bucket name, the request, time, request,

106
00:08:17,600 --> 00:08:19,910
action, response status and error code.

107
00:08:20,510 --> 00:08:24,980
It's disabled by default, and you only pay for the storage space that's actually used.

108
00:08:25,880 --> 00:08:31,250
You must configure a separate bucket as the destination, and you can specify a prefix if you want to.

109
00:08:32,060 --> 00:08:38,660
You must also grant write permission to the Amazon S3 Log Delivery Group on the destination bucket.

110
00:08:40,050 --> 00:08:47,250
Calls with Amazon S3 is enabled free setting, the access control, allow origin, allow methods and

111
00:08:47,250 --> 00:08:48,540
allow head of settings.

112
00:08:49,290 --> 00:08:55,890
These settings are defined using rules and the rules are added using JSON files in Amazon hash rate.

113
00:08:57,120 --> 00:09:03,720
The Cross Account Access Methods, Resource Base policies and IAM policies can be used for programmatic

114
00:09:03,720 --> 00:09:11,580
access to S3 bucket objects, resource based ACL and I am policies for programmatic access to S3 bucket

115
00:09:11,580 --> 00:09:12,480
objects as well.

116
00:09:13,380 --> 00:09:20,670
If you need programmatic and console access, you can use Cross Account I roles for performance optimizations.

117
00:09:20,670 --> 00:09:30,690
S3 does support at least 3500 puts copy paste deletes or 5500 head requests per second per prefix in

118
00:09:30,690 --> 00:09:32,490
a bucket, so it's pretty high performance.

119
00:09:32,850 --> 00:09:37,350
You can increase, read or write performance by paralyzing reads.

120
00:09:37,680 --> 00:09:39,420
You can use Byte range fetches.

121
00:09:39,690 --> 00:09:46,950
You can retry requests for latency sensitive applications, and you can combine S3 and easy to in the

122
00:09:46,950 --> 00:09:48,840
same region for better performance.

123
00:09:49,410 --> 00:09:56,070
Lastly, you can use Amazon S3 transfer acceleration to minimize any latency caused by long distances.

124
00:09:56,730 --> 00:09:58,150
And that's it for this exam chrome.

