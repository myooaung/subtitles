WEBVTT
1
00:00:02.200 --> 00:00:07.860
This is a quick lab to cover how we can use auto scaling with our ECS services.

2
00:00:07.930 --> 00:00:14.830
So we already know that we can use auto scaling with EC2 to provision the actual container instances

3
00:00:14.830 --> 00:00:16.140
themselves.

4
00:00:16.270 --> 00:00:23.170
And so you can set up EC2 auto scaling just as we did in the EC2 section of course to launch

5
00:00:23.560 --> 00:00:29.890
your container instances and then you can configure them so they come into the cluster we can then also

6
00:00:29.890 --> 00:00:36.820
use command line utilities and various other tools to scale the amount of tasks that are running but

7
00:00:36.820 --> 00:00:42.640
we can also go where we have a service we can define some of these characteristics of these behaviors

8
00:00:42.640 --> 00:00:43.630
through the service.

9
00:00:46.440 --> 00:00:53.810
Let's go into our service nginx and head over to auto scaling and we don't have any configured here.

10
00:00:53.820 --> 00:00:59.600
So what we actually have to do is go update and then click through.

11
00:00:59.630 --> 00:01:05.040
Because it's one of the last pages and here we go auto scaling so we can configure service auto scaling

12
00:01:05.040 --> 00:01:12.870
here and you can also you can configure your minimum desired maximum number of tasks and you can also

13
00:01:13.140 --> 00:01:19.470
add a policy so you can have your target tracking policy looking at different metrics and we have CPU,

14
00:01:19.920 --> 00:01:23.520
memory, and IP connection count per target.

15
00:01:23.520 --> 00:01:30.230
So how many requests are being routed per target or you could do step scaling.

16
00:01:30.230 --> 00:01:33.450
And this is all very similar to the way EC2 auto scaling works.

17
00:01:33.560 --> 00:01:36.920
We went over that in the EC2 section of the course.

18
00:01:36.920 --> 00:01:45.240
You could set an alarm for CPU utilization when it reaches say 80 percent or you could do memory utilization.

19
00:01:45.250 --> 00:01:52.850
Same sort of thing what I'm just going to do here is set the minimum number of tasks to 2 and the desire

20
00:01:52.850 --> 00:02:01.150
to fall and let's say the maximum to 6 and let's just click next and update service and we can see that

21
00:02:01.160 --> 00:02:02.470
a couple of things happened.

22
00:02:02.510 --> 00:02:09.530
The IAM auto scale role was created and attached to the policy and we could actually then go into a

23
00:02:09.530 --> 00:02:13.960
new tab and have a look at that role so let's go into.

24
00:02:14.010 --> 00:02:14.580
IAM

25
00:02:24.240 --> 00:02:25.450
and that link didn't work.

26
00:02:25.450 --> 00:02:26.530
So here we go.

27
00:02:26.530 --> 00:02:33.910
So this is the EC2 auto scaling role and let's have a look at what the trust relationship is there say the

28
00:02:34.180 --> 00:02:42.610
service application auto scaling is allowed to assume a role and see what permissions it has the EC2

29
00:02:42.610 --> 00:02:45.840
container  service auto scaling role permissions policy.

30
00:02:45.850 --> 00:02:47.380
Let's have a look into that policy

31
00:02:51.180 --> 00:02:57.540
so we can see this has the actions for describing and updating ECS services and then describing and

32
00:02:57.540 --> 00:02:59.790
putting metric alarms in the cloud watch

33
00:03:04.050 --> 00:03:06.750
the service has been updated so let's go back and have a look.

34
00:03:06.780 --> 00:03:15.450
And if we go over two tasks yeah now we've got our four tasks because that's the desired number that

35
00:03:15.450 --> 00:03:16.640
we just configured.

36
00:03:16.770 --> 00:03:18.120
And if we go into events

37
00:03:23.780 --> 00:03:29.360
we can see that two more targets were registered to the target group.

38
00:03:29.360 --> 00:03:34.130
So if we go back over to our low balances we should see that they're also now in service in service

39
00:03:34.550 --> 00:03:40.030
and they'll be attached to TG1. So sure enough we've got four healthy instances there.

40
00:03:40.050 --> 00:03:41.930
So that's really all I wanted to cover here.

41
00:03:41.970 --> 00:03:48.870
If you want to get some more experience you could set up some auto scaling policies and then go and

42
00:03:49.800 --> 00:03:54.170
generate some load on your tasks and see what happens.

43
00:03:54.660 --> 00:03:59.070
But it's going to be very similar to the way EC2 auto scaling works.

44
00:03:59.070 --> 00:04:00.590
So that's it for this lab.

45
00:04:00.780 --> 00:04:05.550
And what we're going to do now is we're actually going to take this configuration down and then in the

46
00:04:05.550 --> 00:04:11.190
next lab we're going to cover the elastic container registry so we don't need this cluster anymore so

47
00:04:11.190 --> 00:04:21.570
we can go in here and just click delete cluster. We can then go to our load balancer

48
00:04:22.920 --> 00:04:30.680
and delete our load balancer and then we can delete both of our target groups

49
00:04:34.130 --> 00:04:41.710
and then we can go and terminate both of our instances.

50
00:04:41.720 --> 00:04:49.310
The other thing you'll want to do is go back to VPC and assuming you're not using this for anything

51
00:04:49.310 --> 00:04:54.890
else you'll want to get rid of your NAT gateway because they do cost money so you'll use up your credits

52
00:04:56.930 --> 00:05:01.580
on your free tier. Delete the NAT Gateway and then once you've deleted the NAT Gateway you need to

53
00:05:01.580 --> 00:05:05.750
go to your private route table and remove the route

54
00:05:09.270 --> 00:05:11.180
and that's pretty much it.

55
00:05:11.400 --> 00:05:14.850
We can leave the security groups where they are you can remove them if you want to clean up your lab

56
00:05:14.850 --> 00:05:17.780
completely but we don't need them now for the rest of this section.

57
00:05:19.020 --> 00:05:20.400
So that's it for this lab.

58
00:05:20.400 --> 00:05:23.270
Hope you had some fun and I'll see you in the next lab.

