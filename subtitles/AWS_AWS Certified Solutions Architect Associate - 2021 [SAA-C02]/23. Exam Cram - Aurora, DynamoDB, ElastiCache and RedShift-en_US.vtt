WEBVTT
1
00:00:02.280 --> 00:00:04.260
Moving on to Amazon Aurora.

2
00:00:04.470 --> 00:00:07.530
This is an AWS proprietary database.

3
00:00:07.530 --> 00:00:09.090
It's a fully managed service.

4
00:00:09.360 --> 00:00:11.140
It's high performance low price.

5
00:00:11.170 --> 00:00:18.520
It scales in 10 gigabyte increments up to 32 CPUs and 244 gigabytes of RAM.

6
00:00:18.900 --> 00:00:22.860
Two copies of data are kept in each AZ with a minimum of 3 AZs.

7
00:00:22.880 --> 00:00:28.770
So you get six copies of your data for durability and it can handle the loss of up to two copies of

8
00:00:28.770 --> 00:00:35.450
data without affecting the write availability and up to three copies without affecting read availability.

9
00:00:37.420 --> 00:00:38.370
Read replicas.

10
00:00:38.380 --> 00:00:40.770
There's two different types you've got the Aurora replica.

11
00:00:40.770 --> 00:00:44.050
You can have up to 15 and the MySQL read replica.

12
00:00:44.050 --> 00:00:53.960
We can have up to five  Aurora replicas in a region and MySQL is cross region. So for Aurora

13
00:00:53.960 --> 00:01:00.260
cross region replicas the cross region read replicas allows for improved Disaster Recovery, scaling read

14
00:01:00.260 --> 00:01:06.790
operations in regions closer to application users, and easily migrate from one region to another.

15
00:01:07.220 --> 00:01:14.090
So they provide fast local reads across regions, each region can have an additional 15 read replicas

16
00:01:14.180 --> 00:01:17.120
to further scale the local reads.

17
00:01:17.210 --> 00:01:22.580
Now you can choose between global database and that provides the best replication performance or traditional

18
00:01:22.580 --> 00:01:30.260
binlog based replication. Global database is a globally distributed application and it means

19
00:01:30.260 --> 00:01:37.840
that a single or RDS database can span regions for fast local reads and quick disaster recovery.

20
00:01:37.890 --> 00:01:43.640
It uses storage based replication to replicate the database across regions with very low latency of

21
00:01:43.640 --> 00:01:50.170
less than 1 second you can use your secondary region as a backup if you need to recover.

22
00:01:50.180 --> 00:01:57.120
In terms of some kind of disaster or degradation the database in the secondary region can also be promoted

23
00:01:57.120 --> 00:02:01.050
to full read write capabilities very quickly.

24
00:02:01.050 --> 00:02:02.400
We then have multi master.

25
00:02:02.400 --> 00:02:08.460
This is a very new feature overall and it means that you can and you can use this with MySQL only

26
00:02:09.020 --> 00:02:14.220
and it means that you can actually scale out your write performance across availability zones so you

27
00:02:14.220 --> 00:02:19.500
can actually write to multiple database instances at the same time.

28
00:02:19.530 --> 00:02:24.990
It's designed to achieve high availability and ACID transactions across clusters of database nodes

29
00:02:25.420 --> 00:02:31.950
with configurable read after write consistency. Now something that comes up quite a bit on the SAA-C02

30
00:02:31.950 --> 00:02:34.720
exam is Aurora Serverless.

31
00:02:34.770 --> 00:02:38.790
This is an on demand auto scaling configuration for Aurora.

32
00:02:39.090 --> 00:02:45.930
It's compatible with MySQL and PostgreSQL editions. Aurora serverless database

33
00:02:45.960 --> 00:02:54.470
automatically starts up shuts down and scales capacity based on application needs so you can run a database

34
00:02:54.470 --> 00:03:01.460
in the cloud about managing any database instances so good use cases for this where you have infrequent

35
00:03:01.520 --> 00:03:09.040
intermittent or unpredictable workloads what you do is you create a database endpoint and specify optionally

36
00:03:09.040 --> 00:03:14.770
specify the desired capacity range and connect your applications and then the database will basically

37
00:03:14.770 --> 00:03:16.990
spin up when it's needed.

38
00:03:16.990 --> 00:03:23.920
So you only pay for database storage and the actual database capacity in your database consumes while

39
00:03:23.920 --> 00:03:24.880
it is active.

40
00:03:24.880 --> 00:03:30.950
You pay on a per second basis for the database capacity you use when the database is asked.

41
00:03:31.000 --> 00:03:38.740
Next up we've got dynamoDB. So this is a fully manage NoSQL database service that provides fast

42
00:03:38.740 --> 00:03:42.760
and predictable performance with seamless scalability.

43
00:03:42.760 --> 00:03:50.210
It's a multi AZ NoSQL data store with cross region replication is an option it definitely gives

44
00:03:50.210 --> 00:03:56.900
you push button scalability and there's no downtime with DynamoDB. It defaults to what's called the

45
00:03:56.900 --> 00:04:04.010
eventual consistency reads but you can request strongly consistent reads via an SDK parameter which

46
00:04:04.010 --> 00:04:09.590
you'll need to put into your application. You can achieve ACID compliance with dynamoDB transactions

47
00:04:10.280 --> 00:04:17.890
it's SSD based and uses limited indexing on attributes for fast performance databases synchronicity

48
00:04:17.890 --> 00:04:26.230
replicated across three facilities in a region its a schemaless database and it can also be used for

49
00:04:26.230 --> 00:04:30.020
storing session state. So they are two read models.

50
00:04:30.020 --> 00:04:32.110
You got the eventually consistent reads.

51
00:04:32.290 --> 00:04:36.890
This maximizes for reads. With eventually consistent reads

52
00:04:37.000 --> 00:04:42.550
it might not reflect the results of a recently completed write but consistency is reached within a second.

53
00:04:43.180 --> 00:04:50.270
With strongly consistent reads a read returns a result that reflects all rights that received a successful

54
00:04:50.270 --> 00:04:52.610
response prior to the read.

55
00:04:52.730 --> 00:04:53.820
So that's much better.

56
00:04:55.340 --> 00:04:57.290
We then have DynamoDB streams.

57
00:04:57.290 --> 00:05:06.130
This keeps a list of item level changes that have taken place in the last 24 hours so you can use this

58
00:05:06.130 --> 00:05:13.090
for instance with AWS lambda so that AWS lambda can then trigger based on events that are happening

59
00:05:13.120 --> 00:05:20.720
in your dynamoDB database if you create a stream on a table you can associate the stream ARN with

60
00:05:20.720 --> 00:05:24.140
the Lambda function. We then have DynamoDB accelerator.

61
00:05:24.160 --> 00:05:24.820
DAX.

62
00:05:24.830 --> 00:05:31.680
This is a fully managed highly available in memory cache for DynamoDB that greatly improves performance.

63
00:05:31.970 --> 00:05:36.560
So watch out for terminology that says milliseconds or microseconds.

64
00:05:36.560 --> 00:05:44.180
So for microsecond responses you need to look at dynamoDB accelerator. So it's a managed service.

65
00:05:44.360 --> 00:05:51.440
You don't have to modify your application because it's compatible with DynamoDB API calls and its provisioned

66
00:05:51.440 --> 00:05:56.450
using clusters and charged by the nodes so you actually provision a certain number of EC2 instances

67
00:05:56.510 --> 00:05:58.620
and the DAX cluster runs on those.

68
00:05:58.670 --> 00:06:03.320
We then have dynamoDB cross region replication with global tables.

69
00:06:03.410 --> 00:06:09.110
In this case dynamoDB global tables provides a fully managed solution for deploying a multi region

70
00:06:09.170 --> 00:06:15.500
multi master database you credit global tables specify the regions you want the table to be available

71
00:06:15.500 --> 00:06:22.130
in and then performs the necessary tasks to create identical tables in these regions and propagate any

72
00:06:22.130 --> 00:06:30.640
ongoing changes to it's ideal for massively scaled applications globally dispersed users and it's providing

73
00:06:30.730 --> 00:06:37.510
automatic multi master replication to the AWS regions around the world so you can deliver low latency

74
00:06:37.510 --> 00:06:39.860
access to users anywhere in the world.

75
00:06:39.940 --> 00:06:45.790
DynamoDB auto scaling uses application auto scaling to dynamically adjust the provision throughput

76
00:06:45.790 --> 00:06:51.700
capacity on your behalf in response to traffic patterns so you know we have read capacity units and

77
00:06:51.700 --> 00:06:57.400
write capacity units and dynamoDB and it changes those based on how much traffic it's seeing in the

78
00:06:57.400 --> 00:06:58.540
database.

79
00:06:58.540 --> 00:07:03.550
And this all happens automatically and prevent situations where you might end up having throttling taking

80
00:07:03.550 --> 00:07:08.950
place and it will decrease the Freeport as well when the workload decreases.

81
00:07:08.950 --> 00:07:10.300
So what do you pay for.

82
00:07:10.300 --> 00:07:16.580
You pay for reading writing and storing data in the tables along with optional features.

83
00:07:16.610 --> 00:07:21.090
There are two pricing models you've got on demand and provisioned capacity mode.

84
00:07:21.130 --> 00:07:24.710
So try and make sure you understand the difference between these two.

85
00:07:24.730 --> 00:07:26.130
We then have elasticache.

86
00:07:26.140 --> 00:07:30.630
This is a fully managed implementation of redis or memcached.

87
00:07:30.670 --> 00:07:37.590
So what we're talking about here is a managed service from running these two in-memory databases in

88
00:07:37.590 --> 00:07:44.580
the cloud so that can improve latency and throughput for read heavy application workloads or compute intensive

89
00:07:44.580 --> 00:07:46.170
workloads.

90
00:07:46.170 --> 00:07:53.880
It's best for OLAP, so analytics processing transactions and it automatically scales push button

91
00:07:53.880 --> 00:08:00.510
scalability for both the memory and the reads and writes. It's an in-memory key value store and it's not

92
00:08:00.510 --> 00:08:04.980
persistent in the traditional sense because it's in memory database.

93
00:08:05.040 --> 00:08:08.520
ElastiCache can be used to store session state as well.

94
00:08:08.520 --> 00:08:16.250
You have nodes and these are fixed sized chunks of secure network attached RAM. Each node runs an

95
00:08:16.370 --> 00:08:24.170
instance of memcached or redis and has its own DNS name and port. Failed nodes are automatically replaced.

96
00:08:24.170 --> 00:08:31.860
Access to elasticache is controlled by VPC security groups and subnet groups when it's deployed

97
00:08:31.860 --> 00:08:38.380
in a VPC, and subnet groups are a collection of subnets designated for your elasticache cluster.

98
00:08:38.430 --> 00:08:43.830
So a couple of use cases for elasticache you've got a Web session store you've got a database caching

99
00:08:43.830 --> 00:08:47.760
leaderboards and streaming data dashboards.

100
00:08:47.790 --> 00:08:50.330
Now the two engines are slightly different.

101
00:08:50.400 --> 00:08:56.580
You don't need to go into real deep depth about the differences between them but for the solutions architect

102
00:08:56.580 --> 00:08:59.700
exam make sure you understand these differences.

103
00:08:59.700 --> 00:09:06.790
So in most cases memached is considered to be the simple solution.

104
00:09:06.950 --> 00:09:14.360
It can elastically scale out, you can run multiple CPU cores or threads and it's useful when you need

105
00:09:14.360 --> 00:09:17.780
to cache objects such as database queries.

106
00:09:17.780 --> 00:09:21.540
Redis is where you need encryption or HIPAA compliance.

107
00:09:21.590 --> 00:09:28.330
It supports clustering more complex data types and when you need HA this is the one to go with.

108
00:09:28.400 --> 00:09:31.630
So it actually supports replication.

109
00:09:31.790 --> 00:09:34.550
So let's look at these in a bit more detail with memcached.

110
00:09:34.550 --> 00:09:37.950
The data's not persistent can't be used as a data store.

111
00:09:38.000 --> 00:09:41.120
It does support large nodes with multiple cores and threads.

112
00:09:41.180 --> 00:09:46.880
It scales in and out by adding removing nodes and it's good for front-end data stores such as RDS

113
00:09:46.880 --> 00:09:54.290
and dynamoDB. It scales up and down as well by changing the different instance type so the node family

114
00:09:54.290 --> 00:10:01.340
or type it doesn't support multi AZ failover or replication or snapshots it can place nodes in

115
00:10:01.340 --> 00:10:03.000
different AZs however.

116
00:10:03.290 --> 00:10:09.900
Now with redis the data is persistent it can be used as a data store but it's not multi threaded.

117
00:10:10.010 --> 00:10:14.540
Now it scales by adding shards not nodes and a shard is a subset

118
00:10:14.540 --> 00:10:18.410
of the clusters key space that includes a primary node and 0 or more read-replicas.

119
00:10:18.410 --> 00:10:24.620
Because if you remember back to our labs I showed you some diagrams of what this actually looks like

120
00:10:25.420 --> 00:10:33.380
multi AZ is possible using Read replicas in another AZ in the same region. Redshift is a data warehouse.

121
00:10:33.680 --> 00:10:41.780
So this is about analyzing data using standard SQL and business intelligence tools.

122
00:10:41.780 --> 00:10:45.740
Now it doesn't come up much on the exam these days but I'm keeping it short.

123
00:10:45.740 --> 00:10:48.440
So you just understand basically what it is.

124
00:10:48.530 --> 00:10:51.620
It's a petabyte scale data warehouse.

125
00:10:51.620 --> 00:10:52.760
It uses SQL

126
00:10:52.790 --> 00:10:54.640
for analytics.

127
00:10:54.740 --> 00:11:01.670
So think of it as an online analytics processing or OLAP type of database and you can run complex

128
00:11:01.670 --> 00:11:04.790
queries against passive bites of structured data.

129
00:11:04.850 --> 00:11:07.300
So remember again business intelligence.

130
00:11:07.310 --> 00:11:11.070
That's a keyword that often comes up in relation to redshift.

131
00:11:11.090 --> 00:11:17.950
It also features parallel processing and columnar data stores which are optimized for complex queries.

132
00:11:18.030 --> 00:11:24.890
You can optionally query directly from data files on S3 using what's called redshift spectrum.

133
00:11:24.900 --> 00:11:31.530
Now it does use EC2 instances so you have to choose your instance types for scaling a new scale

134
00:11:31.890 --> 00:11:40.320
compute vertically but you can also scale horizontally by adding nodes you cannot directly access your

135
00:11:40.320 --> 00:11:45.300
cluster as a user but you can through the application for availability and durability it uses

136
00:11:45.300 --> 00:11:52.500
replication and continuous backups it's available in one AZ but you can restore snapshots into another

137
00:11:52.500 --> 00:11:53.740
AZ.

138
00:11:53.990 --> 00:12:00.340
Or alternatively you can run data warehouse clusters in multiple AZs by loading data into different

139
00:12:00.580 --> 00:12:07.360
data warehouse clusters from the same set of input files. Redshift also automatically replicates your

140
00:12:07.360 --> 00:12:13.960
data within the data warehouse and backs it up to S3 and it always keeps three copies of your data, the

141
00:12:13.960 --> 00:12:19.090
original, a replica on the compute nodes, and a backup copy on S3.

