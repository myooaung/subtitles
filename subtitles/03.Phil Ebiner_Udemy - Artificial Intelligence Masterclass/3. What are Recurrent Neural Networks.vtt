WEBVTT

00:00.330 --> 00:02.850
Hello and welcome back to the course on deep learning.

00:02.850 --> 00:09.630
Today we're kicking off this section for recurrent neural networks and I'm very excited about this section.

00:09.700 --> 00:12.660
There's going to be quite some interesting tutorials.

00:12.660 --> 00:19.350
This is a one of the most advanced algorithms that exists in the world of supervised learning.

00:19.350 --> 00:21.690
So let's get started.

00:21.690 --> 00:27.910
We have our little breakdown of supervised versus unsupervised deep learning branches.

00:27.930 --> 00:32.160
And here we've got artificial neural networks which we've already talked about.

00:32.190 --> 00:35.940
We were talking about convolutional neural networks as well.

00:36.000 --> 00:38.750
And today we're talking about recurrent neural networks.

00:38.790 --> 00:45.030
So that just so that we see where we are in the big picture of things slowly getting to the unsupervised

00:45.330 --> 00:46.280
part of the course.

00:46.350 --> 00:49.770
But nevertheless that's focused on our own ends today.

00:49.770 --> 00:54.570
All right so now that we know where we are on the map in terms of a list let's have a look where we

00:54.570 --> 00:56.910
are on the map in terms of the human brain.

00:57.300 --> 01:02.210
And so why are we doing this why are we looking at the human brain as as if it's a map of the world.

01:02.340 --> 01:09.720
Well the reason for that is the whole concept behind deep learning is to try mimic the human brain and

01:09.750 --> 01:17.910
get kind of similar functions as the human brain has and leveraged the things that evolution has already

01:17.910 --> 01:18.890
developed for us.

01:18.900 --> 01:26.420
And I thought it would be pretty cool if we can somehow link the different branches of deep learning

01:26.430 --> 01:29.760
and we've discussed so we've talked about or the algorithms of discuss we've talked about.

01:29.770 --> 01:34.950
And then CNN and now we're talking about RNA and if we could link those to certain parts of the human

01:34.950 --> 01:35.940
brain.

01:36.300 --> 01:39.930
And if evolution make sense so let's have a look here.

01:39.960 --> 01:45.690
We've got the brain the human brain has got three parts of the cerebrum which is all of this colored

01:45.690 --> 01:46.320
part.

01:46.320 --> 01:49.880
Then we get the cerebellum which is underneath there and that's a little brain.

01:49.880 --> 01:52.680
I actually looked it up in Latin that does mean little brain.

01:52.690 --> 01:53.830
How funny is that.

01:54.060 --> 02:00.900
And we've already looked at does section of the cerebellum in the parlor talk about Amen's that orange

02:00.900 --> 02:07.320
that the that big orange picture where we saw all of those little neurons that we were trying to kind

02:07.320 --> 02:09.400
of gauge how many there are there.

02:09.420 --> 02:12.260
These millions of neurons in the brain.

02:12.600 --> 02:20.040
And then we've got the brain stem over here which connects the brain to the organs and her arms and

02:20.040 --> 02:21.380
legs and so on.

02:22.330 --> 02:25.140
And so that's how the brain.

02:25.150 --> 02:26.820
Those are the main three parts of the brain.

02:26.910 --> 02:31.080
Now the cerebrum has for Lopez and they're colored in here.

02:31.090 --> 02:33.390
So it's got the frontal lobe.

02:33.670 --> 02:38.540
It's got that temporal lobe it's got the parietal lobe and it's got the occipital lobe.

02:38.830 --> 02:41.530
And now how do we link these.

02:41.540 --> 02:42.860
Right so we've got.

02:42.880 --> 02:45.840
And then we've discussed CNN and Arnon.

02:46.210 --> 02:50.350
And the interesting is on probably was to start off with.

02:50.390 --> 02:54.260
And then because what is the main advantage of an ant.

02:54.280 --> 02:59.740
Well the main advantage the main breakthrough in and ends is apart from the back propagation algorithm

02:59.740 --> 03:01.480
which kind of applies to all of them.

03:01.510 --> 03:05.730
And in fact whatever applies to and applies to everything here.

03:05.740 --> 03:13.890
But for me I think the main thing about an ends and it wouldn't even exist without saying.

03:14.290 --> 03:18.240
This whole concept of the plural when you exist are the weights.

03:18.250 --> 03:26.980
The fact that a can learn through prior experience or through private airports and prior observations

03:27.010 --> 03:29.440
that's extremely valuable.

03:29.440 --> 03:32.740
And so what do those those weights represent.

03:32.740 --> 03:35.970
And moreover the weights of course are present across all neurons in the brain.

03:35.980 --> 03:42.160
But we're going to try to take away the main philosophical underlying notion there and that is that

03:42.280 --> 03:47.830
weights represent long term memory that once you run your own and then you've trained it you can switch

03:47.830 --> 03:53.230
it off you can come back later it's trained up you know the weights and so whatever inputs you put into

03:53.230 --> 03:59.130
it it will Prozess it the same way as it would yesterday as it will tomorrow as it will the day after.

03:59.320 --> 04:05.870
So the weights are long term memory of a neural network and that's why weights or the A-men go into

04:05.870 --> 04:06.500
a temporal lobe.

04:06.500 --> 04:13.180
Again the weights exist across the whole brain but philosophically and ends are a start to deploring

04:13.210 --> 04:15.070
and they represent long term memory.

04:15.070 --> 04:21.220
So we're going to put them in the temporal lobe because the temporal lobe lobe is responsible for long

04:21.220 --> 04:26.320
term memory hence it's called the temporal lobe meaning that lost things lost through time and their

04:27.070 --> 04:31.090
brain is very complex and of course other parts also responsible for memory as well.

04:31.210 --> 04:37.390
But we're going to simplify things and say an ant is like that temporal lobe then CNN is much easier.

04:37.420 --> 04:43.100
It's vision recognition of images and objects and so on and so that's the occipital lobe.

04:43.390 --> 04:45.530
And today we're talking about RNA ends.

04:45.550 --> 04:52.120
And as you'll find out our own ends are like a short term memory they can remember things that just

04:52.120 --> 04:56.620
happened in the previous couple of observations and apply that knowledge in that going forward.

04:56.620 --> 04:58.870
I'm giving away so much already.

04:58.900 --> 05:03.730
You like your pretty much no there as of this tutorial but nevertheless.

05:03.760 --> 05:07.050
So that's the frontal lobe that's where we have a lot of the short term memory.

05:07.060 --> 05:13.840
And of course the frontal lobe also like a quick breakdown of the frontal lobe also responds is responsible

05:13.840 --> 05:17.520
for personality behavior or motor cortex working memory.

05:17.890 --> 05:22.840
And like lots of other things but in our purposes the main thing that we were looking out for is the

05:22.840 --> 05:24.000
short term memory.

05:24.490 --> 05:25.740
By the way if you're interested.

05:25.840 --> 05:31.410
Temporal Lobe is the temporal lobe is concerned with for cognition memory.

05:31.780 --> 05:38.500
That's our long term memory at parietal lobe is and these are from Wikipedia the parietal lobe is something

05:38.500 --> 05:44.950
of a sensation and perception and constructing a spatial coordination system to represent the world

05:44.980 --> 05:51.850
around us and we are yet to create a neural network which would fit into that category and occipital

05:51.850 --> 05:52.970
is vision.

05:52.990 --> 05:59.910
All right so there you go a bit of neuroscience so let's move on to our favorite neural networks.

06:00.070 --> 06:04.850
So here we've got a simple artificial neural network three inputs to outputs one head.

06:05.560 --> 06:11.510
What does a Aren't And how do we we're present this as how do we represent or turn this into an RNA.

06:11.710 --> 06:14.860
Well we squash it we squash it all together.

06:14.860 --> 06:22.180
So they're still there but we think of it as if we're looking from underneath or from underneath this

06:23.500 --> 06:24.220
neural network.

06:24.220 --> 06:25.950
So we're looking in a new dimension.

06:25.950 --> 06:27.510
Right so we're looking.

06:27.700 --> 06:29.650
It's still there it's just flattened out.

06:29.650 --> 06:30.460
We're looking at.

06:30.700 --> 06:35.470
We're adding a new dimension to all of this but remember that those neurons the whole network is still

06:35.470 --> 06:35.650
there.

06:35.650 --> 06:40.960
Nothing changed we just question it for our purposes then to simplify things which is going to change

06:40.960 --> 06:42.420
these multiple hours into two.

06:42.430 --> 06:46.900
And we're going to twist this whole thing make it vertical because that's the stunning representation

06:47.290 --> 06:50.010
then in terms of neural networks we're going to call them instead of green.

06:50.020 --> 06:52.060
We're going to color the hidden layers in blue.

06:52.390 --> 06:53.310
And there we go.

06:53.350 --> 06:54.720
And we're going to add this line.

06:54.820 --> 06:56.500
And what does that line do.

06:56.500 --> 07:00.830
Well that line is the temporal loop.

07:00.940 --> 07:07.690
And this is an old school representation of our own ends and basically means that this hidden layer

07:07.810 --> 07:11.040
not only gives an output but also feeds back into itself.

07:11.050 --> 07:12.880
So again this is an optical representation.

07:12.880 --> 07:21.800
So the common kind of approach is now to unwind this or unroll this temporal loop and represent and

07:21.880 --> 07:27.350
ends in the following manner like that so you can see that again.

07:27.390 --> 07:32.580
Don't forget that we've got we've got lots of these things happening right so you're looking in a new

07:32.580 --> 07:36.650
dimension that the layers are actually still there they're still there.

07:36.810 --> 07:38.840
But we're just not focusing on them.

07:38.850 --> 07:44.480
We just remember that each one of these circles is not a one year on it's a whole layer of neurons.

07:44.580 --> 07:50.250
And so what is happening is you've got inputs coming into the neurons then you've got outputs but also

07:50.460 --> 07:53.860
the neurons are connecting to themselves through time.

07:54.090 --> 07:59.580
So that's the whole concept that they have some sort of memory short term memory that they remember

07:59.580 --> 08:02.540
what was in that neuron just previously or.

08:02.940 --> 08:07.530
And then the one before that or before that it used to remember what it was previous and that allows

08:07.530 --> 08:13.740
them to pass information onto themselves in the future and analyze things.

08:14.430 --> 08:17.910
Kind of like when you're you know when you're watching this course right.

08:17.910 --> 08:24.140
So it would be very sad if you could not remember what was happening in the previous tutorial.

08:24.150 --> 08:30.210
I mean even if we break time down discreetly through not by seconds but like continuously by seconds

08:30.210 --> 08:36.330
by discreetly through tutorials and we say like every moment in time and you tutorial it would be very

08:36.330 --> 08:41.100
sad if you did not remember what we had in the previous tutorial or in the previous section or in the

08:41.100 --> 08:42.470
previous part of the course.

08:42.510 --> 08:46.350
Right because then this whole recurrent neural networks part wouldn't makes any sense.

08:46.420 --> 08:51.810
You wouldn't have memory of what a neuron is what an activation function is but because you do remember

08:51.810 --> 08:54.240
those things you can understand this and same thing here.

08:54.240 --> 09:03.240
So how why would we deprive a artificial construct which is supposed to be a synthetic human brain or

09:03.240 --> 09:04.680
like a mimicking the human brain.

09:04.680 --> 09:10.860
Why would we deprived of something so powerful as short term memory long term memory is great but short

09:10.860 --> 09:15.690
term memory is so powerful why would we not give it that opportunity and that's where recurrent neural

09:15.690 --> 09:16.410
networks come in.

09:16.410 --> 09:18.550
That's the gap that they fill it.

09:19.140 --> 09:21.670
And so let's have a look at a couple of examples.

09:22.440 --> 09:25.950
A huge shout out to the car party blog capacity.

09:26.010 --> 09:28.590
Don't get that I owe some of these examples from here.

09:28.590 --> 09:33.750
So one to many relationship this is when you have one input and have multiple outputs.

09:33.750 --> 09:41.250
Example of this is an image where a computer describes the image you have one input the image and that

09:41.250 --> 09:44.270
would go through CNN and then would be fed into an orange.

09:44.940 --> 09:48.300
And then the computer would come up with words to describe the image.

09:48.300 --> 09:51.810
And this is an actual computer describing image.

09:51.810 --> 09:54.750
How accurate is that black and white dog jumps over bar.

09:54.750 --> 09:57.270
This is a computer looked at this image and it is like up.

09:57.330 --> 10:00.330
It's a black and white dot based on what it's previously learned.

10:00.330 --> 10:09.510
You know the long term memory allowed it to come up with weights and come up with certain feature feature

10:09.510 --> 10:14.970
feature recognition system and come up with the filters come up with everything that is required to

10:14.970 --> 10:20.340
CNN and then the Arnon allows it to make sense out of the sentence right so you can see that the sentence

10:20.340 --> 10:21.480
actually flows.

10:21.480 --> 10:29.790
You know there's a there's an and there's a lake over the bar and then it is like a verb there's a noun

10:29.820 --> 10:35.910
and so and so basically it allows the Arnon is what allows it to put a sentence together in this case

10:36.510 --> 10:37.970
then many to one would.

10:37.980 --> 10:40.610
An example would be sentiment analysis.

10:40.620 --> 10:48.270
So when you have a lot of text and from that text you kind of need to gauge is it other people.

10:48.270 --> 10:53.030
Is this like a positive comment or a negative comment what's the chance that it's a positive or how

10:53.100 --> 10:55.170
positive or negative is that comment.

10:55.290 --> 10:57.360
And you've got an example here as well.

10:57.840 --> 11:01.220
And again there's lots of other different examples these are just some.

11:01.480 --> 11:03.760
Then we've got many too many for instance.

11:03.780 --> 11:05.830
All you wanted to show you this one.

11:06.480 --> 11:12.680
So here we've got an example of Google translator and I don't know if Google translator uses Arnalds

11:12.690 --> 11:13.070
or not.

11:13.080 --> 11:18.840
I know that they have very sophisticated deep learning and Google mind and I've heard that they've used

11:18.840 --> 11:21.450
that in their Android systems and so on.

11:21.510 --> 11:24.990
I'm not sure if they use Arnett's here or not but the concept remains.

11:24.990 --> 11:30.860
So if I say here from English to check I say I am a boy who likes to learn.

11:31.080 --> 11:33.280
You cloak it out of it.

11:33.330 --> 11:33.540
Right.

11:33.570 --> 11:42.510
And basically in other languages in some other languages it is important what gender a person is right.

11:42.510 --> 11:43.880
So here boy is male.

11:43.890 --> 11:46.480
So that's why he's got Terry arat.

11:46.680 --> 11:54.420
And if you see if I change this to girl in English the other words don't change but in check the other

11:54.420 --> 12:00.410
words change you said Holker caetera Aranda said it so you can see right away.

12:00.420 --> 12:08.580
Now it's not entirely a rat it's caetera meaning that these words they depend on the gender of this

12:08.580 --> 12:15.630
word Holker and Holker is a girl and therefore this becomes caetera rather and again I don't know for

12:15.630 --> 12:19.550
Google translate these are an enemy who are going to comment on that.

12:19.560 --> 12:27.340
But basically the concept is the same that you need short term information about the previous word in

12:27.340 --> 12:32.350
order to translate the next we're right you can't just translate word by word and it's just a simple

12:32.350 --> 12:36.760
example and of course it makes to make a sentence makes sense.

12:36.880 --> 12:43.810
You do need information about the words but like a very visual example we have here is that the at the

12:43.950 --> 12:50.170
at the least you need to know the gender of this word to in order to translate the following words for

12:50.170 --> 12:51.330
the sentence to make sense.

12:51.430 --> 12:58.160
And that's where our own ends have power because they have short term memory and they can do these things.

12:58.180 --> 12:59.640
So there we go that's a many to many.

12:59.640 --> 13:02.560
You put in lots of words and then you get lots of words out that's translation.

13:02.560 --> 13:08.380
And of course not every example has to be related to text or images there can be lots and lots of different

13:08.380 --> 13:09.370
applications of ordnance.

13:09.370 --> 13:17.740
For instance many too many you can use are an ends to subtitle movies meaning that you can have running

13:17.740 --> 13:23.410
style So basically or describe every single frame in a movie and that is something you can simply do

13:23.410 --> 13:29.080
with a CNN or other neural networks because if you're watching a movie you need context about what happened

13:29.080 --> 13:31.850
previously to describe what's happening now.

13:31.960 --> 13:36.340
And so you need that short term memory you can't just run around through a million movies and kind of

13:36.580 --> 13:42.670
understand the whole plot that is going to happen you need short term memory of the plot to be able

13:42.670 --> 13:44.490
to comment on every single frame.

13:44.740 --> 13:50.350
And speaking of movies today we don't have additional reading to day we have additional watching.

13:50.380 --> 13:58.320
So a movie called some spring in 2016 directed by Oscar Sharpe and it's got you know this actor almost

13:58.330 --> 14:07.000
middle age from TV shows Silicon Valley and this movie was entirely written by Benjamin who is a Arnon

14:07.230 --> 14:12.010
and elist to be specific so I'm going to show you this movie now.

14:12.820 --> 14:13.740
You are not going to play it.

14:13.750 --> 14:17.620
I'm just not sure which find it so unique because it ARS Technica it's only nine minutes long.

14:17.620 --> 14:18.670
I highly recommend it.

14:18.670 --> 14:19.950
I've seen it twice.

14:19.990 --> 14:24.060
It's so it's so fun like you will find that.

14:24.190 --> 14:24.940
So a couple of things.

14:24.950 --> 14:29.440
There's a great description here as well so we're reading through it there's actually an interview Benjamin

14:29.440 --> 14:31.600
and he actually gave himself the name of Benjamin.

14:31.600 --> 14:33.210
That's why they call him Benjamin.

14:33.310 --> 14:40.390
Is this really cool to see these things and what you'll find about movie is the acting is amazing just

14:40.450 --> 14:41.090
amazing.

14:41.080 --> 14:50.020
Like I had shivers down my spine towards and it got in the top 10 in London in the London Sci-Fi in

14:50.020 --> 14:51.420
the Sci-Fi London Festival.

14:51.640 --> 14:57.880
And then what you'll find is that Benjamin is able to construct sentences which kind of like makes sense

14:57.970 --> 15:03.430
for the most part which is good but what he lacks is kind of the bigger picture.

15:03.460 --> 15:10.150
He cannot come up with a plot that constantly makes sense even that even though the actors do a great

15:10.150 --> 15:14.410
job about putting it together and it does look amazing in the end.

15:14.410 --> 15:19.570
But you will notice and kind of look out for this and separate when you're watching separate the sentences

15:19.630 --> 15:24.240
and you'll see that each sentence on its own more or less 90 percent of the time makes sense.

15:24.280 --> 15:29.680
But overall he cannot properly link sentences together and that's that's a next step for our and ends

15:29.680 --> 15:34.900
where you know this is still quite a new technology or it's only picking up recently so it will be developed

15:34.900 --> 15:40.180
very soon and maybe when you're watching this tutorial you're laughing in the future to five years from

15:40.180 --> 15:44.350
now you're laughing to herself and you're saying oh we've already passed that milestone and probably

15:44.350 --> 15:45.190
we will very soon.

15:45.190 --> 15:47.160
But this is where things are now.

15:47.170 --> 15:49.150
And I highly recommend checking this out.

15:49.210 --> 15:51.400
Only nine minutes long.

15:51.520 --> 15:53.360
So there we go that's what Iranians are.

15:53.380 --> 15:54.170
In a nutshell.

15:54.190 --> 15:59.710
And in the next tutorial we will continue digging deeper look for the next time.

15:59.710 --> 16:01.240
Until then enjoy learning.
