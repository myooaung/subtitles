WEBVTT
1
00:00:06.300 --> 00:00:11.120
Welcome to our last lecture about SPARK data frames where we're going to be discussing working the dates

2
00:00:11.220 --> 00:00:17.310
and time stamps up over the Jupiter notebook and work again with some historical stock data and work

3
00:00:17.310 --> 00:00:25.010
with that date column OK I've opened up a Jupiter notebook and I've imported Sparke session and I created

4
00:00:25.010 --> 00:00:27.470
a spark session called dates.

5
00:00:27.500 --> 00:00:32.060
You can feel free to use any Sparke session that you've done the past and from the spark session I will

6
00:00:32.060 --> 00:00:40.030
say physical to spark read that CXXVI and I'm going to read in the Apple stock cxxviii from earlier

7
00:00:40.710 --> 00:00:45.390
and we'll call it letter is true and will last say in for schema to be true.

8
00:00:45.650 --> 00:00:51.580
That way we can actually see that we have the date objects.

9
00:00:51.590 --> 00:00:58.760
So if I say if I had one I can see that the very first item is a date time date time object and that's

10
00:00:58.760 --> 00:01:00.800
how Python deals with date time objects.

11
00:01:00.800 --> 00:01:02.720
And you can see it has some information.

12
00:01:02.720 --> 00:01:09.860
The year 2010 the month is one day is 4 and then hours 0 minutes are 0 and actually for all of these

13
00:01:10.190 --> 00:01:12.550
they're all going to have the same minute and hour 00.

14
00:01:12.590 --> 00:01:18.320
So for example let me show you the actual data frame itself.

15
00:01:18.380 --> 00:01:23.120
Now looks a little messed up here because I'm kind of zoomed in and there's just not enough space to

16
00:01:23.120 --> 00:01:24.330
display everything.

17
00:01:24.560 --> 00:01:26.300
So that gives you a neater picture.

18
00:01:26.300 --> 00:01:28.810
You select and just show two columns.

19
00:01:28.850 --> 00:01:33.530
So I'll show the date column and maybe I'll also show the opening price column.

20
00:01:33.530 --> 00:01:39.740
So we run that and we can see we have the date column has the year the month the day and then the hours

21
00:01:40.160 --> 00:01:45.570
minutes and even some seconds depending on how many seconds are nanoseconds etcetera.

22
00:01:45.590 --> 00:01:50.670
But we can see that they all basically be at the very beginning of the day hours 0 minutes.

23
00:01:50.810 --> 00:01:56.040
So we're going to basically show you how you can extract information from this date time object.

24
00:01:56.180 --> 00:02:01.610
And essentially what it all comes down to is importing the right function and then applying it.

25
00:02:01.910 --> 00:02:05.280
Let me hash tag this out run this again.

26
00:02:05.660 --> 00:02:09.390
And now I'm going to walk through some functions that you may find useful.

27
00:02:09.590 --> 00:02:16.550
We'll say from PI spark thought sequel functions import and then some really useful ones.

28
00:02:16.550 --> 00:02:20.820
We're not going to go through all of these but I do want you to be aware of all of them is day of month

29
00:02:20.830 --> 00:02:23.180
and you want to extract the actual day of the month.

30
00:02:23.190 --> 00:02:26.660
There's our There's the day of year is another one.

31
00:02:26.810 --> 00:02:29.750
So that's like was it the first day of the year or the 40th day of the year.

32
00:02:29.750 --> 00:02:30.490
Cetera.

33
00:02:30.680 --> 00:02:38.000
There's also a month or so first second third month etc. what year it was so year 2010 year 2011 stuff

34
00:02:38.000 --> 00:02:39.290
like that.

35
00:02:39.340 --> 00:02:41.640
Now let me kind of put these on multiple lines.

36
00:02:41.870 --> 00:02:46.490
So years another one there's also week of year which is kind of an interesting one so goes you know

37
00:02:46.730 --> 00:02:51.680
anywhere from the first week of the year to the 50 second week of the year and then we'll continue on

38
00:02:51.980 --> 00:02:57.590
to some formatting and so format number which we've seen before may be useful to us later on.

39
00:02:57.680 --> 00:03:02.870
But there's also data formats which you may find useful if you want to format your data in a particular

40
00:03:02.870 --> 00:03:03.260
manner.

41
00:03:03.270 --> 00:03:07.070
So I'm going to import all of those and just show you how to use them.

42
00:03:07.190 --> 00:03:11.330
We won't walk through every single one because it'll get a little repetitive but you should be aware

43
00:03:11.330 --> 00:03:12.620
of how to use them.

44
00:03:12.730 --> 00:03:18.360
Basically whenever using any PI sparked thought sequela function you say select and then you just call

45
00:03:18.360 --> 00:03:22.550
the function on whatever column you want and you have to pass in the actual column meaning you have

46
00:03:22.550 --> 00:03:24.240
to use that bracket notation.

47
00:03:24.470 --> 00:03:33.790
So for example let's grab the day of the month and let's pass and DMF date and show those results.

48
00:03:33.960 --> 00:03:37.100
And here we can see we have day of month dates.

49
00:03:37.310 --> 00:03:38.720
And I can actually see the day of the month.

50
00:03:38.720 --> 00:03:39.800
Was it the fourth the fifth.

51
00:03:39.820 --> 00:03:41.070
Six seven eight.

52
00:03:41.070 --> 00:03:41.610
Cetera.

53
00:03:41.610 --> 00:03:45.270
And you can see here that we're actually skipping weekends which is why some of these dates kind of

54
00:03:45.270 --> 00:03:46.800
have some gaps in between them.

55
00:03:47.010 --> 00:03:48.020
So that makes sense.

56
00:03:48.180 --> 00:03:49.930
Let's kind of show you another example.

57
00:03:50.130 --> 00:03:52.680
Let's confirm that it all starts at the beginning of the day.

58
00:03:52.700 --> 00:03:53.610
Biographic hour.

59
00:03:53.610 --> 00:03:55.070
So these should all be zero.

60
00:03:55.560 --> 00:04:02.120
And there we can see it was all zeros maybe we want to see some more information like what month was

61
00:04:02.120 --> 00:04:02.610
it.

62
00:04:02.960 --> 00:04:04.650
So the actual month it was.

63
00:04:04.700 --> 00:04:07.920
If you run that should all be the very first month or January.

64
00:04:08.150 --> 00:04:09.190
And we can continue on.

65
00:04:09.190 --> 00:04:10.610
It's only showing the top 20 rows.

66
00:04:10.640 --> 00:04:11.570
You can see here.

67
00:04:11.570 --> 00:04:14.500
February started to appear at the very bottom of that.

68
00:04:14.870 --> 00:04:16.660
And that's basically the gist of it.

69
00:04:16.730 --> 00:04:20.200
So let's kind of show a different example.

70
00:04:20.270 --> 00:04:24.450
Maybe we wanted to know the average closing price per year.

71
00:04:24.620 --> 00:04:29.340
So this may be a more realistic assignments if you want to know the average closing price per year.

72
00:04:29.450 --> 00:04:33.070
We can use these functions right here to actually grab that.

73
00:04:33.080 --> 00:04:35.840
So it's going to be in several steps.

74
00:04:35.950 --> 00:04:44.280
I will select passen year on the date column and let me just show you what that looks like.

75
00:04:44.430 --> 00:04:50.920
So I can see here it all starts from 2010 and then what I end up doing is I'm going to use with column

76
00:04:51.250 --> 00:04:53.440
to create a new column called The Year.

77
00:04:53.470 --> 00:04:57.230
So let's kind of hash tag that out and build that out.

78
00:04:57.640 --> 00:05:04.650
So we will say if with column remember that's how we can create a new column or create a new column

79
00:05:04.650 --> 00:05:14.150
called The Year and it will be year function called on the dates and just to show what that looks like

80
00:05:14.150 --> 00:05:15.530
it's going to be pretty messy.

81
00:05:15.650 --> 00:05:19.130
But I just want to show that there is some year column at the very end.

82
00:05:19.370 --> 00:05:23.540
So at the very end though we're here I can see that there is a year column and it's right here.

83
00:05:23.540 --> 00:05:24.250
2010.

84
00:05:24.260 --> 00:05:26.640
2010 2010 etc..

85
00:05:26.780 --> 00:05:27.590
Great.

86
00:05:27.590 --> 00:05:31.680
So what we're going to do is put this as a new data frame.

87
00:05:33.560 --> 00:05:39.470
A cool new idea is equal to the fifth column and I will delete that show because I'm just saving it

88
00:05:39.470 --> 00:05:40.620
instead of showing it.

89
00:05:40.970 --> 00:05:44.070
So there's new death and then off of new DNA.

90
00:05:44.090 --> 00:05:49.280
Remember my goal here is to show the average closing price per year.

91
00:05:49.490 --> 00:05:52.300
So there's more than one year in this actual result.

92
00:05:52.490 --> 00:05:59.930
I want to go into a new leaf group by that newly created your column and then I want the average saw

93
00:05:59.930 --> 00:06:07.140
just call me off of this and let's just show what happens when we do this so running this I can see

94
00:06:07.140 --> 00:06:11.940
the average but I'm actually averaging everything by the year so it's getting kind of sloppy.

95
00:06:11.940 --> 00:06:17.040
All I want to know is the average closing price per year so let's just select those and I'm going to

96
00:06:17.040 --> 00:06:19.880
select those off with this column.

97
00:06:19.900 --> 00:06:21.460
There's various ways to do this.

98
00:06:21.510 --> 00:06:29.440
And one way we can do it is just say select But remember these are now called average and year.

99
00:06:29.520 --> 00:06:35.050
And what's a little funny is that it says average year over here so we can just say year as well.

100
00:06:35.190 --> 00:06:36.620
So let's do that.

101
00:06:36.660 --> 00:06:41.210
I'm going to say year let's pass this in in brackets.

102
00:06:42.490 --> 00:06:49.300
And then the next one I want let's close those brackets is going to be very close to the average close

103
00:06:50.510 --> 00:06:53.090
average open average close you can kind of explore whatever you want.

104
00:06:53.090 --> 00:06:56.480
The main ideas used in this group by date time functionality.

105
00:06:56.640 --> 00:07:04.310
And if I show this I can see here that I have now the average closing price per year 2015 2013 etc..

106
00:07:04.370 --> 00:07:07.340
So let me actually save that as a result.

107
00:07:08.520 --> 00:07:12.340
Because I still want to format this a little more just looks a little nicer.

108
00:07:12.540 --> 00:07:14.360
So we'll say result.

109
00:07:14.580 --> 00:07:21.270
And now if I show this result it's the exact same thing but I want to fix this significant issue maybe

110
00:07:21.510 --> 00:07:22.530
order these.

111
00:07:22.530 --> 00:07:26.030
And also maybe change this average close.

112
00:07:26.150 --> 00:07:36.850
So we'll say here with column renamed and I'm going to rename average close

113
00:07:39.130 --> 00:07:43.000
and I want this to be called maybe like

114
00:07:45.670 --> 00:07:54.310
average I don't know average closing price just something a little nicer and let's actually show this

115
00:07:54.320 --> 00:07:55.410
make sure it all worked out.

116
00:07:56.740 --> 00:07:59.420
So we see average closing price so that's looking pretty good.

117
00:07:59.660 --> 00:08:01.860
So I'll say this as a result.

118
00:08:02.060 --> 00:08:05.680
Well let's call it new.

119
00:08:05.680 --> 00:08:10.330
Does it really matter what you call it because it still wants whip's excellently had show there.

120
00:08:10.340 --> 00:08:12.150
So I don't want show when I'm saving it.

121
00:08:12.170 --> 00:08:13.180
There we go.

122
00:08:13.190 --> 00:08:21.150
And now for this new the last thing I want to do is actually format that number so we'll say new selects

123
00:08:21.660 --> 00:08:28.640
and I'm going to select in this case we'll call it average closing price because that's what the name

124
00:08:28.640 --> 00:08:29.870
of the column is now.

125
00:08:30.200 --> 00:08:35.930
So I want to select the average closing price and I'm going to pass format number around it.

126
00:08:36.080 --> 00:08:44.620
So we'll say select Format number and as the second argument I'm going to pass in two digits and then

127
00:08:44.620 --> 00:08:46.080
we'll close parentheses.

128
00:08:46.480 --> 00:08:49.710
And I'm also going to passen I want the year column as well.

129
00:08:50.980 --> 00:08:53.660
And I always play it safe and pass this in as a list.

130
00:08:53.720 --> 00:08:58.130
It should technically work even if we don't pass in a list but better just in case.

131
00:08:58.190 --> 00:09:04.560
And let's run this and see what happens if we show this.

132
00:09:04.770 --> 00:09:06.660
And there it is again the issue is here.

133
00:09:06.660 --> 00:09:11.520
So we have forment number etc. so I probably shouldn't have wasted my time with the column renamed.

134
00:09:11.520 --> 00:09:13.280
That's something that I kind of always forget.

135
00:09:13.410 --> 00:09:15.640
So we can just easily fixed that with alias.

136
00:09:16.080 --> 00:09:20.240
So we'll say average close run that again.

137
00:09:20.310 --> 00:09:22.910
And here I can see average close looking nice.

138
00:09:22.910 --> 00:09:24.650
And then is also looking nice.

139
00:09:24.900 --> 00:09:29.940
Hopefully that kind of gave you an idea of some more realistic operations when dealing with date time.

140
00:09:29.940 --> 00:09:36.180
So a really common exercise is to have that date column some sort of date time object extract information

141
00:09:36.180 --> 00:09:39.550
from it and then possibly do an order by or a group by.

142
00:09:39.550 --> 00:09:44.630
Or some sort of functionality off of that extract that information from the date.

143
00:09:44.640 --> 00:09:50.610
The basic idea though is if you just scroll up here there's functions in Paice sparked up sequel that

144
00:09:50.610 --> 00:09:52.340
relate to dates and time stamps.

145
00:09:52.410 --> 00:09:56.850
You just apply it extract the information and then do whatever you want with that information.

146
00:09:56.850 --> 00:09:57.480
All right.

147
00:09:57.610 --> 00:09:59.070
Put that was pretty straightforward.

148
00:09:59.280 --> 00:10:01.830
Feel free to ask any questions in the Q&amp;A forums.

149
00:10:01.830 --> 00:10:03.530
I'll see you at the next section of the course.
