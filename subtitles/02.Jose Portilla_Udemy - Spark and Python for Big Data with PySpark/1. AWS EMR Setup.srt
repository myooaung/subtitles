1
00:00:05,620 --> 00:00:12,450
Hello everyone and welcome to the Amazon Web Services elastic map reduce set up lecture if you ever

2
00:00:12,450 --> 00:00:18,270
want to quickly set up a cluster of a notebook interface Amazon Web Services elastic map reader service

3
00:00:18,330 --> 00:00:19,820
is actually a really good choice.

4
00:00:19,860 --> 00:00:24,600
But please know where we're going to be showing in this lecture does not fall under the free trial of

5
00:00:24,600 --> 00:00:25,530
a.

6
00:00:25,620 --> 00:00:32,090
You will be charged and depending on what kind of instance you do how large a cluster is the price varies

7
00:00:32,100 --> 00:00:36,930
so definitely check out Amazon's own official documentation for pricing to get the latest pricing and

8
00:00:36,930 --> 00:00:38,570
how much this would actually cost you.

9
00:00:40,210 --> 00:00:45,160
And this particular lecture we're going to walk through is setting up the zipline notebook on AWOS EMR

10
00:00:45,580 --> 00:00:50,530
and we're also going to discuss some security options and I highly recommend you watch to E.S. to instance

11
00:00:50,530 --> 00:00:56,200
lecture's first before watching this particular lecture to learn more about S-sh in case of something

12
00:00:56,200 --> 00:00:58,110
you see yourself doing in the future.

13
00:00:59,420 --> 00:01:03,890
Now the zipline notebook is a fairly new environment that mimics a lot of the cheaper Jupiter notebooks

14
00:01:03,890 --> 00:01:10,950
capabilities but it was created specifically of big data in mind things like Sparc and Hadoop where

15
00:01:11,010 --> 00:01:15,550
we were going to do as quickly explore with zipline up looks like on their official documentation page

16
00:01:15,820 --> 00:01:22,020
and then go through the process of setting up our own on AWOS EMR and creating a cluster and AWOS earmark

17
00:01:22,020 --> 00:01:23,800
can take a while to initialize.

18
00:01:23,800 --> 00:01:28,620
So while initializing the master node in the slave nodes we're going to show you how to set up the security.

19
00:01:28,690 --> 00:01:30,750
So take some time with this.

20
00:01:30,970 --> 00:01:37,750
The actual cluster creation process is really fast but AWOS on there and setting up servers Sometimes

21
00:01:37,750 --> 00:01:42,570
it takes a little while and there we're also going to talk about security settings as we set up the

22
00:01:42,570 --> 00:01:44,550
zipline notebook running on EMR.

23
00:01:44,550 --> 00:01:48,120
I really want to stress here that make sure to read through the resource documentation to choose the

24
00:01:48,120 --> 00:01:50,890
best security settings for you or your organization.

25
00:01:50,910 --> 00:01:56,180
The way we're doing it here may not be secure enough for your needs OK.

26
00:01:56,370 --> 00:01:58,470
Let's get started and jump into the documentation.

27
00:01:58,500 --> 00:02:00,660
I'm going to go up on that Apache the org.

28
00:02:00,780 --> 00:02:06,090
And afterwards we're going to log into our AWOS consul AWOS to Amazon.com and show you how you can go

29
00:02:06,090 --> 00:02:08,370
to the EMR OK.

30
00:02:08,390 --> 00:02:10,470
Here I am at Zeppelin that Apache or.

31
00:02:10,670 --> 00:02:15,860
This is the official documentation page and this is basically almost like a Jupiter notebook except

32
00:02:15,860 --> 00:02:21,390
like I said it's really designed to support a lot of different big data Bacchantes things like sequel

33
00:02:21,390 --> 00:02:28,340
Scalia's spark Hadoop those kind of things hive etc. and the current version is 0.7 at this point in

34
00:02:28,340 --> 00:02:32,330
time and they've added a couple new things things like multi-user support.

35
00:02:32,450 --> 00:02:34,760
A lot of improvements in Python which is good for us.

36
00:02:34,910 --> 00:02:38,600
And then they integrate them at Port lib into some of that Python stuff.

37
00:02:38,600 --> 00:02:44,740
Plus they now support SPARC 2.1 which at this point in filming is the latest version of SPARC Now if

38
00:02:44,740 --> 00:02:49,780
you just want a general idea of what is Apache's upline is a multipurpose notebook for data discovery

39
00:02:49,780 --> 00:02:54,060
data analytics and also has some visualization capabilities built into it.

40
00:02:54,340 --> 00:02:59,320
And more importantly it supports lots of language Balcones so you can see here it supports things that

41
00:02:59,320 --> 00:03:01,000
Cassandra are hive.

42
00:03:01,060 --> 00:03:04,270
Flink a classic search Python HFS etc..

43
00:03:04,480 --> 00:03:09,500
So lots and lots of stuff that Zeppelin can support a lot more than just the Jupiter note book itself

44
00:03:09,970 --> 00:03:17,440
and really what's its main key point is that especially Apache's Zeppelin provides built in SPARC integration

45
00:03:17,770 --> 00:03:23,260
so it's really designed with SPARC in mind and everything else is kind of built on top of that plus

46
00:03:23,260 --> 00:03:28,640
has data visualizations and dynamic forms and really strong support for Sparc sequel.

47
00:03:28,960 --> 00:03:32,310
So you can always just check out the documentation here by clicking on this.

48
00:03:32,620 --> 00:03:38,890
And then if you go to 0.7 point one he'll talk a lot more about some of the QuickStart capabilities

49
00:03:38,890 --> 00:03:45,010
so configuring it tutorials dynamic forums etc. and I encourage you to explore as documentation if you

50
00:03:45,010 --> 00:03:47,970
think zipline up is something you're going to be using in the future.

51
00:03:48,130 --> 00:03:52,210
But what I'm going to do now is basically walk through the process of setting everything up.

52
00:03:52,210 --> 00:03:54,680
So let's jump over to our AWOS console.

53
00:03:55,660 --> 00:03:55,900
All right.

54
00:03:55,900 --> 00:04:02,560
Once you log in to AWOS thought Amazon.com you should be able to search for AWOS services or you can

55
00:04:02,560 --> 00:04:05,380
always just click here and look at the various services.

56
00:04:05,470 --> 00:04:07,450
But what we're going to be using is EMR.

57
00:04:07,450 --> 00:04:13,530
So if you either search for EMR or the classic map reduce it should be some manage the framework.

58
00:04:13,600 --> 00:04:17,740
So click on that and then you have these options of creating clusters.

59
00:04:17,740 --> 00:04:20,770
You can see here already had a cluster that's been terminated.

60
00:04:20,920 --> 00:04:22,680
So click here and create cluster.

61
00:04:22,690 --> 00:04:27,580
This is your first line you're probably the have one yet and then you'll be taken to this page and what

62
00:04:27,580 --> 00:04:34,430
you want to do is give the cluster a name so we can say like you cluster or whatever you want you can

63
00:04:34,430 --> 00:04:37,720
link it up to three folder if you want to do that.

64
00:04:37,820 --> 00:04:41,690
And more importantly down here on the software configuration what we're going to be choosing is all

65
00:04:41,690 --> 00:04:45,830
the way here at the bottom where it says Sparc and Zeppelin.

66
00:04:45,830 --> 00:04:47,420
And that's what you want to make sure is included.

67
00:04:47,420 --> 00:04:51,620
So maybe these applications will show in a different order for you but definitely make sure that it

68
00:04:51,620 --> 00:04:56,030
shows spark and I can zoom in here to make it a little clearer and zipline up look.

69
00:04:56,060 --> 00:04:57,290
That's what we need.

70
00:04:57,290 --> 00:05:02,300
And then as far as hardware configuration This is where based off your needs if you want more power

71
00:05:02,630 --> 00:05:05,730
or more storage or faster computing.

72
00:05:05,870 --> 00:05:10,970
You can choose different types of instances and you basically choose one master and then however many

73
00:05:10,970 --> 00:05:16,970
core nodes you want and you can set the instance type and the number of instances here.

74
00:05:17,020 --> 00:05:18,990
I'm going to stick to the default so large.

75
00:05:19,000 --> 00:05:24,250
But if you want to make it a little cheaper you can come over here and go to like medium of the previous

76
00:05:24,250 --> 00:05:25,390
generation.

77
00:05:25,450 --> 00:05:26,740
It's really up to you.

78
00:05:26,770 --> 00:05:28,630
We can even just stick to medium.

79
00:05:28,660 --> 00:05:32,320
Then finally you have the security and access options.

80
00:05:32,500 --> 00:05:36,770
The most basic option is just to proceed to thought and easy to keep there.

81
00:05:36,850 --> 00:05:41,440
That's kind of a lower security option that means if someone doesn't have that key pair they can still

82
00:05:41,710 --> 00:05:45,650
access your instance as long as they know the actual address to locate it at.

83
00:05:45,730 --> 00:05:49,240
If you're thinking of just going through this one time and you just kind of want to get the feel of

84
00:05:49,240 --> 00:05:53,590
creating the cluster and you're immediately going to shut it down then go ahead and proceed to an easy

85
00:05:53,590 --> 00:05:54,600
to key pair.

86
00:05:54,610 --> 00:05:56,240
It's really easy you don't really need it.

87
00:05:56,320 --> 00:06:01,930
But let me briefly explain in case you didn't watch the E.C two lectures how you can create an easy

88
00:06:01,930 --> 00:06:07,240
to keep here all you have to do is click over here on learn how to create nice to keep there and you

89
00:06:07,240 --> 00:06:11,130
just come over here follow these instructions to actually create an easy to keep there.

90
00:06:11,170 --> 00:06:12,210
It's pretty straightforward.

91
00:06:12,220 --> 00:06:14,620
Just come here to the Amazon easy to con..

92
00:06:14,620 --> 00:06:21,190
Go to click key peers create a keep pair click create and save the resulting T.M. file in a safe location

93
00:06:21,880 --> 00:06:25,310
and then you're going to need to modify your pen file.

94
00:06:25,480 --> 00:06:30,570
If you are on a Windows or Mac so there's instructions here on how to do this on Windows.

95
00:06:30,630 --> 00:06:33,690
And if you click here on this tab there's instructions on how to do it on a Mac.

96
00:06:34,590 --> 00:06:39,390
Since you may or may not have done this before I'm going to briefly create a new key pair that you can

97
00:06:39,390 --> 00:06:44,390
actually see how this works I'm willing to open my Amazon easy to con..

98
00:06:44,460 --> 00:06:48,150
In a new window and click on key pairs in the navigation pane.

99
00:06:48,470 --> 00:06:53,650
So I come here to my console and going to see key pairs here.

100
00:06:53,660 --> 00:07:01,520
I've already created some but let's just make another one point click here on create key pair and typing

101
00:07:01,570 --> 00:07:02,960
you create keep your name.

102
00:07:02,960 --> 00:07:12,830
So for instance we'll call this my sparkie click on Create once you created that new key pair it should

103
00:07:12,890 --> 00:07:16,020
automatically have downloaded that p e m file.

104
00:07:16,220 --> 00:07:19,040
It's really important that you remember where this PTM file is.

105
00:07:19,040 --> 00:07:22,370
You basically don't get another chance to download another one.

106
00:07:22,430 --> 00:07:27,350
So make sure you know the location of this PTM file you just created and downloaded.

107
00:07:27,410 --> 00:07:32,630
All right so once you have that file make sure you save it to a location that you remember going back

108
00:07:32,630 --> 00:07:39,220
here to our set up keep there once you have that pgm or pen file in a safe location.

109
00:07:39,260 --> 00:07:46,710
You're probably going to need to modify a file in order to S-sh or securely connect to your cluster.

110
00:07:46,730 --> 00:07:51,890
Now modifying the pimp files a little different depending on whether you're on a Mac or Linux or Windows

111
00:07:51,890 --> 00:07:52,630
computer.

112
00:07:52,790 --> 00:07:56,960
Amazon Web Services actually has really nice instructions for either version.

113
00:07:56,980 --> 00:08:02,020
But basically if you're on a Mac or Linux you're just going to open up your terminal and type this command

114
00:08:02,030 --> 00:08:06,180
you're going to say S.H. maade space O.G. dash R W X.

115
00:08:06,290 --> 00:08:10,390
And then Mikey Peridot PM or whatever you're called your key pair.

116
00:08:10,400 --> 00:08:16,880
Now remember you have to be at the same directory directory location where you saved your dot file.

117
00:08:16,880 --> 00:08:20,010
Now if you're on Windows it's going to be a little more involved.

118
00:08:20,060 --> 00:08:23,000
You have to download Agent X to your computer.

119
00:08:23,000 --> 00:08:24,870
There's a link right here to download it.

120
00:08:24,920 --> 00:08:27,870
You're going to launch the puttee then click load.

121
00:08:27,950 --> 00:08:33,530
Select the PM file you created earlier click open then click OK on the page and notice telling you your

122
00:08:33,530 --> 00:08:35,180
key was successfully imported.

123
00:08:35,360 --> 00:08:38,180
Enter a passphrase in the key passphrase field.

124
00:08:38,450 --> 00:08:46,190
Click Save private key save it in a PPK format that's the format Windows needs for S-sh into a cluster

125
00:08:47,030 --> 00:08:52,520
and then you're going to name your petty private key such as my key Peridot PPK click save and then

126
00:08:52,580 --> 00:08:54,630
exit the PATTI-JANE application.

127
00:08:54,680 --> 00:08:58,490
OK so go ahead and do that whether you're on a Windows or Mac.

128
00:08:58,490 --> 00:09:00,660
Take care of this PTM file.

129
00:09:00,670 --> 00:09:01,360
I'm going know Windows.

130
00:09:01,370 --> 00:09:03,700
I'll be using this putty generate now.

131
00:09:03,770 --> 00:09:04,990
Windows is a little more involved.

132
00:09:05,000 --> 00:09:08,550
But again Amazon Web Services is really good documentation on this.

133
00:09:08,570 --> 00:09:11,860
If you ever get stuck you can either just look at these steps.

134
00:09:11,900 --> 00:09:17,120
Pretty straightforward or just google search AWOS S-sh easy to keep.

135
00:09:17,130 --> 00:09:18,330
Or something similar.

136
00:09:18,410 --> 00:09:23,350
And Amazon EMR has a whole management guide on how to do this step by step.

137
00:09:23,420 --> 00:09:25,130
So I'm going to close this.

138
00:09:25,250 --> 00:09:26,810
Again the instructions are always here for you.

139
00:09:26,840 --> 00:09:29,290
Just how to create an easy to keep there.

140
00:09:29,540 --> 00:09:34,760
I'm going to choose the one you see to keep.

141
00:09:34,760 --> 00:09:42,280
I just made which was my Sparke key and then I'm going to come down here and click on Create cluster

142
00:09:44,650 --> 00:09:47,050
and that's going to be creating your cluster right now.

143
00:09:47,050 --> 00:09:51,020
Now it usually takes a couple of minutes to actually fully create the cluster.

144
00:09:51,070 --> 00:09:56,020
So you may need to just wait a little while it's going to say starting for a little bit but it's actually

145
00:09:56,020 --> 00:10:01,780
creating a cluster right now and it has the Miss spark key for security and access.

146
00:10:02,120 --> 00:10:07,000
OK what you're waiting for your cluster to actually initialize what you want to do is make sure that

147
00:10:07,000 --> 00:10:11,250
you're going to be able to s s h into your Zeppelin notebook.

148
00:10:11,440 --> 00:10:15,500
And for that you may need to change the security settings so what are you going to do.

149
00:10:15,520 --> 00:10:17,280
Under security and access.

150
00:10:17,350 --> 00:10:25,120
Come here and click on security groups for Master now I'll take you to this link on security groups.

151
00:10:25,120 --> 00:10:25,440
All right.

152
00:10:25,450 --> 00:10:31,890
Once you're on this security group page where you're going to do is select the map reduce M..

153
00:10:31,990 --> 00:10:35,630
Click here and you should see the security groups.

154
00:10:35,650 --> 00:10:39,880
And if you click on inbound tab where you want to do is click here on it.

155
00:10:39,910 --> 00:10:42,400
And we're going to open up some ports here.

156
00:10:42,400 --> 00:10:43,350
So click on it.

157
00:10:44,550 --> 00:10:49,800
And then click here where it says add rule and you'll get a new little rule pop up.

158
00:10:49,800 --> 00:10:59,430
And we want to select S-sh and then make sure that the port is 22 and over here on Kustom we can either

159
00:10:59,430 --> 00:11:02,070
select any where or my IP.

160
00:11:02,070 --> 00:11:07,830
Now if you select my IP that means you can only connect to this cluster from your actual IP address

161
00:11:07,830 --> 00:11:08,830
location.

162
00:11:08,880 --> 00:11:11,170
That's probably the most secure way of going about this.

163
00:11:11,190 --> 00:11:12,660
If you want to click anywhere.

164
00:11:12,660 --> 00:11:18,300
That means anyone will be able to connect to this cluster which could be dangerous or for the most secure

165
00:11:18,300 --> 00:11:26,300
thing just click on my IP and then we want to do is open up one more rule so say our rule and then have

166
00:11:26,300 --> 00:11:33,950
this be a custom TCAP rule and then what I want to do is open up the poor 8 8 9 0 and I going I'm just

167
00:11:33,950 --> 00:11:36,570
going to say my IP.

168
00:11:36,740 --> 00:11:42,670
So if those two things selected click save.

169
00:11:42,690 --> 00:11:47,550
All right so now that we have our security groups for it to go where we needed to just wait for the

170
00:11:47,550 --> 00:11:49,950
actual cluster to start.

171
00:11:49,950 --> 00:11:55,550
So come back here to the AWOS cluster in probably still waiting right now may take a couple of minutes.

172
00:11:55,560 --> 00:11:58,180
But basically we have everything set up.

173
00:11:58,540 --> 00:11:58,880
OK.

174
00:11:58,890 --> 00:12:05,040
Coming back to the Amazon AWOS counsel for your cluster What do you see the masters running in the core

175
00:12:05,040 --> 00:12:05,590
is running.

176
00:12:05,640 --> 00:12:09,540
You should see something like waiting here and that means your customers waiting for you to actually

177
00:12:09,540 --> 00:12:16,410
do something with it which is good to know what we can do here is you have basically two options depending

178
00:12:16,410 --> 00:12:20,450
on how strict you want your security settings to be.

179
00:12:20,520 --> 00:12:27,510
You could S-sh and that has to do all the stuff I was talking about earlier using that dot PM your key

180
00:12:27,510 --> 00:12:28,100
or yours.

181
00:12:28,110 --> 00:12:34,320
PPK if you're on Windows and setting up the actual S-sh connection but if you did the security settings

182
00:12:34,320 --> 00:12:41,200
that I showed you here you can actually access your zipline notebook directly through this public link.

183
00:12:41,200 --> 00:12:45,360
Now keep in mind this is a pretty open way of accessing a cluster.

184
00:12:45,460 --> 00:12:50,440
So this may not be the right setting for you or your organization the pending on how important security

185
00:12:50,440 --> 00:12:51,210
is for you.

186
00:12:51,370 --> 00:12:58,480
But I can just copy and paste this public DNS into my browser and then write Colan 8 8 9 0.

187
00:12:58,480 --> 00:13:03,280
Remember that was the port we left open for Zetlin enter and you should see something that looks like

188
00:13:03,280 --> 00:13:05,030
this these aplan notebook page.

189
00:13:05,190 --> 00:13:10,000
And you can import notebooks or create new notebooks and if you click here on this zipline tutorial

190
00:13:10,000 --> 00:13:16,060
file or folder you'll see it has an example notebook but this is essentially just that big data version

191
00:13:16,060 --> 00:13:16,960
of the Joop or notebook.

192
00:13:16,960 --> 00:13:25,390
So let's create a new note and then we'll give it a you note names we like my first notebook and there's

193
00:13:25,390 --> 00:13:30,040
different default interpreters you can use like spark M.D angular SH Python.

194
00:13:30,250 --> 00:13:35,770
If we want to use Python with Sparke what has worked best for me in the past is choosing Sparc and then

195
00:13:36,040 --> 00:13:39,010
saying you want to use the Paice park interpreter in the notebook.

196
00:13:39,010 --> 00:13:45,180
So select Sparke create note and here let me zoom in so you can see this.

197
00:13:45,430 --> 00:13:49,720
You can end up typing Python of Sparke code.

198
00:13:49,720 --> 00:13:55,660
But the first thing you do in the cell is how a percent sign and say Paice park and then everything

199
00:13:55,660 --> 00:13:58,660
else in the cell can then be Python code.

200
00:13:58,870 --> 00:14:03,580
If you don't do that expects Skala because SPARC has written in Scala so it's sort of a really simple

201
00:14:03,580 --> 00:14:06,910
example say something like for x in the list.

202
00:14:06,920 --> 00:14:12,640
One two three colon if I enter and you see that default indentation that means it's working which is

203
00:14:12,670 --> 00:14:13,260
good.

204
00:14:13,570 --> 00:14:18,120
And then we're going to say print's X do shift enter to run this.

205
00:14:18,700 --> 00:14:21,010
And we see one two three it's looking good.

206
00:14:21,340 --> 00:14:27,380
And you can notice that it continues on with the Paice bark in the next cell kind of expect you to continue

207
00:14:27,380 --> 00:14:33,070
with Paice park and luckily the zipline notebook actually creates a sequel context ready for you.

208
00:14:33,100 --> 00:14:40,120
So if you just type SE and do shift enter that is the spark context object and that's what you can use

209
00:14:40,450 --> 00:14:42,240
to call different things off of it.

210
00:14:42,250 --> 00:14:48,040
Now usually throughout the course we're going to be using Spark's sessions not spark contacts because

211
00:14:48,040 --> 00:14:53,840
spark session is what the newer Sparke data Freyne that 2.0 version runs off.

212
00:14:54,040 --> 00:14:58,950
And instead of typing as c the default for that isn't going to be just Sparke.

213
00:14:58,960 --> 00:15:04,900
So SPARC is already defined as an object of the current SPARC session when we run things locally or

214
00:15:04,900 --> 00:15:08,340
maybe even on an easy to instance that you've seen in the past.

215
00:15:08,350 --> 00:15:10,510
Or maybe you can check out those other lectures.

216
00:15:10,630 --> 00:15:13,990
You'll definitely be seeing me define Sparke all the time.

217
00:15:13,990 --> 00:15:17,660
But here in the Zeppelin notebooks and that knows that you're going to be working with SPARC.

218
00:15:17,770 --> 00:15:19,210
It's already set up that variable.

219
00:15:19,240 --> 00:15:25,220
So don't ever overwrite spark that special variables already set up as a spark session and then off

220
00:15:25,220 --> 00:15:30,310
of this you can do things like read that cxxviii and then usually if you're dealing with the zipline

221
00:15:30,310 --> 00:15:36,820
notebook you're in a situation where you're dealing with data that's hosted on S-3 of Amazon.

222
00:15:36,850 --> 00:15:39,730
So in order to grab that data you would have to do something like this.

223
00:15:39,730 --> 00:15:47,170
I'm sure you you would pass in a string you would say something like as 3 then call and forward slash

224
00:15:47,170 --> 00:15:53,680
forward slash and then you have to pass in your keys that like to connect to your as three buckets and

225
00:15:53,680 --> 00:15:58,720
that would look something like you know whatever your access key is then colon and then your secret

226
00:15:58,720 --> 00:16:04,150
key and then after that you can specify what Buckett you're looking for.

227
00:16:04,160 --> 00:16:10,100
So usually a bucket's in those S3 storage instances and that would be indicated with an at symbol.

228
00:16:10,360 --> 00:16:13,450
And then you would say whatever the name of your bucket is.

229
00:16:13,450 --> 00:16:18,010
And after that you can then start looking for the actual file so essentially here you can just look

230
00:16:18,010 --> 00:16:22,480
through directories or you know if it's saved directly under that S3 bucket just say something like

231
00:16:22,480 --> 00:16:24,540
my file see a city.

232
00:16:24,820 --> 00:16:27,060
And obviously this won't find anything so I won't run this.

233
00:16:27,070 --> 00:16:28,690
But that's basically what this would look like.

234
00:16:28,810 --> 00:16:34,750
If you have a super large dataset that tribut it on S3 Spahr can read it from that just by saying spark

235
00:16:34,750 --> 00:16:39,250
that read that see it's free and then you can also do other options that we show later in the course.

236
00:16:39,250 --> 00:16:42,750
Things like header or infer schema IX cetera.

237
00:16:42,820 --> 00:16:47,590
But the basic idea behind getting's run up and running of the Zeppelin notebook of Python is that in

238
00:16:47,590 --> 00:16:51,480
each cell you got to make sure you have this pie Sparke percent command.

239
00:16:51,670 --> 00:16:57,040
And then if you want to use a spark contex you use se if you want to call a spark session you just call

240
00:16:57,040 --> 00:16:57,520
spark.

241
00:16:57,550 --> 00:17:00,170
So those are key words that are already registered for you.

242
00:17:00,550 --> 00:17:01,050
OK.

243
00:17:01,120 --> 00:17:02,350
I hope that was useful to you.

244
00:17:02,410 --> 00:17:05,950
And remember to terminate this instance when you're done with it.

245
00:17:05,980 --> 00:17:08,380
Otherwise you're going to keep getting charged.

246
00:17:08,380 --> 00:17:10,140
So again this is not free.

247
00:17:10,150 --> 00:17:13,900
This doesn't fall under the free limits of Amazon Web Services.

248
00:17:14,090 --> 00:17:15,640
OK I'll see you at the next lecture.
