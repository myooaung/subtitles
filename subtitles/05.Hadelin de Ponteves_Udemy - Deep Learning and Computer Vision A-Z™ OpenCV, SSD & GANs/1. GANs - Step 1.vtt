WEBVTT
1
00:00:00.760 --> 00:00:07.840
Hello and welcome to the practical applications of module three deep convolutional Gants Gannes mean

2
00:00:07.900 --> 00:00:14.110
generative adversarial networks and there are the new big thing in deep learning that I use today to

3
00:00:14.110 --> 00:00:16.000
do some amazing stuff.

4
00:00:16.000 --> 00:00:24.010
One of these things is to generate some fake images based on the vision of real images and that's exactly

5
00:00:24.010 --> 00:00:29.920
what we'll do in this Mudgal and it's part of computer vision because the Gannes will have eyes through

6
00:00:29.920 --> 00:00:37.280
the convolutional layers to watch all these images and then train itself to reproduce some fake images.

7
00:00:37.510 --> 00:00:44.250
But then you have some other amazing applications of gangs that are for example style transfer or face

8
00:00:44.250 --> 00:00:50.680
where you can make a face weap with cycle Gannes basically Gannes other cutting edge Morell's income

9
00:00:50.680 --> 00:00:51.420
television.

10
00:00:51.640 --> 00:00:55.800
So I'm super excited to implement it with you in this Mudgal 3.

11
00:00:55.900 --> 00:01:01.750
And the good news is that this time we will implement the whole model from scratch and this not only

12
00:01:01.750 --> 00:01:07.900
includes the generation of the images that is we're not going to take a pre-trained moralizing module

13
00:01:07.900 --> 00:01:10.630
to to generate some fake images.

14
00:01:10.690 --> 00:01:13.090
We're going to make the whole thing from scratch.

15
00:01:13.090 --> 00:01:17.980
And by that I mean we're going to make a brain we're going to create a brain which will have some eyes

16
00:01:18.280 --> 00:01:22.560
and we're going to train that brain to make it smart and smart.

17
00:01:22.600 --> 00:01:31.000
I mean capable of generating some fake images based on the vision of a lot and lots of real images these

18
00:01:31.090 --> 00:01:38.290
real images will get them from C4 10 which is a very well known data set containing lots and lots of

19
00:01:38.290 --> 00:01:45.130
images that will be the real images on which are deep convolutional Gannes will be trained and based

20
00:01:45.130 --> 00:01:46.130
on its training.

21
00:01:46.180 --> 00:01:51.270
It will then be smart enough to generate some fake images and you're going to see that fake images.

22
00:01:51.370 --> 00:01:55.280
I'm not talking about some random gradients of colors.

23
00:01:55.300 --> 00:01:57.610
It really looks like something real.

24
00:01:57.640 --> 00:02:03.380
So you'll see that in the end we will see that in the final tutorial of this module as usual.

25
00:02:03.530 --> 00:02:07.920
And now if you're ready we're going to start implementing this model from scratch.

26
00:02:08.020 --> 00:02:10.600
The deep convolutional Ganns.

27
00:02:10.930 --> 00:02:17.020
So the first thing we're going to do is open Anaconda because I want to make sure you don't forget to

28
00:02:17.020 --> 00:02:19.260
connect to the virtual platform.

29
00:02:19.270 --> 00:02:20.020
There we go.

30
00:02:20.020 --> 00:02:28.780
So you go to applications on virtual platform and right after it's loaded you click on launch here to

31
00:02:28.780 --> 00:02:33.360
launch the spider ID right.

32
00:02:33.450 --> 00:02:36.180
Spiders coming in here is spider.

33
00:02:36.490 --> 00:02:40.580
OK so now we have to set the right for them as working directory.

34
00:02:40.660 --> 00:02:42.590
So we're going to go to File Explorer.

35
00:02:42.640 --> 00:02:47.560
We're going to go to where your computer vision is that folder it is on my desktop.

36
00:02:47.560 --> 00:02:54.090
We go inside the computer vision it is a folder and now I have to say congratulations you reached module

37
00:02:54.090 --> 00:02:54.680
3.

38
00:02:54.700 --> 00:02:56.320
This is going to be a big module.

39
00:02:56.320 --> 00:03:03.160
We're going to implement a real huge powerful computer vision model from scratch including the training.

40
00:03:03.310 --> 00:03:08.290
So let's do this let's go inside module three and ask for Module 1 and 2.

41
00:03:08.290 --> 00:03:14.440
You have to code this again commented we're going to look at that right now by the way because I really

42
00:03:14.440 --> 00:03:21.580
want you to get the structure of the code and we have our implementation that we'll do ourselves.

43
00:03:21.580 --> 00:03:24.290
It contains more than 100 lines of code.

44
00:03:24.480 --> 00:03:26.710
So that's quite a challenge but we'll make it.

45
00:03:26.830 --> 00:03:32.290
But before we make it I would like to as I just said show you the structure of the code.

46
00:03:32.350 --> 00:03:33.770
So that's the code.

47
00:03:33.790 --> 00:03:39.570
All the lines of the code argumenta and you can have a clear global view of the structure.

48
00:03:39.610 --> 00:03:44.390
It's important sometimes to take a step back and visualize the structure.

49
00:03:44.500 --> 00:03:46.500
That's exactly what we're going to do now.

50
00:03:46.540 --> 00:03:50.230
So we start by importing all the libraries.

51
00:03:50.320 --> 00:03:55.900
So that's almost the same as before except this time we're going to use towards vision to visualize

52
00:03:55.940 --> 00:03:56.970
the images.

53
00:03:57.040 --> 00:04:03.190
Then we set the values of some hyper parameters like the batch size the image size that is.

54
00:04:03.280 --> 00:04:07.540
We set the size of the generated images to 64 by 64.

55
00:04:07.540 --> 00:04:13.300
Then we create some transformations exactly like in module to we'll use some transformations to make

56
00:04:13.300 --> 00:04:18.470
the input images compatible with the neural network of the generator.

57
00:04:18.490 --> 00:04:19.500
Prepare yourself.

58
00:04:19.510 --> 00:04:22.000
This time we're going to have two neural networks.

59
00:04:22.000 --> 00:04:26.810
We're going to have the neural network of the generator and the neural network of the discriminator.

60
00:04:27.000 --> 00:04:32.540
So that's going to be something but these transformations are for the generator.

61
00:04:32.650 --> 00:04:42.360
Then we load the data set from this folder here data that contains the site far 10 data set in batches.

62
00:04:42.490 --> 00:04:45.110
So we just love the data set from this folder.

63
00:04:45.220 --> 00:04:52.720
As you can see here route we take this data folder and then we use torche utils data data loader to

64
00:04:52.720 --> 00:04:56.510
get the images of the data set batch by batch.

65
00:04:56.530 --> 00:05:01.580
Indeed as you can see we specify here the batch size to specify the size of the batch.

66
00:05:01.840 --> 00:05:08.650
And then we use this shuffle equals true here just so that we can get the images in a random order.

67
00:05:08.890 --> 00:05:09.270
All right.

68
00:05:09.280 --> 00:05:10.410
And then none.

69
00:05:10.450 --> 00:05:17.800
Workers equals true means that we're going to have two parallel threads that will load the data and

70
00:05:17.890 --> 00:05:21.010
using the data loader with this shuffle.

71
00:05:21.100 --> 00:05:28.150
And two threads allows us in fact to get the data faster much faster when the data sets are huge which

72
00:05:28.150 --> 00:05:31.510
is the case for C40 and data set.

73
00:05:31.510 --> 00:05:39.430
All right then we define the weights in it function that will take as input a neural network and that

74
00:05:39.430 --> 00:05:42.180
will initialize all the weights of the neural network.

75
00:05:42.250 --> 00:05:47.390
So we will apply the weights and it function to both the neural networks that is the new network of

76
00:05:47.390 --> 00:05:52.670
the generator and a neural network of the discriminator to initialize all the weights.

77
00:05:52.690 --> 00:05:56.060
The right way for the adversarial networks.

78
00:05:56.470 --> 00:05:58.790
And then here comes the structure.

79
00:05:58.840 --> 00:06:03.810
I really want to highlight and then I really want you to have a clear understanding.

80
00:06:03.950 --> 00:06:07.020
That's super important before we tackle this.

81
00:06:07.060 --> 00:06:13.860
So the further we're going to do is defining the generator and we are going to define it through a class

82
00:06:13.870 --> 00:06:16.510
that's the best way to define a neural network.

83
00:06:16.510 --> 00:06:22.000
So we will define the architecture of the new one that work in this first class G which will contain

84
00:06:22.000 --> 00:06:28.700
this architecture and the forward function that will propagate the signal inside this neural network.

85
00:06:29.050 --> 00:06:35.080
Then once we define our generator with this class we'll be able to create the generator itself which

86
00:06:35.080 --> 00:06:38.330
will be an object of the G class.

87
00:06:38.590 --> 00:06:42.620
So that's the first important section of the structure of the code.

88
00:06:42.700 --> 00:06:49.780
Then once we're done with the generator we'll take care of the discriminator and same well-defined architecture

89
00:06:49.780 --> 00:06:51.070
of the discriminator.

90
00:06:51.070 --> 00:06:57.010
With this class D which will contain the architecture itself and same the forward function that will

91
00:06:57.010 --> 00:07:03.130
propagate the signal inside the neural network of the discriminator then once we define all this we'll

92
00:07:03.130 --> 00:07:10.870
be able to create the discriminator itself by creating an object of this previous class declasse and

93
00:07:10.870 --> 00:07:17.560
then that will be a huge step down because we will have created the brain of our computer vision model

94
00:07:17.830 --> 00:07:21.790
because the brain is composed of the generator and the discriminator.

95
00:07:22.000 --> 00:07:25.230
But then we will just have a brain a brain that is not trained yet.

96
00:07:25.240 --> 00:07:30.200
So our hands will still be stupid and therefore we will need to train it.

97
00:07:30.310 --> 00:07:37.540
And that's exactly the last section of the code where we will train the DC Gannes by training two brains

98
00:07:37.630 --> 00:07:43.350
at the same time you know we have this big brain of the DC again that is composed of two brain the brain

99
00:07:43.360 --> 00:07:48.670
there is a neural network or the generator and the other brain the neural network of the discriminator.

100
00:07:48.820 --> 00:07:53.670
So we will train these two brains at the same time according to the process that you saw with curial

101
00:07:53.700 --> 00:07:55.150
in the intuition lectures.

102
00:07:55.240 --> 00:07:59.250
That is you know we first trained a generator with a real image of the data set.

103
00:07:59.320 --> 00:08:05.180
Then we trained the discriminator with a fake image generated before by the generator.

104
00:08:05.320 --> 00:08:08.720
That's the first subset of this big step here.

105
00:08:08.890 --> 00:08:13.660
And then the second subset is two of them the weight of the neural network of the generator.

106
00:08:13.660 --> 00:08:19.750
So we will see that in details great details actually we will code each of these lines of code base

107
00:08:19.750 --> 00:08:26.230
planning what's going on and eventually after we're done with the implementation of the section not

108
00:08:26.230 --> 00:08:32.050
only will we have brains but also these brains will be smart enough to generate some images and since

109
00:08:32.050 --> 00:08:32.970
they'll be smart enough.

110
00:08:33.040 --> 00:08:39.460
Well of course we'll make them generate some fake images and we'll see these fake images in the last

111
00:08:39.460 --> 00:08:40.280
tutorial.

112
00:08:40.450 --> 00:08:41.860
So I can't wait to start.

113
00:08:41.940 --> 00:08:45.410
I'm super excited to code all this with you.

114
00:08:45.490 --> 00:08:47.130
I'm going to close this now.

115
00:08:47.200 --> 00:08:53.320
And here we are back in our non-committed version of the code that is the code where we'll implement

116
00:08:53.320 --> 00:08:54.440
the whole model.

117
00:08:54.700 --> 00:08:59.950
I already prepared the first sections here where we import the library said the hyper parameters create

118
00:08:59.950 --> 00:09:05.440
the transformations load the data set and define the weights in it function so that we can directly

119
00:09:05.570 --> 00:09:10.740
Diven to the implementation of our future smart brains.

120
00:09:11.170 --> 00:09:15.290
So let's do this and getting back into my replow data.

121
00:09:15.360 --> 00:09:22.390
Oh and by the way this last fall the result is an empty folder so far but that will exactly be the folder

122
00:09:22.390 --> 00:09:26.970
that will be populated with the fake images of our decisions.

123
00:09:26.980 --> 00:09:33.170
So here we go let's tackle our deep convolutional Ganns And let's start in the next tutorial.

124
00:09:33.190 --> 00:09:35.130
Until then enjoy computer vision.
