WEBVTT
1
1

00:00:00.140  -->  00:00:02.580
<v Narrator>Hello and welcome to this Python tutorial.</v>
2

2

00:00:02.580  -->  00:00:05.020
Alright, so this is going to be a very exciting tutorial,
3

3

00:00:05.020  -->  00:00:07.120
because in this tutorial we are going to see
4

4

00:00:07.120  -->  00:00:09.370
if we can achieve our goal to get an accuracy
5

5

00:00:09.370  -->  00:00:12.050
of more than 80% on the test set.
6

6

00:00:12.050  -->  00:00:15.290
So did you figure out a way to reach that accuracy
7

7

00:00:15.290  -->  00:00:17.580
without doing any parameter tuning?
8

8

00:00:17.580  -->  00:00:20.540
Well at the end of the previous tutorial I gave you a hint.
9

9

00:00:20.540  -->  00:00:23.630
The hint was the answer is in the title of the course,
10

10

00:00:23.630  -->  00:00:26.380
deep learning and indeed the solution that will
11

11

00:00:26.380  -->  00:00:27.760
make us achieve our goal
12

12

00:00:27.760  -->  00:00:30.820
is to make a deeper deep learning model
13

13

00:00:30.820  -->  00:00:33.170
that is a deeper convolutional neural network.
14

14

00:00:33.170  -->  00:00:35.010
And how can we make it deeper?
15

15

00:00:35.010  -->  00:00:36.870
Well, we have two options.
16

16

00:00:36.870  -->  00:00:40.610
First option is to add another convolutional layer
17

17

00:00:40.610  -->  00:00:42.250
and the second option is to add
18

18

00:00:42.250  -->  00:00:44.060
another fully connected layer.
19

19

00:00:44.060  -->  00:00:45.880
So maybe you experimented
20

20

00:00:45.880  -->  00:00:48.620
and maybe you figured out that the best solution
21

21

00:00:48.620  -->  00:00:51.390
is actually to add a convolutional layer.
22

22

00:00:51.390  -->  00:00:52.887
So that's what we'll do in this tutorial.
23

23

00:00:52.887  -->  00:00:54.800
But you can always improve your model
24

24

00:00:54.800  -->  00:00:56.450
by considering the two options
25

25

00:00:56.450  -->  00:00:58.460
that is adding a convolutional layer
26

26

00:00:58.460  -->  00:01:00.720
as well as a fully connected layer.
27

27

00:01:00.720  -->  00:01:03.060
But I bet that we managed to reach our goal
28

28

00:01:03.060  -->  00:01:05.800
of getting a test set accuracy of more than 80%
29

29

00:01:05.800  -->  00:01:08.770
by only adding a second convolutional layer.
30

30

00:01:08.770  -->  00:01:11.320
You'll see how it will definitely improve
31

31

00:01:11.320  -->  00:01:14.220
our performance result on your observations
32

32

00:01:14.220  -->  00:01:15.490
that is on the test set,
33

33

00:01:15.490  -->  00:01:18.050
as well as reducing the over fitting.
34

34

00:01:18.050  -->  00:01:20.550
So let's do it and let's see if I'm right.
35

35

00:01:20.550  -->  00:01:22.810
Besides, it's important to do this tutorial,
36

36

00:01:22.810  -->  00:01:25.480
because you're gonna see how it is so easy
37

37

00:01:25.480  -->  00:01:27.980
to add another convolutional layer.
38

38

00:01:27.980  -->  00:01:31.540
Because basically what I only have to do is take this line,
39

39

00:01:31.540  -->  00:01:36.500
copy it and then paste it right after the first two steps.
40

40

00:01:36.500  -->  00:01:39.130
That is right after we build a convolutional layer
41

41

00:01:39.130  -->  00:01:42.350
on which we applied max pooling to get our pooling layer.
42

42

00:01:42.350  -->  00:01:44.880
So that is exactly right here and that is of course
43

43

00:01:44.880  -->  00:01:46.360
before the flattening step.
44

44

00:01:46.360  -->  00:01:48.830
So I'm going to paste this line here
45

45

00:01:48.830  -->  00:01:51.430
that adds another convolutional layer.
46

46

00:01:51.430  -->  00:01:54.610
And of course, we also need to apply max pooling
47

47

00:01:54.610  -->  00:01:57.280
on this convolutional layer that we just added.
48

48

00:01:57.280  -->  00:02:00.080
And so I'm going to paste that here.
49

49

00:02:00.080  -->  00:02:02.440
And let's specify here
50

50

00:02:02.440  -->  00:02:07.233
that we're adding a second convolutional layer.
51

51

00:02:09.519  -->  00:02:12.210
All right and now in these two lines here
52

52

00:02:12.210  -->  00:02:14.170
we just need to change one thing.
53

53

00:02:14.170  -->  00:02:16.650
It's the input shape parameter.
54

54

00:02:16.650  -->  00:02:18.610
Because you know we had to specify
55

55

00:02:18.610  -->  00:02:19.970
this input shape parameter,
56

56

00:02:19.970  -->  00:02:22.450
because this corresponds to our image
57

57

00:02:22.450  -->  00:02:24.890
and how our CNN should expect
58

58

00:02:24.890  -->  00:02:27.140
that is which dimensions it should expect
59

59

00:02:27.140  -->  00:02:28.730
as input of the CNN.
60

60

00:02:28.730  -->  00:02:31.370
And so that's why we specify this input shape parameter
61

61

00:02:31.370  -->  00:02:35.020
to specify the dimensions of the pre processed images
62

62

00:02:35.020  -->  00:02:37.390
that are going to be the input of the CNN.
63

63

00:02:37.390  -->  00:02:40.720
But here we are adding a second convolutional layer
64

64

00:02:40.720  -->  00:02:43.490
and the input is going to be not the images
65

65

00:02:43.490  -->  00:02:45.240
but the pooled feature maps
66

66

00:02:45.240  -->  00:02:47.000
coming from the previous two steps.
67

67

00:02:47.000  -->  00:02:49.680
So we're going to apply the convolution trick
68

68

00:02:49.680  -->  00:02:51.073
and the max pooling trick,
69

69

00:02:51.973  -->  00:02:53.200
not on the images
70

70

00:02:53.200  -->  00:02:54.270
but on the pooled feature maps.
71

71

00:02:54.270  -->  00:02:55.860
So that's exactly the same operation,
72

72

00:02:55.860  -->  00:02:58.480
the same trick but it's on the pooled feature maps
73

73

00:02:58.480  -->  00:03:00.060
from the two previous steps.
74

74

00:03:00.060  -->  00:03:02.750
And so we don't need to include this parameter
75

75

00:03:02.750  -->  00:03:06.170
input shape here because we only need to include that
76

76

00:03:06.170  -->  00:03:08.580
when we don't have anything previously.
77

77

00:03:08.580  -->  00:03:10.100
Here we needed to include that
78

78

00:03:10.100  -->  00:03:12.560
because we didn't have the images previously yet.
79

79

00:03:12.560  -->  00:03:14.720
But here we have something before
80

80

00:03:14.720  -->  00:03:17.560
it's the pooled feature maps of the two previous steps.
81

81

00:03:17.560  -->  00:03:19.250
So Keras will know this
82

82

00:03:19.250  -->  00:03:20.850
and therefore we don't need
83

83

00:03:20.850  -->  00:03:23.550
to include this input shape parameter.
84

84

00:03:23.550  -->  00:03:25.370
So in conclusion when you're adding
85

85

00:03:25.370  -->  00:03:27.080
a new convolutional layer,
86

86

00:03:27.080  -->  00:03:29.370
well you just need a number of features detectors,
87

87

00:03:29.370  -->  00:03:31.850
the dimensions of these feature detectors
88

88

00:03:31.850  -->  00:03:33.730
and an activation function.
89

89

00:03:33.730  -->  00:03:35.180
And then you apply max pooling with
90

90

00:03:35.180  -->  00:03:37.050
only this pool size parameter.
91

91

00:03:37.050  -->  00:03:39.430
And so here we're going to keep the same parameters
92

92

00:03:39.430  -->  00:03:41.510
you'll see that we'll get good results.
93

93

00:03:41.510  -->  00:03:42.790
And then if you want to have fun
94

94

00:03:42.790  -->  00:03:44.860
adding new convolutional layers,
95

95

00:03:44.860  -->  00:03:47.590
then you can increase the number of feature detectors
96

96

00:03:47.590  -->  00:03:49.010
and double it each time.
97

97

00:03:49.010  -->  00:03:51.920
So for example, you can add a third convolutional layer
98

98

00:03:51.920  -->  00:03:54.180
with 64 feature detectors.
99

99

00:03:54.180  -->  00:03:57.360
That's a common practice and that leads to great results.
100

100

00:03:57.360  -->  00:04:00.970
But I bet that now with only these two convolutional layers,
101

101

00:04:00.970  -->  00:04:04.240
we'll get to a test set accuracy of more than 80%.
102

102

00:04:04.240  -->  00:04:05.750
So let's check it out.
103

103

00:04:05.750  -->  00:04:08.030
As you can notice, I restarted my spider.
104

104

00:04:08.030  -->  00:04:13.030
So what I'm going to do now is basically select everything,
105

105

00:04:13.580  -->  00:04:15.130
and I will just need to press Enter
106

106

00:04:15.130  -->  00:04:17.070
and this will run the whole code.
107

107

00:04:17.070  -->  00:04:17.940
So before I run it,
108

108

00:04:17.940  -->  00:04:20.010
let's remember in the previous tutorial
109

109

00:04:20.010  -->  00:04:22.060
we only had one convolutional layer
110

110

00:04:22.060  -->  00:04:25.560
and we got an accuracy of 75% on the test set.
111

111

00:04:25.560  -->  00:04:28.010
And the difference of 10% between the accuracy
112

112

00:04:28.010  -->  00:04:30.520
of the test set and the accuracy of the training set.
113

113

00:04:30.520  -->  00:04:34.100
Because the accuracy of the training set was about 85%.
114

114

00:04:34.100  -->  00:04:36.113
And now we have one goal with this new CNN
115

115

00:04:36.113  -->  00:04:38.070
with two convolutional layers,
116

116

00:04:38.070  -->  00:04:41.400
it is to get a test set accuracy of more than 80%
117

117

00:04:41.400  -->  00:04:42.550
and a much smaller difference
118

118

00:04:42.550  -->  00:04:44.300
between the accuracy of the test set
119

119

00:04:44.300  -->  00:04:46.080
and the one of the training set.
120

120

00:04:46.080  -->  00:04:47.080
So let's see,
121

121

00:04:47.080  -->  00:04:48.030
let's run this
122

122

00:04:48.030  -->  00:04:50.060
and let's get some little coffee.
123

123

00:04:50.060  -->  00:04:54.440
So ready? 3, 2, 1, go.
124

124

00:04:54.440  -->  00:04:55.780
using TensorFlow backend,
125

125

00:04:55.780  -->  00:04:58.190
found 8000 images belonging to two classes
126

126

00:04:58.190  -->  00:04:59.330
for the training set.
127

127

00:04:59.330  -->  00:05:02.150
2000 images belonging to two classes for the test set.
128

128

00:05:02.150  -->  00:05:05.360
And here we go with the first epoch one out of 25
129

129

00:05:05.360  -->  00:05:08.770
and we're beginning with an accuracy of 50%
130

130

00:05:08.770  -->  00:05:10.330
for the training set
131

131

00:05:10.330  -->  00:05:13.010
and the loss function around 70%.
132

132

00:05:13.010  -->  00:05:15.360
And remember this is going to decrease
133

133

00:05:15.360  -->  00:05:17.140
and this is going to increase.
134

134

00:05:17.140  -->  00:05:20.560
And not only we want this accuracy to go over 80%,
135

135

00:05:20.560  -->  00:05:23.070
but we also want the accuracy of the test set
136

136

00:05:23.070  -->  00:05:24.950
to go over 80%.
137

137

00:05:24.950  -->  00:05:26.830
So right now it's running.
138

138

00:05:26.830  -->  00:05:29.230
I'm very excited to see what happens in the end.
139

139

00:05:29.230  -->  00:05:30.580
And before we get some little coffee
140

140

00:05:30.580  -->  00:05:31.560
or get some lunch,
141

141

00:05:31.560  -->  00:05:34.390
let's see the accuracy of the test set
142

142

00:05:34.390  -->  00:05:36.047
for the first epoch.
143

143

00:05:36.047  -->  00:05:38.223
Here we go, almost there.
144

144

00:05:40.090  -->  00:05:42.030
And here we go, first epoch done.
145

145

00:05:42.030  -->  00:05:44.360
The accuracy obtained on the test set
146

146

00:05:44.360  -->  00:05:48.640
began at 55%, almost 56%.
147

147

00:05:48.640  -->  00:05:51.430
So yes that's actually like before.
148

148

00:05:51.430  -->  00:05:52.430
We're starting slowly,
149

149

00:05:52.430  -->  00:05:53.520
we're starting low.
150

150

00:05:53.520  -->  00:05:56.100
But let's see what we'll get in the end.
151

151

00:05:56.100  -->  00:05:58.230
So right now we're in the second epoch,
152

152

00:05:58.230  -->  00:05:59.730
the accuracy of the training set
153

153

00:05:59.730  -->  00:06:01.670
is already increasing pretty well,
154

154

00:06:01.670  -->  00:06:04.070
we already reached 60%.
155

155

00:06:04.070  -->  00:06:07.350
As you can see the ETA is quite the same as before
156

156

00:06:07.350  -->  00:06:10.680
so it's not because we added a second convolutional layer
157

157

00:06:10.680  -->  00:06:14.290
that we need to wait more, so it should be okay.
158

158

00:06:14.290  -->  00:06:18.410
The second epoch is almost done and the accuracy is,
159

159

00:06:18.410  -->  00:06:21.840
well, increasing 64%.
160

160

00:06:21.840  -->  00:06:24.640
Let's see what we'll get at the end of the second epoch.
161

161

00:06:25.570  -->  00:06:30.570
And we got indeed 64% and 68% on the test set.
162

162

00:06:31.400  -->  00:06:32.940
Alright so let's let this run.
163

163

00:06:32.940  -->  00:06:35.260
let's get some coffee or let's take a little nap.
164

164

00:06:35.260  -->  00:06:36.940
As far as I'm concerned I just woke up
165

165

00:06:36.940  -->  00:06:37.970
so I won't take a nap.
166

166

00:06:37.970  -->  00:06:39.860
I'll just be happy with a good coffee.
167

167

00:06:39.860  -->  00:06:41.793
And let's keep in touch in 20 minutes.
168

168

00:06:43.660  -->  00:06:44.830
Alright we're almost done,
169

169

00:06:44.830  -->  00:06:46.040
let's see wat we get.
170

170

00:06:46.040  -->  00:06:49.450
That's the last epoch 25 out of 25.
171

171

00:06:49.450  -->  00:06:50.750
ETA five seconds.
172

172

00:06:50.750  -->  00:06:55.750
We are about to get an accuracy of 85% for the training set
173

173

00:06:57.340  -->  00:07:00.730
and 82% for the test set.
174

174

00:07:00.730  -->  00:07:02.810
Wonderful, not only we reached our goal
175

175

00:07:02.810  -->  00:07:05.750
to obtain the test set accuracy over 80%
176

176

00:07:05.750  -->  00:07:08.400
and also we reduced the difference between the training set
177

177

00:07:08.400  -->  00:07:10.720
accuracy and the test set accuracy.
178

178

00:07:10.720  -->  00:07:14.010
Because now indeed we get a difference of 3%
179

179

00:07:14.010  -->  00:07:16.090
as opposed to this 10% difference
180

180

00:07:16.090  -->  00:07:18.160
that we got in the previous tutorial.
181

181

00:07:18.160  -->  00:07:20.840
So congratulations, we made a great
182

182

00:07:20.840  -->  00:07:24.560
convolutional neural network model with a good prediction.
183

183

00:07:24.560  -->  00:07:28.220
So you can still play around and try to improve this model.
184

184

00:07:28.220  -->  00:07:30.380
Of course, adding more convolutional layers
185

185

00:07:30.380  -->  00:07:33.410
will help get an even better accuracy.
186

186

00:07:33.410  -->  00:07:36.450
But if you want to really get a better accuracy,
187

187

00:07:36.450  -->  00:07:40.460
well, that would be to choose a higher target size here
188

188

00:07:40.460  -->  00:07:43.370
for your images of the train set and the test set
189

189

00:07:43.370  -->  00:07:46.950
so that you get more information of your pixel patterns.
190

190

00:07:46.950  -->  00:07:49.800
Because indeed if you increase the size of your images
191

191

00:07:49.800  -->  00:07:51.630
that is the size down to which
192

192

00:07:51.630  -->  00:07:53.690
all your images will be resized.
193

193

00:07:53.690  -->  00:07:56.260
Well you will get a lot more pixels in the rows
194

194

00:07:56.260  -->  00:07:59.700
and a lot more pixels in the columns in your input images.
195

195

00:07:59.700  -->  00:08:01.590
And therefore you will have more information
196

196

00:08:01.590  -->  00:08:03.480
to take on the pixels.
197

197

00:08:03.480  -->  00:08:06.630
So you can try this but I would recommend using a GPU
198

198

00:08:06.630  -->  00:08:08.900
or trying this before getting to sleep
199

199

00:08:08.900  -->  00:08:13.055
and you might even be able to get an accuracy over 90%.
200

200

00:08:13.055  -->  00:08:15.210
Alright, so that's the end of this section.
201

201

00:08:15.210  -->  00:08:16.770
Congratulations for having made
202

202

00:08:16.770  -->  00:08:18.380
a convolutional neural network.
203

203

00:08:18.380  -->  00:08:21.180
We did not make a cake and I hope this can be useful
204

204

00:08:21.180  -->  00:08:23.100
for you in the future.
205

205

00:08:23.100  -->  00:08:24.863
Until then, enjoy deep learning.
