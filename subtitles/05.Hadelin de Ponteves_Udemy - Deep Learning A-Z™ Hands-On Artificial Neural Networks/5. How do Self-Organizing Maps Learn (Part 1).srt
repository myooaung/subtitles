1
1

00:00:00,000  -->  00:00:01,300
<v Instructor>Hello and welcome back</v>
2

2

00:00:01,300  -->  00:00:02,800
to the course on deep learning.
3

3

00:00:02,800  -->  00:00:04,670
In the previous tutorials, we saw how
4

4

00:00:04,670  -->  00:00:07,800
self-organizing maps work, and today
5

5

00:00:07,800  -->  00:00:09,960
we'll finally find out how they learn.
6

6

00:00:09,960  -->  00:00:11,640
So let's get straight into it.
7

7

00:00:11,640  -->  00:00:13,650
Here we've got a very simple example
8

8

00:00:13,650  -->  00:00:15,500
of a self-organizing map.
9

9

00:00:15,500  -->  00:00:18,850
We've got three features in our input vectors,
10

10

00:00:18,850  -->  00:00:21,930
and we've got nine nodes in the output.
11

11

00:00:21,930  -->  00:00:25,470
And as we discussed previously, self-organizing maps
12

12

00:00:25,470  -->  00:00:28,870
are used to reduce the dimensionality of your data set.
13

13

00:00:28,870  -->  00:00:32,380
And here you might be wondering, how is that the case
14

14

00:00:32,380  -->  00:00:35,460
when our input only has three features,
15

15

00:00:35,460  -->  00:00:38,030
and our output seems to have more.
16

16

00:00:38,030  -->  00:00:41,330
Well don't let this representation
17

17

00:00:41,330  -->  00:00:43,946
confuse your understanding of self-organizing maps.
18

18

00:00:43,946  -->  00:00:47,780
Here we have three features or three columns
19

19

00:00:47,780  -->  00:00:49,910
in our data set, so therefore,
20

20

00:00:49,910  -->  00:00:52,860
we might have thousands and thousands and thousands of rows,
21

21

00:00:52,860  -->  00:00:55,710
each of which has three columns.
22

22

00:00:55,710  -->  00:00:58,330
And that means that our input data set
23

23

00:00:58,330  -->  00:01:01,860
is actually three dimensional, whereas our output data set
24

24

00:01:01,860  -->  00:01:03,520
in a self-organizing map is always
25

25

00:01:03,520  -->  00:01:06,660
a two-dimensional map, and therefore
26

26

00:01:06,660  -->  00:01:09,800
we are reducing the dimensionality from 3D to 2D.
27

27

00:01:09,800  -->  00:01:12,770
So now we're going to turn this self-organizing map
28

28

00:01:12,770  -->  00:01:16,100
into an input that, or into a representation that
29

29

00:01:16,100  -->  00:01:18,900
is familiar to us from what we've studied about
30

30

00:01:18,900  -->  00:01:21,610
artificial neural networks, convolutional neural networks,
31

31

00:01:21,610  -->  00:01:25,030
and recurrent neural networks previously in this course.
32

32

00:01:25,030  -->  00:01:29,420
So let's turn it around. This is what it would look like.
33

33

00:01:29,420  -->  00:01:31,470
And the key thing here is that
34

34

00:01:31,470  -->  00:01:35,360
it's exactly the same network, the only difference
35

35

00:01:35,360  -->  00:01:37,360
is how we've positioned the nodes.
36

36

00:01:37,360  -->  00:01:39,700
We still have the same amount of connections,
37

37

00:01:39,700  -->  00:01:42,090
same amount of inputs, same amount of outputs,
38

38

00:01:42,090  -->  00:01:44,450
it's just the visual representation has changed
39

39

00:01:44,450  -->  00:01:47,240
simply because we're used to this and it's easier for us
40

40

00:01:47,240  -->  00:01:50,480
to understand what's going on like this a bit better.
41

41

00:01:50,480  -->  00:01:52,890
At the same time, what I also wanted to mention
42

42

00:01:52,890  -->  00:01:56,360
is that self-organizing maps are different.
43

43

00:01:56,360  -->  00:01:58,710
They're very different to what we discussed
44

44

00:01:58,710  -->  00:02:00,510
in neural networks previously in
45

45

00:02:00,510  -->  00:02:03,346
the supervised learning part of the course.
46

46

00:02:03,346  -->  00:02:05,580
And there is two parts to this.
47

47

00:02:05,580  -->  00:02:09,260
First of all, self-organizing maps are much, much easier.
48

48

00:02:09,260  -->  00:02:10,630
So you'll see that you'll be able
49

49

00:02:10,630  -->  00:02:13,340
to grasp self-organizing maps very quickly,
50

50

00:02:13,340  -->  00:02:15,020
and the whole concept behind them
51

51

00:02:15,020  -->  00:02:17,200
is very simple and straightforward.
52

52

00:02:17,200  -->  00:02:18,940
At the same time, it's also important to note
53

53

00:02:18,940  -->  00:02:21,620
that because self-organizing maps are different,
54

54

00:02:21,620  -->  00:02:24,680
the concepts that might have the same names
55

55

00:02:24,680  -->  00:02:26,690
have different meanings, and therefore
56

56

00:02:26,690  -->  00:02:29,980
your knowledge of artificial neural networks
57

57

00:02:29,980  -->  00:02:31,590
and convolutional neural networks
58

58

00:02:31,590  -->  00:02:33,770
and recurrent neural networks from
59

59

00:02:33,770  -->  00:02:36,460
what we discussed previously might lead you
60

60

00:02:36,460  -->  00:02:40,090
into confusing meanings of what
61

61

00:02:40,090  -->  00:02:42,580
we're going to be discussing in self-organizing maps.
62

62

00:02:42,580  -->  00:02:44,580
So therefore, just have that in mind
63

63

00:02:44,580  -->  00:02:46,210
when we're going through this tutorial,
64

64

00:02:46,210  -->  00:02:48,700
and just be careful when we're talking about things
65

65

00:02:48,700  -->  00:02:51,140
like weights and synapses and
66

66

00:02:51,140  -->  00:02:53,350
other things that you might encounter.
67

67

00:02:53,350  -->  00:02:54,730
And I will try to point those out,
68

68

00:02:54,730  -->  00:02:56,750
and long as you're aware of this, we should be fine.
69

69

00:02:56,750  -->  00:02:59,300
So if we agree on that, let's get started.
70

70

00:02:59,300  -->  00:03:00,780
First thing that we're going to look at
71

71

00:03:00,780  -->  00:03:04,620
is the top node, the top node in our outputs.
72

72

00:03:04,620  -->  00:03:05,990
And we're specifically going to look at
73

73

00:03:05,990  -->  00:03:07,160
the three connections, there are
74

74

00:03:07,160  -->  00:03:09,690
three synapses leading to this node.
75

75

00:03:09,690  -->  00:03:12,480
In fact, let's gray out the rest of the synapses,
76

76

00:03:12,480  -->  00:03:13,860
so that we know that we're focusing on
77

77

00:03:13,860  -->  00:03:17,200
this specific combination, or these specific three.
78

78

00:03:17,200  -->  00:03:19,570
And each one of them, just as previously,
79

79

00:03:19,570  -->  00:03:22,680
will have a weight assigned to it.
80

80

00:03:22,680  -->  00:03:25,640
So here we've got W one one, one two, and one three.
81

81

00:03:25,640  -->  00:03:28,304
And the first index means that it's the first node
82

82

00:03:28,304  -->  00:03:31,660
in our output nodes, and the second index means
83

83

00:03:31,660  -->  00:03:34,550
where that synapse is connecting from.
84

84

00:03:34,550  -->  00:03:38,480
And the important thing for us to mention here
85

85

00:03:38,480  -->  00:03:42,910
is that weights in self-organizing maps are different,
86

86

00:03:42,910  -->  00:03:46,120
have a whole different connotation to them
87

87

00:03:46,120  -->  00:03:49,140
as opposed to what we saw in artificial neural networks.
88

88

00:03:49,140  -->  00:03:51,540
In artificial neural networks, weights were used
89

89

00:03:51,540  -->  00:03:55,970
to multiply, so we multiply the input of this node,
90

90

00:03:55,970  -->  00:03:57,128
or whatever we have in this node,
91

91

00:03:57,128  -->  00:03:59,410
by the weight, we added them up,
92

92

00:03:59,410  -->  00:04:01,500
and then we applied an activation function.
93

93

00:04:01,500  -->  00:04:03,390
Well, in self-organizing maps,
94

94

00:04:03,390  -->  00:04:05,760
there is no activation function.
95

95

00:04:05,760  -->  00:04:09,690
Weights are a characteristic of the node itself.
96

96

00:04:09,690  -->  00:04:11,230
And that's what we're representing over here,
97

97

00:04:11,230  -->  00:04:16,130
that this node actually has these coordinates.
98

98

00:04:16,130  -->  00:04:19,440
So think of it as in, you've got an input vector here
99

99

00:04:19,440  -->  00:04:21,490
of three dimensions, so X one, X two, and X three.
100

100

00:04:21,490  -->  00:04:23,700
and X one, X two, and X three are
101

101

00:04:23,700  -->  00:04:26,710
its coordinates in the input space.
102

102

00:04:26,710  -->  00:04:31,270
So, just if we think of it as a three-dimensional chart,
103

103

00:04:31,270  -->  00:04:32,460
this is a vector somewhere there,
104

104

00:04:32,460  -->  00:04:33,360
and these are its coordinates.
105

105

00:04:33,360  -->  00:04:35,606
Well this node, instead of just being
106

106

00:04:35,606  -->  00:04:40,340
a result of an activation, or as a result of
107

107

00:04:40,340  -->  00:04:43,530
these values, weighted values summed up,
108

108

00:04:43,530  -->  00:04:45,570
weights have a completely different meaning.
109

109

00:04:45,570  -->  00:04:49,120
This node is actually also trying
110

110

00:04:49,120  -->  00:04:54,120
to be a, like a ghost, a type of a ghost in our input space.
111

111

00:04:54,630  -->  00:04:58,620
It's trying to see where it can fit in our input space,
112

112

00:04:58,620  -->  00:04:59,980
and that's exactly what's going on.
113

113

00:04:59,980  -->  00:05:02,140
So these weights are the coordinates
114

114

00:05:02,140  -->  00:05:04,580
of this node in our input space.
115

115

00:05:04,580  -->  00:05:07,490
So here on one hand, for the input data set
116

116

00:05:07,490  -->  00:05:12,210
you have three nodes which represent each point.
117

117

00:05:12,210  -->  00:05:15,060
Or you could have 20 in the case if you had
118

118

00:05:15,060  -->  00:05:18,660
a twenty-dimensional input space, 20 columns in your inputs.
119

119

00:05:18,660  -->  00:05:21,690
Here you have one node representing a point
120

120

00:05:21,690  -->  00:05:25,860
in your input space, and again if you had 20 columns
121

121

00:05:25,860  -->  00:05:27,870
in your inputs, if you had 20 columns here,
122

122

00:05:27,870  -->  00:05:29,740
each node would have 20 weights.
123

123

00:05:29,740  -->  00:05:30,950
So that's important to understand.
124

124

00:05:30,950  -->  00:05:33,920
So basically just think of these output nodes, these ones,
125

125

00:05:33,920  -->  00:05:36,860
these red ones, each one of them is a ghost,
126

126

00:05:36,860  -->  00:05:41,510
or a imaginary data point in our input space.
127

127

00:05:41,510  -->  00:05:44,270
Doesn't actually exist there, it's trying to blend in.
128

128

00:05:44,270  -->  00:05:46,210
So there we go, that's node number one.
129

129

00:05:46,210  -->  00:05:48,980
Same thing we can do for node number two.
130

130

00:05:48,980  -->  00:05:51,400
Same thing for node number three.
131

131

00:05:51,400  -->  00:05:54,210
Same thing for node number four, and so on.
132

132

00:05:54,210  -->  00:05:56,840
So, each one of the nodes, in our case nine,
133

133

00:05:56,840  -->  00:06:00,100
or there could be many more, has its own weights
134

134

00:06:00,100  -->  00:06:01,280
at the start of the algorithm,
135

135

00:06:01,280  -->  00:06:04,340
as usually weights are assigned at random
136

136

00:06:04,340  -->  00:06:07,370
to values close to zero but not zero.
137

137

00:06:07,370  -->  00:06:08,900
And therefore each one of these nodes
138

138

00:06:08,900  -->  00:06:13,900
has its own imaginary place in the input space.
139

139

00:06:14,030  -->  00:06:16,970
And so why is this important? Where is this leading us to?
140

140

00:06:16,970  -->  00:06:21,970
Well, this is the core of the self-organizing map algorithm.
141

141

00:06:22,020  -->  00:06:24,810
Now we're going to have a competition.
142

142

00:06:24,810  -->  00:06:27,920
Among these nodes, we're going to go through
143

143

00:06:27,920  -->  00:06:29,640
each of our rows of our data set,
144

144

00:06:29,640  -->  00:06:32,890
and we're going to find out which of these nodes is closest
145

145

00:06:32,890  -->  00:06:34,810
to each of our rows in our data set.
146

146

00:06:34,810  -->  00:06:36,130
And we'll start with row number one.
147

147

00:06:36,130  -->  00:06:38,890
So let's go ahead and imagine that we've inputted
148

148

00:06:38,890  -->  00:06:42,500
row number one of our data set into our input nodes.
149

149

00:06:42,500  -->  00:06:44,130
So we've put in column one, column two,
150

150

00:06:44,130  -->  00:06:45,970
column three, the values of row number one.
151

151

00:06:45,970  -->  00:06:47,090
And now we're going to go through
152

152

00:06:47,090  -->  00:06:48,540
every single one of these nodes,
153

153

00:06:48,540  -->  00:06:51,330
and find out which of these is the closest
154

154

00:06:51,330  -->  00:06:54,570
in that original input space, which of these nodes
155

155

00:06:54,570  -->  00:06:56,570
is closest to our row number one.
156

156

00:06:56,570  -->  00:06:58,720
And the way we calculate it is,
157

157

00:06:58,720  -->  00:07:00,840
basically so let's calculate for node number one.
158

158

00:07:00,840  -->  00:07:03,120
We calculate the distance as a Euclidean distance.
159

159

00:07:03,120  -->  00:07:07,380
So it's calculated as X one minus W one one squared,
160

160

00:07:07,380  -->  00:07:09,380
plus X two minus W one two squared,
161

161

00:07:09,380  -->  00:07:11,540
plus X three minus W one three squared,
162

162

00:07:11,540  -->  00:07:13,260
and the square root out of all of that.
163

163

00:07:13,260  -->  00:07:15,410
And let's say we get a value of 1.2.
164

164

00:07:15,410  -->  00:07:18,660
And by the way you should get a values close to one here,
165

165

00:07:18,660  -->  00:07:21,460
because you should make sure that
166

166

00:07:21,460  -->  00:07:23,570
your inputs are between zero and one
167

167

00:07:23,570  -->  00:07:25,660
for all of this algorithm to work properly.
168

168

00:07:25,660  -->  00:07:27,406
So as we discussed previously,
169

169

00:07:27,406  -->  00:07:29,970
normalization or standardization,
170

170

00:07:29,970  -->  00:07:32,310
you've got to apply those things before you actually
171

171

00:07:32,310  -->  00:07:34,880
input the data into the self-organizing map.
172

172

00:07:34,880  -->  00:07:37,370
So that's the distance between node number one
173

173

00:07:37,370  -->  00:07:39,670
and row number one of our data set.
174

174

00:07:39,670  -->  00:07:41,030
Now we're not changing the row,
175

175

00:07:41,030  -->  00:07:42,340
we're still on row number one, but
176

176

00:07:42,340  -->  00:07:43,820
let's calculate the distance to
177

177

00:07:43,820  -->  00:07:46,450
node number two in our input space.
178

178

00:07:46,450  -->  00:07:49,865
The distance is calculated, let's say for example, 0.8.
179

179

00:07:49,865  -->  00:07:53,080
Then we'll calculate the distance to node number three,
180

180

00:07:53,080  -->  00:07:55,115
and this time the distance is 0.4.
181

181

00:07:55,115  -->  00:07:59,220
So you can see that row number one, or this input,
182

182

00:07:59,220  -->  00:08:03,130
this point in our data that this row is representing
183

183

00:08:03,130  -->  00:08:05,920
is three times closer to node number three
184

184

00:08:05,920  -->  00:08:08,844
that it is to node number one in our
185

185

00:08:08,844  -->  00:08:11,390
original three-dimensional space.
186

186

00:08:11,390  -->  00:08:14,620
And then we calculate the same thing for node number four,
187

187

00:08:14,620  -->  00:08:17,950
we get a value of 1.1 for example, and so on.
188

188

00:08:17,950  -->  00:08:22,140
So we calculate all of the distances between row number one,
189

189

00:08:22,140  -->  00:08:24,940
by the way we're still on row number one, we've calculated
190

190

00:08:24,940  -->  00:08:27,550
the distance between row number one, or the point that
191

191

00:08:27,550  -->  00:08:29,410
row number one represents in our input space,
192

192

00:08:29,410  -->  00:08:34,100
to each one these nodes in our self-organizing map.
193

193

00:08:34,100  -->  00:08:36,420
And we found that the closest one
194

194

00:08:36,420  -->  00:08:38,490
out of all of them them is node number three.
195

195

00:08:38,490  -->  00:08:40,550
And we're going to call node number three
196

196

00:08:40,550  -->  00:08:43,760
BMU, or the best matching unit.
197

197

00:08:43,760  -->  00:08:46,090
So that is the core of the algorithm,
198

198

00:08:46,090  -->  00:08:48,510
and now we want to find out what happens next.
199

199

00:08:48,510  -->  00:08:52,500
What happens with all of this, with this result,
200

200

00:08:52,500  -->  00:08:55,540
next what goes on in the self-organizing maps.
201

201

00:08:55,540  -->  00:08:59,390
So for that let's look at a larger self-organizing map.
202

202

00:08:59,390  -->  00:09:00,710
I know this is a bit counterintuitive,
203

203

00:09:00,710  -->  00:09:02,630
usually we make things smaller
204

204

00:09:02,630  -->  00:09:04,010
when we want to understand them better,
205

205

00:09:04,010  -->  00:09:07,070
but in this case we will need a larger map
206

206

00:09:07,070  -->  00:09:08,680
to understand this concept better.
207

207

00:09:08,680  -->  00:09:10,760
And let's say in this larger map we found
208

208

00:09:10,760  -->  00:09:13,200
the best matching unit for row number one.
209

209

00:09:13,200  -->  00:09:14,170
There it is.
210

210

00:09:14,170  -->  00:09:17,140
So what's going to happen next is the self-organizing map
211

211

00:09:17,140  -->  00:09:20,456
is actually going to update the weights,
212

212

00:09:20,456  -->  00:09:23,800
and I'm doing air quotations here for the word weights
213

213

00:09:23,800  -->  00:09:25,620
because they're still called weights,
214

214

00:09:25,620  -->  00:09:27,639
they're just different to the weights that we're used to.
215

215

00:09:27,639  -->  00:09:31,600
as you can see just now, weights are not actually
216

216

00:09:31,600  -->  00:09:34,060
used in the same way, here weights are
217

217

00:09:34,060  -->  00:09:35,850
characteristic of that specific node.
218

218

00:09:35,850  -->  00:09:38,240
So the weights are going to be updated
219

219

00:09:38,240  -->  00:09:41,960
for this best matching unit, so that it is
220

220

00:09:41,960  -->  00:09:46,960
actually even closer to our first row in our data set.
221

221

00:09:47,100  -->  00:09:49,010
And the reason we are updating the weights is because
222

222

00:09:49,010  -->  00:09:51,160
we simply don't have control of our inputs,
223

223

00:09:51,160  -->  00:09:53,440
we cannot our data set, so the only thing
224

224

00:09:53,440  -->  00:09:55,840
that we can control in that formula are the weights
225

225

00:09:55,840  -->  00:09:58,790
of this node in order for it to become closer.
226

226

00:09:58,790  -->  00:10:00,990
And what that will, so there we go
227

227

00:10:00,990  -->  00:10:03,510
that flash means it was updated.
228

228

00:10:03,510  -->  00:10:06,180
And in simple terms what that means,
229

229

00:10:06,180  -->  00:10:07,450
or in visual terms what that means,
230

230

00:10:07,450  -->  00:10:10,530
is the self-organizing map is coming closer
231

231

00:10:10,530  -->  00:10:13,000
to that data point, so it's this part over here that,
232

232

00:10:13,000  -->  00:10:15,320
this is our self-organizing map with its starting weights,
233

233

00:10:15,320  -->  00:10:16,980
and now this point which is actually,
234

234

00:10:16,980  -->  00:10:20,894
as you can see in this image which is from Wikipedia,
235

235

00:10:20,894  -->  00:10:22,680
you can see that it's actually the closest
236

236

00:10:22,680  -->  00:10:24,070
to our current point that we're looking at
237

237

00:10:24,070  -->  00:10:27,960
to row number one, and now we're going to drag it closer,
238

238

00:10:27,960  -->  00:10:29,729
we're going to drag it closer to this point.
239

239

00:10:29,729  -->  00:10:32,040
In the end is a result that we want like this,
240

240

00:10:32,040  -->  00:10:34,447
but let's not get ahead of ourselves for now.
241

241

00:10:34,447  -->  00:10:37,323
At this stage we're just happy to drag that
242

242

00:10:37,323  -->  00:10:41,010
one best matching unit, or BMU, to the current row.
243

243

00:10:41,010  -->  00:10:42,880
So we're dragging it a bit closer.
244

244

00:10:42,880  -->  00:10:44,430
So that's exactly what's going on,
245

245

00:10:44,430  -->  00:10:46,300
and that's why it's called a self-organizing map.
246

246

00:10:46,300  -->  00:10:50,090
It self-organizes onto your input data.
247

247

00:10:50,090  -->  00:10:51,570
And, by the way, as you can see here,
248

248

00:10:51,570  -->  00:10:53,640
what's happening is not just this one point
249

249

00:10:53,640  -->  00:10:55,680
is being dragged closer, but also
250

250

00:10:55,680  -->  00:10:59,040
some of the close, some of the nearby points
251

251

00:10:59,040  -->  00:11:01,570
are being dragged closer to this point.
252

252

00:11:01,570  -->  00:11:03,750
And that's exactly what we're going to look at next.
253

253

00:11:03,750  -->  00:11:07,690
So here's our best matching unit in the self-organizing map.
254

254

00:11:07,690  -->  00:11:10,745
The next step that we have is a whole radius
255

255

00:11:10,745  -->  00:11:15,530
around this best matching unit, and every single point,
256

256

00:11:15,530  -->  00:11:18,280
every single node of our self-organizing map
257

257

00:11:18,280  -->  00:11:21,420
that falls inside that radius is going to have
258

258

00:11:21,420  -->  00:11:23,830
its weight updated to come closer
259

259

00:11:23,830  -->  00:11:27,110
to that row that we matched up with.
260

260

00:11:27,110  -->  00:11:30,090
So there you go, they all got their weights updated.
261

261

00:11:30,090  -->  00:11:33,500
And the way it works is the closer you are to the BMU,
262

262

00:11:33,500  -->  00:11:35,480
the heavier are your weights updated.
263

263

00:11:35,480  -->  00:11:37,610
So these weights are going to be updated the most,
264

264

00:11:37,610  -->  00:11:39,600
these weights are going to be updated less,
265

265

00:11:39,600  -->  00:11:41,730
these weights are going to be updated even less.
266

266

00:11:41,730  -->  00:11:44,810
And to think of it as, the best way to think of it is
267

267

00:11:44,810  -->  00:11:46,990
as if they are dragging each other.
268

268

00:11:46,990  -->  00:11:50,910
So as you pull on this one, the whole,
269

269

00:11:50,910  -->  00:11:54,150
this whole chain or this whole structure
270

270

00:11:54,150  -->  00:11:56,960
is slowly pulled towards the same direction.
271

271

00:11:56,960  -->  00:11:58,970
So the closer you are to this BMU,
272

272

00:11:58,970  -->  00:12:01,610
the harder you will get pulled towards that row
273

273

00:12:01,610  -->  00:12:05,290
that you matched up with, or the BMU matched up with.
274

274

00:12:05,290  -->  00:12:08,210
So that's how the radius concept works.
275

275

00:12:08,210  -->  00:12:09,860
Now let's have a look at row number two.
276

276

00:12:09,860  -->  00:12:12,790
Let's say row number two had its best matching unit
277

277

00:12:12,790  -->  00:12:14,340
somewhere else, for instance over there.
278

278

00:12:14,340  -->  00:12:16,301
That's the best matching unit for row number two.
279

279

00:12:16,301  -->  00:12:20,140
Well what happens here is again that row, that BMU
280

280

00:12:20,140  -->  00:12:23,460
is updated to be closer, and it has its own radius,
281

281

00:12:23,460  -->  00:12:25,680
so everything with the radius is also updated
282

282

00:12:25,680  -->  00:12:30,520
to be closer to that row that we matched up with.
283

283

00:12:30,520  -->  00:12:34,370
And so the question here is how do they combat each other,
284

284

00:12:34,370  -->  00:12:36,040
how do they fight with each other?
285

285

00:12:36,040  -->  00:12:39,190
Well it's pretty simple. So let's have a look at one point.
286

286

00:12:39,190  -->  00:12:42,090
Let's gray all of them out except for this one red one.
287

287

00:12:42,090  -->  00:12:44,843
And as you can see it's quite far away from the green BMU,
288

288

00:12:44,843  -->  00:12:46,860
it's quite close to the blue BMU,
289

289

00:12:46,860  -->  00:12:48,633
in fact it might be so far away from the green BMU
290

290

00:12:48,633  -->  00:12:51,690
that it doesn't even fall within its radius.
291

291

00:12:51,690  -->  00:12:53,940
So what happens here is that it is pulled
292

292

00:12:53,940  -->  00:12:56,220
much harder with the blue BMU,
293

293

00:12:56,220  -->  00:12:59,520
and therefore it becomes like the blue BMU.
294

294

00:12:59,520  -->  00:13:02,620
So it becomes closer, and we're going to color it in blue.
295

295

00:13:02,620  -->  00:13:04,970
Then let's have a look at this one, same thing here,
296

296

00:13:04,970  -->  00:13:06,640
oh not same thing here, this is a bit different.
297

297

00:13:06,640  -->  00:13:08,830
So this one is still far away from the green one,
298

298

00:13:08,830  -->  00:13:12,450
but it's also quite far away from the blue one.
299

299

00:13:12,450  -->  00:13:14,810
In fact, it's just a bit closer to the blue one
300

300

00:13:14,810  -->  00:13:16,505
than the green one, so when we pull on it
301

301

00:13:16,505  -->  00:13:18,320
it will be updated, so in this case,
302

302

00:13:18,320  -->  00:13:21,270
we'll color it in kind of like a greenish-blue.
303

303

00:13:21,270  -->  00:13:23,470
And then this one, this one is actually closer
304

304

00:13:23,470  -->  00:13:26,340
to the green BMU than to the blue BMU,
305

305

00:13:26,340  -->  00:13:28,420
and therefore when we pull on the green
306

306

00:13:28,420  -->  00:13:31,410
and then we pull on the blue, they'll be a bit of a struggle
307

307

00:13:31,410  -->  00:13:33,860
but overall it will move closer
308

308

00:13:33,860  -->  00:13:35,680
to the green one than to the blue one.
309

309

00:13:35,680  -->  00:13:37,570
But both of them will have an impact.
310

310

00:13:37,570  -->  00:13:39,870
And then finally, here is another one.
311

311

00:13:39,870  -->  00:13:44,360
So this node is even closer to the green,
312

312

00:13:44,360  -->  00:13:46,610
and it's quite far away the blue BMU,
313

313

00:13:46,610  -->  00:13:49,560
and therefore when you pull on the green and the blue,
314

314

00:13:49,560  -->  00:13:51,150
of course they're both gonna have an impact,
315

315

00:13:51,150  -->  00:13:54,140
but the green is going to have a much stronger impact,
316

316

00:13:54,140  -->  00:13:56,600
and therefore we are going to color it in green.
317

317

00:13:56,600  -->  00:13:59,410
So there we go, that's us just looking at four random nodes
318

318

00:13:59,410  -->  00:14:04,040
in our self-organizing map, and hopefully that demonstrates
319

319

00:14:04,040  -->  00:14:08,520
how this map self-organizes itself onto your data points
320

320

00:14:08,520  -->  00:14:12,150
in the input, and that's a good start for us for today.
321

321

00:14:12,150  -->  00:14:15,140
In the next tutorial, we will continue exploring
322

322

00:14:15,140  -->  00:14:17,210
what happens when you have even more BMUs
323

323

00:14:17,210  -->  00:14:20,380
and how all the self-organizing map updates.
324

324

00:14:20,380  -->  00:14:21,590
I look forward to seeing you then,
325

325

00:14:21,590  -->  00:14:23,863
and until next time, enjoy deep learning.
