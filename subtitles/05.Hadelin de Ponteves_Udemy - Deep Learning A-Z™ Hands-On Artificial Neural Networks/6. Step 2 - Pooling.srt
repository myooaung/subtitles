1
1

00:00:00,520  -->  00:00:01,770
<v Narrator>Hello and welcome back to the course</v>
2

2

00:00:01,770  -->  00:00:02,910
on deep learning.
3

3

00:00:02,910  -->  00:00:04,480
Today we're talking about max pooling
4

4

00:00:04,480  -->  00:00:06,962
and we've got some very exciting slides coming up ahead
5

5

00:00:06,962  -->  00:00:10,910
and even a special surprise at the very end of the tutorial.
6

6

00:00:10,910  -->  00:00:11,955
So, let's get started.
7

7

00:00:11,955  -->  00:00:14,473
The first question is: what is pooling and
8

8

00:00:14,473  -->  00:00:15,960
why do we need it?
9

9

00:00:15,960  -->  00:00:17,730
Well, to answer that question let's have a look
10

10

00:00:17,730  -->  00:00:19,688
at these images. On these 3 images, we've got
11

11

00:00:19,688  -->  00:00:22,161
a cheetah, in fact it is the same exact cheetah.
12

12

00:00:22,161  -->  00:00:25,580
On the 1st image, the image is positioned properly
13

13

00:00:25,580  -->  00:00:27,970
and the cheetah is looking straight at you.
14

14

00:00:27,970  -->  00:00:30,570
On the 2nd image, it's a bit rotated
15

15

00:00:30,570  -->  00:00:32,296
and the 3rd image is a bit squashed.
16

16

00:00:32,296  -->  00:00:36,580
And the thing here is that we want the neural network
17

17

00:00:36,580  -->  00:00:38,890
to be able to recognize the cheetah
18

18

00:00:38,890  -->  00:00:40,907
in every single one of these images.
19

19

00:00:40,907  -->  00:00:43,160
In fact, this is just one cheetah.
20

20

00:00:43,160  -->  00:00:44,990
What if we have lots of different cheetahs?
21

21

00:00:44,990  -->  00:00:47,078
Here's a cheetah, here's another cheetah,
22

22

00:00:47,078  -->  00:00:50,490
here's a cheetah, here's a cheetah.
23

23

00:00:50,490  -->  00:00:51,570
and here's a cheetah.
24

24

00:00:51,570  -->  00:00:53,680
And we want the neural network to recognize
25

25

00:00:53,680  -->  00:00:57,326
all of these cheetahs as cheetahs and how can it
26

26

00:00:57,326  -->  00:01:01,030
do that if they're all looking in different
27

27

00:01:01,030  -->  00:01:04,030
directions, they're all in different parts of the image,
28

28

00:01:04,030  -->  00:01:05,720
their like, their faces are all positioned
29

29

00:01:05,720  -->  00:01:07,380
in different parts of the image, somebody's
30

30

00:01:07,380  -->  00:01:09,490
on the right hand side, somebody's in the left corner,
31

31

00:01:09,490  -->  00:01:10,730
somebody's in the middle.
32

32

00:01:10,730  -->  00:01:12,410
Uh, they're all a bit different.
33

33

00:01:12,410  -->  00:01:13,900
The texture's a little bit different,
34

34

00:01:13,900  -->  00:01:16,110
the lighting's a bit different.
35

35

00:01:16,110  -->  00:01:18,430
There's lots of little differences and so if
36

36

00:01:18,430  -->  00:01:20,359
the neural network looks for exactly
37

37

00:01:20,359  -->  00:01:22,740
a certain feature, for instance a distinctive
38

38

00:01:22,740  -->  00:01:26,485
feature of the cheetah is the tears that are
39

39

00:01:26,485  -->  00:01:30,850
on its face going from the eyes or the shadows
40

40

00:01:30,850  -->  00:01:34,170
that look like tears, the texture, the pattern
41

41

00:01:34,170  -->  00:01:36,784
that is going from its eyes down on the sides
42

42

00:01:36,784  -->  00:01:38,430
of its nose, that looks like tears
43

43

00:01:38,430  -->  00:01:40,830
that's a distinctive feature of the cheetah.
44

44

00:01:40,830  -->  00:01:43,590
But if it's looking for that feature which it
45

45

00:01:43,590  -->  00:01:47,086
learned from certain cheetahs, in an exact
46

46

00:01:47,086  -->  00:01:50,678
location or an exact shape or form or texture,
47

47

00:01:50,678  -->  00:01:52,877
it will never find these other cheetahs.
48

48

00:01:52,877  -->  00:01:56,808
So, we have to make sure that our neural network
49

49

00:01:56,808  -->  00:01:59,902
has a property called spatial invariance,
50

50

00:01:59,902  -->  00:02:02,780
meaning that it doesn't care
51

51

00:02:02,780  -->  00:02:07,780
where the features are located, not so much as in which part
52

52

00:02:08,679  -->  00:02:11,736
of the image because we've kind of taken that
53

53

00:02:11,736  -->  00:02:13,790
into consideration with our map,
54

54

00:02:13,790  -->  00:02:16,312
with our convolution layer.
55

55

00:02:16,312  -->  00:02:18,802
But it doesn't have to care if
56

56

00:02:18,802  -->  00:02:21,291
the features are a bit tilted, if the features
57

57

00:02:21,291  -->  00:02:24,130
are a bit different in texture, if the
58

58

00:02:24,130  -->  00:02:26,130
features are a bit closer or if the features
59

59

00:02:26,130  -->  00:02:30,140
are a bit further apart, relative to each other.
60

60

00:02:30,140  -->  00:02:32,177
So, if the feature itself is a bit distorted,
61

61

00:02:32,177  -->  00:02:36,766
our neural network has to have some level of flexibility
62

62

00:02:36,766  -->  00:02:39,900
to be able to still find that feature
63

63

00:02:39,900  -->  00:02:42,237
and that is what pooling is all about.
64

64

00:02:42,237  -->  00:02:44,631
So, let's have a look at how pooling works.
65

65

00:02:44,631  -->  00:02:46,960
Here's our feature map, so we've already done
66

66

00:02:46,960  -->  00:02:49,912
our convolution and we've completed that part
67

67

00:02:49,912  -->  00:02:52,570
and now we're working with the convolution layer.
68

68

00:02:52,570  -->  00:02:53,800
Now we're going to apply pooling.
69

69

00:02:53,800  -->  00:02:54,633
So how does it work?
70

70

00:02:54,633  -->  00:02:56,410
We're going to be applying max pooling.
71

71

00:02:56,410  -->  00:02:57,270
Uh, there's several different types of
72

72

00:02:57,270  -->  00:02:59,480
pooling you can apply, there's mean pooling,
73

73

00:02:59,480  -->  00:03:01,640
max pooling, some pooling and we'll comment
74

74

00:03:01,640  -->  00:03:03,460
on those towards the end of this tutorial.
75

75

00:03:03,460  -->  00:03:04,990
But for now we're just applying max pooling.
76

76

00:03:04,990  -->  00:03:09,341
So, we take a box of 2x2 pixels, like that,
77

77

00:03:09,341  -->  00:03:12,520
and again it doesn't have to be 2x2, you can
78

78

00:03:12,520  -->  00:03:13,985
choose any size of box and again we'll comment
79

79

00:03:13,985  -->  00:03:15,790
on that towards the end of the tutorial.
80

80

00:03:15,790  -->  00:03:18,699
And, you place it in the top left hand corner
81

81

00:03:18,699  -->  00:03:21,830
and you find the maximum value in that box
82

82

00:03:21,830  -->  00:03:23,765
and then you record only that value.
83

83

00:03:23,765  -->  00:03:26,920
And you disregard the other 3, so in your
84

84

00:03:26,920  -->  00:03:29,010
box you have 4 values, you disregard three,
85

85

00:03:29,010  -->  00:03:31,690
you only keep one, the maximum, which is 1 in this case.
86

86

00:03:31,690  -->  00:03:34,560
Then you move your box to the right, by a stride,
87

87

00:03:34,560  -->  00:03:36,120
you select the stride once again.
88

88

00:03:36,120  -->  00:03:39,043
So here we select a stride of 2 and that's
89

89

00:03:39,043  -->  00:03:40,970
what you normally select.
90

90

00:03:40,970  -->  00:03:42,555
You can select a stride of 1, you can select
91

91

00:03:42,555  -->  00:03:44,800
so they're overlapping boxes, you can select
92

92

00:03:44,800  -->  00:03:47,749
any kind of stride you like, even 3 if you want.
93

93

00:03:47,749  -->  00:03:50,130
But we're selecting a stride of 2 here,
94

94

00:03:50,130  -->  00:03:52,350
that's what is commonly used.
95

95

00:03:52,350  -->  00:03:55,210
And then you repeat the process, record the maximum.
96

96

00:03:55,210  -->  00:03:57,980
Here, if you cross over it doesn't matter, you
97

97

00:03:57,980  -->  00:03:59,980
just keep continue doing what you're doing.
98

98

00:03:59,980  -->  00:04:02,722
So you still record the maximum here, 0.
99

99

00:04:02,722  -->  00:04:05,954
Um, here the maximum is 4, here the maximum is 2,
100

100

00:04:05,954  -->  00:04:10,621
here the maximum is 1, 0, 2 and then 1.
101

101

00:04:10,621  -->  00:04:13,910
As you can see, a few things happened.
102

102

00:04:13,910  -->  00:04:16,000
First of all, we still were able
103

103

00:04:16,000  -->  00:04:18,060
to preserve the features, right.
104

104

00:04:18,060  -->  00:04:21,277
The maximum numbers, they represent,
105

105

00:04:21,277  -->  00:04:23,660
because we know how the convolution layer works,
106

106

00:04:23,660  -->  00:04:26,300
we know that the maximum or the large numbers
107

107

00:04:26,300  -->  00:04:27,950
in your feature map, they represent
108

108

00:04:27,950  -->  00:04:30,030
where you actually found the closest
109

109

00:04:30,030  -->  00:04:31,570
similarity to your feature.
110

110

00:04:31,570  -->  00:04:33,941
But by then pooling these features,
111

111

00:04:33,941  -->  00:04:37,109
we are, first of all, getting rid of 75%
112

112

00:04:37,109  -->  00:04:40,900
of the information that is not the feature,
113

113

00:04:40,900  -->  00:04:44,020
which is not the important things that
114

114

00:04:44,020  -->  00:04:47,370
we're looking out for because we're disregarding
115

115

00:04:47,370  -->  00:04:50,776
3 pixels out of 4 so we're only keeping 25%,
116

116

00:04:50,776  -->  00:04:55,717
and then also because we are taking the maximum
117

117

00:04:55,717  -->  00:04:59,848
of the pixels or the values that we have,
118

118

00:04:59,848  -->  00:05:03,574
we are therefore accounting for any distortion.
119

119

00:05:03,574  -->  00:05:07,917
So, for instance, 2 images in which, for example,
120

120

00:05:07,917  -->  00:05:12,760
the cheetahs tears' on the eyes are, in 1 image,
121

121

00:05:12,760  -->  00:05:15,470
a bit to the left or a bit rotated to the left.
122

122

00:05:15,470  -->  00:05:17,220
And then in the other one, they're a bit
123

123

00:05:17,220  -->  00:05:19,061
how they're supposed to be or how we,
124

124

00:05:19,061  -->  00:05:20,530
like if we take 1 as the basis and
125

125

00:05:20,530  -->  00:05:23,762
then the other one, they're a bit rotated to the left.
126

126

00:05:23,762  -->  00:05:26,154
The pooled feature will be exactly the same
127

127

00:05:26,154  -->  00:05:28,093
so you can see here, if we're talking
128

128

00:05:28,093  -->  00:05:31,630
about the cheetah's tears then let's say
129

129

00:05:31,630  -->  00:05:33,802
this is the 4 and this is where it was here.
130

130

00:05:33,802  -->  00:05:36,590
Then if it was a bit rotated, so for instance
131

131

00:05:36,590  -->  00:05:38,710
the 4 ended up over here, then when we
132

132

00:05:38,710  -->  00:05:41,220
are doing the pooling, we're still gonna get
133

133

00:05:41,220  -->  00:05:43,030
the same pooled feature map.
134

134

00:05:43,030  -->  00:05:45,569
And that's kind of the principle behind it,
135

135

00:05:45,569  -->  00:05:48,704
it's a very rough explanation again,
136

136

00:05:48,704  -->  00:05:50,318
intuitive explanation, but that's the point
137

137

00:05:50,318  -->  00:05:53,063
of pooling that we're still being able to
138

138

00:05:53,063  -->  00:05:55,690
preserve the features and moreover,
139

139

00:05:55,690  -->  00:06:00,220
account for their possible spatial or textural
140

140

00:06:00,220  -->  00:06:02,290
or other kind of distortions.
141

141

00:06:02,290  -->  00:06:05,130
And in addition to all of that, we're reducing
142

142

00:06:05,130  -->  00:06:07,310
the size, so there's another benefit.
143

143

00:06:07,310  -->  00:06:09,469
So, we've got, we're preserving the features,
144

144

00:06:09,469  -->  00:06:11,720
we're introducing spatial invariance,
145

145

00:06:11,720  -->  00:06:16,720
we're reducing the size by 75% which is huge,
146

146

00:06:16,755  -->  00:06:19,252
which is really gonna help in terms of processing.
147

147

00:06:19,252  -->  00:06:22,810
And, moreover, another benefit of pooling is
148

148

00:06:22,810  -->  00:06:25,340
we're reducing the number of parameters, so we're
149

149

00:06:25,340  -->  00:06:27,848
reducing again by 75%, we're reducing the
150

150

00:06:27,848  -->  00:06:29,485
number of parameters that are going to go
151

151

00:06:29,485  -->  00:06:32,109
into our final layers of the neural network.
152

152

00:06:32,109  -->  00:06:34,791
And therefore, we're preventing overfitting.
153

153

00:06:34,791  -->  00:06:37,730
It is a very important benefit of pooling
154

154

00:06:37,730  -->  00:06:41,826
that we're removing information and that is a good thing,
155

155

00:06:41,826  -->  00:06:44,354
that is a good thing because that way,
156

156

00:06:44,354  -->  00:06:48,124
our model won't be able to overfit
157

157

00:06:48,124  -->  00:06:50,561
onto that information because especially
158

158

00:06:50,561  -->  00:06:52,610
because that information is not relevant.
159

159

00:06:52,610  -->  00:06:54,320
Remember like at the very start, we were talking
160

160

00:06:54,320  -->  00:06:57,090
about even for us as humans, it's important
161

161

00:06:57,090  -->  00:06:59,780
to see exactly the features, rather than all
162

162

00:06:59,780  -->  00:07:01,963
this other noise that is coming into our eyes.
163

163

00:07:01,963  -->  00:07:04,430
Well, same thing for neural networks.
164

164

00:07:04,430  -->  00:07:07,613
They, by disregarding the unnecessary non-important
165

165

00:07:07,613  -->  00:07:11,729
information, we're helping with preventing of overfitting.
166

166

00:07:11,729  -->  00:07:14,500
So there we go, that is what pooling is about.
167

167

00:07:14,500  -->  00:07:19,500
And the question here is of course, why max pooling?
168

168

00:07:19,600  -->  00:07:20,840
Right, there's lots of different types
169

169

00:07:20,840  -->  00:07:23,580
of pooling and you know, why a stride of 2?,
170

170

00:07:23,580  -->  00:07:26,650
why a size of 2x2 pixels?, lots of all these things.
171

171

00:07:26,650  -->  00:07:29,790
And all that note I'd like to introduce you
172

172

00:07:29,790  -->  00:07:32,607
to this lovely research paper called
173

173

00:07:32,607  -->  00:07:35,580
"Evaluation of Pooling Operations in Convolutional
174

174

00:07:35,580  -->  00:07:37,690
Architectures for Object Recognition"
175

175

00:07:37,690  -->  00:07:40,647
by Dominic Scherer from University of Bonn.
176

176

00:07:40,647  -->  00:07:43,380
There is a link and the beauty about
177

177

00:07:43,380  -->  00:07:46,670
this paper is that it's very very simple,
178

178

00:07:46,670  -->  00:07:47,503
very straightforward.
179

179

00:07:47,503  -->  00:07:49,870
So if you've never read a research paper,
180

180

00:07:49,870  -->  00:07:51,450
but you'd like to give it a go,
181

181

00:07:51,450  -->  00:07:53,770
this is a great place to start.
182

182

00:07:53,770  -->  00:07:56,257
It's very short, only 10 pages, very easy to read.
183

183

00:07:56,257  -->  00:07:59,410
And plus the extra benefit is that now that we've
184

184

00:07:59,410  -->  00:08:02,580
discussed convolution and pooling, you will be
185

185

00:08:02,580  -->  00:08:04,650
totally comfortable with everything
186

186

00:08:04,650  -->  00:08:06,052
they're talking about in this paper.
187

187

00:08:06,052  -->  00:08:08,754
This is a great way to actually reinforce your
188

188

00:08:08,754  -->  00:08:11,930
knowledge so I highly recommend checking this paper out.
189

189

00:08:11,930  -->  00:08:13,421
It will take 20 mins to read it
190

190

00:08:13,421  -->  00:08:16,677
and you can even skip part 2, which is called
191

191

00:08:16,677  -->  00:08:18,930
"Related Work" if it feels a bit far-fetched
192

192

00:08:18,930  -->  00:08:21,230
or alienating, just don't read that part,
193

193

00:08:21,230  -->  00:08:23,403
go straight from part 1 to part 3.
194

194

00:08:23,403  -->  00:08:26,040
And the one thing that you do need to know about
195

195

00:08:26,040  -->  00:08:30,129
this paper, they talk about a concept called sub-sampling.
196

196

00:08:30,129  -->  00:08:32,770
Well sub-sampling is basically average pooling.
197

197

00:08:32,770  -->  00:08:35,239
So, remember how here we were taking, we were
198

198

00:08:35,239  -->  00:08:38,168
taking the maximum, so you now square root,
199

199

00:08:38,168  -->  00:08:39,890
taking the maximum value.
200

200

00:08:39,890  -->  00:08:42,960
There's a concept called mean pooling or sum pooling.
201

201

00:08:42,960  -->  00:08:45,140
Sum pooling is just you sum these values up.
202

202

00:08:45,140  -->  00:08:47,150
Average pooling, or mean pooling, you take
203

203

00:08:47,150  -->  00:08:49,900
the average value out of all of these.
204

204

00:08:49,900  -->  00:08:51,660
And sub-sampling is kind of like a
205

205

00:08:51,660  -->  00:08:55,074
generalization of mean pooling, it's a more
206

206

00:08:55,074  -->  00:08:57,786
kind of generalized approach to taking the
207

207

00:08:57,786  -->  00:09:00,780
average of these values.
208

208

00:09:00,780  -->  00:09:02,380
And you can read a bit more about it in the paper,
209

209

00:09:02,380  -->  00:09:03,570
but otherwise just think of it
210

210

00:09:03,570  -->  00:09:06,437
as average pooling when you're reading that paper.
211

211

00:09:06,437  -->  00:09:07,890
And so that's where you can get some
212

212

00:09:07,890  -->  00:09:09,850
additional information on this topic.
213

213

00:09:09,850  -->  00:09:12,240
And now, kind of, let's recap where have we got onto?
214

214

00:09:12,240  -->  00:09:15,430
So, there's our input image, then we apply the
215

215

00:09:15,430  -->  00:09:18,970
convolution operation and we got the convolution layer.
216

216

00:09:18,970  -->  00:09:22,137
And now, to each of those feature maps that we get,
217

217

00:09:22,137  -->  00:09:25,017
we've applied the pooling layer so we've done
218

218

00:09:25,017  -->  00:09:28,450
these two steps: convolution and pooling.
219

219

00:09:28,450  -->  00:09:30,870
And now, we're going to do something very fun,
220

220

00:09:30,870  -->  00:09:32,925
something very exciting, we're going to
221

221

00:09:32,925  -->  00:09:34,370
experiment with this.
222

222

00:09:34,370  -->  00:09:37,899
So this is a screenshot I took from a tool,
223

223

00:09:37,899  -->  00:09:40,770
created by Adam Harley from
224

224

00:09:42,414  -->  00:09:45,961
back when he was at Ryerson University of Computer Science
225

225

00:09:45,961  -->  00:09:49,534
and now he's at Carnegie Mellon, I think doing his PhD.
226

226

00:09:49,534  -->  00:09:53,170
And great tool, so let's open up, let's have a look.
227

227

00:09:53,170  -->  00:09:55,210
So you can find it, you can't actually find it
228

228

00:09:55,210  -->  00:09:57,420
through Google, you have to know the URL.
229

229

00:09:57,420  -->  00:09:59,480
It's, it's just hard to find it
230

230

00:09:59,480  -->  00:10:01,780
through Google 'cause there's no text here.
231

231

00:10:01,780  -->  00:10:04,087
Well, just this URL. (laughing)
232

232

00:10:04,087  -->  00:10:08,220
"scs.ryerson.ca" and then this stuff on the end.
233

233

00:10:08,220  -->  00:10:11,290
And basically, this is exactly
234

234

00:10:11,290  -->  00:10:12,640
what we're doing but visualized.
235

235

00:10:12,640  -->  00:10:14,300
So here you need to draw a number,
236

236

00:10:14,300  -->  00:10:16,203
so let's say I draw a number 4.
237

237

00:10:16,203  -->  00:10:21,203
And this tool will put the number 4 here,
238

238

00:10:21,260  -->  00:10:24,630
that's your image in our first step, then this is the
239

239

00:10:24,630  -->  00:10:26,990
convolution step, right?
240

240

00:10:26,990  -->  00:10:28,830
And this is the pooling step and also pooling,
241

241

00:10:28,830  -->  00:10:30,300
by the way, is also called down-sampling.
242

242

00:10:30,300  -->  00:10:33,860
So, pooling and down-sampling are the same things.
243

243

00:10:33,860  -->  00:10:35,870
So you can see it's applied convolution and
244

244

00:10:35,870  -->  00:10:37,950
it's applied pooling and you can see
245

245

00:10:37,950  -->  00:10:39,450
how it exactly works, so you can see
246

246

00:10:39,450  -->  00:10:41,840
what kinds of convolutions it has applied,
247

247

00:10:41,840  -->  00:10:44,030
or what kind of filters it's applied,
248

248

00:10:44,030  -->  00:10:45,220
what they look like, you can see what
249

249

00:10:45,220  -->  00:10:47,730
features it's looking out for.
250

250

00:10:47,730  -->  00:10:49,543
And then it's applied pooling, so it's
251

251

00:10:49,543  -->  00:10:51,752
reducing the size and you can see here that,
252

252

00:10:51,752  -->  00:10:54,140
this is important right, so you can see
253

253

00:10:55,130  -->  00:10:58,373
that this is the convolved image
254

254

00:10:58,373  -->  00:11:00,660
and this is the pooled image and you can still
255

255

00:11:00,660  -->  00:11:02,601
see the same features, it's just less information
256

256

00:11:02,601  -->  00:11:04,230
but same features, right?
257

257

00:11:04,230  -->  00:11:07,534
The features are preserved, that's the important part.
258

258

00:11:07,534  -->  00:11:10,187
And moreover, you know if our 4 was a bit to the
259

259

00:11:10,187  -->  00:11:12,436
kind of like, rotated a bit to the side,
260

260

00:11:12,436  -->  00:11:14,850
it would still be able to pick
261

261

00:11:14,850  -->  00:11:16,830
up very similar pooled layers.
262

262

00:11:16,830  -->  00:11:18,480
And then after that it's got more layers,
263

263

00:11:18,480  -->  00:11:19,730
we haven't talked about that yet.
264

264

00:11:19,730  -->  00:11:23,399
So then it's got another convolution layer here,
265

265

00:11:23,399  -->  00:11:25,774
which we actually won't have.
266

266

00:11:25,774  -->  00:11:28,490
And then it has another pooled layer,
267

267

00:11:28,490  -->  00:11:30,860
but it's basically just repeating that same process.
268

268

00:11:30,860  -->  00:11:32,130
And then after that, this is what we are
269

269

00:11:32,130  -->  00:11:34,340
going to be talking about further down in the course.
270

270

00:11:34,340  -->  00:11:38,000
It's got all the fully connected layers and so on.
271

271

00:11:38,000  -->  00:11:39,810
But you can definitely play around with that,
272

272

00:11:39,810  -->  00:11:43,299
so if I delete that and if I draw a 7,
273

273

00:11:43,299  -->  00:11:47,185
you will see that it actually tells you the guess
274

274

00:11:47,185  -->  00:11:49,120
and it guesses that this is a 7
275

275

00:11:49,120  -->  00:11:52,930
and the second guess, the second likelihood is a 3.
276

276

00:11:52,930  -->  00:11:55,210
So you can draw it some challenging things
277

277

00:11:55,210  -->  00:11:56,350
and see if it can pick them up.
278

278

00:11:56,350  -->  00:11:58,420
So let's say, if I draw something that
279

279

00:11:58,420  -->  00:12:00,660
looks like a 0, but is not a finished 0
280

280

00:12:00,660  -->  00:12:01,970
will it pick it up?
281

281

00:12:01,970  -->  00:12:03,630
No, this time it didn't pick it up,
282

282

00:12:03,630  -->  00:12:06,080
looks like a 9 to the image.
283

283

00:12:06,080  -->  00:12:07,980
What if I kinda like finish like that?
284

284

00:12:07,980  -->  00:12:11,241
See now, it thinks it's a 0 or a 9 and you can
285

285

00:12:11,241  -->  00:12:13,812
see what's lighting up, the 0 or the 9,
286

286

00:12:13,812  -->  00:12:16,530
but we'll talk about that part further down.
287

287

00:12:16,530  -->  00:12:18,875
Let's do one more, let's say like 8,
288

288

00:12:18,875  -->  00:12:21,572
I think 8's are pretty hard for this.
289

289

00:12:21,572  -->  00:12:24,790
No, picked up a 8, so you can see that goes
290

290

00:12:24,790  -->  00:12:28,850
into an 8 and after that it stops being recognizable.
291

291

00:12:28,850  -->  00:12:32,040
It stops making sense to us humans, right?
292

292

00:12:32,040  -->  00:12:35,460
These features that it's working with, but at the same time,
293

293

00:12:35,460  -->  00:12:38,310
it is correctly recognizing that it's an 8.
294

294

00:12:38,310  -->  00:12:40,440
Alright, so definitely play around with that,
295

295

00:12:40,440  -->  00:12:44,190
you can draw a smiley face, see what happens then.
296

296

00:12:44,190  -->  00:12:47,460
Looks like a 3 to this, to this tool
297

297

00:12:47,460  -->  00:12:48,880
because the tool is obviously only trained
298

298

00:12:48,880  -->  00:12:52,202
up on digits from 0-9, so it has to recognize
299

299

00:12:52,202  -->  00:12:56,024
something there out of those and it recognizes a 3.
300

300

00:12:56,024  -->  00:12:58,882
It's like in life when you see something
301

301

00:12:58,882  -->  00:13:02,240
like a type of fruit that you've never seen before,
302

302

00:13:02,240  -->  00:13:06,670
like a custard apple or something, and you
303

303

00:13:06,670  -->  00:13:10,507
think that it's a pear because you've
304

304

00:13:10,507  -->  00:13:12,260
never actually seen one before,
305

305

00:13:12,260  -->  00:13:13,920
you don't know what to classify it as.
306

306

00:13:13,920  -->  00:13:16,300
Same thing here so, it hasn't actually trained
307

307

00:13:16,300  -->  00:13:19,490
on smiley faces and that's why it thinks it's a tree.
308

308

00:13:19,490  -->  00:13:20,370
It's a three.
309

309

00:13:20,370  -->  00:13:22,600
So there we go, it's a very powerful tool,
310

310

00:13:22,600  -->  00:13:24,877
it will be helpful for you to play around with it
311

311

00:13:24,877  -->  00:13:28,300
and actually put your mouse over a pixel,
312

312

00:13:28,300  -->  00:13:33,034
it shows you where the feature detector was
313

313

00:13:33,034  -->  00:13:35,134
to pick up that pixel, so you can see where
314

314

00:13:35,134  -->  00:13:37,380
this pixel's coming from.
315

315

00:13:37,380  -->  00:13:40,422
And also, so you can see how the filter was
316

316

00:13:40,422  -->  00:13:42,642
kind of like going through the image
317

317

00:13:42,642  -->  00:13:44,400
how we talked about it in the course.
318

318

00:13:44,400  -->  00:13:47,630
And here, you can see the pooling, you can see
319

319

00:13:47,630  -->  00:13:51,550
that the pooling is done with a, the pooling is
320

320

00:13:51,550  -->  00:13:56,550
done with a little square size of 2x2 and you can
321

321

00:13:57,600  -->  00:13:59,850
see that it's a stride of 2 as well,
322

322

00:13:59,850  -->  00:14:03,280
just as we discussed in today's tutorial.
323

323

00:14:03,280  -->  00:14:05,520
So there you go, have a play around with
324

324

00:14:05,520  -->  00:14:09,130
that and I hope you enjoyed today's session.
325

325

00:14:09,130  -->  00:14:10,500
I look forward to seeing you next time
326

326

00:14:10,500  -->  00:14:12,563
and until then, enjoy deep learning!
