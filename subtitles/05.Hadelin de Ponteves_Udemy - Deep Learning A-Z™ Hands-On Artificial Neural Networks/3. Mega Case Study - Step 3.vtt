WEBVTT
1
1

00:00:00.000  -->  00:00:02.390
<v Instructor>Hello and welcome to the second part of the</v>
2

2

00:00:02.390  -->  00:00:04.890
creation of this hybrid deep learning model,
3

3

00:00:04.890  -->  00:00:08.080
going from unsupervised to supervised deep learning.
4

4

00:00:08.080  -->  00:00:11.700
So now the challenge is to create this dependent variable
5

5

00:00:11.700  -->  00:00:14.350
because of course to train a supervised deep learning model,
6

6

00:00:14.350  -->  00:00:17.330
we need a dependent variable, and this is the tricky part
7

7

00:00:17.330  -->  00:00:20.573
because so far we don't have it since we've just worked with
8

8

00:00:20.573  -->  00:00:21.990
a unsupervised deep learning model
9

9

00:00:21.990  -->  00:00:25.070
which doesn't consider any dependent variable.
10

10

00:00:25.070  -->  00:00:28.150
So here comes the tricky part and then we'll have some more
11

11

00:00:28.150  -->  00:00:31.080
tricky parts but that's more related to Python code,
12

12

00:00:31.080  -->  00:00:33.944
but that's very good for you because you will get to learn
13

13

00:00:33.944  -->  00:00:35.610
some useful Python tricks.
14

14

00:00:35.610  -->  00:00:38.250
Alright so as you can see I've prepared what we're gonna do
15

15

00:00:38.250  -->  00:00:41.400
in this part 2 first we're gonna create the matrix of
16

16

00:00:41.400  -->  00:00:44.980
features which is our first input that we need to train our
17

17

00:00:44.980  -->  00:00:48.080
supervised deep learning model, and then we'll create this
18

18

00:00:48.080  -->  00:00:50.700
dependent variable that's the tricky part.
19

19

00:00:50.700  -->  00:00:53.590
This will be very easy to create the matrix of features
20

20

00:00:53.590  -->  00:00:58.070
well we can just use what we did here to you know extract
21

21

00:00:58.070  -->  00:01:01.970
this matrix from the dataset only we won't call it X
22

22

00:01:01.970  -->  00:01:05.920
we will call it by a new name which will be customers,
23

23

00:01:05.920  -->  00:01:08.530
we'll replace X by customers
24

24

00:01:08.530  -->  00:01:11.400
because basically this matrix of features contains
25

25

00:01:11.400  -->  00:01:13.930
the information of all the customers of the bank,
26

26

00:01:13.930  -->  00:01:16.550
and each line corresponds to one customer,
27

27

00:01:16.550  -->  00:01:18.440
with all its different information's.
28

28

00:01:18.440  -->  00:01:20.760
So that's why I'm calling it customers and then you'll see
29

29

00:01:20.760  -->  00:01:23.730
we'll call the dependent variable is_fraud,
30

30

00:01:23.730  -->  00:01:25.810
So that you know that is_fraud equals one,
31

31

00:01:25.810  -->  00:01:27.260
if yes there is a fraud
32

32

00:01:27.260  -->  00:01:30.650
and is_fraud equals zero if no there is no fraud.
33

33

00:01:30.650  -->  00:01:33.380
So customers and now the question is,
34

34

00:01:33.380  -->  00:01:37.120
where do we need to include as columns from the dataset?
35

35

00:01:37.120  -->  00:01:40.390
You know here we took all the columns except the last one
36

36

00:01:40.390  -->  00:01:43.210
and remember the last one was the class
37

37

00:01:43.210  -->  00:01:45.850
whether the application was approved or not,
38

38

00:01:45.850  -->  00:01:48.750
and we included the customer ID to keep track of
39

39

00:01:48.750  -->  00:01:49.990
the customers.
40

40

00:01:49.990  -->  00:01:52.300
But here we only need a matrix of features
41

41

00:01:52.300  -->  00:01:55.340
that contain some information's that can potentially
42

42

00:01:55.340  -->  00:01:58.290
help predict the probability of a fraud,
43

43

00:01:58.290  -->  00:02:01.540
so first of all the customer ID will definitely not
44

44

00:02:01.540  -->  00:02:04.100
help us to predict the probability of a fraud,
45

45

00:02:04.100  -->  00:02:07.360
so we won't include that column, but then the class
46

46

00:02:07.360  -->  00:02:09.740
the last column here of this dataset
47

47

00:02:09.740  -->  00:02:12.350
might be of relevant information that will help us
48

48

00:02:12.350  -->  00:02:14.990
identify some correlations between the customers
49

49

00:02:14.990  -->  00:02:17.750
information's and its probability to cheat.
50

50

00:02:17.750  -->  00:02:21.850
So we never know we will include this independent variable.
51

51

00:02:21.850  -->  00:02:25.430
So basically to create our matrix of features we're taking
52

52

00:02:25.430  -->  00:02:28.390
all the variables from index one, so we don't include the
53

53

00:02:28.390  -->  00:02:31.750
first one of index zero, up to the last one,
54

54

00:02:31.750  -->  00:02:35.930
and therefore customers will be all the columns of our
55

55

00:02:35.930  -->  00:02:40.930
dataset of indexes going from one up to the last column
56

56

00:02:41.440  -->  00:02:44.090
and here with this minus one we don't include
57

57

00:02:44.090  -->  00:02:47.070
the last columns that's not good, we need to remove it
58

58

00:02:47.070  -->  00:02:49.340
and there we go, now we include all the columns
59

59

00:02:49.340  -->  00:02:52.190
except the first one and then of course we take all
60

60

00:02:52.190  -->  00:02:55.060
the lines because we wanna take all the customers.
61

61

00:02:55.060  -->  00:02:58.030
Alright, perfect and then we have these dot values
62

62

00:02:58.030  -->  00:02:59.932
just to create the NumPy array.
63

63

00:02:59.932  -->  00:03:03.230
Okay perfect, now we have our matrix of features
64

64

00:03:03.230  -->  00:03:07.050
so I'm going to select this line and execute
65

65

00:03:07.050  -->  00:03:09.940
and here we go that's our matrix of features,
66

66

00:03:09.940  -->  00:03:14.940
it contains our 690 customers and all their features
67

67

00:03:15.290  -->  00:03:18.610
that is, all their different information that they need to
68

68

00:03:18.610  -->  00:03:21.770
fill out for the credit card application.
69

69

00:03:21.770  -->  00:03:23.890
Perfect and now time for the tricky part,
70

70

00:03:23.890  -->  00:03:26.520
lets create the dependent variable.
71

71

00:03:26.520  -->  00:03:28.400
So how are we going to do that?
72

72

00:03:28.400  -->  00:03:31.080
Well first, what will be this dependent variable?
73

73

00:03:31.080  -->  00:03:34.000
Well as you probably understood, this dependent variable
74

74

00:03:34.000  -->  00:03:37.370
will contain the outcomes whether it was fraud or not,
75

75

00:03:37.370  -->  00:03:40.230
so it will be a fraud with a binary outcome,
76

76

00:03:40.230  -->  00:03:42.380
which will therefore get the value of zero and one,
77

77

00:03:42.380  -->  00:03:46.080
zero if there is no fraud and one if there is fraud.
78

78

00:03:46.080  -->  00:03:48.610
And so how can we use the results that we obtained
79

79

00:03:48.610  -->  00:03:50.730
thanks to our unsupervised deep learning model
80

80

00:03:50.730  -->  00:03:52.240
the self organizing map,
81

81

00:03:52.240  -->  00:03:56.680
well we can extract the customer IDs of this list of frauds
82

82

00:03:56.680  -->  00:03:59.370
because basically this list of frauds contains all the
83

83

00:03:59.370  -->  00:04:02.950
customer IDs of the customers that potentially cheated.
84

84

00:04:02.950  -->  00:04:06.760
So we will use this to create our dependent variable,
85

85

00:04:06.760  -->  00:04:08.610
and if you haven't figured it out yet try,
86

86

00:04:08.610  -->  00:04:11.460
to still create this dependent variable.
87

87

00:04:11.460  -->  00:04:13.080
Alright, so how are we going to do this?
88

88

00:04:13.080  -->  00:04:15.990
Well basically the ideas that we're gonna initialize a
89

89

00:04:15.990  -->  00:04:20.360
vector of zeros a vector of 690 zeros,
90

90

00:04:20.360  -->  00:04:23.420
so basically its like were pretending that at the beginning
91

91

00:04:23.420  -->  00:04:25.250
all the customers didn't cheat
92

92

00:04:25.250  -->  00:04:28.600
and then we will extract these customer IDs
93

93

00:04:28.600  -->  00:04:30.180
and for these customer IDs,
94

94

00:04:30.180  -->  00:04:32.500
we'll put a one in our vector of zeros.
95

95

00:04:32.500  -->  00:04:36.640
We'll replace the zeros by one's for the index corresponding
96

96

00:04:36.640  -->  00:04:38.730
to these customer IDs.
97

97

00:04:38.730  -->  00:04:41.480
So that's the ID and so lets do it.
98

98

00:04:41.480  -->  00:04:44.850
So first what we have to do is initialize a vector
99

99

00:04:44.850  -->  00:04:47.850
and as we said we're gonna have to call this vector is_fraud
100

100

00:04:49.070  -->  00:04:51.570
and that will be our dependent variable.
101

101

00:04:51.570  -->  00:04:53.890
So how can we initialize the vector?
102

102

00:04:53.890  -->  00:04:57.350
Well, there is a trick for that, it's a function by NumPy
103

103

00:04:57.350  -->  00:05:00.020
so let's use first the shortcuts empty here to get
104

104

00:05:00.020  -->  00:05:03.227
this function and this function is zeros.
105

105

00:05:03.227  -->  00:05:05.610
And that's very practical function because basically
106

106

00:05:05.610  -->  00:05:09.780
you can create a vector of zeros of any number of elements.
107

107

00:05:09.780  -->  00:05:13.070
And what we want is 690 elements.
108

108

00:05:13.070  -->  00:05:17.630
And to generalize this even more, we can put len dataset,
109

109

00:05:17.630  -->  00:05:20.250
because len dataset is number of observations
110

110

00:05:20.250  -->  00:05:23.503
in the dataset that is 690.
111

111

00:05:24.490  -->  00:05:26.310
Alright, perfect, so let's check it out.
112

112

00:05:26.310  -->  00:05:28.890
Let's execute this line to make sure,
113

113

00:05:28.890  -->  00:05:33.890
we have vector initialized with 690 zeros.
114

114

00:05:34.660  -->  00:05:36.720
That's the case that's perfect.
115

115

00:05:36.720  -->  00:05:38.640
So now we can move on.
116

116

00:05:38.640  -->  00:05:43.640
So now the challenge is to put one's for the customer IDs
117

117

00:05:43.660  -->  00:05:45.230
that potentially cheated.
118

118

00:05:45.230  -->  00:05:49.090
So now what we need to do, is to loop over all our customers
119

119

00:05:49.090  -->  00:05:51.100
and then for each customer, we're gonna check
120

120

00:05:51.100  -->  00:05:53.100
if the customer ID of this customer,
121

121

00:05:53.100  -->  00:05:56.200
belongs to this list of frauds
122

122

00:05:56.200  -->  00:05:59.904
and if that's the case, will replace the zero by one.
123

123

00:05:59.904  -->  00:06:02.350
So let's do this, we make a for loop,
124

124

00:06:02.350  -->  00:06:05.130
then we need a variable that we call i
125

125

00:06:05.130  -->  00:06:08.680
and then we need a range, so in range
126

126

00:06:08.680  -->  00:06:11.440
and the range must be the range of the indexes
127

127

00:06:11.440  -->  00:06:12.530
of the customers.
128

128

00:06:12.530  -->  00:06:15.860
So since the default start is zero, what we all
129

129

00:06:15.860  -->  00:06:20.450
need to specify is the stop and that's len dataset again.
130

130

00:06:20.450  -->  00:06:22.603
That is 690.
131

131

00:06:22.603  -->  00:06:27.560
Okay, so for i in range len dataset, perfect then colon,
132

132

00:06:27.560  -->  00:06:31.890
no Python syntax, and then enter to go into the loop.
133

133

00:06:31.890  -->  00:06:34.290
And so now as we just said, for each customer,
134

134

00:06:34.290  -->  00:06:36.720
we need to check if it's customer ID,
135

135

00:06:36.720  -->  00:06:40.060
is inside this list of frauds and so how can we do that?
136

136

00:06:40.060  -->  00:06:42.620
Well, that's rather simple, we need to make an
137

137

00:06:42.620  -->  00:06:46.050
if condition, and so that goes this way,
138

138

00:06:46.050  -->  00:06:47.270
we need to start with,
139

139

00:06:47.270  -->  00:06:49.830
if the customer ID of this customer,
140

140

00:06:49.830  -->  00:06:52.570
so we need to extract the customer ID of the customer
141

141

00:06:52.570  -->  00:06:54.880
and this customer ID is contained in

142

142

00:06:57.175  -->  00:07:00.092
dataset.iloc(i,0).
143

143

00:07:02.480  -->  00:07:05.630
Why is that, it's because the I here corresponds
144

144

00:07:05.630  -->  00:07:08.870
to the I's line of the dataset.
145

145

00:07:08.870  -->  00:07:10.760
And you know each customer corresponds to a line,
146

146

00:07:10.760  -->  00:07:14.380
so the I's line corresponds to the I's customer.
147

147

00:07:14.380  -->  00:07:17.030
That is the customer we're dealing with right now the loop
148

148

00:07:17.030  -->  00:07:19.820
and then zero because as you remember,
149

149

00:07:19.820  -->  00:07:23.640
the first column of the data set contains the customer ID
150

150

00:07:23.640  -->  00:07:28.640
so dataset.iloc(i,0) will get the customer ID
151

151

00:07:28.730  -->  00:07:31.050
of customer number I and then that's all,
152

152

00:07:31.050  -->  00:07:33.790
we don't need a dot values because the dot values
153

153

00:07:33.790  -->  00:07:36.390
is just to create the NumPy array.
154

154

00:07:36.390  -->  00:07:39.060
Okay, so first thing done, we managed to extract
155

155

00:07:39.060  -->  00:07:40.780
the customer ID of the customer,
156

156

00:07:40.780  -->  00:07:42.830
we're dealing with right now in the loop.
157

157

00:07:42.830  -->  00:07:46.270
Now, we need to check if this customer ID
158

158

00:07:46.270  -->  00:07:48.330
is in the list of frauds.
159

159

00:07:48.330  -->  00:07:49.490
And so how can we do that?
160

160

00:07:49.490  -->  00:07:52.810
Well, there is nothing more simple and it's very intuitive.
161

161

00:07:52.810  -->  00:07:56.090
We need to add in frauds,
162

162

00:07:56.090  -->  00:07:58.570
and this will look into customer ID
163

163

00:07:58.570  -->  00:08:01.090
is inside this list of frauds.
164

164

00:08:01.090  -->  00:08:03.930
And if that's the case, we need to tell what happens
165

165

00:08:03.930  -->  00:08:05.280
and what happens of course is that
166

166

00:08:05.280  -->  00:08:09.200
we replace the zero by one for that specific customer.
167

167

00:08:09.200  -->  00:08:13.300
So for this customer the value in is_fraud will get a one
168

168

00:08:13.300  -->  00:08:16.940
instead of zero and the value of is_fraud with this customer
169

169

00:08:16.940  -->  00:08:18.747
is given by is_fraud(i).
170

170

00:08:22.400  -->  00:08:25.240
That's the value of is_fraud corresponding to that customer
171

171

00:08:25.240  -->  00:08:27.220
because this customer has index I.
172

172

00:08:27.220  -->  00:08:30.070
You know, in the whole all of our customers in the dataset
173

173

00:08:30.070  -->  00:08:32.280
and also our matrix of features customers,
174

174

00:08:32.280  -->  00:08:35.030
that's why we make sure we keep track of the indexes
175

175

00:08:35.030  -->  00:08:39.171
and so is_fraud(i) is going to be equal to one alright,
176

176

00:08:39.171  -->  00:08:42.480
and that way we replace the zeros by one's
177

177

00:08:42.480  -->  00:08:47.150
for all the customers that have their customer ID and fraud.
178

178

00:08:47.150  -->  00:08:50.860
And so now good news that will create the dependent variable
179

179

00:08:50.860  -->  00:08:54.850
because we will get a dependent variable of 690 elements
180

180

00:08:54.850  -->  00:08:58.600
first initialized zeros, but then we will get some one's
181

181

00:08:58.600  -->  00:09:02.550
at the indexes of the customers that have their customer IDs
182

182

00:09:02.550  -->  00:09:04.150
in this list of frauds.
183

183

00:09:04.150  -->  00:09:07.160
So basically, we're ready to execute this section,
184

184

00:09:07.160  -->  00:09:10.090
and this will create the dependent variable,
185

185

00:09:10.090  -->  00:09:14.830
we can check it out, it is now vector of 690 elements.
186

186

00:09:14.830  -->  00:09:18.460
And if we open it, we get our dependent variable
187

187

00:09:18.460  -->  00:09:21.810
with the one's for the indexes of the customers
188

188

00:09:21.810  -->  00:09:24.300
that are in the list of frauds.
189

189

00:09:24.300  -->  00:09:28.370
So as yo can see we have 37 one's because,
190

190

00:09:28.370  -->  00:09:32.160
in our list of frauds, we have 37 elements,
191

191

00:09:32.160  -->  00:09:34.800
and here are the remaining one's.
192

192

00:09:34.800  -->  00:09:35.960
Okay, that looks good.
193

193

00:09:35.960  -->  00:09:38.790
We're ready to move on to the next step.
194

194

00:09:38.790  -->  00:09:42.040
And actually, another good news, the next step is very easy,
195

195

00:09:42.040  -->  00:09:44.130
because now since we have all the ingredients
196

196

00:09:44.130  -->  00:09:47.960
to train our artificial neural network, well, we can use
197

197

00:09:47.960  -->  00:09:51.590
our code template in the WPI to train it,
198

198

00:09:51.590  -->  00:09:53.600
to train the artificial neural network.
199

199

00:09:53.600  -->  00:09:55.310
So that's what the next step is about.
200

200

00:09:55.310  -->  00:09:58.350
I'm going to move on to the next line.
201

201

00:09:58.350  -->  00:10:00.380
And here we go, let's now train
202

202

00:10:00.380  -->  00:10:02.390
our artificial neural network.
203

203

00:10:02.390  -->  00:10:05.270
So here's the code template and inside this code template,
204

204

00:10:05.270  -->  00:10:06.580
what do we need to take?
205

205

00:10:06.580  -->  00:10:08.100
Well, first, we don't need to take this,
206

206

00:10:08.100  -->  00:10:10.710
because this is the data pre processing phase.
207

207

00:10:10.710  -->  00:10:12.960
And we already have the data well prepared,
208

208

00:10:12.960  -->  00:10:16.350
but still will take the feature scaling part because
209

209

00:10:16.350  -->  00:10:19.350
that's required to train an artificial neural network.
210

210

00:10:19.350  -->  00:10:22.220
So we will take everything from here features scaling
211

211

00:10:22.220  -->  00:10:24.010
up to this line.
212

212

00:10:24.010  -->  00:10:26.210
And we're not taking this line because we wanna get
213

213

00:10:26.210  -->  00:10:27.570
the predicted probabilities.
214

214

00:10:27.570  -->  00:10:29.680
Because we want to make a ranking.
215

215

00:10:29.680  -->  00:10:31.390
So I'm copying all this.
216

216

00:10:31.390  -->  00:10:33.340
So basically, just the features scaling part
217

217

00:10:33.340  -->  00:10:35.830
in all the architecture of the ANN,
218

218

00:10:35.830  -->  00:10:38.730
plus the training here with the fit method,
219

219

00:10:38.730  -->  00:10:42.280
and then the predictions, the predicted probabilities.
220

220

00:10:42.280  -->  00:10:45.900
So let's copy this and let's get back to our mega case study
221

221

00:10:45.900  -->  00:10:48.750
to paste that inside.
222

222

00:10:48.750  -->  00:10:51.120
All right, and now we have a few things to change.
223

223

00:10:51.120  -->  00:10:53.950
Well, first, thanks to the warnings we can already
224

224

00:10:53.950  -->  00:10:55.410
see where we have to change.
225

225

00:10:55.410  -->  00:10:58.570
First is the input that we need to scale.
226

226

00:10:58.570  -->  00:11:02.310
So since we don't have testset, we will remove that line.
227

227

00:11:02.310  -->  00:11:04.990
And now we need to replace X train
228

228

00:11:04.990  -->  00:11:07.660
by the new name of our matrix of features,
229

229

00:11:07.660  -->  00:11:09.593
which is customers,
230

230

00:11:11.080  -->  00:11:11.993
customers and then same here,
231

231

00:11:11.993  -->  00:11:16.450
we need to replace x train by customers.
232

232

00:11:16.450  -->  00:11:19.120
Here we go, now we are ready to feature scale
233

233

00:11:19.120  -->  00:11:20.680
our matrix of features.
234

234

00:11:20.680  -->  00:11:23.070
And we don't need to scale the dependent variable
235

235

00:11:23.070  -->  00:11:26.070
because it takes the value zero and one, so that's okay.
236

236

00:11:26.070  -->  00:11:27.360
Alright, so let's do this.
237

237

00:11:27.360  -->  00:11:30.770
Let's already execute this section and here we go.
238

238

00:11:30.770  -->  00:11:35.254
Perfect now our customers are all scaled and we can move on.
239

239

00:11:35.254  -->  00:11:39.270
Alright, now time to build the ANN,
240

240

00:11:39.270  -->  00:11:40.890
the architecture of the ANN
241

241

00:11:40.890  -->  00:11:43.720
and fit the ANN to our training set.
242

242

00:11:43.720  -->  00:11:46.042
Okay, so first of all, the important thing is that
243

243

00:11:46.042  -->  00:11:48.730
we're working with a very simple dataset.
244

244

00:11:48.730  -->  00:11:51.480
It contains 690 observations,
245

245

00:11:51.480  -->  00:11:53.150
that's very small for deep learning.
246

246

00:11:53.150  -->  00:11:55.580
But the idea is not to do big data here,
247

247

00:11:55.580  -->  00:11:57.870
or work on some very complex data sets.
248

248

00:11:57.870  -->  00:11:59.610
The idea is to learn how to combine
249

249

00:11:59.610  -->  00:12:00.930
two deep learning models.
250

250

00:12:00.930  -->  00:12:03.770
So don't pay attention to the simplicity of the ANN
251

251

00:12:03.770  -->  00:12:06.640
we're about to make, you can totally make it more complex,
252

252

00:12:06.640  -->  00:12:09.800
if you're working on some more complex datasets.
253

253

00:12:09.800  -->  00:12:11.170
So what we're gonna do now
254

254

00:12:11.170  -->  00:12:13.800
is simplify this as much as possible,
255

255

00:12:13.800  -->  00:12:15.420
we don't need this complexity.
256

256

00:12:15.420  -->  00:12:17.760
So I'm removing the second hidden layer.
257

257

00:12:17.760  -->  00:12:21.900
And then we'll just take two neurons instead of six.
258

258

00:12:21.900  -->  00:12:25.060
And of course, now we need to change the input dimension.
259

259

00:12:25.060  -->  00:12:27.590
Remember, the input dimension corresponds to the number
260

260

00:12:27.590  -->  00:12:30.250
of features you have in your matrix of features.
261

261

00:12:30.250  -->  00:12:34.040
And right now in our matrix of features we have 15 features.
262

262

00:12:34.040  -->  00:12:38.890
So input dim should be equal to 15 instead of 11.
263

263

00:12:38.890  -->  00:12:41.230
So that looks better, then we will keep the same
264

264

00:12:41.230  -->  00:12:44.380
initializer, the same activation function, that's all good.
265

265

00:12:44.380  -->  00:12:45.750
So all good here as well.
266

266

00:12:45.750  -->  00:12:48.390
But then we need to make a few change here.
267

267

00:12:48.390  -->  00:12:51.760
First we need to change of course, the input and the output,
268

268

00:12:51.760  -->  00:12:53.320
and then we'll change also the batch size
269

269

00:12:53.320  -->  00:12:54.920
and the number of epochs.
270

270

00:12:54.920  -->  00:12:57.440
Alright, so first the input, the input is of course
271

271

00:12:57.440  -->  00:13:00.780
our matrix of features that's no longer called xtrain but
272

272

00:13:00.780  -->  00:13:05.780
now customers, alright, now we need to change the output
273

273

00:13:05.800  -->  00:13:09.203
which is no longer called white train but now is_fraud,
274

274

00:13:11.160  -->  00:13:14.050
okay, so we have our inputs and our output
275

275

00:13:14.050  -->  00:13:16.240
and now in the same spirit of simplicity,
276

276

00:13:16.240  -->  00:13:19.270
well let's change the batch size to one
277

277

00:13:19.270  -->  00:13:22.780
and the number of epochs to one or two,
278

278

00:13:22.780  -->  00:13:26.550
because the dataset is so simple that it will only take
279

279

00:13:26.550  -->  00:13:29.670
one epoch or maybe two for our ANN to understand
280

280

00:13:29.670  -->  00:13:30.800
the correlations.
281

281

00:13:30.800  -->  00:13:33.760
The weight will only need to be updated in one shot.
282

282

00:13:33.760  -->  00:13:34.890
One or two shots.
283

283

00:13:34.890  -->  00:13:37.390
So maybe we'll take two epochs.
284

284

00:13:37.390  -->  00:13:39.230
You don't need to train a deeper learning model for
285

285

00:13:39.230  -->  00:13:41.820
100 epochs, if you have fewer observations,
286

286

00:13:41.820  -->  00:13:43.380
and few features.
287

287

00:13:43.380  -->  00:13:46.130
Two epochs will here be way efficient.
288

288

00:13:46.130  -->  00:13:49.740
Alright so we have artificial neural network ready
289

289

00:13:49.740  -->  00:13:51.830
and so now what we're gonna do is train it,
290

290

00:13:51.830  -->  00:13:53.920
to our matrix of features customers,
291

291

00:13:53.920  -->  00:13:55.890
and our dependent variable is fraud.
292

292

00:13:55.890  -->  00:13:57.160
So let's do this.
293

293

00:13:57.160  -->  00:14:00.610
I'm going to select all this code section here.
294

294

00:14:00.610  -->  00:14:02.740
And time to learn.
295

295

00:14:02.740  -->  00:14:05.950
All right, using TensorFlow backend, first epoch
296

296

00:14:05.950  -->  00:14:08.730
and second epoch and okay.
297

297

00:14:08.730  -->  00:14:11.570
Alright, so as you can see, first, we slightly improved
298

298

00:14:11.570  -->  00:14:14.320
the accuracy from the first epoch to the second epoch.
299

299

00:14:14.320  -->  00:14:15.660
So that's what I was telling you.
300

300

00:14:15.660  -->  00:14:18.080
The good accuracy was found very quickly.
301

301

00:14:18.080  -->  00:14:20.290
However, the last was reduced pretty well.
302

302

00:14:20.290  -->  00:14:23.250
It went from 53% to 31%.
303

303

00:14:23.250  -->  00:14:25.210
So maybe you can try with more epochs,
304

304

00:14:25.210  -->  00:14:28.070
but I can assure you that two is way sufficient.
305

305

00:14:28.070  -->  00:14:30.510
Okay, so we built our second deep learning model
306

306

00:14:30.510  -->  00:14:32.190
to supervise deep learning one
307

307

00:14:32.190  -->  00:14:33.560
and so now in the next tutorial,
308

308

00:14:33.560  -->  00:14:35.550
we will make the final predictions.
309

309

00:14:35.550  -->  00:14:37.150
Until then, enjoy deep learning.
