1
1

00:00:00,140  -->  00:00:02,590
<v ->Hello, and welcome to this Python tutorial.</v>
2

2

00:00:02,590  -->  00:00:04,210
So, in the two previous tutorials,
3

3

00:00:04,210  -->  00:00:06,940
we added three layers: the input layer,
4

4

00:00:06,940  -->  00:00:09,570
the first hidden layer, and the second hidden layer,
5

5

00:00:09,570  -->  00:00:13,420
and now in this tutorial we're gonna add the output layer.
6

6

00:00:13,420  -->  00:00:15,730
So again, it's going to be very easy because
7

7

00:00:15,730  -->  00:00:19,020
we only need to copy the previous line here
8

8

00:00:19,020  -->  00:00:22,420
and paste it here, and now change a few things.
9

9

00:00:22,420  -->  00:00:24,380
So try to guess what we are going to change,
10

10

00:00:24,380  -->  00:00:26,030
it's pretty straightforward.
11

11

00:00:26,030  -->  00:00:27,910
The first thing we need to change is of course,
12

12

00:00:27,910  -->  00:00:30,250
the output din parameter, because of course
13

13

00:00:30,250  -->  00:00:33,110
in our output layer we want only one node,
14

14

00:00:33,110  -->  00:00:35,060
because our dependent variable is a category
15

15

00:00:35,060  -->  00:00:37,050
called variable with a binary outcome,
16

16

00:00:37,050  -->  00:00:39,060
zero if the customer stays in the bank,
17

17

00:00:39,060  -->  00:00:41,170
and one if the customer leaves the bank,
18

18

00:00:41,170  -->  00:00:42,910
and when we have a binary outcome
19

19

00:00:42,910  -->  00:00:45,300
there is only one node in the output layer,
20

20

00:00:45,300  -->  00:00:47,100
and therefore here we need to input
21

21

00:00:47,100  -->  00:00:49,810
output din equals one.
22

22

00:00:49,810  -->  00:00:52,670
So good, then we will keep this uniform
23

23

00:00:52,670  -->  00:00:54,620
initialization method that is still
24

24

00:00:54,620  -->  00:00:57,410
used to initialize the wait that comes
25

25

00:00:57,410  -->  00:00:59,030
from the second hidden layer,
26

26

00:00:59,030  -->  00:01:01,580
but moving on to the third argument,
27

27

00:01:01,580  -->  00:01:03,060
well, if you remember what I said
28

28

00:01:03,060  -->  00:01:04,410
in the previous tutorials,
29

29

00:01:04,410  -->  00:01:07,160
we need to change the activation function here,
30

30

00:01:07,160  -->  00:01:09,490
because right now we are in the output layer,
31

31

00:01:09,490  -->  00:01:11,350
and since we are making a geodemographic
32

32

00:01:11,350  -->  00:01:13,470
segmentation model, we want to have
33

33

00:01:13,470  -->  00:01:15,630
probabilities for the outcome,
34

34

00:01:15,630  -->  00:01:17,190
because we wanna have the probability
35

35

00:01:17,190  -->  00:01:19,560
that each customer leaves the bank.
36

36

00:01:19,560  -->  00:01:21,800
And so in order to get these probabilities,
37

37

00:01:21,800  -->  00:01:24,720
we need to replace this activation function,
38

38

00:01:24,720  -->  00:01:26,980
which is a rectifier activation function,
39

39

00:01:26,980  -->  00:01:29,610
by the sigmoid activation function,
40

40

00:01:29,610  -->  00:01:31,870
because remember in the logistic regression intuition
41

41

00:01:31,870  -->  00:01:34,130
tutorial given by Carol in part three,
42

42

00:01:34,130  -->  00:01:36,610
while the sigmoid function is the heart of this
43

43

00:01:36,610  -->  00:01:39,160
probabilistic approach, and that is thanks
44

44

00:01:39,160  -->  00:01:40,830
to the sigmoid function that we manage
45

45

00:01:40,830  -->  00:01:44,110
to get some probabilities in the logistic regression model,
46

46

00:01:44,110  -->  00:01:45,930
and that will actually be the same here,
47

47

00:01:45,930  -->  00:01:48,380
if we choose a sigmoid activation function,
48

48

00:01:48,380  -->  00:01:50,070
it's the exact same principle.
49

49

00:01:50,070  -->  00:01:52,620
So here we're gonna replace relu, corresponding
50

50

00:01:52,620  -->  00:01:56,020
to the rectifier function, by sigmoid,
51

51

00:01:56,020  -->  00:01:57,290
and by the way if you are dealing
52

52

00:01:57,290  -->  00:01:59,380
with a dependent variable that has more than two
53

53

00:01:59,380  -->  00:02:02,470
categories, like say for example three categories,
54

54

00:02:02,470  -->  00:02:04,670
then you will need to change two things here.
55

55

00:02:04,670  -->  00:02:06,600
First is the output din parameter
56

56

00:02:06,600  -->  00:02:09,940
that will be set as the number of classes,
57

57

00:02:09,940  -->  00:02:12,610
because it will be based on the one viesol method,
58

58

00:02:12,610  -->  00:02:15,470
while the dependent variable is one hot encoded,
59

59

00:02:15,470  -->  00:02:17,310
so here you would need to input three,
60

60

00:02:17,310  -->  00:02:19,890
if you have three categories for your dependent variable,
61

61

00:02:19,890  -->  00:02:21,860
and the second thing that you would need to change
62

62

00:02:21,860  -->  00:02:25,010
is the activation function, that in this situation
63

63

00:02:25,010  -->  00:02:28,390
would be softmax, and softmax is actually
64

64

00:02:28,390  -->  00:02:30,710
the sigmoid function, but applied
65

65

00:02:30,710  -->  00:02:32,980
to a dependent variable that has more than two
66

66

00:02:32,980  -->  00:02:34,930
categories, so just keep that in mind
67

67

00:02:34,930  -->  00:02:36,180
if in your work you are dealing
68

68

00:02:36,180  -->  00:02:37,850
with a dependent variable that has
69

69

00:02:37,850  -->  00:02:39,890
more than two categories, like three or four
70

70

00:02:39,890  -->  00:02:43,060
categories, you would need to choose the softmax function.
71

71

00:02:43,060  -->  00:02:45,580
But here, we have two categories, two classes,
72

72

00:02:45,580  -->  00:02:48,260
so we are fine with the sigmoid function,
73

73

00:02:48,260  -->  00:02:50,690
exactly like for logistic regression.
74

74

00:02:50,690  -->  00:02:52,360
Alright, so basically we are ready,
75

75

00:02:52,360  -->  00:02:54,320
we are ready to add the output layer
76

76

00:02:54,320  -->  00:02:55,990
that is eventually the final layer
77

77

00:02:55,990  -->  00:02:58,340
of our neural network, that's pretty exciting,
78

78

00:02:58,340  -->  00:03:00,330
that means that we are done building
79

79

00:03:00,330  -->  00:03:02,130
the neural network, well then we'll need
80

80

00:03:02,130  -->  00:03:04,190
to compile it, but basically we're done
81

81

00:03:04,190  -->  00:03:06,320
adding all the different layers.
82

82

00:03:06,320  -->  00:03:08,180
So let's do it, let's add the final layer,
83

83

00:03:08,180  -->  00:03:10,190
the output layer, and so I'm going
84

84

00:03:10,190  -->  00:03:12,320
to select this line and press command or control
85

85

00:03:12,320  -->  00:03:14,940
plus enter to execute, here we go,
86

86

00:03:14,940  -->  00:03:17,720
the output layer was successfully added.
87

87

00:03:17,720  -->  00:03:19,270
Great, so now we are ready to move on
88

88

00:03:19,270  -->  00:03:22,190
to the next step, which will be to compile
89

89

00:03:22,190  -->  00:03:24,330
our artificial neural network,
90

90

00:03:24,330  -->  00:03:25,960
that's going to be very easy as well,
91

91

00:03:25,960  -->  00:03:28,040
since it will only take one line of code,
92

92

00:03:28,040  -->  00:03:30,160
and so we'll do that in the next tutorial.
93

93

00:03:30,160  -->  00:03:31,923
Until then, enjoy deep learning!
