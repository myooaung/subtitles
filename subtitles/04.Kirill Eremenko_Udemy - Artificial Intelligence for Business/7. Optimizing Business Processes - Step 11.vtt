WEBVTT

00:00.450 --> 00:02.090
Hasan Welcome back.

00:02.130 --> 00:06.580
So we've just started the learning process over these 1000 iterations.

00:06.750 --> 00:09.780
We just got the current state here that was the first step.

00:09.990 --> 00:16.950
And now according to the curing process next step we have to tackle step to laying around an action

00:16.950 --> 00:23.430
that can lead to a next possible state that is taking an action such that the reward of that action

00:23.520 --> 00:25.020
plays in the state.

00:25.170 --> 00:29.070
That we got just before no current state is larger than zero.

00:29.170 --> 00:32.930
Then we'll get this action randomly from these actions.

00:33.000 --> 00:38.760
Verifying this and then we'll reach the next date because by plain inaction we reached the next date

00:39.120 --> 00:45.130
and we get the reward obtained by playing that action 80 in the state esty.

00:45.240 --> 00:49.650
So back to our code let's implement this.

00:49.650 --> 00:51.710
All right so what do we have to do.

00:51.750 --> 01:00.120
First we have to type some code that will give us the possible actions that we can play when being in

01:00.120 --> 01:01.530
the current state.

01:01.530 --> 01:08.130
So you know we are in this current state and we can only play some certain actions where we have a positive

01:08.130 --> 01:10.790
reward in the road corresponding to the states.

01:10.800 --> 01:18.780
For example let's say that the current state that we picked randomly in this line of code is the state

01:18.780 --> 01:20.540
here corresponding to this row.

01:20.730 --> 01:27.830
Well the only actions that we can play now are the actions to 6 or 7 right.

01:27.870 --> 01:33.090
So that's what we have together right now the possible actions that we can play one being in this current

01:33.090 --> 01:34.120
state.

01:34.170 --> 01:37.720
Therefore the best way to do that is to make a list.

01:37.800 --> 01:41.870
We'll make a list that will contain these possible actions that we can play.

01:41.910 --> 01:45.260
And let's go this list playable actions.

01:45.270 --> 01:51.990
You know the actions that are playable and will first initialized this list to an empty list which is

01:51.990 --> 01:59.920
how we do it in Python that is was only simple square brackets that initializes an empty list then.

02:00.180 --> 02:08.520
Now we're going to append in this list the actions where the word of playing that action in the current

02:08.520 --> 02:17.340
state is larger than zero and therefore what we simply have to do is get to the row in the matrix of

02:17.340 --> 02:19.720
the word corresponding to the current state.

02:19.740 --> 02:25.620
So let's say this is this row again and then we're going to iterate it as we're going to loop over all

02:25.620 --> 02:32.760
the columns of this row here and we're only going to get the actions that is the columns where we get

02:32.760 --> 02:37.790
a one here because these correspond to the actions that can exactly be played.

02:37.860 --> 02:44.310
You know that can take us to a neighbor location from the location we're in right now in this current

02:44.310 --> 02:45.270
state.

02:45.480 --> 02:47.950
So we have to make a second for loop.

02:48.180 --> 02:53.510
And then again take a looping variable we can take again but it's preferable to take another one.

02:53.520 --> 02:54.970
So let's take J.

02:55.000 --> 02:56.040
J.

02:56.100 --> 02:58.440
In range.

02:58.440 --> 03:05.490
And again we have to specify the range of values that J is going to take and j will actually respond

03:05.520 --> 03:09.150
to the columns that we'll inspect.

03:09.150 --> 03:13.760
One by one to find the ones that is when the reward equals one.

03:13.790 --> 03:22.500
Therefore Jay is simply going to be in the range from 0 the first column to 11 to 12 column the last

03:22.500 --> 03:23.150
column.

03:23.430 --> 03:30.920
But again remember in range we only have to put the upper bound and upper bound is again excluded.

03:31.120 --> 03:39.780
And therefore we have to go up to 12 that way J will go over each of the 12 columns from 0 to 11.

03:40.200 --> 03:40.590
All right.

03:40.610 --> 03:44.260
And then we're ready to start this second follow up.

03:44.440 --> 03:47.930
And so for each of the 12 values of J What are we going to do.

03:47.930 --> 03:57.270
We're going to check if the reward of the action J played in the current state is larger than zero and

03:57.270 --> 04:00.130
therefore that's exactly what we're going to type here.

04:00.420 --> 04:12.250
If the reward of the action J played in the current state if the action J played in the current state

04:12.460 --> 04:20.590
is larger than zero then that means that J is a playable action that is an action that we can play and

04:20.590 --> 04:23.470
therefore in that case what do we have to do.

04:23.470 --> 04:29.110
Well we have to bend it to our list of the playable actions.

04:29.110 --> 04:33.800
That is the actions that we can play when being in the current state.

04:33.810 --> 04:35.410
SC OK.

04:35.650 --> 04:44.470
And therefore how can we spend a value that is our playable action J which verifies this to our list

04:44.470 --> 04:45.770
of playable actions.

04:46.030 --> 04:54.990
Well the trick is to take first our list of playable actions and then just add that and then here we

04:54.990 --> 04:55.450
go.

04:55.470 --> 05:01.710
The first one here spent just pressing enter and then in the parenthesis you just need to input what

05:01.710 --> 05:04.360
you want to happen which is the action.

05:04.860 --> 05:05.700
Perfect.

05:05.970 --> 05:12.060
And then we don't even have to do an else because an ELSE corresponds to the situation where the reward

05:12.120 --> 05:16.850
of the action J played in the current state is below or equal to zero.

05:17.130 --> 05:23.400
And therefore in that case we won't append anything and Indians will get our list of playable actions

05:23.400 --> 05:28.270
containing only the actions that we can play when being in the current state.

05:28.290 --> 05:30.320
SD perfect.

05:30.410 --> 05:33.890
So that gives us the list of actions that we can play.

05:34.120 --> 05:40.410
And now the only remaining thing that we need to do well it is first to get out of this if condition

05:40.410 --> 05:46.800
and also to get out this fall because the for the second for loop with the J was only meant to give

05:46.800 --> 05:49.710
us the list of playable actions that we can play.

05:49.830 --> 05:50.910
And now its done.

05:51.090 --> 05:58.680
So the only thing that we have to do left is we go back to our slide well is to play actually a random

05:58.710 --> 05:59.090
action.

05:59.130 --> 06:06.210
Eighty one random action 80 from this list of possible actions that we just gather and therefore where

06:06.210 --> 06:07.850
are we going to do you know.

06:07.850 --> 06:08.630
You know how to do it.

06:08.630 --> 06:14.700
Now we are going to use again the random module but this time a different function than the rent in

06:14.700 --> 06:15.480
function.

06:15.480 --> 06:16.300
Why is that.

06:16.370 --> 06:22.500
Because the run in function can we take a random number between two given numbers but here we have to

06:22.500 --> 06:29.550
take a random number from a list which is our list of playable actions and the function that does the

06:29.550 --> 06:30.210
trick.

06:30.210 --> 06:37.970
What we want to get is the choice function which will take randomly an element of a list.

06:38.010 --> 06:38.840
All right.

06:38.930 --> 06:44.390
So let's do this let's play this random action from our list of playable actions.

06:44.610 --> 06:51.150
So since we're going to use the random module again which is from NUMP library Well we're going to call

06:51.240 --> 06:58.830
non-Thai again as a short get MP then run them again and then as we just said the choice which must

06:58.830 --> 06:59.450
be here.

06:59.490 --> 07:07.320
Yes the choice function which will take an input of course the list from which we take randomly one

07:07.380 --> 07:09.340
element and what is that list.

07:09.480 --> 07:13.830
Well that's of course playable actions.

07:13.920 --> 07:15.390
Perfect.

07:15.390 --> 07:19.310
Now let's see let's see what we have to do next.

07:19.620 --> 07:25.770
Well we're done with Step 2 actually played around the action we just got there animation effectively.

07:25.800 --> 07:31.020
Now as I said let's also tackle this third step here because it's really simple.

07:31.170 --> 07:35.680
It is to reach the next state and get the reward are as C.A.T..

07:36.030 --> 07:40.160
So how can we reach the next date when playing that action.

07:40.380 --> 07:47.160
Well it's really direct because indeed the action corresponds to where you're going and where are you

07:47.160 --> 07:49.780
going with correspondent to the next state.

07:49.890 --> 07:55.800
Because this is the next location that you were led to by playing that action and therefore what we

07:55.800 --> 07:59.710
can simply do here directly is just here.

07:59.850 --> 08:08.610
Specify that this random choice for more playable actions will exactly be this next state right.

08:08.640 --> 08:15.870
The next state is that action taken randomly from our playable actions because indeed that action leads

08:15.870 --> 08:19.300
us to the next state that gets to the next location.

08:19.300 --> 08:19.990
All right.

08:20.340 --> 08:21.420
And that's it.

08:21.420 --> 08:27.420
Now we're ready to move on to the next step which is the interesting step actually because that's where

08:27.420 --> 08:30.310
we will compute the temporal difference.

08:30.480 --> 08:36.990
And finally in the final tutorial of this part to building the AI solution with Q learning Well they

08:36.990 --> 08:40.660
the Q value at each iteration following the bellmen equation.
