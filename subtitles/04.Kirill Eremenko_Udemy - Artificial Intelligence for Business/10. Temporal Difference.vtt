WEBVTT

00:01.100 --> 00:04.670
Hello and welcome back to the course on artificial intelligence.

00:04.690 --> 00:07.900
Today we're talking about the temporal difference.

00:08.050 --> 00:14.260
Now it's very important to trial because temporal difference is the heart and soul of the Q learning

00:14.290 --> 00:15.050
algorithm.

00:15.070 --> 00:22.150
This is actually how everything we've learned sofar comes together into play inside key learning.

00:22.360 --> 00:23.830
So let's have a look.

00:23.860 --> 00:29.080
Remember the time when we talked about deterministic versus nondeterministic search and remember how

00:29.080 --> 00:34.930
we said in this case it's when the agent wants to go up he definitely goes up and when.

00:35.020 --> 00:38.650
In this case he wants to go up there's a 10 percent chance he'll go lower than 10 percent chance in

00:38.650 --> 00:42.390
the garage and an 80 percent chance he'll go right go straight up.

00:42.400 --> 00:46.370
While these numbers are of course arbitrary and can be different.

00:46.360 --> 00:52.210
And this whole concept is it could be different and different problems so it doesn't have to concern

00:52.270 --> 00:57.040
which way he's moving just that there's some randomness something is out of the control of the agent

00:57.250 --> 00:59.890
happening inside this environment.

01:00.010 --> 01:07.420
And what effect that had is as you remember was that in the deterministic example it was very easy to

01:07.420 --> 01:10.980
calculate the Wii values while not necessarily always very easy.

01:10.990 --> 01:16.480
But in our case we could just simply calculate them by using the Belman equation and we we had the exact

01:16.480 --> 01:24.430
values and then as you remember I very carefully mentioned that these values for the nondeterministic

01:24.430 --> 01:27.750
search example are off the top of my head.

01:27.790 --> 01:32.470
They are not Kalka we know last last time I said not we just want to calculate them because it's very

01:32.470 --> 01:33.040
complex.

01:33.040 --> 01:39.340
But the computer can do it and we just went along with these values that are just values that I made

01:39.340 --> 01:39.540
up.

01:39.550 --> 01:41.260
But they did get the job done.

01:41.260 --> 01:42.980
They helped us understand the concept.

01:43.240 --> 01:48.130
Well now we're going to return to that a little bit and understand what exactly is going on here why

01:48.130 --> 01:55.370
is it so much harder to calculate these values in the nondeterministic example or generally speaking

01:55.370 --> 01:59.520
in these problems in these environments and the agent going through them.

01:59.530 --> 02:00.280
Why is it.

02:00.460 --> 02:02.950
Why can it be so hard to calculate these values.

02:02.950 --> 02:08.930
Well when you think about it because when the agent moves for for instance from here to the right he

02:09.020 --> 02:15.220
doesn't necessarily always move that way sometimes as a chance that he'll go into win instead of going

02:15.370 --> 02:23.500
straight so let's call these northeast southwest so instead of going west the agent might sometimes

02:23.500 --> 02:29.380
go south and for instance from here instead of going north he might sometimes go east.

02:29.410 --> 02:30.190
So sorry.

02:30.190 --> 02:34.640
So here instead of going east he might sometimes go south and here's sort going north.

02:34.660 --> 02:40.560
He might sometimes go east or west and here in the north he might sometimes go west or east or west

02:40.570 --> 02:41.130
and so on.

02:41.130 --> 02:46.670
So and therefore So in order to calculate this value you would need to know what this value is.

02:46.690 --> 02:50.470
But the interesting thing is that in order to calculate this value you need to know what this value

02:50.470 --> 02:50.930
is.

02:51.070 --> 02:56.740
So there's a lot of recursion happening here and therefore you cannot just decide to define what these

02:56.740 --> 02:57.300
values are.

02:57.310 --> 03:01.080
And on top of that this recursion is not deterministic.

03:01.090 --> 03:05.740
It is sometimes it happens this way sometimes instead of going up and go right sometimes instead of

03:05.740 --> 03:10.470
growing up and go left sometimes it's good when you want to go up he will go up.

03:10.510 --> 03:17.410
So it is subject to chance and so maybe many times agent will go through this path and he'll go up up

03:17.410 --> 03:22.000
up up up and you'll think that from here you always kind of goes up and the value of the state will

03:22.000 --> 03:27.280
go it will be good and then all of a sudden he'll drop into the pit and this value will go down.

03:27.570 --> 03:33.550
And so therefore you can see how there is some stochastic randomness to this whole calculation on these

03:33.550 --> 03:35.320
values because they're all interlinked.

03:35.320 --> 03:41.260
Plus on top you've got that randomness in this inherent in the environment because as a mark of decision

03:41.260 --> 03:42.490
process.

03:42.490 --> 03:47.740
So that's where all this comes together and that's where we're going to introduce the concept of the

03:47.740 --> 03:52.300
temporal difference which will allow the agent to calculate these values.

03:52.450 --> 03:55.510
And here we were dealing with the values.

03:55.510 --> 03:59.340
And since then we've already moved on to q values so that's what we're going to be working.

03:59.350 --> 04:01.800
We're going to be looking at gallies.

04:01.960 --> 04:06.030
So as you recall this is our Belman equation for q values.

04:06.130 --> 04:15.040
So AQ value or the value of performing a certain action A in state s is equal to the reward that you

04:15.040 --> 04:22.720
get after performing that actions immediately after performing an action plus do you get the maximum

04:22.720 --> 04:26.660
you get the gamma of the sum of all the possible.

04:26.860 --> 04:31.600
So you kind of get the expected value of the state that you will end up in.

04:31.600 --> 04:34.980
So as you recall there was no formula for the Beldon equation.

04:35.260 --> 04:40.770
And now just for simplicity's sake we're going to rewrite it in the old fashioned way in the in the

04:41.260 --> 04:46.930
way that we used to talk about the Belman equation before we knew about the sickest Asadi So remember

04:46.930 --> 04:53.680
this was our Belman equation in the sense of a deterministic search example because here you don't have

04:53.680 --> 04:57.490
that expected value you don't have the same across all probabilities.

04:57.700 --> 05:03.060
You just have that as if it's determined you're going to end up what states you're going to add up and

05:03.060 --> 05:05.420
then you take the max in that one state.

05:05.520 --> 05:12.120
And the reason we're rewriting it is simply the only reason is because it is just easier to write it

05:12.150 --> 05:14.500
and it'll be easier to fall along with the formula.

05:14.500 --> 05:19.180
So we're going to just remember that we replaced this part of this bar.

05:19.380 --> 05:25.350
And also you'll find this notation in a lot of literature so will be easier for you to follow along

05:25.350 --> 05:28.320
with other sources if you're studying those.

05:28.320 --> 05:35.330
But do remember that in fact what we mean is this probabilistic approach here instead of this notation

05:35.430 --> 05:39.060
is just easier for us to operate this and understand what's going on.

05:39.080 --> 05:44.130
I just kind of like look at the equations so that they're not too cluttered but once again just remember

05:44.130 --> 05:48.010
that in fact what we mean is this probabilistic approach here.

05:48.210 --> 05:52.080
And so we're actually in the really dumb Silis have a look at what's going on.

05:52.140 --> 06:00.600
So here is our blank state of the maze we don't have any cube values let's see or we may but let's just

06:00.600 --> 06:05.470
keep it blank for now let's just look at one of the states or one of the cells.

06:05.520 --> 06:07.010
This one specifically.

06:07.770 --> 06:14.240
And here we have for instance for the action of going up we have a cube value that we calculate.

06:14.240 --> 06:18.010
So it's not that we don't have any cube values yet we have it we do.

06:18.030 --> 06:19.880
But we're just not illustrating anything.

06:19.880 --> 06:25.170
We're just keeping a blank for simplicity's sake but we have the age has been walking around for some

06:25.170 --> 06:33.300
time and let's say hypothetically somehow he's calculated this cube value of going up or Norf from this

06:33.300 --> 06:36.510
state from this specific cell and the values.

06:36.510 --> 06:38.060
Q As a.

06:38.130 --> 06:42.990
And so now what we have so he is currently with his blue arrows point.

06:43.010 --> 06:48.480
The agent is sitting in this cell and now he needs to make a choice where is he going to go.

06:48.510 --> 06:56.590
And he knows the value of this action going north and that is q Senay and here I'm saying before.

06:57.100 --> 07:01.890
And the reason for that is because he that is before he takes action he hasn't taken action yet so he's

07:01.890 --> 07:10.260
still in the cell and before he's taken the action the value here is skew and SNB and now he actually

07:10.290 --> 07:11.330
takes the action.

07:11.340 --> 07:13.610
So let's say he decides is the best one.

07:13.610 --> 07:16.390
He takes action and he moves up to the cell.

07:16.680 --> 07:24.260
Well now what happens is now comes after so after he's taken action we can measure what is this value

07:24.300 --> 07:30.600
let's just calculate this value the value of the reward of for taking that action plus gamma times the

07:30.600 --> 07:35.480
maximum of this new state that he's just gotten into as prime.

07:35.600 --> 07:38.980
And so the maximum across all possible actions and aspirin.

07:39.030 --> 07:44.720
And so what we have here is the value before in of that action.

07:44.760 --> 07:47.590
And then we've calculated this metric afterwards.

07:47.610 --> 07:50.770
But as you can recall from the previous formula.

07:50.770 --> 07:58.800
So if we go back very quickly from the previous formula where we just calculated is indeed the value

07:58.830 --> 08:02.140
that is how Q of s.a.a is calculated.

08:02.160 --> 08:08.030
So this right part of just calculated separately but after we've taken the action.

08:08.280 --> 08:14.790
So as once again before we knew a Q of an S and a value something that we've calculated through our

08:14.790 --> 08:16.950
iterations Preuss is something.

08:16.950 --> 08:19.930
So a value that's stored in our memory.

08:19.950 --> 08:26.610
So just like a number that we know now after the action actions being performed we know what reward

08:26.610 --> 08:30.290
he actually got what reward the agent actually got.

08:30.390 --> 08:33.270
And we can calculate this new value.

08:33.260 --> 08:39.640
So in essence we're kind of recalculating this value but now with new information the new information

08:39.630 --> 08:41.070
is the reward that we got.

08:41.550 --> 08:47.280
And plus what stayed we ended up in and what the maximum across that state what that this new value

08:47.370 --> 08:50.510
is for that specific data real can.

08:50.520 --> 08:54.430
So what's the value of that being in that state.

08:54.450 --> 09:02.010
So basically the KJo of innocence but given new information and now the temporal difference is defined

09:02.100 --> 09:07.650
as tiddy of a and s of these two of the difference between these two.

09:07.650 --> 09:11.590
So here the first element is your off-Terra value.

09:11.730 --> 09:19.110
So the kind of like view of Esson a bit calculated afterwards and the previous quvenzhané a which you

09:19.110 --> 09:21.840
had stored in your memory.

09:22.020 --> 09:24.110
And so the question is are they different.

09:24.240 --> 09:26.160
So ideally they should be the same.

09:26.190 --> 09:31.710
Ideally this should be the same as this simply because this is the formula for calculating this.

09:31.740 --> 09:38.010
But the thing is that this is not something we Kalka this is something that we have from empirical evidence

09:38.010 --> 09:41.250
something that we have from just going through the maze many times and calculus.

09:41.260 --> 09:44.290
So this is something we've come up with so far.

09:44.310 --> 09:46.770
It's not related to the current iteration.

09:46.770 --> 09:52.020
It's something that we came up with previously a long long time ago but in one of our previous iterations

09:52.020 --> 09:53.200
going through the maze.

09:53.460 --> 09:57.690
Whereas this is something we've calculated just now and there is no guarantee that they're going to

09:57.690 --> 10:04.660
be the same because of the randomness that exists in the maze because this could have been calculated

10:04.690 --> 10:10.230
and saw some CRN random events were triggered and this can be calx a different random events happening

10:10.250 --> 10:11.540
were triggered.

10:11.680 --> 10:15.640
And so now let's rewrite the rules here and just move it up there.

10:15.670 --> 10:16.870
So how do we use this.

10:16.870 --> 10:17.530
The question is.

10:17.590 --> 10:20.380
OK so we have this temporal difference.

10:20.380 --> 10:21.310
How do we use this.

10:21.340 --> 10:23.400
And why is it called the temporal difference.

10:23.530 --> 10:28.930
Well the reason is called the temporal difference is because you're basically calculating the same thing

10:28.930 --> 10:33.400
you're calculating Q of S and A so the Q value of that action.

10:33.580 --> 10:36.150
You clicking here and you're calculating it here.

10:36.280 --> 10:38.270
But the difference is time.

10:38.290 --> 10:43.920
This is your q of S and they previously this is yo Q of S and A.

10:44.080 --> 10:49.030
Now your new q is innate and the question is has there been a difference.

10:49.030 --> 10:51.680
Have there's been a shift between them in time.

10:52.000 --> 10:56.760
And how can we use this advantage if there is indeed has been this shift in time.

10:56.980 --> 11:02.350
Well one thing we could do is we could say OK well you know our Q of S N A.

11:02.350 --> 11:06.820
Doesn't this new value doesn't equal old so we're going to get rid of the old or forget about the old

11:07.240 --> 11:09.550
and we'll just use this as a new value.

11:09.910 --> 11:11.880
But that would not be smart.

11:11.890 --> 11:17.920
And the reason for that is that in our environment around random events can sometimes happen.

11:18.070 --> 11:25.550
And what if our old QSA of s.a.a was something that consistently happens like 80 percent of the time.

11:25.720 --> 11:28.650
And then like was represented by what happens 80 percent of the time.

11:28.690 --> 11:33.220
And then this new one just what happened due to randomness.

11:33.220 --> 11:39.550
In that case we're going to throw away the the one that is responsible for the bulk of the situation

11:39.710 --> 11:43.820
and we're going to replace it with something that happens only 10 or 20 percent of the time.

11:43.870 --> 11:50.620
That wouldn't be the best approach to go and that's why that's exactly why we don't want to completely

11:50.620 --> 11:52.000
change Al-Q values.

11:52.000 --> 11:56.630
We want to use like change them step by step a little bit by a little bit.

11:56.830 --> 12:01.890
And that's why we're going to use this temporal difference in a specific way so we're going to say Here's

12:01.960 --> 12:07.270
a formula we're going to take our cue of SNH and we're going to update it in such a way we're going

12:07.280 --> 12:13.090
to take the old value of cure Senay and we are going to add all five times the temporal difference.

12:13.360 --> 12:15.670
So Alpha is going to be learning right.

12:15.670 --> 12:19.710
That's a new parameter that we're introducing That's how quickly is algorithm learning.

12:20.020 --> 12:26.350
So basically we're taking this difference and whatever it is we're adding it on to our previous KJo

12:26.430 --> 12:27.110
snake.

12:27.160 --> 12:31.910
Now this formula probably doesn't make any sense or like just by looking it doesn't make sense because

12:31.910 --> 12:33.980
you've got Covisint here and give us an A here.

12:34.000 --> 12:39.400
It's the same thing so probably should negate each other but we had to rewrite this in a bit of a different

12:39.400 --> 12:40.020
way.

12:40.330 --> 12:44.030
So it is going to show you again so I'm just adding time to these forms.

12:44.050 --> 12:45.040
So here is.

12:45.040 --> 12:48.010
Q T minus 1 the previous years.

12:48.010 --> 12:49.750
Q T minus 1 the previous years.

12:49.750 --> 12:53.060
Q T The New this should be a circle here in circle here as well.

12:53.100 --> 12:58.490
But nevermind add here what Alpha temporal difference the the new the current temporal difference.

12:58.720 --> 13:01.110
So you can see what we're doing we're saying.

13:01.140 --> 13:04.150
OK let's take our current.

13:04.180 --> 13:12.520
Q is going to be equal to all previous Q plus whatever temporal difference we found times for this formula.

13:12.520 --> 13:16.240
Here is the heart and soul of the Kule learning algorithm.

13:16.270 --> 13:22.270
This is how the CUV Salazar OBD-II and it's good that we've already learned what q values are what gamma

13:22.270 --> 13:25.330
is what R is and what all of this stuff is.

13:25.400 --> 13:31.930
And now all we need to see is that you have a previous Q value Yes that's good.

13:31.930 --> 13:37.810
And then what can happen is that when you take in when you actually do take the action when the agent

13:37.810 --> 13:42.490
takes action you'll know he'll get a reward and he'll end up in a state.

13:42.580 --> 13:46.360
And so based on that he can calculate Aha.

13:46.370 --> 13:53.290
OK so what is what would have what should have been the Q value of that move that I made.

13:53.560 --> 13:56.410
And now that is this part of the equation.

13:56.410 --> 14:03.370
Subtract the old Q value gets you a temporal difference and now you need to take a al-Fatah simple difference

14:04.030 --> 14:07.710
and that's how you adjusted to Gallego that's what you're going to just buy.

14:08.130 --> 14:12.900
And now just to finish off this this is kind of like this is sufficient to understand what's going on.

14:12.910 --> 14:18.270
But just to clarify things even more or perhaps maybe confuse things even more.

14:18.400 --> 14:22.590
What are we to do is we get to take this temporal difference or this temporal difference or here where

14:22.660 --> 14:24.150
we just plug it into this formula.

14:24.150 --> 14:29.860
So we're going to take all this part and plug it into this formula and get an up for huge equation.

14:29.860 --> 14:32.560
So here we go there's our equation.

14:32.560 --> 14:38.530
So this is the full equation with the temporal difference written out completely.

14:38.530 --> 14:41.260
And the reason I wrote this out as well.

14:41.300 --> 14:45.280
First of all you probably find this in other literature if you study it.

14:45.700 --> 14:50.770
And the second thing is that it makes some things a bit more complex the form is longer but also makes

14:50.770 --> 14:52.110
some things a bit clearer.

14:52.240 --> 14:55.890
So for instance you can see here the role Alpha plays.

14:55.900 --> 14:58.210
You can see it better because look at this.

14:58.210 --> 15:01.340
Here you go Q T minus one and here you go.

15:01.340 --> 15:03.660
Q T minus one with a negative sign.

15:03.720 --> 15:12.140
So if you plug in Alpher equals to 1 if you put a 1 in here then this will negate with this.

15:12.150 --> 15:16.010
So they will destroy each other and all you'll have left is this part.

15:16.440 --> 15:23.040
And what that means is exactly that situation where we said All right so we've got a new value which

15:23.100 --> 15:24.770
it should have been.

15:24.780 --> 15:29.360
Let's update our Q value with the new value and forget about whatever we had previously.

15:29.670 --> 15:35.430
And as we discussed is not the best approach because there are random events here and we want to update

15:35.430 --> 15:36.750
things step by step.

15:37.470 --> 15:43.530
And on other hand if you said Alpher equal to zero what happens then is that you completely forget about

15:43.530 --> 15:44.350
this whole part.

15:44.550 --> 15:44.880
And you.

15:44.880 --> 15:50.220
Q T the new one or the current one is going to be always equal to the previous one so you're not going

15:50.220 --> 15:51.460
to be learning anything.

15:51.660 --> 15:56.700
And that means whatever is happening in the maze doesn't matter because you've decided and you cuchi

15:56.700 --> 15:58.890
value a long time ago and you're just going to keep it.

15:59.170 --> 16:03.150
So that's why Alpha shouldn't be zero or should be one it should be somewhere in between.

16:03.210 --> 16:09.300
And it's going to allow you to learn slowly step by step is going to allow you to as your or the agent

16:09.300 --> 16:12.720
as it goes through the maze is going to get this temporal difference.

16:12.930 --> 16:17.810
And slowly but surely this value is going to get added and I did ibed.

16:17.970 --> 16:25.490
And what will happen eventually is that at some point hopefully the algorithm will converge.

16:25.650 --> 16:30.930
And what that means is that this temporal difference will start becoming closer and closer to zero and

16:30.930 --> 16:35.320
eventual because we're very close to zero or even 0 0 0 0.

16:35.490 --> 16:43.500
And what that means is that every single time your new cutesie value or your new calculated value what

16:43.500 --> 16:44.380
it should have been.

16:44.400 --> 16:49.890
So not this one but what it hypothetically should be enough to take the step will be just equal to your

16:49.890 --> 16:50.970
previous Q2 value.

16:50.970 --> 16:56.250
And then one that's zero and that means when you're temporal differences zero means your algorithm has

16:56.250 --> 17:02.640
converged and it's not really necessary to continue updating what's going on.

17:02.650 --> 17:06.240
It does this search to continue updating your cube values.

17:06.240 --> 17:12.750
The caveat here is that the only time probably one of the only times when you would still want to continue

17:12.750 --> 17:19.110
performing this whole you know updating of VQ values if the environment is constantly changing.

17:19.110 --> 17:23.040
If not just is not there it just has some randoms to Capstick events in it.

17:23.160 --> 17:28.690
But the environment itself is modifying as is morphing is changing with time.

17:28.980 --> 17:34.230
So you continuously need to learn because it's not possible for you to learn everything and come up

17:34.230 --> 17:39.150
with the optimal policy because the optimal policies also changed with the environment all the time.

17:39.180 --> 17:44.670
In that case you will need to continue CALKIN temporal difference in calculating the Q values.

17:44.670 --> 17:46.770
But other than that that's kind of like an extra complication.

17:46.770 --> 17:49.320
Other than that this is how Q values are data.

17:49.320 --> 17:55.950
So this is the main formula of the Q learning algorithm and this is kind of like the expanded version

17:55.950 --> 17:58.800
of that and now it should all come together.

17:58.790 --> 18:04.380
Makes sense why we have the Belman equation and not only what it represents the gewgaws but also how

18:04.380 --> 18:12.180
the agent goes about updating its values and finding exactly what is going on in that environment so

18:12.180 --> 18:14.220
it can come up with the optimal policy.

18:14.580 --> 18:21.540
So I know quite a lot to take in but hopefully you enjoyed this tutorial and hopefully you able to take

18:21.540 --> 18:28.620
away the underlying concepts and intuition behind your values and what's your whole notion of temporal

18:28.620 --> 18:36.930
difference is and why it's important why it helps us slowly train our agents and get them to understand

18:37.020 --> 18:38.920
their environments that they're operating in.

18:39.210 --> 18:45.480
And if you'd like to learn a bit more about temporal differences then a very popular paper is learning

18:45.480 --> 18:52.500
to predict by the methods of temporal differences by Richard Sutton of nineteen eighty eight.

18:52.560 --> 18:57.480
We've already had a reference by Richard Sutton as well but this is another one and actually has a book

18:57.490 --> 19:05.740
so if you get into his writing style and his style of communication then check out his book as well.

19:05.800 --> 19:08.600
It is kind of like a more expanded version of all of these things.

19:08.610 --> 19:11.850
I haven't read the book but that's what I'm imagining.

19:11.850 --> 19:17.850
At the same time this is going to get to the paper and you can learn a bit more about or and probably

19:17.850 --> 19:20.970
a lot more about temporal differences there.

19:21.240 --> 19:24.210
And I hope you enjoyed today's tutorial and loquats see you next.

19:24.210 --> 19:26.190
Until then enjoy AI.
