WEBVTT

00:00.240 --> 00:02.400
Hello and welcome back to the course in deep learning.

00:02.400 --> 00:07.930
Today we're talking about the neuron which is the basic building block of artificial neural networks.

00:07.950 --> 00:09.330
So let's get started.

00:09.330 --> 00:11.280
Previously we saw an image which looks like this.

00:11.280 --> 00:17.820
And these are actual real life neurons which have been smeared onto a glass and colored a little bit

00:17.850 --> 00:19.920
and they are observed through a microscope.

00:19.920 --> 00:21.890
So this is what they look like as you can see.

00:22.080 --> 00:29.670
Quite an interesting structure a body and then lots of different tails kind of branches coming out of

00:29.670 --> 00:30.180
them.

00:30.270 --> 00:32.320
And this is very interesting.

00:32.340 --> 00:38.340
But the question is how can we recreate that in a machine because we really need to recreate it and

00:38.340 --> 00:47.550
machine since the whole purpose of deep learning is to mimic how the human brain works in the hope that

00:47.760 --> 00:53.040
by doing so we're going to create something amazing and we're going to create an amazing infrastructure

00:53.190 --> 00:55.150
for machines to be able to learn.

00:55.170 --> 00:56.740
And why do we hope for that.

00:56.760 --> 01:03.420
Well because the human brain is well just happens to be one of the most powerful learning learning tools

01:03.870 --> 01:07.220
on the planet or like learning mechanisms on the planet.

01:07.260 --> 01:11.280
And we just hope that if we recreate that we'll have something as awesome as that.

01:11.280 --> 01:17.610
So our challenge right now our very first step to creating artificial neural networks is to recreate

01:17.640 --> 01:18.320
a neuron.

01:18.330 --> 01:19.030
So how do we do it.

01:19.050 --> 01:23.810
Well first of all let's have a closer look at what it actually is.

01:23.850 --> 01:32.950
This image was first created by a Spanish neuroscientist and Chagga Ramon Yi Kajal in 1899.

01:33.150 --> 01:37.770
And what he did was he died in neurons in actual brain tissue.

01:37.800 --> 01:39.650
Look at them under a microscope.

01:39.840 --> 01:43.470
And while he was looking at them he actually drew what he saw and this is what he saw.

01:43.470 --> 01:49.500
He saw it too in your hands or two large neurons are there at the top which had all these branches coming

01:49.500 --> 01:52.220
out of them towards their top parts.

01:52.230 --> 01:59.360
And then the each one had this Araud or like thread coming out towards the bottom very long one.

01:59.470 --> 02:01.440
And so that's what he saw.

02:01.590 --> 02:07.740
And now you know technology has advanced quite a lot and we have seen neurons much closer in more detail

02:07.740 --> 02:11.830
and now we can actually draw what it looks like diagrammatic.

02:11.850 --> 02:13.150
So let's have a look at that.

02:13.380 --> 02:14.150
Here's a neuron.

02:14.160 --> 02:22.020
This is what looks like very similar to what Santiago around one drew over here and here and this neuron

02:22.080 --> 02:24.340
what we can see is that it's got a body.

02:24.510 --> 02:29.040
That's the main part of the neuron and then it's got some branches at the top which are called dendrites

02:29.070 --> 02:33.250
and it's also going an X on which is that long tail of the euro.

02:33.290 --> 02:39.450
And so what are these dendrites and went forward with the X and for all the key point to understand

02:39.450 --> 02:43.950
here is that neurons by themselves are pretty much useless.

02:43.980 --> 02:45.500
It's like it's like an ant.

02:45.540 --> 02:46.030
Right.

02:46.030 --> 02:52.010
And and on its own can do mice like five ants together maybe they can pick something up but again they

02:52.200 --> 02:57.270
they don't they can build an anthill or they call them establish a colony or they can't work together

02:57.270 --> 02:59.340
as a as a huge organism.

02:59.340 --> 03:03.240
But at the same time when you have lots and lots of ads like you have an in a million and so they can

03:03.240 --> 03:06.540
build a whole colony they can build an anthill sensing with neurons.

03:06.540 --> 03:12.210
By itself it's not that strong but when you have lots of neurons together they work together to do magic.

03:12.480 --> 03:13.770
And how do they work together.

03:13.770 --> 03:14.370
That's the question.

03:14.370 --> 03:19.080
Well that's what the dendrites and Aksenov for so the dendrites are kind of like the receivers of the

03:19.080 --> 03:23.110
signal for the neuron and axon is the transmitter of the signal for the neuron.

03:23.160 --> 03:26.460
And here's an image of how it all works conceptually.

03:26.460 --> 03:32.490
So at the top you've got on your own and you can see that it's dendrites are connected to axons of other

03:32.490 --> 03:35.700
neurons that are like even further away above it.

03:35.940 --> 03:42.810
And then the signal from this neuron travels down its axon and connects or passes on to the dendrites

03:42.810 --> 03:44.750
of the next neuron and that's how they're connected.

03:44.970 --> 03:53.090
And in that small image over there you can see that the axon doesn't actually touch the dendrite lot.

03:53.340 --> 03:59.100
A lot of machine learning or like a few machine learning scientists are very adamant about the fact

03:59.100 --> 04:03.600
that it doesn't touch it like the rube it doesn't touch.

04:03.600 --> 04:06.880
It has been proven that there is no physical connection there.

04:06.930 --> 04:13.950
But the point that we're interested in is that that connection between them that the whole concept of

04:13.950 --> 04:16.290
the signal being passed that's called the sign ups.

04:16.290 --> 04:23.220
You can see over there in that little image that's figure bracket is a sign ups and that's a term we're

04:23.220 --> 04:29.160
going to be using So instead of calling our artificial neurons the lines that we're going to have or

04:29.160 --> 04:33.720
the connectors for fuel Neros we're now going to be calling them axons or dendrites because then the

04:33.720 --> 04:36.860
question is whose connection is this is it that neurons are neurons.

04:36.930 --> 04:39.230
We just call that good which is good to call them says.

04:39.450 --> 04:42.620
And that's kind of just answers all questions right away.

04:42.630 --> 04:47.550
That's just basically where the signal is POS doesn't matter who that element belongs to.

04:47.550 --> 04:51.520
They're just a representation of the signal we pass and we'll see that just now.

04:51.930 --> 04:54.840
So basically that's how a neuron works.

04:55.110 --> 05:03.910
And yeah so let's move on to how we going to represent neurons create neurons in machines so we're moving

05:04.000 --> 05:09.370
away now we're moving away from neuroscience and moving into technology.

05:09.400 --> 05:10.210
And here we go.

05:10.300 --> 05:17.200
So here's our neuron also sometimes called the node then your own gets some input signals and it has

05:17.200 --> 05:18.320
an output signal.

05:18.340 --> 05:20.850
So dendrites and axons remember.

05:20.980 --> 05:27.430
But again we're going to call these sinuses and then these input signals we're going to represent them

05:27.430 --> 05:29.000
of other neurons as well.

05:29.020 --> 05:35.440
So in this specific case you can see that this neuron is green you're on is getting signals from yellow

05:35.440 --> 05:35.800
neurons.

05:35.800 --> 05:41.740
And in this course we're going to try and stick to a certain color coding regime where yellow means

05:41.770 --> 05:42.490
an input layer.

05:42.490 --> 05:50.660
So basically all of the neurons that are on the outer layer on the first front of where are the signals

05:50.680 --> 05:52.280
coming in and by signal.

05:52.300 --> 05:59.230
It might be like a bit of an over overkill to call this a signal it's just basically input values so.

05:59.280 --> 06:04.690
So you know how even like in a simple linear regression you have input values and then you have a predicted

06:04.690 --> 06:05.560
value Same thing here.

06:05.560 --> 06:10.660
So you have input values and there they are the yellow ones and then on the right you'll see just now

06:10.660 --> 06:11.190
it will be red.

06:11.200 --> 06:12.910
It'll be the output value.

06:13.580 --> 06:17.080
The other thing that I wanted to point out here is that in this specific example we're looking at a

06:17.080 --> 06:21.280
neuron which is getting its signals from the input layer neurons.

06:21.290 --> 06:24.460
They're also neurons but they're their input their neurons.

06:24.490 --> 06:31.360
Sometimes you'll have neurons which get their signal from other hidden layer neurons so from other green

06:31.360 --> 06:33.140
neurons and the concept is going to be exactly this.

06:33.140 --> 06:38.170
I mean just in this case we used for simplicity's sake we're portraying this example and in terms of

06:38.170 --> 06:46.150
the input layer the way to think about it is in the in the analogy of the human brain the input layer

06:46.150 --> 06:52.270
is your senses right so whatever you can see hear feel touch or smell.

06:52.450 --> 06:57.190
And of course it's like there's there's a lot of things you can see there's a lot of information coming

06:57.190 --> 07:02.660
in but those are your That's what your brain is limited to is pretty much a lie.

07:02.940 --> 07:09.100
Israel lives in a box made out of bones and it's only just it's it's a mind blowing concept to think

07:09.100 --> 07:15.670
about that your brain is just locked in a black box and the only thing it can see you can hear the only

07:15.670 --> 07:21.850
thing is getting is electrical impulses coming from these organs that you have called your ears nose

07:21.940 --> 07:28.840
eyes you know your sense of touch and whatever and you and your and your taste right so you're just

07:28.840 --> 07:34.990
getting signals but it basically lives in this dark black box and it's making making sense of the world

07:34.990 --> 07:38.400
through your senses it's phenomenal.

07:38.440 --> 07:42.970
And so yeah so you have these inputs that are coming in in terms of human brain.

07:42.970 --> 07:49.510
Those are your five senses and in terms of machine learning or deep learning that is basically your

07:49.840 --> 07:55.470
input values are your independent variables and we'll get that in a second so your input values they

07:56.330 --> 08:01.030
the signal is passed through sinuses to the neuron and then in your own has an output value that it

08:01.030 --> 08:03.010
passes further on down the chain.

08:03.490 --> 08:07.930
In this specific case in terms of color coding again yellow means input layer so we kind of simplifying

08:07.930 --> 08:11.800
everything here we're saying we're only going to have like the input layer and that we're going to have

08:11.800 --> 08:16.450
one hidden layer with the green which is the hinterland then we're going to have the output there right

08:16.450 --> 08:17.090
away.

08:17.470 --> 08:21.310
So just so that we can get used to these calls for now.

08:21.550 --> 08:23.980
So there we go that's the basic structure.

08:23.980 --> 08:28.330
So now let's look in a bit more detail at these different elements that we have.

08:28.330 --> 08:31.030
So we've got the input layer and what do we have here.

08:31.030 --> 08:36.690
Well we have these inputs which are in fact independent variable so it depends variable one the debate

08:36.710 --> 08:37.940
variable to depend.

08:37.980 --> 08:44.170
Well the important thing to remember here is that these independent variables are all for one single

08:44.170 --> 08:44.680
observation.

08:44.680 --> 08:47.560
So think of it as just one row in your database.

08:47.560 --> 08:54.730
One observation you just take all of the independent variables you know maybe it's the age of the person

08:54.760 --> 09:00.730
there the amount of money in the bank accounts and then how how do they drive or walk to work.

09:00.730 --> 09:03.000
What method of Champus protection do they use.

09:03.040 --> 09:09.430
So that's all descriptors of one specific person that you are either your training your model on or

09:09.430 --> 09:12.260
you're performing some prediction on.

09:12.550 --> 09:16.870
And the other thing you need to know about these variables is that you need to standardize them so you

09:16.870 --> 09:21.270
need to standardize them which means make sure that they have a mean of zero and variance one.

09:21.280 --> 09:29.020
Or you can also sometimes and headland will point out these traces in a bit more detail perhaps in the

09:29.020 --> 09:33.130
practical stories you might come across these sometimes you might want to know standardize you might

09:33.130 --> 09:34.730
want to normalize them.

09:34.960 --> 09:40.880
Meaning that instead of making sure the mean environmental zero invariants is one you just take you

09:40.870 --> 09:45.280
know to subtract the minimum value and then you divide by the maximum minus minimums or by the range

09:45.820 --> 09:49.150
of your values and the four you get values between 0 and 1.

09:49.450 --> 09:53.530
And it depends on this scenario you might want to do one or the other.

09:53.530 --> 10:00.650
But basically you want all of these variables to be quite similar in about the same a range of values

10:00.710 --> 10:01.730
and why.

10:01.730 --> 10:02.120
Why is that.

10:02.130 --> 10:06.830
Well all of these values are going to go into a neural network where as we'll see just now they'll be

10:06.830 --> 10:13.160
added up and multiply by weights added up and so on and just going to be is going to be easier for the

10:13.160 --> 10:17.120
neural network to process them if they're all about the same.

10:17.280 --> 10:23.730
And and in fact you know that's that's just how it is going to be able to work properly.

10:24.200 --> 10:29.150
And if you want to read more about standardization normalization and other things that you can do if

10:29.150 --> 10:36.410
you know what variables a good additional reading paper is called efficient back prob by young Licken

10:37.010 --> 10:39.800
1998 links over there.

10:39.830 --> 10:47.540
So we're actually going to talk more about this phenomenal person in the space of deep learning in the

10:47.660 --> 10:51.830
part of the course where we're talking about convolutional neural networks and you'll you'll see that

10:51.830 --> 10:55.170
this is definitely a person who knows what he's talking about.

10:55.220 --> 11:00.810
He's a close friend of Jeffrey Hinton who we've already seen who are very dim..

11:00.830 --> 11:07.010
So in this paper you'll learn more about Senator zation normalization but also you can pick up lots

11:07.010 --> 11:11.450
of other different tips and tricks and you'll be a good a good source for additional reading as you

11:11.450 --> 11:12.380
go through this course.

11:12.500 --> 11:15.890
So you check it out if you're interested in some additional reading.

11:16.240 --> 11:20.170
There we go so that's what we do for the variables.

11:20.460 --> 11:23.120
And here we've got the output value.

11:23.120 --> 11:24.900
So what can our output value be.

11:25.070 --> 11:26.220
Well we've got a couple of options.

11:26.240 --> 11:32.040
Output value can be it can be continuous Like for instance price it can be binary for instance a person

11:32.040 --> 11:39.190
will exit or will stay or it can be categorical verbal and physical wriggler categorical variable.

11:39.200 --> 11:43.990
The important thing to remember here is that in that case your output value won't be just one it'll

11:44.000 --> 11:50.330
be several output values because these will be a dummy variables which will be representing your categories

11:51.320 --> 11:57.380
and that just that's how it works and just important to remember that in that case that's how you're

11:57.380 --> 12:02.530
going to be getting your category's out of the artificial neural network.

12:02.750 --> 12:05.440
But then go back to a simple case of one output volume.

12:05.690 --> 12:11.720
And now let's one more point or kind of like a point the ready made I just wanted to reiterate this

12:11.720 --> 12:15.410
point on the left you've got a single observation.

12:15.410 --> 12:19.850
So I wonder if you mean from your data set and on the right you have a single generation as well and

12:19.850 --> 12:22.020
that is the same observation.

12:22.130 --> 12:28.040
So important to remember that like whatever inputs you putting in that's for one row and then the output

12:28.040 --> 12:29.910
you get that is for that same exact row.

12:30.020 --> 12:34.390
Or if you're training your neural networks then you know you're putting the inputs in for that one role

12:34.390 --> 12:36.380
you're putting the output in for that one row.

12:36.380 --> 12:43.080
So like if you want to simplify the complexity think of it as a like a simple regression or in multivariate

12:43.220 --> 12:48.070
linear regression So you're putting in your values you have the output.

12:48.090 --> 12:51.920
There's there's like there's no question about it when we're talking about things like regression because

12:51.920 --> 12:52.730
we're so used to it.

12:52.730 --> 12:54.910
Same thing here it's nothing too complex.

12:54.920 --> 12:56.690
We're just putting in values we're getting output.

12:56.690 --> 13:01.250
But just remember that every time it's one row you're dealing with so you don't get confused and start

13:01.250 --> 13:07.880
putting in like thinking that these are different different rows that you're putting into your artificial

13:07.880 --> 13:12.650
neural network or something this is all just values in that one Rowse different observation different

13:12.650 --> 13:18.940
characteristics or attributes relating to that one observation every single time.

13:19.130 --> 13:25.780
OK so next thing we want to talk about here is the Sign-Up says is a sign it says here we've got sensors

13:25.790 --> 13:28.890
and they all actually get assigned weights weights.

13:28.890 --> 13:37.410
We can talk more about weights further down but in short weights are crucial to artificial neural network

13:37.420 --> 13:44.810
and works functioning because weights are how neural networks learn by adjusting the weights the neural

13:44.810 --> 13:50.340
network decides in every single case what single signal is poor and what signal is not important to

13:50.340 --> 13:51.080
a certain neuron.

13:51.080 --> 13:55.520
What single gets passed along and what signal doesn't get passed along or two what strength.

13:55.520 --> 13:57.690
To what extent signals get passed along.

13:57.730 --> 13:59.260
So weights are crucial.

13:59.270 --> 14:03.530
They are and they are the things that get adjusted through the process of learning.

14:03.540 --> 14:08.150
Like when when you're training an artificial neural network you're basically adjusting all of the weights

14:08.510 --> 14:11.000
in all of the sinuses across this whole neural network.

14:11.210 --> 14:17.840
And that's where gradient descent and back propagation come into play and those are concepts that we

14:17.840 --> 14:19.480
also discussed.

14:19.610 --> 14:21.200
So basically those are the weights.

14:21.350 --> 14:22.810
That's why we need to know for now.

14:23.120 --> 14:28.200
And we've got the neurons so signals go into the neuron and what happens in the euro.

14:28.370 --> 14:30.470
So this is the interesting part.

14:30.470 --> 14:33.610
Like we're talking about the neuron today what happens inside the neuron.

14:33.830 --> 14:40.670
So a few things happen first thing and the first step is that all of these values that is getting gets

14:40.880 --> 14:41.300
added up.

14:41.300 --> 14:49.690
So it takes that added so the weighted sum of all of the input values that is getting very simplified

14:49.850 --> 14:56.390
it's very very straightforward just add up multiply by the way add them up and then it applies an activation

14:56.390 --> 14:57.140
function.

14:57.140 --> 15:01.000
Now we're going to talk more about activation functions go down but it's basically a function that is

15:01.000 --> 15:09.350
assigned to this neuron or this whole there and it is applied to this way did some.

15:09.520 --> 15:16.750
And then from that that you don't understand if it needs to pass on a signal if you like and that's

15:16.750 --> 15:22.210
the signal that it passes on that the function applied to the way that some.

15:22.210 --> 15:26.350
But basically depending on the function the neuron will either pass on a signal it or it won't pass

15:26.350 --> 15:27.330
the signal on.

15:27.820 --> 15:34.150
And that's exactly what happened here in step three the neuron pasta's on that signal to the next neuron

15:34.570 --> 15:35.620
down the line.

15:36.040 --> 15:39.900
And that's what we're going to talk about in the next tutorial because it is quite an important topic.

15:39.900 --> 15:46.570
We want to delve deeper into the activation function but hopefully for now everything is should be pretty

15:46.570 --> 15:51.550
clear how you know the input values you've got weights you've got design houses you've got something

15:51.610 --> 15:56.470
you know happens in neuron you've got way that Sarmad an activation function applied and then that is

15:56.470 --> 16:00.670
passed down the line and that is just repeated throughout the whole neural network on and on and on

16:00.730 --> 16:06.790
and on you know thousands hundreds of thousands of times depending on how big how many neurons you have

16:06.790 --> 16:09.510
how many situps as you have in your neural network.

16:09.520 --> 16:10.060
So there we go.

16:10.060 --> 16:13.170
Hope you enjoyed today's Tauriel Coates to an extent.

16:13.230 --> 16:15.120
And until then enjoy deep learning.
