WEBVTT

00:00.930 --> 00:04.950
Hello and welcome back to the course on artificial intelligence.

00:04.950 --> 00:10.980
Previously we had quite a strenuous and long tutorial on market of decision processes and hopefully

00:11.400 --> 00:18.950
you got along well with that and hopefully I could explain things in a approachable and engaging way.

00:19.080 --> 00:22.670
And today we're going to talk about policies versus plans.

00:22.680 --> 00:27.690
There ought to be a quick and fun tutorial because now we're entering into a new world we're entering

00:27.690 --> 00:33.750
into a world of stochastic search nondeterministic search when it's not just about getting through the

00:33.750 --> 00:38.760
maze but also accounting for random factors that might just hit you in the head when you're going through

00:38.760 --> 00:41.040
this maze and you need to be prepared for that.

00:41.040 --> 00:47.430
That's the world our agent is living in and it's more fun but it's also more dangerous it's more it's

00:47.430 --> 00:48.600
less predictable.

00:48.600 --> 00:50.910
So how is our agent going to behave.

00:50.910 --> 00:52.230
Let's have a look.

00:52.230 --> 00:58.140
There's our mark of decision process framework which is once again our favorite Belman equation.

00:58.200 --> 01:01.940
However the the more advanced version of the Belman equation we are working with.

01:01.950 --> 01:04.550
So from now on we're just going to call this the Beldon equation.

01:04.710 --> 01:10.920
And here we've got our maximal and Crucell actions so the value of a state any state as is the maximum

01:10.920 --> 01:13.950
across all actions an agent could possibly perform in that state.

01:14.070 --> 01:21.240
And the next was taken from the reward that the agent will get by perform action A instate as Plus a

01:21.240 --> 01:26.630
discount factor multiplied by the expected value of the new state it will be in.

01:26.790 --> 01:31.830
And I'd expect those taken here because they are doesn't know exactly what they will end up in.

01:31.830 --> 01:40.350
There are some random effects that are present in the environment that might alter the state and not

01:40.770 --> 01:44.160
might not end up in the desired state it might end up in a different state.

01:44.160 --> 01:47.880
That's why we're taking the expected value over here somewhere here.

01:47.940 --> 01:53.700
So let's have a look at this as our example our or in our example the maze.

01:53.700 --> 02:00.170
So this is what we had previously so previously we're dealing with live deterministic search.

02:00.180 --> 02:01.730
So we knew that.

02:01.920 --> 02:06.870
All right so if I'm here I definitely need to go here if I'm here I definitely need to go here if I'm

02:06.870 --> 02:09.090
here I definitely need to go here if I'm here I'm here.

02:09.090 --> 02:11.400
So it was all pretty straightforward.

02:11.400 --> 02:14.610
Once you have this map and remember you called it we called it a plan.

02:14.610 --> 02:18.000
Once you have the plan it's pretty straightforward to do.

02:18.000 --> 02:20.450
There are errors so that's the plan with arrows.

02:20.530 --> 02:24.950
And from here it was very straightforward where this is these are the routes that they will take whenever

02:24.950 --> 02:26.240
you start on this blue line.

02:26.260 --> 02:28.160
That's exactly the way you'd go.

02:28.620 --> 02:31.070
However now we don't have a plan anymore.

02:31.060 --> 02:36.480
We can't have a plan because you know whatever we plan might not happen.

02:36.650 --> 02:40.890
It's not under control a plan is when you know exactly what you need to do next.

02:40.890 --> 02:41.770
You know the steps.

02:41.790 --> 02:46.590
So you have a you have a starting point you have a goal and you know every single step so you can plan

02:46.590 --> 02:50.330
them out you like I'll do this one I'll do this one I'll do this like in life like a plan.

02:50.580 --> 02:54.840
But at the same time there's so much now randomness going on.

02:54.830 --> 03:00.030
You can have a plan because what if you get here and then you click to the right and actually takes

03:00.030 --> 03:00.500
you down.

03:00.630 --> 03:02.040
So that's not part of your plan.

03:02.310 --> 03:03.920
So that's why it's called the planning more.

03:04.140 --> 03:09.030
And here we're going to calculate the values are actually going to just look at the calculated values

03:09.360 --> 03:11.970
for this same problem.

03:12.030 --> 03:16.650
What's based on that given that we have this randomness inside.

03:16.650 --> 03:18.750
So these are the new values.

03:18.750 --> 03:22.800
And so why are these values different so let's just compare to what we had previously.

03:22.800 --> 03:24.660
This is what we had previously.

03:24.660 --> 03:25.560
These are then you.

03:25.560 --> 03:31.530
So once again we had previously because he won point or pronate it was really 366.

03:31.740 --> 03:36.710
And this is what we have now 86 a less than 1 in force and 1 6 3 and so on.

03:36.750 --> 03:43.780
And by the way these are not exactly the current rolls off the top of my head but if we were to run

03:43.780 --> 03:49.170
an agent some values would be something similar to this and the values could change because depending

03:49.170 --> 03:54.600
on the Gamelin that would choose 0.9 or other value but nevertheless for the for argument's sake these

03:54.600 --> 03:57.750
are the values that we're dealing with now and they're approximate.

03:57.750 --> 04:02.210
They convey the whole notion in the correct way so let's have a look at that.

04:02.220 --> 04:03.170
Why have they changed.

04:03.360 --> 04:07.400
Well why is here with this one here the value was 1.

04:07.410 --> 04:11.680
Why is it Olafson and zero point 86 Why is it less than one can we just go from here here.

04:11.880 --> 04:18.570
Well we actually called because from here if we go right which is our intention if we get right we could

04:18.570 --> 04:18.930
i would.

04:18.930 --> 04:22.290
Actually we have a 10 percent chance we would end up here.

04:22.290 --> 04:25.080
So we'd hit the wall and would be back in this state.

04:25.080 --> 04:30.690
And remember we have a Gamla So the value would be discounted and or we're off or off attempts and just

04:30.690 --> 04:32.100
would end up here in this state.

04:32.100 --> 04:37.620
So it's not 100 percent probability I would get here so therefore disvalue can no longer be a one it's

04:37.620 --> 04:41.440
something less and it's that 0.18 six.

04:41.520 --> 04:47.610
So that's an example of why it's like this and you could get the exact value if you calculated the Belman

04:47.610 --> 04:49.750
equation the full Belman question that we have now.

04:49.800 --> 04:53.640
The only problem is that there would be some recursion because you would need to know the value for

04:53.640 --> 04:54.190
this.

04:54.330 --> 04:55.820
And then you need to know the value for this.

04:55.820 --> 04:59.110
It is quite complex and that's why we're not doing the calculations manually here.

04:59.160 --> 05:05.500
That's why the I can do them as it's going through through all this it's like it's like nothing too

05:05.500 --> 05:06.480
complex for a guy.

05:06.490 --> 05:08.450
You can't play these things.

05:08.470 --> 05:10.020
So that's our value here.

05:10.030 --> 05:11.470
But a lot of this is a different one.

05:11.470 --> 05:16.560
So here it just to be 0.9 just because of the discounting factor remember from here to here again now

05:16.570 --> 05:22.120
from here we colleges just jump from here to here simply because even if we jump if we go like this

05:22.420 --> 05:24.540
we might end up back here back here.

05:24.640 --> 05:28.960
Right this 20 percent chance that we'll still stay in the square because we'll hit a wall and again

05:28.990 --> 05:29.680
and so on.

05:29.680 --> 05:32.840
So the value of being here is zero point seventy one.

05:32.900 --> 05:35.320
Again this and the discounting factor.

05:35.320 --> 05:39.910
You know this might look odd to you that this is even with the discount in fact this is too high.

05:39.970 --> 05:44.360
Maybe the discounting factor in this example is not 0.9 maybe it's zero point ninety nine or something

05:44.360 --> 05:48.430
like that so don't worry about that just kind of like focus on that.

05:48.430 --> 05:53.200
The values have indeed changed that the values are now less.

05:53.410 --> 05:59.000
Mostly because it's not a hundred percent probability to get to the state that you want to get.

05:59.200 --> 06:05.020
And don't you will find an interesting one is here that here just to be 0.9 actually has dropped very

06:05.020 --> 06:06.610
much has dropped substantially.

06:06.610 --> 06:07.030
Why is that.

06:07.030 --> 06:12.070
Well because if you go from here up which is our intention there's a 10 percent chance of hitting a

06:12.070 --> 06:18.600
wall but there's a 10 percent chance of actually ending up in the fire pit and losing minus one to reward

06:18.610 --> 06:22.770
and basically that means for the agent that's that's end of the game.

06:23.110 --> 06:25.570
And so this is a very bad state to be in.

06:25.600 --> 06:28.710
So all of a sudden remember we had zero point nine Here is a point.

06:28.720 --> 06:29.850
So they were equivalent.

06:29.860 --> 06:34.860
Doesn't matter you hear here they're pretty much equal in terms of value of being in each of these states.

06:34.930 --> 06:42.610
But now all of a sudden bam this state is like nearly twice as good as this one simply just because

06:42.790 --> 06:46.880
here if you go straight to it you go right where you want to go.

06:46.980 --> 06:51.240
The you know the consequences of the randomness occurring is you just stay here.

06:51.250 --> 06:55.010
Here one of the consequences a 10 percent chance is you end up in the pit.

06:55.060 --> 07:02.110
So as you can see this is no longer such a good state anymore simply because of something that fluctuation

07:02.110 --> 07:03.400
that could happen.

07:03.520 --> 07:09.070
As you can see this one is also very bad because it's as bad as this one in terms of you know it's only

07:09.070 --> 07:12.510
10 percent chance of ending up in the pit and 10 percent chance of winning in the wall.

07:12.610 --> 07:18.430
But at the same time there's a discounting factor So first of all the discounting factor and also after

07:18.430 --> 07:20.510
this one you'd have to go here.

07:20.650 --> 07:23.830
And even if you hypothetically win here you could end up in the pit again.

07:23.860 --> 07:28.660
So that chance would also be taken into account because remember this values derive from this value

07:28.660 --> 07:31.720
and this value is derived from this value.

07:31.810 --> 07:32.260
Right.

07:32.350 --> 07:37.510
And therefore it's small but in reality actually what I said there was wrong.

07:37.510 --> 07:39.590
This value is not derived from this value.

07:39.760 --> 07:46.750
So if you just have a look now you will notice that this value over here is actually greater than this

07:46.750 --> 07:47.260
one.

07:47.560 --> 07:54.730
You will notice that for the agent it's better to go all this way than this way and it makes sense right.

07:54.730 --> 07:58.540
Because this way it doesn't lose it there's no chance of getting it.

07:58.540 --> 08:03.420
Yes is a bit longer and therefore the discounting factor has a bigger effect.

08:03.460 --> 08:07.420
But at the same time simply because there's a chance of getting in the pit here if it goes straight

08:07.450 --> 08:09.170
it will there's a chance of a jump in.

08:09.190 --> 08:15.070
So it will take a draw to take its time and just go around because that way there's a much lesser chance

08:15.070 --> 08:16.400
of it getting If there still is.

08:16.400 --> 08:19.520
So from here goes there from here goes there.

08:19.540 --> 08:23.600
It could potentially get into the pit because it could end up there and that could end up in the bin.

08:23.680 --> 08:27.310
But nevertheless it's a lesser chance so it will just go around like that.

08:27.310 --> 08:32.380
So very interesting to see how they're all changed remember Bruce you from here you would go like that.

08:32.380 --> 08:34.740
From here you'd go like that and from here we go like that.

08:34.960 --> 08:36.820
And now all of a sudden you can see his change.

08:36.820 --> 08:38.980
Let's roll the arrows and see what it looks like now.

08:39.490 --> 08:43.690
And voila you see even a more random thing right.

08:43.690 --> 08:45.210
So yes this is true.

08:45.220 --> 08:46.450
But look at what happened here.

08:46.450 --> 08:47.550
Look at this one.

08:47.630 --> 08:48.970
Look at this one.

08:49.000 --> 08:50.440
Were you expecting that.

08:50.470 --> 08:54.520
That's something definitely like when I saw this one first time I was was very impressed.

08:54.520 --> 08:59.720
I was not super I was not surprised and I was not expecting this at all.

08:59.920 --> 09:06.760
And this is an example of you know when a guy can outsmart a human insult like something you can't even

09:07.180 --> 09:12.250
you could predict but the AI through reinforcement learning remember that example of dogs can actually

09:12.250 --> 09:14.350
sometimes work better than normal real life.

09:14.350 --> 09:21.280
Dogs are preprogrammed robot dogs can play soccer simply because they come up with these ideas that

09:21.310 --> 09:22.380
even we can't see.

09:22.410 --> 09:27.280
And so as a great example you probably weren't expecting that as well that the Asians instead of going

09:27.280 --> 09:31.080
up is like why would I like if I go up.

09:31.240 --> 09:33.060
Then there's a 10 percent chance I'll jump into the pit.

09:33.070 --> 09:37.440
But what does it achieve by going into the wall while 80 percent of the time will bump back and say

09:37.440 --> 09:42.270
in the state but 10 percent of the time Ill go here and 10 percent of the time I'll go here.

09:42.280 --> 09:49.070
So all of a sudden you can see that now it's actually in this new approach of jumping into the wall.

09:49.120 --> 09:53.300
There is a zero percent chance it will go into the fire pit from this spot so.

09:53.310 --> 09:57.640
And it's like it really doesn't want to go into the fire pit so drugged bon bons into the wall a couple

09:57.640 --> 10:03.000
of times and then it will go the right or left at some point because that randomness is going to happen.

10:03.030 --> 10:09.630
And so it learned that through experimentation it learned that okay when I go forward the results are

10:09.630 --> 10:11.400
not as good as when I go to the wall.

10:11.460 --> 10:13.450
And if you think about it it's like this.

10:13.480 --> 10:18.300
This robot if you think about it this is a firepit is a very this is the this is like a square is like

10:18.300 --> 10:19.570
a very tiny ledge.

10:19.800 --> 10:21.580
And then this is like a mountain like a cliff.

10:21.600 --> 10:27.780
And this robot is just hugging the cliff and just like trying to waiting until it like pushes right

10:27.780 --> 10:32.550
or left because well as a human you probably do the same you wouldn't be standing facing that way that

10:32.580 --> 10:35.870
or you'd be hugging the cliff right or some leg.

10:35.970 --> 10:39.670
Hopefully you never need to end up never end up in situations like that.

10:39.710 --> 10:43.480
But like visually just visually if you think about something here.

10:43.710 --> 10:46.410
And so that's pretty intense right.

10:46.410 --> 10:51.900
So that the AI came up with this idea and same here that is going left and risking getting a fire but

10:51.900 --> 10:56.580
I'm just going to try balls off the wall like you know hug a wall try to jump into the wall and at some

10:56.580 --> 11:01.620
point I know that you know just there is a probability is a 10 percent chance every time I do that I'll

11:01.620 --> 11:05.190
go here and something will happen and I'll end up here and I'll be safe and then I'll just keep going

11:05.190 --> 11:06.630
like that.

11:06.780 --> 11:10.880
So very very interesting approach that they took care of.

11:10.880 --> 11:15.120
As you can see the the routes are like this so from here it might go right and then it'll go right to

11:15.120 --> 11:17.640
the exit or here or go left like that.

11:17.640 --> 11:22.210
And here we will at some point you will go left and go like that again.

11:22.260 --> 11:23.210
This is important.

11:23.290 --> 11:24.050
Is not a policy.

11:24.050 --> 11:27.560
So even when it jumps from here it will go here.

11:27.600 --> 11:31.770
Maybe And then from here it might actually instead of going straight it might actually go back to the

11:31.770 --> 11:34.480
right and then from here I'm going to let me is that right.

11:34.500 --> 11:38.030
So there's lots of different options for him to go through might not follow exactly this hour might

11:38.040 --> 11:38.850
go the other way.

11:38.880 --> 11:42.440
This is just the desired routes that it's designed for itself.

11:42.540 --> 11:44.630
But the way it'll work out is actually could be different.

11:44.630 --> 11:46.070
It depends on the real world.

11:46.290 --> 11:46.870
So there we go.

11:46.870 --> 11:50.040
That's the world of artificial intelligence.

11:50.040 --> 11:52.470
That's what policy versus a plan is.

11:52.680 --> 12:00.300
And hopefully you're getting slowly getting excited by what the can do especially given what we saw

12:00.300 --> 12:01.290
over here.

12:01.290 --> 12:07.370
These are some very virtuoso type of decisions that the AIs coming up with.

12:07.560 --> 12:12.930
And as you can see when you're playing AI even from this small example you can see that when you play

12:12.930 --> 12:19.170
in a real world maybe you'll come up with ideas and decisions that even sometimes humans can keep up.

12:19.200 --> 12:25.410
And that's exactly kind of like what happened in those games where the Google Alpha goal was playing

12:25.470 --> 12:33.000
versus Lisa idole champion of goal in Korea back in the world champion of go and they were playing in

12:33.000 --> 12:36.920
Korea back bakla in 2016 I think is March 2016.

12:36.960 --> 12:41.880
It came up with some moves that humans had never played in three thousand years or humans were not used

12:41.880 --> 12:42.330
to playing.

12:42.330 --> 12:45.460
And this is this is exactly an example of that.

12:45.690 --> 12:50.220
So once again I hope you're getting excited and pumped about discourse and about what we can integrate.

12:50.280 --> 12:52.670
And I look forward see you next time.

12:52.680 --> 12:54.320
Until then enjoy.

12:54.340 --> 12:54.580
I.
