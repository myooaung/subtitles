WEBVTT

00:01.230 --> 00:07.800
And here we go for the final step of this environment Python implementation we have to finish this by

00:07.800 --> 00:13.920
making a method that gives us at any time the current state the last word and whether the game is over.

00:14.160 --> 00:20.130
And I was so dying to go to the next step you know implementing this artificial brain that I found the

00:20.130 --> 00:22.830
most efficient way to finish that method.

00:22.890 --> 00:27.650
You're going to see it will be was just one copy based and one small replacement.

00:27.870 --> 00:29.040
Let's do this.

00:29.040 --> 00:37.530
So we're going to call that method the observe method that is only going to take itself as the argument

00:37.800 --> 00:42.840
because we actually only need the values of the variables of our object which contain the current state

00:42.840 --> 00:45.280
the last word and whether the game is over.

00:45.300 --> 00:47.510
So no need for any other argument.

00:47.520 --> 00:55.710
Now it's at Coulon and that's where my efficiency comes into play in order to get the actual state the

00:55.710 --> 00:58.800
last reward obtained and whether the game is over.

00:58.800 --> 01:06.270
The only thing that we have to do is just copy paste all this because indeed this will give us the current

01:06.420 --> 01:07.960
scaled state.

01:08.040 --> 01:14.250
And of course we want the scale state because we will use this observe method at some point because

01:14.250 --> 01:16.420
our artificial brain will need it.

01:16.590 --> 01:19.190
So we just have to copy and paste this.

01:19.470 --> 01:24.900
But then remember I told you about a little replacement here just to make everything clear.

01:24.900 --> 01:29.880
We're actually not observing the next day but the current state.

01:30.000 --> 01:30.940
And that's it.

01:31.200 --> 01:38.130
And so now we are ready to return the final outcomes of this observed method because indeed what we

01:38.130 --> 01:46.560
want is a observed method to return is the current state then the reward which is a variable of all

01:46.680 --> 01:52.660
objects itself that we word and whether the game is over which is given by another variable or object

01:52.960 --> 01:54.720
which is self.

01:54.860 --> 01:56.860
That game over.

01:57.040 --> 01:58.170
And here we go.

01:58.180 --> 01:59.830
Finally we did it.

01:59.830 --> 02:00.690
We're done.

02:00.700 --> 02:05.970
We're now done with this huge environment implementation so I'm going to save.

02:06.130 --> 02:08.350
And now we are ready for the second.

02:08.350 --> 02:10.410
Very exciting big step.

02:10.420 --> 02:16.170
Our general AI framework which is to build the artificial brain of our AI.

02:16.310 --> 02:18.870
So we'll do that in the next couple of tutorials.

02:18.880 --> 02:20.770
I can't wait to create that with you.

02:20.800 --> 02:22.480
And until then enjoy AI.
