WEBVTT

00:00.450 --> 00:01.690
Hello welcome back.

00:01.770 --> 00:08.590
So we just reached the next date by playing a random action from our list of playable actions.

00:08.760 --> 00:15.990
And now the next step is step for computing the temporal difference the temporal difference which is

00:15.990 --> 00:22.240
given by this formula here is at the core of the cube learning algorithm because indeed that's what

00:22.240 --> 00:27.560
the temporal difference here that will update the cube values at each iteration.

00:27.750 --> 00:34.290
And as a reminder the temporal difference is the difference between this element here which is the reward

00:34.290 --> 00:41.040
we get by playing the action in the state as T plus the highest Q value of the next state as Tipper's

00:41.040 --> 00:42.890
one that we got in step three.

00:43.130 --> 00:49.920
Minus this element which is the q value of action played 80 which is the action we played in step 2

00:50.280 --> 00:55.290
in the current state Estey which is our current state we selected in step 1.

00:55.320 --> 00:55.590
All right.

00:55.590 --> 01:01.940
So this is a temporal difference and that's exactly what we have to compute right now in step 4 of the

01:01.950 --> 01:03.590
Q learning algorithm.

01:03.660 --> 01:06.240
So we'll just compute that exactly as it is.

01:06.420 --> 01:12.600
And therefore let's go back to our code and let's introduce a new variable which we're going to call

01:12.600 --> 01:16.860
of course naturally tiddy as a temporal difference.

01:16.860 --> 01:17.160
All right.

01:17.160 --> 01:18.750
So let's start again.

01:18.990 --> 01:26.370
Tiddy is equal to first the word we get by playing the action 80 which is the action we played in step

01:26.380 --> 01:31.880
2 in the current state t which is the action we selected in step 1.

01:31.890 --> 01:33.280
All right so let's get that.

01:33.300 --> 01:38.450
It's really easy we're already have our reward function or our reward Matrix.

01:38.460 --> 01:39.410
That's the same.

01:39.600 --> 01:46.260
So we can just take it and in some brackets because our matrix we're going to get the inputs we need

01:46.560 --> 01:54.710
which is as we just said first the current state that's as T and then the action we just play.

01:54.720 --> 02:01.560
Remember the action we just played is exactly the same as the next set because remember the action 80

02:01.860 --> 02:05.040
is in fact the state that we reached by playing that action.

02:05.130 --> 02:06.140
So the next day.

02:06.270 --> 02:12.360
Plus one in the action 80 are exactly the same and therefore here instead of putting the Kurn action

02:12.360 --> 02:16.260
we can directly put the next state.

02:16.380 --> 02:21.030
All right and we have our first element of the temporal difference.

02:21.030 --> 02:23.100
Now let's go back to our slide.

02:23.310 --> 02:24.340
Here it is.

02:24.360 --> 02:27.720
Then the next element would still bar of the first element.

02:27.720 --> 02:36.180
The difference is the highest Q value we can have for the next state as the plus 1 multiplied by the

02:36.180 --> 02:37.960
discount factor again.

02:37.960 --> 02:46.230
All right so how are we going to get this maximum Q value of the next date as the first one over the

02:46.290 --> 02:47.560
possible actions.

02:47.670 --> 02:53.260
A That we can have that is over the different columns in the row corresponding to Esti plus 1.

02:53.670 --> 03:01.080
Well once again we're lucky to have an umpire with us because pi is going to give us exactly what we

03:01.080 --> 03:01.680
need.

03:01.830 --> 03:09.600
That is going to give us the action that maximizes the Q value for the row corresponding to the one

03:09.870 --> 03:11.430
in the matrix of Q value.

03:11.730 --> 03:16.670
Therefore we won't have to build or get any max function.

03:16.770 --> 03:23.370
We can just directly take the Q value of the rogue or responding to the next state as Plus 1 and then

03:23.370 --> 03:30.360
using this none by function which is the Oregon max function we'll be able to get the action that will

03:30.360 --> 03:36.580
give us the highest Q value on this row corresponding to Esti plus 1 in our matrix of Q value.

03:36.780 --> 03:37.860
That's really practical.

03:37.860 --> 03:42.160
We don't have to get any max function so I'm going to show you.

03:42.280 --> 03:47.520
First let's get gamma because we discount a little bit this highest Q value.

03:47.520 --> 03:49.780
And now that's where it gets interesting.

03:49.920 --> 03:56.280
In order to get this high Q value we don't have to take any Max here we can just take our matrix of

03:56.280 --> 04:00.210
Q value Q And then remember.

04:00.210 --> 04:02.460
Imagine this is the matrix of Q value here.

04:02.610 --> 04:03.840
And imagine this row.

04:03.840 --> 04:07.720
Here is the row corresponding to the next day as D plus one.

04:07.860 --> 04:13.740
Well we just need to get here is the highest Q value on this road that is.

04:13.740 --> 04:17.430
We just need to get the cell with the highest Q value.

04:17.430 --> 04:18.080
All right.

04:18.240 --> 04:22.600
So first of all the first thing we have to do here is get the correct row.

04:22.650 --> 04:29.210
Which is the row corresponding to SD plus 1 which we called the next state.

04:29.350 --> 04:33.780
Right then that's where we're going to use our magical function.

04:33.780 --> 04:36.080
By and by we want to get here.

04:36.180 --> 04:38.290
Following the same example we want to get here.

04:38.430 --> 04:44.760
The column that has the action which corresponds to the highest Q value on that road.

04:45.000 --> 04:47.780
And this action as we just said we're going to get it.

04:47.790 --> 04:54.150
Thanks to the RMX function by non-pay which will give us exactly the action that maximizes the Q value.

04:54.330 --> 04:55.690
On the specific row.

04:55.980 --> 04:56.970
So here we go.

04:57.090 --> 05:03.000
Let's call this the max function by non-pilots why I just took none by here.

05:03.210 --> 05:05.430
Argh Max than parenthesis.

05:05.570 --> 05:13.080
And inside the parenthesis we simply put the row of our matrix of Q values Q from which we want to get

05:13.170 --> 05:19.800
the action that will give us the highest Q value on that road and therefore inside here I just have

05:19.800 --> 05:27.970
to input this row which is q of the next state that is in the row corresponding to the next date.

05:28.140 --> 05:33.570
And then we just add comma and then nothing else because here that's where it needs to find the action

05:33.570 --> 05:38.290
that will maximize the Q value on this row corresponding to next date.

05:38.310 --> 05:46.890
No arguments here will return the action here which will maximize the value of the next date.

05:47.040 --> 05:50.610
For all the possible actions in the row corresponding to the next date.

05:50.820 --> 05:53.330
And that's exactly what we have here.

05:53.340 --> 06:00.210
That is the highest Q value we can find in the row corresponding to C plus one over the different columns

06:00.510 --> 06:02.220
corresponding to the actions.

06:02.650 --> 06:04.910
All right so here we go.

06:04.920 --> 06:05.820
That was a trick.

06:05.880 --> 06:09.090
That's actually the most efficient way we can get this size Q value.

06:09.090 --> 06:10.050
There are some other ways.

06:10.060 --> 06:12.850
Congratulations if you found any of them.

06:12.930 --> 06:17.400
And of course congratulations if you found this trick about ARG Max function.

06:17.820 --> 06:18.630
All right perfect.

06:18.630 --> 06:20.550
So now what do we have.

06:20.970 --> 06:22.000
What do we have.

06:22.170 --> 06:26.620
Well we have this first element of the temporal difference.

06:26.620 --> 06:28.380
Now let's get the second one.

06:28.470 --> 06:36.650
The value of the action 80 played in step 2 in the current state t selected in step 1.

06:36.780 --> 06:39.110
So that's an easy one to get it.

06:39.240 --> 06:48.360
Well we just need to take our matrix of Q values Q again and then in some brackets just get the current

06:48.360 --> 06:50.940
state because this is as t.

06:51.210 --> 06:54.220
And then of course the action 80.

06:54.330 --> 07:01.200
But again the action is nothing else than the state as Plus one that will reach by playing this action

07:01.230 --> 07:08.380
80 and therefore the column we want here is of course next state perfect.

07:08.430 --> 07:10.220
So congratulations.

07:10.260 --> 07:16.300
We just computed the temporal difference and now we're ready to move on to the final step of the cube

07:16.360 --> 07:20.050
learning algorithm and update our Q value.

07:20.100 --> 07:26.410
That is a q value of the action 80 played in step 2 in the current state as selected in step 1.

07:26.460 --> 07:32.840
We're going to update that by adding this temporal difference multiply by learning rate alpha.

07:32.970 --> 07:34.910
So let's do that in the next toile.

07:34.950 --> 07:36.630
And until then enjoy AI.
