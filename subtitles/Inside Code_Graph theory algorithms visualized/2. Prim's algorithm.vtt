WEBVTT
1

00:00:00.120  -->  00:00:05.700
Welcome back to the course, in this lecture we 
will learn about Prim's algorithm, an algorithm  

2

00:00:05.700  -->  00:00:12.780
that is used to find the minimum spanning tree 
of a graph. Okay imagine that we have this graph,  

3

00:00:12.780  -->  00:00:17.700
it's the example used in the Wikipedia 
article about minimum spanning trees.  

4

00:00:19.020  -->  00:00:25.920
Now we want to build its minimum spanning tree. 
Let's start from an arbitrary vertex, let's say A.  

5

00:00:26.820  -->  00:00:32.760
We know that at the end all vertices will 
be included in the mst so we can choose any  

6

00:00:32.760  -->  00:00:40.740
vertex to start with. Now you have to visualize 
the graph G as two components, the first one is  

7

00:00:40.740  -->  00:00:46.500
the one that contains vertices of our mst, and 
the second one contains remaining vertices.  

8

00:00:48.360  -->  00:00:53.280
The minimum spanning tree is connected so 
we have to connect these two components.  

9

00:00:54.540  -->  00:01:00.900
Right now, the first component contains A only, 
and the second one contains all other vertices.  

10

00:01:02.280  -->  00:01:09.240
How to connect these two components? We have 
three choices, we can either use the edge AB,  

11

00:01:09.240  -->  00:01:16.260
the edge AC, or the edge AF. We want 
the spanning tree with the minimum cost,  

12

00:01:16.260  -->  00:01:24.000
so we take the edge with the smallest weight, 
AC. Now same thing again, we have two components,  

13

00:01:24.000  -->  00:01:30.720
the first contains vertices in our mst, A and C, 
and the second one contains remaining vertices.  

14

00:01:31.740  -->  00:01:42.780
We have to connect them. We have 6 choices, 
using the edge AB, AF, CB, CD, CE, and CF. The  

15

00:01:42.780  -->  00:01:49.440
edge with the smallest weight is CD, we take it, 
we added a new edge and a new vertex to our mst.  

16

00:01:50.640  -->  00:01:57.300
Then again, two components, one contains A, C, and 
D, and the other one contains remaining vertices,  

17

00:01:57.300  -->  00:02:06.900
B E F G H I J. Now try to find how to connect 
them. To connect them, we have previous ways,  

18

00:02:06.900  -->  00:02:14.340
but we also discovered new ones by adding 
D, we can now also use edges DB, DG, and DE.  

19

00:02:15.900  -->  00:02:23.340
The shortest one is DB, we take it. We 
discovered a new way to connect, the edge BG.  

20

00:02:25.320  -->  00:02:30.720
We need to connect the component 
ACDB with the component FEGHIJ.  

21

00:02:32.760  -->  00:02:38.700
We have multiple available edges, edges that we 
can take to extend our minimum spanning tree,  

22

00:02:38.700  -->  00:02:50.580
we have AB, BC, BG, DG, DE, CE, CF, and AF. The 
shortest one is BC. But, B and C are already in  

23

00:02:50.580  -->  00:02:57.540
our mst, already in our first component, so it 
won't extend our mst, we don't take the edge.  

24

00:02:58.380  -->  00:03:03.600
Also, taking it would create a cycle, 
it doesn't even become a tree anymore.  

25

00:03:04.860  -->  00:03:11.220
The next shortest is AB, but same thing, we 
already took A and B, we ignore the edge.  

26

00:03:12.060  -->  00:03:20.040
Next shortest is DE, we take it, and 
we discover new edges, EG, EI, EJ, EF.  

27

00:03:21.960  -->  00:03:28.680
Shortest one is EG, we take it, and 
we discover new ways, GH and GI.  

28

00:03:30.720  -->  00:03:36.420
Here we can notice a pattern in the way we're 
working, what we're doing is that while we didn't  

29

00:03:36.420  -->  00:03:43.440
get our full mst, at each iteration, we search 
for the shortest available edge. And if it doesn't  

30

00:03:43.440  -->  00:03:50.880
lead to a vertex that is already in our mst, then 
we will extend our mst, we add the end vertex to  

31

00:03:50.880  -->  00:03:57.720
our mst. And we traverse its neighbors to see if 
we discover edges that we can take from now on.  

32

00:03:58.860  -->  00:04:07.860
We keep repeating until we build the whole mst. 
Let's continue where we stopped. Shortest edge  

33

00:04:07.860  -->  00:04:15.540
is now GH, and H is not in our MST, we 
take it and we discover edges HI and HJ.  

34

00:04:16.860  -->  00:04:26.400
Next iteration, shortest edge is HI, we add it to 
our mst, and we discover IJ. Then we have the edge  

35

00:04:26.400  -->  00:04:35.100
IJ, we add it, and we discover JF. Then we have 
the edge HJ, but both are in the mst, we skip.  

36

00:04:37.320  -->  00:04:45.360
Then we have the edge GI, but both are in the 
mst, we skip. Then we have the edge EF, F is  

37

00:04:45.360  -->  00:04:53.040
not in the mst, we take it and we discover no new 
edges. All vertices have been added to our mst,  

38

00:04:53.040  -->  00:05:00.420
so we stop here, useless to continue, we got our 
minimum spanning tree by using Prim's algorithm.  

39

00:05:03.000  -->  00:05:09.540
And this is the idea of Prim's algorithm, at the 
beginning we create a graph that will be our mst,  

40

00:05:09.540  -->  00:05:16.500
we select an arbitrary vertex, we add its edges 
to a list of available, then we start iterating.  

41

00:05:17.640  -->  00:05:24.060
While we didn't add all vertices to our mst, we 
select the edge (u,v) with the minimum weight  

42

00:05:24.060  -->  00:05:31.260
from the list of available edges, ones that 
we discovered before. If v, the destination,  

43

00:05:31.260  -->  00:05:37.260
is not in our mst, then we have an 
extension, we add the edge (u,v) to our mst.  

44

00:05:38.400  -->  00:05:43.560
And we traverse edges of the vertex v, 
if the neighbor z is not in our mst,  

45

00:05:43.560  -->  00:05:50.280
it means that we discovered a new edge, we add 
the edge (v,z) to our list of available edges.  

46

00:05:52.320  -->  00:05:59.520
After the loop, we return mst. You 
can notice that at each iteration,  

47

00:05:59.520  -->  00:06:05.640
we're choosing the smallest possible edge, it's 
what makes Prim's algorithm a greedy algorithm,  

48

00:06:05.640  -->  00:06:11.760
we're taking the best local choice at each 
iteration in hope to get the best global result.  

49

00:06:14.220  -->  00:06:19.920
You can understand this algorithm as a monster 
that starts as a single vertex, then it keeps  

50

00:06:19.920  -->  00:06:25.320
growing by always eating the shortest route 
that leads to vertices he didn't eat yet.  

51

00:06:28.800  -->  00:06:34.740
Okay now we know how Prim's algorithm works, 
but how to implement it? The crucial point  

52

00:06:34.740  -->  00:06:40.800
of implementing Prim's algorithm is the choice of 
the data structure we use for the available edges.  

53

00:06:41.940  -->  00:06:48.240
We need a structure capable of doing two 
things, inserting elements, in our case edges,  

54

00:06:48.240  -->  00:06:53.640
and extracting the element with the minimum 
value, in our case the minimum weight.  

55

00:06:56.280  -->  00:07:00.840
The perfect structure for this is 
the priority queue, it's a queue  

56

00:07:00.840  -->  00:07:05.880
where elements have a priority, and we can 
extract the element with the highest priority,  

57

00:07:05.880  -->  00:07:11.280
in our case the smallest weight, we 
worked with it in Dijkstra's algorithm.  

58

00:07:13.620  -->  00:07:19.020
But the priority queue is an abstract data 
type, we can have different implementations.  

59

00:07:21.180  -->  00:07:26.880
We've seen before in this course that using a 
sorted array is slow, it's better to use a heap.  

60

00:07:27.600  -->  00:07:33.600
Let's try with the binary heap. Let's implement 
the solution then move to time complexity.  

61

00:07:35.760  -->  00:07:41.940
We create a graph named mst, we create a binary 
heap available, it will store available edges,  

62

00:07:41.940  -->  00:07:50.220
and we choose an arbitrary vertex as start. Now 
we traverse neighbors of start to add edges to the  

63

00:07:50.220  -->  00:07:57.540
queue. For each edge from start to v with a weight 
w, we add the tuple (w, start, v) to the queue.  

64

00:07:58.080  -->  00:08:03.180
We've put w at the beginning because tuples 
are compared starting from their first element,  

65

00:08:03.180  -->  00:08:08.340
and because we want to compare edges with 
their weight, we put it as first element.  

66

00:08:10.500  -->  00:08:15.240
We also put u and v to know the incident 
vertices when extracting an edge.  

67

00:08:16.200  -->  00:08:23.460
Then while our mst doesn't contain all 
vertices, we keep looping. At each iteration,  

68

00:08:23.460  -->  00:08:30.600
we extract the edge with the smallest weight, 
and we put its elements in 3 variables w, u, v.  

69

00:08:32.160  -->  00:08:38.580
Now we take the edge into consideration only 
if it's doesn't connect 2 vertices that are  

70

00:08:38.580  -->  00:08:46.440
already in our mst, this is why we check that 
v is not in mst. If the condition is true,  

71

00:08:47.100  -->  00:08:53.880
we add the undirected edge to our mst, (v, w) 
to neighbors of u and (u, w) to neighbors of v.  

72

00:08:55.860  -->  00:09:02.700
Last thing to do, we need to traverse neighbors 
v. For each edge from v to z with a weight w,  

73

00:09:02.700  -->  00:09:08.760
if z is not in the mst, then we have a 
potential edge, we add it to the queue,  

74

00:09:08.760  -->  00:09:15.600
with the weight as the first element 
obviously. After the loop, we return the MST.  

75

00:09:18.360  -->  00:09:24.840
Let's measure its time complexity. Inserting 
an element in a binary heap is in O(logn) time.  

76

00:09:24.840  -->  00:09:31.620
Inserting n elements in the binary heap is in O(n) 
time not O(nlogn), we proved it in the YouTube  

77

00:09:31.620  -->  00:09:39.540
video I suggested in Dijkstra's algorithm lecture. 
And extracting an element costs O(logn) time.  

78

00:09:41.580  -->  00:09:47.340
Here we have at most |V| elements to insert 
at the beginning, neighbors of start vertex,  

79

00:09:47.340  -->  00:09:55.680
the cost is |V|. Then we have a loop that does 
at most |E| iterations, it's traversing edges.  

80

00:09:56.700  -->  00:10:04.200
Inside it we extract_min, O(logn) time, and here 
n is |E| because we store edges in the structure,  

81

00:10:04.200  -->  00:10:11.160
the cost is log|E|. We also have an 
inner loop that does deg(v) iterations,  

82

00:10:11.160  -->  00:10:15.060
where we insert an element, done in O(logn) time,  

83

00:10:17.220  -->  00:10:26.700
log|E| here. The sum of degrees is 2|E|, so 
in total we have |V| + |E|log|E| + 2|E|log|E|,  

84

00:10:30.600  -->  00:10:40.920
which is in O(|E|log|E|) time. We're dealing 
with a simple graph, so |E| is smaller or  

85

00:10:40.920  -->  00:10:48.360
equal than |V|². Which implies that log(|E|) <= 
log(|V|²), which implies that log|E| <= 2log|V|,  

86

00:10:56.280  -->  00:11:04.320
so we can replace log|E| by log|V|, we 
get an O(|E|log|V|) time complexity.  

87

00:11:07.980  -->  00:11:13.860
We can still optimize it. And for that, we will 
have a different approach for Prim's algorithm.  

88

00:11:14.460  -->  00:11:19.980
In the outer loop, we're extracting one edge 
at a time, this is why we can have at most  

89

00:11:19.980  -->  00:11:27.180
|E| iterations. In this new approach, instead 
of extracting edges, we will extract vertices,  

90

00:11:27.180  -->  00:11:33.480
so we will have at most |V| iterations, 
which is usually way smaller than |E|.  

91

00:11:35.160  -->  00:11:41.220
For edges, we were extracting the available 
edge with the smallest weight, but for vertices,  

92

00:11:41.220  -->  00:11:48.360
what vertex do we extract? We extract the 
vertex that requires the smallest cost to  

93

00:11:48.360  -->  00:11:54.840
go to from our actual minimum spanning 
tree. Let's try it with our previous  

94

00:11:54.840  -->  00:12:00.840
example. Here also we have an arbitrary 
vertex to start from, let's choose A.  

95

00:12:02.700  -->  00:12:08.820
To be sure that it will be selected, we set its 
cost to 0, and all remaining ones to infinity.  

96

00:12:10.920  -->  00:12:13.860
The algorithm starts, A gets selected.  

97

00:12:15.120  -->  00:12:22.140
Now we have A in our mst, and from here we have 
3 newly discovered edges that we can take to  

98

00:12:22.140  -->  00:12:29.280
connect more vertices. And these new edges may 
reduce the cost for some vertices, let's see.  

99

00:12:30.660  -->  00:12:37.800
We have the edge AB. The cost of B was infinity, 
but with this edge the cost is lower, it's 6,  

100

00:12:37.800  -->  00:12:44.340
so we decrease the cost of B to 6. We also 
have the edge AC. The cost of C was infinity,  

101

00:12:44.340  -->  00:12:52.560
but with this edge the cost is lower, it's 3, 
we decrease the cost of C to 3. And we have  

102

00:12:52.560  -->  00:12:59.400
the edge AF. The cost of F was infinity, but with 
this edge the cost is lower, it's 9, we decrease.  

103

00:13:01.440  -->  00:13:09.060
Next iteration, what is the cheapest vertex that 
is not in our mst? It's the vertex C, we go to it.  

104

00:13:10.860  -->  00:13:16.860
But wait, the hard thing when building the mst 
is not finding what vertices to include, because  

105

00:13:16.860  -->  00:13:23.100
they will all be included at the end anyway, the 
hard thing is to figure out what edges to include.  

106

00:13:23.640  -->  00:13:28.200
So here, we shouldn't just save 
C, we should save the edge (A,C).  

107

00:13:30.120  -->  00:13:35.940
When we were extracting edges, it was easy to do, 
we knew what were the source and the destination,  

108

00:13:35.940  -->  00:13:42.780
while here, we extracted the vertex C only, the 
destination. But how would we know the source,  

109

00:13:42.780  -->  00:13:48.000
how would we know that we should include the 
edge (A,C) and not (B,C) or (E,C) for example.  

110

00:13:49.020  -->  00:13:54.900
To fix this problem, in addition to the minimum 
cost of each vertex, we should also save its  

111

00:13:54.900  -->  00:14:01.920
parent, the vertex that decreased its cost. In 
this case, we should have saved A as the parent  

112

00:14:01.920  -->  00:14:09.120
of C, so that when we extract C, we know that we 
should include the edge (A,C). So when working,  

113

00:14:09.120  -->  00:14:15.780
every time a vertex u decreases the cost of a 
vertex v, we update by putting u as the parent  

114

00:14:15.780  -->  00:14:21.720
of v, so that when we extract v, we know that 
the edge we include should be the edge (u,v).  

115

00:14:23.760  -->  00:14:27.420
Let's start over by taking 
this detail into consideration.  

116

00:14:28.320  -->  00:14:34.500
At the beginning, all vertices parents are null, 
because we don't know even one way to go to them.  

117

00:14:35.760  -->  00:14:44.400
We start by extracting A. Edges it discovers 
are AB, AC, and AF. AB decreases the cost of B,  

118

00:14:44.400  -->  00:14:51.960
and we don't forget to set A as the parent of B. 
Then same thing for AC. And same thing for AF.  

119

00:14:54.240  -->  00:15:00.180
Next iteration, cheapest vertex is C. And 
here, we know that the vertex who gave it  

120

00:15:00.180  -->  00:15:09.360
the cheapest cost was A, so we add the edge 
(A,C). Then C discovers new edges, CB, CD,  

121

00:15:09.360  -->  00:15:16.740
CE, and CF, let's see if they decrease 
costs of some vertices. The weight of CB  

122

00:15:16.740  -->  00:15:23.940
is 4 while the actual cost of B is 6, so it gets 
decreased to 4, and we set C as the parent of B.  

123

00:15:25.320  -->  00:15:31.980
It means that before, the minimum cost to make 
a connection from our mst to B was 6, but now,  

124

00:15:31.980  -->  00:15:38.880
we found a cheaper way for connecting it, with a 
cost of 4 instead of 6, this is why we decreased.  

125

00:15:41.280  -->  00:15:48.480
CD, cost is 2 while cost of D is infinity, it 
surely decreases, we also set C as the parent  

126

00:15:48.480  -->  00:15:57.360
of D. CE, cost is 9 while cost of E is infinity, 
it surely decreases, C becomes the parent of E.  

127

00:15:58.080  -->  00:16:03.540
And CF, cost is 9 while cost of 
F is already 9, nothing changes.  

128

00:16:06.060  -->  00:16:11.880
Next iteration, the cheapest vertex is 
D, with a cost of 2, and its parent is C,  

129

00:16:11.880  -->  00:16:21.960
we include the edge (C,D). We discover DB, 
DG, and DE. DB, it decreases the cost to 2,  

130

00:16:21.960  -->  00:16:30.660
D becomes the parent of B. DG, it decreases 
the cost to 9. DE, it decreases the cost to 8.  

131

00:16:33.360  -->  00:16:39.780
Next vertex to extract is B. By the way, 
when I'm showing an example in detail to  

132

00:16:39.780  -->  00:16:43.800
see how the algorithm works, as soon as 
you think that you understood the process,  

133

00:16:43.800  -->  00:16:49.680
try to pause the video and continue the example 
by yourself, to see if you really understood,  

134

00:16:49.680  -->  00:16:54.960
you can also start writing code before 
you see the one presented in the lecture.  

135

00:16:57.480  -->  00:17:06.930
We said that next vertex to extract is B. It 
has edges BA, BC, BD, and BG. But we ignore BA  

136

00:17:06.930  -->  00:17:14.220
BC and BD because all destinations are already 
visited. For BG, it doesn't decrease the cost.  

137

00:17:16.020  -->  00:17:26.580
Next extracted vertex is E. New edges are EG, EI, 
EJ, and EF. EG, it decreases the cost to 7. EI,  

138

00:17:26.580  -->  00:17:34.380
it decreases the cost to 9. EJ, it decreases the 
cost to 10. And EF, it decreases the cost to 8.  

139

00:17:36.420  -->  00:17:45.120
Next extracted vertex is G, it has the lowest cost 
among remaining vertices. It discovers GH and GI.  

140

00:17:45.780  -->  00:17:54.360
GH, it decreases the cost to 4. GI, it decreases 
the cost to 5. Then we have the vertex H,  

141

00:17:54.360  -->  00:18:03.300
it discovers HI and HJ. HI, it decreases the 
cost to 1. And HJ, it decreases the cost to 4.  

142

00:18:05.040  -->  00:18:12.240
Next vertex is I, it discovers IJ, it decreases 
the cost of J to 3, and it becomes its parent.  

143

00:18:13.500  -->  00:18:18.540
Next vertex is J, it discovers JF, 
but it doesn't decrease its cost.  

144

00:18:19.440  -->  00:18:26.700
And last vertex is F, with a cost of 8, its 
parent is E, we add in MST the edge (E, F).  

145

00:18:27.480  -->  00:18:32.760
And we got our mst by extracting 
vertices instead of edges.  

146

00:18:35.580  -->  00:18:41.400
Okay we've seen an example, but we need some 
pseudocode to understand. We create our mst,  

147

00:18:41.400  -->  00:18:47.820
our available structure, our start vertex, and 
now we need to put our vertices in available.  

148

00:18:49.140  -->  00:18:55.080
For each one of them, we set its cost to 
0 if it's the start vertex, else infinity,  

149

00:18:55.080  -->  00:19:01.620
as we did at the beginning. We set its parent 
to null, and we insert it in available.  

150

00:19:03.060  -->  00:19:09.360
We can start, while we didn't make the full mst, 
we extract the vertex with the minimum cost.  

151

00:19:10.380  -->  00:19:16.020
If it's the start vertex, there's no edge 
to add, we still don't have an edge to add.  

152

00:19:17.400  -->  00:19:21.900
But if it's not the case, we add the 
edge from the parent of u to u itself,  

153

00:19:21.900  -->  00:19:30.780
for example C had A as a parent when extracted, so 
we added the edge (A,C). This is why we get a tree  

154

00:19:30.780  -->  00:19:38.220
of |V|-1 vertices, the -1 comes from the fact that 
start vertex doesn't need an edge to include it.  

155

00:19:40.560  -->  00:19:43.920
Let's continue. Now we need to traverse neighbors  

156

00:19:43.920  -->  00:19:48.180
of u to see if it decreases their 
cost, by checking weights of edges.  

157

00:19:49.800  -->  00:19:56.820
For each edge from u to v with a weight of w, 
we check two conditions. If v is not in the mst  

158

00:19:56.820  -->  00:20:03.720
yet and w is smaller than its actual cost, then 
we found a cheaper way to go to v, we go to it  

159

00:20:03.720  -->  00:20:10.380
from the actual vertex u, this is why the cost 
of v becomes w, and the parent of v becomes u.  

160

00:20:12.120  -->  00:20:18.420
Also, because the key of v changed, which is 
its cost, we need to update it in the heap,  

161

00:20:18.420  -->  00:20:24.600
with the decrease key function. 
After the loop, we return mst.  

162

00:20:26.040  -->  00:20:30.300
This Prim's algorithm approach kinda 
reminds us of Dijkstra's algorithm.  

163

00:20:32.340  -->  00:20:38.280
What about the implementation? Let's 
keep our choice: using a binary heap.  

164

00:20:38.280  -->  00:20:44.400
But wait, without even implementing, just by 
analyzing the pseudocode, we can notice a problem.  

165

00:20:45.240  -->  00:20:51.300
Remember that the binary heap has a time 
complexity of O(logn) for decrease key operation.  

166

00:20:52.320  -->  00:20:57.540
We have |V| to build the heap, then a 
loop that does |V| iterations this time,  

167

00:20:58.260  -->  00:21:03.240
extract min costs log|V| because 
we have at most |V| vertices.  

168

00:21:04.200  -->  00:21:10.020
We also have a loop that does deg(u) 
iterations, inside it we're decreasing  

169

00:21:10.020  -->  00:21:17.160
the key of a node in the heap, which costs 
O(logn) as mentioned earlier, here n is |V|.  

170

00:21:19.020  -->  00:21:23.820
The sum of degrees is 2|E|, so in 
total we get |V|+|V|log|V|+2|E|log|V|,  

171

00:21:29.580  -->  00:21:34.800
which is in O(|E|log|V|) time, 
same as the previous approach.  

172

00:21:38.040  -->  00:21:41.100
With a binary heap, we get 
the same time complexity,  

173

00:21:41.100  -->  00:21:45.360
but to get a better time complexity, 
we will implement the priority queue  

174

00:21:45.360  -->  00:21:50.520
with another data structure that we've seen 
before in this course: the Fibonacci heap.  

175

00:21:52.800  -->  00:21:59.520
Building a Fibonacci heap of n elements is in 
O(n) time. Inserting an element is in O(1) time.  

176

00:21:59.520  -->  00:22:06.780
Extracting minimum is in O(logn) time amortized. 
And decrease key is in O(1) time amortized.  

177

00:22:08.340  -->  00:22:14.640
This is why we get, as you can see, a 
time complexity of O(|E|+|V|log|V|).  

178

00:22:19.920  -->  00:22:27.180
Let's move to the implementation, and we will the 
use fibheap Python module. You will see that the  

179

00:22:27.180  -->  00:22:32.520
code will look like the one we wrote to implement 
Dijkstra's algorithm with a Fibonacci heap.  

180

00:22:33.540  -->  00:22:40.200
We create mst, we create our start vertex, 
we create cost map, we create parent map, we  

181

00:22:40.200  -->  00:22:46.080
create nodes map to map each vertex label to its 
node in the heap, and we create a Fibonacci heap.  

182

00:22:47.580  -->  00:22:53.040
Now for each vertex u, we need to initialize 
its information in cost and parent,  

183

00:22:53.040  -->  00:23:01.080
and create its node. So we start by calculating 
the cost, 0 if u is start, else infinity,  

184

00:23:02.100  -->  00:23:08.400
we assign the result to cost[u]. 
We also set parent[u] to null.  

185

00:23:09.360  -->  00:23:15.720
We also create a node whose key is the tuple 
(cost[u], u), same logic as for Dijkstra's,  

186

00:23:15.720  -->  00:23:22.140
cost[u] at the beginning to compare and u to know 
what vertex we're working with when extracting.  

187

00:23:25.440  -->  00:23:32.460
We assign it to nodes[u], and we put it in 
our Fibonacci heap. Now we can start working.  

188

00:23:33.600  -->  00:23:39.900
While we didn't make the full mst, in other words, 
while we still have vertices not in the mst,  

189

00:23:39.900  -->  00:23:46.680
we extract a node. To get the label of its 
associated vertex, we can find it in the  

190

00:23:46.680  -->  00:23:54.540
second element of its key, remember that its key 
is the tuple (cost[u], u). Then if u is not start,  

191

00:23:54.540  -->  00:23:59.940
we insert the edge between u and its parent, 
by keeping its weight, which is cost[u].  

192

00:24:00.840  -->  00:24:07.680
For that we add (parent[u], cost[u]) to neighbors 
of u and (u, cost[u]) to neighbors of parent[u].  

193

00:24:09.660  -->  00:24:16.260
Last step, we traverse neighbors to see if it 
decreases cost. For each edge from u to v and with  

194

00:24:16.260  -->  00:24:24.240
a weight w, if v isn't included in the mst yet and 
w is smaller than the actual cost of v, we update.  

195

00:24:24.900  -->  00:24:32.580
We update by assigning w to cost[v], assigning u 
to parent[v], and decreasing the key of the vertex  

196

00:24:32.580  -->  00:24:40.560
v, by putting the tuple (cost[v], v), again, 
cost for comparing and v for knowing what vertex.  

197

00:24:42.840  -->  00:24:47.460
You can see that in decrease_key we passed 
the node associated with the label v.  

198

00:24:49.620  -->  00:24:56.460
After the loop, we return mst. And we 
implemented Prim's algorithm by using a  

199

00:24:56.460  -->  00:25:05.280
Fibonacci heap, which gives a time complexity of 
O(|E|+|V|log|V|), better than what we got before.  

200

00:25:07.140  -->  00:25:15.180
Especially if the graph is dense, where |E| is 
much higher than |V|. We've reached the end of  

201

00:25:15.180  -->  00:25:19.260
this lecture, I hope that you now understand 
Prim's algorithm and its implementation.  

202

00:25:19.260  -->  00:25:25.200
See you in the next lecture to discuss 
another MST algorithm: Kruskal's algorithm.
