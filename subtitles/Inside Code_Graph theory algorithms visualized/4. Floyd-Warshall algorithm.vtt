WEBVTT
1

00:00:00.120  -->  00:00:05.160
In the two previous lectures, we discussed 
algorithms that solve the single-source  

2

00:00:05.160  -->  00:00:10.980
shortest path problem, but what if we wanted the 
shortest path from each vertex to each vertex.  

3

00:00:12.000  -->  00:00:17.880
In other words, the shortest path from u to v 
for each pair of vertices (u, v) in the graph.  

4

00:00:18.600  -->  00:00:22.080
Such a problem is called: The 
all-pairs shortest path problem.  

5

00:00:23.580  -->  00:00:29.460
How to solve this problem? Knowing that 
we want to still get the optimal result  

6

00:00:29.460  -->  00:00:33.960
when there are negative edges, unless 
there is a negative cycle obviously.  

7

00:00:35.160  -->  00:00:41.760
Currently, we know how to get the shortest path 
from a single vertex to any vertex v, by using  

8

00:00:41.760  -->  00:00:47.220
the Bellman-Ford algorithm. So we may think, 
why don't we just call Bellman-Ford starting  

9

00:00:47.220  -->  00:00:53.880
from each vertex and we get what we're searching 
for? This solution works, yes, it's a valid one.  

10

00:00:54.480  -->  00:01:01.620
For the time complexity, Bellman-Ford is in 
O(|V||E|) time, and we're calling it |V| times,  

11

00:01:01.620  -->  00:01:09.840
once on each vertex, so we multiply, we 
get a time complexity of O(|V|Â²+|V||E|).  

12

00:01:12.780  -->  00:01:18.480
However, it's not the most optimized 
solution, we have more efficient algorithms,  

13

00:01:18.480  -->  00:01:22.800
like the one we will see in this 
lecture: The Floyd-Warshall algorithm.  

14

00:01:24.240  -->  00:01:30.420
Okay, imagine that going directly from your house 
to your school is 50 meters. Then you notice  

15

00:01:30.420  -->  00:01:35.580
that going from your house to the supermarket 
then from the supermarket to your school has a  

16

00:01:35.580  -->  00:01:43.800
total of distance of 35. Here you found a shorter 
path by using intermediate vertices. In general,  

17

00:01:43.800  -->  00:01:51.000
to go from a vertex u to a vertex v, passing by an 
intermediate vertex z can give a shorter path than  

18

00:01:51.000  -->  00:01:57.900
directly taking the edge from u to v. And it's the 
idea Floyd-Warshall algorithm uses, to calculate  

19

00:01:57.900  -->  00:02:03.000
the shortest path from u to v, we start by 
considering the edge (u, v) as the shortest path,  

20

00:02:03.000  -->  00:02:09.060
then we keep discovering shorter and shorter 
paths by setting other vertices as intermediates.  

21

00:02:11.880  -->  00:02:17.160
The Floyd-Warshall algorithm is based on two 
things: This principle of intermediate vertices,  

22

00:02:17.160  -->  00:02:24.360
and dynamic programming. In Bellman-Ford, we found 
a recurrence relation, we implemented it with a  

23

00:02:24.360  -->  00:02:30.120
recursive function, that we later optimized 
with dynamic programming. In Floyd-Warshall,  

24

00:02:30.120  -->  00:02:35.160
same thing, we will discover a recurrence relation 
that calculates the shortest path from u to v,  

25

00:02:35.160  -->  00:02:40.440
we implement it with a recursive function, 
then we optimize it with dynamic programming.  

26

00:02:41.940  -->  00:02:50.220
Let's start. Imagine that we have this graph. 
Let's first define some notation. We have the  

27

00:02:50.220  -->  00:02:58.140
array of vertices of the graph, each one of them 
has an index. A is 0, B is 1...etcetera. We define  

28

00:02:58.140  -->  00:03:04.680
dij as the shortest distance from the vertex 
whose index is i to the vertex whose index is j.  

29

00:03:04.680  -->  00:03:11.880
For example the shortest distance from A to B 
would be denoted d01, because A's index is 0 and  

30

00:03:11.880  -->  00:03:20.040
B's index is 1. Also, we have an extra variable 
k in superscript, it's an indicator that tells us  

31

00:03:20.040  -->  00:03:29.160
that we're allowed to use the vertices {0, 1, 2, 
..., k} as intermediates. For example if k = 3,  

32

00:03:29.160  -->  00:03:35.940
then we can use vertices ABCD as intermediates. 
You will better understand with an example.  

33

00:03:37.920  -->  00:03:43.320
Let's say we want to calculate the shortest 
distance from A to B, we want to calculate d01.  

34

00:03:43.860  -->  00:03:48.360
At the beginning, we don't allow any 
vertex to be an intermediate vertex,  

35

00:03:48.360  -->  00:03:57.120
we want the value of d01^(-1). When we cannot 
use an intermediate vertex, we have no choice  

36

00:03:57.120  -->  00:04:04.740
except taking the direct edge from i to j, if it 
exists obviously. Here it exists, and it has a  

37

00:04:04.740  -->  00:04:11.400
weight of 18, so by not using an intermediate 
vertex, we get a shortest path of length 18.  

38

00:04:13.740  -->  00:04:19.380
Now k becomes 0, so we allow the first 
vertex, A, to be an intermediate vertex.  

39

00:04:20.640  -->  00:04:27.180
Now we have two choices: Either keeping our 
current shortest path, A to B, or set A as an  

40

00:04:27.180  -->  00:04:34.140
intermediate, we first go from A to A, then from A 
to B. Obviously, we will choose the shortest one.  

41

00:04:35.580  -->  00:04:39.960
Well, going from a vertex to itself 
has always a shortest length of 0,  

42

00:04:39.960  -->  00:04:45.180
so it doesn't decrease our shortest distance as 
you can see, we can just keep the current one.  

43

00:04:47.760  -->  00:04:53.640
Now let's set k to 1, we can use the first 
two vertices, A and B, as intermediates.  

44

00:04:54.420  -->  00:05:02.220
If we put B, we get a new path to try, from A to 
B then from B to B. Same thing here, we have a  

45

00:05:02.220  -->  00:05:09.840
vertex going to itself, 0, we get the same result. 
In general, if we're searching for the shortest  

46

00:05:09.840  -->  00:05:15.960
distance from i to j, putting one of them as 
the intermediate vertex is useless. This is why,  

47

00:05:15.960  -->  00:05:25.200
we can say that dik^(k) is equal to dik^(k-1), in 
other words, when searching for the shortest path  

48

00:05:25.200  -->  00:05:31.260
with k as the destination, it's useless to put 
k as an intermediate vertex, it will give the  

49

00:05:31.260  -->  00:05:38.400
same result as when we had one less allowed 
vertex, dik^(k-1), this is why they're equal.  

50

00:05:40.680  -->  00:05:45.540
Same thing for when k is the source, it's 
useless to put it as an intermediate,  

51

00:05:45.540  -->  00:05:54.720
this is why dkj^(k) is equal to dkj^(k-1). 
You really need to understand these.  

52

00:05:58.440  -->  00:06:02.760
Let's continue. k = 2, we 
put C as the intermediate,  

53

00:06:04.080  -->  00:06:11.400
now things start getting interesting. So we have 
two choices, either keeping the current best path,  

54

00:06:11.400  -->  00:06:16.680
or taking the shortest path from A to C, 
then taking the shortest path from C to B.  

55

00:06:17.460  -->  00:06:22.500
The shortest path from A to C is to 
directly take the edge (A, C), we get  

56

00:06:22.500  -->  00:06:27.660
-4. And from C to B, directly 
take the edge (C, B), we get 16.  

57

00:06:28.560  -->  00:06:34.980
The sum is 12, so we found a shorter path than 
the one we had, by using C as an intermediate.  

58

00:06:38.820  -->  00:06:47.460
Let's move to k = 3, we put D as an intermediate. 
The shortest path from A to D is A-C-D, length is  

59

00:06:47.460  -->  00:06:55.620
10. And from D to B is the path D-B, 6. The sum 
is 16, our current path is better, we keep it.  

60

00:06:57.000  -->  00:07:03.240
Now you may tell me, you're wrong, the shortest 
path from A to D is actually A-C-E-D, which has a  

61

00:07:03.240  -->  00:07:08.760
total weight of -1, which would give us a path 
from A to B of 5, better than the actual one.  

62

00:07:09.480  -->  00:07:16.980
Yes, but, remember that k is 3, we can only use 
the vertices {0, 1, 2, 3} as intermediates, ABCD,  

63

00:07:16.980  -->  00:07:25.440
not E. But what if, because of this restriction, 
we miss a shorter path? Don't worry, it doesn't  

64

00:07:25.440  -->  00:07:31.740
happen, because the shorter path that includes 
E, A-C-E-D, will appear in the next iteration,  

65

00:07:31.740  -->  00:07:40.500
when E will be the intermediate. What are we doing 
in this iteration? We are searching for the value  

66

00:07:40.500  -->  00:07:48.120
of d01^(3), the shortest distance from A to B 
that we get by allowing the vertices {0, 1, 2,  

67

00:07:48.120  -->  00:07:54.660
3} to be intermediate vertices. To calculate its 
value, we're comparing the length of two paths:  

68

00:07:54.660  -->  00:08:00.660
The first one is the current shortest path, the 
one we already had even without allowing the  

69

00:08:00.660  -->  00:08:10.620
new vertex, the one of the previous iteration, 
its weight is d01^(2). And the second path is  

70

00:08:10.620  -->  00:08:16.440
the one we get by putting the newly allowed 
vertex, the vertex k, D, as intermediate.  

71

00:08:17.280  -->  00:08:22.920
Its weight is the sum of the shortest path 
from A to D, + the shortest path from D to B.  

72

00:08:23.760  -->  00:08:29.820
But, as said earlier, these two shortest paths 
are the one we get by allowing the vertices {0,  

73

00:08:29.820  -->  00:08:35.520
1, 2, ..., k} only, this is why we didn't 
take the path that contains E for example,  

74

00:08:35.520  -->  00:08:41.580
even if it was shorter. This is why we 
express the restriction with superscript,  

75

00:08:42.120  -->  00:08:47.640
the shortest distance from A to D by 
allowing vertices {A, B, C, D} is d03^(3).  

76

00:08:50.280  -->  00:08:55.860
And the shortest distance from D to B by 
allowing vertices {A, B, C, D} is d31^(3).  

77

00:08:59.220  -->  00:09:03.540
We have these two distances, and because 
we're searching for the shortest one,  

78

00:09:03.540  -->  00:09:10.920
we take the minimum. Okay let's continue, 
let's move to k = 4, now we allow E.  

79

00:09:11.520  -->  00:09:17.340
We want to have the value of d01^(4), so we 
will compare the current shortest distance,  

80

00:09:17.340  -->  00:09:26.400
d01^(3), and the one we get by putting 
E as an intermediate, d04^(4) + d41^(4).  

81

00:09:29.340  -->  00:09:34.080
The shortest distance from A to E is 
-6, that we get with the path A-C-E.  

82

00:09:34.080  -->  00:09:39.660
And the shortest distance from E to B 
is 11, that we get with the path E-D-B.  

83

00:09:40.260  -->  00:09:48.720
The sum is 5, smaller than 12, we found a shorter 
path to go from A to B, it's A-C-E-D-B. And as  

84

00:09:48.720  -->  00:09:55.080
you can see, we have A-C-E-D, we didn't lose it, I 
told you that we fill find in the next iteration,  

85

00:09:55.080  -->  00:10:02.160
this is why when we set k as an intermediate, 
we work with vertices {0, 1, 2, ..., k} only,  

86

00:10:02.160  -->  00:10:07.500
we don't worry about ones higher than k 
because we will find them in next iterations.  

87

00:10:10.920  -->  00:10:16.920
Here is what we calculated at each value of 
k. When k is -1, we were not allowed to have  

88

00:10:16.920  -->  00:10:22.440
intermediate vertices at all, so we directly 
took the value of the direct edge from A to B,  

89

00:10:22.440  -->  00:10:29.940
whose weight is represented by w01. 
And for greater values, to get d01^(k),  

90

00:10:30.840  -->  00:10:36.660
we were always comparing between two values: The 
shortest distance with the previous value of k,  

91

00:10:36.660  -->  00:10:43.860
d01^(k-1), and the shortest distance 
by putting k as an intermediate vertex.  

92

00:10:44.460  -->  00:10:50.520
To get the second one, we do the sum of the 
shortest distance from 0 to k by using vertices  

93

00:10:50.520  -->  00:11:00.240
0 to k, d0k^(k), + the shortest distance from 
k to 1 by using vertices from 0 to k, dk1^(k).  

94

00:11:03.240  -->  00:11:12.300
In brief, the value of d01^(k) is w01 if 
k = -1, else it's min between d01^(k-1),  

95

00:11:13.560  -->  00:11:24.240
and d0k^(k) + dk1^(k). Here we were calculating 
the shortest distance from 0 to 1, from A to B,  

96

00:11:24.240  -->  00:11:33.960
this is why we wrote d01, but this formula is 
valid for any pair (i, j). So dij^(k) is equal  

97

00:11:33.960  -->  00:11:49.560
to wij if k = -1, and min between dij^(k-1) and 
dik^(k) + dkj^(k) otherwise. wij is 0 if i is  

98

00:11:49.560  -->  00:11:55.380
equal to j, else the weight of the edge from 
i to j if it exists, and infinity otherwise.  

99

00:11:57.840  -->  00:12:02.220
And earlier we said that dik^(k) is equal to 
dik^(k-1), and dkj^(k) is equal to dkj^(k-1),  

100

00:12:09.960  -->  00:12:13.680
we replace, and we get this 
nice recurrence relation.  

101

00:12:18.240  -->  00:12:25.080
In some other resources you will find k=0 instead 
of -1, it's because it depends on if we use  

102

00:12:25.080  -->  00:12:33.480
0-indexing or 1-indexing. If we use 0-indexing, 
as we did here, the base case is k = -1. And if  

103

00:12:33.480  -->  00:12:38.760
it's 1-indexing, as it's the case in a lot 
of resources, the base case is when k = 0.  

104

00:12:42.180  -->  00:12:50.340
Let's add a quick example, we want to calculate 
the shortest distance from A to D, d03. d03^(-1)  

105

00:12:51.240  -->  00:13:01.800
is w03, which is infinity because we don't have a 
direct edge from A to D. d03^(0) is min(d03^(-1),  

106

00:13:03.780  -->  00:13:22.320
d00^(-1)+d03^(-1)), we still get infinity. d03^(1) 
is min(d03^(0), d01^(0)+d13^(0)), we get infinity.  

107

00:13:24.420  -->  00:13:33.960
d03^(2) is min(d03^(1), d02^(1)+d23^(1)), we get 
10. d03^(3) is min(d03^(2), d03^(2)+d33^(2)), we  

108

00:13:33.960  -->  00:13:59.160
get 10. d03^(4) is min(d03^(3), d04^(3)+d43^(3)), 
we get -1, we found a shorter path.  

109

00:14:00.420  -->  00:14:05.880
We cannot go beyond k=4, so the 
shortest distance from A to D is -1.  

110

00:14:11.340  -->  00:14:17.400
Let's convert this recurrence relation to code. 
We need the adjacency matrix, to easily know the  

111

00:14:17.400  -->  00:14:27.900
value of wij. We also need i j and k. If k == -1, 
we return adj_mat[i][j], which represents wij.  

112

00:14:28.560  -->  00:14:36.780
Else, we return min between d(i, j, k-1) 
and d(i, k, k-1)+d(k, j, k-1). That's it.  

113

00:14:39.120  -->  00:14:43.860
Okay but how to solve our initial problem, 
the all pairs shortest path problem.  

114

00:14:45.180  -->  00:14:50.400
We have an adjacency list graph. We start 
by creating a mapping between each vertex  

115

00:14:50.400  -->  00:14:57.420
and its index, as we did in the example, A 
was 0, B was 1...etcetera, it's important to  

116

00:14:57.420  -->  00:15:03.660
work with the adjacency matrix and later the dp 
table. For that we compute the list of vertices,  

117

00:15:03.660  -->  00:15:11.340
and for each index i, we assign i to the vertex 
at index i. Then we convert the adjacency list  

118

00:15:11.340  -->  00:15:17.280
to an adjacency matrix by creating an n by 
n matrix with infinity as a default value.  

119

00:15:18.180  -->  00:15:22.260
Then for each edge (u, v, w), we put 
w in the cell mat[idx[u]][idx[v]].  

120

00:15:26.820  -->  00:15:32.040
We also put zeros for cells from a vertex 
to itself, because even if we may not have  

121

00:15:32.040  -->  00:15:38.340
an edge from u to itself, the shortest distance 
from u to itself is 0, by not taking any edge.  

122

00:15:39.780  -->  00:15:42.420
Now adj_mat[i][j] represents wij.  

123

00:15:46.380  -->  00:15:53.400
You need to know that as a result, we want a table 
dist of size n by n where dist[i][j] represents  

124

00:15:53.400  -->  00:15:59.700
the shortest distance from the vertex whose index 
is i to the vertex whose index is j. We create it,  

125

00:15:59.700  -->  00:16:06.420
then to fill it, we use our recursive 
function. For each cell (i, j), we want dij.  

126

00:16:07.620  -->  00:16:15.000
We want dij by allowing all vertices, so the 
initial value of k is n-1, the index of the  

127

00:16:15.000  -->  00:16:25.680
last vertex. This is why we assign d(i, j, n-1) 
to dist[i][j]. We got our dist table, we return  

128

00:16:25.680  -->  00:16:30.960
it along with idx map to be able to recognize 
what vertex each row and column represent.  

129

00:16:33.180  -->  00:16:37.680
Now we can know the shortest distance 
from any vertex to any vertex,  

130

00:16:37.680  -->  00:16:42.900
for example if we want the shortest 
distance from C to B, index of C is 2,  

131

00:16:42.900  -->  00:16:50.400
index of B is 1, so we read dist[2][1], which 
is 9, the shortest distance from C to B is 9.  

132

00:16:54.660  -->  00:17:00.780
Before we move further, you may ask yourself why 
do we need k in the first place? Why do we allow  

133

00:17:00.780  -->  00:17:07.800
0 then 1 then 2 vertices and so on? Why don't we 
just directly calculate by allowing all vertices?  

134

00:17:08.700  -->  00:17:15.420
Well, imagine that you want to directly get the 
global shortest distance from A to B. It can be by  

135

00:17:15.420  -->  00:17:21.720
going directly from A to B, going from A to C then 
from C to B, going from A to D then from D to B,  

136

00:17:21.720  -->  00:17:29.340
and so on. Imagine that you want to evaluate this 
possibility, going from A to C then from C to B.  

137

00:17:29.340  -->  00:17:34.620
For that, you need the shortest distance from 
A to C, and the shortest distance from C to B.  

138

00:17:35.760  -->  00:17:40.320
And the shortest distance from A to C 
can be: Taking the edge from A to C,  

139

00:17:40.320  -->  00:17:47.700
going from A to B then from B to C, and so on. As 
you can see, we have mutually dependent values,  

140

00:17:47.700  -->  00:17:56.520
to calculate dAB we need dAC, and to calculate dAC 
we need dAB. This is why we cannot do it directly,  

141

00:17:56.520  -->  00:18:04.500
we need to build shortest paths incrementally, 
first with k = -1, then 0, then 1, and so on.  

142

00:18:07.920  -->  00:18:13.890
Okay the solution we made now works, however, 
if we draw the recursion tree of calling d(0, 1,  

143

00:18:13.890  -->  00:18:19.920
4) for example, we can see a lot of repeated 
recursive calls, same as in Bellman-Ford.  

144

00:18:21.360  -->  00:18:27.780
What to do then? Dynamic programming. 
To avoid repeated work, we use dynamic  

145

00:18:27.780  -->  00:18:32.580
programming, its bottom-up approach to be 
specific, the one where we build a table.  

146

00:18:33.960  -->  00:18:39.780
Here we have 3 changing parameters: i, 
j, and k, so we will have a 3D table.  

147

00:18:40.740  -->  00:18:48.540
i has n possible values, because it represents 
a vertex and we have n vertices. j, same thing,  

148

00:18:48.540  -->  00:18:57.540
n possible values. And for k, it has n+1 
possible values: -1, 0, 1, until the last  

149

00:18:57.540  -->  00:19:06.240
vertex, whose assigned index is n-1. So we 
will have a 3D table of shape (n+1, n, n).  

150

00:19:07.860  -->  00:19:13.320
Why did I put k in the first dimension? 
It's because to calculate dij for a value k,  

151

00:19:13.320  -->  00:19:19.440
we need distances dij for the value 
k-1, ones with the previous value of k.  

152

00:19:21.720  -->  00:19:29.100
This is why we put k as the first dimension, to 
have all values dij^(-1) in the first iteration,  

153

00:19:29.100  -->  00:19:34.680
then we use them to calculate all 
values dij^(0) in the second iteration,  

154

00:19:34.680  -->  00:19:41.760
then we use them to calculate all values 
dij^(1) in the third iteration, and so on.  

155

00:19:43.740  -->  00:19:50.940
We will see an example don't worry, let's just 
finish making our solution. A 3D table is hard to  

156

00:19:50.940  -->  00:19:57.720
visualize, especially if we want to see all the 
values, so instead, we will show the 2D tables  

157

00:19:57.720  -->  00:20:04.200
that are inside individually, because as you may 
know, a 3D array is just an array of 2D arrays.  

158

00:20:05.340  -->  00:20:12.060
For this example, here is the table with k 
= -1, then the one with k = 0, and so on.  

159

00:20:13.680  -->  00:20:19.320
The table with k = -1 is in reality 
just the updated adjacency matrix,  

160

00:20:19.320  -->  00:20:26.160
so we can create a table of size n instead of n+1 
and use adj_mat when we need values of dij^(-1).  

161

00:20:30.720  -->  00:20:33.360
We made the table, now we need to fill it.  

162

00:20:35.160  -->  00:20:43.800
From the recurrence relation, when k = -1, dij^(k) 
is just wij, that we can get from the updated  

163

00:20:43.800  -->  00:20:51.360
adjacency matrix. Then for remaining values of k, 
for each one of them, we traverse couples of cells  

164

00:20:54.240  -->  00:21:00.640
(i, j) of dp[k]. dp[k][i][j] represents dij^(k), 
and from the relation we know that dij^(k) is  

165

00:21:00.640  -->  00:21:02.580
equal to min(dij^(k-1), dik^(k-1)+dkj^(k-1)). 
So dp[k][i][j] is equal to min(dp[k-1][i][j],  

166

00:21:10.920  -->  00:21:25.200
dp[k-1][i][k]+dp[k-1][k][j]), as simple 
as that. Exception made when k is 0,  

167

00:21:25.200  -->  00:21:32.340
because there is no previous row k-1, we use the 
adjacency matrix, which contains values dij^(-1).  

168

00:21:36.300  -->  00:21:42.060
We filled the table, we return its last element, 
which is the table that contains values dij^(n-1),  

169

00:21:43.140  -->  00:21:49.020
along with idx map, and we optimized 
the solution with dynamic programming.  

170

00:21:51.600  -->  00:21:57.840
We still have some things to modify however. 
Same as with Bellman-Ford, we can get rid of 1  

171

00:21:57.840  -->  00:22:04.860
dimension, the first one, the result will stay the 
same. This is why instead of using a 3D table, we  

172

00:22:04.860  -->  00:22:10.980
will just use a single table of shape (n, n) that 
we will keep updating. The meaning of dp[i][j]  

173

00:22:10.980  -->  00:22:18.540
slightly changes but we still get the same result. 
dp starts with values of adj_mat because they  

174

00:22:18.540  -->  00:22:26.760
represent values when k = -1, then we get values 
of the next value of k at each iteration. Also,  

175

00:22:26.760  -->  00:22:32.580
here the adjacency matrix can be removed, instead 
of creating and filling the updated adjacency  

176

00:22:32.580  -->  00:22:40.200
matrix then copying it to dp, we can just directly 
fill dp. So we create dp, a table of size n by n,  

177

00:22:40.200  -->  00:22:47.760
and we initially fill it with values wij. For each 
edge (u, v, w), we assign w to dp[idx[u][idx[v]].  

178

00:22:51.480  -->  00:22:57.000
And we assign 0 for values of the diagonal, 
because distance from u to u is 0.  

179

00:22:58.020  -->  00:23:03.840
Now with remaining values of k, we just 
update values of dp[i][j] with the formula.  

180

00:23:06.420  -->  00:23:13.320
We can rename dp to dist by the way, dist means 
distance. And we can also turn this min function  

181

00:23:13.320  -->  00:23:20.640
into a condition, if dp[i][k]+dp[k][j] is smaller 
than dp[i][j], dp[i][j] becomes dp[i][k]+dp[k][j].  

182

00:23:24.360  -->  00:23:29.760
Last thing, with things being like that, we 
just have the distance, not the path itself,  

183

00:23:29.760  -->  00:23:34.800
let's fix that. For that, we need 
to introduce path reconstruction.  

184

00:23:36.600  -->  00:23:41.220
In Dijkstra's algorithm and Bellman-Ford 
algorithm, we were using prev table,  

185

00:23:41.220  -->  00:23:46.920
a 1D table where prev[v] represents the 
vertex just before v in the shortest path  

186

00:23:46.920  -->  00:23:52.680
from source to v. In Floyd-Warshall, we will 
use the opposite, we will use a table next,  

187

00:23:52.680  -->  00:23:59.580
it's a 2D table where nxt[i][j] represents the 
vertex just after ith vertex in the shortest path  

188

00:23:59.580  -->  00:24:05.520
from ith vertex to jth vertex, it's more adapted 
for the way Floyd-Warshall algorithm works.  

189

00:24:08.100  -->  00:24:13.740
We have a shortest path for each couple (i, 
j), so we need a 2D table of size n by n.  

190

00:24:14.880  -->  00:24:20.880
How to fill the next table? Initially, the 
shortest path from i to j is the one where  

191

00:24:20.880  -->  00:24:27.660
we directly take the edge (i, j), if it exists, 
this is why dist[i][j] is initialized to wij.  

192

00:24:28.800  -->  00:24:35.040
Which means that in the shortest path, j comes 
just after i, it's the second vertex of the path,  

193

00:24:35.040  -->  00:24:42.960
we put j in next[i][j]. If the edge 
exists obviously, otherwise we put null,  

194

00:24:42.960  -->  00:24:51.360
because we didn't find any path from i to j yet. 
We also know that to go from a vertex to itself,  

195

00:24:51.360  -->  00:24:56.820
we initially assume that the shortest path is by 
just staying on the vertex, to get a weight 0.  

196

00:24:57.720  -->  00:25:04.680
So we put i in next[i][i], the next vertex of the 
shortest path from a vertex to itself is itself.  

197

00:25:05.880  -->  00:25:11.580
We can say that initially, next[i][j] is i if 
i is equal to j, because we're going from a  

198

00:25:11.580  -->  00:25:17.280
vertex to itself, and to j if there is an edge 
from ith vertex to jth vertex, because without  

199

00:25:17.280  -->  00:25:24.300
intermediate vertices, the only possible path 
from Vi to Vj is taking the edge from Vi to Vj.  

200

00:25:24.900  -->  00:25:29.460
And null otherwise, we don't 
have a path from Vi to Vj yet.  

201

00:25:31.680  -->  00:25:39.600
For example you can see that in the diagonal, we 
have 0 1 2 3 4, because next[i][i] is equal to i.  

202

00:25:40.860  -->  00:25:47.400
And for example we have an edge from A, whose 
index is 0, to C, whose index is 2, this is  

203

00:25:47.400  -->  00:25:56.100
why next[0][2] is 2. And during iterations, when 
dist[i][k]+dist[k][j] is smaller than dist[i][j],  

204

00:25:56.820  -->  00:26:01.800
it means that we found a shorter path 
by putting k as an intermediate vertex,  

205

00:26:01.800  -->  00:26:10.920
this is why we update dist[i][j]. We also need to 
update next[i][j], because the path might change.  

206

00:26:12.000  -->  00:26:17.580
Putting k as an intermediate means that 
we first go from i to k, then from k to j,  

207

00:26:17.580  -->  00:26:23.580
in other words, we first take the shortest path 
from i to k then the shortest path from k to j.  

208

00:26:24.600  -->  00:26:31.080
And how to get the next vertex after i to go 
to k? It's stored in next[i][k], this is why  

209

00:26:31.080  -->  00:26:38.220
we assign it to next[i][j], because now to go from 
i to j, we first need to go to k, and to go to k,  

210

00:26:38.220  -->  00:26:47.520
the next vertex is next[i][k]. In code, after 
dist we create another n by n matrix next,  

211

00:26:47.520  -->  00:26:54.660
where cells have initially the value null. Now 
for each edge (u, v), we put the index of v in  

212

00:26:54.660  -->  00:27:00.660
next[idx[u]][idx[v]], because v should come 
just after u in the initial shortest path,  

213

00:27:03.240  -->  00:27:07.860
and in tables we work with indices, 
not vertices themselves, because  

214

00:27:07.860  -->  00:27:15.900
arrays accept indices only as a key. And when 
traversing the diagonal to put 0 in dist[i][i],  

215

00:27:16.560  -->  00:27:23.220
we also put i in next[i][i], as explained 
earlier. And when updating dist[i][j],  

216

00:27:23.880  -->  00:27:32.460
we also put next[i][k] in next[i][j], we just 
explained why. And we got our next table, we  

217

00:27:32.460  -->  00:27:38.280
return it with dist and idx to be able to actually 
find the shortest path not just its weight.  

218

00:27:41.160  -->  00:27:46.860
Okay but how to reconstruct the path? Easy, 
we have source vertex, destination vertex,  

219

00:27:46.860  -->  00:27:52.800
next table, and we keep jumping to the next 
vertex by using the table, the opposite of what  

220

00:27:52.800  -->  00:28:00.420
we were doing in Dijkstra's and Bellman-Ford. 
But our matrix stores indices of vertices,  

221

00:28:00.420  -->  00:28:08.220
not their labels, this is why we need the idx map 
to get the index of a vertex, and we also need to  

222

00:28:08.220  -->  00:28:15.480
create the opposite thing, label map, a map that 
maps the index of a vertex to its label. After it,  

223

00:28:15.480  -->  00:28:22.140
we create a path array where we put the source 
vertex. We also need a variable temp to keep track  

224

00:28:22.140  -->  00:28:27.720
of the index of the current vertex, it starts 
at the index of source because we start from it.  

225

00:28:29.820  -->  00:28:34.440
Now while we didn't get to the index of 
the destination, we keep moving to the  

226

00:28:34.440  -->  00:28:40.560
next vertex and adding to the path. This is 
why we assign nxt[temp][idx[dest]] to temp,  

227

00:28:40.560  -->  00:28:46.140
it represents the next vertex in the shortest 
path from current vertex to destination.  

228

00:28:47.340  -->  00:28:53.580
And we assign the label of the current vertex 
to the path. After the loop, we return path.  

229

00:28:55.740  -->  00:28:59.040
Once again, we need to make 
sure that a path exists,  

230

00:28:59.040  -->  00:29:06.420
this is why if nxt[idx[src]][idx[dest]] is null, 
then there is no path, we return an empty array.  

231

00:29:10.380  -->  00:29:17.220
Second problem, detecting negative cycles. By 
definition, a negative cycle starts and ends at  

232

00:29:17.220  -->  00:29:22.560
the same vertex because it's a cycle, and has 
a negative total weight because it's negative.  

233

00:29:23.700  -->  00:29:29.580
The shortest path from a vertex to itself is 
0, this is why there are zeros in the diagonal.  

234

00:29:30.240  -->  00:29:34.740
Except when there is a negative cycle, 
because it goes from a vertex to itself,  

235

00:29:34.740  -->  00:29:39.720
with a weight that is smaller than 
0, 0 will be replaced by that value.  

236

00:29:41.040  -->  00:29:46.860
So to detect existence of a negative cycle, we 
just traverse the main diagonal of dist table  

237

00:29:46.860  -->  00:29:52.620
after filling it, and if one of the values is 
smaller than 0, then there is a negative cycle,  

238

00:29:52.620  -->  00:29:56.880
we can for example return null as 
we did with the previous algorithm.  

239

00:29:57.900  -->  00:30:02.700
And we finished our implementation, 
this is the Floyd-Warshall algorithm.  

240

00:30:06.840  -->  00:30:12.960
For the time complexity, we get an O(|V|^3) 
time complexity because of the nested loops.  

241

00:30:14.340  -->  00:30:18.900
You can see that the time complexity 
isn't affected by the number of edges,  

242

00:30:18.900  -->  00:30:22.920
which makes this algorithm a good 
choice when having a dense graph.  

243

00:30:26.460  -->  00:30:31.920
We needed around 30 minutes for this algorithm, 
with a lot of calculations, recurrence relation,  

244

00:30:31.920  -->  00:30:38.700
recursion tree, dynamic programming, reducing the 
table dimensions from 3D to 2D, reconstructing the  

245

00:30:38.700  -->  00:30:43.860
path...etcetera. I know that you may have 
felt lost in all of this, and it's fine,  

246

00:30:43.860  -->  00:30:49.800
you can still watch it again now that you have the 
full idea of the algorithm, or ask me questions.  

247

00:30:51.600  -->  00:30:57.060
Because I think that starting from the basic 
idea and building the intuition is better than  

248

00:30:57.060  -->  00:31:02.820
directly showing the code with 3 loops and that's 
it, as it's the case in a lot of online tutorials.  

249

00:31:03.840  -->  00:31:09.000
In brief, it's better to know about the 
underlying details of an algorithm than  

250

00:31:09.000  -->  00:31:14.700
just reading the global idea without knowing 
why and from where it comes from. Sure you  

251

00:31:14.700  -->  00:31:19.080
can be confused at the beginning, but a 
thought-provoking explanation that will  

252

00:31:19.080  -->  00:31:23.580
let you ask questions and make researches 
to better understand, is more interesting,  

253

00:31:23.580  -->  00:31:31.320
in my opinion, than just reciting the steps of the 
algorithm, show a small example and basta. And you  

254

00:31:31.320  -->  00:31:35.880
can apply what I just said to any algorithm 
we studied and will study in this course.  

255

00:31:39.000  -->  00:31:44.160
Last thing we will talk about in this lecture 
is the transitive closure of a graph. Let's say  

256

00:31:44.160  -->  00:31:51.660
we have a graph G. We know about the adjacency 
matrix, an n by n matrix where mat[i][j] is 1  

257

00:31:51.660  -->  00:32:00.480
if there is an edge from i to j, 0 otherwise. For 
unweighted graphs at least. The transitive closure  

258

00:32:00.480  -->  00:32:07.320
of a graph, is slightly different, it's an n by n 
matrix where mat[i][j] is 1 if there exists a path  

259

00:32:07.320  -->  00:32:15.960
from i to j, 0 otherwise, this is why it's also 
called "reachability matrix". For example here  

260

00:32:15.960  -->  00:32:22.860
mat[A][D] is 0 in the adjacency matrix, because 
there is no direct edge from A to D, but 1 in the  

261

00:32:22.860  -->  00:32:29.280
transitive closure because we can go from A to D, 
at least indirectly, by taking the path A->C->D.  

262

00:32:31.260  -->  00:32:36.480
Okay but what does it have to do with this 
lecture? The relationship is that Floyd-Warshall  

263

00:32:36.480  -->  00:32:42.600
algorithm is one of the ways we can use to compute 
it. In the matrix returned by Floyd-Warshall,  

264

00:32:42.600  -->  00:32:50.160
dist[i][j], represents the shortest distance to 
go from i to j. If the cell's value is infinity,  

265

00:32:50.160  -->  00:32:56.400
then we couldn't find any path, else if it's 
a number, then we found at least one path.  

266

00:32:57.300  -->  00:33:02.880
So what we can do to find the transitive closure 
is to turn cells that contain a number into 1,  

267

00:33:02.880  -->  00:33:09.840
because there is at least one path, and turn cells 
that contain infinity into 0, there is no path  

268

00:33:09.840  -->  00:33:17.580
from i to j, and we get the transitive closure. 
Or we can directly get the result we want with  

269

00:33:17.580  -->  00:33:24.120
a single pass, by replacing the expression we 
assign to dist[i][j] by this bitwise operation.  

270

00:33:28.200  -->  00:33:32.880
We've reached the end of this dense lecture, I 
hope that you understood the presented material,  

271

00:33:33.840  -->  00:33:38.880
and see you in the next lecture to discover 
a new algorithm: Johnson's algorithm.
