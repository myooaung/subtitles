WEBVTT
1

00:00:00.120  -->  00:00:04.080
Welcome to this lecture where we 
will talk about Dijkstra's algorithm,  

2

00:00:04.080  -->  00:00:09.480
a fundamental graph theory algorithm that 
handles the single-source shortest path problem.  

3

00:00:12.300  -->  00:00:18.120
The example we will work with is this graph, we 
have this weighted graph where vertices represent  

4

00:00:18.120  -->  00:00:23.460
locations, an edge between two vertices 
means that we can go from one to the other,  

5

00:00:23.460  -->  00:00:30.720
and a weight represents the distance between those 
two locations. And we want to find the shortest  

6

00:00:30.720  -->  00:00:39.060
path from the source vertex A to every other 
vertex. How will we proceed? The idea that we get  

7

00:00:39.060  -->  00:00:45.780
is to push a liquid starting from the source, and 
see how much distance it traverses before reaching  

8

00:00:45.780  -->  00:00:53.160
each vertex. For the source vertex, it's already 
there, it traverses a distance of 0 to reach it.  

9

00:00:55.860  -->  00:01:00.900
It starts running in directions that we 
can take from A, we have 4 directions,  

10

00:01:00.900  -->  00:01:08.400
the one from A to B, from A to E, from A 
to F, and from A to C. It keeps running,  

11

00:01:08.400  -->  00:01:15.000
and a first part reaches the vertex B after a 
distance of 7, let's pause to see what happens.  

12

00:01:16.920  -->  00:01:23.820
The liquid reached B for the first time, and it 
did after traversing a distance of 7. We can say  

13

00:01:23.820  -->  00:01:30.420
that the shortest distance to reach B from A is 
7. And we know that it's the shortest distance  

14

00:01:30.420  -->  00:01:37.800
because it's the first time the liquid reaches B. 
Basically the first time liquid reaches a vertex  

15

00:01:37.800  -->  00:01:45.660
determines the shortest distance to go from A to 
that vertex, this is the strategy we're using.  

16

00:01:46.920  -->  00:01:53.700
Liquid now doesn't stop at B, it will continue 
towards D and E. Let's continue the simulation  

17

00:01:53.700  -->  00:02:00.780
to see what happens. It keeps running, and it 
reaches the vertex C after a distance of 10.  

18

00:02:01.860  -->  00:02:05.520
We can say that the shortest 
distance to reach C is 10.  

19

00:02:06.360  -->  00:02:12.420
We continue, and the liquid reaches D, with 
a distance of 11, the shortest distance to  

20

00:02:12.420  -->  00:02:21.060
reach D is 11. Which we get by going to 
B, 7, then going to D, 4, and 7+4 is 11.  

21

00:02:22.740  -->  00:02:29.520
We continue, and it reaches E, with a distance 
of 13, we write that 13 is the shortest distance  

22

00:02:29.520  -->  00:02:37.440
to reach E. Let's continue, just after it 
some liquid reaches F, with a distance of 14.  

23

00:02:39.360  -->  00:02:48.660
We continue. Some liquid arrived at G after a 
total distance of 23. We continue. Some liquid  

24

00:02:48.660  -->  00:02:56.520
reaches H after traversing a distance of 27. 
We continue, we reach I with a distance of 28.  

25

00:02:57.960  -->  00:03:04.800
We keep walking. We reach J with a distance 
of 33. Then we continue, we reach K with a  

26

00:03:04.800  -->  00:03:13.080
distance of 35. And we continue, we reach L with a 
distance of 36. We finished reaching every vertex,  

27

00:03:13.080  -->  00:03:22.740
we now know the shortest distance to go from A 
to any other vertex. And that's the core idea of  

28

00:03:22.740  -->  00:03:28.680
Dijkstra's algorithm. By the way, this is called 
the shortest-path tree, a subgraph of G where  

29

00:03:28.680  -->  00:03:34.260
the path from root to a vertex v represents the 
shortest path from the root to v in the graph G.  

30

00:03:37.140  -->  00:03:42.900
However, in practice, we won't simulate the 
liquid movement, we will directly calculate  

31

00:03:42.900  -->  00:03:49.320
at what time it will arrive at each vertex. For 
example if we're at the vertex E with a distance  

32

00:03:49.320  -->  00:03:56.700
of 13 and we have a vertex to G of length 10, we 
know that by taking that direction we arrive at G  

33

00:03:56.700  -->  00:04:03.060
with a distance of 23, we don't need to simulate 
the whole process of liquid traversing that edge.  

34

00:04:06.840  -->  00:04:10.620
Let's redo this example but 
without simulating liquid.  

35

00:04:12.300  -->  00:04:18.600
We have this table dist where dist[v] represents 
the smallest distance we need to arrive at the  

36

00:04:18.600  -->  00:04:24.300
vertex v. At the beginning, we don't even know 
if we will reach the vertices at some point,  

37

00:04:24.300  -->  00:04:32.220
we can just put infinity, to say that we didn't 
find any path yet. For the source vertex A,  

38

00:04:32.220  -->  00:04:37.380
we start at it, so we reach it with 
a distance of 0, we're already there.  

39

00:04:39.480  -->  00:04:45.540
We can start working now. What's the first vertex 
we reach? It's obviously A, we start from there.  

40

00:04:46.140  -->  00:04:52.080
From A we have 4 edges, to B C E 
and F. To B with a distance of 7,  

41

00:04:52.080  -->  00:05:00.120
so we know that we will be at B after traversing 
a distance of 7. How did we calculate that? We  

42

00:05:00.120  -->  00:05:06.420
took the shortest distance to A, which is 0, and 
we added the distance from A to B, which is 7.  

43

00:05:06.420  -->  00:05:14.580
We got 7, which is smaller than infinity, 
we found a shorter way to go to B. For C,  

44

00:05:14.580  -->  00:05:22.440
the distance is 10, we will reach the vertex C at 
time 10. Then E with a distance of 13, so we know  

45

00:05:22.440  -->  00:05:29.880
that we will be at E after traversing a distance 
of 13. And to F with a distance of 14, same thing.  

46

00:05:31.980  -->  00:05:38.040
Now we suppose that liquid starts running, what 
is the first vertex they will reach? To know it,  

47

00:05:38.040  -->  00:05:44.280
we take the unvisited vertex with the smallest 
arrival time, with the smallest value of dist[v].  

48

00:05:46.380  -->  00:05:49.740
It's obviously B, it's the one 
with the earliest distance.  

49

00:05:52.380  -->  00:05:58.380
Okay we're at B with a distance of 7, we deduce 
that the shortest distance to reach B is 7.  

50

00:05:59.400  -->  00:06:03.240
Let's check its out-neighbors. 
It has an edge to D and E.  

51

00:06:04.260  -->  00:06:10.560
To D with a distance of 4, and we traversed a 
distance of 7 to reach B, we deduce that we can  

52

00:06:10.560  -->  00:06:20.460
reach D with a distance of 7+4, 11, better than 
infinity, we put 11 in dist[D]. Also to E with a  

53

00:06:20.460  -->  00:06:29.220
distance of 8, we deduce that we can reach E with 
a distance of 7+8, 15. But, dist[E] is 13, which  

54

00:06:29.220  -->  00:06:36.900
is smaller than 15, this is why we don't update, 
we found a better path before, dist[E] remains 13.  

55

00:06:39.300  -->  00:06:46.260
Okay we traversed B, what is the next vertex 
liquid will reach? At distance 8 nothing happens,  

56

00:06:46.260  -->  00:06:53.880
at distance 9 nothing happens, and at distance 
10 we reach C, it has the earliest time, 10.  

57

00:06:54.900  -->  00:07:03.480
From C we can go to F and I. To F with a distance 
of 12. And 10+12 is 22, so we found a way to go  

58

00:07:03.480  -->  00:07:11.340
from A to F with a distance of 22. However, 
dist[F] is 14, which is smaller, so we know  

59

00:07:11.340  -->  00:07:20.640
that we will arrive at F earlier, we don't update. 
And to I with a distance of 22. 10+22 gives 32,  

60

00:07:20.640  -->  00:07:27.420
and it's better than infinity, we update, we 
now know how to reach I with a distance of 32.  

61

00:07:29.160  -->  00:07:34.740
We might find a better path later, but 
32 is the best distance we found so far.  

62

00:07:37.260  -->  00:07:42.780
Okay what's the next vertex liquid will 
reach? We have D with 11, E with 13,  

63

00:07:42.780  -->  00:07:47.280
F with 14, and I with 32, infinity for others.  

64

00:07:48.540  -->  00:07:54.960
Liquid will reach D, because it has the earliest 
arrival time among vertices we didn't visit yet.  

65

00:07:57.660  -->  00:08:05.100
From D we can go to E and G. To E with 
a distance of 6, 11+6 is 17, same thing,  

66

00:08:05.100  -->  00:08:13.080
it doesn't replace, 17 is not smaller 
than 13. And to G with a distance of 15,  

67

00:08:13.080  -->  00:08:20.460
11+15 is 26, better than infinity, we 
found a path of length 26 to reach G.  

68

00:08:23.220  -->  00:08:29.940
What's the next vertex? It's E, with a distance 
of 13. You can see that we're considering only  

69

00:08:29.940  -->  00:08:36.660
vertices that we didn't visit yet. E can 
go to G and F. To F with a distance of 7,  

70

00:08:36.660  -->  00:08:44.940
13+7 is 20, doesn't replace. And to 
G with a distance of 10, 13+10 is 23,  

71

00:08:44.940  -->  00:08:52.560
and here it's smaller than 26, dist[G], what does 
it mean? It means that earlier, we found a path  

72

00:08:52.560  -->  00:08:59.700
to G whose the length is 26, but now we found 
a better path, whose the length is only 23,  

73

00:08:59.700  -->  00:09:06.120
this is why we replace, we now say that 
the earliest time to reach G so far is 23.  

74

00:09:06.960  -->  00:09:12.000
With the liquid example, it means that there 
was some liquid that was planning to arrive  

75

00:09:12.000  -->  00:09:21.480
at G at distance 26, but we found another part 
that will reach G sooner. We might still find  

76

00:09:21.480  -->  00:09:27.180
better paths later, because we didn't reach G 
yet, we're just discovering paths going to it.  

77

00:09:28.980  -->  00:09:35.940
What's the next vertex? It's F, with a distance 
of 14. It can go to G, H and I. To G with  

78

00:09:35.940  -->  00:09:47.160
a distance of 11, and 14+11 is 25, it doesn't 
replace, we have 23. To H with 13, 14+13 is 27.  

79

00:09:48.120  -->  00:09:57.600
We never found a path to H before so we replace. 
And to I with 14, 14+14 is 28, it also replaces.  

80

00:10:00.120  -->  00:10:08.160
What's the next vertex? We still have K J 
L H G and I. The next one is G, with 23,  

81

00:10:08.160  -->  00:10:15.480
it has the smallest distance among remaining 
vertices. It can go to H and J. To H with 12,  

82

00:10:15.480  -->  00:10:24.420
23+12 is 35, it doesn't replace. And to J 
with 12, 23+12 is 35, it replaces infinity.  

83

00:10:26.400  -->  00:10:35.820
Next vertex to be reached is H, with a distance 
of 27. It can go to J K and L. To J with 6, 27+6  

84

00:10:36.420  -->  00:10:47.100
is 33, it replaces 35, so we found a better path 
to go to J. To K with 8, 27+8 is 35, it replaces.  

85

00:10:47.760  -->  00:10:59.040
And to L with 9, 27+9 is 36, it replaces. Next 
vertex is I with a distance of 28. We reached  

86

00:10:59.040  -->  00:11:05.220
I after traversing a distance of 28 so the 
shortest distance to go from A to I is 28.  

87

00:11:06.840  -->  00:11:16.620
It can go to H and L. To H, it doesn't replace, 
to L, it doesn't replace. Next vertex is J with  

88

00:11:16.620  -->  00:11:24.240
a distance of 33. It can go to K. To K, we get 
the same distance as dist[K] so nothing changes.  

89

00:11:25.920  -->  00:11:34.620
Next vertex is K with a distance of 35. It can 
go to L. To L, the sum is 45, it doesn't replace.  

90

00:11:36.120  -->  00:11:41.940
Last vertex, L, with a distance of 
36. It doesn't have out-neighbors.  

91

00:11:45.300  -->  00:11:50.640
We traversed all vertices, so we finished the 
process, we got that the shortest distance to  

92

00:11:50.640  -->  00:11:58.680
go from A to A is 0, from A to K is 35, from A 
to C is 10, from A to J is 33, from A to E is 13,  

93

00:11:58.680  -->  00:12:07.320
from A to L is 36, from A to B is 7, from A to 
F is 14, from A to H is 27, from A to D is 11,  

94

00:12:07.320  -->  00:12:16.680
from A to G is 23, and from A to I is 28. Okay 
okay what happened here? I know that some of you  

95

00:12:16.680  -->  00:12:22.740
lost the track and zoned out while I was doing 
the example. Short attention span problem keeps  

96

00:12:22.740  -->  00:12:28.980
increasing and that's terrible to be honest, I'm 
suffering from it too, but anyway. In this example  

97

00:12:28.980  -->  00:12:35.460
we've seen how Dijkstra's algorithm works. We can 
understand it by imagining ourselves dropping a  

98

00:12:35.460  -->  00:12:42.360
liquid from the source vertex A, it keeps running 
in all available directions. And every time  

99

00:12:42.360  -->  00:12:48.360
some liquid reaches a vertex the first time, the 
distance it took to do so represents the shortest  

100

00:12:48.360  -->  00:12:53.940
distance to reach that vertex, the shortest 
because no other liquid could reach it before.  

101

00:12:55.800  -->  00:13:01.320
And when we reach a vertex, we check neighbors 
of that vertex to calculate at what time we  

102

00:13:01.320  -->  00:13:08.160
will arrive at them. In this animation, liquid 
start at A, then they first reach B, then C,  

103

00:13:08.160  -->  00:13:17.400
then D, then E, F, G, H, I, J, K, and L, in this 
chronological order. The alphabetical order is  

104

00:13:17.400  -->  00:13:24.600
just a coincidence by the way. And this is what 
we try to replicate in the Dijkstra's algorithm,  

105

00:13:24.600  -->  00:13:33.360
if you noticed, we traversed vertices in 
chronological order, A B C D E F G H I J K L.  

106

00:13:36.960  -->  00:13:42.480
Because we were keeping track of the earliest 
time we will arrive at each vertex, and we kept  

107

00:13:42.480  -->  00:13:47.760
moving to the one with the smallest value in 
dist, because it represents the next vertex  

108

00:13:47.760  -->  00:13:54.300
liquid will reach. By doing so, we're making sure 
that we're reaching a vertex as soon as possible,  

109

00:13:54.300  -->  00:13:59.760
hence, with the shortest distance, that's 
why the Dijkstra's algorithm works.  

110

00:14:02.280  -->  00:14:06.120
If you're still confused, you just 
need to imagine liquid running in  

111

00:14:06.120  -->  00:14:11.160
all available directions, and each time 
it finds a new vertex, we deduce that the  

112

00:14:11.160  -->  00:14:15.600
shortest distance to reach it from source 
is the total distance it traversed so far.  

113

00:14:17.220  -->  00:14:21.960
But instead of simulating this process, 
we keep track of earliest time we will  

114

00:14:21.960  -->  00:14:27.240
arrive at each vertex, to be able to find 
the next vertex in chronological order.  

115

00:14:29.460  -->  00:14:35.040
Having a look at the pseudocode might give you 
a better understanding, some people feel more  

116

00:14:35.040  -->  00:14:40.500
comfortable with clear instructions instead 
of visualizations of examples, so let's try  

117

00:14:40.500  -->  00:14:48.660
to convert what we did into pseudocode. Remember 
that at the beginning dist[u] was infinity for  

118

00:14:48.660  -->  00:14:56.040
each vertex u, because we didn't know any path. 
We also need a structure open that represents  

119

00:14:56.040  -->  00:15:04.080
vertices we didn't visit yet with their respective 
value in dist. So in pseudocode, we create those  

120

00:15:04.080  -->  00:15:10.860
two structures, then for each vertex u, we put 
infinity in dist[u] and we add the vertex to open.  

121

00:15:13.740  -->  00:15:18.120
We know that the shortest distance to 
reach the source is 0, so we update,  

122

00:15:18.120  -->  00:15:23.580
we put 0 in dist[source]. 
Now we can start traversing,  

123

00:15:23.580  -->  00:15:29.220
we keep traversing while we still have open 
vertices, vertices that we didn't visit.  

124

00:15:30.420  -->  00:15:35.940
During the process, we were always going to the 
unvisited vertex with the smallest value in dist,  

125

00:15:35.940  -->  00:15:43.680
to follow the chronological order of events. This 
is why, we extract the vertex u from open that has  

126

00:15:43.680  -->  00:15:49.500
the smallest value dist[u], it represents 
the next new vertex liquid will reach.  

127

00:15:51.660  -->  00:15:56.940
When extracting it we remove it from open by 
the way, because it's no longer unvisited.  

128

00:15:59.280  -->  00:16:03.420
What to do with this vertex u now? 
We need to traverse its neighbors.  

129

00:16:06.000  -->  00:16:11.460
By the way, in a weighted graph, elements in 
the adjacency list aren't a simple destination  

130

00:16:11.460  -->  00:16:17.280
vertex, they're a tuple of two elements, the 
destination vertex and the weight of the edge.  

131

00:16:17.880  -->  00:16:22.020
This is why when traversing neighbors 
we write for v, w in graph[u],  

132

00:16:22.020  -->  00:16:26.580
to get both the destination and 
the weight, we need them both.  

133

00:16:28.620  -->  00:16:34.380
During the process, we were traversing neighbors 
to check if we didn't find a better path than the  

134

00:16:34.380  -->  00:16:42.660
actual one, and this is what we will do now. For 
each v, w in graph[u], we start by calculating the  

135

00:16:42.660  -->  00:16:47.460
distance of the new path. It's the distance 
we traversed to reach the actual vertex u,  

136

00:16:47.460  -->  00:16:53.700
which is dist[u], + the length of the edge that 
will take us to the neighbor v, its length is w.  

137

00:16:55.740  -->  00:17:03.360
For example when we were at H we said 
to J with 6, 27+6 is 33. 27 was dist[H],  

138

00:17:03.900  -->  00:17:11.340
6 was the weight of the edge from H to J, and 
the sum was the length of the new path, 33.  

139

00:17:12.480  -->  00:17:20.100
So the distance of the new path is dist[u]+w, the 
distance to reach u + the distance to go to v from  

140

00:17:20.100  -->  00:17:26.880
u. And now, we compare it with the length of the 
actual shortest path to reach v, which is dist[v].  

141

00:17:28.200  -->  00:17:34.020
In the same example we compared 33, the 
length of the new path we found, with 35,  

142

00:17:34.020  -->  00:17:41.760
the length of the best path we had found so far, 
dist[v]. And because 33 was smaller than 35,  

143

00:17:41.760  -->  00:17:49.200
what we did, we replaced, we replaced dist[v] by 
the length of the new path, which is dist[u]+w.  

144

00:17:51.360  -->  00:17:57.540
And that's what we call edge relaxation, the 
action of checking if the edge produces a better  

145

00:17:57.540  -->  00:18:05.100
path than the actual best one. And that's it for 
the loop instructions, the loop will continue  

146

00:18:05.100  -->  00:18:11.400
like that, it keeps moving to the next vertex in 
chronological order while updating dist table.  

147

00:18:12.600  -->  00:18:18.600
After the loop, dist table now holds the shortest 
distance to reach each vertex starting from the  

148

00:18:18.600  -->  00:18:29.040
source, we return it, and that's the Dijkstra's 
algorithm. If you had to remember two lines on how  

149

00:18:29.040  -->  00:18:34.620
the algorithm works, it's that we put infinity 
for all vertices except source, we put 0,  

150

00:18:34.620  -->  00:18:40.020
then we keep extracting the next vertex to be 
reached, the one with the smallest value in dist,  

151

00:18:40.020  -->  00:18:46.020
and we check its neighbors to check if the 
actual vertex leads to better paths, that's it.  

152

00:18:49.200  -->  00:18:53.760
But wait, the algorithm is just returning the 
shortest distance to reach other vertices,  

153

00:18:53.760  -->  00:18:59.820
but not the actual path, it's not returning 
what vertices to take to minimize the distance.  

154

00:19:01.080  -->  00:19:06.060
To add this feature, we can just keep track 
of the previous vertex of each vertex.  

155

00:19:06.780  -->  00:19:12.300
To do so, every time we update dist[v], 
we also update its previous vertex.  

156

00:19:13.020  -->  00:19:17.820
With our example, at the beginning all 
vertices don't have a previous vertex,  

157

00:19:17.820  -->  00:19:25.320
we didn't find any path that leads to them. 
With A, we update dist[B], dist[E], dist[F],  

158

00:19:25.320  -->  00:19:32.700
and dist[C]. So we put A as their previous vertex, 
the vertex they came from in their shortest path.  

159

00:19:33.660  -->  00:19:41.460
Then we went to B, where we updated dist[D], so we 
put B as the previous vertex of D. Then we went to  

160

00:19:41.460  -->  00:19:49.020
C where we updated dist[I], so we put C as the 
previous vertex of I. Basically every time we  

161

00:19:49.020  -->  00:19:55.620
find a better path for v by going from the actual 
vertex u, we put u as the previous vertex of v.  

162

00:19:57.420  -->  00:20:06.240
The process continues like that, at the end we 
get this prev table. Now if we want to retrieve  

163

00:20:06.240  -->  00:20:11.820
the shortest path from source to a vertex v, we 
just keep going backwards by using the prev table.  

164

00:20:14.760  -->  00:20:21.060
Let's suppose that we want the shortest path to 
go from A to L. L is the last vertex, we put it  

165

00:20:21.060  -->  00:20:29.460
in the path. prev[L] is H, we go to it and we put 
it in the path. prev[H] is F, we go to it and we  

166

00:20:29.460  -->  00:20:37.320
put it in the path. prev[F] is A, we go to it and 
put it in the path. prev[A] is null, so we went  

167

00:20:37.320  -->  00:20:43.380
back to the source, we finished making the path, 
we just reverse it before returning it to get it  

168

00:20:43.380  -->  00:20:51.540
in the right order, from source to destination, 
not the opposite. In pseudocode, we first need to  

169

00:20:51.540  -->  00:20:58.020
update what we made earlier to add the feature of 
keeping track of previous. Very easy, we create a  

170

00:20:58.020  -->  00:21:03.720
table prev. And initially the previous vertex 
of each vertex is null, we don't know it yet.  

171

00:21:04.560  -->  00:21:10.440
Then while working in the loop, every time we're 
on the vertex u and find a better path to go to v,  

172

00:21:10.440  -->  00:21:17.280
u becomes the previous vertex of v because of 
the new path we found, so we put u in prev[v].  

173

00:21:19.020  -->  00:21:28.260
After the loop, we return both dist table and prev 
table, we need them both. We also need a function  

174

00:21:28.260  -->  00:21:33.780
to reconstruct the path, it takes as parameters 
the prev table we built and the destination.  

175

00:21:34.800  -->  00:21:40.080
We create path that initially contains the 
destination, and we use a variable vertex  

176

00:21:40.080  -->  00:21:47.040
that starts at the end of the path, it represents 
the green dot we've been working with now. While  

177

00:21:47.040  -->  00:21:53.580
vertex still has a previous vertex, then we didn't 
reach the source, vertex becomes prev[vertex],  

178

00:21:53.580  -->  00:21:59.520
and we add it to the path, as we were doing now 
in the example, we were each time moving to the  

179

00:21:59.520  -->  00:22:06.120
previous vertex of the actual vertex. After the 
loop, we just reverse the path and return it.  

180

00:22:10.320  -->  00:22:15.540
What we did now was discussing the pseudocode, 
but what about the actual implementation?  

181

00:22:16.440  -->  00:22:21.240
I wanted to start with the pseudocode because we 
have different choices for the implementation,  

182

00:22:21.240  -->  00:22:28.200
so I wanted to first let you focus on the steps, 
to understand how the algorithm works, regardless  

183

00:22:28.200  -->  00:22:34.680
on how we implement it. By the way, if you still 
don't understand something about the algorithm,  

184

00:22:34.680  -->  00:22:39.900
if you're still not convinced, even if you have 
that little feeling that something is not clear,  

185

00:22:39.900  -->  00:22:45.480
you must get rid of it. For that you can 
watch the video again, to see the example  

186

00:22:45.480  -->  00:22:51.120
again and the explanation, or you can ask 
me questions. If you have any doubt right  

187

00:22:51.120  -->  00:22:56.640
now about the algorithm, pause the video and 
ask me a question, I really want you to do it.  

188

00:22:59.460  -->  00:23:03.840
Everything is fine now? You understood the 
algorithm? Let's move to the implementation.  

189

00:23:05.820  -->  00:23:11.340
The dilemma for the implementation is what 
data structure to choose. For dist and prev,  

190

00:23:11.340  -->  00:23:17.160
we will obviously use a hash table, where the 
key is a vertex, and the value is the shortest  

191

00:23:17.160  -->  00:23:24.120
distance and the previous vertex respectively. 
But what about open? The problem comes from this  

192

00:23:24.120  -->  00:23:30.720
instruction, extract the vertex from open 
with the smallest value in dist. Let's use  

193

00:23:30.720  -->  00:23:36.780
an array and see what happens. By the way, 
the difference between implementations will  

194

00:23:36.780  -->  00:23:41.220
mainly be in the time complexity, so 
it's what we will evaluate to compare.  

195

00:23:42.960  -->  00:23:49.440
Let's start. Traversing the vertices to update 
their value and inserting them in open costs |V|,  

196

00:23:49.440  -->  00:23:52.860
the number of vertices. Because updating in a hash  

197

00:23:52.860  -->  00:23:58.440
table costs O(1) in average and adding an 
element to an array costs O(1) amortized.  

198

00:24:00.180  -->  00:24:07.260
Now we have the loop. We keep looping while we 
have elements in open, but how much iterations the  

199

00:24:07.260  -->  00:24:13.920
loop will do? We initially have |V| vertices in 
open, we're extracting one vertex per iteration,  

200

00:24:13.920  -->  00:24:21.060
and we're not adding new elements to open, we 
deduce that we will do |V| loop iterations.  

201

00:24:24.000  -->  00:24:29.580
What about vertex extraction now. We want to 
extract the vertex with the smallest value  

202

00:24:29.580  -->  00:24:35.520
dist[u], we're basically searching for the 
minimum. And searching for the minimum in  

203

00:24:35.520  -->  00:24:42.720
an array requires traversing the whole set. The 
array here has |V| elements, so the cost is |V|.  

204

00:24:45.120  -->  00:24:50.460
We also have the loop that traverses neighbors 
of u. The number of neighbors of u is its degree,  

205

00:24:50.460  -->  00:24:55.920
so the loop does deg(u) iterations, 
and operations inside cost O(1).  

206

00:24:57.840  -->  00:25:04.380
So the total cost is T(V,E) = 
|V| + |V|*|V| + sum(deg(u)).  

207

00:25:06.060  -->  00:25:11.520
Here we need to do the sum because we can't 
multiply, not all vertices have the same degree.  

208

00:25:13.980  -->  00:25:20.400
We just know that the sum of degrees is 2|E| 
for an undirected graph and |E| for directed,  

209

00:25:20.400  -->  00:25:24.360
we've talked about it in the 
chapter about dfs and bfs.  

210

00:25:26.700  -->  00:25:33.900
So we have |V| + |V|² + |E|, 
which gives O(|V|²+|E|).  

211

00:25:35.760  -->  00:25:38.700
We can ignore the |E| because in a simple graph,  

212

00:25:38.700  -->  00:25:45.600
the number of edges is smaller than or equal 
to |V|², so we get O(|V|²) time complexity.  

213

00:25:47.100  -->  00:25:52.620
O(|V|²) is quite slow for this problem, 
let's try to find something else.  

214

00:25:57.420  -->  00:26:03.240
The solution is to use a priority queue. A 
priority queue is a structure where each elements  

215

00:26:03.240  -->  00:26:09.060
has a priority, and extracting an element from 
it returns the element with the highest priority.  

216

00:26:09.840  -->  00:26:15.240
In our problem, the priority of a vertex is 
inversely proportional to its value in dist,  

217

00:26:16.140  -->  00:26:20.220
the smaller dist[v] is, the 
bigger the priority of v is.  

218

00:26:24.300  -->  00:26:29.580
And the vertex with the highest priority 
is the one with the smallest value dist[v],  

219

00:26:29.580  -->  00:26:36.120
the one we're searching for to go to it. And we 
will use 3 operations with this priority queue,  

220

00:26:36.120  -->  00:26:41.880
we will first use it to insert our |V| 
vertices, we also use it to extract the  

221

00:26:41.880  -->  00:26:47.760
vertex with the highest priority, and we use 
update priority when we update dist[vertex].  

222

00:26:49.260  -->  00:26:53.940
Updating the priority is important to 
maintain the order in the priority queue.  

223

00:26:55.260  -->  00:27:01.380
Starting from this pseudocode, we have the 
cost of traversing the |V| vertices, |V|,  

224

00:27:01.380  -->  00:27:07.440
the cost of initially inserting the |V| vertices, 
in other words building the priority queue,  

225

00:27:07.440  -->  00:27:14.100
let's name it Tbuild. We also have the cost of 
updating the priority of the source, let's name it  

226

00:27:14.100  -->  00:27:21.060
Tupdate. Then the loop does |V| iterations, inside 
it we have the cost of extracting the minimum,  

227

00:27:21.060  -->  00:27:26.100
let's name it Textract, and we also 
have the loop that traverses neighbors.  

228

00:27:28.200  -->  00:27:33.300
We know that it does deg(u) iterations, 
and inside it we're updating dist[v],  

229

00:27:33.300  -->  00:27:37.560
so we're updating the priority 
of v, the cost is Tupdate.  

230

00:27:39.180  -->  00:27:50.100
The total cost is T(V,E) = |V| + Tbuild + 
Tupdate + |V|*Textract + sum(deg(u))*Tupdate.  

231

00:27:51.600  -->  00:28:02.760
The sum of degrees is |E|, we get T(V,E) = |V| 
+ Tbuild + Tupdate + |V|*Textract + |E|*Tupdate.  

232

00:28:07.620  -->  00:28:13.140
Okay now we have our expression, we just need 
to find out the cost of Tbuild, Textract,  

233

00:28:13.140  -->  00:28:18.660
and Tupdate. And these costs depend on 
how we implement the priority queue.  

234

00:28:19.500  -->  00:28:26.100
We can do so by using a sorted array. At the 
beginning all vertices have the same priority, we  

235

00:28:26.100  -->  00:28:33.780
don't need to sort, we just create an array of |V| 
vertices, which costs |V|, Tbuild is in O(|V|).  

236

00:28:35.340  -->  00:28:40.440
To extract minimum from a sorted array, 
assuming that vertices are in decreasing order,  

237

00:28:40.440  -->  00:28:48.480
we just go to the last element, which can 
be done in O(1). Removing it also costs  

238

00:28:48.480  -->  00:28:56.580
O(1) because we're just popping from an array. So 
Textract is O(1). But the problem is with Tupdate,  

239

00:28:56.580  -->  00:29:02.100
when updating the priority of an element in a 
sorted array, we need to take it to its right  

240

00:29:02.100  -->  00:29:07.980
position to maintain the order. And doing so 
requires us to shift all the elements in the  

241

00:29:07.980  -->  00:29:15.660
worst case, which costs |V|, so Tupdate 
is in O(|V|). So by using a sorted array,  

242

00:29:15.660  -->  00:29:27.840
we get T(V,E) = |V| + |V| + |V| + |V|*1 + |E|*|V|, 
which gives a time complexity of O(|E||V|).  

243

00:29:31.680  -->  00:29:38.040
O(|E||V|) is also slow, using a sorted array is 
not the best choice. A better implementation of  

244

00:29:38.040  -->  00:29:44.520
the priority queue is by using a heap. A heap 
is a tree data structure that satisfies the  

245

00:29:44.520  -->  00:29:51.060
heap property: For each node C, if P is a parent 
node of C, then the key of P is greater than or  

246

00:29:51.060  -->  00:29:56.100
equal to the key of C if we're in a max-heap, 
and smaller or equal if we're in a min-heap.  

247

00:29:57.360  -->  00:30:02.880
This is why at the top we can find the node 
with the highest priority, the one with the  

248

00:30:02.880  -->  00:30:07.740
greatest key if we're in a max-heap and the one 
with the smallest key if we're in a min-heap.  

249

00:30:09.780  -->  00:30:14.580
In our problem, vertices with small 
keys, small values of dist[v],  

250

00:30:14.580  -->  00:30:19.920
are the ones with a high priority, so we 
will use a min-heap, we want the vertex  

251

00:30:19.920  -->  00:30:24.600
with the smallest value dist[v] to be 
at the top, to be easily accessible.  

252

00:30:26.520  -->  00:30:31.020
And in our problem, we're updating the 
key only when we find a smaller key,  

253

00:30:31.020  -->  00:30:36.600
when we find a smaller value dist[v], this is 
why we will use the decrease_key() operation  

254

00:30:36.600  -->  00:30:41.640
of a heap to update the priority, so 
Tupdate is the cost of decrease_key().  

255

00:30:44.880  -->  00:30:51.060
The heap has many variants, the binary heap, 
the binomial heap, the Fibonacci heap, and many  

256

00:30:51.060  -->  00:30:56.220
other ones, they slightly differ in behavior 
and in time complexity of main operations.  

257

00:30:58.020  -->  00:31:03.360
The most popular one is the binary heap, I 
won't focus on how it works, because it's  

258

00:31:03.360  -->  00:31:08.760
not the subject of this lecture, and I made a 
YouTube video on the subject that I recommend  

259

00:31:08.760  -->  00:31:17.220
you to watch. I'll just focus on time complexity 
of its main operations. Operations we need here  

260

00:31:17.220  -->  00:31:24.240
are building a heap of n elements, extracting the 
minimum, and decrease key. For the binary heap,  

261

00:31:24.240  -->  00:31:31.200
building a heap of n elements is in O(n), 
in our case n is |V| so Tbuild is in O(|V|).  

262

00:31:32.100  -->  00:31:37.500
Extracting the minimum is done in O(logn) 
where n is the number of elements in the heap,  

263

00:31:37.500  -->  00:31:43.260
it's not in constant time because it needs to 
reorder some nodes to maintain the heap property.  

264

00:31:44.400  -->  00:31:54.060
In our case n is |V| so Textract is in O(log|V|). 
And decrease_key() is also done in O(logn),  

265

00:31:54.060  -->  00:32:07.140
O(log|V|) in our case. In total, we have |V| + 
|V| + log|V| + |V|log|V| + |E|log|V|, which gives  

266

00:32:07.140  -->  00:32:15.060
a time complexity of O((|E|+|V|)log|V|), 
better than when using a sorted array.  

267

00:32:19.560  -->  00:32:25.560
But we have a variant that is even better for 
Dijkstra's algorithm, it's the Fibonacci heap.  

268

00:32:25.560  -->  00:32:32.460
With a Fibonacci heap, building is in |V|, no 
difference. Extracting the minimum is in O(logn)  

269

00:32:32.460  -->  00:32:40.140
amortized, O(log|V|) amortized. And decrease_key() 
is done in O(1) amortized instead of O(logn).  

270

00:32:41.580  -->  00:32:48.780
In total, we get |V| + |V| 
+ 1 + |V|log|V| + |E|*1,  

271

00:32:49.320  -->  00:32:56.760
which gives a time complexity of 
O(|E|+|V|log|V|), quite efficient.  

272

00:33:02.700  -->  00:33:08.520
Let's code this solution, the one that 
uses a Fibonacci heap. The function takes  

273

00:33:08.520  -->  00:33:13.500
as parameters the graph, represented as 
an adjacency list, and the source vertex.  

274

00:33:15.180  -->  00:33:18.540
We create the dist hash table, 
we create the prev hash table,  

275

00:33:18.540  -->  00:33:24.840
and here we need another hash table nodes to save 
the references of nodes that will be in our heap.  

276

00:33:24.840  -->  00:33:30.300
We do so because when we want to decrease the 
key of a node, we have to provide the reference,  

277

00:33:30.300  -->  00:33:35.160
so instead of searching for it, we store 
references of nodes to have direct access.  

278

00:33:36.840  -->  00:33:43.560
In this nodes table the key will be the label of 
the vertex, and the value will be a Node object.  

279

00:33:44.640  -->  00:33:50.100
After it we create open, that we can also 
name queue, the structure where we will  

280

00:33:50.100  -->  00:33:55.020
store unvisited vertices and from where we 
will extract the minimum vertex to go to it,  

281

00:33:55.680  -->  00:33:59.340
in this solution we use a 
Fibonacci heap for its efficiency.  

282

00:34:01.560  -->  00:34:06.480
Now we traverse vertices, for each 
vertex u, we set dist[u] to infinity,  

283

00:34:06.480  -->  00:34:11.700
we set prev[u] to null, and we need 
to insert it in the priority queue.  

284

00:34:13.440  -->  00:34:19.140
We know that dist[u] is infinity so the key 
will be infinity. We also want to store the  

285

00:34:19.140  -->  00:34:24.360
label of the current vertex in the node to know 
what vertex we're working with when extracting a  

286

00:34:24.360  -->  00:34:31.560
node from the Fibonacci heap. The solution is to 
put the tuple (dist, label), we fix both problems,  

287

00:34:31.560  -->  00:34:38.640
tuples are first compared by their first value, 
and we made room for the label. This is why  

288

00:34:38.640  -->  00:34:45.120
we create a node with (dist[u], u) as a key, 
dist[u] to compare, and u to have the label.  

289

00:34:46.500  -->  00:34:53.520
We assign it to nodes[u] to save the reference, 
and we insert it in the queue. By the way,  

290

00:34:53.520  -->  00:34:58.740
the key is what will give the ability to the 
priority queue to compare between its elements and  

291

00:34:58.740  -->  00:35:04.680
take the one with the highest priority, here the 
key of a node is the value of the vertex in dist.  

292

00:35:06.660  -->  00:35:12.780
After it, we set dist[source] to 0, and we 
decrease key in open, remember that we decrease  

293

00:35:12.780  -->  00:35:20.280
key every time we update dist of some vertex. 
Here we've set dist[source] to 0, so we provide  

294

00:35:20.280  -->  00:35:25.080
the reference of the node of the source vertex and 
decrease its key to the new value of dist[src].  

295

00:35:26.820  -->  00:35:31.680
Now we can start looping, we keep 
looping while we still have nodes.  

296

00:35:34.620  -->  00:35:39.720
The way I found to do that with this fibheap 
module is to check if the minimum is not null,  

297

00:35:39.720  -->  00:35:46.440
it means we still have a node. Inside the loop, 
we extract the minimum vertex and store the  

298

00:35:46.440  -->  00:35:51.840
second value of its key in u, it represents 
the label of the vertex, for example B.  

299

00:35:52.860  -->  00:35:57.960
This is why storing the label is important, we 
need to know what vertex we're dealing with.  

300

00:35:58.800  -->  00:36:02.400
Then we traverse neighbors, we traverse tuples (v,  

301

00:36:02.400  -->  00:36:08.340
w) that are in graph[u], v is the neighbor 
and w the distance of the edge from u to v.  

302

00:36:11.220  -->  00:36:15.960
The distance of the new path is 
dist[u]+w, and we check if it's  

303

00:36:15.960  -->  00:36:21.960
better than the shortest path we found so far 
to v. If dist[u]+w is smaller than dist[v],  

304

00:36:21.960  -->  00:36:28.500
we assign it to dist[v], we set u as prev[v] 
as explained earlier, and we decrease key.  

305

00:36:29.160  -->  00:36:34.140
We provide the reference of the node of 
the vertex v, and the key (dist[v], v).  

306

00:36:36.480  -->  00:36:43.080
After the loop, we return dist and prev. And we 
finished implementing Dijkstra's algorithm by  

307

00:36:43.080  -->  00:36:51.720
using a Fibonacci heap. For the time complexity, 
we get O(|E|+|V|log|V|) as explained earlier.  

308

00:36:52.500  -->  00:36:59.700
And for the space complexity, we have |V| for each 
structure, dist, prev, nodes and queue all hold at  

309

00:36:59.700  -->  00:37:08.160
most |V| items, they're storing vertices without 
repetition. We get a space complexity of O(|V|).  

310

00:37:14.640  -->  00:37:20.700
Now question, what about the visited set? 
Why didn't we use a visited set? We're not  

311

00:37:20.700  -->  00:37:24.600
using a visited set simply because 
we're not re inserting vertices,  

312

00:37:24.600  -->  00:37:32.160
queue starts with |V| vertices and we just 
keep popping. Not re inserting vertices means  

313

00:37:32.160  -->  00:37:37.200
that once we pop a vertex, we're sure that 
we won't find a shorter path to it later.  

314

00:37:38.340  -->  00:37:45.180
Is it true though? We will talk about it in the 
last point of this lecture. Another question,  

315

00:37:45.180  -->  00:37:50.640
in the example we've seen, all vertices were 
reachable from A, and the algorithm worked  

316

00:37:50.640  -->  00:37:56.460
normally. But what if some vertices were not 
reachable from A? What would we get as a result?  

317

00:37:58.080  -->  00:38:03.840
The algorithm finishes at some point, it doesn't 
return an error because of that. It's just that  

318

00:38:03.840  -->  00:38:09.600
because some vertices are not reachable from A, we 
won't have an edge to reach them, so we will never  

319

00:38:09.600  -->  00:38:16.380
update their value in dist and prev. As a result, 
if let's say the vertex K is not reachable from A,  

320

00:38:16.380  -->  00:38:22.440
dist[K] will remain infinity, and prev[K] 
will remain null, it means that we don't  

321

00:38:22.440  -->  00:38:28.020
have a previous vertex of K that can take 
us to A, we don't have a path from A to K.  

322

00:38:29.880  -->  00:38:33.660
So if you want to reconstruct the 
shortest path with the function we made,  

323

00:38:33.660  -->  00:38:39.960
first make sure that dist of that vertex is not 
infinity, make sure that at least one path exists.  

324

00:38:44.280  -->  00:38:49.800
Next question, we use Dijkstra's algorithm to 
solve the Single-source shortest path problem,  

325

00:38:49.800  -->  00:38:55.140
but can it solve other variations? 
The answer is yes. It can for example  

326

00:38:55.140  -->  00:38:58.560
solve the Single-destination 
shortest path problem variation.  

327

00:39:01.560  -->  00:39:06.720
To do so, we just replace the graph with 
its transpose graph. The transpose graph  

328

00:39:06.720  -->  00:39:11.940
of a graph is made just by reversing the 
direction of edges, for each edge (u,v),  

329

00:39:11.940  -->  00:39:18.540
we add an edge (v,u) in the transpose graph. We 
apply Dijkstra's algorithm on the transpose graph,  

330

00:39:18.540  -->  00:39:24.600
and we get the results dist and prev. Small 
difference in the reconstruct path function,  

331

00:39:24.600  -->  00:39:30.960
this time we don't reverse the path, to get 
dest as the destination and not as the source.  

332

00:39:32.640  -->  00:39:36.060
The time complexity of Dijkstra's 
algorithm remains the same.  

333

00:39:37.620  -->  00:39:40.680
It can also solve the Single-pair 
shortest path problem.  

334

00:39:41.760  -->  00:39:46.500
We're getting the shortest path from A to 
every other vertex, so technically we're  

335

00:39:46.500  -->  00:39:51.780
getting the shortest path to the vertex we set 
as a destination, so instead of returning the  

336

00:39:51.780  -->  00:39:57.720
whole dist and prev table, we return results 
for that specific destination only. We return  

337

00:39:58.260  -->  00:40:03.360
dist[destination], and the shortest path itself, 
that we can get with the reconstruct function.  

338

00:40:04.260  -->  00:40:10.020
We can even stop in the while loop as soon as we 
reach the destination vertex, we don't need to  

339

00:40:10.020  -->  00:40:15.900
continue remaining ones. Remember that as soon 
as we reach a vertex in Dijkstra's algorithm,  

340

00:40:15.900  -->  00:40:22.560
then we found its shortest path, we know that we 
won't find something better later, remember the  

341

00:40:22.560  -->  00:40:29.040
first liquid that reaches a vertex example. So in 
the while loop, if the vertex we extract is the  

342

00:40:29.040  -->  00:40:35.460
destination, we break, the result will be returned 
just after it. The time complexity doesn't change.  

343

00:40:37.020  -->  00:40:43.260
What about the All-pairs shortest path 
problem? Yes, it's also possible to solve  

344

00:40:43.260  -->  00:40:48.180
it by using Dijkstra's algorithm, we'll 
see it in the Johnson's algorithm lecture.  

345

00:40:50.460  -->  00:40:57.420
Last question: does Dijkstra's algorithm work with 
all types of graphs? Well, nope. First problem,  

346

00:40:57.420  -->  00:41:04.320
negative cycles. Imagine that we have this graph 
and we apply Dijkstra's algorithm, here are the  

347

00:41:04.320  -->  00:41:11.760
results we get. We got that the shortest distance 
from A to E is 7, by taking the path A->B->E-.  

348

00:41:11.760  -->  00:41:16.560
Which is wrong, by looping over the 
cycle BCD, we can decrease it to 4,  

349

00:41:16.560  -->  00:41:22.260
because the sum of weights of the cycle 
BCD is negative, BCD is a negative cycle.  

350

00:41:23.520  -->  00:41:28.800
Once again, we can loop over it again and 
decrease the distance from A to B to 1.  

351

00:41:29.640  -->  00:41:36.240
One more turn and we can make it -2. And we 
can continue like this to infinity, so we don't  

352

00:41:36.240  -->  00:41:42.000
really have a shortest path from A to B, we can 
always add one more turn and get a shorter path.  

353

00:41:43.500  -->  00:41:49.500
It's because of the negative cycle, so Dijkstra's 
algorithm doesn't work with graphs that contain  

354

00:41:49.500  -->  00:41:57.120
negative cycles. Actually, the negative cycle 
problem is not proper to Dijkstra's algorithm,  

355

00:41:57.120  -->  00:42:04.020
it causes issues with the shortest path problem 
in general, even with other algorithms. However,  

356

00:42:04.020  -->  00:42:10.260
unlike other algorithms like Bellman-Ford that can 
detect that there is a negative cycle, Dijkstra's  

357

00:42:10.260  -->  00:42:15.660
algorithm doesn't even detect it, it continues 
to run normally and returns the wrong result.  

358

00:42:18.360  -->  00:42:24.000
Are negative cycles the only issue with 
Dijkstra's? No. Let's take this graph and apply  

359

00:42:24.000  -->  00:42:31.800
the algorithm. We start with 0 infinity infinity 
infinity. We extract A, it updates dist[B] to 5  

360

00:42:31.800  -->  00:42:40.680
and dist[C] to 7. Unvisited vertex with smallest 
dist is B, we extract it. We did because we assume  

361

00:42:40.680  -->  00:42:46.260
that we found the shortest path to it, now we're 
assuming that the shortest distance from A to B is  

362

00:42:46.260  -->  00:42:55.440
5. But let's continue and see what happens. 
B updates dist[D] to 8. Then we extract C,  

363

00:42:55.440  -->  00:43:02.160
it updates dist[B] to 3. Then we extract 
D, no out-neighbor, and the algorithm ends.  

364

00:43:03.300  -->  00:43:09.720
The result says that the shortest distance from 
A to D is 8, which is wrong, it's 6, by taking  

365

00:43:09.720  -->  00:43:16.260
A-C-B-D. It's because when we extracted B, we 
assumed that we found the shortest path to it,  

366

00:43:16.260  -->  00:43:22.440
we didn't know that it was possible to find a 
shorter path later. All of this because of this  

367

00:43:22.440  -->  00:43:29.700
negative edge, it made our assumption wrong. And 
this is why Dijkstra's algorithm doesn't work well  

368

00:43:29.700  -->  00:43:35.820
with negative edges, it might still give the right 
result, but it might not, like with this example.  

369

00:43:38.520  -->  00:43:44.040
If we have only positive edges, this problem 
doesn't happen, because the distance can only  

370

00:43:44.040  -->  00:43:50.040
increase, which is not the case with negative 
weights, a negative edge that comes way later can  

371

00:43:50.040  -->  00:43:54.780
decrease dist of a vertex that we extracted 
before, which can produce wrong results.  

372

00:43:55.740  -->  00:43:59.820
This is why we say that Dijkstra's 
algorithm shouldn't be used on a  

373

00:43:59.820  -->  00:44:03.600
graph with negative weights, even 
if it doesn't have negative cycles.  

374

00:44:04.620  -->  00:44:10.080
But there are algorithms that solve the 
same problem as Dijkstra's and can handle  

375

00:44:10.080  -->  00:44:15.720
negative weights, like the one we will see 
in the next lecture: Bellman-Ford algorithm.  

376

00:44:18.120  -->  00:44:21.000
I hope that you understood 
this lecture, as always,  

377

00:44:21.000  -->  00:44:26.040
ask questions if you didn't understand 
something. See you in the next lecture!
