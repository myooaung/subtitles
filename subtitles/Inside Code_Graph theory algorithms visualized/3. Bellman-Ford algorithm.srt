1

00:00:00,120  -->  00:00:05,580
In the last lecture, we discussed Dijkstra's 
algorithm, but it had some problems with negative  

2

00:00:05,580  -->  00:00:11,940
weights and negative cycles. What if we have a 
graph with negative weights? We cannot find the  

3

00:00:11,940  -->  00:00:17,940
shortest path? No, we have alternatives that 
handle this, like the algorithm we will see  

4

00:00:17,940  -->  00:00:24,900
in this lecture: The Bellman-Ford algorithm. 
The way this lecture will be organized is:  

5

00:00:24,900  -->  00:00:30,780
We will start by stating the global idea of 
the algorithm, see an example, implement it,  

6

00:00:30,780  -->  00:00:39,960
then we will see a more detailed explanation, and 
we finish the lecture by analyzing complexity. The  

7

00:00:39,960  -->  00:00:46,080
Bellman-Ford algorithm solves the same problem as 
Dijkstra's algorithm: The single-source shortest  

8

00:00:46,080  -->  00:00:52,260
path problem, we're given a start vertex, and 
we want the shortest path to all other vertices.  

9

00:00:54,840  -->  00:01:00,120
Another common aspect of Bellman-Ford and 
Dijkstra's is the use of edge relaxation,  

10

00:01:00,120  -->  00:01:07,980
we will use it here also. Edge relaxation 
is when we have a map dist where dist[v]  

11

00:01:07,980  -->  00:01:14,400
represents the shortest path from source to v. 
Let's say dist[C] is currently 24, because we  

12

00:01:14,400  -->  00:01:21,480
found a path that takes us from source to v with 
a total distance of 24. Then we find an edge (D,  

13

00:01:21,480  -->  00:01:29,040
C) such that dist[D]+w(D,C) is smaller than 
dist[C], it means that we found a shorter way  

14

00:01:29,040  -->  00:01:36,300
to go to C, by going to D then taking the edge 
(D, C), here we update dist[C] by dist[D]+w(D,C).  

15

00:01:40,620  -->  00:01:49,440
What we're doing here is relaxation. Okay, but how 
does Bellman-Ford algorithm work? Imagine that we  

16

00:01:49,440  -->  00:01:57,180
have this graph of 8 vertices, and we want to find 
the shortest path from A to each vertex. First of  

17

00:01:57,180  -->  00:02:04,380
all, in a graph of n vertices, any path has a 
length of at most n-1. Which means that here,  

18

00:02:04,380  -->  00:02:11,220
the maximum length of a shortest path is 7. I said 
the length, the number of edges, not the weight.  

19

00:02:13,260  -->  00:02:19,440
What does it mean? Here we have 8 vertices, so 
there exist 8 paths that we're searching for,  

20

00:02:19,440  -->  00:02:23,280
the one from A to A, the one 
from A to B, A to C...etcetera.  

21

00:02:25,080  -->  00:02:33,660
And each one of them can have a length of 0, 
1, 2, and so on until 7. But you may tell me,  

22

00:02:33,660  -->  00:02:40,080
if we have a cycle we can have a path of length 
greater than n-1, it can even be infinite.  

23

00:02:40,860  -->  00:02:48,060
That's true, but by path we mean ones that don't 
pass from the same vertex twice. Because ones  

24

00:02:48,060  -->  00:02:54,480
that do, paths that contain a cycle, will not 
be in the final result, let me tell you why.  

25

00:02:56,160  -->  00:03:00,840
If the cycle has a positive weight, then 
it's just increasing our path's weight,  

26

00:03:00,840  -->  00:03:06,900
which makes it not the shortest path. If the 
cycle has a weight of 0, then it's useless,  

27

00:03:06,900  -->  00:03:13,620
we can just remove it and still get the same total 
weight. Else if it has a negative weight, it's  

28

00:03:13,620  -->  00:03:19,440
true that it's decreasing our path's total weight, 
but negative weight cycles are not allowed.  

29

00:03:22,620  -->  00:03:29,160
If you understood this, we can continue. The 
Bellman-Ford algorithm is based on the fact  

30

00:03:29,160  -->  00:03:34,560
that if we relax all the edges k times, 
we're guaranteed to have shortest paths  

31

00:03:34,560  -->  00:03:43,020
of at most k edges. And because paths lengths 
cannot exceed n-1, repeating the operation n-1  

32

00:03:43,020  -->  00:03:50,520
times is guaranteed to produce shortest paths 
of at most n-1 edges, which is the maximum a  

33

00:03:50,520  -->  00:03:56,580
valid shortest path could have in a graph, so it 
produces the shortest paths we're searching for.  

34

00:03:58,800  -->  00:04:05,040
Let's take this graph as an example. Same 
as Dijkstra's, at the beginning the shortest  

35

00:04:05,040  -->  00:04:10,860
distance from the source, A, to itself 
is 0, and infinity to all other vertices.  

36

00:04:12,600  -->  00:04:18,120
Now first iteration, we relax 
all edges once. For example for  

37

00:04:18,120  -->  00:04:26,580
the edge (A, B, 3), dist[B] is infinity while 
dist[A]+w(A,B) is 0+3, 3, smaller, we update.  

38

00:04:28,800  -->  00:04:37,500
Same thing for (A, C, 12), dist[C] becomes 
12. All other edges didn't have an impact,  

39

00:04:37,500  -->  00:04:44,520
because for example for (D, F, 5), inifnity+5 
is not smaller than infinity, no update.  

40

00:04:47,100  -->  00:04:53,340
We finished with the first iteration, we're now 
guaranteed to have all shortest paths of length 1.  

41

00:04:54,480  -->  00:04:59,760
But it's not enough, some paths we're 
searching for may have a length greater than 1.  

42

00:05:00,540  -->  00:05:08,880
Let's move to the second iteration. We relax 
all edges. Some edges will not have an impact,  

43

00:05:08,880  -->  00:05:17,280
like (D, F, 5) once again, but some edges will. We 
have (C, E, 3), it decreases dist[E] from infinity  

44

00:05:17,280  -->  00:05:26,820
to 15. Also (B, C, 6), it decreases dist[C] 
from 12 to 9. Also (B, D, 2), it decreases  

45

00:05:26,820  -->  00:05:35,160
dist[D] from infinity to 5. And finally (B, 
E, 11), it decreases dist[E] from 15 to 14.  

46

00:05:37,680  -->  00:05:43,560
We finished the iteration, we're guaranteed 
to have all shortest paths of at most 2 edges.  

47

00:05:44,460  -->  00:05:53,100
But we can find shorter paths by using 3 edges, 
let's add an iteration. Let's relax all edges.  

48

00:05:54,600  -->  00:06:02,520
Some edges will not have an impact, like 
(D, E, 10). dist[D]+w(D, E) is 5+10, 15,  

49

00:06:02,520  -->  00:06:08,880
but it does not update, because we already 
know how to go to E with less than 15.  

50

00:06:10,620  -->  00:06:17,280
But some of them will. We have (D, F, 5), 
it decreases dist[F] from infinity to 10,  

51

00:06:17,280  -->  00:06:22,200
it's the first path that have been 
able to reach F, and we waited until  

52

00:06:22,200  -->  00:06:28,380
iteration 3 to find it, it means that we 
need at least 3 edges to go from A to F.  

53

00:06:30,780  -->  00:06:37,980
We also have (C, E, 3), it decreases 
dist[E] from 14 to 12. We deduce that for E,  

54

00:06:37,980  -->  00:06:45,300
allowing paths of 3 edges gave us a shorter path 
than when we had only 2 edges. With 2 edges,  

55

00:06:45,300  -->  00:06:52,500
we can go to E with a distance of at least 14, 
but with 3 edges, we can go with a distance of 12.  

56

00:06:55,500  -->  00:07:04,440
Let's continue, we may have shorter paths with 
4 edges, so we add an iteration. We relax all  

57

00:07:04,440  -->  00:07:11,580
the edges. Edges that will have an impact are 
these ones: (F, H, 13) will decrease dist[H]  

58

00:07:11,580  -->  00:07:20,340
from infinity to 23. (F, G, 6) will decrease 
dist[G] from infinity to 16. And (F, E, -2) will  

59

00:07:20,340  -->  00:07:27,540
decrease dist[E] from 12 to 8, by allowing paths 
of length 4, we found a shorter path to go to E.  

60

00:07:31,080  -->  00:07:38,580
We may have shorter paths with length 5, so 
let's add an iteration. We relax all the edges,  

61

00:07:38,580  -->  00:07:45,600
and the only edge that will have an impact is 
(G, H, 4), it decreases dist[H] from 23 to 20.  

62

00:07:47,520  -->  00:07:55,200
Let's add an iteration for paths of length 6. 
We relax all the edges, and nothing changes,  

63

00:07:55,200  -->  00:07:59,280
there is no edge that will give us 
a shorter path to its destination.  

64

00:08:00,540  -->  00:08:06,240
It means that we're done, we found all 
shortest paths, useless to continue,  

65

00:08:06,240  -->  00:08:11,280
all shortest paths have a length 
of at most 5, and we found them.  

66

00:08:13,080  -->  00:08:20,220
We're done, we officially have the shortest path 
from A to any vertex. And you can see that they  

67

00:08:20,220  -->  00:08:26,220
differ in length, for example shortest path from A 
to C has a length of 2, we found it at the second  

68

00:08:26,220  -->  00:08:34,680
iteration. The one from A to E has a length of 4, 
we found it at the iteration 4. And this is why we  

69

00:08:34,680  -->  00:08:41,640
need multiple iterations, each iteration allows 
us to find potential shorter paths with one more  

70

00:08:41,640  -->  00:08:50,580
edge, until either we do n-1 iterations or nothing 
changes anymore. And this is how Bellman-Ford  

71

00:08:50,580  -->  00:08:57,060
algorithm works, we keep relaxing all edges 
until no update is done in the current iteration.  

72

00:09:02,760  -->  00:09:07,080
Let's implement it. We have the 
graph, and the source vertex.  

73

00:09:07,860  -->  00:09:14,760
We need the list of edges, we extract them by 
traversing the adjacency list. Then we create  

74

00:09:14,760  -->  00:09:21,600
dist map where dist[v] is the shortest distance 
from source to v. Initially we put infinity for  

75

00:09:21,600  -->  00:09:29,460
all vertices except the source, for which we 
put 0. Then, we gonna do at most n-1 iterations,  

76

00:09:29,460  -->  00:09:36,720
so we use a for loop that gets repeated n-1 times, 
where n is the number of vertices of the graph.  

77

00:09:38,040  -->  00:09:44,160
Inside it, we put a boolean variable changed, to 
see if something changes during the iteration.  

78

00:09:45,180  -->  00:09:53,220
It's initially false, then if an update 
happens, we set it to true. Now we relax edges,  

79

00:09:53,220  -->  00:10:00,780
for each edge (u, v, w), as we were doing, 
if dist[u]+w is smaller than dist[v], we  

80

00:10:00,780  -->  00:10:09,000
update dist[v] by assigning dist[u]+w. And we set 
changed to true, to know that an update happened.  

81

00:10:11,340  -->  00:10:14,820
After relaxing all the edges, if nothing changed,  

82

00:10:14,820  -->  00:10:23,340
we break the loop for an early exit, useless 
to continue. After the loop, we return dist.  

83

00:10:27,360  -->  00:10:32,820
I know that I didn't talk about reconstructing 
the path and negative weights and negative cycles,  

84

00:10:32,820  -->  00:10:39,120
I'll do it later. But before, it's possible that 
you're not totally convinced of how and why the  

85

00:10:39,120  -->  00:10:44,940
algorithm works, this is why I want to explain 
to you the dynamic programming aspect of this  

86

00:10:44,940  -->  00:10:53,040
algorithm. Okay, we have this graph, and we're 
searching for the shortest distance from A to any  

87

00:10:53,040  -->  00:11:00,480
other vertex. We have 8 vertices, so the maximum 
length of a path is 7. Which means that we're  

88

00:11:00,480  -->  00:11:06,840
searching for the shortest distance from A to 
any other vertex with a path of at most 7 edges.  

89

00:11:10,080  -->  00:11:15,300
We want to calculate all these values, 
we want to calculate d(v,7) for each  

90

00:11:15,300  -->  00:11:20,520
vertex v such that d(v,k) represents 
the shortest distance from the source  

91

00:11:20,520  -->  00:11:25,020
to the vertex v by using a path whose 
length is smaller than or equal to k.  

92

00:11:27,960  -->  00:11:33,690
Let's assume that we have the shortest distance 
from A to any other vertex with a path of at  

93

00:11:33,690  -->  00:11:41,520
most 6 edges, we have the value of d(v, 6) for 
any vertex v, and we want to calculate d(E, 7).  

94

00:11:43,680  -->  00:11:50,220
We have multiple possibilities for the shortest 
path to E of at most 7 edges: We can either,  

95

00:11:50,220  -->  00:11:57,840
take the shortest path to E of at most 6 edges, 
which is ABDFE, and change nothing, or take the  

96

00:11:57,840  -->  00:12:03,000
shortest path to one of its in-neighbours 
of at most 6 edges and add the last edge,  

97

00:12:03,000  -->  00:12:13,140
the one that goes to E. E has 4 in_neighbours, B 
C D and F. So in total, we have 5 possibilities:  

98

00:12:13,140  -->  00:12:19,710
keep ABDFE, take AB and add the edge 
(B, E), take ABC and add the edge (C,  

99

00:12:19,710  -->  00:12:25,920
E), take ABD and add the edge (D, E), 
take ABDF and add the edge (F, E).  

100

00:12:28,440  -->  00:12:32,820
How to choose? We simply take the 
one with the smallest total weight.  

101

00:12:33,480  -->  00:12:41,700
For ABDFE it's 8, for AB + the edge (B, 
E) it's 3+11, 14, for ABC + the edge (C,  

102

00:12:41,700  -->  00:12:50,670
E) it's 9+3, 12, for ABD + the edge (D, E) 
it's 5+10, 15, and for ABDF + the edge (F,  

103

00:12:50,670  -->  00:13:01,080
E) it's 10-2, 8. The min is 8, that we can 
get by keeping ABDFE, or going to F then to E.  

104

00:13:04,800  -->  00:13:11,040
What we did here is that to calculate d(E, 7), 
we took the min between d(E, 6), and the min  

105

00:13:11,040  -->  00:13:21,900
between d(u, 6)+w(u,E) for each in-neighbor u of 
E. Here we assumed that we had those values, but  

106

00:13:21,900  -->  00:13:29,640
in reality to get them, we do the same recursive 
operation, it's a recursive process. In general,  

107

00:13:29,640  -->  00:13:36,360
we have that the shortest distance from source to 
a vertex v with a path of at most k edges, d(v,k),  

108

00:13:36,360  -->  00:13:46,080
is the min between d(v, k-1), and the min between 
d(u, k-1)+w(u, v) for each in-neighbor u of v.  

109

00:13:50,640  -->  00:13:56,580
We have a recursive formula, what about the 
base case? The base case is when k is 0,  

110

00:13:56,580  -->  00:14:04,800
with a path of 0 edges, the minimum distance is 
easy to calculate, it's 0 if v is the source, and  

111

00:14:04,800  -->  00:14:13,320
infinity if it's not, remember the initialization 
step. And we get this recurrence relation: d(v,k)  

112

00:14:13,320  -->  00:14:20,580
is equal to: 0 if k is 0 and v is equal to source, 
infinity if k is 0 and v is not equal to source,  

113

00:14:20,580  -->  00:14:30,300
else it's min(d(v,k-1), min({d(u,k-1)+w(u,v) 
| u is an in-neighbor of v})).  

114

00:14:35,400  -->  00:14:41,460
We can easily turn this recurrence relation into 
code, we take as parameters the transpose graph,  

115

00:14:41,460  -->  00:14:49,380
the source vertex, v, and k. We need the transpose 
graph and not the graph itself to be able to  

116

00:14:49,380  -->  00:14:57,480
traverse in-neighbours not out-neighbours. If 
k is 0 and v is equal to the source, return 0,  

117

00:14:57,480  -->  00:15:04,800
else if k is 0 and v is not equal to the source, 
return infinity. Else, return min(d(v,k-1),  

118

00:15:06,360  -->  00:15:13,920
and min between d(u,k-1)+w(u,v) for each 
in-neighbor u of v with an edge weight w.  

119

00:15:17,820  -->  00:15:22,080
We can also write it this this way if you're 
not comfortable with list comprehension,  

120

00:15:22,080  -->  00:15:30,960
we set d(v,k-1) as the min, then we traverse 
in-neighbors u to see if d(u,k-1)+w(u,v) replaces.  

121

00:15:31,620  -->  00:15:40,020
And we return the min distance. What do we 
do with this function now? Well, we can use  

122

00:15:40,020  -->  00:15:45,720
it to calculate shortest path from source to 
vertices of the graph. We have a function sssp,  

123

00:15:45,720  -->  00:15:50,940
single source shortest path, that takes 
as parameters the graph, and the source.  

124

00:15:52,200  -->  00:15:58,080
We create the transpose graph by reversing all 
the edges, an edge (u,v) becomes an edge (v,u).  

125

00:15:58,980  -->  00:16:06,000
Then, the maximum number of edges of a path is 
n-1, so we call the function we made with n-1  

126

00:16:06,000  -->  00:16:12,900
on each vertex v, and we store results in 
dist map, that we return after finishing.  

127

00:16:13,740  -->  00:16:19,140
And we got the shortest distance from 
source to any vertex, by using recursion.  

128

00:16:21,840  -->  00:16:27,900
Okay then why would we need Bellman-Ford 
algorithm?. Well, because this function is slow,  

129

00:16:27,900  -->  00:16:33,360
it's exponential, each call may need 
the result of multiple other calls.  

130

00:16:35,040  -->  00:16:40,140
Let's see why. Let's draw a part of 
the recursion tree for one vertex call,  

131

00:16:40,140  -->  00:16:48,480
d(E,7). We needed the result of d(E,6), 
d(B,6), d(C,6), d(D,6), and d(F,6).  

132

00:16:49,560  -->  00:16:50,730
And d(E,6) needs the result of d(E,5), d(B,5), 
d(C,5), d(D,5), and d(F,5). d(B,6) needs the  

133

00:16:50,730  -->  00:16:50,830
result of d(B,5), d(A,5), and d(F,5). d(C,6) needs 
the result of d(C,5), d(A,5), and d(B,5). d(D,6)  

134

00:16:50,830  -->  00:17:19,860
needs the result of d(D,5) and d(B,5). And d(F,6) 
needs the result of d(F,5), d(D,5), and d(H,5).  

135

00:17:21,720  -->  00:17:27,120
Remaining levels of the tree will get 
wider and wider, until k becomes 0.  

136

00:17:29,100  -->  00:17:34,440
Without even seeing them, we can already notice 
something interesting from this part of the tree,  

137

00:17:34,440  -->  00:17:40,380
it's that we have repeated recursive calls, we're 
doing the same computations again and again.  

138

00:17:41,760  -->  00:17:48,240
To avoid this, we use dynamic programming, an 
algorithmic technique that optimizes recursive  

139

00:17:48,240  -->  00:17:53,520
functions when the same calls are done 
multiple times, like it's the case here.  

140

00:17:55,500  -->  00:18:02,100
What we want is that when we solve a subproblem, 
in other terms, when we get the result of a call,  

141

00:18:02,100  -->  00:18:07,500
we store it somewhere so that the next time 
we need it, we don't compute it from scratch,  

142

00:18:07,500  -->  00:18:11,460
we directly take the result from 
the structure where we stored it,  

143

00:18:12,240  -->  00:18:19,020
this is dynamic programming. And we have two 
approaches: The top-down approach, memoization,  

144

00:18:19,020  -->  00:18:25,320
and the bottom-up approach, tabulation. 
In memoization we keep the recursive form  

145

00:18:25,320  -->  00:18:30,480
of the function, we just add a hash table 
where we store the results of subproblems,  

146

00:18:30,480  -->  00:18:40,140
the key is what characterizes a subproblem and the 
value is its result. And in tabulation, we build  

147

00:18:40,140  -->  00:18:45,660
an n-dimensional table, whose the dimension 
and the size depends on the shape and number  

148

00:18:45,660  -->  00:18:52,440
of subproblems, then we fill it, and we find the 
result of the initial problem in the last cells.  

149

00:18:54,600  -->  00:18:59,940
Let's go with tabulation, it's more suitable 
for this problem because we need to solve all  

150

00:18:59,940  -->  00:19:07,260
possible subproblems. Okay but what will 
be the shape and size of our dp table?  

151

00:19:09,540  -->  00:19:16,920
First of all, here a subproblem is characterized 
by two things: The destination vertex, v, and the  

152

00:19:16,920  -->  00:19:24,060
number of allowed edges, k. The source is always 
the same, A in our example, so we don't count  

153

00:19:24,060  -->  00:19:32,160
it. This is why we will have a 2D table, rows will 
represent values of k, and columns will represent  

154

00:19:32,160  -->  00:19:41,340
the different values of v, the vertices. Paths 
can be of length 0, 1, and so on until n-1, so we  

155

00:19:41,340  -->  00:19:50,700
have n rows. And we have n vertices, so we have 
n columns. Our dp table will be of size n by n.  

156

00:19:53,040  -->  00:19:59,760
And dp[k][v] represents the result of d(v, k), 
the shortest distance from the source to v by  

157

00:19:59,760  -->  00:20:06,240
using at most k edges. So what we're searching 
for is results of the last row of the table,  

158

00:20:06,240  -->  00:20:12,660
they represent shortest distance from 
source to each vertex, all values d(v,n-1).  

159

00:20:16,320  -->  00:20:23,700
But to get them, we need to fill the table, how 
to do so? Well, we will just use the recurrence  

160

00:20:23,700  -->  00:20:30,480
relation. The base case is when k is 0, where 
we put 0 if v is equal to source, and infinity  

161

00:20:30,480  -->  00:20:38,700
otherwise. We do exactly the same thing to 
fill dp[0], we put 0 if v is equal to source,  

162

00:20:38,700  -->  00:20:47,220
which is the case for A, and infinity in others. 
And for remaining rows, we use the recursive case.  

163

00:20:48,900  -->  00:20:54,720
We know that d(v, k) is min between 
d(v,k-1), and min between d(u,k-1)+w(u,v)  

164

00:20:56,640  -->  00:21:04,020
for each in-neighbour u of v. And here, same 
thing, dp[k][v] is min between d[k-1][v],  

165

00:21:04,920  -->  00:21:11,940
and min between d[k-1][u]+w(u,v) for 
each in-neighbour u of v, very simple.  

166

00:21:14,760  -->  00:21:20,040
By applying these formulas to our example, 
this is how the table gets filled.  

167

00:21:23,940  -->  00:21:30,120
And as you can see, the last row represents 
the shortest distance from A to each vertex,  

168

00:21:30,120  -->  00:21:33,660
the same result as with 
the Bellman-Ford algorithm.  

169

00:21:37,980  -->  00:21:42,780
It's because Bellman-Ford algorithm is 
based on this dynamic programming idea.  

170

00:21:44,640  -->  00:21:50,280
Let's implement this solution. We start by 
calculating the transpose graph, we will  

171

00:21:50,280  -->  00:21:57,300
need it to find in-neighbours. Then we create 
a dp table of size n by n, but for the second  

172

00:21:57,300  -->  00:22:03,360
dimension we use a hash map rather than an array 
to be able to have the vertex label as the key.  

173

00:22:05,460  -->  00:22:10,500
We start by filling the first row, 
dp[0]. We traverse vertices v,  

174

00:22:10,500  -->  00:22:16,320
and we put 0 in dp[0][v] if v is 
equal to source, else we put infinity.  

175

00:22:18,660  -->  00:22:26,460
Now we traverse remaining rows, this is why k 
starts at 1. For each row, we traverse vertices v.  

176

00:22:27,120  -->  00:22:31,920
For each vertex v, we use that formula 
and assign the result to dp[k][v].  

177

00:22:33,960  -->  00:22:39,060
After the loop, we return the last row of 
dp, it's the result we've been searching for.  

178

00:22:40,020  -->  00:22:42,960
We implemented the dynamic programming solution.  

179

00:22:45,120  -->  00:22:51,060
However, let's change a few things. For example, 
we're not really obliged to work with a 2D table,  

180

00:22:51,060  -->  00:22:57,480
a 1D table would do the job, we can use only 
one row that we keep updating instead of a  

181

00:22:57,480  -->  00:23:04,620
whole matrix. The signification of a cell will 
slightly change, but we still get the same result.  

182

00:23:06,720  -->  00:23:12,240
Also, instead of using min function, we can 
traverse in-neighbors and use a condition:  

183

00:23:12,240  -->  00:23:20,820
If dp[u]+w is smaller than dp[v], we update 
dp[v] by putting dp[u]+w, same result.  

184

00:23:22,140  -->  00:23:27,840
Another thing, at each iteration, we're 
traversing vertices and for each vertex we're  

185

00:23:27,840  -->  00:23:33,420
traversing its in-neighbors, so actually we're 
just traversing all the edges at each iteration.  

186

00:23:34,140  -->  00:23:40,680
This is why, we can directly traverse all the 
edges (u, v, w) and still get the job done.  

187

00:23:42,780  -->  00:23:47,940
Notice that we don't need the transpose 
graph anymore, but we need the list of edges.  

188

00:23:51,120  -->  00:23:55,140
We're just making small changes to the 
code that still give the same result guys.  

189

00:23:59,220  -->  00:24:06,240
We can use the name dist instead of dp. Another 
thing, we can add a boolean variable changed,  

190

00:24:06,240  -->  00:24:12,360
to stop as soon as nothing changes during a whole 
iteration, to avoid adding useless iterations.  

191

00:24:13,560  -->  00:24:18,720
And as you can see, we got our Bellman-Ford 
implementation we've seen at the beginning,  

192

00:24:18,720  -->  00:24:23,160
we've been able to produce it 
by using dynamic programming.  

193

00:24:27,000  -->  00:24:34,020
However, two things are missing: Being able to 
reconstruct the path, and handle negative cycles.  

194

00:24:34,020  -->  00:24:41,340
Because here, we will just have the distance, not 
the path itself. This is why we should have also  

195

00:24:41,340  -->  00:24:48,240
added prev map, same as in Dijkstra's algorithm. 
prev[v] represents the previous vertex of v in  

196

00:24:48,240  -->  00:24:55,500
its shortest path. Then if an update happens, if 
dist[u]+w is smaller than v, it means that to go  

197

00:24:55,500  -->  00:25:01,800
to v, we will pass from u, this is why u becomes 
the previous vertex of v, same as in Dijkstra's.  

198

00:25:03,300  -->  00:25:08,940
After the loop we return both dist and prev, 
and if we want to find the distance we use dist,  

199

00:25:08,940  -->  00:25:14,400
and if we want to reconstruct the path, we use 
the function we used in Dijkstra's to reconstruct  

200

00:25:14,400  -->  00:25:22,320
the path from source to a chosen vertex. We keep 
going back and we reverse the path at the end.  

201

00:25:24,240  -->  00:25:29,820
What about negative weights? Well, as you could 
see in the example, there was no problem with  

202

00:25:29,820  -->  00:25:36,660
negative weights, Bellman-Ford algorithm handles 
negative weights perfectly. Except when we have  

203

00:25:36,660  -->  00:25:41,820
negative cycles, because when we do, it's 
not even possible to have a shortest path,  

204

00:25:41,820  -->  00:25:49,440
we can always add one cycle traversal to decrease 
the total weight. However, we can detect it with  

205

00:25:49,440  -->  00:25:55,380
Bellman-Ford algorithm. After the iterations, 
we need to traverse edges one more time.  

206

00:25:55,980  -->  00:26:03,300
For each edge (u, v, w), if dist[u]+w is smaller 
than dist[v], then we have a negative cycle.  

207

00:26:04,260  -->  00:26:09,900
How can it be possible? Let's say we allow 
passing from the same vertex more than once.  

208

00:26:09,900  -->  00:26:14,760
You need to know that if we have a path 
from u to v that has more than n-1 edges,  

209

00:26:14,760  -->  00:26:21,060
then there must be a cycle in it, it must pass 
from a vertex more than once, here is an example.  

210

00:26:22,440  -->  00:26:28,980
Our actual shortest paths have a length of 
at most n-1, because we did n-1 iterations.  

211

00:26:29,640  -->  00:26:36,420
But, can we add cycle to make them shorter? 
Well, if it's a positive weight cycle, then it  

212

00:26:36,420  -->  00:26:41,820
will increase the weight of our shortest path, 
we don't want it. If it's a zero weight cycle,  

213

00:26:41,820  -->  00:26:46,620
then it's useless, it doesn't make it 
shorter. The only case where it's worth  

214

00:26:46,620  -->  00:26:52,200
it is when it's a negative weight cycle, 
adding it to our path decreases its weight.  

215

00:26:53,100  -->  00:26:59,100
And this is why if we have a path that is shorter 
than our at most n-1 length shortest paths,  

216

00:26:59,100  -->  00:27:04,380
then it contains a negative cycle, we will 
know that the graph contains a negative cycle.  

217

00:27:05,340  -->  00:27:10,920
This is why the loop detects them, the loop checks 
if there is a shorter path of length greater than  

218

00:27:10,920  -->  00:27:19,320
n-1, because if there is, then we have a negative 
cycle. Here is an example, we have this graph,  

219

00:27:19,320  -->  00:27:25,020
and after the n-1 iterations, we add a last 
one to see if there is a negative cycle.  

220

00:27:26,880  -->  00:27:32,220
We check the condition with edges, and you can 
see that it worked with one, the edge (E, D).  

221

00:27:33,180  -->  00:27:37,380
So we have a negative weight 
cycle, it's the cycle DFE.  

222

00:27:39,660  -->  00:27:46,560
In code, we add this loop that traverses edges 
one last time. If the condition is true, we can  

223

00:27:46,560  -->  00:27:52,380
for example return null for both dist and prev to 
say that there's a negative cycle in the graph.  

224

00:27:53,220  -->  00:27:57,780
And we got our full implementation 
of Bellman-Ford algorithm.  

225

00:28:01,680  -->  00:28:06,120
If you're not familiar with dynamic 
programming and this explanation wasn't enough,  

226

00:28:06,120  -->  00:28:11,640
I have a last approach to let you understand 
the algorithm, I found it on stackexchange.  

227

00:28:13,020  -->  00:28:19,380
Imagine that we have a digital door lock with a 
four-digit code. And this lock allows not writing  

228

00:28:19,380  -->  00:28:26,100
the code all at once, having characters between 
characters of the code is fine. For example if the  

229

00:28:26,100  -->  00:28:36,660
code is 2749 and we write 32675049, the lock would 
still get opened because 2749 is a subsequence.  

230

00:28:39,180  -->  00:28:45,120
Knowing this information, you want to open 
the door, without entering a lot of digits  

231

00:28:45,120  -->  00:28:52,800
if possible. A possible way is to simply type 
the 10000 possible codes one after the other,  

232

00:28:52,800  -->  00:29:01,260
we're guaranteed to open the lock. But, we'd 
need to write 40000 digits, too long. A smarter  

233

00:29:01,260  -->  00:29:08,340
way is this one: We write all digits once. Here 
we're guaranteed to have all codes of length 1.  

234

00:29:08,340  -->  00:29:16,140
But, it's not enough, we want to have all codes 
of length 4. We write all digits again. Now we're  

235

00:29:16,140  -->  00:29:24,840
guaranteed to have all codes of length 2: 00, 
01, 02...and so on. Then again, we write all  

236

00:29:24,840  -->  00:29:30,300
the digits. Now we're guaranteed to have all 
codes of length 3, you can check by yourself.  

237

00:29:31,200  -->  00:29:37,620
Last iteration, we write all the digits. And now 
we're guaranteed to have all codes of length 4,  

238

00:29:37,620  -->  00:29:45,000
enough to open the door. You can try any code of 
length 4 and you will find it here, we've been  

239

00:29:45,000  -->  00:29:53,460
able to do that by writing 40 digits only, instead 
of 40000, because we avoided repeating work.  

240

00:29:57,420  -->  00:30:03,780
It's a perfect analogy for Bellman-Ford algorithm. 
We write all the digits a kth time and we're  

241

00:30:03,780  -->  00:30:09,720
guaranteed to have all codes of length of at 
most k digits, and in Bellman-Ford, we try to  

242

00:30:09,720  -->  00:30:15,840
relax all edges a kth time and we're guaranteed 
to have all shortest paths of at most k edges.  

243

00:30:17,580  -->  00:30:23,580
This is why we try to relax all edges multiple 
times, to make sure to traverse all possible  

244

00:30:23,580  -->  00:30:29,760
paths starting from the vertex A, while keeping 
track of the shortest one for each destination v.  

245

00:30:33,300  -->  00:30:36,720
Last thing to talk about in 
this lecture: Time complexity.  

246

00:30:38,220  -->  00:30:43,260
Extracting edges costs |V|+|E| because 
we traverse the adjacency list.  

247

00:30:43,980  -->  00:30:50,760
We also have |V| to create dist map, |V| to 
create prev map, and |V| to fill dist map.  

248

00:30:52,560  -->  00:30:58,080
Then we repeat the same operation c times, 
where c is the number of iterations before  

249

00:30:58,080  -->  00:31:07,740
the process stops, it's between 1 and |V|-1. 
Inside it, we traverse all the edges, |E| cost.  

250

00:31:08,520  -->  00:31:18,360
After it, we traverse edges one more time, 
|E| cost. In total, we have 4|V|+(c+2)|E|.  

251

00:31:19,920  -->  00:31:28,080
In the worst case, we need to perform |V|-1 
iterations, c is |V|-1. We replace, and we  

252

00:31:28,080  -->  00:31:41,100
get 4|V|+(|V|+1)|E|, which gives a time complexity 
of O(|V||E|). But in the best case, c is only 1,  

253

00:31:41,100  -->  00:31:49,140
the process stops at the first iteration. We 
replace, and we get 4|V|+3|E|, which gives a  

254

00:31:49,140  -->  00:31:57,480
time complexity of O(|V|+|E|). So the number of 
iterations is important in the running time, we  

255

00:31:57,480  -->  00:32:03,120
should try to keep it as low as possible, for that 
I think that we need to make the order of edges  

256

00:32:03,120  -->  00:32:09,480
traversal start from ones that are closer to the 
source, to make more updates in early iterations.  

257

00:32:12,960  -->  00:32:18,540
We've reached the end of this lecture, where 
we discussed Bellman-Ford algorithm. It's a bit  

258

00:32:18,540  -->  00:32:23,700
slower than Dijsktra's algorithm, but it handles 
negative values, so we should choose depending  

259

00:32:23,700  -->  00:32:29,640
on the situation. See you in the next lecture 
to talk about the Floyd-Warshall algorithm.
