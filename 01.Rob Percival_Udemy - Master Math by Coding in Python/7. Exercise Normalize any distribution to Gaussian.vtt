WEBVTT
1
00:00:02.860 --> 00:00:08.870
This video contains the exercise associated with the previous video.

2
00:00:08.950 --> 00:00:12.970
So what you want to do here is start from this distribution.

3
00:00:12.970 --> 00:00:22.420
Y equals two to the power of x where x is distributed or is drawn from a normal distribution with a

4
00:00:22.420 --> 00:00:25.810
mean of zero and a variance of 1.

5
00:00:25.810 --> 00:00:29.470
That's what all this funny looking notation means.

6
00:00:29.470 --> 00:00:36.550
So x is drawn from a normal distribution with a mean of 0 and a variance of 1.

7
00:00:36.550 --> 00:00:43.050
Now the histogram of this distribution this value Y is going to look something like this.

8
00:00:43.060 --> 00:00:46.210
You can see this is definitely not normally distributed.

9
00:00:46.210 --> 00:00:52.420
This is not Gaussian distributed and then you are going to apply an algorithm you will implement an

10
00:00:52.420 --> 00:00:57.580
algorithm that I will explain on the next slide that will convert this distribution so convert all of

11
00:00:57.580 --> 00:01:03.730
these numbers into this distribution which as you can see is basically a perfect Gaussian and looks

12
00:01:03.730 --> 00:01:05.500
extremely normal.

13
00:01:05.510 --> 00:01:11.470
Well okay it's actually technically not a gaussian but it is a very normal looking or Gaussian looking

14
00:01:11.470 --> 00:01:13.090
distribution.

15
00:01:13.090 --> 00:01:14.500
So how do you do this.

16
00:01:14.500 --> 00:01:19.660
How do you transform this distribution into this distribution.

17
00:01:19.660 --> 00:01:22.760
So the way that you do that it's a three step procedure.

18
00:01:22.840 --> 00:01:30.610
You have to rank transform the data and rank transforming the data means to convert all of the values

19
00:01:30.640 --> 00:01:37.880
in the data set into integers according to their location in the data set by magnitude.

20
00:01:38.320 --> 00:01:44.590
So rank transform the data and then you want to normalize the data to so normalize the rank transform

21
00:01:44.590 --> 00:01:51.660
data to between minus 1 and plus 1 and then apply the inverse hyperbolic tangent.

22
00:01:51.670 --> 00:01:56.710
Now I have to warn you this is a little bit of a tricky exercise.

23
00:01:56.710 --> 00:02:02.090
It is relatively difficult compared to a lot of the other exercises that I have in this course.

24
00:02:02.200 --> 00:02:07.570
So it's possible that you will need to do a little bit of testing and maybe a little bit of Internet

25
00:02:07.570 --> 00:02:11.980
searches to completely solve this exercise on your own.

26
00:02:12.070 --> 00:02:18.130
Now if you like you can pause the video now and try to get as far as you can in a moment.

27
00:02:18.130 --> 00:02:24.550
I'm going to reveal a couple of hints it's going to be one coding hint per item here.

28
00:02:24.580 --> 00:02:29.800
So if you don't want the hints then this is your last opportunity to pause the video.

29
00:02:29.860 --> 00:02:37.600
Okay so here are the hints the hints are you can rank transform the data by applying the function rank

30
00:02:37.600 --> 00:02:38.310
data.

31
00:02:38.320 --> 00:02:44.200
This comes from the Sy pi dot stats module so you can write from sci pirate stats.

32
00:02:44.260 --> 00:02:47.280
Import rank data and then apply this function.

33
00:02:48.280 --> 00:02:57.280
And then the hint for normalizing the ranks to a range of minus 1 to 1 is to take the output of the

34
00:02:57.280 --> 00:03:04.950
rank data function so the rank transform data first normalize these to a maximum value of 1 multiplied

35
00:03:05.240 --> 00:03:12.280
by 2 and well it's not exactly everything you need to do first step 2 but that will get you part of

36
00:03:12.280 --> 00:03:13.050
the way.

37
00:03:13.300 --> 00:03:14.530
And then for this third step.

38
00:03:14.530 --> 00:03:21.850
Taking the inverse hyperbolic tangent function you need to be careful to watch out for the exact values

39
00:03:21.850 --> 00:03:24.430
of minus 1 and 1.

40
00:03:24.430 --> 00:03:31.570
These are not valid inputs into the inverse hyperbolic tangent function so you will need to do something

41
00:03:31.840 --> 00:03:38.080
to make sure that your dataset does not contain exactly minus 1 and exactly plus 1.

42
00:03:38.080 --> 00:03:42.020
All right so with those hints Good luck working through this code.

43
00:03:42.130 --> 00:03:50.640
And now I'm going to switch to Python and show you my solution so I'm going to use num pi matte plot

44
00:03:50.640 --> 00:03:56.810
lib and this rank data function from the CI pi dot stats module.

45
00:03:57.420 --> 00:04:03.630
So I'm gonna start by creating the distribution of two to the power of X..

46
00:04:03.780 --> 00:04:11.150
So this is going to be a bridge data I'll call this variable a rich data two to the power of num Pieta

47
00:04:11.190 --> 00:04:19.500
random Rand N and then in numbers here now in the slides I showed you this like funny little squiggly

48
00:04:19.500 --> 00:04:25.260
thing thing and the funny looking end and all that stuff all that notation was really just there to

49
00:04:25.320 --> 00:04:31.490
introduce you to the notation that is often used for drawing from different kinds of distributions.

50
00:04:31.560 --> 00:04:37.680
So in fact you don't really need to do anything special with the code to get the desired distribution.

51
00:04:37.860 --> 00:04:41.650
So let's start by just plotting these data and seeing what these look like.

52
00:04:41.670 --> 00:04:51.660
So I'm going to create a figure with Peel T dot subplots and I'll make this a one by two geometry and

53
00:04:51.690 --> 00:05:02.010
I'm gonna start by setting the first access to contain a histogram of the original data with 30 bins

54
00:05:02.790 --> 00:05:05.390
and I'll set the x axis.

55
00:05:07.170 --> 00:05:20.250
So set X label to b value and the y axis label is going to be the count loops not to label this should

56
00:05:20.250 --> 00:05:22.570
be y label.

57
00:05:22.800 --> 00:05:24.180
Okay there you go.

58
00:05:24.200 --> 00:05:29.630
So far you know this is the easiest part of the assignment but it's good to start somewhere.

59
00:05:29.760 --> 00:05:29.960
Okay.

60
00:05:29.970 --> 00:05:33.180
And then let's see I'd appeal to that show down here.

61
00:05:33.390 --> 00:05:33.660
All right.

62
00:05:33.690 --> 00:05:37.130
And this does look more or less like what I showed in the slides.

63
00:05:37.260 --> 00:05:40.350
So I think this part is pretty good.

64
00:05:40.350 --> 00:05:45.720
So let's see what we want to do now is rank transform the data.

65
00:05:46.200 --> 00:05:54.780
So I'm gonna say rank data equals and then the function is also called rank data bridge data.

66
00:05:55.650 --> 00:06:01.440
And actually you know I'm gonna take a moment to introduce you to the rank transform and what that function

67
00:06:01.440 --> 00:06:03.420
and rank data actually does.

68
00:06:03.420 --> 00:06:06.990
So let's say we have actually I'll just write it out like this.

69
00:06:06.990 --> 00:06:09.510
We don't need extra variables so rank data.

70
00:06:09.690 --> 00:06:18.450
I'm going to input 1 1 point 1 one point one one and one.

71
00:06:18.450 --> 00:06:20.840
I don't know what number that is but it's a really large number.

72
00:06:21.420 --> 00:06:25.790
So if you look at these numbers you can see that these numbers are really really close to each other.

73
00:06:25.790 --> 00:06:31.410
And this number is really large and it's really really far away from these other numbers.

74
00:06:31.410 --> 00:06:37.530
But when I rank transform the data I just get one two three four and then maybe this wasn't the best

75
00:06:37.530 --> 00:06:43.290
example because then you think that it's just ordering the numbers by their index so I'm going to put

76
00:06:43.740 --> 00:06:45.980
one point one one in the beginning.

77
00:06:46.050 --> 00:06:52.950
So now you can see that the output of this ranked data function is 3 1 2 4 and this basically means

78
00:06:52.950 --> 00:06:59.790
that this first number is the third largest number in the set the second number is the first largest

79
00:06:59.790 --> 00:07:02.100
number instead of the smallest number in the set.

80
00:07:02.130 --> 00:07:08.400
This is the second largest and this is the fourth largest number in the set so rank transforming the

81
00:07:08.400 --> 00:07:16.370
data is actually throwing out all of the absolute magnitudes and just reordering according to the rank.

82
00:07:16.410 --> 00:07:16.640
Okay.

83
00:07:16.680 --> 00:07:17.870
So that was this step.

84
00:07:17.880 --> 00:07:25.860
So we get rank data and now let's see I'm going to create a histogram of this so you can see what this

85
00:07:25.860 --> 00:07:27.020
looks like.

86
00:07:27.030 --> 00:07:33.770
So the second subplot and then this is going to be rank underscore data.

87
00:07:33.960 --> 00:07:42.480
So all of the numbers between 0 and 500 because there 500 numbers are equally likely to occur.

88
00:07:42.480 --> 00:07:49.560
So with this rank data we need to normalize this to between minus 1 and plus 1.

89
00:07:49.590 --> 00:07:56.220
So I will right normalize to minus one to plus 1.

90
00:07:56.700 --> 00:08:01.110
So I'll create a new variable I'll call that Norm data equals.

91
00:08:01.110 --> 00:08:05.450
Now the hint that I gave was to divide by the maximum.

92
00:08:05.460 --> 00:08:16.020
So I'm going to say rank underscored data divided by the maximum of rank rank underscore data and then

93
00:08:16.050 --> 00:08:20.070
let's see what this histogram looks like for Norm data.

94
00:08:21.920 --> 00:08:22.170
All right.

95
00:08:22.170 --> 00:08:26.960
So now you can see that these data range between 0 and plus 1.

96
00:08:26.970 --> 00:08:35.220
So what I'm going to do now is multiply this whole thing by two and then we get a range from 0 to 2.

97
00:08:35.220 --> 00:08:38.220
But we want a range from minus one to plus one.

98
00:08:38.250 --> 00:08:42.000
So therefore we simply subtract one from this distribution.

99
00:08:42.000 --> 00:08:44.820
And now we get numbers from zero.

100
00:08:45.060 --> 00:08:48.080
Sorry minus one to plus one OK.

101
00:08:48.080 --> 00:08:58.340
And then we need to do the third step which is to apply the inverse hyper ball hype per Bolick trends

102
00:08:58.340 --> 00:08:59.500
form.

103
00:08:59.540 --> 00:08:59.810
Okay.

104
00:08:59.810 --> 00:09:04.340
And then I will call this trends data for transformed data.

105
00:09:04.670 --> 00:09:09.700
And that will be none pi dot arc 10 H.

106
00:09:09.710 --> 00:09:12.830
That is the function of the norm data.

107
00:09:14.480 --> 00:09:14.740
Okay.

108
00:09:14.750 --> 00:09:15.950
So we get an error.

109
00:09:15.950 --> 00:09:21.110
It says divide by zero and let's see what this distribution looks like anyway.

110
00:09:21.110 --> 00:09:23.960
So I'll say trends data huh.

111
00:09:23.960 --> 00:09:26.090
And now we don't get any values.

112
00:09:26.090 --> 00:09:27.400
So something is going wrong.

113
00:09:27.410 --> 00:09:31.130
We can see a supply range something with infinity.

114
00:09:31.130 --> 00:09:35.630
I'm going to dump out all of these numbers so we can see what they look like.

115
00:09:35.660 --> 00:09:39.050
So print trends data and I think it will.

116
00:09:39.050 --> 00:09:40.700
Yeah I will print out all of them.

117
00:09:40.710 --> 00:09:42.590
Okay so here we see a bunch of numbers.

118
00:09:42.590 --> 00:09:43.700
This is all fine.

119
00:09:43.820 --> 00:09:46.350
There is one infinity there.

120
00:09:46.760 --> 00:09:56.060
And this is related to the third hint that I gave in the slides and that was that the inverse hyperbolic

121
00:09:56.060 --> 00:10:03.890
tangent or the hyperbolic arc tangent is valid for most numbers you know for many numbers except if

122
00:10:03.890 --> 00:10:12.230
they are exactly minus one where we have minus infinity or plus one where we get plus infinity.

123
00:10:12.230 --> 00:10:20.660
So what we need to do up here is basically change the rank data so that we don't get a value of exactly

124
00:10:20.660 --> 00:10:23.590
minus one or exactly one.

125
00:10:23.600 --> 00:10:25.250
So there's a few ways to do this.

126
00:10:25.250 --> 00:10:30.050
My strategy here is going to be to add another number to these data.

127
00:10:30.080 --> 00:10:37.550
So I'm gonna say rank data equals num pi dot append and this is a function I've introduced previously

128
00:10:37.550 --> 00:10:47.790
in this course I'm going to say the rank data with the maximum of the rank data plus 1.

129
00:10:47.810 --> 00:10:52.850
So what I'm doing here is actually making this data set be one point longer.

130
00:10:52.850 --> 00:10:55.400
So this is 500 data points.

131
00:10:55.430 --> 00:11:02.180
This is now going to be five hundred and one data point and the largest data point is going to be larger

132
00:11:02.210 --> 00:11:06.600
than the largest value in the original data set.

133
00:11:06.770 --> 00:11:14.750
And that means that when these data get normalized here we divide by the maximum value but then we take

134
00:11:14.750 --> 00:11:20.480
off the very last value which is a value that actually didn't come from the data set.

135
00:11:20.510 --> 00:11:22.980
This is just something I artificially added.

136
00:11:23.030 --> 00:11:24.640
So here I will write Norm.

137
00:11:24.680 --> 00:11:33.380
Data equals num paid out delete and we want to delete from Norm data and we want to get rid of the final

138
00:11:33.380 --> 00:11:33.770
point.

139
00:11:33.770 --> 00:11:35.840
So the end point okay.

140
00:11:35.840 --> 00:11:39.260
And then let me get rid of this printout line here.

141
00:11:39.530 --> 00:11:40.870
And so that warning goes away.

142
00:11:40.880 --> 00:11:47.030
And then we see this very normal looking distribution which is actually a fairly straightforward transform

143
00:11:47.090 --> 00:11:51.440
of all of these numbers so that was pretty fun.

144
00:11:51.460 --> 00:11:56.770
Pretty insightful you learned how to work with different kinds of distributions shape distributions

145
00:11:56.860 --> 00:11:59.580
into distributions of other shapes.

146
00:11:59.680 --> 00:12:06.880
And this is actually a transformation that has real practical value because many algorithms in statistics

147
00:12:06.910 --> 00:12:13.690
in machine learning and other aspects of data science and in deep learning actually require or the analysis

148
00:12:13.690 --> 00:12:20.050
make assumptions that the values are distributed in a Gaussian or somewhat Gaussian way.

149
00:12:20.050 --> 00:12:26.860
So it's pretty handy to know how to transform any non normal distribution into a normal distribution.
