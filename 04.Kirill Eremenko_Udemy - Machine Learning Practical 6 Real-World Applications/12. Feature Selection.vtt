WEBVTT

00:01.250 --> 00:06.020
Hello everybody today we're going to be in the feature selection process.

00:06.020 --> 00:07.330
What is it going to accomplish.

00:07.340 --> 00:13.380
Is it going to shorten the amount of columns we need to get the same accuracy that we did in the previous

00:13.470 --> 00:21.240
years with less columns and the same accuracy the marksman to be faster and is also useful because when

00:21.290 --> 00:26.920
we want to put models into production to make sure that it's not too heavy to run.

00:26.960 --> 00:33.010
So as we get this process first we need to import the library is the over use.

00:33.140 --> 00:39.270
And of course it's going to be that linear model slash logistic regression function that we poured in

00:39.290 --> 00:40.410
early before.

00:40.580 --> 00:47.750
And we're also going to import that are IF function from feature selection great.

00:48.040 --> 00:52.400
So now let's begin building these feature selection process.

00:52.720 --> 00:56.420
First we create the classifier.

00:56.440 --> 01:02.350
We've got to make sure that we tell the jury selection process what kind of model that we're designing

01:02.350 --> 01:03.330
for in this case.

01:03.390 --> 01:08.520
Logistic Regression actually.

01:09.070 --> 01:13.560
Now then we need to select the top best features.

01:13.840 --> 01:15.650
So how many features you would select.

01:15.790 --> 01:20.650
Well let's take a look at the shape of the extreme variable.

01:20.650 --> 01:27.670
So if we do extreme that shape we can see the shift of how many cards we have in this case is going

01:27.670 --> 01:30.050
to be extreme.

01:30.910 --> 01:34.070
Excellent because that's a good amount.

01:34.090 --> 01:36.950
How about we shorten that by 20.

01:37.240 --> 01:41.430
So we're going to build the process by doing the following.

01:43.110 --> 01:52.060
R F E which is our feature selection process is going to be the calling of the RFU function as you might

01:52.060 --> 01:59.350
expect and we're going to apply the classifier to it and we're going to tell how many QAnd we want and

01:59.350 --> 02:03.440
the end result which in this case is going to be great.

02:03.670 --> 02:10.450
So then we're going to run that and we're also going to fit this new model.

02:10.480 --> 02:17.080
This is not exactly a model but it's going to work just as one meaning that you fit the strength in

02:17.080 --> 02:21.920
the works why drink to it.

02:22.000 --> 02:22.920
Excellent.

02:23.450 --> 02:30.340
So that's what's this going to take a few seconds because there is lot other different permutations

02:30.340 --> 02:37.700
of models that is right but because it's small and our model is relatively small so we finish very quickly.

02:38.320 --> 02:38.910
Great.

02:39.160 --> 02:46.290
So now that we have fit the model to the extreme and the white train let's see which particular attributes

02:46.300 --> 02:48.510
are actually useful in this case.

02:48.510 --> 02:51.770
Those are going to be coming from.

02:51.790 --> 02:52.820
So we're going to print.

02:52.820 --> 02:57.040
They're going to be coming from are we that support.

02:57.610 --> 03:02.420
So let's see what these poor returns it returns a bunch of.

03:02.470 --> 03:10.840
True True False false values meaning that these values are actually mapping which of the columns are

03:10.840 --> 03:15.610
included in the final results and which are not so a subset.

03:15.610 --> 03:19.030
The column names you see true true for false.

03:19.270 --> 03:23.810
We're going to get the fields that were included in the final result.

03:24.100 --> 03:25.300
So let's do it.

03:25.360 --> 03:35.400
We're going to run extrem that columns and we're going to use to support a subset of that support.

03:35.980 --> 03:40.010
And if we run this we get the calls that were actually included.

03:40.240 --> 03:45.730
So these are the 20 fields that the model that was the best predictor if we actually want to see the

03:45.730 --> 03:51.060
ranking as well we can do RFE because as you guys may expect and similar.

03:51.180 --> 03:54.380
And instead of support we're going to use ranking.

03:54.790 --> 03:59.890
We run it and then we call once represent the field that went into it.

04:00.000 --> 04:07.670
They're mapping to the True in it or if you support and the rest are ranked by importance.

04:07.670 --> 04:12.410
So number two is not good in the top 20 but it is the 21st more important value.

04:12.440 --> 04:17.830
And number three goes on forward number four all the way to the very last great.

04:17.920 --> 04:20.940
So now we know which columns are better to use.

04:20.940 --> 04:24.280
So this actually used as combed to fill them up.

04:24.600 --> 04:29.770
Well we're going to do in this case is we're going to copy and paste exact same code that we had before

04:30.340 --> 04:32.750
just using the new copies.

04:32.800 --> 04:38.120
So the scope it is we're going to base it.

04:39.430 --> 04:40.390
Excellent.

04:40.810 --> 04:42.640
So what is going to change here.

04:42.760 --> 04:47.760
Well obviously we run because you fire we get it with a random state.

04:47.860 --> 04:56.280
But instead of training on extreme We're going to do it on X-raying RF E support.

04:56.290 --> 05:02.190
You guys can see why this is because we don't want to work with the columns that we say that we're not

05:02.200 --> 05:03.100
useful.

05:03.100 --> 05:09.450
So this is like in this case it is going to be extreme that columns.

05:10.300 --> 05:21.870
Let's make this wish for and then we're going to use the subset we want to use are the support.

05:22.540 --> 05:24.420
And this should work just fine.

05:24.430 --> 05:28.400
If we run these couple lines which are in our model there you go.

05:28.690 --> 05:39.330
And what we tested is going to be the same thing we're going to use X test columns and Weakland a subset

05:39.390 --> 05:42.340
of that support.

05:42.960 --> 05:50.170
And then we call pretty not we run everything else the same way that we did before.

05:50.520 --> 05:59.190
This is going to give us first the accuracy of 61 almost sixty two percent actually 61 percent.

05:59.520 --> 06:06.230
OK nothing crazy that the precision against pretty low or under 50 the percentage the record is high.

06:06.230 --> 06:12.120
Again that 75 percent is very similar to our first results and the first video and the one score is

06:12.120 --> 06:19.290
similar to the accuracy as we partygoer we can apply the math for the confusion matrix that we see in

06:19.290 --> 06:21.620
the middle and the results are almost the same.

06:21.720 --> 06:26.870
There's a couple number differences but that's not to be mostly the same given that the random state

06:26.870 --> 06:27.390
is zero.

06:27.390 --> 06:29.800
So it should be pretty similar.

06:29.820 --> 06:32.190
So what have we accomplished with this step.

06:32.190 --> 06:35.550
We've accomplished something very very important.

06:35.550 --> 06:41.750
We have found 20 columns that are not giving us anything new in this model.

06:41.970 --> 06:47.050
And this is one of the main reasons this party was built in this manner.

06:47.610 --> 06:54.690
We wanted to create a model that could predict whether or not this is going to turn many of the fields

06:54.690 --> 06:57.760
that we have in the U.S. have nothing to do with the inability to churn.

06:57.760 --> 07:03.330
So they're going to be pretty much useless but we need to balance those we need to make sure that we

07:03.330 --> 07:04.930
have at least tried to use them.

07:05.220 --> 07:06.190
And this is what we did.

07:06.240 --> 07:08.760
We had tended to use them to give us some lift.

07:08.850 --> 07:14.610
We chopped them all off half of them off and the leaf was the same meaning that on the first 20 fields

07:14.960 --> 07:16.590
that is where most of the weight is lying.

07:16.620 --> 07:18.660
Most of the predictive power.

07:19.200 --> 07:22.260
So we are done with this process.

07:22.350 --> 07:24.690
We have finalized that feature selection process.

07:24.690 --> 07:26.490
We came away with these 20 columns.

07:26.670 --> 07:27.590
If you guys want.

07:27.590 --> 07:29.610
You can play around with different columns.

07:29.610 --> 07:34.770
You guys are going to realize if you keep playing the stronger power comes in the very few number of

07:34.820 --> 07:37.990
columns but for is sufficient for us.

07:38.280 --> 07:44.700
We want to at least have some kind of leeway and don't be specifically restricted to relying on one

07:44.700 --> 07:46.760
or two columns for predictive power.

07:46.860 --> 07:48.690
So 20 is going to be a good number.

07:49.110 --> 07:53.610
Anyways thank you very much for watching and see you in the next week.
