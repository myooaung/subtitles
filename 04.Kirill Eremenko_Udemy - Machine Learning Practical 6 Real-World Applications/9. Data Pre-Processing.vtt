WEBVTT

00:01.290 --> 00:02.850
Hello everybody.

00:02.850 --> 00:06.220
Welcome to the model building process for these products.

00:06.300 --> 00:10.330
Today we're going to be in the same process of building their actual model.

00:10.360 --> 00:15.720
I'm going to utilize all the clean data that we worked so hard in the previous piece.

00:16.080 --> 00:24.170
So as always the first thing with any script is to import the letters so go and import that need in

00:24.170 --> 00:29.330
libraries again Pandurs non-POD seaport mightily.

00:29.370 --> 00:33.380
And in this case we're going to use the time library.

00:33.780 --> 00:39.350
Then we're also going to read that data that we created in the previous videos which is then you update

00:39.390 --> 00:39.980
them.

00:40.440 --> 00:41.140
Great.

00:41.150 --> 00:45.050
So now maybe the pre-processing bar.

00:46.140 --> 00:55.940
So the first thing to do in this case is let's leave the response bearable frome the independent features.

00:56.310 --> 01:06.860
So this query column I'm sorry about your response which is just going to be the end roll call and roll

01:06.930 --> 01:09.030
great We'll run it.

01:09.060 --> 01:11.960
We created these new response.

01:12.240 --> 01:20.070
Now we're going to remove the response period from the original set and we're going Puzo as follows.

01:20.070 --> 01:28.780
The way we always do it we're going to drop the columns and roll which is the response for great that

01:28.860 --> 01:30.530
strop.

01:30.930 --> 01:37.440
For now let's do the first thing we always do when building the list split the dataset into training

01:37.470 --> 01:43.470
and testing it to do so we're going to import that treat display function from a scanner.

01:43.620 --> 01:45.320
So we're going to do as follows.

01:45.330 --> 01:50.460
Scaler that model selection.

01:51.960 --> 01:52.590
There you go.

01:52.620 --> 02:00.830
The super cells import train test but great.

02:01.050 --> 02:04.150
So it's running good now.

02:04.170 --> 02:12.180
Shrink This plate is going to return the train set for that test set and the y axis which is a response

02:12.180 --> 02:15.030
bearable for trainset and the responsible for it that's it.

02:15.030 --> 02:16.650
So those are four variables.

02:16.650 --> 02:27.570
So it's an extra access point train and white test.

02:28.140 --> 02:35.920
And this is going to be that we're sort of the train split function applied to our dataset The She's

02:36.190 --> 02:38.780
the execs the x variable the independent variables.

02:39.060 --> 02:45.870
And of course the response we also have to choose how to split the sizes so we're going into test size

02:46.470 --> 02:47.950
of 0.2.

02:48.120 --> 02:52.800
Meaning that 80 percent of that data is going to go into trainset in 20 percent into the test.

02:53.040 --> 02:59.760
And something I like to do myself is creating the random state argument of zero so that these random

02:59.760 --> 03:02.740
selection can be duplicated in the future.

03:02.820 --> 03:07.220
So let's run this great power train display.

03:07.740 --> 03:11.870
If you want you can see right here this is the train said.

03:12.990 --> 03:15.530
And this is this

03:19.100 --> 03:26.990
now one thing that you may have noticed here is that we have the user ID as part of our fields which

03:26.990 --> 03:32.170
is fine but of course we're not going to use that as a model because it's not a real feature.

03:32.170 --> 03:35.520
It's simply random use right in the file for each user.

03:35.720 --> 03:36.710
So let's remove.

03:37.190 --> 03:40.860
But keep in mind and this is very important.

03:40.880 --> 03:46.660
Keep in mind that at the end of the model we're going to want to associate a prediction to the user

03:46.670 --> 03:47.600
it came from.

03:47.870 --> 03:51.040
So we're going to save it away before we remove it.

03:51.140 --> 03:52.700
So let's do it.

03:52.930 --> 03:56.610
We grade that train identifier.

03:57.050 --> 04:05.560
So this is the usual 4:42 trainset and it's just extreme use.

04:06.920 --> 04:11.630
Good they we're going to remove these from trainset.

04:12.110 --> 04:13.720
So extreme.

04:14.150 --> 04:15.230
That's right.

04:15.240 --> 04:16.490
What are you guys.

04:16.590 --> 04:19.160
I'm very familiar with this point.

04:19.490 --> 04:34.920
Use the axle and we do the same for that test test then fire fire cause X test that you sir.

04:35.840 --> 04:36.560
Run it.

04:36.560 --> 04:37.210
Great.

04:37.520 --> 04:44.240
And then of course next test is now the same without the use of fire

04:48.510 --> 04:50.090
action.

04:50.150 --> 04:51.720
So we have done that.

04:52.160 --> 04:57.720
The next step in these pre-processing part is going to be feature Schelling.

04:58.520 --> 05:04.760
So to begin this process let's import the standard Scheller function from a scalar.

05:04.860 --> 05:10.750
We gonna do Sourcefire escape on that pre-processing

05:13.040 --> 05:19.410
import standard Scheller great.

05:19.880 --> 05:22.910
So let's run this important just fine.

05:22.910 --> 05:28.330
We're going to call the standard Scheller just simply EastEnder Scheller.

05:28.870 --> 05:38.220
We're going to call se x y and run this and then we're going to scale and we're going to scale the extreme

05:38.240 --> 05:40.350
and we're going to create a new feel.

05:40.350 --> 05:49.520
Put this in your variable and what is going to do is to fire a standard Scheller return and this is

05:49.520 --> 05:55.130
very important to swap returns a number array of what the machines.

05:55.220 --> 06:04.850
Ok the problem with this process is that it loses the column names and he loses the index.

06:05.340 --> 06:13.190
OK we care about the index because the index is how we identify each set of fields to the user and we

06:13.190 --> 06:15.800
care about the columns because we want to call them names.

06:15.800 --> 06:17.260
We'll build that models.

06:17.790 --> 06:18.350
OK.

06:18.560 --> 06:24.680
So the way we're going to do this is we're going to save the skilled part into a different data for

06:24.700 --> 06:33.010
them and we're going to do this by comparing the result of these Scheller into say a frame.

06:33.140 --> 06:40.940
So we're going to do see X that transform transform feet's the data into the standard Scheller and then

06:41.090 --> 06:44.580
right after transforms it into the proper scanner.

06:44.960 --> 06:46.580
So so far so good.

06:46.680 --> 06:55.590
So do with the new scale we're going to do the same with the x axis 2 which is that theta frame.

06:55.880 --> 07:04.730
And we're going to actually only transform the access because it's already been fitted to the trains

07:04.760 --> 07:05.590
it

07:08.020 --> 07:09.170
great.

07:09.260 --> 07:16.820
Now let's make sure that the new training say these tenderized the skill training they have to call

07:16.820 --> 07:18.040
them as well.

07:18.080 --> 07:21.700
So we're going to do this for a number two.

07:21.920 --> 07:28.280
We're going to select columns which at this moment is just now and they we're going to say it to the

07:28.280 --> 07:32.870
columns of the original extrinsic columns.

07:32.880 --> 07:35.860
That is great.

07:36.100 --> 07:40.800
And we're going to do this with a test set as well.

07:41.090 --> 07:46.590
So we're going to do here with test and here as well.

07:46.670 --> 07:50.480
We just quit.

07:50.510 --> 07:51.990
So so far so good.

07:52.010 --> 07:58.920
The last thing we have to do is recuperate in excess from the regional training index.

07:58.940 --> 08:08.580
To do that we're going to do extreme underscore training to that in that's going to be extreme.

08:08.770 --> 08:12.920
You know that index that was great.

08:13.100 --> 08:16.360
So we run this and it works just fine.

08:16.390 --> 08:26.300
The want to do the same for the desert which is just going to be done this is five years and then you

08:28.250 --> 08:31.780
said it's ok works perfectly.

08:32.120 --> 08:40.240
And the finest that now is going to be simply to compare the original transcend into the new trace it

08:40.550 --> 08:46.070
just that to underscore here run it perfect.

08:46.220 --> 08:53.530
And they were going to do X test because X test that too great.

08:54.230 --> 08:54.980
Awesome.

08:55.240 --> 09:04.530
For now we have converted that train into a scale trains meaning that all of the features all the numerical

09:04.550 --> 09:08.000
features have intervals as you may have known before.

09:08.000 --> 09:12.990
The reason we use standard Schelling in the first place is because we don't want any particular to make

09:12.990 --> 09:20.540
or feel to have a greater influence on the model simply because it's absolute values are very large.

09:20.570 --> 09:26.640
For example etching go from something of like 18 to 100 perhaps.

09:27.100 --> 09:28.220
Wow.

09:28.520 --> 09:36.070
Some screen color could only go 7 1 because H can go as far as a hundred.

09:36.080 --> 09:43.610
We don't want that age to have that extra weight a more to be more influential in the model simply because

09:43.610 --> 09:44.510
of its spot.

09:44.690 --> 09:52.670
So we all normalize every single feature and every single feature can only influence the response variable

09:52.790 --> 09:57.280
depending on how correlate it is and not based on its body.

09:57.740 --> 09:59.780
So we have done this process.

09:59.780 --> 10:03.830
So this is the final part before the model building process.

10:03.830 --> 10:08.640
This is the X-ray idea preprocess and we have done after initial EPA.

10:08.900 --> 10:10.210
The data is ready.

10:10.220 --> 10:15.620
It couldn't be any more ready and that the next year we're going to actually build and train the model

10:15.800 --> 10:17.320
and see our results.

10:17.330 --> 10:20.000
Thanks a lot for watching and see you in the next video.
