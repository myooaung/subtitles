WEBVTT

00:02.640 --> 00:09.200
So in this section we're going to keep going and discuss the different layers that we were covered earlier.

00:09.200 --> 00:11.330
Again a quick overview of what we've covered so far.

00:11.330 --> 00:13.440
So again here we have our neural network.

00:13.550 --> 00:17.950
We have our target classes and we have 10 outputs.

00:18.000 --> 00:21.660
Here we have our images and here we perform the convolution process.

00:21.680 --> 00:27.260
Again I think you guys are experts by now when it comes to convolutions and I come to how can we apply

00:27.260 --> 00:29.920
a feature detector to come up with our feature maps.

00:29.990 --> 00:30.520
OK.

00:30.830 --> 00:37.000
Next step is we wanted to do what we call it real new activation function OK or add a new function or

00:37.010 --> 00:40.220
local rectified linear units rectify lenience.

00:40.220 --> 00:40.810
OK.

00:41.090 --> 00:47.600
So really layers they simply add what we call it nonlinearity in our feature map and what it does it

00:47.600 --> 00:52.350
basically enhances the sparsity of how scattered the feature we can be.

00:52.620 --> 00:54.340
OK so what do you mean by this.

00:54.350 --> 00:56.630
So again let's clarify.

00:56.700 --> 01:01.100
Where did the location first of the really really basically are that the five linear units function

01:01.340 --> 01:06.830
and actually applied right after the feature detection process.

01:07.010 --> 01:07.410
OK.

01:07.430 --> 01:10.330
After applying the convolution before the pulling.

01:10.370 --> 01:13.480
So let's take a look at how can we apply the rule you can see here.

01:13.480 --> 01:14.540
This is kind of an image.

01:14.570 --> 01:14.910
OK.

01:14.930 --> 01:20.860
And let's assume that we can kind of apply our rectify a unit or a new function on it.

01:20.930 --> 01:23.530
I just can see any values if it's seven.

01:23.540 --> 01:28.640
OK if it's let's say the line here is kind of 45 degrees we get up like it's real estate 7.

01:28.790 --> 01:32.300
If it's standing in a state then however it's minus five that's been negative.

01:32.300 --> 01:33.300
We're just going to shut it down.

01:33.310 --> 01:34.570
It's going to set it to zero.

01:34.850 --> 01:40.790
OK so any number that's negative as you can see it has been set to zero G minus 8 becomes zero and so

01:40.790 --> 01:41.420
on and so forth.

01:41.440 --> 01:46.040
OK that's how can you apply what we call the really what's the what's the essence what's the advantage

01:46.040 --> 01:47.690
of having something like this.

01:47.690 --> 01:55.910
So what we have done in a way is that we try to make the image as sparse as possible as scattered as

01:55.910 --> 01:56.550
possible.

01:56.720 --> 02:00.030
We don't have kind of we don't need to have valleys within the image.

02:00.140 --> 02:03.390
We want to have like negative values and positives and so on.

02:03.510 --> 02:06.230
We're going to be very difficult to do what we wanted.

02:06.230 --> 02:08.880
We wanted to make the features pop up.

02:09.050 --> 02:12.890
We want to simply any any value that's below zero we're just going to kill it.

02:13.030 --> 02:15.720
OK and a very simple Forth it was going to set it to zero.

02:15.830 --> 02:20.480
So all these numbers let's say that's 10 and several are going to pop up in a way and will become kind

02:20.480 --> 02:27.160
of sparse or scattered across our image that's in a very in this intuition of applying it new activation

02:27.170 --> 02:27.900
function.

02:28.250 --> 02:32.710
You guys can apply different activation function which will call it sigmoid activation function OK the

02:32.880 --> 02:36.160
sigmoid activation function look something like this.

02:36.770 --> 02:42.050
If you guys here are between let's say these values we're going to set it to let's say point seven point

02:42.080 --> 02:45.170
eight point nine and then it's kind of saturates afterwards.

02:45.170 --> 02:45.790
OK.

02:45.920 --> 02:50.810
And that's not desired when we design our neural network in general especially the conclusion here and

02:50.830 --> 02:54.820
that was why because we wanted to preserve our slope.

02:54.980 --> 02:56.780
We want to preserve our gradient.

02:56.810 --> 03:01.670
We want to keep the gradient moving for we don't want to make it saturate or make it less stable in

03:01.670 --> 03:03.010
a way we want to avoid this.

03:03.020 --> 03:08.360
That's why we stay away from sigmoid functions especially during where we were after performing the

03:08.690 --> 03:10.320
feature detection process.

03:10.430 --> 03:13.190
OK we're going to play sigmoid function at the end of the network.

03:13.400 --> 03:17.960
OK let's say do like 0 or 1 we apply soft max function at the end of the network.

03:17.960 --> 03:21.340
But inside we generally stick with the two functions right.

03:21.500 --> 03:28.070
That's kind of a quick crash you know kind of course on the loop and the next step is we wanted to understand

03:28.070 --> 03:32.440
what any of it meant by Max pooling and feature and flattening.

03:32.960 --> 03:34.940
The first step is what we call the next again.

03:35.060 --> 03:36.950
The concept is very simple very easy.

03:36.950 --> 03:43.400
What we want to do if we want to take let's say four by four image OK and boil it down to two by two.

03:43.520 --> 03:43.950
OK.

03:44.000 --> 03:45.840
While preserving the same features.

03:46.040 --> 03:48.830
That's the whole objective of doing the pooling in general.

03:48.900 --> 03:56.040
But what we're going to do here is apply that Max pooling which is a certain category of pooling that

03:56.050 --> 04:00.360
is average pooling there's Max putting There's men pulling there's whatever pooling we can perform.

04:00.410 --> 04:05.620
So these guys can see here what we're going to do that we're going to use it to buy to filter with a

04:05.620 --> 04:06.500
stride of two.

04:06.500 --> 04:08.930
When I say try that means the movement of two.

04:09.050 --> 04:09.660
OK.

04:10.040 --> 04:16.250
So what are we going to do if we simply we're going to apply the tube to filter in here and select the

04:16.250 --> 04:18.880
maximum value as simple as that.

04:18.920 --> 04:21.910
So the maximum value is six which is going to put six here.

04:22.170 --> 04:23.010
Let's this too.

04:23.020 --> 04:29.360
So we're going to move to the right by two that would generate eight rate moving forward that would

04:29.360 --> 04:36.230
generate 9 moving forward that would generate 4 and so on so forth and that's how we perform the process

04:36.230 --> 04:37.740
of kind of max pulling.

04:37.970 --> 04:40.240
So what's the essence what did we do here.

04:40.280 --> 04:46.450
First of all we do what we call it we reduced the feature map dimensionality which is very critical.

04:46.670 --> 04:52.120
We moved from a four by four matrix to let's say we cut in half we were what we want to bite into a

04:52.130 --> 04:54.620
two by two Matrix.

04:55.520 --> 04:59.130
Second critical critical element is we actually preserve the feature.

04:59.390 --> 05:00.960
OK we actually ignored.

05:00.980 --> 05:06.110
Let's say these one in one it we kept only the most prominent values or prominent features which is

05:06.110 --> 05:07.410
six here in this case.

05:07.520 --> 05:09.930
We kept the AIDS we kept the 9 and so on.

05:09.950 --> 05:15.460
So we again we preserved the feature however we presented in a much kind of condensed four.

05:15.530 --> 05:16.370
OK.

05:16.910 --> 05:19.740
So this is this is the first benefit.

05:19.760 --> 05:25.250
The second benefit of Max pooling which is extremely important is that it helps the model to generalize

05:25.250 --> 05:26.170
in a way.

05:26.180 --> 05:26.910
What do you mean.

05:27.140 --> 05:29.900
So let's take a look at kind of let's say the images of bags here.

05:29.990 --> 05:30.570
OK.

05:30.800 --> 05:31.700
So what we want.

05:31.700 --> 05:38.510
We want our trained deep neural network to actually look at this bag and let's say OK this is an actual

05:38.510 --> 05:39.190
class bag.

05:39.200 --> 05:39.850
OK.

05:39.860 --> 05:43.820
At the same time if you wanted to look let's say at the bag that's a little bit tilted to the right

05:44.150 --> 05:48.360
a little bit tilted to the left or maybe looking upwards or looking whatever.

05:48.430 --> 05:48.960
OK.

05:49.040 --> 05:54.590
And that's how humans are very strong and very powerful in performing it can actually look at all these

05:54.590 --> 05:55.330
bags and tell.

05:55.340 --> 05:55.770
OK.

05:55.880 --> 05:56.810
All of them are bags.

05:56.810 --> 05:58.050
How can we do this.

05:58.060 --> 05:58.440
OK.

05:58.610 --> 06:03.250
We do this by a part of it just by using the pooling or the max pooling.

06:03.260 --> 06:04.440
Why.

06:04.460 --> 06:09.890
Because if that is the location of the peaks that shifted to the right or shifted to the left or right

06:10.010 --> 06:12.250
by one pixel up or down.

06:12.410 --> 06:16.130
Actually the values were going to be pretty much the same way because you you're applying a filter and

06:16.130 --> 06:17.940
you're getting the maximum value anyways.

06:17.970 --> 06:18.500
OK.

06:18.710 --> 06:25.000
So the location of the pixels can actually shift or be tilted a little bit no problem than that.

06:25.000 --> 06:31.240
Actually our network will be able to classify it as well accurately.

06:31.300 --> 06:32.120
Okay.

06:32.740 --> 06:38.600
So again maximum Max pooling works by retaining the maximum feature responds with gate with any given

06:38.600 --> 06:40.760
sample size and a specific feature.

06:40.870 --> 06:41.660
Okay.

06:41.720 --> 06:44.030
And then afterwards that's pretty much what we need.

06:44.060 --> 06:49.940
The next step is we will apply Roekel flattening which is simply what we wanted to do from the beginning

06:50.270 --> 06:55.910
to actually take the image take the 28 by 28 image and actually make it kind of you know like one array

06:56.090 --> 07:02.740
and feed it to our network our fully connected artificial neural network to tell us what class it is.

07:02.750 --> 07:04.620
Thats pretty much what we want at the beginning.

07:04.700 --> 07:11.840
Unfortunately we had to go through all this to extract feature maps to do pooling or Max pooling to

07:11.840 --> 07:15.660
apply really functions and to do flattening afterwards.

07:15.680 --> 07:16.220
OK.

07:16.490 --> 07:17.840
Again all this stuff.

07:17.850 --> 07:22.460
Okay it looks really complex but trust me when I'm going to go to the code it's actually really simple

07:22.700 --> 07:27.200
bunch of lines we can to build an artificial neural network with a convolution you know network which

07:27.200 --> 07:32.200
is kind of you know really exciting we can actually build them human Pyra brain in 10 minutes.

07:32.240 --> 07:38.390
You know teach it to do whatever whatever you want to classify these images in in bunch of seconds.

07:38.450 --> 07:38.970
OK.

07:39.370 --> 07:39.930
All right.

07:40.150 --> 07:42.110
So let's take a look at a quick illustration.

07:42.170 --> 07:43.110
OK.

07:43.220 --> 07:48.670
It's actually performed by Reierson Ryerson University in Canada.

07:48.860 --> 07:49.650
So here.

07:49.670 --> 07:55.340
I actually asked you OK let's draw kind of a number and the network we're going to tell you what number

07:55.430 --> 07:56.210
that is.

07:56.210 --> 07:58.280
So that's for example toilet's say five.

07:58.280 --> 08:01.760
So if you try five you'll see it and that's OK.

08:01.760 --> 08:05.620
So here it's telling you that OK this is number five.

08:05.680 --> 08:06.160
OK.

08:06.170 --> 08:07.700
And these are the different layers.

08:07.700 --> 08:11.400
The first layer as you can see here this is our input layer.

08:11.450 --> 08:12.340
OK.

08:12.380 --> 08:14.540
Again that's the first step which kind of convolution.

08:14.540 --> 08:15.950
These are kind of a feature maps.

08:16.040 --> 08:16.600
OK.

08:16.850 --> 08:21.880
And then the next step we can apply what we call the here we call it the downsampling player.

08:21.950 --> 08:26.180
Again you can show it can enable it hide it or show it here you can hide it or show it.

08:26.180 --> 08:32.360
So that means this layer that convolutional layer this layer is we'll call it downsampling layer downsampling

08:32.360 --> 08:32.750
layer.

08:32.750 --> 08:34.580
It's just a different name of pooling.

08:34.730 --> 08:35.000
OK.

08:35.000 --> 08:36.600
So that's the idea of pooling.

08:36.680 --> 08:37.490
Okay.

08:37.490 --> 08:42.710
And then afterwards we have another convolutional layer and then afterwards we did all the flattening

08:42.930 --> 08:43.600
right.

08:44.060 --> 08:47.030
And then afterwards we connect connected to the output.

08:47.030 --> 08:52.970
That's what basically specifies our classes which is either 0 2 9 that's pretty much what we wanted

08:52.970 --> 08:57.860
to implement but in in a different form that we're not there just in the right numbers we actually get

08:57.860 --> 09:00.840
to show images of different fashion items.

09:00.860 --> 09:01.380
OK.

09:01.790 --> 09:02.930
It's actually pretty interesting.

09:02.930 --> 09:05.520
I want you guys to go through it here.

09:05.540 --> 09:07.360
Obviously you know when we're out we wrote five.

09:07.430 --> 09:10.690
It was the first guess actually five and the second guess is seven.

09:10.790 --> 09:11.520
OK.

09:11.750 --> 09:15.970
You can go head and maybe let's say try a different number try let's say 1.

09:15.980 --> 09:21.360
It will tell you OK the first guess is 1 and that's pretty much how the convolution works.

09:21.410 --> 09:22.490
It's a different layers.

09:22.550 --> 09:26.410
OK applies to all planes feature maps first.

09:26.600 --> 09:27.230
OK.

09:27.320 --> 09:32.240
And then after the feature maps it applies the max pulling for downsampling.

09:32.240 --> 09:38.360
And then we do the flattening layers and then we feed it in a fully connected network to tell us what's

09:38.360 --> 09:40.830
the hour classification is.

09:40.970 --> 09:42.980
All right it's pretty interesting illustration.

09:42.980 --> 09:44.570
I hope you guys enjoyed it.

09:44.570 --> 09:47.370
All right let's go back to our slides.

09:47.390 --> 09:47.750
All right.

09:47.840 --> 09:50.710
That's pretty much all what I have for our for the section.

09:50.750 --> 09:53.800
I hope we get into that section and see you in the next section.
