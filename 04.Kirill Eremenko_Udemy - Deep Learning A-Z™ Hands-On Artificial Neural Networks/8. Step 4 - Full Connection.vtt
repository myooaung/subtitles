WEBVTT
1
1

00:00:00.400  -->  00:00:01.620
<v Instructor>Hello and welcome back to the course</v>
2

2

00:00:01.620  -->  00:00:02.720
on Deep Learning.
3

3

00:00:02.720  -->  00:00:06.210
Today we're finally at step number four, Full Connection.
4

4

00:00:06.210  -->  00:00:08.340
So what is this step all about?
5

5

00:00:08.340  -->  00:00:13.100
Well, in this step we're adding a whole artificial
6

6

00:00:13.100  -->  00:00:16.920
neural network to our convolutional neural network.
7

7

00:00:16.920  -->  00:00:19.700
So to all of this things that we've done so far
8

8

00:00:19.700  -->  00:00:22.400
which are convolution, pooling and flattening,
9

9

00:00:22.400  -->  00:00:27.240
now we're adding a whole new ANN on the back of that.
10

10

00:00:27.240  -->  00:00:28.920
How intense is that?
11

11

00:00:28.920  -->  00:00:30.880
That is just, that is something.
12

12

00:00:30.880  -->  00:00:32.480
That is definitely something.
13

13

00:00:32.480  -->  00:00:35.480
And so here we've got the input layer,
14

14

00:00:35.480  -->  00:00:37.190
we've got a fully connected layer and output layer
15

15

00:00:37.190  -->  00:00:39.563
and by the way, the fully connected layer,
16

16

00:00:40.410  -->  00:00:42.050
in the artificial neural networks,
17

17

00:00:42.050  -->  00:00:44.000
we used to call them hidden layers
18

18

00:00:44.000  -->  00:00:45.870
and here we're calling them fully connected layers
19

19

00:00:45.870  -->  00:00:47.360
because they are hidden layers,
20

20

00:00:47.360  -->  00:00:50.550
but at the same time they're a more specific type
21

21

00:00:50.550  -->  00:00:52.550
of hidden layers, they are fully connected layers.
22

22

00:00:52.550  -->  00:00:54.050
In artificial neural networks,
23

23

00:00:55.430  -->  00:00:57.440
hidden layers don't have to be fully connected
24

24

00:00:57.440  -->  00:00:59.690
whereas in convolutional neural networks,
25

25

00:00:59.690  -->  00:01:01.920
we're gonna be using fully connected layers
26

26

00:01:01.920  -->  00:01:04.010
and that's why they're generally called
27

27

00:01:04.010  -->  00:01:05.670
fully connected layers.
28

28

00:01:05.670  -->  00:01:08.280
And so basically that whole column or vector
29

29

00:01:08.280  -->  00:01:10.780
of outputs that we have after the flattening,
30

30

00:01:10.780  -->  00:01:12.640
we're passing it into the input layer
31

31

00:01:12.640  -->  00:01:15.250
and here we've got a very simplified example,
32

32

00:01:15.250  -->  00:01:18.030
just for illustration purposes
33

33

00:01:18.030  -->  00:01:20.300
and what the main purpose
34

34

00:01:20.300  -->  00:01:21.970
of the artificial neural network is,
35

35

00:01:21.970  -->  00:01:26.690
is to combine our features into more attributes
36

36

00:01:26.690  -->  00:01:28.890
that predict the classes even better.
37

37

00:01:28.890  -->  00:01:32.935
So we already in our vector of output
38

38

00:01:32.935  -->  00:01:37.790
in the flattened result from what we've already done,
39

39

00:01:37.790  -->  00:01:41.640
we have some features encoded in the numbers in that vector.
40

40

00:01:41.640  -->  00:01:44.520
And they can already do probably a pretty good job
41

41

00:01:44.520  -->  00:01:49.520
at predicting what class we're looking at.
42

42

00:01:49.700  -->  00:01:50.970
Whether it's a dog or a cat
43

43

00:01:50.970  -->  00:01:53.820
or whether it's a tumor or not a tumor and so on.
44

44

00:01:53.820  -->  00:01:57.370
But at the same time we know that we have this structure,
45

45

00:01:57.370  -->  00:02:00.540
called artificial neural network, which is designed,
46

46

00:02:00.540  -->  00:02:05.450
which has a purpose of dealing with attributes
47

47

00:02:05.450  -->  00:02:07.300
and coming out, we're dealing with features
48

48

00:02:07.300  -->  00:02:09.410
and coming up with new attributes
49

49

00:02:09.410  -->  00:02:11.690
and combining attributes together
50

50

00:02:11.690  -->  00:02:16.690
to even better predict things that we're trying to predict
51

51

00:02:16.740  -->  00:02:18.610
and we know that from the previous part,
52

52

00:02:18.610  -->  00:02:20.310
so why not leverage that?
53

53

00:02:20.310  -->  00:02:22.650
And that's exactly what the plan here is.
54

54

00:02:22.650  -->  00:02:25.240
So how about we pass on those values
55

55

00:02:25.240  -->  00:02:26.580
into an artificial neural network
56

56

00:02:26.580  -->  00:02:29.390
and let it even further optimize everything
57

57

00:02:29.390  -->  00:02:30.520
that we're doing.
58

58

00:02:30.520  -->  00:02:31.800
And so that's what we're going to be doing
59

59

00:02:31.800  -->  00:02:34.670
but let's look at at more realistic example,
60

60

00:02:34.670  -->  00:02:36.500
because this was a bit too simple.
61

61

00:02:36.500  -->  00:02:41.160
So here we've got a better looking artificial neural network
62

62

00:02:41.160  -->  00:02:43.920
where we have five attributes on the inputs
63

63

00:02:43.920  -->  00:02:47.245
then we have, in the first hidden layer we have six neurons
64

64

00:02:47.245  -->  00:02:51.160
in the second fully connected layer,
65

65

00:02:51.160  -->  00:02:53.730
we have eight neurons and then we have two outputs,
66

66

00:02:53.730  -->  00:02:55.120
one for a dog and one for a cat.
67

67

00:02:55.120  -->  00:02:59.980
And so an important thing for us to talk about here is
68

68

00:02:59.980  -->  00:03:02.130
that why do we have two outputs?
69

69

00:03:02.130  -->  00:03:05.050
We are kind of used to having only one output
70

70

00:03:05.050  -->  00:03:06.790
in our artificial neural networks,
71

71

00:03:06.790  -->  00:03:09.720
well, one output is for kind of
72

72

00:03:09.720  -->  00:03:12.276
when you're predicting a numerical value
73

73

00:03:12.276  -->  00:03:15.680
when you're running a regression type of problem.
74

74

00:03:15.680  -->  00:03:18.150
But when you're doing classification,
75

75

00:03:18.150  -->  00:03:20.340
you need an output per class.
76

76

00:03:20.340  -->  00:03:23.680
Except for the exception is when you have just two classes,
77

77

00:03:23.680  -->  00:03:25.410
like we have two classes here, dog and cat
78

78

00:03:25.410  -->  00:03:27.890
and we could've just done one output
79

79

00:03:27.890  -->  00:03:31.150
and made it a binary output and said one is a dog
80

80

00:03:31.150  -->  00:03:33.950
and zero is a cat as that would've worked totally fine
81

81

00:03:33.950  -->  00:03:36.610
and actually in fact you'll see Hadlan do that
82

82

00:03:36.610  -->  00:03:37.810
in the practical tutorials
83

83

00:03:37.810  -->  00:03:39.190
and that's how they'll be structured.
84

84

00:03:39.190  -->  00:03:44.000
But at the same time if you have more than two categories
85

85

00:03:44.000  -->  00:03:45.710
for instance, dogs, cats and birds,
86

86

00:03:45.710  -->  00:03:49.580
then you have to have a neuron per every category
87

87

00:03:49.580  -->  00:03:52.350
and that's why we're going to practice with two categories
88

88

00:03:52.350  -->  00:03:55.050
in this example so that we know what to expect
89

89

00:03:55.050  -->  00:03:58.430
if we're ever have more than two categories.
90

90

00:03:58.430  -->  00:03:59.930
And so what' going to be happening here?
91

91

00:03:59.930  -->  00:04:02.040
So, we've already done all the ground work.
92

92

00:04:02.040  -->  00:04:04.400
We've done the convolution, we've done the pooling
93

93

00:04:04.400  -->  00:04:07.860
and the flattening and now the information's gonna go
94

94

00:04:07.860  -->  00:04:09.450
through the artificial neural network.
95

95

00:04:09.450  -->  00:04:12.220
So let's have a look at how that all happens.
96

96

00:04:12.220  -->  00:04:13.940
There's the information going through
97

97

00:04:13.940  -->  00:04:16.420
from the very start, from the moment
98

98

00:04:16.420  -->  00:04:19.657
when the image is processed and convolved
99

99

00:04:19.657  -->  00:04:22.460
and then pooled, flattened and then through
100

100

00:04:22.460  -->  00:04:25.100
the artificial neural network, all four steps.
101

101

00:04:25.100  -->  00:04:28.020
And then a prediction is made.
102

102

00:04:28.020  -->  00:04:29.580
And we'll see how this happens in a moment.
103

103

00:04:29.580  -->  00:04:30.670
It will be very very interesting.
104

104

00:04:30.670  -->  00:04:32.830
But for now let's just say a prediction's made
105

105

00:04:32.830  -->  00:04:36.000
and for instance 80% that is a dog.
106

106

00:04:36.000  -->  00:04:37.880
But it turns out to be a cat.
107

107

00:04:37.880  -->  00:04:40.746
And then an error is calculated,
108

108

00:04:40.746  -->  00:04:43.070
well what we used to call a cost function
109

109

00:04:43.070  -->  00:04:45.860
in a artificial neural network
110

110

00:04:45.860  -->  00:04:48.530
and we use the median squared error there
111

111

00:04:48.530  -->  00:04:51.320
or in convolutional neuron networks,
112

112

00:04:51.320  -->  00:04:54.010
it's called a loss function and we use
113

113

00:04:54.010  -->  00:04:57.530
a cross entropy function for that.
114

114

00:04:57.530  -->  00:04:58.880
And we'll talk about cross entropy
115

115

00:04:58.880  -->  00:05:01.480
and median squared errors in a separate tutorial
116

116

00:05:01.480  -->  00:05:02.730
and how all that happens,
117

117

00:05:02.730  -->  00:05:03.563
but for now let's just say
118

118

00:05:03.563  -->  00:05:06.440
that we have a loss type of function
119

119

00:05:06.440  -->  00:05:08.640
which tells us how well our network is performing
120

120

00:05:08.640  -->  00:05:12.300
and we're trying to optimize it or minimize that function
121

121

00:05:12.300  -->  00:05:13.610
to optimize our network.
122

122

00:05:13.610  -->  00:05:16.990
So the error's calculated and then it's back propagated
123

123

00:05:16.990  -->  00:05:18.610
through the network, just like we had
124

124

00:05:18.610  -->  00:05:20.380
in the artificial neural networks.
125

125

00:05:20.380  -->  00:05:24.240
It is back propagated and some things are adjusted
126

126

00:05:24.240  -->  00:05:27.930
in the network to help optimize the performance.
127

127

00:05:27.930  -->  00:05:29.790
And the things that are adjusted are as usual
128

128

00:05:29.790  -->  00:05:31.660
the weights in the artificial neural network,
129

129

00:05:31.660  -->  00:05:35.230
parts of the blue lines that you see here, the synopsis.
130

130

00:05:35.230  -->  00:05:38.900
Then, also another thing that is adjusted is
131

131

00:05:38.900  -->  00:05:41.610
the feature detectors.
132

132

00:05:41.610  -->  00:05:44.400
So we know that we're looking for features,
133

133

00:05:44.400  -->  00:05:46.050
but what if we're looking for the wrong features,
134

134

00:05:46.050  -->  00:05:47.970
what if this didn't work out
135

135

00:05:47.970  -->  00:05:49.360
because the features are incorrect
136

136

00:05:49.360  -->  00:05:51.170
and so the feature detectors,
137

137

00:05:51.170  -->  00:05:53.270
remember those little matrices that we had
138

138

00:05:54.120  -->  00:05:57.310
that the three by three matrices,
139

139

00:05:57.310  -->  00:06:01.100
they are adjusted so that maybe next time
140

140

00:06:01.100  -->  00:06:03.240
it'll be better and let's see what happens,
141

141

00:06:03.240  -->  00:06:05.880
type of thing, but of course it's all done
142

142

00:06:05.880  -->  00:06:09.140
with a lot of science in the background,
143

143

00:06:09.140  -->  00:06:11.140
with a lot of math and it's all done
144

144

00:06:11.140  -->  00:06:14.490
through a grade in descend, with back propagation.
145

145

00:06:14.490  -->  00:06:17.870
So it's all not just random perturbations,
146

146

00:06:17.870  -->  00:06:21.130
it's actually very thought through how it's done.
147

147

00:06:21.130  -->  00:06:25.840
But nevertheless the feature detectors are adjusted,
148

148

00:06:25.840  -->  00:06:26.840
the weights are adjusted
149

149

00:06:26.840  -->  00:06:28.740
and this whole process happens again.
150

150

00:06:28.740  -->  00:06:30.650
And then again, the errors back propagate,
151

151

00:06:30.650  -->  00:06:32.640
and this keeps going on and on and on.
152

152

00:06:32.640  -->  00:06:35.070
And that's how our network is optimized
153

153

00:06:35.070  -->  00:06:37.870
that's how our network trains on the data.
154

154

00:06:37.870  -->  00:06:41.090
So the important thing here is that the data goes through
155

155

00:06:41.090  -->  00:06:44.330
the whole network from the very start to the very end,
156

156

00:06:44.330  -->  00:06:45.913
then the error is compared.
157

157

00:06:47.210  -->  00:06:49.890
So the error is calculated and then it's back propagated.
158

158

00:06:49.890  -->  00:06:52.500
So same story as with artificial neural networks
159

159

00:06:52.500  -->  00:06:55.760
it's just a bit longer because of that whole
160

160

00:06:55.760  -->  00:06:58.060
for the first three steps that we already had.
161

161

00:06:58.910  -->  00:07:01.530
And now let's have look at the interesting part,
162

162

00:07:01.530  -->  00:07:04.730
the really interesting part, how do these two classes work?
163

163

00:07:04.730  -->  00:07:07.270
Because, or how do these two output neurons work?
164

164

00:07:07.270  -->  00:07:10.530
Because before we've always kind of had one output neuron.
165

165

00:07:10.530  -->  00:07:11.792
What happens when we have two?
166

166

00:07:11.792  -->  00:07:16.792
How does the situation of classification of images play out?
167

167

00:07:17.560  -->  00:07:19.570
Well, let's start with the top neuron first.
168

168

00:07:19.570  -->  00:07:21.970
We're gonna start with the dog.
169

169

00:07:21.970  -->  00:07:22.803
How do we...
170

170

00:07:22.803  -->  00:07:25.300
The main purpose, what we need to do first is we need
171

171

00:07:25.300  -->  00:07:30.300
to understand what weights to assign to all of these
172

172

00:07:30.300  -->  00:07:33.730
synapses that connect to the dog, so that we know which
173

173

00:07:33.730  -->  00:07:37.760
of the previous neurons are actually important for the dog.
174

174

00:07:37.760  -->  00:07:38.840
And let's see how that is done.
175

175

00:07:38.840  -->  00:07:42.020
So let's say hypothetically, we've got these numbers
176

176

00:07:42.020  -->  00:07:46.430
in our previous layer, previous
177

177

00:07:46.430  -->  00:07:47.980
in the final fully connected layer.
178

178

00:07:47.980  -->  00:07:50.900
And again, these numbers can be absolutely anything,
179

179

00:07:50.900  -->  00:07:53.780
they don't have to be that, they can be any numbers.
180

180

00:07:53.780  -->  00:07:56.390
But just for argument's sake, we're going to agree
181

181

00:07:56.390  -->  00:08:00.430
that we are looking specifically at numbers
182

182

00:08:00.430  -->  00:08:02.190
between zero and one.
183

183

00:08:02.190  -->  00:08:05.570
So it's easier for us to argue these things and understand.
184

184

00:08:05.570  -->  00:08:09.770
And one means that that neuron was very confident
185

185

00:08:09.770  -->  00:08:11.500
that it fall in a certain feature.
186

186

00:08:11.500  -->  00:08:14.620
And zero is going to mean that neuron
187

187

00:08:14.620  -->  00:08:15.990
didn't find a feature it's looking for.
188

188

00:08:15.990  -->  00:08:18.710
So because at the end of the day, these neurons
189

189

00:08:20.590  -->  00:08:23.520
like anything else on this left side,
190

190

00:08:23.520  -->  00:08:25.370
is just looking at features at an image.
191

191

00:08:25.370  -->  00:08:27.920
This is already very very processed but still,
192

192

00:08:27.920  -->  00:08:30.350
it's detecting a certain feature combination
193

193

00:08:30.350  -->  00:08:32.210
of features on the image right?
194

194

00:08:32.210  -->  00:08:35.790
Before in the control step, we had to kind of recognizable
195

195

00:08:35.790  -->  00:08:38.270
features in the pool set they're less recognizable,
196

196

00:08:38.270  -->  00:08:40.560
then they're becoming even less recognizable in a flat
197

197

00:08:40.560  -->  00:08:42.520
and image, and then they get combined, and so on.
198

198

00:08:42.520  -->  00:08:45.550
But nevertheless, this we're talking about here
199

199

00:08:45.550  -->  00:08:47.830
certain features that are present image
200

200

00:08:47.830  -->  00:08:48.663
or their combination.
201

201

00:08:48.663  -->  00:08:52.160
So a one which has been passed, and this is important
202

202

00:08:52.160  -->  00:08:55.315
is being passed to both the dog and the cat at the same time
203

203

00:08:55.315  -->  00:08:57.020
to both the output neurons.
204

204

00:08:57.020  -->  00:09:02.020
So one means that for us, for all argument, it means that
205

205

00:09:02.267  -->  00:09:06.940
this neuron is firing up, it's, it's really rapidly
206

206

00:09:06.940  -->  00:09:10.070
detecting that feature that might be an eyebrow.
207

207

00:09:10.070  -->  00:09:12.550
It might be detecting this eyebrow again
208

208

00:09:12.550  -->  00:09:15.130
for simplicity sake, it's detecting this eyebrow.
209

209

00:09:15.130  -->  00:09:17.290
And it's communicate that to the dog neuron
210

210

00:09:17.290  -->  00:09:18.600
and to the cat neuron saying,
211

211

00:09:18.600  -->  00:09:20.240
I can see my eyebrow, I can see my eyebrow.
212

212

00:09:20.240  -->  00:09:22.350
And then it's up to the dog and the cat neuron
213

213

00:09:22.350  -->  00:09:25.770
to understand what that means for them, right?
214

214

00:09:25.770  -->  00:09:28.510
And so in this case, which neurons are firing up?
215

215

00:09:28.510  -->  00:09:29.830
These three neurons are firing up.
216

216

00:09:29.830  -->  00:09:32.970
The eyebrow, and let's say the nose is saying,
217

217

00:09:32.970  -->  00:09:36.160
I can see I can see a big nose, and I can see floppy ears.
218

218

00:09:36.160  -->  00:09:39.020
So it and it's saying that to the dog, and the cat.
219

219

00:09:39.020  -->  00:09:41.650
And then what the dog and then what happens is,
220

220

00:09:41.650  -->  00:09:43.350
we know that this is a dog.
221

221

00:09:43.350  -->  00:09:46.700
So the dog neuron knows that the answer it is actually
222

222

00:09:46.700  -->  00:09:50.540
a dog, because at the end, we're comparing to the picture
223

223

00:09:50.540  -->  00:09:53.560
or to the label on the picture and we know it's a dog.
224

224

00:09:53.560  -->  00:09:55.890
So basically, the dog neuron is gonna say,
225

225

00:09:55.890  -->  00:09:58.720
Aha, so I should be triggered in this case,
226

226

00:09:58.720  -->  00:10:00.350
so these are my neurons.
227

227

00:10:00.350  -->  00:10:02.770
They're telling the signal that they're sending
228

228

00:10:02.770  -->  00:10:05.370
to both to me to the dog and to the cat
229

229

00:10:05.370  -->  00:10:08.910
is actually a indication for me that it is a dog.
230

230

00:10:08.910  -->  00:10:11.410
And throughout these lots and lots and lots of iterations
231

231

00:10:11.410  -->  00:10:13.870
if this happens many times, the dog will learn
232

232

00:10:13.870  -->  00:10:17.270
that these neurons do indeed fire up
233

233

00:10:17.270  -->  00:10:19.550
when the feature belongs to a dog.
234

234

00:10:19.550  -->  00:10:21.400
On the other hand, the cat neuron will know
235

235

00:10:21.400  -->  00:10:24.080
that it's not a cat and it will know that this feature
236

236

00:10:24.080  -->  00:10:25.850
is firing up and this neuron is telling me
237

237

00:10:25.850  -->  00:10:28.290
it can see floppy ears floppy ears floppy ears.
238

238

00:10:28.290  -->  00:10:30.990
But at the same time, it's not a cat.
239

239

00:10:30.990  -->  00:10:33.940
So basically, to me, that's a signal that I should
240

240

00:10:33.940  -->  00:10:36.770
ignore this neuron and like, and the more that happens,
241

241

00:10:36.770  -->  00:10:40.130
the more the cat neuron is gonna ignore this neuron
242

242

00:10:40.130  -->  00:10:41.423
about the floppy ears.
243

243

00:10:42.320  -->  00:10:46.630
And so basically, that's how through lots
244

244

00:10:46.630  -->  00:10:49.010
and lots of iterations if this happens often,
245

245

00:10:49.010  -->  00:10:50.020
so this is just one example.
246

246

00:10:50.020  -->  00:10:53.400
But if this happens often, and it maybe one, maybe 0.8, 0.9,
247

247

00:10:53.400  -->  00:10:55.340
maybe sometimes it won't fire but overall,
248

248

00:10:55.340  -->  00:10:59.600
on average this neuron is lighting up very often
249

249

00:10:59.600  -->  00:11:03.060
when it is indeed a dog, the dog neuron will start
250

250

00:11:03.060  -->  00:11:05.840
attributing higher importance to this neuron.
251

251

00:11:05.840  -->  00:11:08.330
And so there we go, that's how we're going to signify it.
252

252

00:11:08.330  -->  00:11:10.690
We're going to say that these three neurons
253

253

00:11:10.690  -->  00:11:14.160
through this iterative process with many many
254

254

00:11:14.160  -->  00:11:16.450
many many samples, and many, many epochs.
255

255

00:11:16.450  -->  00:11:19.080
Remember so sample is a row in your data set
256

256

00:11:19.080  -->  00:11:22.080
and epoch is when you go through your whole dataset, again,
257

257

00:11:22.080  -->  00:11:23.240
and again, and again.
258

258

00:11:23.240  -->  00:11:25.973
Through lots and lots of iterations, this dog neuron
259

259

00:11:25.973  -->  00:11:30.973
learned that this eyebrow neuron and this big nose neuron
260

260

00:11:31.030  -->  00:11:36.030
and this floppy ears neuron, they all seem to really
261

261

00:11:37.490  -->  00:11:41.450
contribute very well to the classification
262

262

00:11:41.450  -->  00:11:44.360
of what it's looking for and which is a dog.
263

263

00:11:44.360  -->  00:11:45.630
So that's how it works.
264

264

00:11:45.630  -->  00:11:48.820
And again, these ears and nose and eyebrows,
265

265

00:11:48.820  -->  00:11:52.660
those are very, very approximate,
266

266

00:11:52.660  -->  00:11:55.590
or like very far fetched examples.
267

267

00:11:55.590  -->  00:11:58.680
Because by this stage, in this whole convolution
268

268

00:11:58.680  -->  00:12:02.480
of neural network it is completely unrecognizable
269

269

00:12:02.480  -->  00:12:03.470
what they're looking for.
270

270

00:12:03.470  -->  00:12:06.260
But at the same time, it is something in the
271

271

00:12:06.260  -->  00:12:09.300
features of dogs, or cats, or whatever you're classifying.
272

272

00:12:09.300  -->  00:12:11.110
And then, so let's move on to the next one.
273

273

00:12:11.110  -->  00:12:12.460
Now, we're going to look at the cat neuron.
274

274

00:12:12.460  -->  00:12:15.623
But these were going to remember that these weights are,
275

275

00:12:16.670  -->  00:12:17.810
that we've sold out the dog.
276

276

00:12:17.810  -->  00:12:20.530
So the dog is kind of like pretty much ignoring all these
277

277

00:12:20.530  -->  00:12:23.590
other neurons one, two, three, four or five, but it's really
278

278

00:12:23.590  -->  00:12:26.470
paying attention to what these three neurons are saying.
279

279

00:12:26.470  -->  00:12:28.370
Now what is the cat's listening to?
280

280

00:12:28.370  -->  00:12:31.273
Well, whenever it is actually a cat right,
281

281

00:12:32.630  -->  00:12:35.520
this is an example of a situation when it's actually a cat.
282

282

00:12:35.520  -->  00:12:40.520
So you'll see that these three neurons 0.9, 0.9, and one,
283

283

00:12:41.130  -->  00:12:44.610
they're saying something to both the dog and the cat.
284

284

00:12:44.610  -->  00:12:45.710
And this is again, important to remember.
285

285

00:12:45.710  -->  00:12:49.450
So this output signal goes both ways, it's the same, right?
286

286

00:12:49.450  -->  00:12:52.580
It's saying one to the dog it's saying one to the cat.
287

287

00:12:52.580  -->  00:12:55.120
But then it's up to the dog and the cat to decide to
288

288

00:12:55.120  -->  00:12:58.079
whether to take into account that signal
289

289

00:12:58.079  -->  00:13:00.400
and learn from it or not.
290

290

00:13:00.400  -->  00:13:04.050
And both the dog and the cat can see that this is a photo,
291

291

00:13:04.050  -->  00:13:05.520
I should have put a photo of a cat here.
292

292

00:13:05.520  -->  00:13:07.327
But basically imagine a photo of a cat, both the dog
293

293

00:13:07.327  -->  00:13:10.090
and the cat can see that this is actually a cat.
294

294

00:13:10.090  -->  00:13:14.210
So basically, the dog is like, oh okay so these whiskers
295

295

00:13:14.210  -->  00:13:19.210
and these pointing triangle ears and this small size,
296

296

00:13:20.290  -->  00:13:25.280
I guess or oh maybe this time you know how cats have
297

297

00:13:25.280  -->  00:13:28.220
these things in their eyes, their eyes are like little,
298

298

00:13:28.220  -->  00:13:32.170
they're not circles, they're lines or something like that,
299

299

00:13:32.170  -->  00:13:34.900
like cat eyes basically, these cat eyes,
300

300

00:13:34.900  -->  00:13:37.360
they're definitely not working for me.
301

301

00:13:37.360  -->  00:13:39.240
They're not helping me out predict
302

302

00:13:39.240  -->  00:13:41.840
because every time these neurons light up,
303

303

00:13:41.840  -->  00:13:44.120
the prediction is not what I'm looking for.
304

304

00:13:44.120  -->  00:13:46.800
On the other hand, the cat is like, that's interesting.
305

305

00:13:46.800  -->  00:13:49.230
Every time these, this one lights up,
306

306

00:13:49.230  -->  00:13:53.810
or most of the time it lights up, it matches my expectation.
307

307

00:13:53.810  -->  00:13:55.230
It matches what I'm looking for.
308

308

00:13:55.230  -->  00:13:58.040
Okay I'm gonna listen to this guy more than this one.
309

309

00:13:58.040  -->  00:13:58.873
This one is the same thing.
310

310

00:13:58.873  -->  00:14:00.950
Every time it lights up or most of the times,
311

311

00:14:00.950  -->  00:14:04.700
it's lights up, I happen to get a good,
312

312

00:14:04.700  -->  00:14:07.651
I happen to be rewarded for my prediction
313

313

00:14:07.651  -->  00:14:09.040
because I get it right.
314

314

00:14:09.040  -->  00:14:11.520
It's a cat, okay and so I'm gonna listen to him more.
315

315

00:14:11.520  -->  00:14:15.290
This one is useless to me because he's not actually,
316

316

00:14:15.290  -->  00:14:17.980
like he's not even lighting up.
317

317

00:14:17.980  -->  00:14:19.860
It's a cat but he's not lighting up
318

318

00:14:19.860  -->  00:14:20.920
so the opposite is happening.
319

319

00:14:20.920  -->  00:14:23.410
And this one as well, it's a cat, but he's not lighting up
320

320

00:14:23.410  -->  00:14:24.350
so I'm not gonna listen to him.
321

321

00:14:24.350  -->  00:14:27.510
But this one, when... what is this?
322

322

00:14:27.510  -->  00:14:29.730
The eyes, the cat eyes light up.
323

323

00:14:29.730  -->  00:14:32.570
We can see, I can see that it's a cat, it matches
324

324

00:14:32.570  -->  00:14:34.950
most of the time so I'm gonna learn from that and I'm going
325

325

00:14:34.950  -->  00:14:38.640
to listen to these three guys, more often than not.
326

326

00:14:38.640  -->  00:14:41.220
And so basically, the cat is listening to these three,
327

327

00:14:41.220  -->  00:14:43.150
and it's ignoring the other five.
328

328

00:14:43.150  -->  00:14:48.150
And that is how these final neurons learn which neurons
329

329

00:14:48.840  -->  00:14:53.600
in the final fully connected layer to listen to.
330

330

00:14:53.600  -->  00:14:56.510
So the output neurons learn which of the fully
331

331

00:14:56.510  -->  00:14:58.770
or which are the final fully connected layer
332

332

00:14:58.770  -->  00:15:00.060
neurons to listen to.
333

333

00:15:00.060  -->  00:15:03.010
And that's how they understand, basically
334

334

00:15:03.010  -->  00:15:05.130
that's how the features are propagated
335

335

00:15:05.130  -->  00:15:08.870
through the network and conveyed to the output.
336

336

00:15:08.870  -->  00:15:11.880
And so even though these features, of course don't have
337

337

00:15:11.880  -->  00:15:15.120
that much meaning to them, like floppy ears, or whiskers,
338

338

00:15:15.120  -->  00:15:18.610
at the same time, they do have some distinctive,
339

339

00:15:18.610  -->  00:15:21.790
there is a distinctive feature of that specific class.
340

340

00:15:21.790  -->  00:15:24.870
And that's how the network is trained because we also during
341

341

00:15:24.870  -->  00:15:27.210
remember, during the back propagation process,
342

342

00:15:27.210  -->  00:15:29.690
we also adjust the feature detectors.
343

343

00:15:29.690  -->  00:15:32.290
So if a feature is useless to the output
344

344

00:15:32.290  -->  00:15:35.900
it's going to probably be disregarded,
345

345

00:15:35.900  -->  00:15:38.330
because this doesn't happen over one or two trees.
346

346

00:15:38.330  -->  00:15:40.930
This happens through thousands and thousands of iterations.
347

347

00:15:40.930  -->  00:15:44.510
So with time, a feature that is useless to the network
348

348

00:15:44.510  -->  00:15:46.150
is going to be disregarded and replaced
349

349

00:15:46.150  -->  00:15:47.110
with feature as useful.
350

350

00:15:47.110  -->  00:15:50.470
And so at the end of the day, in this final layer
351

351

00:15:50.470  -->  00:15:53.490
of neurons, you're likely to have lots of features,
352

352

00:15:53.490  -->  00:15:56.920
or combinations of features from the image that are indeed
353

353

00:15:56.920  -->  00:16:00.573
representative or descriptive of dogs and cat.
354

354

00:16:01.610  -->  00:16:05.000
And so then once your network is trained up,
355

355

00:16:05.000  -->  00:16:06.570
then this is how its applied.
356

356

00:16:06.570  -->  00:16:08.200
So this is the next step like we've already trained
357

357

00:16:08.200  -->  00:16:10.020
up on our network so this happened, let's see what happens
358

358

00:16:10.020  -->  00:16:12.950
when this network is applied.
359

359

00:16:12.950  -->  00:16:15.083
So let's say we pass on an image of a dog,
360

360

00:16:16.240  -->  00:16:18.950
the values are propagated through our network,
361

361

00:16:18.950  -->  00:16:20.500
we get certain values.
362

362

00:16:20.500  -->  00:16:24.130
And so and this time, the dog and the cat neurons
363

363

00:16:24.130  -->  00:16:26.640
don't know they don't have the image of the dog here.
364

364

00:16:26.640  -->  00:16:28.390
They don't know that it's a dog or a cat.
365

365

00:16:28.390  -->  00:16:29.900
They have no idea where it is.
366

366

00:16:29.900  -->  00:16:33.570
But they have learned to listen to
367

367

00:16:33.570  -->  00:16:35.600
what is being shown here, right?
368

368

00:16:35.600  -->  00:16:37.740
They have learned to listen to the dog
369

369

00:16:37.740  -->  00:16:39.640
and listens to these three neurons, the cat neuron
370

370

00:16:39.640  -->  00:16:40.780
listens to these three.
371

371

00:16:40.780  -->  00:16:43.140
And so the dog neuron looks at one, two, three
372

372

00:16:43.140  -->  00:16:46.010
and says these are pretty high so my probability
373

373

00:16:46.010  -->  00:16:47.720
is gonna be high that it's a dog.
374

374

00:16:47.720  -->  00:16:51.320
The cat neuron looks at these and says okay this one
375

375

00:16:51.320  -->  00:16:53.530
is pretty high but these are pretty low.
376

376

00:16:53.530  -->  00:16:57.057
Interesting, so my probability is gonna be 0.05.
377

377

00:16:57.057  -->  00:17:00.060
And then that's where you get to predictions.
378

378

00:17:00.060  -->  00:17:03.470
So then your first choice for this neural network
379

379

00:17:03.470  -->  00:17:06.840
is a dog, second choice is a cat and that's pretty much it.
380

380

00:17:06.840  -->  00:17:08.180
So the answer is dog.
381

381

00:17:08.180  -->  00:17:11.870
And same thing happens when you pass an image of a cat,
382

382

00:17:11.870  -->  00:17:14.870
you get new values and you can see that even though
383

383

00:17:14.870  -->  00:17:17.848
this one's high, these ones are low and for the cat,
384

384

00:17:17.848  -->  00:17:20.560
this one's higher, this one's high and this one's a bit low.
385

385

00:17:20.560  -->  00:17:23.870
So the probability here might not be as great as previously
386

386

00:17:23.870  -->  00:17:26.840
but still, you can see that it's a cat of 79%.
387

387

00:17:26.840  -->  00:17:28.710
And so therefore the neural network
388

388

00:17:28.710  -->  00:17:30.190
is gonna vote that it's a cat.
389

389

00:17:30.190  -->  00:17:32.280
And so basically or the neural network is gonna conclude
390

390

00:17:32.280  -->  00:17:33.220
that it's a cat.
391

391

00:17:33.220  -->  00:17:36.240
Voting is a term that is used for these guys.
392

392

00:17:36.240  -->  00:17:40.250
So these neurons in the final fully connected layer,
393

393

00:17:40.250  -->  00:17:42.760
they get to vote and these are their votes.
394

394

00:17:42.760  -->  00:17:46.190
And again we are just for argument's sake putting values
395

395

00:17:46.190  -->  00:17:47.070
between zero and one here.
396

396

00:17:47.070  -->  00:17:49.530
These could be any values but they get to vote
397

397

00:17:49.530  -->  00:17:54.410
and then these weights are the importance of their vote.
398

398

00:17:54.410  -->  00:17:59.020
So these purple weights are how the dog neuron
399

399

00:17:59.020  -->  00:18:00.480
views their votes.
400

400

00:18:00.480  -->  00:18:03.480
How much importance is it assigns to these neurons
401

401

00:18:03.480  -->  00:18:06.630
and to those votes and this is how much importance
402

402

00:18:06.630  -->  00:18:09.740
the cat's neuron assigns to these
403

403

00:18:11.150  -->  00:18:12.650
though to the votes of these neurons.
404

404

00:18:12.650  -->  00:18:14.107
And so these neurons vote, the dog
405

405

00:18:14.107  -->  00:18:18.170
and the cat based on their learned weights they decide
406

406

00:18:18.170  -->  00:18:20.300
who to listen to and then they make their predictions
407

407

00:18:20.300  -->  00:18:22.400
and then hold neural network concludes
408

408

00:18:22.400  -->  00:18:24.520
that this is in this case a cat.
409

409

00:18:24.520  -->  00:18:26.890
And then that's and then that's your conclusion.
410

410

00:18:26.890  -->  00:18:28.750
And that's how you get images like this
411

411

00:18:28.750  -->  00:18:33.750
where you have a cheetah and then you have a cheetah claws
412

412

00:18:34.680  -->  00:18:36.740
like a high high probability.
413

413

00:18:36.740  -->  00:18:39.960
So this is the probability that the network has predicted
414

414

00:18:39.960  -->  00:18:40.793
and these are laws.
415

415

00:18:40.793  -->  00:18:42.820
But these still exists because they're still kind of like
416

416

00:18:42.820  -->  00:18:46.820
a small chance the other neurons are also listening to their
417

417

00:18:46.820  -->  00:18:49.370
voters and they're saying oh maybe it's actually a leopard.
418

418

00:18:49.370  -->  00:18:52.560
And the bullet train very very prevalent here scissors.
419

419

00:18:52.560  -->  00:18:54.920
This one one but hand glass was very close
420

420

00:18:54.920  -->  00:18:57.170
second and then frying pans stethoscope
421

421

00:18:57.170  -->  00:19:00.220
because you could see like these neurons,
422

422

00:19:00.220  -->  00:19:03.010
the scissors neuron, the output scissors neuron listen
423

423

00:19:03.010  -->  00:19:07.010
to its voters and it had the predominant vote overall
424

424

00:19:07.010  -->  00:19:10.100
but then the hand glass had a good outcome as well.
425

425

00:19:10.100  -->  00:19:10.933
So there we go.
426

426

00:19:10.933  -->  00:19:13.680
That's how the full connection works
427

427

00:19:13.680  -->  00:19:16.560
and how this all plays out together.
428

428

00:19:16.560  -->  00:19:18.700
I hope you enjoyed today's tutorial.
429

429

00:19:18.700  -->  00:19:21.300
We're gonna summarize all of this in the summary as well
430

430

00:19:21.300  -->  00:19:22.740
and I'll see you next time.
431

431

00:19:22.740  -->  00:19:24.753
Until then, enjoy Deep Learning.
