WEBVTT
1
1

00:00:00.290  -->  00:00:02.740
<v Man>Hello and welcome to this Python tutorial.</v>
2

2

00:00:02.740  -->  00:00:05.120
Alright, so now that our A&amp;N is compiled
3

3

00:00:05.120  -->  00:00:06.580
it's time for the exciting step
4

4

00:00:06.580  -->  00:00:09.730
which is to fit the A&amp;N to the training set.
5

5

00:00:09.730  -->  00:00:11.710
Because you probably noticed that so far
6

6

00:00:11.710  -->  00:00:14.460
we've only built the A&amp;N without
7

7

00:00:14.460  -->  00:00:16.910
making the connection to the training set
8

8

00:00:16.910  -->  00:00:19.290
and so of course now we need to make this connection,
9

9

00:00:19.290  -->  00:00:21.050
and to make this connection we're going to use
10

10

00:00:21.050  -->  00:00:25.870
the fit method, that will fit our A&amp;N to the training set.
11

11

00:00:25.870  -->  00:00:27.200
Alright, so let's do it.
12

12

00:00:27.200  -->  00:00:30.397
We're gonna take as usual our object classifier
13

13

00:00:30.397  -->  00:00:33.570
then dot, because we're going to use the fit method,
14

14

00:00:33.570  -->  00:00:35.990
and then, of course, we take the fit method,
15

15

00:00:35.990  -->  00:00:38.120
here we go that's the one.
16

16

00:00:38.120  -->  00:00:40.240
Parenthesis to add the arguments
17

17

00:00:40.240  -->  00:00:42.280
and so as for all the others models
18

18

00:00:42.280  -->  00:00:44.050
we've built in this course
19

19

00:00:44.050  -->  00:00:46.600
well the first argument is the data set
20

20

00:00:46.600  -->  00:00:48.920
on which we want to train our classifier
21

21

00:00:48.920  -->  00:00:50.530
that is our training set.
22

22

00:00:50.530  -->  00:00:52.590
And as in the classification part
23

23

00:00:52.590  -->  00:00:55.210
this training set is separated in two arguments
24

24

00:00:55.210  -->  00:00:58.350
first x train, that is the matrix it features containing
25

25

00:00:58.350  -->  00:01:00.370
the observations of the train set,
26

26

00:01:00.370  -->  00:01:01.800
and then y train that contains
27

27

00:01:01.800  -->  00:01:04.040
the actual outcomes of the dependent variable
28

28

00:01:04.040  -->  00:01:06.500
for all the observations in our training set.
29

29

00:01:06.500  -->  00:01:08.810
Alright, so let's first input these two arguments
30

30

00:01:08.810  -->  00:01:12.783
So x train first and then y train.
31

31

00:01:13.750  -->  00:01:17.220
So far it's exactly like in the classification part
32

32

00:01:17.220  -->  00:01:18.750
when we used the fit method.
33

33

00:01:18.750  -->  00:01:20.230
But now things are going to be new
34

34

00:01:20.230  -->  00:01:23.170
because we will add two additional arguments
35

35

00:01:23.170  -->  00:01:26.510
and if we go back to the Stochastic Gradient Descent slide,
36

36

00:01:26.510  -->  00:01:29.050
you might guess what these two arguments are.
37

37

00:01:29.050  -->  00:01:31.180
As you can see in step six and seven
38

38

00:01:31.180  -->  00:01:34.060
of the Stochastic Gradient Descent Algorithm, while we see
39

39

00:01:34.060  -->  00:01:36.210
that we can choose to update the weight either
40

40

00:01:36.210  -->  00:01:39.060
after each observation passing through the A&amp;N,
41

41

00:01:39.060  -->  00:01:41.670
or after a batch of observations.
42

42

00:01:41.670  -->  00:01:44.630
So as you might guess, this first additional argument
43

43

00:01:44.630  -->  00:01:47.060
is going to be the batch size.
44

44

00:01:47.060  -->  00:01:50.070
And the batch size is the number of observations
45

45

00:01:50.070  -->  00:01:52.580
after which, you want to update the weight.
46

46

00:01:52.580  -->  00:01:53.910
Alright, and now what is going
47

47

00:01:53.910  -->  00:01:56.290
to be the second additional argument.
48

48

00:01:56.290  -->  00:01:58.770
Well, to find it, we need to look at step 7
49

49

00:01:58.770  -->  00:02:01.740
because indeed in step 7 there is this notion of epoch,
50

50

00:02:01.740  -->  00:02:04.450
and an epoch is basically a round when
51

51

00:02:04.450  -->  00:02:07.600
the whole training set passed through the A&amp;N
52

52

00:02:07.600  -->  00:02:10.180
and, in reality, training the A&amp;N consists
53

53

00:02:10.180  -->  00:02:14.370
of applying steps one to six over many epochs.
54

54

00:02:14.370  -->  00:02:16.460
So this second additional argument that we're going
55

55

00:02:16.460  -->  00:02:20.280
to input here is going to be the number of epoch.
56

56

00:02:20.280  -->  00:02:22.080
Alright so actually we can check it out,
57

57

00:02:22.080  -->  00:02:24.070
I'm going to press command I here
58

58

00:02:24.070  -->  00:02:26.580
to get some information of this fit function.
59

59

00:02:26.580  -->  00:02:28.060
And as you can see here,
60

60

00:02:28.060  -->  00:02:30.440
well first we input correctly the first two arguments
61

61

00:02:30.440  -->  00:02:32.010
which are the matrix of features and
62

62

00:02:32.010  -->  00:02:34.730
the dependent variable vector, and then we have these
63

63

00:02:34.730  -->  00:02:37.280
two additional arguments, the batch size,
64

64

00:02:37.280  -->  00:02:39.080
and the number of epoch.
65

65

00:02:39.080  -->  00:02:41.480
So here we can see 32 and 10,
66

66

00:02:41.480  -->  00:02:43.580
these are not numbers that we are going to choose.
67

67

00:02:43.580  -->  00:02:46.210
Again, this is where your deep learning artist soul
68

68

00:02:46.210  -->  00:02:49.290
comes into play, because again there is no rule of thumb
69

69

00:02:49.290  -->  00:02:52.090
and we need to experiment to find some optimal choice
70

70

00:02:52.090  -->  00:02:55.200
for this batch size here and this number of epochs.
71

71

00:02:55.200  -->  00:02:57.400
So right now we're not going to experiment,
72

72

00:02:57.400  -->  00:03:00.470
we will go with some fixed choice of batch size
73

73

00:03:00.470  -->  00:03:02.510
and number of epochs and we will choose
74

74

00:03:02.510  -->  00:03:06.520
a batch size of 10 and a number of epochs of 100,
75

75

00:03:06.520  -->  00:03:08.810
so that we can see the algorithm in action
76

76

00:03:08.810  -->  00:03:11.340
and so that we can see the accuracy improving over
77

77

00:03:11.340  -->  00:03:14.080
the rounds that is over the different epochs.
78

78

00:03:14.080  -->  00:03:15.380
Alright so let's do it.
79

79

00:03:15.380  -->  00:03:18.010
Let's add these two additional arguments.
80

80

00:03:18.010  -->  00:03:20.423
So first is batch size,
81

81

00:03:21.550  -->  00:03:26.550
so we say we want 10 and then NB epoch equals 100.
82

82

00:03:29.110  -->  00:03:30.320
Perfect.
83

83

00:03:30.320  -->  00:03:32.180
So now time for the show.
84

84

00:03:32.180  -->  00:03:34.420
We are going to see the Stochastic Gradient Descent
85

85

00:03:34.420  -->  00:03:36.320
in action and we are going to see how
86

86

00:03:36.320  -->  00:03:39.240
the accuracy is improving over the different rounds.
87

87

00:03:39.240  -->  00:03:42.040
So let's not wait anymore and let's start the show.
88

88

00:03:42.040  -->  00:03:45.430
I'm going to select this line and execute.
89

89

00:03:45.430  -->  00:03:47.370
Alright and now the action takes place,
90

90

00:03:47.370  -->  00:03:50.250
we can see the different epochs going on
91

91

00:03:50.250  -->  00:03:52.940
so we started with the 79% accuracy,
92

92

00:03:52.940  -->  00:03:55.733
then 82% accuracy in the second epoch.
93

93

00:03:58.390  -->  00:03:59.970
Alright so it's going pretty fast.
94

94

00:03:59.970  -->  00:04:03.630
We're almost getting to 25% of the total number of epochs.
95

95

00:04:03.630  -->  00:04:05.850
So which accuracy have we reached?
96

96

00:04:05.850  -->  00:04:08.940
Well, here we can see that after epoch number 24
97

97

00:04:08.940  -->  00:04:13.940
we reached an accuracy of 0.8486, almost 85%.
98

98

00:04:17.640  -->  00:04:22.640
Okay, epoch number 37 out of 100 accuracy reached 85%.
99

99

00:04:25.010  -->  00:04:27.810
We can also see the information about the loss function.
100

100

00:04:31.440  -->  00:04:33.840
Alright and we've just passed half way and we can see here
101

101

00:04:33.840  -->  00:04:38.023
for epoch number 54 an accuracy of 85%.
102

102

00:04:42.410  -->  00:04:47.120
I think we're going to converge into a 86% accuracy,
103

103

00:04:47.120  -->  00:04:48.380
that would be pretty good.
104

104

00:04:48.380  -->  00:04:52.953
Epoch number 70, here we go 86.27%.
105

105

00:04:53.940  -->  00:04:58.940
70, it's converging still 86% for epoch number 81.
106

106

00:04:59.080  -->  00:05:01.080
Alright, we're getting close to the end.
107

107

00:05:02.300  -->  00:05:07.300
Epoch number 90 out of 100 still 86%.
108

108

00:05:10.480  -->  00:05:13.910
And eventually, our model is ready!
109

109

00:05:13.910  -->  00:05:17.520
And I think we reached an accuracy of 86%.
110

110

00:05:17.520  -->  00:05:18.780
Yes, definitely.
111

111

00:05:18.780  -->  00:05:23.530
Here we can see 86.50%, that was expected and that's how
112

112

00:05:23.530  -->  00:05:26.450
the Stochastic Gradient Descent algorithm performed
113

113

00:05:26.450  -->  00:05:28.240
on this training set here.
114

114

00:05:28.240  -->  00:05:29.930
So great, very exciting this is actually
115

115

00:05:29.930  -->  00:05:32.080
the first time we see something like that
116

116

00:05:32.080  -->  00:05:35.340
because so far all our models executed in one second,
117

117

00:05:35.340  -->  00:05:36.840
even less than one second.
118

118

00:05:36.840  -->  00:05:38.275
So here I'm very happy to introduce you
119

119

00:05:38.275  -->  00:05:41.630
to this new kind of machinery model,
120

120

00:05:41.630  -->  00:05:43.750
the artificial neural network.
121

121

00:05:43.750  -->  00:05:46.580
Great, so I hope you liked it and now time for
122

122

00:05:46.580  -->  00:05:49.030
the last step which will be to predict
123

123

00:05:49.030  -->  00:05:52.130
the deceit results while we already know what to expect
124

124

00:05:52.130  -->  00:05:56.260
in terms of accuracy, we expect an accuracy around 86%.
125

125

00:05:56.260  -->  00:05:59.760
So we'll check it out, it's going to be very easy actually
126

126

00:05:59.760  -->  00:06:02.470
because you know everything is already well prepared
127

127

00:06:02.470  -->  00:06:04.670
thanks to our classification template.
128

128

00:06:04.670  -->  00:06:07.480
So we won't need to change anything here in this line
129

129

00:06:07.480  -->  00:06:09.970
to get the predicted probabilities that the customers
130

130

00:06:09.970  -->  00:06:12.700
of the test set leave the bank and send
131

131

00:06:12.700  -->  00:06:14.190
for the confusion matrix here.
132

132

00:06:14.190  -->  00:06:16.650
Everything is already well prepared.
133

133

00:06:16.650  -->  00:06:18.600
So we'll do these last two steps in the next
134

134

00:06:18.600  -->  00:06:20.530
and final tutorial and until then,
135

135

00:06:20.530  -->  00:06:21.530
enjoy deep learning.
