WEBVTT
1
00:00:01.140 --> 00:00:05.580
Understanding your availability requirements is extremely important so you

2
00:00:05.580 --> 00:00:11.160
don't waste time and money overbuilding a solution or end up underbuilding

3
00:00:11.160 --> 00:00:14.040
and have the system fail at a critical time.

4
00:00:14.040 --> 00:00:18.170
Let's go through some options when it comes to availability and when you

5
00:00:18.170 --> 00:00:22.350
might choose one over the other. Depending on the database service you're

6
00:00:22.350 --> 00:00:27.200
using, some high availability configurations are automatic or as easy as

7
00:00:27.200 --> 00:00:29.760
clicking a checkbox to enable the option,

8
00:00:29.760 --> 00:00:34.620
while for other services, you're going to need to do a little more work.

9
00:00:34.620 --> 00:00:38.840
First, let's tackle the simple case, a single instance.

10
00:00:38.840 --> 00:00:41.960
This is best suited for development environments where the data

11
00:00:41.960 --> 00:00:44.720
isn't critical and if the system crashes,

12
00:00:44.720 --> 00:00:49.390
the person using it knows how and has access to just start

13
00:00:49.390 --> 00:00:52.420
it back up. Since development can often break the

14
00:00:52.420 --> 00:00:55.240
database, speaking from experience,

15
00:00:55.240 --> 00:00:59.770
it's nice to provide developers with their own copy so they can move faster

16
00:00:59.770 --> 00:01:04.150
without affecting other team members in a shared environment. Running single

17
00:01:04.150 --> 00:01:07.320
instances reduces management overhead and cost,

18
00:01:07.320 --> 00:01:11.110
so it's a good fit for noncritical scenarios.

19
00:01:11.110 --> 00:01:17.140
Next, we have multi‑AZ, or, running in more than one availability zone.

20
00:01:17.140 --> 00:01:21.540
This configuration is actually addressing two different problems.

21
00:01:21.540 --> 00:01:24.840
The first is having a single point of failure.

22
00:01:24.840 --> 00:01:29.850
When your database runs on a single instance and that one instance goes down,

23
00:01:29.850 --> 00:01:31.640
you've lost your database.

24
00:01:31.640 --> 00:01:35.520
Clustering multiple machines to serve a single database is a way to

25
00:01:35.520 --> 00:01:40.160
mitigate having a single point of failure. Availability zones take it a

26
00:01:40.160 --> 00:01:45.030
step further by not only running your database on multiple machines, but

27
00:01:45.030 --> 00:01:48.540
also physically separating those machines.

28
00:01:48.540 --> 00:01:52.390
Running multiple machines in different physical locations provides

29
00:01:52.390 --> 00:01:55.940
a very good foundation for high availability.

30
00:01:55.940 --> 00:01:59.780
So what is an availability zone? An availability zone is an

31
00:01:59.780 --> 00:02:05.470
isolated set of resources within an AWS region that are separated

32
00:02:05.470 --> 00:02:10.200
such that a fire or power outage in one availability zone should

33
00:02:10.200 --> 00:02:13.050
not affect other availability zones.

34
00:02:13.050 --> 00:02:15.880
They're also connected by high speed networks,

35
00:02:15.880 --> 00:02:19.820
so running a database cluster across availability zones shouldn't

36
00:02:19.820 --> 00:02:22.940
add significant latency to your application.

37
00:02:22.940 --> 00:02:28.460
Most of the available managed database solutions are multi‑AZ by default,

38
00:02:28.460 --> 00:02:31.230
since that configuration meets most production

39
00:02:31.230 --> 00:02:33.840
requirements for high availability.

40
00:02:33.840 --> 00:02:34.530
Finally,

41
00:02:34.530 --> 00:02:41.010
we have multi‑region. AWS regions are geographically separated around the world,

42
00:02:41.010 --> 00:02:45.630
such that a disaster affecting one region has a very small chance of

43
00:02:45.630 --> 00:02:49.130
affecting another region. In the history of AWS,

44
00:02:49.130 --> 00:02:54.540
there have only been a few outages that took out a service in an entire region.

45
00:02:54.540 --> 00:03:01.840
For example, S3 was down in the North Virginia region for 4‑5 hours in 2017,

46
00:03:01.840 --> 00:03:08.040
and EC2 was down for 1‑5 hours in the Sydney region in 2016.

47
00:03:08.040 --> 00:03:12.540
While regional outage mitigation is one reason to go multi‑region,

48
00:03:12.540 --> 00:03:16.080
a more common case for operating across regions is

49
00:03:16.080 --> 00:03:18.700
to get data closer to your users.

50
00:03:18.700 --> 00:03:22.540
The cost and complexity of a multi‑region deployment will vary

51
00:03:22.540 --> 00:03:26.820
depending on the database service you use. For services like Amazon

52
00:03:26.820 --> 00:03:31.520
Aurora Global Database and DynamoDB global tables, creating a

53
00:03:31.520 --> 00:03:35.830
multi‑region deployment is relatively simple. For other services, it

54
00:03:35.830 --> 00:03:40.360
may not be quite as readily supported, although features are constantly evolving,

55
00:03:40.360 --> 00:03:42.540
so that could change over time.

56
00:03:42.540 --> 00:03:48.240
A multi‑region architecture is going to cost the most and be the most complex.

57
00:03:48.240 --> 00:03:52.550
So unless you have a specific requirement for multi‑region,

58
00:03:52.550 --> 00:04:00.000
you can usually stick with multi‑AZ and achieve the necessary availability for your database system.

