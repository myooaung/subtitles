1

00:00:00,390  -->  00:00:03,170
Cap analysis we've talked about cap a lot.

2

00:00:03,180  -->  00:00:08,640
And in fact we've talked about cap that much that I'm no longer even saying cumulative accuracy profile

3

00:00:08,640  -->  00:00:14,910
because I am assuming that you're entirely comfortable with this abbreviation and the whole term and

4

00:00:14,910  -->  00:00:15,560
what it means.

5

00:00:15,720  -->  00:00:21,720
So let's see how to analyze the cap as we've discussed.

6

00:00:21,750  -->  00:00:28,590
There are three lines that are important on the Kepcher of the blue line which is the random line when

7

00:00:28,590  -->  00:00:31,950
you select your samples at random.

8

00:00:31,980  -->  00:00:38,980
The red line which is our model line the and different models will have different red lines but basically

9

00:00:38,980  -->  00:00:40,020
look something like that.

10

00:00:40,200  -->  00:00:46,500
And the gray line which is the perfect model or when you have a crystal ball when you can select all

11

00:00:46,560  -->  00:00:54,990
of the future turners or purchaser's or whatever action takers and you can select them right away on

12

00:00:54,990  -->  00:00:59,460
the dot before even selecting one single person that you don't want to select.

13

00:00:59,790  -->  00:01:05,970
And so these are the three main lines and how do we analyze this cap Kaveri know how to build it.

14

00:01:05,980  -->  00:01:09,280
But what can we derive what insights can we derive from here.

15

00:01:09,420  -->  00:01:14,700
Well it's kind of intuitive that the closer your red line is to the gray line the better you model the

16

00:01:14,700  -->  00:01:17,670
closer to the blue line the worse.

17

00:01:17,670  -->  00:01:19,730
So how can we quantify this effect.

18

00:01:20,040  -->  00:01:26,930
Well there is a standard approach to calculate the accuracy ratio and to calculate accuracy ratios you

19

00:01:26,950  -->  00:01:34,200
take the area under the perfect model or the perfect line which is color in gray here and it's called

20

00:01:34,290  -->  00:01:35,370
a pea.

21

00:01:35,790  -->  00:01:44,640
And then you need to take that area under the red line which is colored in red here which is a R and

22

00:01:44,850  -->  00:01:46,740
then you need to divide one by the other.

23

00:01:46,770  -->  00:01:53,290
So you need to divide a r by AP and then this ratio that you get is obviously between 0 and 1.

24

00:01:53,460  -->  00:01:59,340
And the closer this ratio is to 1 the better the further it is away from one and close to zero the worse

25

00:01:59,340  -->  00:02:00,420
.

26

00:02:00,420  -->  00:02:05,030
However it can be quite complicated to calculate this area under the curve statistical tools can do

27

00:02:05,030  -->  00:02:05,820
it for you.

28

00:02:05,910  -->  00:02:14,130
But how can you assess the cap curve by just looking at it so visually it's not that easy to get this

29

00:02:14,130  -->  00:02:16,540
quantifiable metric just by looking at the curve.

30

00:02:16,590  -->  00:02:19,990
So there's a second approach and that's what we're going to discuss.

31

00:02:19,990  -->  00:02:28,680
Now let's get rid of areas and instead of looking at the area what you can do is look at the 50 percent

32

00:02:28,680  -->  00:02:36,000
line on the horizontal axis and look where it crosses your model and then look at where that line the

33

00:02:36,000  -->  00:02:42,270
horizontal line from there crosses the vertical axis So basically how many turners will you pick up

34

00:02:42,630  -->  00:02:50,640
or action takers or how many positive outcomes are you going to identify if you take 50 percent of your

35

00:02:50,640  -->  00:02:51,620
population.

36

00:02:51,720  -->  00:02:55,150
And in this case we can see it's around 90 percent or something like that.

37

00:02:55,290  -->  00:03:01,920
And just by looking at that there is like a rule of thumb how you can assess your model based on that

38

00:03:01,920  -->  00:03:03,640
X number and here it is.

39

00:03:03,670  -->  00:03:04,230
Are you ready.

40

00:03:04,230  -->  00:03:05,060
Here we go.

41

00:03:05,070  -->  00:03:10,000
So if x is less than 60 percent the model is rubbish.

42

00:03:10,440  -->  00:03:14,410
Basically it's not useful at all.

43

00:03:14,640  -->  00:03:19,270
You can create a better one probably you can create a better one and you need to try again.

44

00:03:19,650  -->  00:03:27,150
If your model your X is between 60 percent and 70 percent then the model is considered to be poor poor

45

00:03:27,150  -->  00:03:30,390
or average and by the way these are my this is my rule of thumb.

46

00:03:30,390  -->  00:03:34,900
Other people might have a different rule of thumb but this is what I go by is between 60 percent and

47

00:03:34,910  -->  00:03:37,590
those and it's it's a poor model to be honest like you can.

48

00:03:37,590  -->  00:03:39,890
You can do better than that.

49

00:03:40,530  -->  00:03:46,110
If it's if X is between 70 percent and 80 percent that's a good model that's already where you should

50

00:03:46,110  -->  00:03:53,130
be aiming for anything above 70 percent that's can deliver good quality insights to the business and

51

00:03:53,130  -->  00:03:54,670
actually deliver value.

52

00:03:54,780  -->  00:03:58,620
Anything between 80 percent and 90 percent like we see here is very good.

53

00:03:58,620  -->  00:04:00,210
It's extremely good.

54

00:04:00,210  -->  00:04:08,250
That's if you can get a model over 80 percent that is an amazing result and anything above 90 percent

55

00:04:08,250  -->  00:04:08,980
up to 100.

56

00:04:09,000  -->  00:04:10,540
That is just too good.

57

00:04:10,650  -->  00:04:17,800
It is too good to believe and the are there is one option that there should be very careful here with

58

00:04:18,100  -->  00:04:19,350
his overfitting.

59

00:04:19,410  -->  00:04:25,320
If your model is showing you results like 90 percent or save for Mulshine you 100 percent then the obvious

60

00:04:25,320  -->  00:04:30,420
answer there is that one of your independent variables is actually a post facto variable meaning that

61

00:04:30,930  -->  00:04:33,930
it shouldn't be in the data because it's looking into the future.

62

00:04:34,140  -->  00:04:39,570
The person who supplied you that variable forgot to take it out or forgot to explain to you that you

63

00:04:39,570  -->  00:04:46,470
know their credit score actually is turned into zero after they leave the bank and therefore everybody

64

00:04:46,470  -->  00:04:51,590
offer zero credit card obviously has left the bank and therefore your model is picking them up like

65

00:04:51,950  -->  00:04:53,550
like it's super easy.

66

00:04:53,550  -->  00:04:57,870
So if you have 100 percent that's definitely something or if your variables even if you have 90 to 100

67

00:04:57,870  -->  00:05:02,130
percent you have to check that there could be some forward looking variables.

68

00:05:02,130  -->  00:05:08,220
The other thing is overfitting you could be overfitting a model and what that means is that you your

69

00:05:08,220  -->  00:05:15,110
model has been so well fit that specific data set that you supplied it that when you try it that it's

70

00:05:15,110  -->  00:05:18,570
just heavily relying on the anomalies in that data set.

71

00:05:18,600  -->  00:05:24,720
And when you feed it a new data set like you know in a month time or something like not not training

72

00:05:24,780  -->  00:05:26,730
or not the data that you trained your model on.

73

00:05:26,730  -->  00:05:32,130
We'll talk about this a bit a lot more actually in the coming tutorials but so if you feed this model

74

00:05:32,130  -->  00:05:36,900
some data that you want to actually predict on then you will crash it all it won't crash it will it

75

00:05:36,900  -->  00:05:40,560
won't perform as well perform you know at the 60 percent mark or something.

76

00:05:40,560  -->  00:05:44,490
So that means the model is overfit it and be very careful about that.

77

00:05:44,490  -->  00:05:50,010
We'll talk about overfitting more in fact in the coming to terms we will learn how to avoid that problem

78

00:05:50,020  -->  00:05:50,180
.

79

00:05:50,340  -->  00:05:57,930
And finally if you can get an x or this parameter to be between 90 percent 100 percent and you're not

80

00:05:57,930  -->  00:06:03,590
using for looking parameters or not overfitting then give me a call because I might have a job for you

81

00:06:04,320  -->  00:06:11,790
people like that are rare and I have a lot of headhunters looking for people who can do modeling like

82

00:06:11,790  -->  00:06:12,090
that.

83

00:06:12,090  -->  00:06:15,530
So definitely keep that in mind.

84

00:06:15,570  -->  00:06:16,060
Look for it.

85

00:06:16,130  -->  00:06:18,530
And then until next time happy analyzing
