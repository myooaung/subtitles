1

00:00:00,330  -->  00:00:05,670
Hello and welcome to this art tutorial Center following tutorials we're going to implement the a priori

2

00:00:05,670  -->  00:00:11,130
algorithm and as you know we are going to make this machine learning model to create some added value

3

00:00:11,220  -->  00:00:12,840
in some specific business.

4

00:00:12,840  -->  00:00:18,180
And in this part this business problem is going to be about optimizing the sales in a grocery store

5

00:00:18,410  -->  00:00:23,850
or grocery store in the south of France and you're going to perfectly understand how the a priori algorithm

6

00:00:23,850  -->  00:00:27,940
is going to do a perfect job at doing this optimizing the sales.

7

00:00:28,140  -->  00:00:34,130
Because recently a lot of stores considerably created some added value things to machine learning and

8

00:00:34,150  -->  00:00:39,960
especially Association rule learning by using it to optimize the sales of their products.

9

00:00:39,990  -->  00:00:41,240
And how did they do that.

10

00:00:41,400  -->  00:00:48,180
Well they just used Association rule learning to know exactly where to place the product in the store

11

00:00:48,180  -->  00:00:48,480
.

12

00:00:48,480  -->  00:00:51,360
You know for example I'll give you a very simple example.

13

00:00:51,720  -->  00:00:57,190
If someone buys some cereals Well the same person is very likely to buy some milk as well.

14

00:00:57,360  -->  00:01:03,090
So by placing the cereals close to the milk the store is very likely to put these two products into

15

00:01:03,090  -->  00:01:09,240
the same basket even if the buyer originally intended to only buy cereals or I can give you a more general

16

00:01:09,240  -->  00:01:12,860
example suppose a person wants to buy a specific product.

17

00:01:12,900  -->  00:01:14,390
Let's call it product A.

18

00:01:14,700  -->  00:01:20,310
And this product can be associated very well to another product B and the person who wants to buy the

19

00:01:20,310  -->  00:01:20,730
product.

20

00:01:20,760  -->  00:01:21,900
A minor.

21

00:01:21,900  -->  00:01:26,290
Think of this good association between the product and the product B.

22

00:01:26,460  -->  00:01:30,120
Well if you place the product in the product be next to each other.

23

00:01:30,240  -->  00:01:35,850
Well the association can suddenly pop up in the buyer's mind so that you know the buyer can tell hey

24

00:01:35,850  -->  00:01:37,460
that's actually a good combination.

25

00:01:37,470  -->  00:01:40,430
Why don't I try these two for my next lunch or something.

26

00:01:40,620  -->  00:01:45,260
And so again even if the buyer was originally meant to buy only the product.

27

00:01:45,510  -->  00:01:50,530
Well Judy this association that popped up in its mind thanks to the placement of product and product

28

00:01:50,530  -->  00:01:51,720
to be next to each other.

29

00:01:51,870  -->  00:01:55,560
Well the buyer finally buys a two parent A and B.

30

00:01:55,740  -->  00:02:00,990
So that's the idea of how we can create added value for retail stores or grocery stores.

31

00:02:00,990  -->  00:02:06,510
And so what we'll make in this future tutorials to optimize the sales can be also applied to any other

32

00:02:06,510  -->  00:02:08,850
store that is selling some different products.

33

00:02:08,910  -->  00:02:10,640
You can think of an online store.

34

00:02:10,740  -->  00:02:14,350
You know these recommendations people who bought this also bought that.

35

00:02:14,490  -->  00:02:19,980
Well these recommendations are based on association rules as well but not only it can be also the result

36

00:02:19,980  -->  00:02:25,980
of recommendation systems like collaborative filtering or a custom based item based collaborative filtering

37

00:02:26,060  -->  00:02:26,240
.

38

00:02:26,390  -->  00:02:29,040
Association will learning has a role to play.

39

00:02:29,340  -->  00:02:35,130
So now let's make our first association rule and an algorithm which is the a priori model for this specific

40

00:02:35,130  -->  00:02:36,860
store in the south of France.

41

00:02:36,960  -->  00:02:37,960
So let's do it.

42

00:02:38,160  -->  00:02:43,700
As usual we're going to set the working directory by going to our new part folder which is the fall

43

00:02:43,700  -->  00:02:49,200
of Part Five Association rote learning and we're starting with the a priori algorithm.

44

00:02:49,200  -->  00:02:54,390
So that's the fall that we want to set as we can direct remission that you have the market basket optimizations

45

00:02:54,400  -->  00:02:59,630
he has found and you can click on this more button here and then set as working directory.

46

00:02:59,640  -->  00:03:00,220
All right.

47

00:03:00,220  -->  00:03:01,490
We're on the rifle now.

48

00:03:01,560  -->  00:03:08,300
So the first thing we're going to do is to import the dataset so the dataset is marking back at optimization

49

00:03:08,310  -->  00:03:11,690
so as usual we were going to call it data sets.

50

00:03:11,790  -->  00:03:16,110
And then of course we're going to use to read that as we function.

51

00:03:16,230  -->  00:03:19,930
And now we simply put in quotes the name of the city.

52

00:03:20,040  -->  00:03:21,650
So here we go.

53

00:03:21,690  -->  00:03:29,790
Market Basket optimization dot CSC.

54

00:03:29,820  -->  00:03:34,950
All right so let's execute that and let's explain what the dataset is about.

55

00:03:34,950  -->  00:03:35,660
Here we go.

56

00:03:35,670  -->  00:03:41,880
They said well imported it has seven thousand five hundred observations and 20 variables.

57

00:03:41,880  -->  00:03:45,070
So let's check it out and clicking on dataset here.

58

00:03:45,090  -->  00:03:45,410
All right.

59

00:03:45,420  -->  00:03:46,620
And that is Dasent.

60

00:03:46,620  -->  00:03:54,340
So the first thing that we can see here is that this line here contains some products.

61

00:03:54,360  -->  00:03:59,620
These products here and of course these are not the titles of the different comps here.

62

00:03:59,640  -->  00:04:07,590
So to improve this what we can first do is to add this Hetter argument here had are equals and then

63

00:04:07,590  -->  00:04:14,580
simply false this way and that tells are that the first line of our data set doesn't contain the titles

64

00:04:14,580  -->  00:04:15,880
of the columns.

65

00:04:15,990  -->  00:04:17,870
So let's check it out now.

66

00:04:18,150  -->  00:04:19,950
That's like this line and execute.

67

00:04:19,950  -->  00:04:20,990
Here we go.

68

00:04:21,360  -->  00:04:24,710
Let's close this and click again on the dataset.

69

00:04:24,930  -->  00:04:25,470
And here we go.

70

00:04:25,500  -->  00:04:30,960
We don't have any titles for the columns but you know this first observation is no longer seen as the

71

00:04:30,960  -->  00:04:32,430
titles of the columns.

72

00:04:32,440  -->  00:04:34,200
That's the real observation itself.

73

00:04:34,200  -->  00:04:34,450
OK.

74

00:04:34,470  -->  00:04:37,770
So better now let's describe the data set.

75

00:04:37,890  -->  00:04:44,100
So as I told you we're making this a priori model for a store in the south of France.

76

00:04:44,190  -->  00:04:49,550
And so we want to find out the association rules of the different products of this tour to see how the

77

00:04:49,550  -->  00:04:55,430
manager of the store can optimize the placement of its different products to optimize the sales.

78

00:04:55,660  -->  00:04:55,910
OK.

79

00:04:55,900  -->  00:05:01,600
So the first thing to say now is that this store is located in one of the most popular places in the

80

00:05:01,600  -->  00:05:02,480
south of France.

81

00:05:02,500  -->  00:05:08,480
So a lot of people go into the store and so you know this place is a very convivial place a very friendly

82

00:05:08,470  -->  00:05:12,380
place where people love to hang out relax talk to each other.

83

00:05:12,400  -->  00:05:18,340
And so these people come very often to this tour because even if it's not by something it's a place

84

00:05:18,340  -->  00:05:23,630
to meet their friends and therefore the manager of the store noticed and calculated that on average

85

00:05:23,930  -->  00:05:27,750
each customer goes and buys something to the store once a week.

86

00:05:27,760  -->  00:05:34,630
So this dataset here contains the seven thousand five hundred transactions of all the different customers

87

00:05:34,630  -->  00:05:38,140
that bought a basket of products during a whole week.

88

00:05:38,140  -->  00:05:42,960
Indeed the manager took it as the basis of its analysis because since each customer is going an average

89

00:05:43,000  -->  00:05:49,210
once a week to the store then the transaction registered over a week is quite representative of what

90

00:05:49,210  -->  00:05:50,570
customers want to buy.

91

00:05:50,810  -->  00:05:58,830
So based on all these 7500 transactions our machinery model our a priori model is going to learn the

92

00:05:58,830  -->  00:06:03,120
different associations it can make to actually understand the rules.

93

00:06:03,230  -->  00:06:08,970
Such as if customers buy this product then they're likely to buy this other set of products.

94

00:06:08,990  -->  00:06:13,870
So that's what we want to figure out and that's what our pre-read model will tell us.

95

00:06:14,010  -->  00:06:14,580
OK.

96

00:06:14,950  -->  00:06:21,610
So each observation line here corresponds to a specific customer who bought a specific basket of product

97

00:06:21,630  -->  00:06:21,760
.

98

00:06:21,880  -->  00:06:28,750
So for example if you look at line two here that corresponds to one customer who bought burgers meatballs

99

00:06:28,840  -->  00:06:31,570
and eggs at a specific time of this week.

100

00:06:31,810  -->  00:06:36,130
And that's the same for all the other observations that correspond to other customers.

101

00:06:36,130  -->  00:06:40,860
Or maybe the same customer who went back to the store another day or another time.

102

00:06:40,900  -->  00:06:42,900
So that's what today is about.

103

00:06:42,910  -->  00:06:45,180
But actually this is not the set.

104

00:06:45,190  -->  00:06:49,440
We're going to use to train our apriori model.

105

00:06:49,730  -->  00:06:55,380
And the reason is that the package we're going to use to build our Priore model which is by the way

106

00:06:55,380  -->  00:07:00,040
the Avril's package doesn't take a dataset like this as input.

107

00:07:00,040  -->  00:07:02,630
It doesn't take a C as we felt that we import.

108

00:07:02,650  -->  00:07:09,160
Thanks to the redone cxxviii function what it takes as input is called a sparse matrix.

109

00:07:09,160  -->  00:07:11,100
And so what is a sparse matrix.

110

00:07:11,140  -->  00:07:16,990
It's actually a matrix that contains a lot of zeroes in machinery and you will encounter a lot of times

111

00:07:17,000  -->  00:07:21,520
the word sparsity that corresponds to a large number of zeros.

112

00:07:21,620  -->  00:07:26,800
So a sparse matrix is a matrix containing a very few number of non-zero values.

113

00:07:26,800  -->  00:07:32,960
So what we're going to do now is transform this dataset here into a sparse matrix and can you guess

114

00:07:32,950  -->  00:07:34,010
what we're going to do.

115

00:07:34,300  -->  00:07:39,060
Well what you're going to do is take all the different products of this data set.

116

00:07:39,400  -->  00:07:44,510
And actually I already know that there are a hundred and twenty products and we are going to attribute

117

00:07:44,600  -->  00:07:48,090
one column to each of these 120 products.

118

00:07:48,110  -->  00:07:52,370
So that means we'll get a hundred and twenty columns.

119

00:07:52,420  -->  00:07:53,530
So for example.

120

00:07:53,800  -->  00:07:59,320
So for example we'll have to call them Shrem they call them almonds to call them avocado to call them

121

00:07:59,320  -->  00:08:06,400
vegetables mix Karachi's energy drink tomato juice up to the 100 and 20th product that there is we're

122

00:08:06,400  -->  00:08:08,790
going to see all the products then on a plot.

123

00:08:09,040  -->  00:08:14,210
But in this area said there are a hundred and twenty products which are by the way the one hundred and

124

00:08:14,190  -->  00:08:16,540
twenty products of the store.

125

00:08:16,570  -->  00:08:21,390
So there is going to be one going for each of these products and that's going to be the columns.

126

00:08:21,620  -->  00:08:28,410
And then the lines are still going to be the different transactions corresponding to each of the 7500

127

00:08:28,510  -->  00:08:32,260
customers that bought a basket of products during the whole week.

128

00:08:32,260  -->  00:08:38,470
But instead of having the list of the product they bought We will have in each of the 120 columns here

129

00:08:38,790  -->  00:08:40,480
a zero or one.

130

00:08:40,660  -->  00:08:46,340
And it's going to be a 1 if the product is in the basket of the customer during its transaction and

131

00:08:46,350  -->  00:08:49,300
is zero if the product is not in the basket.

132

00:08:49,300  -->  00:08:52,760
So for example let's take the second customer here.

133

00:08:53,020  -->  00:08:58,440
The second customer bought a basket of three product burgers meat balls and eggs.

134

00:08:58,630  -->  00:08:59,290
OK.

135

00:08:59,290  -->  00:09:05,630
So in our sparse matrix we'll have one burgers call them 1 meatballs call and 1 x call them.

136

00:09:05,620  -->  00:09:08,360
They're not necessarily going to be next to each other.

137

00:09:08,410  -->  00:09:14,770
You know burgers can be the fifth column and meatballs can be Neyens call them an X can be 12 Scullin

138

00:09:15,050  -->  00:09:20,020
that depends on how the Avril's package is going to make the matrix but we will have a column for each

139

00:09:20,020  -->  00:09:21,260
of these three products.

140

00:09:21,250  -->  00:09:26,380
And so in these columns since the customer number two bought some burgers meatballs and eggs there will

141

00:09:26,380  -->  00:09:31,630
be a one in each of these columns that will be a one in the burbs column or one in the meatballs column

142

00:09:31,930  -->  00:09:36,760
and the one in the X column and all the rest of the columns are going to have a zero value.

143

00:09:36,860  -->  00:09:42,140
And that's because all the other products were not in the basket of this customer number two.

144

00:09:42,380  -->  00:09:48,200
So you can guess you can imagine that we're going to have a lot of zero values and that's even more

145

00:09:48,190  -->  00:09:53,170
true considering the fact that we have a lot of customers that bought baskets of only one product.

146

00:09:53,170  -->  00:09:56,400
For example this customer number 10 here bought some French fries.

147

00:09:56,560  -->  00:10:00,210
This one bought some cookies this one bought some mineral water.

148

00:10:00,400  -->  00:10:05,300
So you know for these three customers who bought only one product we're going to have only one column

149

00:10:05,290  -->  00:10:11,780
that contains a non-zero value and all the other columns that means all the 119 Collins will contain

150

00:10:11,770  -->  00:10:12,570
zeros.

151

00:10:12,700  -->  00:10:16,240
So you can see that we're going to have a lot of zeroes in this matrix.

152

00:10:16,300  -->  00:10:22,360
And so for those of you who are discovering sparsity I'm happy to introduce you to sparse matrices so

153

00:10:22,450  -->  00:10:25,250
let's build this sparse matrix right now.

154

00:10:25,330  -->  00:10:27,260
You'll see that it's going to be very easy.

155

00:10:27,400  -->  00:10:31,120
So let's go back to our code and let's create the sparse matrix.

156

00:10:31,120  -->  00:10:37,710
So to create the sparse matrix we're going to use a package of course and this package is the Avril's

157

00:10:37,720  -->  00:10:38,350
package.

158

00:10:38,360  -->  00:10:42,390
So we are going to install that as important.

159

00:10:42,670  -->  00:10:49,420
So as usual we're going to take the function install packages and then in parenthesis we just input

160

00:10:49,720  -->  00:10:54,850
the name of the package in quotes and that's the Avril's package.

161

00:10:55,030  -->  00:10:55,930
All right.

162

00:10:56,080  -->  00:10:59,690
So let's check to see if I have it.

163

00:10:59,830  -->  00:11:01,470
Well I already know I have it.

164

00:11:01,490  -->  00:11:03,810
It's actually already here and already imported.

165

00:11:03,940  -->  00:11:10,090
So that's the Avril's package for which the description says that it's Mining Association rules and

166

00:11:10,100  -->  00:11:11,640
frequent item sets.

167

00:11:11,820  -->  00:11:16,010
OK so mine is already installed so I'm not going to execute this line.

168

00:11:16,030  -->  00:11:17,280
I'll just put in comment.

169

00:11:17,440  -->  00:11:23,380
And so if you don't have the Avril's package here in the package just list you need to select this line

170

00:11:23,800  -->  00:11:24,670
and execute.

171

00:11:24,760  -->  00:11:27,520
And this will install the package without any issue.

172

00:11:27,740  -->  00:11:31,170
And as far as I'm concerned I'm just going to put that in.

173

00:11:31,420  -->  00:11:36,260
Right and to make sure that the rules package is well imported.

174

00:11:36,460  -->  00:11:42,050
We need to add the line here library and in parenthesis Avril's already there.

175

00:11:42,100  -->  00:11:42,940
Perfect.

176

00:11:43,060  -->  00:11:47,990
And that makes sure that if you execute the whole script the Avril's package will be imported.

177

00:11:48,220  -->  00:11:51,910
And now we were ready to create our sparse matrix.

178

00:11:52,000  -->  00:11:58,160
So since our data set has no use here because we're not going to use it to build and train our printer

179

00:11:58,150  -->  00:12:05,450
model we will call our sparse matrix again dataset again and to create the sparse matrix It's actually

180

00:12:05,470  -->  00:12:13,180
almost the same as importing ACSU file because instead of writing here read that says we we simply need

181

00:12:13,180  -->  00:12:21,040
to type read dot transactions read that transactions and then it's the same in parenthesis we need to

182

00:12:21,040  -->  00:12:23,710
input the name of the CSP file.

183

00:12:23,710  -->  00:12:27,470
So we'll copy that and paste it here.

184

00:12:27,940  -->  00:12:34,810
That's the first documents but then we need to specify to this function that the separator of our CHB

185

00:12:34,810  -->  00:12:37,140
file is actually a comma.

186

00:12:37,300  -->  00:12:41,320
So we need to add here cept the calls in quotes comma.

187

00:12:41,600  -->  00:12:47,320
And why do we need to do this it's because you know RACF we file if you open it with a text editor you

188

00:12:47,320  -->  00:12:50,320
will see that the different products are separated by a comma.

189

00:12:50,560  -->  00:12:55,540
And we actually didn't have to specify that the separator was coming here because that's the default

190

00:12:55,540  -->  00:12:58,040
separator of the reductions V function.

191

00:12:58,120  -->  00:13:02,050
But that's not the default separator of the reductions actions function.

192

00:13:02,090  -->  00:13:04,500
So that's why we need to specify here.

193

00:13:04,540  -->  00:13:08,730
So set equals come up and actually we could start here.

194

00:13:08,870  -->  00:13:13,880
But since I promised you to give you real life data sets I added on purpose and reality in the data

195

00:13:13,880  -->  00:13:14,340
sets.

196

00:13:14,410  -->  00:13:21,430
And this reality is about having some anomalies in the data and these anomalies are actually some duplicates

197

00:13:21,440  -->  00:13:21,590
.

198

00:13:21,670  -->  00:13:25,300
Indeed when this manager register all the different transactions.

199

00:13:25,300  -->  00:13:30,920
Well he might have been very likely to make some human mistakes to put some duplicates in the data.

200

00:13:31,030  -->  00:13:33,230
So for example if we go back to our dataset.

201

00:13:33,280  -->  00:13:37,550
So that's the whole data that's important that's his view with the readout function.

202

00:13:37,570  -->  00:13:44,290
And so for example when this transaction of the 30 first customer was registered one can make some mistake

203

00:13:44,290  -->  00:13:51,110
of putting twice like cream here for example and to train the a priori algorithm we need to have no

204

00:13:51,110  -->  00:13:51,860
duplicate.

205

00:13:52,000  -->  00:13:55,840
So there is actually a good way to handle these duplicates.

206

00:13:55,850  -->  00:14:00,360
It's actually very simple because we just need to add an additional argument.

207

00:14:00,550  -->  00:14:07,690
If we look at the readout transactions function here by pressing one you can see that our end of duplicate

208

00:14:07,750  -->  00:14:08,440
arguments.

209

00:14:08,710  -->  00:14:14,980
And as you can see it's a logical value specifying if duplicate items should be removed from the transactions

210

00:14:14,980  -->  00:14:15,240
.

211

00:14:15,250  -->  00:14:21,290
So since the a priori algorithm is trained on transaction data set they're supposed to have no duplicate

212

00:14:21,280  -->  00:14:22,090
values.

213

00:14:22,100  -->  00:14:30,520
We need to add this argument or and don't duplicate and set it to true.

214

00:14:30,730  -->  00:14:34,440
And that will remove all the duplicates in each of the transactions.

215

00:14:34,450  -->  00:14:39,290
Maybe your dataset won't have any duplicates but it's very common to have a few anomalies in dataset

216

00:14:39,360  -->  00:14:41,030
such as some duplicates.

217

00:14:41,180  -->  00:14:42,480
But here we will be fine.

218

00:14:42,490  -->  00:14:45,590
Thanks to our end of the blockade argument.

219

00:14:45,620  -->  00:14:50,390
All right so we're now actually ready to create our sparse matrix.

220

00:14:50,470  -->  00:14:54,770
So let's do this let's execute this line and here we go.

221

00:14:55,000  -->  00:14:55,580
All right.

222

00:14:55,720  -->  00:14:58,160
So now the sparse matrix is created.

223

00:14:58,360  -->  00:15:03,110
Unfortunately we cannot have a look at it as you can see if I click on these days here.

224

00:15:03,150  -->  00:15:06,060
The new dataset sparse matrix is not appearing here.

225

00:15:06,060  -->  00:15:12,910
That's actually the old one so we can close this but we can actually get some info about this sparse

226

00:15:12,900  -->  00:15:13,610
matrix.

227

00:15:13,720  -->  00:15:18,720
But before getting all these detailed information well we can see that we already have some information

228

00:15:18,900  -->  00:15:20,520
about the duplicate itself.

229

00:15:20,740  -->  00:15:26,310
When you execute this line to create your sparse matrix with the reduction sections function including

230

00:15:26,360  -->  00:15:31,410
our end of duplicates arguments you will automatically have this message distribution of transaction

231

00:15:31,410  -->  00:15:34,070
with duplicate and you'll see that we have 1 5.

232

00:15:34,120  -->  00:15:38,190
That means that there are five transactions containing one duplicates.

233

00:15:38,320  -->  00:15:45,240
And for example if in your dataset you have some triplicates duplicates there appear twice in any transaction

234

00:15:45,250  -->  00:15:45,410
.

235

00:15:45,580  -->  00:15:50,120
Well you will have two here and you will have the number of triplicates here.

236

00:15:50,160  -->  00:15:53,390
So that just gives the distribution of transaction with duplicates.

237

00:15:53,400  -->  00:15:55,010
And anyway now they're removed.

238

00:15:55,170  -->  00:16:02,270
So we can actually get some more detailed info about the sparse matrix and to get this info.

239

00:16:02,390  -->  00:16:07,390
We as we already did many times before need to use the summary function.

240

00:16:07,570  -->  00:16:08,560
So summary.

241

00:16:08,740  -->  00:16:11,060
And here we input data set.

242

00:16:11,110  -->  00:16:11,430
All right.

243

00:16:11,430  -->  00:16:16,110
And that will give us some info about the sparse matrix so let's execute this line.

244

00:16:16,120  -->  00:16:17,290
And here we go.

245

00:16:17,880  -->  00:16:18,910
So what do we see here.

246

00:16:18,900  -->  00:16:26,260
First we reminded that this dataset contains transactions as I have a matrix in sparse format so that

247

00:16:26,250  -->  00:16:32,610
exactly means that a sparse matrix and we can see that we have seven thousand five hundred and one rows

248

00:16:32,760  -->  00:16:40,120
and we have 119 columns and we can see that we have a density of 0.03 in the sparse matrix and what

249

00:16:40,120  -->  00:16:40,950
does that mean.

250

00:16:40,990  -->  00:16:46,610
That means that the proportion of non-zero values is 0.03.

251

00:16:46,770  -->  00:16:50,950
We have 3 percent non-zero values and 97 percent 0 values.

252

00:16:51,160  -->  00:16:53,520
Ok then we have the most RIKOON items.

253

00:16:53,520  -->  00:16:56,580
So the item that is the most bought is mineral water.

254

00:16:56,740  -->  00:17:01,690
Yes it can be very hot in the south of France and it's a good French tradition to have a bottle of water

255

00:17:01,890  -->  00:17:02,840
during meals.

256

00:17:03,120  -->  00:17:08,520
OK then the French love very much eggs they love spaghetti French fries chocolate and that's all the

257

00:17:08,530  -->  00:17:09,640
other products.

258

00:17:09,760  -->  00:17:16,440
And then we have some interesting information about the distribution of the baskets of all the 7500

259

00:17:16,470  -->  00:17:17,340
transactions.

260

00:17:17,350  -->  00:17:27,660
So for example here this one associated to 1754 means that there were 1754 baskets containing only one

261

00:17:27,660  -->  00:17:35,760
product and then we have 1358 baskets containing two products 1044 baskets containing three products

262

00:17:35,810  -->  00:17:36,760
et cetera.

263

00:17:37,170  -->  00:17:42,370
And we also have the quintiles of this distribution with the minimum value the maximum value.

264

00:17:42,450  -->  00:17:47,580
So the minimum value is of course a basket of one product the maximum value is a basket of 20 products

265

00:17:48,010  -->  00:17:54,220
and on average people put four products in their basket when they go to the store.

266

00:17:54,210  -->  00:17:54,520
All right.

267

00:17:54,530  -->  00:17:56,450
So that's interesting information.

268

00:17:56,490  -->  00:18:00,280
But of course we'll get some even more interesting information afterwards.

269

00:18:00,420  -->  00:18:04,640
And speaking of these more interesting informations we can already have one now.

270

00:18:04,810  -->  00:18:10,140
It's actually going to be visual information because we're going to make a frequency plot of the different

271

00:18:10,140  -->  00:18:14,130
products bought by the different customers in the store during this whole week.

272

00:18:14,400  -->  00:18:20,580
And so to get this plug very easily we can use one function of the Avril's package which is the item

273

00:18:20,670  -->  00:18:27,210
frequency plot function and in this function we just need to put two arguments which is going to be

274

00:18:27,370  -->  00:18:28,290
the data set.

275

00:18:28,300  -->  00:18:29,970
So that's the sparse matrix.

276

00:18:30,010  -->  00:18:32,710
That's the first argument and the second argument is tough.

277

00:18:32,760  -->  00:18:38,260
And and that's the number of the most solid products you want to have in this frequency plot.

278

00:18:38,380  -->  00:18:47,460
So for example if I put up any calls 100 I will get the 100 most purchased product by the French customers

279

00:18:47,460  -->  00:18:48,440
in this French store.

280

00:18:48,580  -->  00:18:49,810
So let's check it out.

281

00:18:49,850  -->  00:18:52,410
We're going to execute this line.

282

00:18:52,410  -->  00:18:53,130
Here we go.

283

00:18:53,140  -->  00:18:54,070
And that's the plug.

284

00:18:54,070  -->  00:18:58,360
Don't worry I'm going to zoom on it so that we can see better the products.

285

00:18:58,620  -->  00:18:59,460
And here we go.

286

00:18:59,670  -->  00:19:04,260
So that's the first 100 products most purchased by the customers.

287

00:19:04,260  -->  00:19:09,220
So that's kind of interesting and if you want to have less product in this plot you can just look at

288

00:19:09,220  -->  00:19:15,870
the top 10 and you'll get actually the first 10 products purchased by the customers which are of course

289

00:19:15,880  -->  00:19:17,420
the same first 10 products.

290

00:19:17,590  -->  00:19:17,860
OK.

291

00:19:17,860  -->  00:19:21,290
So this plot is actually going to be interesting for us.

292

00:19:21,390  -->  00:19:27,790
What's coming next because we will have to choose a value for the support according to the Priory algorithm

293

00:19:27,780  -->  00:19:34,840
itself and we will be able to actually use this plot to look at different supports of the product to

294

00:19:34,840  -->  00:19:37,440
choose a good value for support.

295

00:19:37,470  -->  00:19:39,950
So that's what we're going to do in the next tutorials.

296

00:19:39,950  -->  00:19:46,170
We're going to start training our a priori model on our data set which is going to be the sparse matrix

297

00:19:46,170  -->  00:19:47,560
here that we just built.

298

00:19:47,760  -->  00:19:50,570
And so I look forward to building the a priori model with you.

299

00:19:50,740  -->  00:19:52,960
And until then enjoy machine learning
