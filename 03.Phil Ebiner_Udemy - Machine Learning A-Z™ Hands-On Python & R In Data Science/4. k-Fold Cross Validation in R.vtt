WEBVTT
1
00:00:00.360 --> 00:00:06.360
Hello and welcome to this art to toil and mostly welcome to the last part of this course bartend model

2
00:00:06.360 --> 00:00:08.290
selection and boosting.

3
00:00:08.340 --> 00:00:10.170
So in this part we will do two things.

4
00:00:10.200 --> 00:00:16.010
First evaluating our moral performance and second improving our model performance.

5
00:00:16.020 --> 00:00:20.430
And then there will be this bonus section about one of the most powerful algorithm in machine learning

6
00:00:20.760 --> 00:00:24.610
which has become more and more popular and that is called Extreme boost.

7
00:00:24.780 --> 00:00:29.690
But first we want to be able to improve the model performance of all the machine learning models we've

8
00:00:29.700 --> 00:00:35.520
built in this course and improving the model performance can be done with a technique called model selection

9
00:00:35.790 --> 00:00:41.490
that consist of choosing the best parameters of your machine learning models because you know remember

10
00:00:41.730 --> 00:00:46.310
every time we build a machine learning model Well we have two types of parameters.

11
00:00:46.320 --> 00:00:51.210
The first type where the parameters that the model learns that is the parameters that were changed and

12
00:00:51.210 --> 00:00:57.210
found optimal values by running the model and then the second type of parameters the parameters that

13
00:00:57.210 --> 00:00:58.760
we chose ourselves.

14
00:00:58.770 --> 00:01:04.710
For example the kernel parameter in the kernel as we are model and these parameters are called the hyper

15
00:01:04.710 --> 00:01:05.790
parameters.

16
00:01:05.790 --> 00:01:10.920
So there is still room to improve the model because we can still choose some optimal values for these

17
00:01:10.920 --> 00:01:11.810
parameters.

18
00:01:11.970 --> 00:01:17.220
But since these parameters another parameters learned by the model then we need to figure out another

19
00:01:17.220 --> 00:01:22.280
way to choose these optimal values for these parameters for the hyper parameters.

20
00:01:22.500 --> 00:01:27.180
And that's one of the powerful thing we'll do in this part 10 and that's will be through a very efficient

21
00:01:27.180 --> 00:01:29.170
technique called grid search.

22
00:01:29.430 --> 00:01:35.580
But before we start grid search we need to optimize our way to evaluate our models because so far what

23
00:01:35.580 --> 00:01:39.550
we did is split our dataset between a training set and a test set.

24
00:01:39.660 --> 00:01:44.970
And you know we trained our model on the training sets and we tested its performance on the test set.

25
00:01:45.000 --> 00:01:48.200
That's a correct way of evaluating the model performance.

26
00:01:48.270 --> 00:01:53.430
But that's not the best one because we actually have the variance problem the variance problem can be

27
00:01:53.430 --> 00:01:57.110
explained by the fact that when we get the accuracy on the test set.

28
00:01:57.330 --> 00:02:01.810
Well if we run the model again and test again it's performance on another test set.

29
00:02:02.010 --> 00:02:04.460
Well we can get a very different accuracy.

30
00:02:04.770 --> 00:02:11.700
So judging our model performance only on one accuracy on one test set is actually not super relevant.

31
00:02:11.700 --> 00:02:15.620
That's not the most relevant way to evaluate the model performance.

32
00:02:15.720 --> 00:02:21.330
And so there is this technique called K4 cross-validation that improves this a lot because that will

33
00:02:21.330 --> 00:02:28.470
fix this Varians problem and how will it fix it it will fix it by spinning the training set into tenfold

34
00:02:28.740 --> 00:02:29.740
when cake will stand.

35
00:02:29.760 --> 00:02:31.760
And most of the time cake will stand.

36
00:02:31.980 --> 00:02:36.760
And we train our model a nine fold and we test it on the last remaining foot.

37
00:02:36.900 --> 00:02:42.550
And since with 10 falls we can make 10 different combinations of nine fours to trend a model and one

38
00:02:42.550 --> 00:02:43.800
for to test it.

39
00:02:43.800 --> 00:02:49.860
That means that we can train the model and test them on all N10 combinations of training and tests and

40
00:02:49.920 --> 00:02:54.570
that will already give us a much better idea of the model performance because what we can do have to

41
00:02:55.020 --> 00:03:01.050
take an average of the different accuracy is up to 10 evaluations and also compute a standard deviation

42
00:03:01.320 --> 00:03:02.890
to have a look at the variance.

43
00:03:02.910 --> 00:03:08.520
So eventually our analysis will be much more relevant and besides we'll know in which of these four

44
00:03:08.520 --> 00:03:14.010
categories will be because if we get a good accuracy and a small variance will be on the lower left

45
00:03:14.010 --> 00:03:20.010
one if we get a large accuracy and a high variance we will be on the lower right one if we get a small

46
00:03:20.010 --> 00:03:21.780
accuracy in a low variance.

47
00:03:21.780 --> 00:03:26.730
We will be on the upper left one and eventually if we get a low accuracy and high variance we will be

48
00:03:26.730 --> 00:03:28.140
on the right one.

49
00:03:28.140 --> 00:03:31.310
So this K4 cross-validation is very useful.

50
00:03:31.350 --> 00:03:35.200
And besides our performance analysis is much more relevant.

51
00:03:35.220 --> 00:03:38.630
So let's start with this K4 across the nation.

52
00:03:38.790 --> 00:03:41.180
Our first technique of moral selection.

53
00:03:41.280 --> 00:03:45.280
So since we already built a lot of models we're not going to build another one.

54
00:03:45.280 --> 00:03:50.410
We are going to use one of the model we built and apply careful the nation on it.

55
00:03:50.490 --> 00:03:56.040
And so the model we're going to use is this kernel as V.M. we made in part three classification.

56
00:03:56.190 --> 00:04:01.470
And I remember we used to predict if the customers are going to click on the ads on the social network

57
00:04:01.710 --> 00:04:03.950
to buy Yes no the SUV.

58
00:04:03.960 --> 00:04:06.980
So the model is already built and we already have everything.

59
00:04:07.080 --> 00:04:14.610
So what we're going to do is take the whole model and we are going to add a new section of code inside

60
00:04:14.610 --> 00:04:21.150
of it that is going to be of course the section code that will implement K4 cross-validation.

61
00:04:21.150 --> 00:04:26.260
So before we start doing it let's pick the right folder as a working directory.

62
00:04:26.340 --> 00:04:27.550
So we go to machine.

63
00:04:27.590 --> 00:04:30.150
It is that we are now in the last part of this course.

64
00:04:30.150 --> 00:04:36.830
Congratulations for reaching out bartend mouse selection and boosting and section 48 model selection.

65
00:04:37.020 --> 00:04:37.380
All right.

66
00:04:37.380 --> 00:04:40.210
Make sure that you have the social network at as you file.

67
00:04:40.260 --> 00:04:42.200
And if that's the case you're ready to go.

68
00:04:42.600 --> 00:04:46.520
All right so now where do we apply the K4 cross-validation code section.

69
00:04:46.650 --> 00:04:52.890
Well since that consists of evaluating them all performance Well the most relevant location to put it

70
00:04:53.130 --> 00:04:57.160
is right after we build our kernel as a model that is right.

71
00:04:57.180 --> 00:05:04.250
We built the model and actually in this here we have the predictions of the test results and the confusion

72
00:05:04.250 --> 00:05:08.240
matrix that is actually a first way of evaluating the model.

73
00:05:08.240 --> 00:05:13.820
But as I said at the beginning of this tutorial this is a correct way of evaluating the model but not

74
00:05:13.820 --> 00:05:14.560
the best one.

75
00:05:14.660 --> 00:05:19.270
And in today's Statoil we are introducing a much better way to evaluate our model.

76
00:05:19.550 --> 00:05:26.180
And so let's put it right after the section as in a more advanced performance evaluation method.

77
00:05:26.180 --> 00:05:34.050
And so we're going to call this section applying K FULDE cross validation.

78
00:05:34.610 --> 00:05:40.550
All right so now the first thing that we have to do is to install the carrot package because this contains

79
00:05:40.610 --> 00:05:45.120
a very practical tool to create the tenfold of our training set.

80
00:05:45.170 --> 00:05:53.430
So let's start with this install that packages and in parenthesis and quotes Carrot's.

81
00:05:53.460 --> 00:05:54.030
All right.

82
00:05:54.090 --> 00:05:59.640
So mine is already installed we can check it out check the same on your list of packages.

83
00:05:59.640 --> 00:06:01.300
Here it is carit.

84
00:06:01.350 --> 00:06:04.300
So I will just put that in comment.

85
00:06:04.410 --> 00:06:11.880
But don't forget to install it and then let's not forget the library command to import automatically

86
00:06:11.880 --> 00:06:14.270
the carrot package.

87
00:06:14.370 --> 00:06:14.800
All right.

88
00:06:14.820 --> 00:06:18.180
And now let's start coding careful cross-validation.

89
00:06:18.180 --> 00:06:24.450
So first we are going to create the ten folds that will divide our training sets and do this it's very

90
00:06:24.450 --> 00:06:25.220
simple.

91
00:06:25.220 --> 00:06:31.220
We're going to use to create false function by the carrot package to create these ten folds very efficiently.

92
00:06:31.500 --> 00:06:32.220
So let's do it.

93
00:06:32.220 --> 00:06:33.800
We're going to call this fold.

94
00:06:33.950 --> 00:06:39.050
FOLDS Well actually be a list of 10 different test folds composing our training sets.

95
00:06:39.180 --> 00:06:43.170
So let's use this create capital F full function.

96
00:06:43.170 --> 00:06:44.040
Here it is.

97
00:06:44.260 --> 00:06:48.660
And inside the parenthesis we just need to specify the training set.

98
00:06:48.660 --> 00:06:50.720
So here I'm adding the training set.

99
00:06:51.000 --> 00:06:55.280
And then we take our dependent variable and call them by which we want to make this play.

100
00:06:55.290 --> 00:07:00.000
You know it's exactly like when we split the days between the training set and a test set we need to

101
00:07:00.000 --> 00:07:05.610
specify the dependent variable to make a split so that the training set in the test set are well distributed

102
00:07:05.700 --> 00:07:07.530
according to the dependent variable.

103
00:07:07.650 --> 00:07:12.960
Well here that's the same we're creating 10 folds of the trainset and we are specifying the dependent

104
00:07:12.960 --> 00:07:17.450
variable to make sure are well distributed according to the dependent variable.

105
00:07:17.670 --> 00:07:24.590
So that's why here we need to specify our Develin variable which is purchased all right.

106
00:07:24.610 --> 00:07:27.760
That's the first argument of the create force function.

107
00:07:27.760 --> 00:07:33.190
And of course as you might have guessed the second argument is the number of FULDE you want to divide

108
00:07:33.190 --> 00:07:38.720
your trainset into and really a good choice of the number of fours is 10.

109
00:07:38.740 --> 00:07:45.040
Because by creating 10 fold we will eventually get 10 accuracy's and 10 accuracy's is the relevant way

110
00:07:45.310 --> 00:07:49.500
to measure the accuracy through the mean of these 10 accuracies.

111
00:07:49.560 --> 00:07:50.720
So we'll take 10.

112
00:07:50.740 --> 00:07:53.030
And I recommend to do that in practice.

113
00:07:53.170 --> 00:07:57.520
So here we just add K equals 10.

114
00:07:57.520 --> 00:07:58.360
All right.

115
00:07:58.360 --> 00:08:03.850
Now we're going to implement careful cross-validation because what we just did here is just to create

116
00:08:03.850 --> 00:08:04.600
the fold.

117
00:08:04.690 --> 00:08:10.960
But now we need to implement the algorithm itself and to do this well there are several ways of doing

118
00:08:10.960 --> 00:08:11.240
it.

119
00:08:11.350 --> 00:08:18.370
But we're going to use a very practical function in our which is called Laplae function and that consists

120
00:08:18.700 --> 00:08:22.750
of applying a function to the different elements of a list.

121
00:08:22.750 --> 00:08:30.280
So this list is going to be our full list that contains the tentes folds and the function is the function

122
00:08:30.280 --> 00:08:34.870
that is going to compute the accuracy for each of these tentes falls.

123
00:08:34.870 --> 00:08:41.620
So let's start by creating a new are that we're going to call C-v and then let's use here this L apply

124
00:08:41.830 --> 00:08:42.930
function.

125
00:08:42.970 --> 00:08:43.270
All right.

126
00:08:43.300 --> 00:08:45.190
And you're going to understand what's going to happen.

127
00:08:45.190 --> 00:08:51.700
So in this Laplae function we need to put two arguments the first argument is the list of the elements

128
00:08:52.060 --> 00:08:55.900
to which we are going to apply the next function which is the next argument.

129
00:08:55.960 --> 00:08:59.440
And so as I just said this list is false.

130
00:08:59.440 --> 00:09:01.810
The list of our tent follows.

131
00:09:02.170 --> 00:09:05.250
And then the next argument is the function.

132
00:09:05.260 --> 00:09:09.860
So a function and R can be written this way function.

133
00:09:10.210 --> 00:09:17.490
Then in parenthesis we need to input the argument which will call X this is a local argument so far

134
00:09:17.800 --> 00:09:21.880
but X is actually going to be each one of the tentes fault.

135
00:09:21.880 --> 00:09:25.930
So X here and then a pair of brackets.

136
00:09:25.930 --> 00:09:26.700
Here we go.

137
00:09:26.860 --> 00:09:32.470
And inside these brackets we are going to implement this function that will compute the accuracy of

138
00:09:32.470 --> 00:09:35.000
the model on each of these tentes folds.

139
00:09:35.170 --> 00:09:39.330
So basically in this function we are going to implement careful cross-validation.

140
00:09:39.640 --> 00:09:42.740
So what do we need to implement careful cross-validation.

141
00:09:42.820 --> 00:09:49.060
Well first we need the training field the training field is the whole training set to which we withdraw

142
00:09:49.060 --> 00:09:49.980
the test fold.

143
00:09:50.200 --> 00:09:58.570
So basically training for here I'm creating a new local variable actually called that I'm calling training

144
00:09:58.570 --> 00:09:59.230
fault.

145
00:09:59.230 --> 00:10:02.450
And so as I just said this is the whole training set.

146
00:10:02.470 --> 00:10:03.270
Here we go.

147
00:10:03.520 --> 00:10:12.280
But to which we withdraw the test fold that is minus X because you know X is actually each element of

148
00:10:12.280 --> 00:10:13.690
this false list here.

149
00:10:13.690 --> 00:10:17.120
So by putting minus X here we are taking the whole training set.

150
00:10:17.230 --> 00:10:18.580
But without the test failed.

151
00:10:18.700 --> 00:10:20.670
And therefore that's actually the trunkful.

152
00:10:20.920 --> 00:10:24.940
And then come up to take all the columns All right.

153
00:10:25.010 --> 00:10:26.800
So we got our Tranfield.

154
00:10:26.840 --> 00:10:30.320
Now let's get our test fold or test fold.

155
00:10:30.380 --> 00:10:38.020
Try to guess what it's going to be test fold equals training set and inside the square brackets.

156
00:10:38.180 --> 00:10:39.690
Well what do we need to put here.

157
00:10:39.830 --> 00:10:46.340
Well that's actually X because you know X represents all the observations for each one of the tentes

158
00:10:46.340 --> 00:10:46.920
folds.

159
00:10:47.150 --> 00:10:49.830
So we got our test fold.

160
00:10:50.270 --> 00:10:51.960
And then what do we need to do now.

161
00:10:52.190 --> 00:11:00.050
Now what we need to do is train our colonel as we're all on the training fold and then we will test

162
00:11:00.050 --> 00:11:02.270
its performance on the test fold.

163
00:11:02.270 --> 00:11:04.170
So basically what do we need to do now.

164
00:11:04.310 --> 00:11:09.300
We need to add our model which is our kernel as V.M. classifier.

165
00:11:09.620 --> 00:11:16.490
So what we can do now is just take this code section here because that's where we build the model and

166
00:11:16.490 --> 00:11:20.070
we need to include this model in the function that's why we're taking it.

167
00:11:20.360 --> 00:11:25.240
So copy and let's add it here paste.

168
00:11:25.460 --> 00:11:32.390
And here we go we have our model but we are not training this kernel Colonel SVM classifier on the training

169
00:11:32.390 --> 00:11:40.310
set we were training on the training force because that's the principle of Caple cross-validation we

170
00:11:40.310 --> 00:11:41.860
are training our classifier.

171
00:11:41.860 --> 00:11:44.250
On each one of the ten training falls.

172
00:11:44.480 --> 00:11:51.920
So that's why here we're taking the train full and that we create here inside this function that we're

173
00:11:51.920 --> 00:11:55.340
making right now and then we keep the same arguments.

174
00:11:55.520 --> 00:11:57.590
All right then what do we need to do.

175
00:11:57.710 --> 00:12:03.140
Well that's exactly the same as what we're doing when we make a model that is predicting the test that

176
00:12:03.140 --> 00:12:03.710
results.

177
00:12:03.710 --> 00:12:10.400
That's the next step because that's from this test that results that we will then compute the confusion

178
00:12:10.460 --> 00:12:16.220
matrix and therefore the accuracy which is exactly what we need that is which is exactly what will be

179
00:12:16.220 --> 00:12:21.350
returned by the function we are making right now to implement careful cross-validation.

180
00:12:21.350 --> 00:12:28.980
So same let's copy this line to predict the test result and let's copy it here.

181
00:12:29.120 --> 00:12:31.110
And is that all of course.

182
00:12:31.120 --> 00:12:38.610
No because we are not testing or classify on the test set but we're testing it on the test fold.

183
00:12:38.690 --> 00:12:38.960
Right.

184
00:12:38.960 --> 00:12:44.080
Because you know we are training a model on the training field and testing its performance on the test

185
00:12:44.080 --> 00:12:44.610
foot.

186
00:12:44.840 --> 00:12:46.060
So now it's good.

187
00:12:46.340 --> 00:12:52.470
And now let's move on to the next step which is to compute the confusion matrix.

188
00:12:52.500 --> 00:13:00.470
So still let's take this line here and that's pasted below right here paste.

189
00:13:00.480 --> 00:13:06.710
And now of course we need to change test set and replace it by test fold.

190
00:13:06.740 --> 00:13:07.070
All right.

191
00:13:07.070 --> 00:13:13.350
And this will give us the confusion matrix of this classifier as being more all of this Colonel SVM

192
00:13:13.390 --> 00:13:14.310
classifier.

193
00:13:14.600 --> 00:13:19.780
And that is trained on the training field and tested on the test field.

194
00:13:20.000 --> 00:13:25.570
And therefore this line of code will give you the compression matrix for the observations of the test.

195
00:13:25.850 --> 00:13:26.540
All right.

196
00:13:26.660 --> 00:13:33.740
And now last step we need to compute the accuracy because we're doing all this to get the accuracy's

197
00:13:34.130 --> 00:13:36.180
for all the tentes falls here.

198
00:13:36.230 --> 00:13:42.840
So let's compute the accuracy the accuracy is we've calculated this accuracy many times.

199
00:13:42.990 --> 00:13:51.030
We take the number of correct predictions which is see n one come up one because this corresponds to

200
00:13:51.270 --> 00:13:59.640
the number of correct predictions of the first class plus cme to come to because this corresponds to

201
00:13:59.640 --> 00:14:02.610
the number of correct predictions of the second class.

202
00:14:02.730 --> 00:14:09.020
And since we have two classes this sum corresponds to the total number of correct predictions.

203
00:14:09.210 --> 00:14:18.030
And then we divide it by the total number of observations in the test and therefore that's the number

204
00:14:18.030 --> 00:14:20.950
of correct predictions which is the sum here.

205
00:14:22.380 --> 00:14:29.430
Too which we also need to add the number of incorrect predictions and therefore no we can copy this

206
00:14:30.000 --> 00:14:36.660
and take the first number of incorrect predictions that corresponds to the first class and the second

207
00:14:36.660 --> 00:14:40.190
number of incorrect actions that corresponds to the second class.

208
00:14:40.210 --> 00:14:46.320
And so here we are actually taking all the elements of this confusion matrix that is the number of correct

209
00:14:46.360 --> 00:14:49.110
actions plus the number of incorrect predictions.

210
00:14:49.440 --> 00:14:54.870
And so now with this line of code we get the accuracy for one fold.

211
00:14:54.930 --> 00:15:01.440
But since we're using this supply function this will do all this compute the accuracy for each of the

212
00:15:01.440 --> 00:15:06.690
10 test falls and therefore we will get 10 accuracies and we will compute it mean which will give us

213
00:15:07.000 --> 00:15:13.410
a much more relevant accuracy than just a single one we obtained earlier with our previous method of

214
00:15:13.470 --> 00:15:15.690
evaluating the model performance.

215
00:15:15.690 --> 00:15:22.850
All right so now we have everything but we just need to specify that we want to have this accuracy returned

216
00:15:23.040 --> 00:15:28.380
because this is a function so we need to specify what we want this function to return and to do this

217
00:15:28.380 --> 00:15:33.180
we just add return parenthesis and accuracy.

218
00:15:33.180 --> 00:15:34.930
And now everything is ready.

219
00:15:34.980 --> 00:15:38.160
Careful transformation is well implemented.

220
00:15:38.480 --> 00:15:44.250
All right so now we are ready to get the 10 accuracy's that will result from this 10 fold cross-validation

221
00:15:44.250 --> 00:15:45.180
technique.

222
00:15:45.210 --> 00:15:52.210
So we're going to select everything from here up to the top because we haven't imported the data set

223
00:15:52.290 --> 00:15:52.850
yet.

224
00:15:53.130 --> 00:15:57.360
So let's Presque American troops enter to execute the whole thing.

225
00:15:57.360 --> 00:15:58.100
Here we go.

226
00:15:58.200 --> 00:16:01.720
Everything was correctly executed in less than one second.

227
00:16:01.770 --> 00:16:02.840
So that's perfect.

228
00:16:03.000 --> 00:16:05.200
Let's have a look at the results.

229
00:16:05.220 --> 00:16:07.860
So first let's put that down.

230
00:16:07.860 --> 00:16:08.820
All right.

231
00:16:08.820 --> 00:16:10.260
So here we get all the results.

232
00:16:10.260 --> 00:16:12.330
First the data set was well imported.

233
00:16:12.400 --> 00:16:19.160
We split it into the training set and the test set at this section here and then we built our classifier

234
00:16:19.170 --> 00:16:21.460
which is our kernel as being classifier.

235
00:16:21.570 --> 00:16:30.080
And of course we get our CV list that we built through careful cross-validation that is this Aviles

236
00:16:30.150 --> 00:16:35.190
which is the list of the 10 accuracies that result from Caple transformation.

237
00:16:35.410 --> 00:16:36.750
And so let's check it out.

238
00:16:36.750 --> 00:16:39.310
Let's have a look at what these 10 accuracies are.

239
00:16:39.540 --> 00:16:42.210
So we're going to look at it from the console.

240
00:16:42.320 --> 00:16:45.120
So I'm pressing Siri here and pressing Enter.

241
00:16:45.510 --> 00:16:46.940
And here we go.

242
00:16:46.940 --> 00:16:48.450
That's the results.

243
00:16:48.450 --> 00:16:50.010
That's the 10 accuracy's.

244
00:16:50.250 --> 00:16:58.740
So full one we get a 93 percent accuracy that's very good full to 87 percent for 3 100 percent and no

245
00:16:58.770 --> 00:17:02.450
incorrect prediction for 86 percent full 5.

246
00:17:02.460 --> 00:17:12.150
96 percent 90 percent on 4:6 90 percent 7 93 percent and 4 8 9 percent 4 9 and eventually 83 percent

247
00:17:12.300 --> 00:17:13.300
on full 10.

248
00:17:13.470 --> 00:17:19.470
So that clearly illustrates what I told you about this Varians problem that can occur when we rerun

249
00:17:19.470 --> 00:17:25.500
the model several times because indeed we get different accuracies and sometimes a large difference

250
00:17:25.560 --> 00:17:28.650
in accuracy from one field to another.

251
00:17:28.650 --> 00:17:35.100
So from here to here that's fine but here for example from 4 2 2 4 3 we get a 13 percent difference

252
00:17:35.400 --> 00:17:36.660
of accuracy.

253
00:17:36.840 --> 00:17:43.350
So that's why it's not that relevant to compute the accuracy on one single split and it's much more

254
00:17:43.350 --> 00:17:47.650
relevant to compute the accuracy than 10 splits because then we can take the mean.

255
00:17:47.760 --> 00:17:50.030
And that's exactly what we're going to do right now.

256
00:17:50.030 --> 00:17:54.330
We're going to compute the mean after 10 accuracies that we obtain here.

257
00:17:54.330 --> 00:17:58.600
So to get this I mean it's actually very simple.

258
00:17:58.680 --> 00:18:01.980
We're just going to use the mean function.

259
00:18:02.160 --> 00:18:09.090
So parenthesis here and inside this when we of course input CV because CV is a list of our ten accuracies

260
00:18:09.240 --> 00:18:10.500
that we obtain here.

261
00:18:10.500 --> 00:18:16.410
However just to make sure we get the values of the accuracies of each of the ten fold we need to specify

262
00:18:16.410 --> 00:18:24.150
here as that numeric and in parenthesis we include TV to make sure we take the mean of these values

263
00:18:24.360 --> 00:18:32.220
that are the accuracies and let's put this average of the accuracies into one variable that will appear

264
00:18:32.280 --> 00:18:33.610
in the values here.

265
00:18:33.690 --> 00:18:41.190
And let's go these variables simply accuracy because the mean of these accuracies is just the ultimate

266
00:18:41.310 --> 00:18:42.730
relevant accuracy.

267
00:18:42.840 --> 00:18:48.240
So accuracy was mean of the accuracies in the civil list.

268
00:18:48.240 --> 00:18:56.970
All right so let's compute it and we'll get Let's see an accuracy of 91 percent and that's the relevant

269
00:18:57.030 --> 00:18:58.030
accuracy.

270
00:18:58.030 --> 00:18:59.150
We're looking for.

271
00:18:59.520 --> 00:19:08.110
So overall we can say with more credibility that our model our kernel as the classifier is pretty performance.

272
00:19:08.160 --> 00:19:09.160
So that's pretty good.

273
00:19:09.240 --> 00:19:14.700
And now congratulations you have a much more advanced way of evaluating your model performance and your

274
00:19:14.700 --> 00:19:20.010
designs science targets what you'll see in the next Statoil we'll see a very powerful technique that

275
00:19:20.010 --> 00:19:24.910
will help us choose the optimal hyper parameters of any machine learning model we built.

276
00:19:25.140 --> 00:19:27.640
So I look forward to doing that in the next Statoil.

277
00:19:27.660 --> 00:19:29.430
And until then enjoy learning.
