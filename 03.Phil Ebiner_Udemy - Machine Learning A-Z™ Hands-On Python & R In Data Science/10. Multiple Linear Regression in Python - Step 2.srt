1
00:00:00,700 --> 00:00:01,140
All right.

2
00:00:01,350 --> 00:00:02,590
So perfect.

3
00:00:02,650 --> 00:00:06,900
Now that everything is essentially said let us tackle this data repressing faith.

4
00:00:06,930 --> 00:00:09,020
So we're going to do this very efficiently.

5
00:00:09,030 --> 00:00:15,360
I'm going to go to my data depressing template and I'm going to copy paste each of these code cells.

6
00:00:15,360 --> 00:00:18,600
You know the first ones so I'm creating a new code cell here.

7
00:00:18,600 --> 00:00:21,620
Pasting them here that's for empowering the libraries.

8
00:00:21,690 --> 00:00:28,920
Then we're gonna take care of the second step of pressing which is empowering the data set creating

9
00:00:29,100 --> 00:00:31,580
therefore a new code cell here.

10
00:00:31,590 --> 00:00:33,440
And let us first take care of this.

11
00:00:33,440 --> 00:00:35,730
You know the last one the easy one.

12
00:00:35,730 --> 00:00:43,530
Splitting the data set into the training set and the test set and pasting that in a new code cell right

13
00:00:43,530 --> 00:00:43,980
here.

14
00:00:43,980 --> 00:00:44,640
All right.

15
00:00:44,640 --> 00:00:45,480
Perfect.

16
00:00:45,490 --> 00:00:51,060
And now before we encode a categorical data let's just make sure to replace what's necessary here in

17
00:00:51,060 --> 00:00:52,350
this template.

18
00:00:52,410 --> 00:00:55,020
And then once again that's the beauty of the template.

19
00:00:55,050 --> 00:01:00,420
We only need to replace one little thing which is of course the name of the data set here.

20
00:01:00,420 --> 00:01:00,750
Right.

21
00:01:00,750 --> 00:01:03,330
And the name is of course 50 on the score.

22
00:01:03,330 --> 00:01:05,030
Capital S startups.

23
00:01:05,080 --> 00:01:06,080
That's yes.

24
00:01:06,180 --> 00:01:06,600
There we go.

25
00:01:06,600 --> 00:01:07,790
Let's do this.

26
00:01:08,040 --> 00:01:11,790
50 on the score start ups.

27
00:01:11,790 --> 00:01:12,270
Great.

28
00:01:12,270 --> 00:01:18,270
And as a reminder we don't have to change anything here because this automatically selects all the columns

29
00:01:18,510 --> 00:01:22,590
except the last one and therefore all the four features here.

30
00:01:22,590 --> 00:01:23,790
So that's perfect.

31
00:01:23,850 --> 00:01:32,010
And this line of code automatically selects the last column which means the dependent variable profit.

32
00:01:32,040 --> 00:01:32,860
Okay.

33
00:01:32,880 --> 00:01:38,760
So once again we've tackled data pricing and a flashlight and now we just have this one less tool to

34
00:01:38,760 --> 00:01:44,610
add in our data repricing phase which is to encode that state variable here.

35
00:01:44,670 --> 00:01:49,800
So to do this we're going to get our data repricing tools which you have in your part one data progressing

36
00:01:49,870 --> 00:01:50,830
further.

37
00:01:51,000 --> 00:01:57,720
And now we're going to scroll down to find that tool that you know encodes the Caracol data.

38
00:01:57,720 --> 00:02:00,320
So remember we actually have two such tools here.

39
00:02:00,330 --> 00:02:05,250
If I may say that first tool that applies one hot encoding which is exactly what we want.

40
00:02:05,400 --> 00:02:09,550
And that tool that just encodes a binary variable into 0 and 1.

41
00:02:09,750 --> 00:02:16,290
And of course what we need is this one so I'm just gonna copy paste that piece of code and then I'm

42
00:02:16,290 --> 00:02:21,930
going to face that right here in a new code cell to encode categorical data.

43
00:02:21,930 --> 00:02:27,750
And now your turn your turn to think and figure out what we need to do next please press pause on this

44
00:02:27,750 --> 00:02:35,440
video and figure out what you have to change here in order to indeed apply one hut encoding on our dataset.

45
00:02:35,490 --> 00:02:36,320
I'll give you a hint.

46
00:02:36,330 --> 00:02:39,810
You only have one little thing to change and then you'll be good to go.

47
00:02:39,960 --> 00:02:41,570
So please press pause.

48
00:02:41,580 --> 00:02:42,130
Okay.

49
00:02:42,180 --> 00:02:44,300
And now I'm gonna give you the solution.

50
00:02:44,430 --> 00:02:48,530
So the only thing that you had to change here is that index here.

51
00:02:48,570 --> 00:02:54,700
Remember this corresponds to the index of the column you want to apply one hot encoding.

52
00:02:54,910 --> 00:03:00,690
And in our previous dataset you know data that says we well remember the categorical variable was the

53
00:03:00,690 --> 00:03:01,290
first column.

54
00:03:01,290 --> 00:03:03,390
That's why we put index 0 here.

55
00:03:03,450 --> 00:03:08,960
But for new data set the categorical variable is actually the fourth column.

56
00:03:09,030 --> 00:03:10,230
But be careful.

57
00:03:10,230 --> 00:03:12,840
Remember that indexes in Python start from zero.

58
00:03:12,840 --> 00:03:14,490
Therefore this gone hasn't it zero.

59
00:03:14,490 --> 00:03:18,340
This one is the next one this one as is x2 and this one has indexed three.

60
00:03:18,360 --> 00:03:23,650
And therefore the index you need to change here is of course three.

61
00:03:23,760 --> 00:03:24,420
Right.

62
00:03:24,420 --> 00:03:29,700
So this will apply one hut including to the column of index three in your data set.

63
00:03:29,760 --> 00:03:32,520
Therefore exactly this date column.

64
00:03:32,520 --> 00:03:33,230
Perfect.

65
00:03:33,240 --> 00:03:36,190
So we're done with the data repricing phase.

66
00:03:36,190 --> 00:03:39,960
So now we are going to observe the results of what we just built.

67
00:03:40,000 --> 00:03:44,190
You know just in terms of data pricing and therefore we're going to do several things here.

68
00:03:44,190 --> 00:03:50,640
First we're going to upload the data set into our notebook right and to do this we click this little

69
00:03:50,640 --> 00:03:53,410
folder here and then upload.

70
00:03:53,670 --> 00:03:54,140
All right.

71
00:03:54,150 --> 00:03:57,800
So as usual my machinery is that folder is on my desktop.

72
00:03:57,840 --> 00:04:00,600
So we're gonna go inside make sure to find it on your machine.

73
00:04:00,600 --> 00:04:06,110
Then we're going to go to part of regression then Section 5 multiple in our regression in Python.

74
00:04:06,120 --> 00:04:06,960
And there we go.

75
00:04:06,960 --> 00:04:11,820
That's the data set which we need to open and upload into our notebook.

76
00:04:11,820 --> 00:04:12,270
All right.

77
00:04:12,270 --> 00:04:13,320
It is uploaded.

78
00:04:13,320 --> 00:04:17,420
And now what we're gonna do is we're gonna run each of these cells that we just made.

79
00:04:17,700 --> 00:04:21,890
But I'm gonna add a few prints you know so that you can really see what we did.

80
00:04:21,900 --> 00:04:26,760
You know how the different metrics of features and have been in viral vector are created and modified

81
00:04:26,850 --> 00:04:28,290
along the data repricing phase.

82
00:04:28,860 --> 00:04:29,070
All right.

83
00:04:29,070 --> 00:04:31,370
So first let's start by imploring the libraries.

84
00:04:31,440 --> 00:04:33,360
That's easy done.

85
00:04:33,360 --> 00:04:39,270
Next step we import the data set and we can now because we have the dataset uploaded in our notebook.

86
00:04:39,480 --> 00:04:40,750
So make sure to have it as well.

87
00:04:40,950 --> 00:04:41,300
Okay.

88
00:04:41,310 --> 00:04:42,720
Now data set is imported.

89
00:04:42,750 --> 00:04:45,830
We have a matrix of features and the dependent variable vector Y.

90
00:04:45,870 --> 00:04:46,530
Good.

91
00:04:46,530 --> 00:04:51,470
And now I'm gonna do a print to show you the state of X you know what is x exactly.

92
00:04:51,510 --> 00:04:57,350
At this stage so I'm going to print x and I'm going to run the cell.

93
00:04:57,360 --> 00:04:59,390
All right and let's see what we get.

94
00:04:59,400 --> 00:04:59,660
All right.

95
00:04:59,660 --> 00:05:07,630
So indeed we get exactly the same columns as in this dataset with first aren't you spend then administration

96
00:05:07,630 --> 00:05:13,090
spend then marketing spend and state right we can clearly see that we get the same columns here in the

97
00:05:13,090 --> 00:05:13,800
same order.

98
00:05:13,850 --> 00:05:14,200
All right.

99
00:05:14,230 --> 00:05:16,370
That's the matrix of features all good.

100
00:05:16,840 --> 00:05:21,130
Now I'm not going to show you the dependent variable vector because that's abuse we're going to get

101
00:05:21,130 --> 00:05:22,520
the same profits.

102
00:05:22,750 --> 00:05:30,490
But what I want to show you is what becomes X after we encode the categorical data you know and you

103
00:05:30,490 --> 00:05:35,410
can actually guess what it will become but you will see that the three comes resulting here from one

104
00:05:35,410 --> 00:05:38,470
how the encoding will actually be placed at the beginning.

105
00:05:38,470 --> 00:05:39,900
All right so let's check it out.

106
00:05:39,940 --> 00:05:44,200
Let's run the cell to indeed apply encoding categorical data.

107
00:05:44,200 --> 00:05:52,870
And now let's create a new code cell in which we're going to print x again and let's run this cell to

108
00:05:52,870 --> 00:05:54,570
see what X becomes.

109
00:05:55,090 --> 00:05:55,840
And there you go.

110
00:05:55,840 --> 00:05:57,230
Exactly as I told you.

111
00:05:57,430 --> 00:06:00,310
We have the same three first columns here.

112
00:06:00,310 --> 00:06:04,080
So that corresponds to Orange spend that corresponds to the administration spend.

113
00:06:04,210 --> 00:06:06,400
And that corresponds to marketing spend.

114
00:06:06,400 --> 00:06:12,790
But now instead of having this state column here we indeed have these three new columns at the beginning

115
00:06:13,090 --> 00:06:18,160
encoding that state variable and we can actually see what corresponds to what you know if we have a

116
00:06:18,160 --> 00:06:19,440
look at our dataset.

117
00:06:19,450 --> 00:06:27,850
Well the first row has new york as a state and therefore New York was encoded as 0 0 and 1.

118
00:06:27,910 --> 00:06:32,130
Then let's see as a second State of the second row you know corresponding to the second start.

119
00:06:32,140 --> 00:06:37,570
We have California and therefore California was encoded as 1 0 and 0.

120
00:06:37,570 --> 00:06:38,620
And finally.

121
00:06:38,620 --> 00:06:43,450
Well Florida was encoded as 0 1 and 0.

122
00:06:43,450 --> 00:06:43,830
All right.

123
00:06:43,840 --> 00:06:47,130
So that's the one how encoding that happens and now all good.

124
00:06:47,170 --> 00:06:50,380
We have a fully pre processed dataset.

125
00:06:50,560 --> 00:06:51,850
And as I told you in part 1.

126
00:06:51,850 --> 00:06:54,330
But I'm gonna say it again here because this is important.

127
00:06:54,430 --> 00:06:57,370
We don't have to apply feature scaling.

128
00:06:57,370 --> 00:06:57,700
Why.

129
00:06:57,700 --> 00:07:02,560
Because you know in the equation of the multiple in our regression you know you have this coefficient

130
00:07:02,680 --> 00:07:08,350
that is multiplied to each independent viable of each feature and therefore it doesn't matter that some

131
00:07:08,350 --> 00:07:13,660
features have higher values than others because the coefficients will compensate to put everything on

132
00:07:13,660 --> 00:07:19,390
the same scale and therefore remember this in multiple linear regression there is absolutely no need

133
00:07:19,660 --> 00:07:21,380
to apply feature scaling.

134
00:07:21,580 --> 00:07:26,680
And one last thing I would like to add as well because I know a lot of you asked this question Do we

135
00:07:26,680 --> 00:07:31,570
need to check the assumptions of linear regression.

136
00:07:31,570 --> 00:07:33,790
The answer is absolutely not.

137
00:07:33,850 --> 00:07:39,340
Because I will explain at the end of this part you know part two regression that whenever you have a

138
00:07:39,340 --> 00:07:45,940
new dataset and you want to experiment with some machinery models to figure out which one leads to the

139
00:07:45,940 --> 00:07:47,410
highest accuracy.

140
00:07:47,410 --> 00:07:54,460
Well even if your dataset doesn't have linear relationships you can still try a multiple in our regression

141
00:07:54,460 --> 00:07:55,010
on it.

142
00:07:55,090 --> 00:07:59,530
And if you know your dataset doesn't have linear relationships well you're multiple in our regression

143
00:07:59,530 --> 00:08:06,250
model we'll just perform poorly and therefore it will get an accuracy lower than the accuracy of your

144
00:08:06,340 --> 00:08:10,080
other models so you will just not select the multiple in our regression model.

145
00:08:10,090 --> 00:08:15,880
But you don't have to check the multiple in our regression assumptions it will just be a waste of time

146
00:08:16,210 --> 00:08:21,460
really I will show you at the end how you can so fast and so efficiently try each of the models on your

147
00:08:21,570 --> 00:08:25,990
dataset and select very quickly the one that has the highest accuracy.

148
00:08:25,990 --> 00:08:26,280
All right.

149
00:08:26,590 --> 00:08:31,640
So I just wanted to be clear on that point don't worry about the multiple in our regression assumptions.

150
00:08:31,750 --> 00:08:36,760
If your dataset has linear relationships then good you're multiple in our regression will check the

151
00:08:36,760 --> 00:08:42,640
assumptions indeed and we'll bring to you a high accuracy and if your dataset doesn't have linear relationships

152
00:08:42,910 --> 00:08:48,070
well fine your multiple in our regression just will perform poorly and you will just take another model

153
00:08:48,220 --> 00:08:48,990
and that's it.

154
00:08:49,000 --> 00:08:50,080
That's as simple as that.

155
00:08:50,230 --> 00:08:50,940
All right.

156
00:08:50,980 --> 00:08:54,610
So now good we're done with data processing.

157
00:08:54,670 --> 00:09:00,220
We can therefore move on to the next step which is to train the multiple in our regression model on

158
00:09:00,220 --> 00:09:01,320
the training set.

159
00:09:01,390 --> 00:09:02,700
So take a little break here.

160
00:09:02,740 --> 00:09:08,350
And as soon as you're ready to build your next machinery model well join me in the next material to

161
00:09:08,350 --> 00:09:09,400
tackle this.

162
00:09:09,430 --> 00:09:11,260
And until then enjoy machine learning.
