WEBVTT
1

00:00:00.420  -->  00:00:03.930
Hello and welcome to this Arta Tauriel and Embree use the toilets.

2

00:00:03.930  -->  00:00:09.470
We already implemented a multiple regression model that we fitted to the trainset.

3

00:00:09.480  -->  00:00:14.340
But when we take a step back do you think it's actually the optimal model that we can make with the

4

00:00:14.340  -->  00:00:15.780
data set that we have here.

5

00:00:15.930  -->  00:00:21.290
You know because when we build this model we actually used all the independent variables.

6

00:00:21.450  -->  00:00:26.640
But what if among these independent variables there are some that are highly statistically significant

7

00:00:26.820  -->  00:00:34.290
that is have great impact or great effect on the dependent variable profit and some that are not statistically

8

00:00:34.290  -->  00:00:35.510
significant at all.

9

00:00:35.520  -->  00:00:41.700
That means that if we removed these nonstick distinctly significant variables from the moral world we

10

00:00:41.700  -->  00:00:44.670
would still get some amazing predictions.

11

00:00:44.670  -->  00:00:51.210
So the goal in this tutorial is to actually find a team an optimal team of independent variables so

12

00:00:51.210  -->  00:00:57.570
that each independent variable of the team has great impact on the dependent variable profits that is

13

00:00:57.720  -->  00:01:03.060
each independent variable of the team is a powerful predictor that is highly statistically significant

14

00:01:03.270  -->  00:01:08.630
and definitely has an effect on the dependent variable profit and this effect can be positive.

15

00:01:08.700  -->  00:01:12.010
That is for an increase of 1 unit of the independent variable.

16

00:01:12.030  -->  00:01:14.710
The profit will increase or it can be negative.

17

00:01:14.760  -->  00:01:17.800
That is for an increase of 1 unit of the independent variable.

18

00:01:17.820  -->  00:01:24.060
The profit will decrease and so we're going to divide this final step of building this optimal model

19

00:01:24.060  -->  00:01:29.890
using backward elimination into two tutorials in this first tutorial that we are having right now.

20

00:01:29.910  -->  00:01:35.460
I'm going to walk you through the backdoor elimination algorithm without completing it up to the end

21

00:01:35.460  -->  00:01:35.960
.

22

00:01:36.030  -->  00:01:42.540
That means that at the end of this Tauriel you'll get a homework which will consist of completing what

23

00:01:42.540  -->  00:01:44.370
we started with backward elimination.

24

00:01:44.400  -->  00:01:49.260
So I'm sure we will have no problem because I'm going to walk you through the introduction of backward

25

00:01:49.290  -->  00:01:55.290
elimination so that you can understand everything and have all the tools to complete the homework.

26

00:01:55.500  -->  00:02:00.240
And then in the next tutorial I'll give you the solution of this homework and we will complete together

27

00:02:00.240  -->  00:02:01.960
the backward elimination.

28

00:02:02.190  -->  00:02:03.730
So I hope you're excited.

29

00:02:03.960  -->  00:02:04.980
Let's start right now.

30

00:02:04.980  -->  00:02:07.320
The backward elimination.

31

00:02:07.440  -->  00:02:12.690
So for those of you who follow the Python tutorial you will notice that it's actually a little more

32

00:02:12.690  -->  00:02:19.020
simple here because in the PIF anti-Tory we had to use another library and another the regression model

33

00:02:19.170  -->  00:02:21.830
to implement backward elimination.

34

00:02:22.020  -->  00:02:27.870
And this time we will simply take the model that we created here and we will use this amazing function

35

00:02:27.870  -->  00:02:35.400
summary of our that returns a great deal of statistical information that can help make our model more

36

00:02:35.400  -->  00:02:36.570
robust.

37

00:02:36.570  -->  00:02:42.720
And then same as in Python We are going to do some copy paste very simply until we get to the final

38

00:02:42.720  -->  00:02:45.260
team of our independent variables.

39

00:02:45.330  -->  00:02:46.500
So let's do this.

40

00:02:46.620  -->  00:02:48.470
You're going to see it's really quick and easy.

41

00:02:48.480  -->  00:02:50.230
We're going to do that very efficiently.

42

00:02:50.340  -->  00:02:56.160
And the first step of doing that is to actually take our model because as I just mentioned we're going

43

00:02:56.160  -->  00:03:00.110
to use the same model to implement backward elimination.

44

00:03:00.180  -->  00:03:06.660
So here I just copied the model and I'm going to paste it here and now we're just going to change two

45

00:03:06.660  -->  00:03:07.590
things.

46

00:03:07.620  -->  00:03:13.470
The first thing is instead of having this dot here you notice that that represents all the independent

47

00:03:13.470  -->  00:03:20.130
variables we are going to write all the independent variables separated by a plus because you know the

48

00:03:20.130  -->  00:03:26.550
principle of backward elimination is that we will remove each independent variable that is not statistically

49

00:03:26.550  -->  00:03:28.600
significant one by one.

50

00:03:28.650  -->  00:03:34.950
So we need here to write each of the independent variables so that when we copy paste this model here

51

00:03:35.220  -->  00:03:40.990
we will just need to remove the non statistically significant variable from this equation here.

52

00:03:41.280  -->  00:03:41.490
OK.

53

00:03:41.490  -->  00:03:42.660
So let's first do this.

54

00:03:42.660  -->  00:03:47.340
I'm going to take our dataset here to look at the independent variables.

55

00:03:47.340  -->  00:03:49.690
So the first independent variable is Arty's Ben.

56

00:03:49.710  -->  00:03:51.450
So let's add it here.

57

00:03:51.720  -->  00:03:58.650
So our dot D so you know as a reminder there is a dot here because the original name for this independent

58

00:03:58.650  -->  00:04:04.510
variable is our space D and are just replaced the space by a dot here.

59

00:04:04.800  -->  00:04:09.660
So it's good to know that if you're working with are and if you have some data sets with spaces in your

60

00:04:09.660  -->  00:04:11.780
column names and then OK.

61

00:04:11.790  -->  00:04:14.670
So what was the name dot.

62

00:04:14.700  -->  00:04:18.070
Another daughter that means all the space dot and spend.

63

00:04:18.210  -->  00:04:20.460
All right so that's the first independent viable.

64

00:04:20.460  -->  00:04:22.170
Now let's add the second one.

65

00:04:22.170  -->  00:04:24.770
So we need to separate them by a plus.

66

00:04:24.870  -->  00:04:25.590
OK.

67

00:04:25.770  -->  00:04:27.360
And what is the second one.

68

00:04:27.450  -->  00:04:29.440
The second one is administration.

69

00:04:29.520  -->  00:04:30.420
OK.

70

00:04:30.810  -->  00:04:35.670
So here there is no doubt everything is fine just as it's spelt right.

71

00:04:35.670  -->  00:04:37.860
Administration plus

72

00:04:40.900  -->  00:04:41.860
marketing spend

73

00:04:44.830  -->  00:04:52.360
plus and we have one one last independent very well which is the states so we don't need to create a

74

00:04:52.460  -->  00:05:00.220
dummy variables as we did in Python because remember we use here this amazing factor function that encoded

75

00:05:00.370  -->  00:05:07.570
this state categorical variable into factors that are one to three and there is no relational order

76

00:05:07.600  -->  00:05:09.630
between those categories.

77

00:05:09.670  -->  00:05:11.000
So everything is fine.

78

00:05:11.050  -->  00:05:13.540
We don't need to create any dummy variables.

79

00:05:13.610  -->  00:05:15.120
So that's the beauty of our.

80

00:05:15.340  -->  00:05:21.370
And so here is saying we don't need to sum to separate dummy variables we can take the original independent

81

00:05:21.370  -->  00:05:22.560
variable state.

82

00:05:22.870  -->  00:05:25.930
OK so as I mentioned there are two things that we would like to change here.

83

00:05:25.930  -->  00:05:31.750
The first thing was to replace the dot by all these independent variables separated by a plus.

84

00:05:31.930  -->  00:05:36.400
And now the second thing that we would like to do but it's not compulsory is just because I would like

85

00:05:36.400  -->  00:05:44.420
to use all the data set to see the correlations is to replace your training set by simply our data set

86

00:05:44.430  -->  00:05:45.150
.

87

00:05:45.190  -->  00:05:46.750
So that's not compulsory.

88

00:05:46.750  -->  00:05:52.620
We can actually do backward elimination using the training set but we're just taking the whole data

89

00:05:52.620  -->  00:05:58.660
set in order to have complete informations about which independent variables are statistically significant

90

00:05:58.900  -->  00:06:02.060
and which independent variables are not OK.

91

00:06:02.080  -->  00:06:04.390
And now actually we're almost ready.

92

00:06:04.450  -->  00:06:09.670
We just need to use the summary function which we actually already used before.

93

00:06:09.850  -->  00:06:14.830
And there is nothing more simple than using the summary function we just need to take the summary function

94

00:06:14.830  -->  00:06:19.520
here and then in parenthesis we input are regressors.

95

00:06:19.600  -->  00:06:20.470
Here it is.

96

00:06:20.500  -->  00:06:26.050
And now that's actually ready we're actually ready to start the first steps of our backward elimination

97

00:06:26.050  -->  00:06:26.080
.

98

00:06:26.080  -->  00:06:31.930
Well speaking of backward elimination Let's have a look at the slide you saw with Kirill in the intuition

99

00:06:31.930  -->  00:06:34.040
tutorial and here's the slide.

100

00:06:34.150  -->  00:06:37.680
So let's have a quick reminder about the five steps here.

101

00:06:37.690  -->  00:06:43.600
So the first step is to select the significance level that is a threshold for our P-value such that

102

00:06:43.750  -->  00:06:49.420
if the p value of an independent variable is below the significance level then this independent variable

103

00:06:49.430  -->  00:06:55.210
stays in the model and if the p value of the independent variable is higher than the significance level

104

00:06:55.510  -->  00:06:57.120
then it will not stay in the model.

105

00:06:57.130  -->  00:06:58.650
We will remove it.

106

00:06:59.000  -->  00:07:04.480
So the first step is just to select a significance that we don't have to do anything here with the independent

107

00:07:04.480  -->  00:07:04.900
variables.

108

00:07:04.900  -->  00:07:09.230
We just need to choose one and we're going to choose 5 percent 0.05.

109

00:07:09.480  -->  00:07:09.940
Okay.

110

00:07:09.960  -->  00:07:15.040
And now step two step two is to fit the full model with all possible predictors.

111

00:07:15.040  -->  00:07:20.500
So that's actually what we've just done you know by taking all our independent variables in our regressors

112

00:07:20.500  -->  00:07:26.390
using the LN function that actually fits the full model with all the possible predictors that is with

113

00:07:26.390  -->  00:07:28.130
all the independent variables.

114

00:07:28.420  -->  00:07:30.310
Okay so done.

115

00:07:30.370  -->  00:07:35.780
And now what is Step Three Step three is to look at the predictor that has the highest P value.

116

00:07:36.100  -->  00:07:39.940
So we will find it thanks to our summary function.

117

00:07:40.240  -->  00:07:45.360
And if the p value is higher than the significance level that is if it's higher than 5 percent then

118

00:07:45.360  -->  00:07:46.520
we'll go to Step 4.

119

00:07:46.720  -->  00:07:52.950
And if that's not the case our model is actually ready but don't worry it will not be that quick.

120

00:07:53.080  -->  00:07:59.170
So actually let's suppose we found the highest value higher than the significance level of 5 percent

121

00:07:59.590  -->  00:08:05.110
then we need to move on to Step 4 and the Step 4 is actually to remove this independent viable that

122

00:08:05.110  -->  00:08:07.000
has the highest value.

123

00:08:07.420  -->  00:08:13.270
And once we remove the predictor we're ready to move onto Step Five which is to fit the model without

124

00:08:13.270  -->  00:08:14.340
this viable.

125

00:08:14.410  -->  00:08:20.440
So that's why you know we wrote all the independent variables one by one separated by a plus because

126

00:08:20.740  -->  00:08:26.950
you know once we've reached step five here we will just copy paste the regress or and the summary function

127

00:08:27.160  -->  00:08:33.960
and remove this in the Bible that had the highest value from the regress or to build a new regress or

128

00:08:33.970  -->  00:08:35.310
without this viable.

129

00:08:35.350  -->  00:08:43.360
And that will fit this model without the voidable and once it's done we go back to Step 3 here to repeat

130

00:08:43.480  -->  00:08:49.480
the same pathway there is once again we're going to look for the independent variables among the new

131

00:08:49.480  -->  00:08:54.130
team of independent variables without the independent variable that we just removed.

132

00:08:54.130  -->  00:08:58.990
So we're going to look for the independent variable that has the highest value and say if the p value

133

00:08:58.990  -->  00:09:04.070
is higher than the significance level we'll get to Step 4 and otherwise our model is ready.

134

00:09:04.480  -->  00:09:11.920
So let's do this we already completed step 1 by choosing a significant level of 5 percent and same for

135

00:09:11.920  -->  00:09:14.940
step 2 we actually fitted the model with all possible predictors.

136

00:09:14.950  -->  00:09:17.920
Well we need of course to execute the code.

137

00:09:18.100  -->  00:09:23.800
And now we will move onto step three which will consist of looking for the independent variable that

138

00:09:23.800  -->  00:09:25.100
has the highest P value.

139

00:09:25.300  -->  00:09:26.490
So let's do this right now.

140

00:09:27.290  -->  00:09:27.880
OK.

141

00:09:28.010  -->  00:09:35.550
So as I just mentioned we need to execute this to build our regressors with all the independent variables

142

00:09:35.550  -->  00:09:35.580
.

143

00:09:35.580  -->  00:09:40.940
Well actually we don't really need to execute this because we actually executed this code section here

144

00:09:40.950  -->  00:09:43.370
that builds exactly the same regress or.

145

00:09:43.400  -->  00:09:49.220
But just to complete all the steps in this tutorial let's execute that again that will not cause any

146

00:09:49.230  -->  00:09:49.870
issue.

147

00:09:49.980  -->  00:09:53.950
So I'm going to press command control press enter to execute.

148

00:09:54.090  -->  00:09:54.960
And here we go.

149

00:09:55.080  -->  00:10:01.890
Same regrets are created again with a different syntax and that's because we want to remove the non-significant

150

00:10:01.880  -->  00:10:04.090
and the bell invariable one by one.

151

00:10:04.380  -->  00:10:05.020
Great.

152

00:10:05.100  -->  00:10:07.830
So that actually completes step two.

153

00:10:08.120  -->  00:10:13.170
And now let's move on to step three which was to look for the independent variable that has the highest

154

00:10:13.170  -->  00:10:20.670
P value and to do this we're going to select this summary function with the regressors inside and press

155

00:10:20.670  -->  00:10:23.230
command and control us and to execute.

156

00:10:23.970  -->  00:10:26.610
Let's move that up a bit.

157

00:10:26.700  -->  00:10:32.610
So these informations are very important informations when we want to build a robust model.

158

00:10:32.820  -->  00:10:38.250
And that's not only thanks to the information about the P-value here that will help select the optimal

159

00:10:38.250  -->  00:10:43.080
team of independent variables because below we also have this multiple R-squared.

160

00:10:43.110  -->  00:10:49.320
And this I just add R-squared that will help us build even more robust model than the one we're going

161

00:10:49.320  -->  00:10:54.420
to make in the next two tutorials because at the end of this part there is a section called evaluating

162

00:10:54.410  -->  00:10:58.520
models performance to actually improve the model performance.

163

00:10:58.760  -->  00:11:03.990
And in this part we'll actually use the multiple R-squared and the adjusted R-squared to finalise our

164

00:11:03.990  -->  00:11:09.360
journey towards the most robust model and you will perfectly understand why at the end of this part

165

00:11:10.080  -->  00:11:15.600
but for now let's focus on the P-value So the p values are actually in this column and then our There

166

00:11:15.610  -->  00:11:19.080
is actually a shortcut to look at the statistical significance.

167

00:11:19.110  -->  00:11:24.080
It's this last column here while this Nasscom doesn't have a name but you need to look at the stars

168

00:11:24.090  -->  00:11:30.980
here because as a reminder the more the value is below 5 percent are significance level then the more

169

00:11:30.990  -->  00:11:36.240
the independent variable will be statistically significant for the dependent variable profit and the

170

00:11:36.240  -->  00:11:42.360
more the value is higher than the significance level 5 percent then the less statistically significant

171

00:11:42.360  -->  00:11:44.010
the independent variable will be.

172

00:11:44.310  -->  00:11:50.970
So in short the lower the value the more your independent variable will have high impact on your dependent

173

00:11:50.970  -->  00:11:57.180
variable and the higher is the value the less effect impact your independent variable is going to have

174

00:11:57.360  -->  00:11:58.760
on the dependent variable.

175

00:11:59.150  -->  00:12:06.830
And there is this reminder here that says that if the P-value is between 0 and 0.1 percent then it's

176

00:12:06.840  -->  00:12:13.530
3 stars meaning that it's highly statistically significant than if the p value is between 0.1 percent

177

00:12:13.680  -->  00:12:19.620
and 1 percent then it's 2 stars meaning that it's very statistically significant but less significant

178

00:12:19.620  -->  00:12:21.060
than when there is three stars.

179

00:12:21.060  -->  00:12:27.170
Then if you've got us between 1 percent and 5 percent then it's simply statistically significant.

180

00:12:27.180  -->  00:12:31.810
That is your independent variables still have some good impact on the dependent variable.

181

00:12:32.150  -->  00:12:36.770
And then if the value is between 5 percent and 10 percent then it's a dot.

182

00:12:36.840  -->  00:12:42.780
Meaning that there is definitely a certain level of statistical significance there is your independent

183

00:12:42.780  -->  00:12:50.370
variable has a certain effect on your dependent variable but definitely not as much as your other independent

184

00:12:50.370  -->  00:12:53.980
variables that are in these categories here especially for this one.

185

00:12:54.330  -->  00:12:58.340
And finally if your p value is between 10 percent and 1.

186

00:12:58.500  -->  00:13:02.540
Well there's absolutely no statistical significance.

187

00:13:02.550  -->  00:13:05.320
So that means that with what we first observe here.

188

00:13:05.490  -->  00:13:12.870
Well we can see that the R&D spend is highly statistically significant but the rest seems to be not

189

00:13:12.870  -->  00:13:13.670
significant.

190

00:13:13.830  -->  00:13:20.540
But let's wait for the backward elimination to be completed to find out if our final team is actually

191

00:13:20.550  -->  00:13:26.250
only composed of Ardie spend because by removing some independent variables here that will remove some

192

00:13:26.250  -->  00:13:30.390
possible bias that want some independent variables are removed.

193

00:13:30.380  -->  00:13:35.870
We can actually find an independent variable that is more statistically significant than what it appeared

194

00:13:35.880  -->  00:13:37.280
to be at the beginning.

195

00:13:37.290  -->  00:13:39.030
That is the first step here.

196

00:13:39.260  -->  00:13:40.610
So let's find out about that.

197

00:13:40.640  -->  00:13:45.730
And actually you will find out about that yourself because this will be the subject of the homework

198

00:13:45.740  -->  00:13:45.800
.

199

00:13:45.870  -->  00:13:51.210
But don't worry I'm going to walk you through the first steps backward elimination and you will complete

200

00:13:51.210  -->  00:13:52.020
it yourself.

201

00:13:52.160  -->  00:13:56.440
And then the next tutorial of course will have the solution and we'll complete it together.

202

00:13:56.550  -->  00:13:59.180
So I look forward to seeing if we get the same results.

203

00:13:59.580  -->  00:14:02.970
Ok so now let's carry on with backward elimination.

204

00:14:03.060  -->  00:14:05.270
So remember we are at Step three.

205

00:14:05.340  -->  00:14:11.520
Step three is actually to look for the independent variable that has the highest P value and we can

206

00:14:11.520  -->  00:14:12.860
find it very easily.

207

00:14:12.890  -->  00:14:20.010
It's actually this one because indeed it's P-value is open 99 that is 99 percent.

208

00:14:20.070  -->  00:14:22.400
So that's actually a very high value.

209

00:14:22.560  -->  00:14:26.320
And we are way above the significance level of 5 percent.

210

00:14:26.520  -->  00:14:33.700
So this dummy variable for state state 2 is definitely not statistically significant at all.

211

00:14:33.720  -->  00:14:37.720
It has absolutely no effect on the dependent variable profit.

212

00:14:37.910  -->  00:14:43.240
And by the way we also observe that stage 3 here has a 94 percent p value.

213

00:14:43.400  -->  00:14:49.920
And there is no way that if we remove state to well this be value will decrease below the 5 percent

214

00:14:49.910  -->  00:14:51.240
significance level.

215

00:14:51.240  -->  00:14:57.330
So we can actually remove this state three independent variable as well because clearly the state has

216

00:14:57.330  -->  00:15:01.200
no effect or impact on the dependent variable profit.

217

00:15:01.400  -->  00:15:06.770
So I'll actually make some kind of a shortcut here and instead of removing the independent variable

218

00:15:06.780  -->  00:15:13.130
that has the highest P value that is state two will actually remove both these dummy variables for states

219

00:15:13.590  -->  00:15:17.410
because definitely the state is not statistically significant.

220

00:15:17.580  -->  00:15:21.870
So let's do this let's remove the state variable from our equation.

221

00:15:21.920  -->  00:15:24.440
So I'm going to put that down.

222

00:15:25.290  -->  00:15:33.350
OK so as I told you it's very simple we're just going to copy this and paste it here and then.

223

00:15:33.380  -->  00:15:34.740
So what do we have to do now.

224

00:15:34.880  -->  00:15:43.490
We just need to remove the state in the variable from our equation here and by doing that we complete

225

00:15:43.640  -->  00:15:50.610
Step four because if we go back to our slide step four is to actually remove the predicter grades and

226

00:15:50.610  -->  00:15:55.830
now we can move onto Step Five which is to fit the multiple regression model without the independent

227

00:15:55.830  -->  00:15:58.240
viable state that we just removed.

228

00:15:58.560  -->  00:15:58.810
OK.

229

00:15:58.830  -->  00:16:07.740
So we removed States so step 4 completed and now step 5 is to actually fit the model without this independent

230

00:16:07.740  -->  00:16:09.420
viable state that we just removed.

231

00:16:09.410  -->  00:16:10.410
So let's do this.

232

00:16:10.400  -->  00:16:15.520
We just need to select this press command and control this and to do execute.

233

00:16:15.600  -->  00:16:21.050
And here it is our new regressors is ready without the state independent viable.

234

00:16:21.060  -->  00:16:26.460
So now we have a team of three independent variables wait and see which have been invaluable is going

235

00:16:26.460  -->  00:16:27.810
to be kicked out of the team.

236

00:16:28.050  -->  00:16:33.770
And speaking of that this is where I'm going to leave you alone for the homework but don't worry you

237

00:16:33.780  -->  00:16:35.800
will have the solution in the next tutorial.

238

00:16:35.900  -->  00:16:41.360
But really try to implement this yourself complete backward elimination up to the end.

239

00:16:41.700  -->  00:16:44.310
And it will be fun to see if we get the same result.

240

00:16:44.310  -->  00:16:48.070
And there is actually kind of a decision to make at the end of Backwell elimination.

241

00:16:48.120  -->  00:16:54.540
So I'm curious to see how you make that decision make that call because both solutions are actually

242

00:16:54.570  -->  00:16:58.190
great and we will talk about that in the solution.

243

00:16:58.470  -->  00:17:00.870
So good luck for the homework.

244

00:17:01.080  -->  00:17:02.180
You're going to see it's going to be fine.

245

00:17:02.180  -->  00:17:08.200
So basically what you only have to do is to follow this backward elimination slide and so together and

246

00:17:08.200  -->  00:17:09.930
the Statoil went up to this.

247

00:17:10.050  -->  00:17:16.430
Step Five here and now as you can see you have to go back to Step Three and redo the steps three four

248

00:17:16.450  -->  00:17:24.020
five exactly like we just did until you find that the highest value is not higher than the significance

249

00:17:24.030  -->  00:17:24.510
level.

250

00:17:24.680  -->  00:17:27.940
And when it's the case your model will be ready.

251

00:17:28.400  -->  00:17:28.670
OK.

252

00:17:28.670  -->  00:17:31.110
So I look forward to seeing you in the next tutorial.

253

00:17:31.110  -->  00:17:37.620
I look forward to comparing with you your results to mine and I'm sure everything will be ok.

254

00:17:37.660  -->  00:17:40.280
Backward elimination is very practical on our.

255

00:17:40.430  -->  00:17:43.450
It will actually be fun and easy to complete this.

256

00:17:43.770  -->  00:17:45.570
So thank you for watching this story.

257

00:17:45.740  -->  00:17:49.100
And I look forward to seeing you in the next one for the solution.

258

00:17:49.130  -->  00:17:51.080
Until then and machine learning.
