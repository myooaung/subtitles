1
00:00:00,180 --> 00:00:00,960
Our IMF friends.

2
00:00:00,960 --> 00:00:01,770
Let's do this.

3
00:00:01,890 --> 00:00:06,690
Let's use the Elbow Method to find the optimal number of clusters.

4
00:00:06,720 --> 00:00:12,590
So we're gonna use of course the W C S S which is the within cluster sum of squares.

5
00:00:12,600 --> 00:00:13,760
I will remain what this is.

6
00:00:13,770 --> 00:00:20,000
But first let's create a new coat cell to start this new step of the implementation.

7
00:00:20,010 --> 00:00:20,370
All right.

8
00:00:20,370 --> 00:00:22,350
So what are we going to start with here.

9
00:00:22,350 --> 00:00:28,710
Well we're gonna find back our very good friend psychedelia because we will actually implement that

10
00:00:28,800 --> 00:00:36,450
elbow method with a class of psychic burn which guess what is called well k means because indeed the

11
00:00:36,450 --> 00:00:43,560
way we will implement the Elbow Method will actually be by running the K Means algorithm with several

12
00:00:43,620 --> 00:00:49,500
number of clusters you see we're gonna run the Caymans algorithm several times each time with a different

13
00:00:49,770 --> 00:00:50,860
number of clusters.

14
00:00:50,880 --> 00:00:53,370
And that's why we have to call that came in.

15
00:00:53,370 --> 00:00:56,970
Class that can run this algorithm already and so.

16
00:00:57,030 --> 00:01:04,440
Well our first step here will be to start from cycle learn cycle learn from which we're gonna get access

17
00:01:04,440 --> 00:01:10,500
to the module that contains that K Means class and that module is called cluster.

18
00:01:10,590 --> 00:01:11,580
Just like that.

19
00:01:11,580 --> 00:01:18,420
And then from which we are going to import well that K Means class.

20
00:01:18,420 --> 00:01:18,990
Perfect.

21
00:01:19,590 --> 00:01:22,380
And now what do you think the next step is going to be.

22
00:01:22,380 --> 00:01:29,070
Well exceptionally this time the next step won't be to create an instance or you know an object of this

23
00:01:29,070 --> 00:01:38,010
came in class because we're about to start a for loop which will run the K Means algorithm with 10 different

24
00:01:38,190 --> 00:01:39,600
numbers of clusters.

25
00:01:39,600 --> 00:01:45,750
So very simply we will run the Caymans algorithm with one cluster then with two clusters three clusters

26
00:01:46,020 --> 00:01:52,980
etc. up to 10 clusters and therefore the way to do this is through a loop and we will do a for loop

27
00:01:53,160 --> 00:01:59,370
because we know exactly the different numbers of clusters we want to try which are from 1 to 10 and

28
00:01:59,520 --> 00:02:04,380
each time we run the Caymans algorithm you know with these different numbers of clusters.

29
00:02:04,380 --> 00:02:10,200
Well we will compute Of course you know that famous metric and clustering which is as I told you at

30
00:02:10,200 --> 00:02:19,410
the beginning W C S S2 within cluster sum of squares which I remind is defined as the sum of the squared

31
00:02:19,470 --> 00:02:27,370
distances between each observation point of the cluster and its century the century of the cluster.

32
00:02:27,420 --> 00:02:30,930
So we're going to compute that some of these squared distances.

33
00:02:31,080 --> 00:02:36,810
And this is exactly what will be on the y axis in the graph of the Elbow Method.

34
00:02:36,840 --> 00:02:43,050
You know remember the graph in the Elbow Method contains in the x axis well the different numbers of

35
00:02:43,050 --> 00:02:51,150
clusters we will try from one to 10 and in the y axis it contains the WC as is computed for each of

36
00:02:51,210 --> 00:02:52,700
these numbers of clusters.

37
00:02:52,860 --> 00:02:59,550
And therefore here what we have to do right before starting this for loop is to create a list which

38
00:02:59,550 --> 00:03:06,630
will through the for loop be populated with the successive WC yes values know for each of the numbers

39
00:03:06,630 --> 00:03:14,490
of clusters and therefore we're going to call that list W C as S which we will initialize as an empty

40
00:03:14,490 --> 00:03:15,060
list.

41
00:03:15,060 --> 00:03:19,620
Remember that list in Python are written in a pair of square brackets.

42
00:03:19,620 --> 00:03:26,250
So here in this pair of square brackets we're going to add one by one to different WC asset values for

43
00:03:26,250 --> 00:03:28,470
each of the numbers of clusters.

44
00:03:28,530 --> 00:03:28,970
Okay.

45
00:03:29,160 --> 00:03:30,870
And now we can start the for loop.

46
00:03:30,930 --> 00:03:34,460
So the way to write a full loop in Python is to start with 4.

47
00:03:34,890 --> 00:03:41,730
Then we choose a name of the iterator variable which you know will be incremented by 1 each time in

48
00:03:41,850 --> 00:03:43,440
each iteration of the loop.

49
00:03:43,440 --> 00:03:46,670
And the classic name for that horrible is I.

50
00:03:46,770 --> 00:03:49,320
And then we add in range.

51
00:03:49,320 --> 00:03:57,230
And here we specify in parenthesis Well the values we want this index of the loop to take over the iterations.

52
00:03:57,360 --> 00:03:58,950
And here that's very simple.

53
00:03:58,950 --> 00:04:05,190
I will actually take the different values of the numbers of clusters we want to try which are from 1

54
00:04:05,310 --> 00:04:14,160
to 10 included but remember ranges in Python include the lower bound but excluding the upper bound that's

55
00:04:14,280 --> 00:04:15,410
actually what we see here.

56
00:04:15,420 --> 00:04:17,430
You know start defaults to zero.

57
00:04:17,470 --> 00:04:21,860
Okay so that's the default lower bound and stop is emitted.

58
00:04:21,900 --> 00:04:22,290
Right.

59
00:04:22,290 --> 00:04:23,700
It is excluded.

60
00:04:23,700 --> 00:04:26,070
So that's why I also really like Google collab.

61
00:04:26,070 --> 00:04:31,590
You have all the info in this little help window but I'm also here for the explanation so there you

62
00:04:31,590 --> 00:04:32,160
go.

63
00:04:32,160 --> 00:04:39,510
The range we have to input here is from 1 you know the first number of classes we will try and then

64
00:04:39,690 --> 00:04:47,160
up to not ten but eleven because we want to include 10 and therefore we have to go up to 11 which is

65
00:04:47,160 --> 00:04:47,860
excluded.

66
00:04:47,940 --> 00:04:48,300
All right.

67
00:04:48,600 --> 00:04:54,300
And then we add just a little color just like that and then we start to flip.

68
00:04:54,500 --> 00:04:54,930
All right.

69
00:04:54,930 --> 00:05:00,890
And now now can come the next natural step in know after we import this class to Damon's class because

70
00:05:00,890 --> 00:05:05,120
indeed now we can create our first came into object.

71
00:05:05,120 --> 00:05:08,070
Why do I say our first came into object.

72
00:05:08,090 --> 00:05:12,980
That's because once again you know where you're going to create 10 different came into objects for each

73
00:05:12,980 --> 00:05:16,300
of these numbers of clusters from one to 10.

74
00:05:16,310 --> 00:05:23,300
So here we're creating the first K Means algorithm which will be run with therefore one cluster because

75
00:05:23,360 --> 00:05:25,010
I hear starts at 1.

76
00:05:25,100 --> 00:05:31,850
All right so let's create our first k means object which represents exactly the Caymans algorithm which

77
00:05:31,850 --> 00:05:33,660
will be run to identify.

78
00:05:33,680 --> 00:05:36,040
Well actually some one cluster.

79
00:05:36,080 --> 00:05:41,300
You see what I mean and then I will be equal to two so that new came in the algorithm will be run to

80
00:05:41,300 --> 00:05:46,930
identify two clusters and then a new Caymans algorithm will be run to identify three clusters etc..

81
00:05:46,970 --> 00:05:47,590
Up to 10.

82
00:05:47,770 --> 00:05:49,490
OK so there you go.

83
00:05:49,490 --> 00:05:54,800
That's our first object which we create by calling of course the K Means class.

84
00:05:54,800 --> 00:05:57,790
Be careful with the capital letters came into class.

85
00:05:57,830 --> 00:06:01,970
We add some parenthesis and now we import the arguments.

86
00:06:02,300 --> 00:06:06,980
So here Google collab is not helping us but no worries I'm here so I'm going to tell you exactly what

87
00:06:06,980 --> 00:06:09,510
we need to input in this scheme in this class.

88
00:06:09,590 --> 00:06:14,720
And if you want to do it even better well you can actually press pass on this video and look into the

89
00:06:14,720 --> 00:06:15,490
documentation.

90
00:06:15,500 --> 00:06:21,620
You know in this cycle learn API what you need input at parameters in this game is class.

91
00:06:21,620 --> 00:06:22,170
All right so.

92
00:06:22,190 --> 00:06:25,840
Press but if you want and now I'm going to tell you the solution.

93
00:06:26,630 --> 00:06:33,680
So the first parameters obviously is going to be well that number of clusters we want to identify you

94
00:06:33,680 --> 00:06:40,790
know when running this first K Means Algorithm represented by this first came into object and that name

95
00:06:40,790 --> 00:06:47,720
of the parameter is n underscore clusters which stands for exactly number of clusters.

96
00:06:47,720 --> 00:06:48,200
All right.

97
00:06:48,200 --> 00:06:50,450
And this should be equal to what.

98
00:06:50,500 --> 00:06:57,380
Well if you understood the way this full loop works of course the number of classes here is high which

99
00:06:57,380 --> 00:07:03,710
starts at 1 then we'll be equal to 2 and 3 up 10 which are two different numbers of clusters.

100
00:07:03,710 --> 00:07:08,060
We want to experiment in order to plot that elbow method graph.

101
00:07:08,180 --> 00:07:08,450
All right.

102
00:07:08,450 --> 00:07:10,640
So numbers of clusters equal ie.

103
00:07:10,730 --> 00:07:17,180
And then we would like to do something to avoid the random initialization trap which was explained by

104
00:07:17,180 --> 00:07:24,380
Carol in the intuition lecturers and the way to avoid it is to initialize the Caymans algorithm with

105
00:07:24,620 --> 00:07:29,000
a particular method and that method is called K Means plus plus.

106
00:07:29,000 --> 00:07:35,390
So it's basically an advanced initialization trick which will make sure we don't fall into the random

107
00:07:35,510 --> 00:07:36,770
initialization trap.

108
00:07:36,920 --> 00:07:43,970
So we must absolutely input that parameter and the name of that parameter is in it and the value to

109
00:07:43,970 --> 00:07:44,510
select.

110
00:07:44,510 --> 00:07:52,730
Well that came in plus plus initialization is called in quotes because that's a string k means plus

111
00:07:52,730 --> 00:07:53,270
plus.

112
00:07:53,300 --> 00:07:54,220
Just like that.

113
00:07:54,260 --> 00:07:54,650
All right.

114
00:07:54,650 --> 00:08:01,850
So now we're safe from the random initialization trap and now we will just add one final argument.

115
00:08:01,850 --> 00:08:06,980
You know this one very well it's just in order for us to have the exact same results on our notebook

116
00:08:07,180 --> 00:08:12,710
that we can you know follow and describe what's happening on our notebook and that parameter is of course

117
00:08:12,800 --> 00:08:21,740
random underscore a state which we will send equal to 42 42 apparently is a number that brings luck

118
00:08:21,770 --> 00:08:23,000
in mathematics.

119
00:08:23,060 --> 00:08:29,330
I'm not saying that I believe in this but anyway we just have to fix the seed here and any number is

120
00:08:29,330 --> 00:08:32,000
OK as long as we choose the same.

121
00:08:32,040 --> 00:08:32,440
All right.

122
00:08:32,440 --> 00:08:39,200
Forty two and now the next step because we only created the objects so far we haven't run the algorithm

123
00:08:39,200 --> 00:08:39,890
yet.

124
00:08:39,890 --> 00:08:40,880
Well here we go.

125
00:08:40,880 --> 00:08:46,340
That's the next step the next step is to run the algorithm and by running the algorithm I actually mean

126
00:08:46,460 --> 00:08:47,310
train it.

127
00:08:47,340 --> 00:08:52,940
You know we we are ready to train that came into algorithm with that AI number of clusters.

128
00:08:52,940 --> 00:08:58,730
And as any function you know especially in the cycle learn library but also you know an attentive library

129
00:08:58,940 --> 00:09:05,540
while the function used to train an algorithm and machinery model is the fit function here a method

130
00:09:05,810 --> 00:09:08,570
because it will be called from this came in as objects.

131
00:09:08,570 --> 00:09:09,530
There you go.

132
00:09:09,530 --> 00:09:11,150
The next step here is of course to take.

133
00:09:11,150 --> 00:09:19,160
Well our key means objects from which we're going to call that fit method which will take as input.

134
00:09:19,160 --> 00:09:22,290
Well you're gonna tell me what does it take as input.

135
00:09:22,430 --> 00:09:29,450
It takes us and put this time of course only the matrix of features X because remember you know in the

136
00:09:29,600 --> 00:09:33,320
graph that was shown to you to explain the intuition lecturers.

137
00:09:33,320 --> 00:09:40,100
Well in order to train the Caymans algorithm we only need the data of the features in here as a reminder

138
00:09:40,130 --> 00:09:46,940
we are training the Caymans algorithm with only the annual income and the spending score and you will

139
00:09:46,940 --> 00:09:51,960
see that it will be way enough to identify some patterns some clusters.

140
00:09:51,960 --> 00:09:53,090
All right and that's it.

141
00:09:53,140 --> 00:09:58,000
That's only what we have to input to run or train the Caymans algorithm.

142
00:09:58,070 --> 00:10:02,790
And so now according to you are we done with the iteration of the loop.

143
00:10:02,790 --> 00:10:09,630
Well no because remember we are only doing this to get one particular thing which we already initialized.

144
00:10:09,630 --> 00:10:16,230
I'm talking of course about the WC asset value which is the within class the sum of squares between

145
00:10:16,350 --> 00:10:21,850
the observation points in each cluster and the century of each cluster.

146
00:10:21,870 --> 00:10:22,910
So there you go.

147
00:10:22,920 --> 00:10:29,160
That's exactly what we have to compute right now now that we already trains and run our Caymans algorithm

148
00:10:29,640 --> 00:10:39,600
and well the way to get that WC asset value is to first take or WC SS list which is so far initialized

149
00:10:39,810 --> 00:10:47,220
as an empty list and then we're gonna use the append function which is a prebuilt function of Python

150
00:10:47,220 --> 00:10:53,310
lists and which will of course add or append you know a new value inside this list.

151
00:10:53,310 --> 00:11:00,930
And the first value it will happen of course is the WTS has value computed for one cluster which is

152
00:11:00,930 --> 00:11:06,750
therefore actually the sum of the squared distances between all the observation points you know because

153
00:11:06,750 --> 00:11:10,720
there is only one cluster and the Century of the single cluster.

154
00:11:10,770 --> 00:11:11,170
All right.

155
00:11:11,490 --> 00:11:19,170
So append since it is a function of adding some parenthesis and well the way to get that WC SS value

156
00:11:19,350 --> 00:11:22,320
is to call an attribute of the Caymans object.

157
00:11:22,320 --> 00:11:27,460
You know objects and classes have attributes which gives you directly some values you want.

158
00:11:27,460 --> 00:11:33,180
And well luckily for us there is an attribute of the Caymans class which is called inertia and which

159
00:11:33,180 --> 00:11:36,220
will give us exactly that WC as its value.

160
00:11:36,260 --> 00:11:36,670
All right.

161
00:11:36,960 --> 00:11:41,520
So in order to get that attribute we just need to call our object first because you know when you want

162
00:11:41,520 --> 00:11:46,350
to get an attribute you always have to call it from the object and then you added that and there you

163
00:11:46,350 --> 00:11:52,790
go you call for the attribute in which is here inertia with an underscore added.

164
00:11:53,070 --> 00:11:53,490
All right.

165
00:11:53,490 --> 00:11:54,330
Congratulations.

166
00:11:54,330 --> 00:11:56,910
I think this was the very first for loop.

167
00:11:56,940 --> 00:11:58,200
We actually built in this course.

168
00:11:58,200 --> 00:12:02,050
So if it is your very first full loop of all time congratulations.

169
00:12:02,130 --> 00:12:08,700
As you see this is not Nazi at all and you actually built a very useful for loop which will plot very

170
00:12:08,700 --> 00:12:15,300
nicely the graph of the Elbow Method and now to get out of the for loop we need to you know go back

171
00:12:15,300 --> 00:12:21,990
here at the beginning of the row to specify to Python that we are indeed not anymore in the loop and

172
00:12:21,990 --> 00:12:23,990
that we are back in the main code.

173
00:12:24,090 --> 00:12:29,940
And speaking of the main code well the only thing that we're left to do is just to plot the graph because

174
00:12:29,940 --> 00:12:35,730
indeed we have all the WC SS values for each of the indexes are going from 1 to 10.

175
00:12:36,060 --> 00:12:41,400
Therefore for each of the numbers of clusters because I represent here the different numbers of clusters

176
00:12:41,400 --> 00:12:42,800
we want to experiment.

177
00:12:42,810 --> 00:12:47,870
So here we just have to plot the graph and to do this while we're going to use of course Matt plotted

178
00:12:47,930 --> 00:12:56,490
the pie plot which we will use this way first by calling the P L T shortcut here and then from which

179
00:12:56,670 --> 00:12:59,250
we're gonna call the plot function.

180
00:12:59,250 --> 00:13:04,830
This is something we already did of course when plotting our regression curves or classification curves

181
00:13:05,160 --> 00:13:12,630
in part 2 and 3 and now we about a plot just a simple curve that will follow the different WC as has

182
00:13:12,630 --> 00:13:19,020
values taken for the different numbers of clusters from 1 to 10 and so well in that plot function remember

183
00:13:19,020 --> 00:13:20,330
what we have to input.

184
00:13:20,340 --> 00:13:25,470
For us we have to input the different values that will be taken on the x axis and that's the values

185
00:13:25,470 --> 00:13:26,500
from 1 to 10.

186
00:13:26,550 --> 00:13:32,730
So in order to specify this well we can simply take you know that range again because that range from

187
00:13:32,880 --> 00:13:36,470
1 to 10 exactly returns all the values from 1 to 10.

188
00:13:36,480 --> 00:13:37,080
So there you go.

189
00:13:37,080 --> 00:13:43,440
That's what we can input here for the X coordinates and now for the y coordinates according to what

190
00:13:43,560 --> 00:13:45,130
we're going to be here.

191
00:13:45,120 --> 00:13:51,750
Well very simply that's of course all the different values of WC yeses and they have to be input in

192
00:13:51,750 --> 00:13:53,670
a list and well good news.

193
00:13:53,700 --> 00:13:59,850
That's exactly what we have already and that's of course also the reason why we created that list in

194
00:13:59,850 --> 00:14:08,070
the first place so that we can directly input this into the plot function to indeed plot are elbow method

195
00:14:08,070 --> 00:14:09,210
graph.

196
00:14:09,210 --> 00:14:15,360
All right things are starting to get completed here now where else can we do to improve that graph.

197
00:14:15,360 --> 00:14:22,140
Well you know very simply we're gonna add a nice title with the title function and we'll actually title

198
00:14:22,170 --> 00:14:27,110
our graph by you know the L BOE method.

199
00:14:27,180 --> 00:14:27,600
All right.

200
00:14:27,600 --> 00:14:31,190
Very simply then we'll add a label to the x axis.

201
00:14:31,200 --> 00:14:41,370
Thanks to the X label function and on the x axis we can specify that it is indeed the number of clusters.

202
00:14:41,370 --> 00:14:42,400
Perfect.

203
00:14:42,480 --> 00:14:52,980
And now same for the Y label which we will specify to be of course W C S S will increase the sum of

204
00:14:52,980 --> 00:14:53,680
squares.

205
00:14:54,150 --> 00:15:02,890
And finally remember the last thing we have to do which is to show the graph with the show function.

206
00:15:02,890 --> 00:15:03,510
All right.

207
00:15:03,570 --> 00:15:05,560
So I think we're done here.

208
00:15:05,560 --> 00:15:06,160
Let's see.

209
00:15:06,160 --> 00:15:09,530
Let's see if we're right and if we didn't make a mistake.

210
00:15:09,610 --> 00:15:17,260
So we're actually going to play that cell and plot the Elbow Method graph.

211
00:15:17,350 --> 00:15:18,590
Congratulations.

212
00:15:18,760 --> 00:15:21,080
We did it 100 percent correctly.

213
00:15:21,160 --> 00:15:25,350
So now according to you after you followed you know the intuition lectures.

214
00:15:25,480 --> 00:15:28,630
What is the optimal number of clusters we must use here.

215
00:15:29,140 --> 00:15:37,600
Well I remind that this is the number of clusters from which you know the WC assessed value starts slowing

216
00:15:37,600 --> 00:15:41,310
down you know start reducing its descent and here.

217
00:15:41,320 --> 00:15:46,780
Well that of course that number here you know the number five because indeed from this number.

218
00:15:46,930 --> 00:15:49,920
Well you know the curve starts being almost flat.

219
00:15:49,930 --> 00:15:52,460
No it decreases very slowly here.

220
00:15:52,510 --> 00:15:57,160
It decreases very strongly you know decreases a lot here still quite much.

221
00:15:57,280 --> 00:16:01,900
And from the number of clusters five well it decreases slowly.

222
00:16:01,940 --> 00:16:02,200
Okay.

223
00:16:02,230 --> 00:16:08,640
So clearly the optimal number of classes here is five and therefore for our next step training came

224
00:16:08,650 --> 00:16:16,930
in tomorrow on the data set we will choose to build it to train it and to run it to identify five clusters.

225
00:16:16,930 --> 00:16:22,060
All right so let's do this in a next material and actually I have an exercise for you based on what

226
00:16:22,060 --> 00:16:28,230
we did here to plot that elbow method graph you can actually totally do this on your own.

227
00:16:28,240 --> 00:16:33,370
So actually in the next material we will train that came in tomorrow on the day set you know to identify

228
00:16:33,460 --> 00:16:39,220
five clusters and then we'll also create that dependent variable which I've told you about you know

229
00:16:39,220 --> 00:16:44,830
that's the principle of clustering we are creating at some point a new dependent variable in which the

230
00:16:44,830 --> 00:16:47,590
values will be exactly the different clusters.

231
00:16:47,590 --> 00:16:54,130
So at least before we start the next tutorial well please train the Caymans model on the data set to

232
00:16:54,130 --> 00:16:56,440
identify five clusters.

233
00:16:56,440 --> 00:16:58,300
And until then enjoy machine learning.
