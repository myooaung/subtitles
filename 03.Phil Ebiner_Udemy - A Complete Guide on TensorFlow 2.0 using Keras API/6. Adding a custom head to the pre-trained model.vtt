WEBVTT
1
00:00:00.360 --> 00:00:05.440
Hello everyone and welcome to this python tutorial in the previous with you.

2
00:00:05.440 --> 00:00:11.740
We have frozen our base network and now it's time to define our custom head on top of it.

3
00:00:11.890 --> 00:00:16.570
The custom head is always designed for a task that you're trying to solve.

4
00:00:16.570 --> 00:00:20.450
In this case it is classifying between cats and dogs.

5
00:00:21.450 --> 00:00:28.290
To define a custom head the first thing to do is to check what is the output size from the base network

6
00:00:29.160 --> 00:00:36.300
and based on that information we can see how many layers if any should be added to the custom part of

7
00:00:36.300 --> 00:00:37.400
the network.

8
00:00:37.800 --> 00:00:45.150
In the first cell right base model dot output as you can see the output from our base and therefore

9
00:00:45.250 --> 00:00:51.260
has the size of four times four times one thousand two hundred and eighty.

10
00:00:51.260 --> 00:00:56.070
This size is not very suited for the output layer of the custom head.

11
00:00:56.090 --> 00:01:01.740
There are a few approaches that we can take to handle this problem as always.

12
00:01:01.750 --> 00:01:08.440
We could use the flattening layer to convert or reshape our output to vectors.

13
00:01:08.440 --> 00:01:15.300
But in this case we would have far to be vectors for our custom part of the network.

14
00:01:15.370 --> 00:01:21.220
The other better solution in our case is to use a global average pooling layer.

15
00:01:21.220 --> 00:01:27.250
We haven't discussed this layer before but the concept is very similar to the max pulling layer that

16
00:01:27.250 --> 00:01:36.200
we used all across the CNN s the global war means that is going to take the whole input instead of processing

17
00:01:36.200 --> 00:01:37.920
parts of it at the time.

18
00:01:38.480 --> 00:01:40.850
And this feature will help us.

19
00:01:40.850 --> 00:01:44.930
It reduces the input size significantly.

20
00:01:45.010 --> 00:01:47.710
The second part of the name is average.

21
00:01:47.710 --> 00:01:54.430
Instead of finding the most significant value what Max bullying is doing this layer takes an average

22
00:01:54.490 --> 00:02:03.140
of all numbers in an input defined a variable called global average layer and set it to be equal to

23
00:02:03.580 --> 00:02:06.170
the DOT carers dot layers.

24
00:02:06.170 --> 00:02:14.320
And from this point to global average pooling to the this function doesn't take any arguments so provide

25
00:02:14.740 --> 00:02:20.350
only the input to it which is the output from our base model.

26
00:02:20.470 --> 00:02:23.190
Let's check what is the size of this layer.

27
00:02:23.350 --> 00:02:32.310
And as you can see it is none by two and which is the last dimension of the input.

28
00:02:32.330 --> 00:02:38.240
The only thing left to do is to define our output layer or prediction layer.

29
00:02:38.240 --> 00:02:45.710
Let's write prediction layer equal to the don't care US DOT dance and let's provide all arguments to

30
00:02:45.710 --> 00:02:46.530
it.

31
00:02:46.670 --> 00:02:51.270
The first one is to specify the number of units or neurons.

32
00:02:51.680 --> 00:02:57.950
As you know our output layer should have the same amount of units as number of classes in our data set

33
00:02:59.150 --> 00:03:01.300
since we only have two classes.

34
00:03:01.340 --> 00:03:08.380
We can specify this to one because we are performing binary classification in the second argument is

35
00:03:08.380 --> 00:03:12.500
to define the activation which is the sigmoid.

36
00:03:12.500 --> 00:03:19.830
In our case and the inputs to this layer is our global average layer execute the cell.

37
00:03:19.840 --> 00:03:22.190
And now we have defined the whole network.

38
00:03:22.300 --> 00:03:29.180
We had on top of it and it said for this video if you have any questions or comments so far please post

39
00:03:29.180 --> 00:03:30.800
them in the comments section.

40
00:03:30.800 --> 00:03:32.690
Otherwise I'll see in the next tutorial.
