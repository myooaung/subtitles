WEBVTT

00:00.330 --> 00:01.510
Hello welcome back.

00:01.530 --> 00:03.420
And now let's define the rewards.

00:03.810 --> 00:10.170
So by defining the rewards we have to define a reward function that will take as input a couple of two

00:10.170 --> 00:13.740
elements the input state and the output action.

00:13.950 --> 00:21.450
And then of course it will return the reward that the AI gets when playing the action a status and here

00:21.540 --> 00:27.940
since we have a finite number of states and a finite number of actions which are actually the same numbers.

00:28.110 --> 00:35.670
While the best way to define that function is through this matrix where each of the rows here corresponds

00:35.670 --> 00:41.170
to the input state and each of the columns here correspond to the action that can be played.

00:41.460 --> 00:47.280
And then in each of the cells here we'll get either a zero or a one will get a 1.

00:47.430 --> 00:52.580
If we can play the action of this column here when being in the state of this row here.

00:52.620 --> 00:58.290
So for example here we are in the second row corresponding to the State beat and in the column five

00:58.380 --> 01:01.880
corresponding to the action that leads to location f.

01:02.100 --> 01:06.460
Well let's see when being in location B we can go to F..

01:06.570 --> 01:13.200
Indeed because it's a neighbor location and therefore here in a specific cell we'll get one because

01:13.200 --> 01:15.810
we can go to location EF 1 being in location B.

01:15.960 --> 01:22.290
But then for example let's take this cell the cell corresponds to the situation where we are in location

01:22.330 --> 01:24.670
B and we want to go to locations.

01:24.870 --> 01:31.230
Well let's see again when being in location B We cannot go directly to location G because we have to

01:31.230 --> 01:37.660
go to see first and therefore we can not play an action that will lead us from location to location.

01:38.000 --> 01:41.960
And therefore in this specific cell here we'll get a zero.

01:41.970 --> 01:45.810
So that's how we're going to populate our matrix of words in the first place.

01:45.810 --> 01:48.580
That is that's how we are going to initialize it.

01:48.750 --> 01:55.890
And then you'll see as a second step will give a high reward in the cell where we want our ultimate

01:55.890 --> 01:57.630
wherehouse robot to go.

01:57.630 --> 01:59.960
And I remind that this is the location.

02:00.210 --> 02:06.750
Because this is a location that has the top priority ranking with the highest priority of product delivery.

02:07.080 --> 02:13.830
And so you'll see in the end after initializing our matrix of reward we'll put a huge reward here in

02:13.830 --> 02:17.310
the cell Jiji but that will be in second step.

02:17.310 --> 02:21.670
So first let's populate our matrix of words row by row.

02:21.900 --> 02:23.860
And let's start with the first row.

02:23.910 --> 02:26.320
So the first line correspond to state a.

02:26.670 --> 02:33.030
And if we go back to our warehouse we can see that one being in a state a the only location that we

02:33.030 --> 02:39.540
can reach is location B and therefore the only possible action that we can play when being in the state

02:39.590 --> 02:45.660
A is the action that leads to state B and therefore that's the action one because according to our mapping

02:46.020 --> 02:47.850
B corresponds to 1.

02:47.880 --> 02:55.070
So in the first row of the matrix you will only have a 1 for location B and zero otherwise.

02:55.410 --> 02:58.250
And now let's populate the second row of our matrix.

02:58.350 --> 03:04.890
That is the row corresponding to stay B that is corresponding to the situation where our outer warehouse

03:05.040 --> 03:07.030
robot is B.

03:07.200 --> 03:15.750
And so when being in location B are Adnams warehouse robot can only go to location a location see location.

03:15.960 --> 03:22.710
So we'll only get to one for these three locations location Achor response to index zero location Siegrist

03:22.710 --> 03:29.540
plans to index to any location corresponds to index 0 0 1 2 3 4 and 5.

03:29.820 --> 03:36.420
And therefore in the second row of our matrix A reward will only get a 1 for the first column.

03:36.450 --> 03:39.730
The third column and the Sixth Column of index file.

03:39.900 --> 03:41.260
Let's check it out.

03:41.310 --> 03:48.380
Indeed we only get a 1 for a on the one for C and only one for F and the other locations have zeroes.

03:48.420 --> 03:49.130
Great.

03:49.140 --> 03:53.980
Now let's do it one last time again with row 3 corresponding to location C.

03:54.010 --> 03:56.750
So if we go back to our warehouse.

03:57.030 --> 04:04.190
Well when being in the input state see is when our other members were house robot is in location see.

04:04.340 --> 04:12.660
Well it can only go to location B or location location B has index 1 because the indexes start from

04:12.660 --> 04:18.750
zero and location G has index 0 1 2 3 4 5 6 index 6.

04:19.020 --> 04:27.120
And therefore as you can see will only yellow ones for location B or location G and the other locations

04:27.120 --> 04:27.900
have zeroes.

04:28.290 --> 04:31.250
And that's how we populate our matrix of rewards.

04:31.470 --> 04:38.100
And therefore you can do the other rows yourself which you'll get in the end is the following matrix

04:38.100 --> 04:39.230
of rewards.

04:39.450 --> 04:41.100
So you can check it out by yourself.

04:41.240 --> 04:48.450
I hope I don't make any mistakes because I actually did it manually at first but that's our final matrix

04:48.450 --> 04:56.160
of reward initialized only initialized and you'll see to train the robot to go to a specific location

04:56.160 --> 05:02.930
that is the top priority location which I remind is location Well what will have to do is attribute

05:03.310 --> 05:11.190
a high reward to locations in the sale G.G. and that is why at some point in the implementation we will

05:11.270 --> 05:20.390
see that we'll populate the matrix of reward with 1000 specific cell here of Rogie and Collinge by only

05:20.390 --> 05:27.380
specifying that our crew learning model will find the optimal route from wherever we start to know whether

05:27.380 --> 05:32.430
we start from location A B C D and actually we'll start from location.

05:32.590 --> 05:39.080
In the case study we'll from wherever we start we'll be able to find the optimal route to go to the

05:39.080 --> 05:41.700
temporary location location.

05:42.350 --> 05:43.240
All right.

05:43.400 --> 05:44.370
And here we go.

05:44.390 --> 05:48.460
We are done with the first part of our plan of attack.

05:48.500 --> 05:51.880
That is the first part of the case study find funding the environment.

05:51.980 --> 05:56.030
That's a fundamental part that has to be done any time here.

05:56.030 --> 06:01.160
It was actually simple we were done with the first case study but you will see that the funding environment

06:01.160 --> 06:05.480
can be much more complex as you will see in case study number two.

06:05.750 --> 06:07.380
But first we have to warm up.

06:07.520 --> 06:10.750
That's why we're starting with this pretty simple environment.

06:10.880 --> 06:16.730
But keep in mind that what we're doing here is actually applicable to lots and lots of business problems

06:16.940 --> 06:22.210
even with this simplicity that's why it's really important that you assimilate all this.

06:22.230 --> 06:28.010
All right now we're going to move on to the second part where you'll study the intuition and the theory

06:28.310 --> 06:30.310
of the solution we're going to build.

06:30.410 --> 06:36.490
That is a cool learning model and you will see that with curial with his amazing intuition lectures.

06:36.620 --> 06:41.930
And again I remind that you also have a notebook where you will find exactly the same the intuition

06:42.230 --> 06:48.890
actually explained by myself and this theory with all the mathematical details including all the mathematical

06:48.890 --> 06:49.880
details of the cure.

06:49.880 --> 06:54.030
And tomorrow you will find that in the so whatever you prefer.

06:54.130 --> 06:55.660
What's the intuition lectures.

06:55.670 --> 06:57.340
Read the book or do both.

06:57.470 --> 06:59.870
That's according to your preferred way of study.

07:00.200 --> 07:05.250
All right so enjoy the second part and I will see you back again for part three.

07:05.270 --> 07:06.980
The implementation in Python.
