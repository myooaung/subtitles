WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.000 --> 00:00:00.640
everybody.

00:00:00.640 --> 00:00:04.860
And welcome to this lesson are looking at how we can build a machine learning application.

00:00:04.860 --> 00:00:11.090
So building applications are building ML applications is an iterated process that enrolled

00:00:11.090 --> 00:00:12.570
is sequence of steps.

00:00:12.570 --> 00:00:16.090
So to build a machine learning applications,

00:00:16.090 --> 00:00:20.360
there's generally five different steps that one should follow.

00:00:20.360 --> 00:00:21.340
For example,

00:00:21.340 --> 00:00:25.230
there is formulate the problem and collect and label data,

00:00:25.230 --> 00:00:29.650
analyze the data feature processing and splitting the data.

00:00:29.650 --> 00:00:34.630
So what I mean by formulating the problem or formulate a problem to the first step in

00:00:34.630 --> 00:00:37.270
machine learning is to decide what you want to predict,

00:00:37.270 --> 00:00:40.120
which is known as the label or target answer.

00:00:40.120 --> 00:00:43.380
So imagine a scenario in which you want to manufacture products,

00:00:43.380 --> 00:00:47.790
but your decision to manufacture each product depends on its number of potential sales.

00:00:47.790 --> 00:00:48.960
On the scenario.

00:00:48.960 --> 00:00:51.840
You want to predict how many times each product will be purchased,

00:00:51.840 --> 00:00:53.990
which is predicting the number of sales.

00:00:53.990 --> 00:00:57.880
So there's multiple ways to define this problem by using machine learning.

00:00:57.880 --> 00:01:03.560
So choosing how to define the problem depends on your use case or specific business need.

00:01:03.560 --> 00:01:04.720
For example,

00:01:04.720 --> 00:01:09.070
do you want to predict the number of purchases your customers will make for each product In

00:01:09.070 --> 00:01:09.680
that case,

00:01:09.680 --> 00:01:10.900
the target is in America,

00:01:10.900 --> 00:01:12.630
and you're solving a regression problem,

00:01:12.630 --> 00:01:17.460
or do you want to predict which products will get more than 10 purchases?

00:01:17.460 --> 00:01:18.530
In that case,

00:01:18.530 --> 00:01:19.840
the target is binary,

00:01:19.840 --> 00:01:23.260
and you're simply solving a binary classification problem,

00:01:23.260 --> 00:01:28.770
so it's very important to avoid over complicating the problem and to frame the simplest

00:01:28.770 --> 00:01:30.940
solution that meets your needs.

00:01:30.940 --> 00:01:31.950
However,

00:01:31.950 --> 00:01:34.800
it's also important to avoid losing information,

00:01:34.800 --> 00:01:37.750
especially information in the historical answers.

00:01:37.750 --> 00:01:39.500
For example,

00:01:39.500 --> 00:01:47.120
converting an actual past sales number into a binary value off over 10 versus fewer would

00:01:47.120 --> 00:01:48.930
lose valuable information.

00:01:48.930 --> 00:01:53.560
So you have to make sure you invest the time and deciding which target makes the most sense

00:01:53.560 --> 00:01:57.740
for you to predict will save you from building models that don't really answer your

00:01:57.740 --> 00:01:58.370
question.

00:01:58.370 --> 00:02:00.330
So that's basically formula in.

00:02:00.330 --> 00:02:04.990
The problem is will lay the groundwork for making sure that the model that you're trying to

00:02:04.990 --> 00:02:10.250
build and we're trying to predict will essentially meet your needs and meet your business

00:02:10.250 --> 00:02:10.520
case.

00:02:10.520 --> 00:02:12.030
So if you do that incorrectly,

00:02:12.030 --> 00:02:14.680
the rest of the process kind of falls apart.

00:02:14.680 --> 00:02:18.490
So it's very important that we spend the right amount of time and resource is and making

00:02:18.490 --> 00:02:19.950
sure we get this right.

00:02:19.950 --> 00:02:22.050
So after we have that,

00:02:22.050 --> 00:02:24.810
then we need to do the data.

00:02:24.810 --> 00:02:27.530
So machine learning problems obviously start with data,

00:02:27.530 --> 00:02:30.940
preferably lots of data for which you already know the target.

00:02:30.940 --> 00:02:31.430
Answer.

00:02:31.430 --> 00:02:34.240
So what I mean by that is basically historical data.

00:02:34.240 --> 00:02:39.150
So an example that I had given you would need to get the historical data for all of your

00:02:39.150 --> 00:02:40.350
past sales.

00:02:40.350 --> 00:02:41.210
So,

00:02:41.210 --> 00:02:42.460
data again,

00:02:42.460 --> 00:02:48.800
the data for which you already know the target answer is what's called the labeled data and

00:02:48.800 --> 00:02:50.280
unsupervised machine Learning.

00:02:50.280 --> 00:02:55.000
The algorithm teaches itself toe learn from the label data examples that we provide.

00:02:55.000 --> 00:02:57.100
So each observation,

00:02:57.100 --> 00:03:03.660
each example your data has to have two elements the target and then the features when the

00:03:03.660 --> 00:03:06.500
target is the answer that you want to predict.

00:03:06.500 --> 00:03:07.080
For example,

00:03:07.080 --> 00:03:12.070
the number of sales and the features are attributes of the example that can be used to

00:03:12.070 --> 00:03:14.980
identify patterns to predict the target.

00:03:14.980 --> 00:03:15.530
So,

00:03:15.530 --> 00:03:16.250
for example,

00:03:16.250 --> 00:03:18.070
for the email classification,

00:03:18.070 --> 00:03:23.120
that target is a label that indicates whether an email is spam or not.

00:03:23.120 --> 00:03:27.130
Spam Examples of variables are the center of the email.

00:03:27.130 --> 00:03:29.820
The text in the body of the email detection,

00:03:29.820 --> 00:03:30.920
the subject line,

00:03:30.920 --> 00:03:32.420
the time the email was sent,

00:03:32.420 --> 00:03:33.050
and so on.

00:03:33.050 --> 00:03:38.190
All those variables will help the machine learning mile predict whether that email is spam

00:03:38.190 --> 00:03:38.890
or not.

00:03:38.890 --> 00:03:39.550
Often,

00:03:39.550 --> 00:03:43.070
data is not readily available in a labeled form,

00:03:43.070 --> 00:03:48.620
so collecting and preparing the variables and the target are often the most important steps

00:03:48.620 --> 00:03:50.650
in solving a machine learning problem.

00:03:50.650 --> 00:03:56.070
So the example data should be representative of the data that you that you will have when

00:03:56.070 --> 00:03:57.880
you're using the model to make a prediction.

00:03:57.880 --> 00:03:58.530
So,

00:03:58.530 --> 00:03:59.040
for example,

00:03:59.040 --> 00:04:01.300
if you want to predict whether an email is spam or not,

00:04:01.300 --> 00:04:03.210
you must collect both positive,

00:04:03.210 --> 00:04:03.510
which is,

00:04:03.510 --> 00:04:03.700
you know,

00:04:03.700 --> 00:04:10.330
you should collect both spam emails and non spam emails so the machine learning can learn

00:04:10.330 --> 00:04:12.760
what is spam and what is not spam.

00:04:12.760 --> 00:04:13.470
So,

00:04:13.470 --> 00:04:15.090
and once you've labeled the data,

00:04:15.090 --> 00:04:20.460
you might need to convert it to a format that's acceptable to your longer them or softer.

00:04:20.460 --> 00:04:21.390
For example,

00:04:21.390 --> 00:04:26.130
the Amazon machine learning you need to convert the data to a C S V format,

00:04:26.130 --> 00:04:30.080
with each example making up one row off the CSB file.

00:04:30.080 --> 00:04:32.860
So this is specifically for the Amazon she learning.

00:04:32.860 --> 00:04:34.690
And if you're using another software.

00:04:34.690 --> 00:04:39.430
You have to make sure that that data is formatted according to the requirements of that

00:04:39.430 --> 00:04:41.410
program or are that software.

00:04:41.410 --> 00:04:46.280
So after we have the data and before feeding that label data to the algorithm,

00:04:46.280 --> 00:04:47.360
it's a good practice.

00:04:47.360 --> 00:04:52.010
Inspect your data to identify issues and gain insights about the data you're using,

00:04:52.010 --> 00:04:56.500
and the predictive power off model will only be as good as the data.

00:04:56.500 --> 00:04:57.210
You feed it,

00:04:57.210 --> 00:05:01.530
so you have to make sure you analyze your data and keep a following things in mind.

00:05:01.530 --> 00:05:06.530
It's useful to understand the values that your variable take in which valuables are

00:05:06.530 --> 00:05:11.460
dominant in your data so you could run these summaries by a subject matter expert for the

00:05:11.460 --> 00:05:13.040
problem that you want to solve.

00:05:13.040 --> 00:05:15.690
Ask yourself or whoever the expert is,

00:05:15.690 --> 00:05:17.680
does the data match your expectations?

00:05:17.680 --> 00:05:21.520
Does it look like you have a data collection problem and so on?

00:05:21.520 --> 00:05:28.060
You have to make sure that you run it by an expert to make sure the data makes sense.

00:05:28.060 --> 00:05:34.130
And also the second is knowing the correlation between each variable and the target class

00:05:34.130 --> 00:05:38.650
is helpful because the high correlation implies that there is a relationship between the

00:05:38.650 --> 00:05:40.330
variable and the target class.

00:05:40.330 --> 00:05:41.270
And in general,

00:05:41.270 --> 00:05:46.760
you want to include variables with high correlation because they're the ones with higher

00:05:46.760 --> 00:05:50.410
predictive power and leave out the variable to local relation.

00:05:50.410 --> 00:05:53.050
So now that we have labeled data,

00:05:53.050 --> 00:05:57.390
we've analyzed to make sure that it's proper and that it's correct that we have the right

00:05:57.390 --> 00:05:58.550
correlations.

00:05:58.550 --> 00:06:04.240
That's when you might want to transform your variables further to make them more meaningful

00:06:04.240 --> 00:06:04.240
.

00:06:04.240 --> 00:06:06.920
And this is what's known as feature processing.

00:06:06.920 --> 00:06:07.530
So,

00:06:07.530 --> 00:06:08.370
for example,

00:06:08.370 --> 00:06:13.080
so you have a variable that captures the date and time at which an event occurred.

00:06:13.080 --> 00:06:18.780
This date in time will never occur again and hence won't be useful to predict your target.

00:06:18.780 --> 00:06:20.050
However,

00:06:20.050 --> 00:06:25.600
if this very was transformed into features that represent the hour of the day,

00:06:25.600 --> 00:06:27.080
the day of the week,

00:06:27.080 --> 00:06:32.320
the month now these variables could be useful toe learn if the event tends to happen at a

00:06:32.320 --> 00:06:37.320
particular our particular day of the week or a particular month of the year.

00:06:37.320 --> 00:06:42.000
So such feature processing to form more generalize,

00:06:42.000 --> 00:06:47.220
herbal data points to learn from can provide significant improvements to the predictive

00:06:47.220 --> 00:06:47.900
models.

00:06:47.900 --> 00:06:49.930
Obviously,

00:06:49.930 --> 00:06:56.240
it's not always possible to know the features that have the predictive influence in advance

00:06:56.240 --> 00:06:56.240
.

00:06:56.240 --> 00:07:01.820
So it's good to include as many features as you potentially can and that are potentially

00:07:01.820 --> 00:07:06.960
related to the target label and let them model training a longer than pick the features

00:07:06.960 --> 00:07:08.510
with the strongest correlations.

00:07:08.510 --> 00:07:14.170
So your job and your job should be to include as many features as possible and let the

00:07:14.170 --> 00:07:15.640
machine learning do its work.

00:07:15.640 --> 00:07:17.420
Let it learn from all of that data,

00:07:17.420 --> 00:07:18.320
because if you remember,

00:07:18.320 --> 00:07:19.050
as I mentioned,

00:07:19.050 --> 00:07:24.660
you want to make sure you have as much data as possible and feed as much data as possible

00:07:24.660 --> 00:07:26.040
into the machine learning model.

00:07:26.040 --> 00:07:32.830
But that does not mean that feeding data that's unstructured or data that's not analysed or

00:07:32.830 --> 00:07:34.080
data that's not relevant.

00:07:34.080 --> 00:07:36.020
We have to make sure that all that is done,

00:07:36.020 --> 00:07:37.460
but after all of that is done,

00:07:37.460 --> 00:07:38.290
we have to make sure,

00:07:38.290 --> 00:07:43.160
and we want to make sure that we have as much data as possible into the machine learning

00:07:43.160 --> 00:07:49.270
model so it can learn and make correct predictive answers and then finally splitting the

00:07:49.270 --> 00:07:49.810
data.

00:07:49.810 --> 00:07:49.950
Now,

00:07:49.950 --> 00:07:54.970
the fundamental goal off machine learning is to generalize beyond the data instances used

00:07:54.970 --> 00:07:55.860
to train models,

00:07:55.860 --> 00:08:00.050
We want to evaluate the model to estimate the quality of its pattern.

00:08:00.050 --> 00:08:03.580
Generalization for data and model has not been trained up,

00:08:03.580 --> 00:08:04.230
however,

00:08:04.230 --> 00:08:10.170
because future instances have unknown target values and we cannot really check the accuracy

00:08:10.170 --> 00:08:12.250
of our predictions for future instances.

00:08:12.250 --> 00:08:14.270
Since we don't have a crystal ball,

00:08:14.270 --> 00:08:17.490
we need to use some of the data that we already know.

00:08:17.490 --> 00:08:23.270
The answer for as a proxy for future data and evaluating the model with the same data that

00:08:23.270 --> 00:08:28.220
would use for training is not really useful because it rewards models that can remember the

00:08:28.220 --> 00:08:30.930
training data as opposed to generalizing for it.

00:08:30.930 --> 00:08:36.960
So common strategy is to take all available label data and split it into training and

00:08:36.960 --> 00:08:38.390
evaluation subsets,

00:08:38.390 --> 00:08:40.980
usually commonly with a racial off,

00:08:40.980 --> 00:08:45.580
70 to 80% for training and 20 to 30% for evaluation.

00:08:45.580 --> 00:08:51.020
And the machine learning system uses the training data to train models to see patterns and

00:08:51.020 --> 00:08:55.540
uses the evaluation data to evaluate the predictive quality off.

00:08:55.540 --> 00:09:00.150
The trained model on the system evaluates the predictive performance by comparing

00:09:00.150 --> 00:09:05.560
predictions on the evaluation data set with true values or known as ground truth.

00:09:05.560 --> 00:09:11.620
Using a variety of metrics and usually you see the best model on the evaluation subset to

00:09:11.620 --> 00:09:15.760
make predictions on future instances for which you do not know the target.

00:09:15.760 --> 00:09:16.390
Answer.

00:09:16.390 --> 00:09:22.810
Now the Amazon machine learning Splits data sent for training a model through the council

00:09:22.810 --> 00:09:26.360
into 70% for training and 30% for evaluation.

00:09:26.360 --> 00:09:27.950
That's done by default.

00:09:27.950 --> 00:09:35.040
It also allows you to select a random 70% off your source data for training instead of

00:09:35.040 --> 00:09:40.570
using the 1st 70% and using the complement of this random subset for evaluation.

00:09:40.570 --> 00:09:44.760
And you can use the AP eyes that are provided by Amazon.

00:09:44.760 --> 00:09:50.560
She learned to specify custom split ratios and provide training and evaluation data that

00:09:50.560 --> 00:09:52.520
was split outside of machine learning.

00:09:52.520 --> 00:09:55.950
So if you have done it outside and you like to pump in that data,

00:09:55.950 --> 00:10:00.290
you do have that capability with Amazon machine learning if you do not want to use that

00:10:00.290 --> 00:10:01.430
automated system.

00:10:01.430 --> 00:10:07.510
So these are the five main steps that we need to make sure that we follow in order.

00:10:07.510 --> 00:10:14.120
If we want to have a properly working machine learning model that predicts our future sales

00:10:14.120 --> 00:10:14.910
are forecast,

00:10:14.910 --> 00:10:20.020
our future sales or predicts spam emails and the example that I had given properly and

00:10:20.020 --> 00:10:23.740
effectively because if we do not follow these steps to the tea,

00:10:23.740 --> 00:10:26.830
then we can have issues off making wrong predictions.

00:10:26.830 --> 00:10:27.750
And essentially,

00:10:27.750 --> 00:10:30.850
if you are going to be doing this in the production environment,

00:10:30.850 --> 00:10:34.750
that can have pretty dire consequences for you and for your organization.

00:10:34.750 --> 00:10:39.940
So it's the simple steps to follow but one but nonetheless ones that we need to make sure

00:10:39.940 --> 00:10:44.980
that we follow in detail in order to have a probably were properly working machine learning

00:10:44.980 --> 00:10:45.410
model.

