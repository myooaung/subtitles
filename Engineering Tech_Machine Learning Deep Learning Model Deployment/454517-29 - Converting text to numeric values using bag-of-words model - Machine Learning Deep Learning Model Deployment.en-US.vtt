WEBVTT
X-TIMESTAMP-MAP=LOCAL:00:00:00.000,MPEGTS:0

00:00:00.200 --> 00:00:05.100
All machine learning models are designed to work on numerical data.

00:00:05.100 --> 00:00:09.060
So we have seen an example of how to do classification

00:00:09.060 --> 00:00:13.380
for store purchase data which contains Asian salary in numeric format.

00:00:13.380 --> 00:00:17.115
How can we apply the same technique to classify text?

00:00:17.115 --> 00:00:20.670
For example, we could have reviewed data for a restaurant like

00:00:20.670 --> 00:00:24.000
services good or ambiances really nice, hard.

00:00:24.000 --> 00:00:29.190
We categorize them as positive or negative reviews.

00:00:29.190 --> 00:00:34.545
If we're able to build a classification model based on this review data,

00:00:34.545 --> 00:00:38.370
then we can predict whether a new review,

00:00:38.370 --> 00:00:40.260
for example, main course was nice,

00:00:40.260 --> 00:00:42.520
whether it is good or bad.

00:00:42.540 --> 00:00:47.200
The problem that we need to solve is how do we convert this?

00:00:47.200 --> 00:00:49.945
Takes data to numerical format.

00:00:49.945 --> 00:00:53.695
This takes us to natural language processing or NLP.

00:00:53.695 --> 00:00:56.680
It's an area of computer science which deals with

00:00:56.680 --> 00:01:00.565
interaction of computer and human languages.

00:01:00.565 --> 00:01:05.125
Nlp can be used to process text or speech.

00:01:05.125 --> 00:01:10.330
One of the ways to convert picks to numeric format is by

00:01:10.330 --> 00:01:15.175
using bag of words model you represent text is bag-of-words,

00:01:15.175 --> 00:01:18.085
disregarding the grammar and the order in which they occur,

00:01:18.085 --> 00:01:19.945
but keeping the multiplicity,

00:01:19.945 --> 00:01:22.480
you give higher weightage to award if it

00:01:22.480 --> 00:01:26.025
occurs more number of times in a particular sentence.

00:01:26.025 --> 00:01:29.855
Let's understand bag-of-words through a simple example.

00:01:29.855 --> 00:01:31.760
We have three sentences.

00:01:31.760 --> 00:01:35.030
Service, good, nice ambience, good food.

00:01:35.030 --> 00:01:37.625
Now let's see how we can represent them

00:01:37.625 --> 00:01:40.985
in numeric format using the bag-of-words modelling.

00:01:40.985 --> 00:01:45.290
Let's identify all the words appearing in all three sentences.

00:01:45.290 --> 00:01:46.850
These are service, good,

00:01:46.850 --> 00:01:49.085
nice, ambience, and food.

00:01:49.085 --> 00:01:53.465
Now let's see how many times each word occurs in each of the sentences.

00:01:53.465 --> 00:01:54.590
In the first sentence,

00:01:54.590 --> 00:01:56.990
Service occurs once, so let's capture one.

00:01:56.990 --> 00:02:01.355
Nice doesn't occur in the first sentence. So let's capture 0.

00:02:01.355 --> 00:02:05.060
So similarly, you can do that for all the words in all three sentences.

00:02:05.060 --> 00:02:09.450
And then you can create a matrix of numeric values.

00:02:10.720 --> 00:02:15.390
Let's look at a slightly more complex example.

00:02:15.700 --> 00:02:18.335
We have three sentences,

00:02:18.335 --> 00:02:22.860
and these sentences have many word says shown here.

00:02:24.130 --> 00:02:27.290
The first sentences services good today,

00:02:27.290 --> 00:02:29.195
then ambiance is really nice.

00:02:29.195 --> 00:02:32.915
Then the third one is today for his coat and salad is nice.

00:02:32.915 --> 00:02:38.900
We'll create a histogram of words and capture how many times each word is occurring.

00:02:38.900 --> 00:02:42.350
When you convert a sentence to numeric format,

00:02:42.350 --> 00:02:45.530
you do not necessarily take all the words.

00:02:45.530 --> 00:02:50.160
You will have to find the top words and then create a matrix out of that.

00:02:50.530 --> 00:02:54.815
There are various libraries available for you to pick

00:02:54.815 --> 00:03:01.340
Top 1000 or 10 thousand English words for your text and create a numeric vector.

00:03:01.340 --> 00:03:05.600
For now, let's try to understand how the model is created by taking

00:03:05.600 --> 00:03:10.175
these simple examples and then picking top four or five watts.

00:03:10.175 --> 00:03:12.920
When you start working on actual NLP project,

00:03:12.920 --> 00:03:19.830
you'll have libraries to help you extract the words and create numeric vectors.

00:03:20.470 --> 00:03:22.745
So in this particular case,

00:03:22.745 --> 00:03:25.340
we have arranged word by word count.

00:03:25.340 --> 00:03:28.490
And let's pick these five watts is good,

00:03:28.490 --> 00:03:29.840
nice today in service,

00:03:29.840 --> 00:03:31.520
which occur most number of times.

00:03:31.520 --> 00:03:35.780
And let's pick this top five watts which occur more number of times,

00:03:35.780 --> 00:03:40.980
and then build a numeric vector for our three sentences.

00:03:41.380 --> 00:03:43.490
So as you can see here,

00:03:43.490 --> 00:03:46.190
what iz occurs twice for the third sentence.

00:03:46.190 --> 00:03:48.680
So that's where the value is two here.

00:03:48.680 --> 00:03:50.360
For rest of the sentences,

00:03:50.360 --> 00:03:51.530
it is occurring one.

00:03:51.530 --> 00:03:52.850
So we have captured one-year,

00:03:52.850 --> 00:03:55.235
similarly count of number of times

00:03:55.235 --> 00:03:58.655
each word is occurring in each sentence is captured here.

00:03:58.655 --> 00:04:04.910
The limitation of bag-of-words model sees each what is given the same importance.

00:04:04.910 --> 00:04:08.270
If you have to do some analysis using text, for example,

00:04:08.270 --> 00:04:11.135
if you have to calculate the sentiment of the text,

00:04:11.135 --> 00:04:13.745
not all words might at the same importance.

00:04:13.745 --> 00:04:17.360
For example, words like nice will have higher importance

00:04:17.360 --> 00:04:21.380
than today when it comes to positive sentiment analysis.

00:04:21.380 --> 00:04:23.870
Let's now look at another technique using which

00:04:23.870 --> 00:04:27.120
we can give higher importance to certain words.
