1
00:00:00,956 --> 00:00:05,167
Last, but not least, let's simulate a resource race condition.

2
00:00:05,167 --> 00:00:06,365
As a reminder,

3
00:00:06,365 --> 00:00:09,525
resource race conditions are a hazard introduced by the

4
00:00:09,525 --> 00:00:12,138
asynchronous nature of microservice environments,

5
00:00:12,138 --> 00:00:15,163
and are typically caused by developer error.

6
00:00:15,163 --> 00:00:15,793
Even so,

7
00:00:15,793 --> 00:00:20,874
SaaS Bass wants to guard against resource race conditions as much as possible.

8
00:00:20,874 --> 00:00:26,131
We'll discuss how retry can alleviate this pain point for SaaS Bass.

9
00:00:26,131 --> 00:00:27,483
To follow along with this demo,

10
00:00:27,483 --> 00:00:29,523
for the Bass Tracker Service check out the

11
00:00:29,523 --> 00:00:34,229
getting-started-with-spring-retry-resource- race-condition branch.

12
00:00:34,229 --> 00:00:35,354
For the Lake Profile Service,

13
00:00:35,354 --> 00:00:37,903
also check out the getting-started-with-spring-retry-

14
00:00:37,903 --> 00:00:40,296
resource-race-condition branch.

15
00:00:40,296 --> 00:00:42,533
Starting with the lake-profile-service,

16
00:00:42,533 --> 00:00:45,752
you can see that we haven't made any changes from the

17
00:00:45,752 --> 00:00:48,776
module branch for this simulation.

18
00:00:48,776 --> 00:00:50,583
Switching over to the bass-tracker-service,

19
00:00:50,583 --> 00:00:52,122
we've made one simple change,

20
00:00:52,122 --> 00:00:55,413
and that is to bypass the sleep between creating and

21
00:00:55,413 --> 00:00:57,664
getting the LakeProfile resource.

22
00:00:57,664 --> 00:01:01,720
This simulates a truly asynchronous situation in which the resource is

23
00:01:01,720 --> 00:01:05,803
being both created and requested at the same time.

24
00:01:05,803 --> 00:01:09,314
Let's run the service and see what happens.

25
00:01:09,314 --> 00:01:13,053
We get a 404 not found error because we've now essentially run both

26
00:01:13,053 --> 00:01:16,353
the create and getLakeProfile calls in parallel.

27
00:01:16,353 --> 00:01:18,663
So the LakeProfile resource can't be created fast

28
00:01:18,663 --> 00:01:20,852
enough before we attempt to get it.

29
00:01:20,852 --> 00:01:24,200
This is because, switching back to the lake-profile-service,

30
00:01:24,200 --> 00:01:29,384
we have a simulated database latency of 2 seconds.

31
00:01:29,384 --> 00:01:32,316
If we would have retried the getLakeProfile call for

32
00:01:32,316 --> 00:01:34,199
slightly longer than 2 seconds,

33
00:01:34,199 --> 00:01:38,163
the resource would be available and we wouldn't get a 404 error.

34
00:01:38,163 --> 00:01:48,000
This scenario can be prevented by being more careful with parallelization, but adding retry adds an invaluable safeguard in the event of developer error.

