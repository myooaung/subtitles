1
00:00:01,040 --> 00:00:04,690
Now I mentioned earlier that SageMaker is the primary service that we'll

2
00:00:04,690 --> 00:00:08,510
leverage for operationalizing our machine learning on AWS.

3
00:00:08,510 --> 00:00:10,540
But it wasn't the only way.

4
00:00:10,540 --> 00:00:13,060
And here we're going to cover the different options that you

5
00:00:13,060 --> 00:00:16,340
have if you choose not to use SageMaker.

6
00:00:16,340 --> 00:00:18,640
So here we'll look at the different compute services that

7
00:00:18,640 --> 00:00:21,140
we can leverage for machine learning.

8
00:00:21,140 --> 00:00:24,440
And first of all, we have Amazon EC2.

9
00:00:24,440 --> 00:00:29,780
So we can do both our machine learning training and inference directly on EC2.

10
00:00:29,780 --> 00:00:33,800
Now if you want to do this, I would recommend using the deep learning AMI,

11
00:00:33,800 --> 00:00:37,850
which provides a base AMI with the needed configuration.

12
00:00:37,850 --> 00:00:41,340
Now with this, there are two different options that you can choose from.

13
00:00:41,340 --> 00:00:44,670
One is the Conda AMI that comes preinstalled with

14
00:00:44,670 --> 00:00:47,140
Conda and many popular frameworks.

15
00:00:47,140 --> 00:00:49,460
But you also have the Base AMI,

16
00:00:49,460 --> 00:00:53,070
which comes with the needed configuration for working with either advanced

17
00:00:53,070 --> 00:00:57,860
CPU instances or GPU instances, and you can install whatever frameworks you

18
00:00:57,860 --> 00:01:01,950
want directly on the Base AMI. If you're interested in the deep learning

19
00:01:01,950 --> 00:01:05,560
AMI, I have another course on Pluralsight that'll walk you through how to

20
00:01:05,560 --> 00:01:10,130
integrate with it. Now next, we have the Container Services,

21
00:01:10,130 --> 00:01:14,040
and this includes things like Fargate and ECS and EKS.

22
00:01:14,040 --> 00:01:16,790
And training or inference can also be leveraged on

23
00:01:16,790 --> 00:01:19,240
any of these container services.

24
00:01:19,240 --> 00:01:22,780
And AWS provides deep learning containers that are

25
00:01:22,780 --> 00:01:27,360
pre‑configured for specific frameworks, including TensorFlow,

26
00:01:27,360 --> 00:01:30,040
PyTorch, and MXNet.

27
00:01:30,040 --> 00:01:34,440
And you can get the AWS deep learning containers from the ECR.

28
00:01:34,440 --> 00:01:37,800
Now the next service is one that we've already talked about within this module,

29
00:01:37,800 --> 00:01:40,040
and that's Amazon EMR.

30
00:01:40,040 --> 00:01:44,660
So out of the box, Amazon EMR can provide support for Jupyter Notebooks,

31
00:01:44,660 --> 00:01:48,260
and it also includes support for multiple machine learning frameworks.

32
00:01:48,260 --> 00:01:52,040
And some of these frameworks include TensorFlow and MXNet.

33
00:01:52,040 --> 00:01:55,260
So if you're already leveraging Amazon EMR and you simply

34
00:01:55,260 --> 00:01:58,800
want to have a way to extend that to training and

35
00:01:58,800 --> 00:02:02,940
providing inference on your models, you can continue to use it for that purpose.

36
00:02:02,940 --> 00:02:06,070
Now another option that you have is you can also use an

37
00:02:06,070 --> 00:02:09,830
on‑premise server. So if you have the capability within your own

38
00:02:09,830 --> 00:02:12,110
data centers to do training and inference,

39
00:02:12,110 --> 00:02:16,770
you can utilize the pre‑built SageMaker Docker images even within your

40
00:02:16,770 --> 00:02:20,730
own data center. And you can integrate into SageMaker for either

41
00:02:20,730 --> 00:02:24,410
training or inference, and here's what I mean by that You could if you

42
00:02:24,410 --> 00:02:26,230
wanted to on your own infrastructure,

43
00:02:26,230 --> 00:02:29,490
train a model and then upload for use in SageMaker.

44
00:02:29,490 --> 00:02:36,000
Or if you had a need, you could pull the model from SageMaker for inference on your own hardware.

