WEBVTT
1
00:00:01.140 --> 00:00:05.170
So next, we're going to be discussing the AWS AI services.

2
00:00:05.170 --> 00:00:09.440
Now these services are a suite of services that enable developers to quickly

3
00:00:09.440 --> 00:00:12.420
integrate deep learning into their custom applications.

4
00:00:12.420 --> 00:00:13.100
However,

5
00:00:13.100 --> 00:00:15.950
they're doing so by leveraging pre‑trained models that

6
00:00:15.950 --> 00:00:18.940
are targeted at specific use cases.

7
00:00:18.940 --> 00:00:20.320
And if you haven't used these before,

8
00:00:20.320 --> 00:00:22.740
I would encourage you to interact with each of them.

9
00:00:22.740 --> 00:00:26.110
And they generally have a rich experience in the console that

10
00:00:26.110 --> 00:00:28.650
makes it easy for you to test them out.

11
00:00:28.650 --> 00:00:33.240
Now we're going to be discussing three different categories of these services.

12
00:00:33.240 --> 00:00:36.880
First, we'll be focusing on the services that provide language analysis.

13
00:00:36.880 --> 00:00:40.720
Then, we'll be looking at the services that support general dataset analysis.

14
00:00:40.720 --> 00:00:44.740
And finally, we'll be looking at the service that supports computer vision.

15
00:00:44.740 --> 00:00:47.170
So here, let's start off by looking at language analysis.

16
00:00:47.170 --> 00:00:50.250
We're going to be examining Amazon Comprehend,

17
00:00:50.250 --> 00:00:54.440
Amazon Lex, Amazon Polly, Amazon Textract,

18
00:00:54.440 --> 00:00:58.340
Amazon Translate, and Amazon Transcribe.

19
00:00:58.340 --> 00:01:01.230
So first, here we have Amazon Comprehend.

20
00:01:01.230 --> 00:01:05.320
Now this service is a natural language processing service that pulls

21
00:01:05.320 --> 00:01:08.100
insights out of the text that you pass into it.

22
00:01:08.100 --> 00:01:10.500
So this can be utilized for things like,

23
00:01:10.500 --> 00:01:14.210
for example, doing sentiment analysis on unstructured text.

24
00:01:14.210 --> 00:01:17.020
So let's say you want to pull all of the different ways that users

25
00:01:17.020 --> 00:01:19.640
have interacted with your company over social media,

26
00:01:19.640 --> 00:01:22.400
and you want to highlight those that have a negative sentiment.

27
00:01:22.400 --> 00:01:25.440
That's something you could do utilizing the service.

28
00:01:25.440 --> 00:01:29.740
It also gives you the ability to categorize documents by topics.

29
00:01:29.740 --> 00:01:34.000
You also can use a subservice called Amazon Comprehend Medical,

30
00:01:34.000 --> 00:01:37.830
specifically for medical use cases that has been pre‑trained to focus on

31
00:01:37.830 --> 00:01:42.040
things like diagnoses and potential dosages of prescriptions.

32
00:01:42.040 --> 00:01:44.410
Next, we have Amazon Lex.

33
00:01:44.410 --> 00:01:50.140
And Amazon Lex is all about conversational experiences with both voice and text.

34
00:01:50.140 --> 00:01:54.620
So the key thing that Amazon Lex does is that it extracts intent

35
00:01:54.620 --> 00:01:58.140
from either the text you pass in or voice audio.

36
00:01:58.140 --> 00:02:00.900
So this could be useful if you were wanting to do things like

37
00:02:00.900 --> 00:02:03.060
deploying a chatbot for customer service.

38
00:02:03.060 --> 00:02:07.190
So if you had a messaging experience within your app or maybe just over text

39
00:02:07.190 --> 00:02:10.480
messaging and you wanted users to be able to ask a question,

40
00:02:10.480 --> 00:02:14.050
and then you could discern what the intent is from that question.

41
00:02:14.050 --> 00:02:16.300
But this doesn't have to just be text.

42
00:02:16.300 --> 00:02:17.640
This also can be audio,

43
00:02:17.640 --> 00:02:20.430
so you could integrate this with your call center solution.

44
00:02:20.430 --> 00:02:24.450
So users could ask a specific question, you could discern the intent,

45
00:02:24.450 --> 00:02:26.440
and then act upon that.

46
00:02:26.440 --> 00:02:28.850
Now there's another service though that would be needed to

47
00:02:28.850 --> 00:02:33.580
make that call center solution work, and that other service is Amazon Polly.

48
00:02:33.580 --> 00:02:37.410
And what Amazon Polly does is that it creates lifelike audio of

49
00:02:37.410 --> 00:02:40.500
speech from input text that you pass into it.

50
00:02:40.500 --> 00:02:43.960
And it supports multiple languages and multiple voices

51
00:02:43.960 --> 00:02:46.040
in most of the supported languages.

52
00:02:46.040 --> 00:02:48.480
So these use cases include, for example,

53
00:02:48.480 --> 00:02:51.920
providing automated audio on a call for dynamic information,

54
00:02:51.920 --> 00:02:56.090
and this is really the flipside of what we talked about with Amazon Lex.

55
00:02:56.090 --> 00:02:58.200
You can go get data, maybe from a database,

56
00:02:58.200 --> 00:03:00.520
and then read bits of that back to the user.

57
00:03:00.520 --> 00:03:04.740
But you also could use this to enable accessibility of your content.

58
00:03:04.740 --> 00:03:07.070
So maybe you have some type of digital content,

59
00:03:07.070 --> 00:03:10.740
and you want to be able to read that to users that have differing abilities,

60
00:03:10.740 --> 00:03:13.240
and maybe they can't read that directly on the screen.

61
00:03:13.240 --> 00:03:15.140
That's something you could do with Polly.

62
00:03:15.140 --> 00:03:18.200
This also gives you the ability to include lifelike audio

63
00:03:18.200 --> 00:03:21.380
within embedded devices if you wanted to create a voice

64
00:03:21.380 --> 00:03:23.840
experience with your embedded device.

65
00:03:23.840 --> 00:03:26.680
Now next, we have Amazon Textract,

66
00:03:26.680 --> 00:03:30.390
and this extracts insights and data from scanned documents.

67
00:03:30.390 --> 00:03:33.750
So if you're in a vertical that heavily relies on printed

68
00:03:33.750 --> 00:03:37.740
documents that need to be scanned in, this can be a very valuable service.

69
00:03:37.740 --> 00:03:40.520
And you could use this for things like automating the

70
00:03:40.520 --> 00:03:44.270
importing of documents into an application or developing a

71
00:03:44.270 --> 00:03:47.540
classification workflow for documents.

72
00:03:47.540 --> 00:03:51.740
Now in addition to Textract, we also have Amazon Translate.

73
00:03:51.740 --> 00:03:55.040
And this utilizes a neural machine translation engine

74
00:03:55.040 --> 00:03:57.840
or NMT to translate input text.

75
00:03:57.840 --> 00:04:01.940
Now currently, this supports 55 different languages,

76
00:04:01.940 --> 00:04:05.200
and so use cases for this could include automating the

77
00:04:05.200 --> 00:04:08.280
localization process for a digital experience.

78
00:04:08.280 --> 00:04:12.140
Let's say that your organization just launched a new microsite in English,

79
00:04:12.140 --> 00:04:15.910
but you want to have a quick way to be able to translate all of the different

80
00:04:15.910 --> 00:04:19.490
strings used within that microsite over to another language.

81
00:04:19.490 --> 00:04:22.740
You could automate that process with Amazon Translate.

82
00:04:22.740 --> 00:04:23.240
In addition,

83
00:04:23.240 --> 00:04:26.780
you might want to enable cross‑language search of your digital content.

84
00:04:26.780 --> 00:04:28.530
That's something else you could do with this

85
00:04:28.530 --> 00:04:33.560
service. Now in addition to Translate, we also have Amazon Transcribe.

86
00:04:33.560 --> 00:04:38.800
And what this does is that it enables speech‑to‑text from an audio file.

87
00:04:38.800 --> 00:04:42.670
So where we get text to speech with Polly, here with Transcribe,

88
00:04:42.670 --> 00:04:44.390
we get speech to text.

89
00:04:44.390 --> 00:04:48.340
Now this supports both batch and real‑time processing of audio.

90
00:04:48.340 --> 00:04:49.220
So for example,

91
00:04:49.220 --> 00:04:51.270
if you want to go through and actually transcribe

92
00:04:51.270 --> 00:04:53.140
something that was previously recorded,

93
00:04:53.140 --> 00:04:55.730
you could utilize that batch approach. And you might

94
00:04:55.730 --> 00:04:57.470
want to transcribe a live event,

95
00:04:57.470 --> 00:05:00.340
in which case you could utilize the real‑time approach.

96
00:05:00.340 --> 00:05:04.120
So use cases for this could be automating the generation of captions for

97
00:05:04.120 --> 00:05:07.020
your video content. And just like with Comprehend,

98
00:05:07.020 --> 00:05:10.700
this includes a subservice that supports medical use cases,

99
00:05:10.700 --> 00:05:13.540
and that's Amazon Transcribe Medical.

100
00:05:13.540 --> 00:05:13.950
Now next,

101
00:05:13.950 --> 00:05:17.360
let's talk about some general dataset analysis that we can

102
00:05:17.360 --> 00:05:20.630
do with some custom AI services on AWS.

103
00:05:20.630 --> 00:05:23.250
The first is going to be Amazon Forecast.

104
00:05:23.250 --> 00:05:28.840
Then, we have Amazon Fraud Detector. And finally, we have Amazon Personalize.

105
00:05:28.840 --> 00:05:31.200
So let's start with Amazon Forecast.

106
00:05:31.200 --> 00:05:36.680
This provides forecasting on historical time‑series data. So use cases

107
00:05:36.680 --> 00:05:40.420
for this could include maybe you want to predict your supply chain needs

108
00:05:40.420 --> 00:05:43.610
based on projected manufacturing demand.

109
00:05:43.610 --> 00:05:48.570
So if you have information on supply chain orders and then have historical data

110
00:05:48.570 --> 00:05:52.790
on your demand, you could go ahead and project in the future how much you would

111
00:05:52.790 --> 00:05:55.440
need to order of all of your different components.

112
00:05:55.440 --> 00:05:58.080
Now we also could use this to predict our sales data

113
00:05:58.080 --> 00:06:00.850
based on multiple historical data sets.

114
00:06:00.850 --> 00:06:03.920
So Amazon Forecast allows us to work both with the

115
00:06:03.920 --> 00:06:05.410
data set that we want to forecast,

116
00:06:05.410 --> 00:06:09.500
but also what it calls metadata sets that correlate, and it can use that

117
00:06:09.500 --> 00:06:12.840
correlation to help improve the overall prediction.

118
00:06:12.840 --> 00:06:15.390
Next, we have Amazon Fraud Detector,

119
00:06:15.390 --> 00:06:17.790
and this utilizes a customizable machine learning

120
00:06:17.790 --> 00:06:20.910
model to detect fraudulent activities.

121
00:06:20.910 --> 00:06:23.620
Now the use cases for this could be some things you might expect,

122
00:06:23.620 --> 00:06:26.290
like identifying fraudulent payment transactions.

123
00:06:26.290 --> 00:06:29.170
But it also can be used for things like identifying

124
00:06:29.170 --> 00:06:31.340
a fraudulent account creation.

125
00:06:31.340 --> 00:06:34.150
Or it can even be used if you're identifying fraudulent

126
00:06:34.150 --> 00:06:36.490
actions that are taken on a legitimate account,

127
00:06:36.490 --> 00:06:39.240
such as when a user gets their password stolen.

128
00:06:39.240 --> 00:06:41.860
Now next, we have Amazon Personalize,

129
00:06:41.860 --> 00:06:46.200
and this creates a personalization engine for users based on user

130
00:06:46.200 --> 00:06:50.360
behavior data. And this actually is a lot of the same logic that

131
00:06:50.360 --> 00:06:54.530
powers the engine that is used on amazon.com. And use cases for

132
00:06:54.530 --> 00:06:58.450
this could include potentially providing personalized content or

133
00:06:58.450 --> 00:07:00.000
product recommendations.

134
00:07:00.000 --> 00:07:01.800
So let's say you have a content site,

135
00:07:01.800 --> 00:07:04.630
and you know that users have looked at these 17 different

136
00:07:04.630 --> 00:07:07.710
articles. You could from that provide a personalized

137
00:07:07.710 --> 00:07:10.540
recommendation for what they should look at next.

138
00:07:10.540 --> 00:07:13.990
We also can use this for enabling personalized promotions.

139
00:07:13.990 --> 00:07:17.570
So if you want to be able to process their behavior and then give them custom

140
00:07:17.570 --> 00:07:20.140
promotions that maybe you're going to send out via email,

141
00:07:20.140 --> 00:07:22.140
you could do that with this service.

142
00:07:22.140 --> 00:07:22.550
Now next,

143
00:07:22.550 --> 00:07:25.920
let's talk about computer vision, and computer vision really is

144
00:07:25.920 --> 00:07:29.180
targeted at utilizing what we use our eyes for,

145
00:07:29.180 --> 00:07:31.540
but doing it programmatically. And the service that

146
00:07:31.540 --> 00:07:35.540
supports this on AWS is Amazon Recognition.

147
00:07:35.540 --> 00:07:41.140
So Amazon Recognition provides automated analysis of image and video data.

148
00:07:41.140 --> 00:07:43.330
And when we're talking here about video data,

149
00:07:43.330 --> 00:07:47.040
we can do this both in batch or in real time.

150
00:07:47.040 --> 00:07:49.810
And with this, we can do text extraction,

151
00:07:49.810 --> 00:07:51.540
object recognition,

152
00:07:51.540 --> 00:07:54.340
facial detection, and then even within that emotion detection

153
00:07:54.340 --> 00:07:58.260
within faces. So some of the use cases here could be enabling

154
00:07:58.260 --> 00:08:01.570
searching across a library of digital content.

155
00:08:01.570 --> 00:08:04.660
Maybe you want to search over a bunch of images and be able to

156
00:08:04.660 --> 00:08:07.520
find all the images that contain a guitar,

157
00:08:07.520 --> 00:08:09.800
for example, or a dog or a cat.

158
00:08:09.800 --> 00:08:13.570
Those are the kind of things you can do with Recognition. Now it also

159
00:08:13.570 --> 00:08:17.440
could be used to implement a facial authentication system because what you

160
00:08:17.440 --> 00:08:21.770
can do inside of Recognition is you can actually store faces and then see

161
00:08:21.770 --> 00:08:24.200
if they're detected in future images.

162
00:08:24.200 --> 00:08:33.000
You also could use this to automate the moderation of images as it has explicit content detection built into it.

