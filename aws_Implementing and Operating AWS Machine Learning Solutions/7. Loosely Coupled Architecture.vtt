WEBVTT
1
00:00:01.040 --> 00:00:01.730
So next,

2
00:00:01.730 --> 00:00:06.420
we're going to talk about another concept that factors in to high availability,

3
00:00:06.420 --> 00:00:09.840
and that is the concept of loose coupling.

4
00:00:09.840 --> 00:00:11.810
So by building a modular architecture,

5
00:00:11.810 --> 00:00:15.060
components can do integrate with other components without having to know about

6
00:00:15.060 --> 00:00:18.260
specific definitions or configurations of those components.

7
00:00:18.260 --> 00:00:22.810
So we can enable loose coupling by leveraging services that incorporate things

8
00:00:22.810 --> 00:00:26.540
like load balancers and queues and managed workflow engines.

9
00:00:26.540 --> 00:00:30.140
So let's take a look at how we enable loose coupling

10
00:00:30.140 --> 00:00:32.550
within our machine learning solutions.

11
00:00:32.550 --> 00:00:36.440
So first of all, we can look at leveraging AWS Step Functions,

12
00:00:36.440 --> 00:00:40.210
and this is a workflow service for AWS that enables

13
00:00:40.210 --> 00:00:44.670
us to work with lambda functions, as well as several direct service integrations,

14
00:00:44.670 --> 00:00:46.560
to build workflows.

15
00:00:46.560 --> 00:00:49.570
In addition, we have Amazon Simple Queue Service,

16
00:00:49.570 --> 00:00:51.040
or SQS,

17
00:00:51.040 --> 00:00:55.020
and this is a message queue that enables us to have durable data stored within

18
00:00:55.020 --> 00:00:58.660
queues that we can then use to trigger other executions.

19
00:00:58.660 --> 00:01:01.260
We also have Amazon Simple Notification Service,

20
00:01:01.260 --> 00:01:02.260
or SNS,

21
00:01:02.260 --> 00:01:05.510
and this can handle both notifications out of the

22
00:01:05.510 --> 00:01:08.440
platform by things like email or SMS.

23
00:01:08.440 --> 00:01:12.740
But it also can enable fan‑out implementations within our architectures.

24
00:01:12.740 --> 00:01:15.620
In addition, we have Amazon EventBridge,

25
00:01:15.620 --> 00:01:19.100
and this enables us to integrate event‑based workflows,

26
00:01:19.100 --> 00:01:22.000
for example if we want to be able to trigger something

27
00:01:22.000 --> 00:01:25.340
based on uploading a file into S3.

28
00:01:25.340 --> 00:01:31.340
So let's look at a sample architecture utilizing this concept of loose coupling.

29
00:01:31.340 --> 00:01:34.030
So let's say, first of all, we have a secure facility.

30
00:01:34.030 --> 00:01:36.710
And as a part of this multi‑building facility,

31
00:01:36.710 --> 00:01:39.550
we have some IoT cameras that are set up.

32
00:01:39.550 --> 00:01:41.880
And one of the things that we want to check is we want to be sure

33
00:01:41.880 --> 00:01:44.570
that vehicles that are going to different areas of our secure

34
00:01:44.570 --> 00:01:47.140
facility have permission to be there.

35
00:01:47.140 --> 00:01:50.190
So our IoT cameras are detecting vehicles,

36
00:01:50.190 --> 00:01:52.130
and they're going to take a picture of the vehicle.

37
00:01:52.130 --> 00:01:55.670
And what we want to be able to do is to check the license plate

38
00:01:55.670 --> 00:01:58.970
number and make sure that those cars are designated for the area

39
00:01:58.970 --> 00:02:00.540
that they're supposed to be in.

40
00:02:00.540 --> 00:02:05.460
So with this, once those cameras actually detect that a vehicle is present,

41
00:02:05.460 --> 00:02:08.300
they'll take that image and then take that to S3.

42
00:02:08.300 --> 00:02:11.650
So that IoT camera will upload it into S3.

43
00:02:11.650 --> 00:02:14.830
We then want that to end up within a processing queue.

44
00:02:14.830 --> 00:02:17.640
So we're going to use Amazon EventBridge to put

45
00:02:17.640 --> 00:02:20.840
these new items within an SQS queue.

46
00:02:20.840 --> 00:02:25.040
And this will actually be what we call a FIFO queue, first in, first out.

47
00:02:25.040 --> 00:02:28.130
Now one of the benefits of using a FIFO queue is that we can

48
00:02:28.130 --> 00:02:32.870
make sure that we execute a lambda function exactly once for

49
00:02:32.870 --> 00:02:34.760
every item that gets put into it.

50
00:02:34.760 --> 00:02:37.970
So EventBridge dropping the item into the queue will actually

51
00:02:37.970 --> 00:02:41.640
trigger an execution of our lambda function.

52
00:02:41.640 --> 00:02:44.390
And then what we really want to do is we want to isolate all of the

53
00:02:44.390 --> 00:02:47.620
logic around detecting those license plates and checking if they're

54
00:02:47.620 --> 00:02:51.140
authorized within what we call a step function.

55
00:02:51.140 --> 00:02:55.640
And so the lambda function itself will actually invoke the step function.

56
00:02:55.640 --> 00:02:58.860
Now let's take a little bit of time to understand more about

57
00:02:58.860 --> 00:03:01.440
this step function and what it will include.

58
00:03:01.440 --> 00:03:04.090
So now we have our processing step function,

59
00:03:04.090 --> 00:03:07.000
and the input to the step function is going to be the

60
00:03:07.000 --> 00:03:09.640
image that was uploaded into S3.

61
00:03:09.640 --> 00:03:12.380
And let's say the first step in our overall processing

62
00:03:12.380 --> 00:03:15.180
path is to preprocess the image.

63
00:03:15.180 --> 00:03:17.570
So we have a lambda function that will do that.

64
00:03:17.570 --> 00:03:20.780
Now the step function will know when that process is complete,

65
00:03:20.780 --> 00:03:23.690
and it will then trigger the next lambda function.

66
00:03:23.690 --> 00:03:28.840
And this next lambda function will actually invoke our SageMaker endpoint.

67
00:03:28.840 --> 00:03:32.700
So let's say that we have already configured a SageMaker endpoint

68
00:03:32.700 --> 00:03:35.910
following all the best practices that we've covered so far.

69
00:03:35.910 --> 00:03:38.810
So first, it will reach out to our SageMaker endpoint.

70
00:03:38.810 --> 00:03:41.840
Within the endpoint, we will try to use inference,

71
00:03:41.840 --> 00:03:45.150
and we'll try to use the image data to pull back a license plate

72
00:03:45.150 --> 00:03:47.540
number off of the image that was uploaded.

73
00:03:47.540 --> 00:03:49.000
We'll then get the results back.

74
00:03:49.000 --> 00:03:50.240
And then from here,

75
00:03:50.240 --> 00:03:52.730
we'll be able to go through the process of actually

76
00:03:52.730 --> 00:03:55.240
looking up that license plate.

77
00:03:55.240 --> 00:03:56.390
Now from here,

78
00:03:56.390 --> 00:04:00.400
we can go and look in a DynamoDB table to see if we actually

79
00:04:00.400 --> 00:04:02.970
have that registered for that particular area,

80
00:04:02.970 --> 00:04:05.880
and then we'll get the data back from the DynamoDB table.

81
00:04:05.880 --> 00:04:08.610
Now here's where we can have a choice that gets injected.

82
00:04:08.610 --> 00:04:12.210
If the user is already in the database and they're authorized for that area,

83
00:04:12.210 --> 00:04:13.010
that's perfect.

84
00:04:13.010 --> 00:04:15.040
We can then just log the results.

85
00:04:15.040 --> 00:04:17.440
However, if they're not in the database,

86
00:04:17.440 --> 00:04:20.580
we can utilize SNS to send a notification,

87
00:04:20.580 --> 00:04:23.950
and maybe that notification would send an SMS or an email.

88
00:04:23.950 --> 00:04:26.400
But we also can do what we call fan out here.

89
00:04:26.400 --> 00:04:29.020
So we could potentially do multiple things.

90
00:04:29.020 --> 00:04:32.740
We could have another lambda function that executes based on this.

91
00:04:32.740 --> 00:04:37.440
And then once that notification is sent, we can log the results here as well.

92
00:04:37.440 --> 00:04:39.450
Now let's take a step back from this example,

93
00:04:39.450 --> 00:04:42.180
and let's talk about how we have enabled high

94
00:04:42.180 --> 00:04:44.430
availability with this architecture.

95
00:04:44.430 --> 00:04:47.320
First of all, by using queues,

96
00:04:47.320 --> 00:04:51.760
any failure in launching the step function will be retried.

97
00:04:51.760 --> 00:04:55.480
So the way that the queues work, if we successfully process it,

98
00:04:55.480 --> 00:04:57.090
it's removed from the queue.

99
00:04:57.090 --> 00:04:58.740
But if it's not, it stays there.

100
00:04:58.740 --> 00:05:01.060
Let's say we deploy a bad change,

101
00:05:01.060 --> 00:05:03.730
and it causes our step function not to work properly

102
00:05:03.730 --> 00:05:05.540
or not to be able to be invoked.

103
00:05:05.540 --> 00:05:06.350
In those cases,

104
00:05:06.350 --> 00:05:09.700
we still don't lose any data. And it immediately will pick

105
00:05:09.700 --> 00:05:12.940
up processing once we deploy the fix.

106
00:05:12.940 --> 00:05:13.480
Next,

107
00:05:13.480 --> 00:05:17.470
we're leveraging an event‑driven workflow here by utilizing

108
00:05:17.470 --> 00:05:21.230
EventBridge. So Event Bridge knows how to listen for events on

109
00:05:21.230 --> 00:05:25.550
the AWS platform and also for some configured third‑party events

110
00:05:25.550 --> 00:05:27.040
as well. But in this case,

111
00:05:27.040 --> 00:05:29.160
we're using it to listen for items that are

112
00:05:29.160 --> 00:05:32.240
uploaded within a specific S3 bucket.

113
00:05:32.240 --> 00:05:38.280
Now next, step functions enable customizable retries if a specific step fails.

114
00:05:38.280 --> 00:05:41.960
So we have complete control within the step function's state machine

115
00:05:41.960 --> 00:05:44.590
to be able to say if this particular step fails,

116
00:05:44.590 --> 00:05:48.240
do something else or retry after a period of time.

117
00:05:48.240 --> 00:05:48.830
Now in this case,

118
00:05:48.830 --> 00:05:58.000
we're already enabling high availability because we're following the best practices that we've covered so far for using SageMaker endpoints.

