WEBVTT
1
00:00:01.040 --> 00:00:03.720
So now we're going to be putting into practice all the

2
00:00:03.720 --> 00:00:05.970
things that we've covered within this module,

3
00:00:05.970 --> 00:00:08.400
and we'll actually be deploying a trained model

4
00:00:08.400 --> 00:00:11.090
using SageMaker Hosting Services.

5
00:00:11.090 --> 00:00:12.860
So here, over the course of this demo,

6
00:00:12.860 --> 00:00:16.580
we're first going to be training a model using a SageMaker algorithm.

7
00:00:16.580 --> 00:00:19.440
But please note, this is not the focus of this module.

8
00:00:19.440 --> 00:00:22.840
So we'll be pushing through this portion of the demo pretty quickly.

9
00:00:22.840 --> 00:00:25.750
Next, we'll be saving the trained model into SageMaker.

10
00:00:25.750 --> 00:00:29.870
And then from that, we'll be creating an endpoint configuration.

11
00:00:29.870 --> 00:00:34.430
And then based on that endpoint configuration, we'll be deploying an endpoint.

12
00:00:34.430 --> 00:00:36.400
And then from that,

13
00:00:36.400 --> 00:00:40.400
we'll be implementing multiple production variants into an endpoint.

14
00:00:40.400 --> 00:00:42.280
So let's dive in.

15
00:00:42.280 --> 00:00:44.450
So I'm here in SageMaker Studio,

16
00:00:44.450 --> 00:00:47.300
and I've already uploaded the notebook that is included

17
00:00:47.300 --> 00:00:49.930
with the exercise files for this module,

18
00:00:49.930 --> 00:00:51.590
and I've opened it up.

19
00:00:51.590 --> 00:00:56.350
I've also selected the Python 3 Data Science kernel for this notebook.

20
00:00:56.350 --> 00:00:59.460
Now we're going to be using the common MNIST dataset.

21
00:00:59.460 --> 00:01:00.080
Again,

22
00:01:00.080 --> 00:01:03.240
the focus of this particular module is not around the data

23
00:01:03.240 --> 00:01:05.410
or how the model is actually trained,

24
00:01:05.410 --> 00:01:08.540
but we'll be quickly pushing through those things first.

25
00:01:08.540 --> 00:01:10.970
So first, we're going to need to load our dataset.

26
00:01:10.970 --> 00:01:13.680
Now as mentioned, this is a publicly available dataset.

27
00:01:13.680 --> 00:01:16.800
And included in this, we're going to have a trained dataset,

28
00:01:16.800 --> 00:01:19.260
a validation set, and a test set.

29
00:01:19.260 --> 00:01:22.840
So first, we're going to pull down that data.

30
00:01:22.840 --> 00:01:25.550
Now the next thing we want to do is be able to quickly visualize

31
00:01:25.550 --> 00:01:27.560
the data that we're going to be working with.

32
00:01:27.560 --> 00:01:31.280
This is important because we'll need to understand the context as well

33
00:01:31.280 --> 00:01:34.350
be validating our model later within this notebook.

34
00:01:34.350 --> 00:01:37.050
So I have included a few sample functions that will help

35
00:01:37.050 --> 00:01:39.160
us with that visualization process.

36
00:01:39.160 --> 00:01:41.170
So I'm going to go ahead and run this cell.

37
00:01:41.170 --> 00:01:42.740
And once this is completed,

38
00:01:42.740 --> 00:01:45.870
we'll now be able to visualize some samples of each of the

39
00:01:45.870 --> 00:01:48.740
different classes from within this dataset.

40
00:01:48.740 --> 00:01:51.620
Now the MNIST dataset contains examples of

41
00:01:51.620 --> 00:01:55.500
handwritten digits that are 28px x 28px.

42
00:01:55.500 --> 00:01:56.500
And here, you can see,

43
00:01:56.500 --> 00:02:00.400
we have examples all the way from 0 to 9 to help understand the

44
00:02:00.400 --> 00:02:02.180
data that we're going to be working with.

45
00:02:02.180 --> 00:02:05.800
Now if we want to dive into a specific digit and help to understand some of

46
00:02:05.800 --> 00:02:08.530
the challenges we're going to have to solve with our model,

47
00:02:08.530 --> 00:02:12.840
we can use this particular call to get back examples of the number 7,

48
00:02:12.840 --> 00:02:16.740
and here we have 40 different versions of the number 7.

49
00:02:16.740 --> 00:02:19.020
Now the next thing we're going to need to do because we are

50
00:02:19.020 --> 00:02:22.740
going to use SageMaker to actually train our dataset is that

51
00:02:22.740 --> 00:02:26.300
we need to upload our data into S3.

52
00:02:26.300 --> 00:02:29.620
And before we can upload it, we need to be sure that it's in the right format.

53
00:02:29.620 --> 00:02:30.270
In this case,

54
00:02:30.270 --> 00:02:34.500
we want to be sure our data is going to be in a CSV format that the

55
00:02:34.500 --> 00:02:36.940
algorithm we're going to work with can handle.

56
00:02:36.940 --> 00:02:39.180
So in this case, we'll go ahead and run this.

57
00:02:39.180 --> 00:02:40.540
And you'll see here at the end,

58
00:02:40.540 --> 00:02:43.490
we're going to be uploading to three different areas.

59
00:02:43.490 --> 00:02:45.080
We're going to be saving our training dataset,

60
00:02:45.080 --> 00:02:46.020
test dataset,

61
00:02:46.020 --> 00:02:53.340
and validation set all within different folders within our S3 bucket.

62
00:02:53.340 --> 00:02:56.110
And now we can see that that process has completed,

63
00:02:56.110 --> 00:02:58.270
and we have uploaded our training dataset,

64
00:02:58.270 --> 00:03:01.130
which is going to be 50,000 items, our test dataset,

65
00:03:01.130 --> 00:03:04.400
which is 10,000, and validation, which is also 10,000.

66
00:03:04.400 --> 00:03:04.920
In addition,

67
00:03:04.920 --> 00:03:08.600
each of those have been saved within the S3 bucket that we've specified.

68
00:03:08.600 --> 00:03:09.820
Now it's important to remember,

69
00:03:09.820 --> 00:03:14.910
you'll need to add in the name of the S3 bucket and any prefix that you want to

70
00:03:14.910 --> 00:03:18.250
use here within this notebook before you run it because you won't have

71
00:03:18.250 --> 00:03:21.940
permission to access the bucket that I have included here.

72
00:03:21.940 --> 00:03:25.500
Now the next thing we need to do is we need to actually train our model.

73
00:03:25.500 --> 00:03:29.790
So we need to go get the container for the XGBoost algorithm.

74
00:03:29.790 --> 00:03:32.280
Now I'm specifying the newest version here.

75
00:03:32.280 --> 00:03:35.440
You may have to specify a different version if you also

76
00:03:35.440 --> 00:03:37.340
want to be using the latest version.

77
00:03:37.340 --> 00:03:39.690
Now that we've pulled in that container,

78
00:03:39.690 --> 00:03:43.160
we can now go through the process of creating our estimator,

79
00:03:43.160 --> 00:03:44.940
setting our hyperparameters,

80
00:03:44.940 --> 00:03:47.620
and then going through the process of training our model.

81
00:03:47.620 --> 00:03:50.460
As mentioned, this isn't the focus of this module.

82
00:03:50.460 --> 00:03:52.110
So I'll just include this here,

83
00:03:52.110 --> 00:03:56.240
and we'll go ahead and start the training process.

84
00:03:56.240 --> 00:03:59.040
So now that our model training is completed,

85
00:03:59.040 --> 00:04:01.560
we're now ready to proceed with the deployment process.

86
00:04:01.560 --> 00:04:03.070
And just a quick reminder,

87
00:04:03.070 --> 00:04:05.640
we're going to be doing three different things to deploy our

88
00:04:05.640 --> 00:04:08.060
models with SageMaker Hosting Services.

89
00:04:08.060 --> 00:04:10.280
First, we're going to be creating a model,

90
00:04:10.280 --> 00:04:14.140
which will actually be registering our model in with SageMaker.

91
00:04:14.140 --> 00:04:16.500
We'll then be creating an endpoint configuration,

92
00:04:16.500 --> 00:04:19.630
which specifies how we want our inference endpoint to work.

93
00:04:19.630 --> 00:04:23.140
And then we'll be actually creating the endpoint itself.

94
00:04:23.140 --> 00:04:26.640
So first, we need to create a model within SageMaker.

95
00:04:26.640 --> 00:04:28.420
Now it's important to note that within Python,

96
00:04:28.420 --> 00:04:31.740
there are two different ways that you can interact with SageMaker.

97
00:04:31.740 --> 00:04:35.740
First, you can use the AWS SDK for Python directly,

98
00:04:35.740 --> 00:04:38.510
or you can use the SageMaker SDK.

99
00:04:38.510 --> 00:04:42.400
The SageMaker SDK is going to simplify many of the tasks.

100
00:04:42.400 --> 00:04:47.200
For example, there is a single deploy call you can make with the SageMaker SDK,

101
00:04:47.200 --> 00:04:50.840
which will take care of all three steps that I just mentioned.

102
00:04:50.840 --> 00:04:51.270
However,

103
00:04:51.270 --> 00:04:54.600
it doesn't give you some of the configuration options that we

104
00:04:54.600 --> 00:04:57.420
will need later within this particular demo.

105
00:04:57.420 --> 00:05:00.760
So because of that, at this point, we're going to be switching over,

106
00:05:00.760 --> 00:05:03.900
and we're going to leverage the AWS SDK for Python

107
00:05:03.900 --> 00:05:06.740
for the remainder of this notebook.

108
00:05:06.740 --> 00:05:11.040
So the first step is to create a model within SageMaker.

109
00:05:11.040 --> 00:05:13.190
Now we're first going to give our model a name,

110
00:05:13.190 --> 00:05:15.400
and then we need to give some information about the

111
00:05:15.400 --> 00:05:18.440
container that it needs to run on for inference.

112
00:05:18.440 --> 00:05:23.270
And then we'll call the create_model call from the AWS SDK for Python.

113
00:05:23.270 --> 00:05:24.110
And then from this,

114
00:05:24.110 --> 00:05:26.160
we should get back information that would allow us to

115
00:05:26.160 --> 00:05:28.600
actually view our model within the console.

116
00:05:28.600 --> 00:05:32.160
So we'll go ahead and execute this cell. And here, I'm going to click on the

117
00:05:32.160 --> 00:05:36.120
link to view in console. And here we can see within our account, we now have

118
00:05:36.120 --> 00:05:39.780
a model that has been registered, and included in this is going to be the

119
00:05:39.780 --> 00:05:44.170
image that needs to be used for inference with this model. We also can see

120
00:05:44.170 --> 00:05:46.740
where it is saved within S3.

121
00:05:46.740 --> 00:05:50.340
So now I'll close this and go back to our notebook in SageMaker Studio.

122
00:05:50.340 --> 00:05:54.760
Now the next step that I mentioned was creating an endpoint configuration,

123
00:05:54.760 --> 00:05:59.650
and this dictates how inference is actually going to work on that endpoint.

124
00:05:59.650 --> 00:06:01.980
And so here, within our endpoint configuration,

125
00:06:01.980 --> 00:06:03.950
we're going to be controlling several settings.

126
00:06:03.950 --> 00:06:07.940
Now some of these here you don't need to specify if you're not

127
00:06:07.940 --> 00:06:11.110
using multiple production variants. We'll cover multiple

128
00:06:11.110 --> 00:06:13.240
production variants later within this demo.

129
00:06:13.240 --> 00:06:16.950
But for now, we're really concerned with passing in the InstanceType,

130
00:06:16.950 --> 00:06:19.410
which will be the types of instances that are spun up for

131
00:06:19.410 --> 00:06:22.200
our endpoint, the InitialInstanceCount,

132
00:06:22.200 --> 00:06:24.980
meaning the number of instances that are going to be included

133
00:06:24.980 --> 00:06:28.040
when we launch our endpoint, and the ModelName,

134
00:06:28.040 --> 00:06:30.140
which is the model name that we specified earlier.

135
00:06:30.140 --> 00:06:34.340
And that's how it will know how to fetch our model for the inference endpoint.

136
00:06:34.340 --> 00:06:37.840
So at this point, we'll go ahead and run this cell.

137
00:06:37.840 --> 00:06:41.560
And just as with the model, we can actually do and view this in the console.

138
00:06:41.560 --> 00:06:45.050
And we can see that this is an endpoint configuration,

139
00:06:45.050 --> 00:06:48.480
and all of the values that we've specified are going to be included in here.

140
00:06:48.480 --> 00:06:52.120
We can see that there is a single production variant that is specified,

141
00:06:52.120 --> 00:06:57.140
and it's going to be running an ml.m4.xlarge instance type.

142
00:06:57.140 --> 00:06:58.450
So now that we have that in place,

143
00:06:58.450 --> 00:07:02.030
we can now proceed to the third and final step in the deployment process,

144
00:07:02.030 --> 00:07:04.880
which is actually creating the endpoint.

145
00:07:04.880 --> 00:07:08.170
Now this is a relatively easy step once we have that

146
00:07:08.170 --> 00:07:11.030
configuration in place. We're going to call the

147
00:07:11.030 --> 00:07:14.740
create_endpoint method on the Python AWS SDK.

148
00:07:14.740 --> 00:07:18.040
We're going to pass in both the endpoint name that we've created

149
00:07:18.040 --> 00:07:20.820
and the config that we previously created.

150
00:07:20.820 --> 00:07:22.160
So now that that's in place,

151
00:07:22.160 --> 00:07:25.440
we'll go ahead and start the process of creating that.

152
00:07:25.440 --> 00:07:28.570
Now it's important to note, this will take a few minutes to

153
00:07:28.570 --> 00:07:30.710
get your endpoint up and running. And then,

154
00:07:30.710 --> 00:07:31.740
once it's up and running,

155
00:07:31.740 --> 00:07:36.740
we'll be able to go through and validate the deployment of our endpoint.

156
00:07:36.740 --> 00:07:39.080
So now that our deployment is complete,

157
00:07:39.080 --> 00:07:41.840
we can see that our endpoint is up and running.

158
00:07:41.840 --> 00:07:45.590
So two things that we need to notice, first, is that the status is InService,

159
00:07:45.590 --> 00:07:48.250
meaning that we can actually call our endpoint,

160
00:07:48.250 --> 00:07:51.940
and we can also see the URL for our endpoint.

161
00:07:51.940 --> 00:07:53.330
Now let's go back to the notebook,

162
00:07:53.330 --> 00:07:55.990
and the next step here is going to be to validate the

163
00:07:55.990 --> 00:07:58.740
model and the deployment of that model.

164
00:07:58.740 --> 00:08:01.520
So what I'm going to be doing here is we're going to loop over 10

165
00:08:01.520 --> 00:08:05.280
examples from our test dataset. Then, we're going to call the

166
00:08:05.280 --> 00:08:09.640
invoke_endpoint function of the SageMaker runtime API.

167
00:08:09.640 --> 00:08:10.480
So from here,

168
00:08:10.480 --> 00:08:13.480
I'm going to be able to pull back the inference, and we're going

169
00:08:13.480 --> 00:08:18.670
to actually view that alongside the images. And here we can see

170
00:08:18.670 --> 00:08:21.440
these starting to come back in. We can see initially we have a 7

171
00:08:21.440 --> 00:08:22.980
with the prediction of a 7,

172
00:08:22.980 --> 00:08:26.600
and you can see all 10 of the different examples that we've pulled back.

173
00:08:26.600 --> 00:08:27.610
Now this is perfect.

174
00:08:27.610 --> 00:08:31.580
This gives us a model with a single production variant that we have

175
00:08:31.580 --> 00:08:34.160
deployed that we can then integrate in with our own custom

176
00:08:34.160 --> 00:08:37.810
applications and workflows because we've deployed it as an endpoint

177
00:08:37.810 --> 00:08:39.740
on SageMaker Hosting Services.

178
00:08:39.740 --> 00:08:44.590
However, in situations where we're building a true continuous delivery workflow,

179
00:08:44.590 --> 00:08:47.890
there will be times when we want to actually do A/B testing of our

180
00:08:47.890 --> 00:08:50.820
models and evaluate the performance against either.

181
00:08:50.820 --> 00:08:51.820
So to do that,

182
00:08:51.820 --> 00:08:56.940
we're going to update our configuration to include multiple production variants.

183
00:08:56.940 --> 00:09:00.240
So the first thing we're going to do here is we're going to retrain a model.

184
00:09:00.240 --> 00:09:03.280
You'll notice here that we're calling this one xgb_model2,

185
00:09:03.280 --> 00:09:08.240
and we're going to be slightly adjusting our hyperparameters for this model.

186
00:09:08.240 --> 00:09:11.650
So now that we've retrained the new version of our model,

187
00:09:11.650 --> 00:09:16.140
we're now going to go through the process of saving it, just as we did before.

188
00:09:16.140 --> 00:09:18.840
So this will create a new model instance.

189
00:09:18.840 --> 00:09:21.310
Then, we're going to create a new configuration.

190
00:09:21.310 --> 00:09:25.050
Now note here that we now have two different variants that we'll

191
00:09:25.050 --> 00:09:27.740
be setting on this endpoint configuration.

192
00:09:27.740 --> 00:09:28.100
Also,

193
00:09:28.100 --> 00:09:30.500
notice here that because we're specifying the initial

194
00:09:30.500 --> 00:09:33.250
variant weight as being 1 for both,

195
00:09:33.250 --> 00:09:38.840
it should equally split the traffic going to each model 50/50.

196
00:09:38.840 --> 00:09:42.180
Now that we have that configured, we can now go in and update our

197
00:09:42.180 --> 00:09:46.870
endpoint. And notice here that we're calling the update_endpoint

198
00:09:46.870 --> 00:09:50.100
method, and we're passing in the endpoint name that we created

199
00:09:50.100 --> 00:09:53.640
originally and our new endpoint configuration.

200
00:09:53.640 --> 00:09:57.000
So now that the updating of our endpoint has completed, we can now test

201
00:09:57.000 --> 00:10:00.240
our endpoint that has multiple production variants.

202
00:10:00.240 --> 00:10:03.960
So when you invoke the endpoint that has multiple production variants,

203
00:10:03.960 --> 00:10:06.710
you do have a property, InvokedProductionVariant,

204
00:10:06.710 --> 00:10:08.720
that comes back with the result.

205
00:10:08.720 --> 00:10:12.040
So we should be able to view that alongside the prediction to be

206
00:10:12.040 --> 00:10:15.900
able to see how many of our inference requests come back with

207
00:10:15.900 --> 00:10:21.030
one model versus another. And here we can see, this first one

208
00:10:21.030 --> 00:10:22.100
has a prediction of a 7,

209
00:10:22.100 --> 00:10:25.500
and it's using Model1. And the next one has a prediction of a 2, and it's

210
00:10:25.500 --> 00:10:28.960
using Model2. And you can see so on and so forth, this ends up being split

211
00:10:28.960 --> 00:10:32.980
about half and half as we would expect because of the different weights

212
00:10:32.980 --> 00:10:35.240
that we set on each production variant.

213
00:10:35.240 --> 00:10:38.000
So through this process, we have trained an initial model,

214
00:10:38.000 --> 00:10:39.930
and we've gone through the deployment process,

215
00:10:39.930 --> 00:10:42.140
which included creating the model in SageMaker,

216
00:10:42.140 --> 00:10:45.380
creating our endpoint configuration, and deploying our endpoint.

217
00:10:45.380 --> 00:10:48.620
And then we created a new configuration that utilized two

218
00:10:48.620 --> 00:10:51.810
different models that had an equal weight on each.

219
00:10:51.810 --> 00:11:00.000
And then, we deployed an update to our SageMaker Hosting Services endpoint, and it is now utilizing both of those models equally.

