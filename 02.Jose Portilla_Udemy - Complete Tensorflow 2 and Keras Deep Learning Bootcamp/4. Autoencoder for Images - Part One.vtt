WEBVTT
1
00:00:05.440 --> 00:00:11.280
Come everyone to the series of lectures on using auto encoders on image data.

2
00:00:11.330 --> 00:00:16.150
We've already seen that even simple images are actually high dimensional data sets.

3
00:00:16.160 --> 00:00:22.910
Recall that the endless dataset or even the fashion and this dataset that were simple 28 by 20 images

4
00:00:23.270 --> 00:00:27.440
that actually contains then seven hundred and eighty four features and we can think of each of these

5
00:00:27.440 --> 00:00:28.940
features as a dimension.

6
00:00:28.940 --> 00:00:32.400
So each particular pixel is a dimension of data.

7
00:00:32.570 --> 00:00:34.730
So have seven hundred eighty four features.

8
00:00:34.730 --> 00:00:39.140
It might be a good idea to apply auto encoders to the sort of dataset.

9
00:00:39.190 --> 00:00:42.680
So what we could do is start off with a very simple premise.

10
00:00:42.760 --> 00:00:49.000
We're going to take our original image pass it through an auto encoder and then have the auto encoder

11
00:00:49.060 --> 00:00:52.510
attempt to recreate the image as the output.

12
00:00:52.870 --> 00:00:58.300
So essentially what it's going to do is it's going to attempt to learn what pixels are important as

13
00:00:58.360 --> 00:01:03.850
it encodes it down to a smaller hidden layer and then it's going to use those important features to

14
00:01:03.850 --> 00:01:07.520
attempt to reconstruct it in the decoder on the output.

15
00:01:07.930 --> 00:01:13.060
So recall that those hidden layers get smaller and smaller so it's going to have to learn which pixels

16
00:01:13.060 --> 00:01:19.680
per actually important for identifying image in order to reconstruct it as the output so then we would

17
00:01:19.680 --> 00:01:24.400
now have an auto encoder that understands what features of the seven hundred and eighty four pixels

18
00:01:24.460 --> 00:01:26.270
are important in which you're not.

19
00:01:26.290 --> 00:01:30.820
For example it will likely understand that pixels on the edge don't really matter.

20
00:01:30.820 --> 00:01:36.670
In fact if we take a look at a variety of the endless digital dataset images you'll notice that the

21
00:01:36.670 --> 00:01:42.220
very first couple of rows at the very top and really all the pixels around the edge usually don't contain

22
00:01:42.310 --> 00:01:47.170
any useful information because all these numbers are centered in the image.

23
00:01:47.170 --> 00:01:52.600
So hopefully the auto encoder would learn that those particular pixels are not very valuable.

24
00:01:52.600 --> 00:01:57.520
Now what we could do is do what we just did in the previous lecture and then just cut this other encoder

25
00:01:57.520 --> 00:02:01.570
in half and then see what we can do with dimensionality reduction.

26
00:02:01.570 --> 00:02:07.300
We can then plot this dimensionality reduction down to maybe two neurons or three neurons and then plot

27
00:02:07.300 --> 00:02:12.850
out the number classes in this reduced dimensionality space and explore what numbers are similar to

28
00:02:12.850 --> 00:02:14.020
what other numbers.

29
00:02:14.020 --> 00:02:19.260
But in a real world case this isn't super useful because you already have the image data to begin with.

30
00:02:19.600 --> 00:02:24.690
So it's an actual use case we could work with for image data that also involves auto encoders.

31
00:02:25.780 --> 00:02:31.960
Well what we can do is we can use this same logic to create an auto encoder that actually removes noise

32
00:02:32.080 --> 00:02:35.330
and we know that noisy images are definitely a real world problem.

33
00:02:35.800 --> 00:02:41.740
So what's going to happen here is the auto encoder will learn what features are important.

34
00:02:41.950 --> 00:02:49.030
So we're actually going to be able to do is using an auto encoder we will feed in a noisy version of

35
00:02:49.150 --> 00:02:50.470
our number.

36
00:02:50.500 --> 00:02:52.830
So we already have these clean no data set.

37
00:02:52.840 --> 00:02:57.400
So we have the m this dataset all the numbers are clean and the auto unclear when it's first going to

38
00:02:57.400 --> 00:02:59.770
do is as it takes in and it's input.

39
00:02:59.950 --> 00:03:01.240
It's going to add in noise.

40
00:03:01.240 --> 00:03:06.400
So here we can see on the left hand side we have a noisy version of that number seven and then it's

41
00:03:06.400 --> 00:03:12.250
going to encode as we go deeper into these smaller hidden layers and it's going to hopefully be able

42
00:03:12.250 --> 00:03:19.030
to learn what pixels are important and which are just noisy in order to reconstruct the correct number

43
00:03:19.120 --> 00:03:25.210
on the output since we'll be comparing the output to the real number image and then we now have an auto

44
00:03:25.210 --> 00:03:29.180
encoder that can actually deem noise images.

45
00:03:29.530 --> 00:03:34.660
So we're good explorer to auto encoders we're first going to attempt to recreate the very first simple

46
00:03:34.660 --> 00:03:38.380
auto encoder that just recreates input images in the output.

47
00:03:38.410 --> 00:03:43.690
So it just takes an image and then encodes it and expands it back out and we'll see how well it can

48
00:03:43.690 --> 00:03:48.100
do at retaining information as we reduce the number of neurons.

49
00:03:48.100 --> 00:03:53.320
The second thing we're going to do is build the actual application auto encoder which removes noise

50
00:03:53.320 --> 00:03:56.800
from input images to accurately reproduce output.

51
00:03:56.890 --> 00:04:02.350
Let's get started by heading over to a notebook and attempting to create that first auto encoder and

52
00:04:02.370 --> 00:04:03.760
it jumps to that notebook now.

53
00:04:03.790 --> 00:04:07.860
All right here and at my notebook I've already gone ahead and imported pandas PD.

54
00:04:07.980 --> 00:04:13.730
Now spies MP and met pup lib and the other thing I did was I also said from tense float that Chris thought

55
00:04:13.740 --> 00:04:19.750
datasets import m this and I loaded up the M dataset just as he did during the coalition all neural

56
00:04:19.750 --> 00:04:21.780
network section of the course.

57
00:04:21.790 --> 00:04:26.640
So you can recall that you can use peel T M show to show any of these images.

58
00:04:26.650 --> 00:04:29.320
So let's just grab the first training image run it.

59
00:04:29.500 --> 00:04:31.210
And here we can see there was a five.

60
00:04:31.800 --> 00:04:32.250
All right.

61
00:04:32.620 --> 00:04:39.250
So we're going to also do is quickly scale our dataset and recall just as we did in the compositional

62
00:04:39.250 --> 00:04:43.860
neural network section of course we're going to say X train is equal to x train divided by two fifty

63
00:04:43.870 --> 00:04:50.140
five and we'll say x test is equal to x test divided by two fifty five.

64
00:04:50.130 --> 00:04:55.210
Okay so we're already very familiar with this dataset to really cover it in more detail instead.

65
00:04:55.330 --> 00:04:58.090
Let's move on to actually building out our basic auto encoder.

66
00:04:58.630 --> 00:05:04.500
We'll say from tensor flow that carries that models in four sequential.

67
00:05:05.830 --> 00:05:17.640
And then from tensor flow that carries the layers import dense flatten and reshape and then we'll also

68
00:05:17.640 --> 00:05:24.350
use the stochastic gradient descent optimizer as we did before we'll say it tensor flow carries the

69
00:05:24.360 --> 00:05:28.230
optimizer is go ahead and import s g d.

70
00:05:29.480 --> 00:05:30.650
OK.

71
00:05:30.690 --> 00:05:36.630
Now keep in mind there's no right or wrong way to build out this auto encoder because this falls under

72
00:05:36.630 --> 00:05:42.750
kind of a semi supervised learning process because at the end of the day there's no kind of super correct

73
00:05:42.780 --> 00:05:46.360
answer as far as what the encoding should have been.

74
00:05:46.380 --> 00:05:47.470
Exactly.

75
00:05:47.550 --> 00:05:52.440
So we're going to do is we're going to build what's known as a stacked auto encoder which means there's

76
00:05:52.440 --> 00:05:58.980
actually multiple stacked hidden layers that slowly reduces the dimensionality of the data set.

77
00:05:58.980 --> 00:06:05.370
So we can do is we understand that we have seven hundred eight for essentially twenty eight times twenty

78
00:06:05.460 --> 00:06:06.180
eight pixels.

79
00:06:06.180 --> 00:06:10.010
Right now we're going to do is we'll just keep dividing this in half.

80
00:06:10.080 --> 00:06:15.210
So we'll go from seven hundred eighty four to maybe around 400 since this is equal to three ninety two.

81
00:06:16.110 --> 00:06:25.500
So go from r encoder sort of a sequential and then the other thing you should recall is if we take a

82
00:06:25.500 --> 00:06:32.880
look at the very first image or the way these images are constructed they are actually still retaining

83
00:06:32.880 --> 00:06:35.080
their shape of 20 by 28.

84
00:06:35.100 --> 00:06:40.260
So the first thing I'm going to do is we're going to flatten this out we'll say encoder ad and we're

85
00:06:40.260 --> 00:06:48.750
going to first flatten this out and we'll make it aware that the input shape is twenty eight by twenty

86
00:06:48.750 --> 00:06:49.030
eight.

87
00:06:49.380 --> 00:06:54.360
She could always adjust that input shape to fix whatever dimensions you're working with for your own

88
00:06:54.360 --> 00:06:55.210
images.

89
00:06:55.260 --> 00:06:56.490
So we first flatten it out.

90
00:06:56.550 --> 00:06:58.580
So we have it now seven hundred eighty four.

91
00:06:59.670 --> 00:07:04.230
And then we're going to do is we're going to add in a dense layer that goes from seven hundred and eighty

92
00:07:04.230 --> 00:07:04.820
four.

93
00:07:04.820 --> 00:07:11.070
Now let's go ahead and cut that about half to 400 neurons and we'll set for activation function equal

94
00:07:11.070 --> 00:07:16.770
to a rectified linear unit and we're going to keep doing this in order to make this a stacked auto encoder.

95
00:07:17.220 --> 00:07:21.930
It's probably too much to ask to just go from seven hundred eighty four down to something like twenty

96
00:07:21.930 --> 00:07:22.880
five dimensions.

97
00:07:22.920 --> 00:07:28.470
So we'll do this slowly that way the encoding half of the auto encoder can actually attempt to kind

98
00:07:28.470 --> 00:07:34.200
of slowly learn this dimensionality reduction so then we'll go from four hundred to two hundred and

99
00:07:34.200 --> 00:07:41.310
then let's cut then a half again we'll go from two hundred to one hundred and then cut that in half

100
00:07:41.310 --> 00:07:41.920
again.

101
00:07:42.180 --> 00:07:47.620
They'll go from one hundred to let's say 50 and then we'll go into that one more time.

102
00:07:47.760 --> 00:07:51.630
So we go down from 50 to twenty five OK.

103
00:07:51.690 --> 00:07:56.700
And again this kind of just an arbitrary choice of how far down we're gonna go here.

104
00:07:56.700 --> 00:08:02.550
So now I'm going down from seven hundred eighty four to twenty five which if I think about that in terms

105
00:08:02.640 --> 00:08:07.860
of a percent I'm actually going down to just 3 percent of the size.

106
00:08:07.980 --> 00:08:14.040
So I'm going from seven hundred eighty four dimensions down to twenty five dimensions which is around

107
00:08:14.040 --> 00:08:18.630
three point two percent of the original feature size.

108
00:08:18.810 --> 00:08:22.910
So we have some handy for dimensions we're going down to three point two percent of that which is twenty

109
00:08:22.910 --> 00:08:23.910
five neurons.

110
00:08:23.910 --> 00:08:29.250
So this is kind of impressive already especially if it's able to recreate after it goes through the

111
00:08:29.250 --> 00:08:29.840
decoder.

112
00:08:29.850 --> 00:08:38.520
So let's build out our decoder just as we did before we'll use a sequential model and then we'll say

113
00:08:38.520 --> 00:08:42.450
decoder ad it's going to take condense.

114
00:08:42.600 --> 00:08:47.120
And here we're essentially going to build out the reverse of the encoder.

115
00:08:47.130 --> 00:08:51.610
Keep in mind we're not going to duplicate this very last one because that's the centre hidden layer.

116
00:08:51.990 --> 00:08:57.660
So the very first layer in the decoder should match the second to last layer in the encoder which is

117
00:08:57.660 --> 00:08:59.220
going to be 50.

118
00:08:59.370 --> 00:09:05.400
So right in the middle it's going to have that twenty five neurons and expand back out to mirror the

119
00:09:05.400 --> 00:09:15.180
encoder so then it goes from 50 here and then we're going to specify is the input shape is equal to

120
00:09:15.940 --> 00:09:16.610
twenty five.

121
00:09:17.070 --> 00:09:20.670
So that kind of shows the connection here between the encoder and the decoder.

122
00:09:20.670 --> 00:09:23.160
So we have the input shape as equals twenty five.

123
00:09:23.160 --> 00:09:29.050
And then finally let's say that the activation function is equal to a rectified linear unit.

124
00:09:29.830 --> 00:09:30.230
OK.

125
00:09:30.660 --> 00:09:32.970
So that's the very first layer and the decoder.

126
00:09:32.970 --> 00:09:35.850
And now we're just going to mirror our encoder.

127
00:09:35.940 --> 00:09:44.160
So add in in other dense layer and then we'll go back out to from 50 to 100 and say the activation function

128
00:09:44.250 --> 00:09:50.160
is a rectified linear unit and then I'll just copy and paste this and expand it back out to the original

129
00:09:50.340 --> 00:09:51.530
seven hundred and eighty four.

130
00:09:52.290 --> 00:09:59.070
So a 50 to 100 to 200 add in one more 200 to 400.

131
00:09:59.340 --> 00:10:05.790
And then finally we'll go from 400 to the original which is either you can type out twenty eight times

132
00:10:05.790 --> 00:10:10.430
twenty eight which is OK or you can say seven hundred and eighty four.

133
00:10:10.470 --> 00:10:16.670
The important thing to note here is that this activation is going to change to sigmoid and the other

134
00:10:16.670 --> 00:10:21.870
important thing to note here is we need to compare this to the actual original images.

135
00:10:22.670 --> 00:10:34.340
So we'll say decoder ad and we're going to reshape this to be 28 by 28 in order to successfully compare

136
00:10:34.820 --> 00:10:39.080
the input of 28 by 28 to the output.

137
00:10:39.080 --> 00:10:41.100
That should also be 28 by 20.

138
00:10:41.150 --> 00:10:49.040
After going through the auto encoder and the reason we have sigmoid as our final activation function

139
00:10:49.460 --> 00:10:56.750
is because we essentially are performing a binary cross entropy loss at the end of our auto encoder

140
00:10:57.080 --> 00:11:04.160
we're just checking does the final output image after going through the entire auto encoder match the

141
00:11:04.190 --> 00:11:06.050
true image that we suspect it to be.

142
00:11:06.740 --> 00:11:08.420
So what does that actually look like.

143
00:11:09.050 --> 00:11:15.890
Well we take our auto encoder and build it by saying sequential model just as we did before we pass

144
00:11:15.890 --> 00:11:27.680
in the encoder and the decoder and then to compile it we'll say compile and loss is equal to binary

145
00:11:28.790 --> 00:11:36.740
cross entropy and it's binary across entropy because the auto encoder doesn't really care how many distinct

146
00:11:36.800 --> 00:11:37.960
types of numbers are.

147
00:11:37.970 --> 00:11:43.940
It doesn't care that there's 10 classes of numbers all the auto encoder cares about is is the image

148
00:11:44.030 --> 00:11:50.030
I'm producing at the output going to match the image that was originally put into the input.

149
00:11:50.180 --> 00:11:54.520
So that's why it's just sigmoid and binary across entropy.

150
00:11:55.070 --> 00:11:59.510
And then we'll go ahead and specify our optimizer and this is something you can play around with especially

151
00:11:59.510 --> 00:12:00.990
for your own data sets.

152
00:12:01.010 --> 00:12:05.720
So that's why we use the classic gradient descent and you can play around that learning rate then you

153
00:12:05.720 --> 00:12:11.510
can always slow down your learning rate by giving a smaller value if you notice your reproductions are

154
00:12:11.510 --> 00:12:14.500
pretty off or if your training is taking too much time.

155
00:12:14.540 --> 00:12:19.490
You can always experiment with increasing the learning rate by giving a larger value to hopefully learn

156
00:12:19.490 --> 00:12:20.560
faster.

157
00:12:20.660 --> 00:12:25.320
So we discussed that in our original theory lectures all the way towards the beginning of this course.

158
00:12:25.520 --> 00:12:31.760
And then finally let's go ahead and keep metrics and we're gonna keep track of accuracy instead of just

159
00:12:32.060 --> 00:12:33.620
our loss.

160
00:12:33.620 --> 00:12:35.690
So there's our accuracy.

161
00:12:35.690 --> 00:12:39.560
And then finally we'll say auto encoder and let's go ahead and fit this model.

162
00:12:39.680 --> 00:12:42.570
We're simply going to pass in X train next train.

163
00:12:43.280 --> 00:12:49.790
And again the actual train test split is kind of irrelevant here because this is just an auto encoder.

164
00:12:49.970 --> 00:12:54.680
And here's why again it's called a I supervised learning process because it's not like we're trying

165
00:12:54.680 --> 00:12:57.820
to actually perform some sort of classification task here.

166
00:12:57.920 --> 00:13:03.800
Instead all we're trying to do is see if this auto encoder is able to learn what features are important

167
00:13:04.220 --> 00:13:07.730
as it encodes the information to a smaller dimensionality.

168
00:13:07.910 --> 00:13:12.500
Remember it's just three point two percent of the space with twenty five neurons and then expand that

169
00:13:12.500 --> 00:13:13.100
back out.

170
00:13:13.400 --> 00:13:17.440
So that's why I'm just passing an extra X train when we pass and fit.

171
00:13:17.750 --> 00:13:24.460
That's really both the x and the Y is just is the image number one equal to image number one from X

172
00:13:24.460 --> 00:13:24.890
train.

173
00:13:25.370 --> 00:13:34.130
Okay so then we'll go ahead and train this for let's say five epochs and we've got to do is pass in

174
00:13:34.190 --> 00:13:35.190
validation data.

175
00:13:36.740 --> 00:13:43.490
So if you want to just check its performance so to speak on data it's not actually being trained on

176
00:13:43.490 --> 00:13:44.690
to reproduce.

177
00:13:44.690 --> 00:13:49.510
That's what you can do with the test set by saying X test x test.

178
00:13:49.640 --> 00:13:57.980
But again that train test split is not a fundamental part of this process so we'll go ahead and fit

179
00:13:57.980 --> 00:13:58.570
this.

180
00:13:58.950 --> 00:14:04.690
And I'm going to fast forward in time until the auto encoder is done fitting all right.

181
00:14:04.710 --> 00:14:06.690
This finished train for me.

182
00:14:06.690 --> 00:14:13.200
Now let's go ahead and see how we can use the auto encoder and take a look at what the images look like

183
00:14:13.380 --> 00:14:22.290
after they've been passed through the auto encoder so we can do here is we can say past images and let's

184
00:14:22.290 --> 00:14:32.000
go ahead and just grab a batch from the Tesla will say auto encoder predict and say X test go ahead

185
00:14:32.040 --> 00:14:34.200
just pass and if you want ten of those.

186
00:14:34.200 --> 00:14:38.800
And so we're doing is replacing 10 images that the auto encoder was not trained on.

187
00:14:38.880 --> 00:14:44.010
And then we're asking the auto encoder to quote unquote predict and predicting for this auto encoder

188
00:14:44.400 --> 00:14:49.700
really just means attempt to reconstruct the image after reducing its dimensionality down to twenty

189
00:14:49.700 --> 00:14:50.980
five neurons.

190
00:14:51.000 --> 00:14:53.410
So let's see how well of a job at that first.

191
00:14:53.700 --> 00:14:57.970
Let's go ahead and view what one of the original images looks like.

192
00:14:58.050 --> 00:15:04.650
So we'll say P.L. T M show and in fact let's do a couple of things there we'll say n is equal to zero.

193
00:15:04.650 --> 00:15:10.410
So that's something to play around with and we'll show why in a second we'll say appeal T M show and

194
00:15:10.410 --> 00:15:20.900
then we'll say from X test grab n and then we'll say peel t show here and right below it we'll say appeal

195
00:15:20.900 --> 00:15:31.500
t n show and we'll say is past images of n and let's add in a little label here so we'll print out original

196
00:15:31.500 --> 00:15:41.050
image and then we'll print out attempted reconstruction of it.

197
00:15:41.520 --> 00:15:48.330
And this is technically after it's gone through the entire auto encoder again all we're doing here is

198
00:15:48.330 --> 00:15:53.910
we're comparing the original image and what the image would look like after being passed through the

199
00:15:53.910 --> 00:15:55.290
entire auto encoder.

200
00:15:55.290 --> 00:15:58.850
So we're doing this just for the first image for n zero run that.

201
00:15:58.860 --> 00:16:05.160
So here's our original image seven and this is what it looks like after being reconstructed.

202
00:16:05.160 --> 00:16:07.870
So is this impressive or not.

203
00:16:07.920 --> 00:16:13.590
Notice the seven looks a little blurrier but you should realize here that this is actually extremely

204
00:16:13.590 --> 00:16:19.500
impressive because what the auto encoder was able to do is it squeezed down the seven hundred and eighty

205
00:16:19.500 --> 00:16:26.400
four features or dimensions down to just twenty five and then was able to then expand that back out

206
00:16:26.790 --> 00:16:30.080
to recreate what essentially looks like the original image.

207
00:16:30.120 --> 00:16:33.130
And this allows you to then play around with the value of n.

208
00:16:33.140 --> 00:16:35.340
You can choose another one let's say n is equal to three.

209
00:16:35.370 --> 00:16:36.670
Check out that third image.

210
00:16:36.780 --> 00:16:38.330
And here is the original image.

211
00:16:38.340 --> 00:16:43.440
Looks like a zero and then here it is after being passed through the other encoder so you can see that

212
00:16:43.440 --> 00:16:47.480
the auto encoder is almost acting like kind of blur functionality.

213
00:16:47.490 --> 00:16:53.500
We're just checking what it looks to be important in order to reconstruct the image we're going to do

214
00:16:53.920 --> 00:16:59.850
and essentially Part 2 of this lecture series is build out an auto encoder for D noisier images.

215
00:16:59.920 --> 00:17:02.920
So we'll continue right where we left off in part two.

216
00:17:02.930 --> 00:17:03.480
I'll see you there.
