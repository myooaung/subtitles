1
00:00:05,290 --> 00:00:11,290
Welcome everyone to part one of tech generation with Python and Kerry's intensive flow to support part

2
00:00:11,290 --> 00:00:15,090
one we're going to keep things simple we're just going to import the main libraries should have a read

3
00:00:15,090 --> 00:00:20,770
in and import a text file and then we'll focus on understanding the characters in that text file.

4
00:00:20,770 --> 00:00:22,570
Let's open up a new notebook and get started.

5
00:00:23,000 --> 00:00:28,150
All right here I am at the notebook I've already imported num pies and P pansies Beatty and Matt putt

6
00:00:28,150 --> 00:00:28,680
lib.

7
00:00:28,810 --> 00:00:33,610
The last thing going to import which we don't do often so that's why I want to specify it is in putting

8
00:00:33,610 --> 00:00:40,370
tensor flow as TMF Since later on in the notebook will be actually importing stuff directly as TMF Dot.

9
00:00:40,370 --> 00:00:43,180
Okay so step one is to grab the data.

10
00:00:43,240 --> 00:00:45,410
You can check out the notebook that we provide for you.

11
00:00:45,420 --> 00:00:49,810
You can go to Gutenberg dot org to grab any free texts you want from there.

12
00:00:49,930 --> 00:00:53,830
But in our case we're gonna be choosing Shakespeare's works which you've already downloaded for you

13
00:00:53,950 --> 00:00:57,430
and they're actually in the same folder as the MLP notebook.

14
00:00:57,460 --> 00:01:00,610
So there's two main reasons we choose Shakespeare's works.

15
00:01:00,610 --> 00:01:05,140
One is that it's already large corpus of text it's usually recommended to have at least a source of

16
00:01:05,140 --> 00:01:08,080
a million characters to get some sort of real estate generation.

17
00:01:08,260 --> 00:01:13,150
And then second this one's kind of more important is because Shakespeare has a very distinct style.

18
00:01:13,150 --> 00:01:18,360
If you open up some random Shakespeare work you can kind of tell the spacing and style of a play someone

19
00:01:18,370 --> 00:01:19,690
entered someone exits.

20
00:01:19,690 --> 00:01:23,080
The names are capitalized and then there's the phrases of what they say.

21
00:01:23,110 --> 00:01:27,820
So we'll be able to see our recurrent natural network actually duplicate that style just on a character

22
00:01:27,850 --> 00:01:29,210
by character basis.

23
00:01:29,320 --> 00:01:35,270
So I'm going to create a variable called Path to file and go ahead and just write the full file path

24
00:01:35,270 --> 00:01:36,950
to wherever the text file is.

25
00:01:37,010 --> 00:01:39,730
In my case This notebook is actually in the same location as it.

26
00:01:39,830 --> 00:01:46,610
So I used to say Shakespeare the text to go ahead and run that and then let's read it and we'll say

27
00:01:46,610 --> 00:01:54,860
text is equal to open and we'll say have to file and then we'll just read it with mode R and then we

28
00:01:54,860 --> 00:01:57,930
call read okay.

29
00:01:57,950 --> 00:02:03,670
So that will go ahead and if we check out the text let's just see the first five four new characters

30
00:02:03,670 --> 00:02:04,390
in it.

31
00:02:04,450 --> 00:02:10,090
So you notice that it has spaces and it also has these backslash end and that basically stands for a

32
00:02:10,090 --> 00:02:10,800
new line.

33
00:02:10,810 --> 00:02:14,280
So when you print it out it has a very specific style.

34
00:02:14,290 --> 00:02:18,160
So we print this out and we can see these are his sonnets and they're kind of spaced.

35
00:02:18,160 --> 00:02:25,690
So let's go and choose some kind of random go to four thousand five hundred to four thousand let's say

36
00:02:25,810 --> 00:02:30,980
800 and you can see here that clearly there's distinct spacing here.

37
00:02:31,000 --> 00:02:35,230
There's spaces based New Line you line your line some number for your sonnet.

38
00:02:35,230 --> 00:02:36,450
And then the sonnet again.

39
00:02:36,820 --> 00:02:41,290
So the character recurrent neural network there's actually going to be able to learn that and much further

40
00:02:41,290 --> 00:02:48,490
along if we actually start getting to his plays later on in this text Let's actually make this quite

41
00:02:48,490 --> 00:02:56,230
a bit longer say 10000 run that actually make it 140.

42
00:02:56,290 --> 00:02:57,020
There we go.

43
00:02:57,040 --> 00:03:02,590
So we can see this Helena's turn to speak so we can see her texts that she's speaking and if we expand

44
00:03:02,590 --> 00:03:08,680
on this further we get five hundred more characters here you can see King than the King speaks then

45
00:03:08,680 --> 00:03:11,030
Helena speaks again et cetera.

46
00:03:11,030 --> 00:03:14,250
OK so this is actually very well structured.

47
00:03:14,380 --> 00:03:15,460
So we're gonna be using it.

48
00:03:15,560 --> 00:03:21,130
Let's go ahead and take that out and next thing I want to do is understand the unique characters that

49
00:03:21,130 --> 00:03:22,760
are inside this text file.

50
00:03:22,960 --> 00:03:23,680
So to do that.

51
00:03:23,770 --> 00:03:31,870
One quick way to grab all the unique characters is to just cast it into a set and then we can sort that

52
00:03:31,880 --> 00:03:32,880
set.

53
00:03:32,890 --> 00:03:37,210
So if I run this these are all the unique characters and in fact let's go ahead and just assign this

54
00:03:37,240 --> 00:03:47,670
as our vocab so vocab is equal to sort of set text and then we'll say vocab here so we can see there's

55
00:03:47,700 --> 00:03:51,060
new line there's just a space exclamation point.

56
00:03:51,060 --> 00:03:58,290
Some numbers here all capital letters some punctuation and then lowercase letters and then some braces

57
00:03:58,530 --> 00:04:00,800
for probably formatting later on.

58
00:04:00,860 --> 00:04:04,840
Okay so that means we check out the length of our vocab.

59
00:04:05,000 --> 00:04:09,500
There are 84 unique characters that we're going to be working with and we'll have to keep that number

60
00:04:09,500 --> 00:04:14,080
in mind when designing the less dense layer of our neural network.

61
00:04:14,090 --> 00:04:14,420
Okay.

62
00:04:14,480 --> 00:04:15,290
That's it for this step.

63
00:04:15,290 --> 00:04:16,970
Just reading in the text file.

64
00:04:16,970 --> 00:04:21,290
Main thing to note here is that we import a tenth flows TAF and also make sure you provide the correct

65
00:04:21,290 --> 00:04:22,540
path to the file.

66
00:04:22,640 --> 00:04:27,710
We already download Shakespeare that text for you and it's located in the LP folder.

67
00:04:27,890 --> 00:04:30,890
Thanks and we'll see you at step 2 talking about text processing.
