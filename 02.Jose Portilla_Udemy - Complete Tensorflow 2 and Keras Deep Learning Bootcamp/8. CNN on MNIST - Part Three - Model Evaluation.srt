1
00:00:05,220 --> 00:00:06,180
Welcome back everyone.

2
00:00:06,180 --> 00:00:11,940
In this lecture we're going to focus on evaluating our model that we just train in the previous lecture.

3
00:00:11,940 --> 00:00:14,820
Let's head to our Jupiter notebook and continue where we left off.

4
00:00:15,230 --> 00:00:15,470
OK.

5
00:00:15,480 --> 00:00:19,770
Here we are at the notebook where we left off last time after training the model as always what we can

6
00:00:19,770 --> 00:00:28,900
do is we can say losses are actually in this case we're going to say metrics is equal to PD.

7
00:00:28,900 --> 00:00:36,840
That data frame and say model history the history and the reason I'm saying metrics instead of just

8
00:00:36,840 --> 00:00:42,720
losses is because let's take a look at what the history that history attribute actually return because

9
00:00:42,750 --> 00:00:46,720
I also said keep track of accuracy here not just loss.

10
00:00:46,740 --> 00:00:52,290
I get both my loss and accuracy on the training set as well as my validation loss and validation accuracy

11
00:00:53,220 --> 00:00:55,850
which means I can plot both of them out.

12
00:00:55,890 --> 00:01:00,510
So instead of saying metrics that plot it doesn't make sense to plot both loss and accuracy otherwise

13
00:01:00,510 --> 00:01:01,770
you get a plot that looks like this.

14
00:01:02,100 --> 00:01:07,410
Instead you should be plotting loss for validation loss and accuracy with validation accuracy.

15
00:01:07,410 --> 00:01:13,980
So what we'll do is we'll pass analyst here with loss and validation loss.

16
00:01:13,990 --> 00:01:19,540
Go ahead and plot those out and we can see how the loss for the training sets going down but it looks

17
00:01:19,540 --> 00:01:23,110
like the validation loss was essentially starting to go up again.

18
00:01:23,140 --> 00:01:25,500
So why we stopped the epoch training.

19
00:01:25,660 --> 00:01:33,010
And if you want to we can also see the accuracy change so you can see accuracy versus the validation

20
00:01:33,010 --> 00:01:41,240
accuracy note that the validation metrics basically just have V8 l underscore added before them.

21
00:01:41,430 --> 00:01:43,770
And here we can see our accuracy continue on the training set.

22
00:01:43,830 --> 00:01:44,340
So that's good.

23
00:01:44,340 --> 00:01:48,610
Almost reaching a hundred percent accuracy but our validation set started to level off when we end the

24
00:01:48,610 --> 00:01:49,100
training.

25
00:01:49,600 --> 00:01:56,020
OK so in case you want to remember what metrics are available to you in your model you can say model

26
00:01:56,680 --> 00:02:02,980
metrics names and I'll report back the actual metrics there at loss and accuracy and if you actually

27
00:02:02,980 --> 00:02:10,120
want to get the metrics of these lost or accuracy on any set of data we can say model that evaluates

28
00:02:11,110 --> 00:02:16,720
and we can pass in x test and Y categorical test.

29
00:02:16,720 --> 00:02:21,190
Go ahead and say verbose is equal to zero so you don't see the actual running of this data through the

30
00:02:21,190 --> 00:02:27,400
model and it will evaluate and basically return back loss and accuracy on the test set and it makes

31
00:02:27,400 --> 00:02:32,590
sense that these are zero point zero four and zero point nine eight because if we take a look back at

32
00:02:32,590 --> 00:02:38,410
this the last validation loss run on the test set was zero point zero four and zero point nine eight.

33
00:02:38,500 --> 00:02:44,530
So they should be essentially the exact same numbers as the very last loop or less epoch.

34
00:02:44,680 --> 00:02:47,350
And that's the evaluation on this test set.

35
00:02:47,410 --> 00:02:52,930
You can also do the same thing for the training set and a report back these numbers loss and accuracy.

36
00:02:52,930 --> 00:02:53,400
OK.

37
00:02:53,500 --> 00:02:57,340
Recall the accuracy issues the calculation of what percentages you get right.

38
00:02:57,400 --> 00:03:02,240
Loss here is the result of this categorical cross entropy function.

39
00:03:02,300 --> 00:03:05,920
Now we understand how it performed during the epoch training.

40
00:03:05,930 --> 00:03:11,410
Let's go ahead and just get the classification report and confusion matrix on our test data.

41
00:03:11,570 --> 00:03:20,690
We can do this from S.K. learn not metrics import classification report and we can also import the confusion

42
00:03:20,690 --> 00:03:22,130
matrix.

43
00:03:22,130 --> 00:03:28,610
So we run that we'll go ahead and grab our predictions off of our test set and for this case we want

44
00:03:28,610 --> 00:03:33,950
to predict classes based off the information in the x test dataset.

45
00:03:34,340 --> 00:03:35,820
And now we have our predictions.

46
00:03:36,080 --> 00:03:44,070
What we can do is recall that white cat test it's still in the shape of ten thousand by ten.

47
00:03:44,070 --> 00:03:48,030
So what we want to do is make sure that we're comparing this correctly to.

48
00:03:48,060 --> 00:03:50,600
Why test which is these actual labels.

49
00:03:50,670 --> 00:03:56,170
So for our actually evaluation we need to pass and why test no longer these categorical ones.

50
00:03:56,490 --> 00:04:04,440
So we'll say prints classification report compare the true why test values to our predicted values and

51
00:04:04,440 --> 00:04:10,670
we can see the classification report essentially showing you the precision recall an f1 score per class.

52
00:04:10,740 --> 00:04:13,860
So how will that do on zeros ones etc..

53
00:04:13,900 --> 00:04:18,990
You can see it does fairly well across almost all classes with ninety nine percent accuracy and if you

54
00:04:18,990 --> 00:04:24,120
want to do a deeper dive on this you can do a confusion matrix based off that same data.

55
00:04:24,210 --> 00:04:29,590
Why test versus predictions and you can see the results here.

56
00:04:29,690 --> 00:04:36,140
If you want to visualize this you can also use Seabourn to transform this so we can say Seabourn as

57
00:04:36,230 --> 00:04:43,190
S.A. and then call a heat map which would essentially color the results that we have here.

58
00:04:43,280 --> 00:04:48,830
So you can grab this and then paste in the results and we can make this figure a little larger can say

59
00:04:48,830 --> 00:04:57,280
something like fig size equals 10 by 6 and you can run that and we'll show you a heat map just need

60
00:04:57,280 --> 00:05:00,310
to add in annotations equal to true.

61
00:05:00,310 --> 00:05:02,590
So I can see those values on top of it.

62
00:05:02,620 --> 00:05:04,060
So that's a we can quickly visualize it.

63
00:05:04,060 --> 00:05:08,980
Not super informative here because of how well the performances across all the numbers.

64
00:05:08,980 --> 00:05:11,610
OK so that's one way to visualize it.

65
00:05:11,680 --> 00:05:14,890
The last thing you're going to cover is how do you predict a single image.

66
00:05:14,890 --> 00:05:17,830
So someone gave you an image of a single number.

67
00:05:17,860 --> 00:05:24,850
So for example say my number is equal to x test 0.

68
00:05:25,000 --> 00:05:29,050
So if I just peel team show my number here.

69
00:05:29,170 --> 00:05:30,980
Make sure it did this correctly.

70
00:05:31,060 --> 00:05:37,000
We'll say my number reshaped to 28 by 28.

71
00:05:37,000 --> 00:05:37,990
There we go.

72
00:05:37,990 --> 00:05:39,520
So here's my number.

73
00:05:39,520 --> 00:05:40,730
It's reshaped 20 by 28.

74
00:05:40,740 --> 00:05:43,090
So I can visualize it clearly it's a seven.

75
00:05:43,090 --> 00:05:47,200
So if somebody gave you this single my number how would you actually predict it.

76
00:05:47,500 --> 00:05:56,020
Well you would say model predict classes and then the only thing you'd have to be aware of is this reshaping.

77
00:05:56,370 --> 00:06:04,050
So I would say my number not reshape and then the shape should end up being the batch size.

78
00:06:04,050 --> 00:06:12,990
So essentially the number of images the width the height and then the color channels.

79
00:06:13,020 --> 00:06:15,360
So in our case it's a single image.

80
00:06:15,360 --> 00:06:16,680
So that's one.

81
00:06:16,680 --> 00:06:18,430
It's 28 by 28.

82
00:06:18,450 --> 00:06:19,830
And then there's one color channel.

83
00:06:19,830 --> 00:06:24,240
So that's why I need to reshape it that way because that's the shape it was trained on given the fact

84
00:06:24,240 --> 00:06:27,200
that we're feeding multiple numbers at a time.

85
00:06:27,270 --> 00:06:30,150
We'll go ahead and predict the classes here and then we get back.

86
00:06:30,150 --> 00:06:34,820
It predicts that it's a seven which makes sense because here I can see it's clearly a seven.

87
00:06:34,830 --> 00:06:35,340
OK.

88
00:06:35,490 --> 00:06:39,780
So the compositional all the work performed very well on the M this dataset.

89
00:06:39,900 --> 00:06:44,780
Now that we know how to work with grayscale images we're going to do is expand our knowledge and in

90
00:06:44,790 --> 00:06:50,280
the next series of lectures we'll follow a very similar path but working on color data with three color

91
00:06:50,280 --> 00:06:51,860
channels red green and blue.

92
00:06:52,080 --> 00:06:52,560
I'll see you there.
