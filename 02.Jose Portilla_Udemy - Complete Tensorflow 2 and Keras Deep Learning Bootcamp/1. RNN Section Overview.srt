1
00:00:05,900 --> 00:00:07,270
Welcome back everyone.

2
00:00:07,310 --> 00:00:11,790
In this section of the course we're going to take a look at recurrent neural networks.

3
00:00:12,020 --> 00:00:16,820
We've used neural networks to solve classification and regression problems but we still haven't seen

4
00:00:16,850 --> 00:00:22,600
how neural networks can deal with sequence information just as convolution neural networks were more

5
00:00:22,600 --> 00:00:27,760
effective for use of two dimensional image data Recurrent Neural Networks have unique properties that

6
00:00:27,760 --> 00:00:33,460
allow them to be more effective for sequence data sequence data can be a variety of data sources it

7
00:00:33,460 --> 00:00:39,880
can be anything from timestamps sales data or sequence of text in a sentence or biological data like

8
00:00:39,880 --> 00:00:42,130
heartbeat data over time et cetera.

9
00:00:43,980 --> 00:00:46,830
So let's think about what a time series actually is.

10
00:00:46,830 --> 00:00:51,960
Here we're showing beer wine and alcohol sales across the United States for a certain period of time

11
00:00:52,320 --> 00:00:55,140
on the x axis we can actually see the timeframe.

12
00:00:55,140 --> 00:01:00,660
So starting at nineteen ninety two all the way until around 2018 2019.

13
00:01:00,660 --> 00:01:07,710
So here on the y axis we can see we have sales in millions of dollars when we're thinking about forecasting

14
00:01:07,770 --> 00:01:10,900
and time series predictions with recurrent neon networks.

15
00:01:10,910 --> 00:01:17,370
But we want to do is we want to be able to learn of historical information and forecast into the unknown

16
00:01:17,370 --> 00:01:17,880
future.

17
00:01:18,300 --> 00:01:22,030
So that's how we're going to be using recurrent fuel networks with time series data.

18
00:01:22,080 --> 00:01:27,450
In this section of the course in future sections what we're going to realize is that sequences can also

19
00:01:27,450 --> 00:01:31,360
be essentially categorical sequences such as a sentence.

20
00:01:31,440 --> 00:01:34,190
For example we want to be able to given the data.

21
00:01:34,200 --> 00:01:35,490
Hello how are you.

22
00:01:35,490 --> 00:01:41,670
Predict that today is the highest probability word to show up next and recurrent known networks will

23
00:01:41,670 --> 00:01:43,000
also be able to do that.

24
00:01:43,140 --> 00:01:49,200
And if you have email or text messaging from Google you've probably already seen this sort of technology

25
00:01:49,200 --> 00:01:52,140
in practice where you have predictive texts.

26
00:01:52,140 --> 00:01:57,480
Ok so in this particular section we're going to learn a lot about recurrent neural network theory and

27
00:01:57,480 --> 00:02:02,550
then we'll learn about specialized types of neurons that work particularly well with time series data

28
00:02:02,820 --> 00:02:08,820
called Ellis teams or short term memory units and our use or groups which are gated recurrent units.

29
00:02:08,850 --> 00:02:10,640
So we'll learn about the theory behind them.

30
00:02:10,830 --> 00:02:15,480
Once you understand the theory behind these specialized units we'll move on to a basic implementation

31
00:02:15,540 --> 00:02:20,820
of recurrent neural network on a sine wave and then we'll learn how to operate a recurrent network for

32
00:02:20,820 --> 00:02:24,160
forecasting capabilities on a real Lifetime series.

33
00:02:24,330 --> 00:02:29,160
Then we'll test your skills for an exercise and solution in the next section of course we'll focus on

34
00:02:29,160 --> 00:02:33,930
recurrent neural networks and other neural network techniques for natural language processing and text

35
00:02:33,930 --> 00:02:34,670
data.

36
00:02:34,680 --> 00:02:36,240
All right let's get started.

37
00:02:36,240 --> 00:02:37,200
I'll see in the next lecture.
