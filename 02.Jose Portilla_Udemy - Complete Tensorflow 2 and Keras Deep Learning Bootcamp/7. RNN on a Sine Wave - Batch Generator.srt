1
00:00:05,750 --> 00:00:08,360
OK here we are where we left off last time.

2
00:00:08,480 --> 00:00:14,330
It's now time to take our training data and create batches for training purposes off of it.

3
00:00:14,330 --> 00:00:23,140
The way we can do this is by saying from tensor flow that carries that pre processing that sequence

4
00:00:25,180 --> 00:00:35,110
import time series and then a capital G generator so go ahead and run that import and then off of this

5
00:00:35,520 --> 00:00:40,660
go ahead and just call help on this time series generate generator class so we can explore just a little

6
00:00:40,660 --> 00:00:41,680
bit about it.

7
00:00:41,680 --> 00:00:48,040
So essentially what this is it's a super helpful utility class that generates these batches for this

8
00:00:48,100 --> 00:00:49,630
sequence data.

9
00:00:49,630 --> 00:00:55,600
So it takes in the sequence data and what we have to be familiar with is the actual arguments or parameters

10
00:00:55,930 --> 00:00:58,360
that we provide this time series generator.

11
00:00:58,360 --> 00:01:03,290
So what it does and the parameters that we're gonna be focused on is the data parameter.

12
00:01:03,370 --> 00:01:09,520
Essentially what the actual X is or the source of this X that we're training on then the targets is

13
00:01:09,520 --> 00:01:10,120
the label.

14
00:01:10,120 --> 00:01:14,370
Again the source of the label and in our case they're actually both going to be the same thing.

15
00:01:14,380 --> 00:01:20,860
We're both taking the data in our targets from the training data because we have time stamped sequence

16
00:01:20,860 --> 00:01:22,000
information.

17
00:01:22,000 --> 00:01:27,200
So we're going to essentially be passing in data and targets as the same source.

18
00:01:27,220 --> 00:01:33,360
Okay then we have the length which is the length of the output sequences and number of time steps.

19
00:01:33,550 --> 00:01:36,970
And then we have later on we'll see that there's a batch size.

20
00:01:37,090 --> 00:01:41,440
So beyond the sampling rate or stride which wouldn't have to worry about really we're going to focus

21
00:01:41,440 --> 00:01:46,060
on after that is batch size which is the number of time serious samples in each batch.

22
00:01:46,060 --> 00:01:50,980
Okay so let's go ahead and play around these parameters just to make sure we understand time series

23
00:01:50,980 --> 00:01:57,870
generator because a lot of the work is actually going to happen behind the scenes for us so I'm going

24
00:01:57,870 --> 00:01:59,940
to create a couple of variables here.

25
00:01:59,940 --> 00:02:05,700
One is length and this is the length of the output sequences in number of time steps.

26
00:02:05,700 --> 00:02:13,980
So say 2 and then the batch size is essentially how many batches are we returning or how many time series

27
00:02:13,980 --> 00:02:16,140
samples are returning in each batch.

28
00:02:16,140 --> 00:02:18,080
So we'll go ahead and say 1.

29
00:02:18,210 --> 00:02:23,190
And typically when it comes to sequence information of Time series just the batch size of one performs

30
00:02:23,430 --> 00:02:25,660
pretty well.

31
00:02:25,720 --> 00:02:32,420
So now it's time to actually create our generator so say Time series generator and then we have to decide

32
00:02:32,810 --> 00:02:34,540
what is the source of our data.

33
00:02:34,550 --> 00:02:42,050
Essentially what contains the X timestamp or the X index and in our case it's our scale training data

34
00:02:43,220 --> 00:02:48,350
and then the next one is asking us well where's the Y label contain then for our case that's also skill

35
00:02:48,350 --> 00:02:53,730
training data and it makes sense because a skilled training data has both series and information.

36
00:02:53,720 --> 00:02:58,580
If we take a look at it it's right here at the scale training data that we saw in this case it's the

37
00:02:58,580 --> 00:03:05,000
test but it's the same sort of format it already has the source of the index or X and our y our label.

38
00:03:05,030 --> 00:03:11,120
Basically what we want is that the model given some value here on the index predicts what the value

39
00:03:11,120 --> 00:03:11,780
should be here.

40
00:03:12,320 --> 00:03:17,390
So later on we'll be able to pass in something like fifty point one and see what the model thinks the

41
00:03:17,390 --> 00:03:18,340
output should be.

42
00:03:18,850 --> 00:03:19,450
OK.

43
00:03:19,730 --> 00:03:26,460
So these happen to have the same source then after this we have to decide on the length so we'll pass

44
00:03:26,460 --> 00:03:34,740
in length that's equal to length and then we'll also say batch size is equal to batch size whips.

45
00:03:34,760 --> 00:03:37,300
Make sure it's correct.

46
00:03:37,320 --> 00:03:38,130
There we go.

47
00:03:38,140 --> 00:03:41,940
And we're going to do is we're gonna play around with length and batch size to make sure that you understand

48
00:03:42,240 --> 00:03:45,000
what these parameters actually do.

49
00:03:45,000 --> 00:03:50,420
So let's take a look at the length of our scaled training data.

50
00:03:50,540 --> 00:03:54,940
So recall our training data right now is four hundred and fifty one.

51
00:03:54,950 --> 00:03:58,760
Let's take a look at the length of our generator object.

52
00:03:58,760 --> 00:04:04,030
Essentially this gentleman our object is going to yield or generate batches for us.

53
00:04:04,190 --> 00:04:12,590
So our generator object is 451 minus our length to which kind of makes sense because we're going to

54
00:04:12,590 --> 00:04:16,490
do is explore what does the first batch actually look like.

55
00:04:16,490 --> 00:04:24,490
So what the generator does if we take the generator and just ask for index 0 What does the first batch

56
00:04:24,490 --> 00:04:25,360
look like.

57
00:04:25,360 --> 00:04:31,870
Well we're going to do some tuple unpacking here because it returns both the x and the Y.

58
00:04:31,870 --> 00:04:34,690
That should be predicted off of the X..

59
00:04:35,170 --> 00:04:38,550
So this is the very first batch that is generated off of this.

60
00:04:38,860 --> 00:04:43,460
So if we take a look at X it looks like this.

61
00:04:43,530 --> 00:04:47,980
It's zero point for nine nine and zero point five for nine.

62
00:04:48,120 --> 00:04:53,260
And we take a look at our y it's zero point five nine nine.

63
00:04:53,260 --> 00:04:55,730
So what do those values actually mean.

64
00:04:55,730 --> 00:05:01,620
Well let's take a look at our skilled training data again and see what's actually happening here.

65
00:05:01,630 --> 00:05:06,670
Essentially what we're going to be telling our recurrent neural network model is given these two points

66
00:05:06,670 --> 00:05:13,090
in a row try to predict this third point and you'll notice that the very first three numbers in our

67
00:05:13,090 --> 00:05:18,090
script scale training dataset is four point ninety nine then five point four nine.

68
00:05:18,250 --> 00:05:23,290
And then the third one is what it's going to mean to try to predict which is zero point five nine nine.

69
00:05:23,290 --> 00:05:28,230
So that's essentially what this generator is using when it comes to length.

70
00:05:28,270 --> 00:05:34,570
We're saying given this length of to predict this one into the future let's play around if that just

71
00:05:34,570 --> 00:05:35,650
to make sure we understand.

72
00:05:36,490 --> 00:05:43,460
Let's see what happens if we say our length is equal to four and then redefine this generator notice.

73
00:05:43,460 --> 00:05:50,180
Now the generator is the length the skilled training data minus four which makes sense because we can't

74
00:05:50,180 --> 00:05:55,880
have the generator go all the way to the end of our training data set because then it won't have those

75
00:05:55,970 --> 00:05:59,320
extra values into the future to actually grab from.

76
00:05:59,330 --> 00:06:03,640
So let's see what the actual x y generator at zero returns.

77
00:06:03,640 --> 00:06:11,150
Now notice now since the length is four it's going to say OK here are the first four points.

78
00:06:11,150 --> 00:06:13,700
Go ahead and predict point number five.

79
00:06:13,700 --> 00:06:16,020
So that is what this length is representing.

80
00:06:16,070 --> 00:06:22,340
Now this length shouldn't just be an arbitrary choice the length the X that actually think about because

81
00:06:22,400 --> 00:06:28,500
it should be enough for the network to pick up on any seasonality or repeating effects.

82
00:06:28,760 --> 00:06:32,270
If we think back to our actual data frame.

83
00:06:32,450 --> 00:06:34,300
So if I plot my data frame.

84
00:06:34,400 --> 00:06:36,200
Notice that it's a sine wave.

85
00:06:36,200 --> 00:06:43,190
What I want to do is make sure that I feed my network a long enough sequence of information so I can

86
00:06:43,190 --> 00:06:45,100
begin to pick up on any trends.

87
00:06:45,110 --> 00:06:49,120
It's probably not very helpful for the network to just see one point to the past.

88
00:06:49,130 --> 00:06:55,520
And one point into the future instead I probably want to at least have enough points so that a network

89
00:06:55,520 --> 00:06:59,480
can pick up on this cyclical motion here of the trend.

90
00:06:59,480 --> 00:07:09,040
So I can see that if I go from maybe zero to probably around twenty five points I can see a full cycle.

91
00:07:09,170 --> 00:07:12,200
So that doesn't mean zero to twenty five on the x axis.

92
00:07:12,320 --> 00:07:16,640
It means actually twenty five individual points and you can expand on this.

93
00:07:16,700 --> 00:07:22,070
But keep in mind the larger the length then the longer the training time.

94
00:07:22,600 --> 00:07:23,320
Okay.

95
00:07:23,600 --> 00:07:29,630
So imagine you're dealing with yearly time series data and you were on a yearly sales cycle maybe had

96
00:07:29,630 --> 00:07:34,850
holidays sales cycle summer et cetera you would probably want to include at least a year's worth of

97
00:07:34,850 --> 00:07:38,540
information in this length variable.

98
00:07:38,540 --> 00:07:44,870
So what we'll do is we'll go ahead and set this length to 25 and you can feel free to expand on that

99
00:07:45,560 --> 00:07:50,510
but I'm going to now set length of twenty five so that when I actually look at my generator what it's

100
00:07:50,510 --> 00:07:57,800
doing is it's feeding twenty five pieces information as X and then asking the model to predict what.

101
00:07:57,800 --> 00:08:02,940
Point number twenty six looks like okay so it's four time series generator object.

102
00:08:02,990 --> 00:08:07,430
Well we're going to do in the next lecture is actually create the model and then evaluate it and we'll

103
00:08:07,430 --> 00:08:12,740
explore the differences between a simple recurrent neural network and using a long short term memory

104
00:08:12,740 --> 00:08:13,670
unit.

105
00:08:13,670 --> 00:08:14,780
I'll see you in the next lecture.
