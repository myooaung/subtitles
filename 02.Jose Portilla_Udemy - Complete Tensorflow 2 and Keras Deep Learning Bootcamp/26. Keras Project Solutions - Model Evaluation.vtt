WEBVTT
1
00:00:05.240 --> 00:00:08.180
Welcome back everyone to finish off our solution lectures.

2
00:00:08.180 --> 00:00:12.860
We're going to now evaluate the model that we trained in the previous lecture.

3
00:00:12.860 --> 00:00:13.680
Let's get started.

4
00:00:14.300 --> 00:00:14.610
OK.

5
00:00:14.630 --> 00:00:19.550
We finish training our model Optionally you can go ahead and save your model the code to do them is

6
00:00:19.550 --> 00:00:30.130
just simply saying from tensor flow that Caris thought models import load underscore model and that

7
00:00:30.130 --> 00:00:34.220
will allow you to actually load it later but to save it you technically don't need to do that import.

8
00:00:34.270 --> 00:00:38.590
You can say model that save and then choose any string code.

9
00:00:38.590 --> 00:00:44.370
So my favorite model dot H five and then save that.

10
00:00:44.380 --> 00:00:47.590
And if you wanted to load it up again you simply run Load model.

11
00:00:47.590 --> 00:00:51.370
So this is totally optional you don't need to actually save your model here if you don't want to use

12
00:00:51.370 --> 00:00:51.790
it again.

13
00:00:52.720 --> 00:00:57.180
So let's focus on evaluating the model performance recall during training.

14
00:00:57.310 --> 00:01:01.840
We passed in both our validation set and our training set.

15
00:01:01.840 --> 00:01:04.000
Let's go ahead and plot those out.

16
00:01:04.000 --> 00:01:10.170
So we're going to say model history thought history and that returns back.

17
00:01:10.180 --> 00:01:17.230
This dictionary of the losses which we can then easily convert to a panda's data frame and then we'll

18
00:01:17.230 --> 00:01:22.930
set that to losses run that and let's go ahead and plot these out.

19
00:01:23.080 --> 00:01:25.050
So we'll say losses plot.

20
00:01:25.150 --> 00:01:31.120
However if we take a look at losses right now we have loss and validation loss.

21
00:01:31.120 --> 00:01:37.040
So recall this loss is the training loss this validation loss is the loss on our test set.

22
00:01:37.060 --> 00:01:38.480
The x test and the White test.

23
00:01:38.950 --> 00:01:42.530
So hopefully when we run this we get to see similar behavior.

24
00:01:42.730 --> 00:01:48.370
And it looks like our training loss and validation loss were both decreasing but eventually we were

25
00:01:48.430 --> 00:01:51.070
really improving that much on the validation.

26
00:01:51.070 --> 00:01:55.990
Something that might be interesting to explore here is to add in an early stopping callback and just

27
00:01:55.990 --> 00:02:03.280
train for a lot more epochs and see if this would have continued to decline or photos started increasing.

28
00:02:03.280 --> 00:02:07.920
Let's go ahead and continue to next task which was create predictions from the X test set and display

29
00:02:07.930 --> 00:02:11.530
classification import and confusion matrix for that test set.

30
00:02:11.710 --> 00:02:20.380
What we can do that is from S.K. learn that metrics will go and import a classification report and a

31
00:02:20.440 --> 00:02:28.830
confusion matrix we can grab our predictions by simply grabbing our model and running predict classes

32
00:02:29.370 --> 00:02:35.100
and then you just need a pass in some features like x test and that returns back predictions in which

33
00:02:35.100 --> 00:02:41.130
case once that's done we can print out a classification report that takes in if you take a look at it

34
00:02:41.390 --> 00:02:46.470
blips not prints but the actual classification report that takes in white true versus Y predictions.

35
00:02:46.560 --> 00:02:50.670
So we'll pass in y true versus our predictions.

36
00:02:50.670 --> 00:02:57.870
And because the classification task recall we're going to have different books this should be why test

37
00:02:59.210 --> 00:03:04.180
and as I was saying because of the classification task there's going to be different metrics we can

38
00:03:04.180 --> 00:03:05.050
evaluate this by.

39
00:03:05.050 --> 00:03:10.010
There's going to be an accuracy metric a precision metric recall an F1 score.

40
00:03:10.390 --> 00:03:14.050
So accuracy that's just the actual percent that we got right.

41
00:03:14.080 --> 00:03:19.150
So if you did the same ran the split we did the exact same network we're looking at around 90 percent

42
00:03:19.180 --> 00:03:25.090
accuracy but recall that in the very beginning of this notebook so all the way at the top what we did

43
00:03:25.180 --> 00:03:30.970
is we first analyzed the actual label itself and recall that it's an imbalanced labels.

44
00:03:30.970 --> 00:03:35.760
There is a lot more fully paid than there are charged off loans.

45
00:03:35.900 --> 00:03:43.000
In effect if we were to take a look at a model that simply recalled back any loan as being fully paid

46
00:03:43.300 --> 00:03:44.650
it would actually still be pretty accurate.

47
00:03:44.740 --> 00:03:48.750
So we'll scroll down here and just to kind of show you what I mean by that.

48
00:03:48.910 --> 00:03:57.190
If we take a look at our original data frame and we have whether or not our loan was repaid or we're

49
00:03:57.190 --> 00:04:09.280
going to do is let's do some value counts here and we have this many loan repaid so let's go ahead and

50
00:04:09.310 --> 00:04:14.800
take that and divide it by the actual length of that data frame and run that.

51
00:04:14.890 --> 00:04:21.370
So notice here that what this is indicating is that 80 percent of my points were already being predicted

52
00:04:21.490 --> 00:04:28.300
as loan repaid which means if I created a very simple model that simply said any loan will be repaid

53
00:04:28.660 --> 00:04:30.520
I would be 80 percent accurate.

54
00:04:30.880 --> 00:04:36.940
So don't be fooled by a model that returns back 80 percent accuracy because by default a model that

55
00:04:36.940 --> 00:04:42.160
just always reports back to the loan will be repaid itself will be 80 percent accurate more or less

56
00:04:42.250 --> 00:04:44.090
on this actual test data set.

57
00:04:44.110 --> 00:04:49.330
So we should be looking at kind of a bottom threshold of 80 percent which means our 89 percent accuracy

58
00:04:49.330 --> 00:04:54.790
here is OK but it's not absolutely fantastic because of our imbalanced data set.

59
00:04:54.940 --> 00:05:00.170
As mentioned in the machine learning metric lectures the actual metrics who want to take a look at our

60
00:05:00.190 --> 00:05:05.500
precision recall and F1 score and it looks like depending on the class you perform a little worse.

61
00:05:05.500 --> 00:05:11.650
So the true class we should be looking at here is the one that's lower representation which is zero.

62
00:05:11.710 --> 00:05:13.910
So now we have a lot less instances of zero.

63
00:05:13.960 --> 00:05:17.650
We're pretty good on the precision here but really where we suffer is the recall.

64
00:05:17.860 --> 00:05:23.790
And we can get an F1 score which recalls the harmonic mean between precision and recall.

65
00:05:23.830 --> 00:05:32.110
So really the true notification of whether or not this model is doing well is this f1 score on this

66
00:05:32.200 --> 00:05:33.470
0 class.

67
00:05:33.490 --> 00:05:38.660
So what I would encourage you to do is see if you can play around the model hyper parameters maybe adding

68
00:05:38.680 --> 00:05:44.200
more layers add in more neurons maybe play around the dropout rate to see if you can improve off a base

69
00:05:44.380 --> 00:05:46.650
zero point six 1 f1 score.

70
00:05:46.800 --> 00:05:49.210
OK so is this good or bad.

71
00:05:49.210 --> 00:05:54.190
Well that really depends on the entire context of the situation whether we have a model that already

72
00:05:54.190 --> 00:05:57.040
at times to predict this and what's its f1 score.

73
00:05:57.070 --> 00:06:02.980
So we need a lot more context to decide whether or not this recall in this f1 score are good enough.

74
00:06:03.010 --> 00:06:08.500
Well we can't say right off the bat is that this accuracy is better than just kind of a default guess

75
00:06:08.500 --> 00:06:09.590
which would be 80 percent.

76
00:06:09.970 --> 00:06:14.740
So this model is definitely better than just kind of a random guess or a straight guess.

77
00:06:14.770 --> 00:06:16.170
So we are performing much better.

78
00:06:16.540 --> 00:06:22.450
A random guess would get 50 percent accuracy a straight guess of always being repaid with get 80 percent

79
00:06:22.450 --> 00:06:25.430
accuracy in our model is getting 89 percent accuracy.

80
00:06:25.460 --> 00:06:30.020
So we are performing better than both a random guess and a straight loan repaid return.

81
00:06:30.490 --> 00:06:37.060
OK so overall we can see that our model is learning something from this dataset and then we can see

82
00:06:37.720 --> 00:06:44.170
the confusion matrix as well if we're interested in that we can perform y tests versus predictions run

83
00:06:44.170 --> 00:06:46.560
that and we get to see this confusion matrix.

84
00:06:46.570 --> 00:06:52.540
And again you can see or mis classifying a lot of those zero points which causes this kind of low recall

85
00:06:53.760 --> 00:07:00.170
OK so given the last task given the customer below would you offer this person alone.

86
00:07:00.190 --> 00:07:04.110
Well we're going to do here is basically use our model to run on a single person.

87
00:07:04.150 --> 00:07:11.110
So we'll simply import random seed set it to 1 to 1 and then we'll create a random index using this

88
00:07:11.380 --> 00:07:17.050
then off this random index we're going to grab some new customer and then display their actual features

89
00:07:18.350 --> 00:07:19.390
so go ahead and run this.

90
00:07:19.400 --> 00:07:23.260
And if you ran everything the same as you get the same random customer that we got.

91
00:07:23.350 --> 00:07:26.160
And you can play off the seed if you want a different random customer.

92
00:07:26.360 --> 00:07:32.110
And the way would actually predict off this customer is first we have to make sure that this is no longer

93
00:07:32.110 --> 00:07:35.030
a the series but actually a number higher.

94
00:07:35.420 --> 00:07:38.010
So that's kind of the hardest part is making sure your data is in the right shape.

95
00:07:38.330 --> 00:07:40.580
So a new customer right now it's a panda series.

96
00:07:40.580 --> 00:07:47.480
What I need to do is grab the values which returns back these feature values and then after that I need

97
00:07:47.480 --> 00:07:54.350
to reshape this to be in the same shape of the training data that the model was trained on which in

98
00:07:54.350 --> 00:08:00.610
our case is won by 78 and that essentially adds a little extra bracket call there which is what our

99
00:08:00.610 --> 00:08:08.020
model expects and then we're going to go ahead and make sure that we scale this data in order to predict

100
00:08:08.020 --> 00:08:14.010
the correct class because recall our model learned on scaled data.

101
00:08:14.010 --> 00:08:15.640
So we will take our scalar.

102
00:08:15.750 --> 00:08:24.000
And we will transform this data and set that to our new customer.

103
00:08:24.000 --> 00:08:30.350
So say new customer run that go ahead and check out our new customer.

104
00:08:30.360 --> 00:08:36.330
So now we have a scaled version of this new customer and let's pass this into the models say model predict

105
00:08:36.330 --> 00:08:42.930
classes on this new customer run that in our model predicts that it was 8 1.

106
00:08:42.930 --> 00:08:46.780
So now let's actually check that this person actually end up paying back their loan.

107
00:08:46.830 --> 00:08:54.630
So we're going to do here is essentially run this same command here but we won't actually drop it.

108
00:08:54.640 --> 00:08:58.240
We just want that actual column there run it.

109
00:08:58.360 --> 00:09:02.400
And if we look at the very bottom or we can just call it ourselves.

110
00:09:02.480 --> 00:09:07.570
Want to see whether or not the loan was repaid and it happened to be repaid.

111
00:09:07.660 --> 00:09:10.860
So it looks like in this particular case we got it right.

112
00:09:10.870 --> 00:09:11.450
All right.

113
00:09:11.530 --> 00:09:14.070
So that's it for this project.

114
00:09:14.110 --> 00:09:19.060
Notice it was a very large project but a big part of it was actually feature engineering and understanding

115
00:09:19.060 --> 00:09:19.860
the data.

116
00:09:19.990 --> 00:09:25.480
Usually when it comes to actually training the model itself that's a much simpler task because the model

117
00:09:25.480 --> 00:09:26.550
is doing most of the work.

118
00:09:26.560 --> 00:09:30.600
All you need to decide on is how many layers and how many neurons per layer.

119
00:09:30.610 --> 00:09:32.740
So there's lots of options to play around with here.

120
00:09:32.890 --> 00:09:37.360
And I would encourage you to play off your own models and see if you can be our performance that we've

121
00:09:37.360 --> 00:09:39.520
shown here with this simpler model.

122
00:09:39.560 --> 00:09:41.380
Thanks and I'll see you at the next lecture.
