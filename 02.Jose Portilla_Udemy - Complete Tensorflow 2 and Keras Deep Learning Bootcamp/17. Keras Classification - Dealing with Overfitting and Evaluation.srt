1
00:00:05,280 --> 00:00:10,650
Welcome back everyone to part two of our classification code along in part two we're going to create

2
00:00:10,650 --> 00:00:14,970
the model and then show you how to help prevent over fitting of the model.

3
00:00:14,970 --> 00:00:19,220
Let's head back to the notebook and continue where we left off last time OK.

4
00:00:19,250 --> 00:00:23,190
I'm going to begin by importing tensor flow.

5
00:00:23,270 --> 00:00:26,030
Actually we'll say from tensor flow

6
00:00:28,720 --> 00:00:34,480
from tense flow that carries that model's import sequential.

7
00:00:34,480 --> 00:00:35,770
Make sure you spell import right.

8
00:00:36,940 --> 00:00:44,950
Run that and then we'll also say from tensor flow that Kerry's stock layers import and will first start

9
00:00:44,950 --> 00:00:52,110
off using dense layers but we'll also add in dropout layers later on OK so let's create a very simple

10
00:00:52,110 --> 00:00:55,850
model given what we know so far about creating models.

11
00:00:55,860 --> 00:00:59,000
So right now in my training set I have four and twenty six rows.

12
00:00:59,010 --> 00:01:02,400
So not a whole lot of rows and then 30 features.

13
00:01:02,400 --> 00:01:15,090
So what I will do is I will create a sequential model and then I will add in a first layer of 30 neurons.

14
00:01:15,120 --> 00:01:20,700
You can say units equal to 30 if you want and then the activation will just be a rectified linear unit.

15
00:01:20,700 --> 00:01:25,610
And then we will repeat that except we'll go ahead and cut that in half.

16
00:01:25,610 --> 00:01:32,840
So the next layer will go down to 15 and we'll keep things simple so that we have one last output layer.

17
00:01:32,840 --> 00:01:35,790
And this is just going to be one neuron.

18
00:01:35,810 --> 00:01:44,100
However the activation and this critical will be sigmoid because this is a binary classification problem.

19
00:01:44,150 --> 00:01:49,520
So for a binary classification problem we want the last activation to be sigmoid.

20
00:01:49,520 --> 00:01:51,160
Check out the theory lectures on this.

21
00:01:51,170 --> 00:01:57,050
If you are a little fuzzy on why we're choosing that specific activation to have binary classification

22
00:01:57,230 --> 00:02:03,860
one neuron outputting something between a 0 and 1 and that will decide what class this belongs to either

23
00:02:03,860 --> 00:02:04,990
malignant or benign.

24
00:02:05,630 --> 00:02:12,220
And then we will compile this we'll say model compile and we also have to make sure this last call is

25
00:02:12,220 --> 00:02:13,020
correct.

26
00:02:13,060 --> 00:02:19,360
This should be binary underscore cross entropy in order for it to work correctly.

27
00:02:19,360 --> 00:02:22,930
And then the optimizer we have lots of different options here but we'll go ahead and just choose an

28
00:02:22,930 --> 00:02:24,610
atom optimizer.

29
00:02:24,700 --> 00:02:31,330
So we created our model and now it's time to train the model we'll say model that fit and we'll say

30
00:02:31,330 --> 00:02:36,220
X is equal to x train why is equal to y.

31
00:02:36,220 --> 00:02:39,880
Train and then epochs.

32
00:02:39,880 --> 00:02:42,430
And I'm going to choose a really large number of epochs here.

33
00:02:42,430 --> 00:02:46,370
So six hundred is probably way too many for its particular training.

34
00:02:46,480 --> 00:02:50,950
But I want to specifically actually show you what it looks like when you're over fit to your training

35
00:02:50,950 --> 00:02:54,820
data and to do that we're also gonna pass in our validation data.

36
00:02:54,940 --> 00:03:03,450
So say validation data and we'll pass an X test and white test so go ahead and run this and this will

37
00:03:03,450 --> 00:03:06,210
take a while because we're running it for so many epochs.

38
00:03:06,210 --> 00:03:09,070
So I'm going to fast forward in time until this is done.

39
00:03:09,120 --> 00:03:10,900
Training on the six hundred epochs.

40
00:03:11,010 --> 00:03:14,000
So that's six hundred times through the entire training set.

41
00:03:14,010 --> 00:03:16,490
So let me fast forward in time okay.

42
00:03:16,500 --> 00:03:19,470
This is just finished training for the six hundred epochs.

43
00:03:19,500 --> 00:03:24,030
We're going to do now is we'll go ahead and plot out the loss and remember you passed in our validation

44
00:03:24,030 --> 00:03:25,400
data during the training.

45
00:03:25,410 --> 00:03:30,160
So we'll be able to plot out both the training loss and the validation loss.

46
00:03:30,510 --> 00:03:38,220
Recall that I can say model thought history that history and I can pass that into a pan this data frame

47
00:03:40,110 --> 00:03:48,810
and we'll call that losses and then here's my losses I have the training loss and the validation loss.

48
00:03:48,810 --> 00:03:55,730
Let's go ahead and plot this out and see what this looks like so here are my losses and this is a perfect

49
00:03:55,730 --> 00:03:57,960
example of over fitting.

50
00:03:58,010 --> 00:04:00,190
So what is the key characteristic here over fitting.

51
00:04:00,380 --> 00:04:06,410
You'll notice in the beginning during the first couple of epochs both validation and training loss are

52
00:04:06,410 --> 00:04:07,520
both decreasing.

53
00:04:07,520 --> 00:04:08,440
That's good.

54
00:04:08,450 --> 00:04:11,360
That means we haven't yet over 50 training data.

55
00:04:11,360 --> 00:04:16,920
And as we go along we're decreasing loss in both the validation set and the training set.

56
00:04:16,940 --> 00:04:23,760
However at a certain point in time notice that our training loss here in blue is still going down.

57
00:04:23,780 --> 00:04:27,450
However our validation loss is beginning to increase.

58
00:04:27,470 --> 00:04:35,380
That basically tells us that we're over fitting to our training dataset so we have a clear indication

59
00:04:35,380 --> 00:04:37,980
here that we're training just for too many epochs.

60
00:04:37,990 --> 00:04:42,100
Notice the validation list gets worse and worse after these epochs.

61
00:04:42,100 --> 00:04:46,270
So we're going to do is we're going to see if we can use early stopping.

62
00:04:46,270 --> 00:04:48,330
So we've obviously trained too much.

63
00:04:48,340 --> 00:04:54,340
And we're going to do is show you how to use tensor flow cares callbacks to actually based on your validation

64
00:04:54,340 --> 00:04:58,870
loss stop the training before it gets out of hand as shown here.

65
00:04:58,870 --> 00:05:05,110
So I'm going to copy and paste our model again and this is kind of important in order to show this because

66
00:05:05,140 --> 00:05:07,060
we don't want to keep training on the same model.

67
00:05:07,060 --> 00:05:13,270
I want to recreate the model fresh so I will copy and paste these commands or scroll down.

68
00:05:13,350 --> 00:05:20,230
Go ahead and basically redefine your model again and then let me show you how we can use callbacks.

69
00:05:20,370 --> 00:05:23,150
And these are not the only callbacks we'll be using throughout the course.

70
00:05:23,190 --> 00:05:31,410
This is our first instance of using one we'll say from tensor float dot care stop callbacks import and

71
00:05:31,410 --> 00:05:36,630
the callback we'll be learning about right now is called early stopping and I would encourage you to

72
00:05:36,660 --> 00:05:40,410
call help on early stopping to see the full details on it.

73
00:05:40,620 --> 00:05:46,620
But basically what's happening here is we have to choose a metric to monitor in our case it will be

74
00:05:46,620 --> 00:05:47,830
validation loss.

75
00:05:47,970 --> 00:05:50,430
This orange metric right here.

76
00:05:50,430 --> 00:05:55,650
So we're gonna be tracking that validation loss and then you can specify things like the minimum changed

77
00:05:55,650 --> 00:05:56,670
required.

78
00:05:56,670 --> 00:06:01,770
Also there's patients which is the number of epochs with no improvement after which training will be

79
00:06:01,770 --> 00:06:02,160
stopped.

80
00:06:02,490 --> 00:06:07,770
So it doesn't just do a hard stop the minute that validation loss goes up a little bit you can see that

81
00:06:07,950 --> 00:06:12,330
throughout training there is a little bit of noise so maybe we want to wait a couple of epochs so we

82
00:06:12,330 --> 00:06:16,830
can have that patient's parameter there as well and we'll have different modes of training.

83
00:06:16,860 --> 00:06:22,050
So lots of different things you can explore here and you can even see the full example that's available

84
00:06:22,050 --> 00:06:23,640
to you in the doc stream.

85
00:06:23,740 --> 00:06:29,400
But let me show you how to use this early stopping and the early stopping has basically two steps.

86
00:06:29,400 --> 00:06:40,330
One is to define the variable early stop is equal to early stopping so we do that actual call and in

87
00:06:40,330 --> 00:06:44,460
our case we're going to be moderating monitoring validation loss

88
00:06:47,420 --> 00:06:51,470
and then the mode that we're actually looking for is men.

89
00:06:51,500 --> 00:06:53,980
So there's a couple of different modes here.

90
00:06:54,020 --> 00:06:55,880
Go back up here and check them out.

91
00:06:55,880 --> 00:06:59,000
Recall that the mode is basically what are you actually trying to do here.

92
00:06:59,030 --> 00:07:01,710
Are you trying to minimize the thing you're monitoring.

93
00:07:01,710 --> 00:07:07,880
Are you trying to maximize the thing you're monitoring etc. so you can imagine if our metric was accuracy

94
00:07:08,390 --> 00:07:11,450
accuracy something you want to maximize.

95
00:07:11,450 --> 00:07:19,400
If our metric is loss essentially the reverse of accuracy loss is something you want to minimize.

96
00:07:19,400 --> 00:07:20,860
So keep that in mind.

97
00:07:20,960 --> 00:07:26,660
And there's also this nice little auto string that basically the direction is automatically inferred

98
00:07:26,990 --> 00:07:32,630
from the name of the Monitor quantity so ill infer it based off the string that usually almost always

99
00:07:32,630 --> 00:07:34,420
works but just in case it doesn't.

100
00:07:34,430 --> 00:07:37,620
I would recommend that you manually put in min or max.

101
00:07:37,670 --> 00:07:43,370
It also lets you know that you know enough about the metric you're actually tracking to understand what

102
00:07:43,370 --> 00:07:45,410
you should be doing for early stopping.

103
00:07:45,410 --> 00:07:50,600
So in this case we're tracking our validation loss which is what we want to minimize because if we have

104
00:07:50,600 --> 00:07:53,830
a loss of zero that means we have a perfect fit.

105
00:07:53,900 --> 00:07:59,240
So we'll go in and say early stopping monitor validation loss try to minimize it.

106
00:07:59,240 --> 00:08:03,670
And we'll also say for both is equal to 1.

107
00:08:03,950 --> 00:08:09,550
Basically just have a little report back and then we'll set patients equal to twenty five.

108
00:08:09,590 --> 00:08:15,200
That means we'll wait twenty five epochs even after we've kind of detected a stopping point because

109
00:08:15,200 --> 00:08:17,830
of noise that could occur.

110
00:08:17,930 --> 00:08:24,950
So we create this early stop variable and then upon calling model that fit and I'm going to copy the

111
00:08:24,950 --> 00:08:26,550
same command we used before.

112
00:08:26,570 --> 00:08:29,840
So up here we have our original model fit command.

113
00:08:29,840 --> 00:08:31,530
Just go ahead and copy that.

114
00:08:31,730 --> 00:08:35,230
So we'll go and copy the contents of that cell.

115
00:08:35,360 --> 00:08:37,540
Make sure you've redefined the model again.

116
00:08:37,550 --> 00:08:39,920
Otherwise you'll accidentally be training the old model.

117
00:08:39,920 --> 00:08:45,620
So we just redefined the model again and I'm calling model that fit everything looks the same except

118
00:08:45,620 --> 00:08:54,260
now I'm going to add in a couple more lines here we'll say callback parameter or callbacks is equal

119
00:08:54,260 --> 00:08:54,670
to.

120
00:08:54,710 --> 00:09:00,770
And you actually pass this in as a list even if it's just one and you pass in that early stop callback

121
00:09:01,930 --> 00:09:03,500
so go ahead and run this.

122
00:09:03,550 --> 00:09:10,450
And now it's going to happen is it's going to attempt to run on 600 epochs unless the early stop is

123
00:09:10,600 --> 00:09:11,080
triggered.

124
00:09:11,080 --> 00:09:16,300
And in this case note that the early stop was triggered and if you scroll down here it stopped training

125
00:09:16,390 --> 00:09:17,300
after 81.

126
00:09:17,380 --> 00:09:19,420
So it has that early stopping call.

127
00:09:19,450 --> 00:09:20,170
So that's nice.

128
00:09:20,170 --> 00:09:22,220
Now we know that 600 was too much.

129
00:09:22,230 --> 00:09:28,090
What's also nice about this is you can now with early stomping to some arbitrarily large number of epochs

130
00:09:28,420 --> 00:09:32,320
and then indicate that you want it to stop early with this callback.

131
00:09:32,320 --> 00:09:37,420
So now you have to worry too much about choosing the correct number for epochs since callbacks with

132
00:09:37,450 --> 00:09:38,020
early stop.

133
00:09:38,080 --> 00:09:40,210
We'll take care of that for you automatically.

134
00:09:40,210 --> 00:09:47,560
Let's now check out that model loss so we'll say model loss is equal to this pan this data frame call

135
00:09:48,160 --> 00:09:55,570
on Model history the history and then we will say model loss plot.

136
00:09:55,570 --> 00:09:57,160
Go ahead and run this.

137
00:09:57,550 --> 00:10:03,760
And this is exactly the kind of plot that we want to see or loss and validation loss are both beginning

138
00:10:03,760 --> 00:10:06,810
to go down and right as they begin to spread out.

139
00:10:06,820 --> 00:10:10,210
That's probably were a good indication of where we should stop training.

140
00:10:10,210 --> 00:10:12,230
So notice this flattening out.

141
00:10:12,250 --> 00:10:13,580
That's OK behavior.

142
00:10:13,590 --> 00:10:18,670
Well we want to prevent is validation lost beginning to increase and that's what was happening so early

143
00:10:18,670 --> 00:10:20,620
stopped was triggered.

144
00:10:20,620 --> 00:10:21,350
All right.

145
00:10:21,490 --> 00:10:27,210
So the third thing we can do to try to help prevent overfishing is add in dropout layers.

146
00:10:27,370 --> 00:10:32,940
So dropout layers will essentially turn off a percentage of neurons randomly.

147
00:10:33,010 --> 00:10:39,670
So let's come back up here and I'm going to copy and paste my model again to make sure I don't accidentally

148
00:10:39,880 --> 00:10:47,740
keep training my old model so there's my model again and what I'm going to do is I'm also you can do

149
00:10:47,740 --> 00:10:49,930
this in the same cell or in the cell above it.

150
00:10:50,110 --> 00:10:57,500
We will say from tensor flow that carries that layers import dropout with technically already than this

151
00:10:57,510 --> 00:11:02,570
I just want to clarify that the drop out call comes from Carousel layers and you should have already

152
00:11:02,570 --> 00:11:05,230
imported this before but go ahead just do it again.

153
00:11:05,390 --> 00:11:11,450
And what we're going to do is after each of these two dense layers we will add in the drop out calls

154
00:11:11,450 --> 00:11:18,390
a model dot add and then we say drop out and then the main parameter you choose will drop out.

155
00:11:18,390 --> 00:11:23,700
You can do shift tab here and you'll notice that the main thing is basically raped and the rate is the

156
00:11:23,730 --> 00:11:29,880
probability that you're going to randomly turn off the actual neurons.

157
00:11:29,880 --> 00:11:34,310
So it's the fraction of which your randomly turning them off.

158
00:11:34,320 --> 00:11:41,010
So if you put a zero that means your taking zero percent of the neurons and randomly turning them off

159
00:11:41,130 --> 00:11:45,560
during training if you put a one here you typically would never do that.

160
00:11:45,570 --> 00:11:50,190
But that basically means that 100 percent of the neurons are going to be turned off randomly for each

161
00:11:50,190 --> 00:11:51,340
batch of training.

162
00:11:51,480 --> 00:11:55,980
So is a really common value is somewhere between zero point two and zero point five.

163
00:11:56,160 --> 00:12:02,130
And essentially that means is half the neurons during each batch essentially each batches one entire

164
00:12:02,160 --> 00:12:02,930
epoch of training.

165
00:12:02,940 --> 00:12:09,000
In our case because we haven't specified it that size half of those neurons in this layer of 30 are

166
00:12:09,000 --> 00:12:10,190
going to be turned off.

167
00:12:10,290 --> 00:12:13,170
So their weights and biases won't be getting updated.

168
00:12:13,170 --> 00:12:15,560
So we'll go ahead and put that here as well.

169
00:12:16,550 --> 00:12:20,960
And that means again about half of these neurons are going to be turned off randomly.

170
00:12:20,990 --> 00:12:26,830
So it's not the same neurons each time it's a random sub selection of 50 percent of the neurons.

171
00:12:26,870 --> 00:12:33,050
OK so that each neuron has essentially a 50 percent probability of being turned off during each batch.

172
00:12:33,080 --> 00:12:34,660
So go ahead and rerun this.

173
00:12:34,670 --> 00:12:42,230
So we read the fine our model and then we'll use this in combination with drop out so we can still retain

174
00:12:42,230 --> 00:12:49,190
the same early stopping here but I'm going to copy and paste the contents of this model that fit.

175
00:12:49,340 --> 00:12:53,830
We still have our early stopping and now we've added in these dropouts.

176
00:12:53,840 --> 00:12:57,030
So both of these things should really help prevent overfishing.

177
00:12:57,080 --> 00:13:02,360
We'll go ahead and run this and we should expect this to run on all 600 epochs.

178
00:13:02,390 --> 00:13:07,070
So go ahead and just wait a little bit and eventually it should stop running.

179
00:13:07,070 --> 00:13:11,960
Notice it did run for a little bit longer and that's actually good because it means it's still learning

180
00:13:11,990 --> 00:13:13,640
even on those further epochs.

181
00:13:13,670 --> 00:13:16,530
And that's due to the fact of these dropout layers.

182
00:13:16,580 --> 00:13:26,230
So let's go ahead and analyze now these losses here will say moral loss is equal to PD data frame

183
00:13:29,000 --> 00:13:33,880
model history and then we'll go ahead and plot this out.

184
00:13:35,590 --> 00:13:39,550
And this is even better behavior in fact this is absolutely fantastic.

185
00:13:39,550 --> 00:13:45,520
Note that the training loss and the validation loss are both quickly going down and they essentially

186
00:13:45,520 --> 00:13:47,210
are flattening out at the same rate.

187
00:13:47,210 --> 00:13:49,480
This is exactly the kind of behavior we want to see.

188
00:13:49,480 --> 00:13:52,460
This is much improved over what we saw earlier.

189
00:13:52,600 --> 00:13:59,980
Recall our original plot here where even at that set of epochs we were already clearly over fitting.

190
00:13:59,980 --> 00:14:06,430
So no adding in the early stopping and adding those dropout layers has significantly increased performance.

191
00:14:06,430 --> 00:14:11,620
So let's do now a full evaluation on our classes.

192
00:14:11,620 --> 00:14:17,620
So recall that we're performing a classification task so we're predicting essentially either a zero

193
00:14:17,710 --> 00:14:18,850
or one.

194
00:14:19,330 --> 00:14:24,400
And the way this works of chorus is instead of saying models that predict we actually now say model

195
00:14:24,400 --> 00:14:35,170
predict underscore classes we pass in our test dataset and it will end up showing you the classes it

196
00:14:35,170 --> 00:14:41,140
predicts for the X test dataset and recall that even if you had some new tumor with all these features

197
00:14:41,200 --> 00:14:43,210
it's still just predict classes.

198
00:14:43,210 --> 00:14:49,860
A new data point is essentially the exact same thing as a test set so then we'll go in and say these

199
00:14:49,860 --> 00:14:58,080
are our predictions and now let's go ahead and say from S.K. learn that metrics import and there's two

200
00:14:58,080 --> 00:15:05,300
main things we import for a classification problem and that is a classification report and they confusion

201
00:15:05,300 --> 00:15:08,990
matrix and definitely check out the machine learning theory lectures.

202
00:15:08,990 --> 00:15:13,970
If you have any questions on things like accuracy precision recall or F1 score we've actually already

203
00:15:13,970 --> 00:15:21,420
covered what those represent so we'll go in and print out our classification report and this takes in

204
00:15:21,420 --> 00:15:22,260
white true.

205
00:15:22,350 --> 00:15:24,040
In that case that's why test.

206
00:15:24,140 --> 00:15:27,820
And we directly compare against predictions.

207
00:15:27,870 --> 00:15:31,220
So go ahead and run that and we can see the results here.

208
00:15:31,230 --> 00:15:38,490
So notice we're getting very good performance and we can check the performance by printing out our confusion

209
00:15:38,490 --> 00:15:44,410
matrix showing the comparison of white test versus our predictions.

210
00:15:44,660 --> 00:15:50,510
And that essentially shows that our network only misclassified one point in our test set.

211
00:15:50,510 --> 00:15:51,950
Yours may be slightly different.

212
00:15:51,950 --> 00:15:57,710
You may mis classify a few more specific sets especially if you're using a different random split than

213
00:15:57,710 --> 00:15:58,120
us.

214
00:15:58,220 --> 00:16:02,690
But overall overall you should have gotten better than zero point nine five.

215
00:16:02,690 --> 00:16:05,380
Performance on precision and recall.

216
00:16:05,440 --> 00:16:06,000
Okay.

217
00:16:06,170 --> 00:16:10,490
So you can also then check out the accuracy here we're ninety nine percent accuracy and we're doing

218
00:16:10,490 --> 00:16:16,340
fantastic on precision and recall and recall that here that accuracy is a good metric because we saw

219
00:16:16,340 --> 00:16:21,170
that we had relatively balanced classes they were perfectly balanced but they weren't extremely unbalanced

220
00:16:21,230 --> 00:16:21,700
either.

221
00:16:21,800 --> 00:16:25,590
And that's what this count plot of the actual label was for.

222
00:16:25,640 --> 00:16:26,360
All right.

223
00:16:26,360 --> 00:16:30,560
So now we have more tools in our arsenal for deep learning.

224
00:16:30,590 --> 00:16:36,590
We've understood now that we can add in dropout layers and we can also use early stopping to not have

225
00:16:36,590 --> 00:16:39,610
to worry about the number of epochs that we're training for.

226
00:16:39,650 --> 00:16:44,720
So lots and lots of different things we're going to keep adding to our toolkit to become better practitioners

227
00:16:44,840 --> 00:16:47,210
of deep learning of tensor flow.

228
00:16:47,210 --> 00:16:47,750
Okay.

229
00:16:48,050 --> 00:16:48,590
Thanks.

230
00:16:48,620 --> 00:16:49,730
And I'll see you at the next lecture.
