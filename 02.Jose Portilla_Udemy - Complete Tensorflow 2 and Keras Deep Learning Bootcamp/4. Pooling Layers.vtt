WEBVTT
1
00:00:05.830 --> 00:00:06.990
Welcome back everyone.

2
00:00:07.090 --> 00:00:11.650
In this lecture we're going to discuss pulling layers which is the last theoretical concept we need

3
00:00:11.650 --> 00:00:18.520
to cover before jumping in and cutting out our own compositional neural networks even with local connectivity

4
00:00:18.520 --> 00:00:23.350
occurring in this convolution of layers when dealing with color images and possibly ask our network

5
00:00:23.350 --> 00:00:26.220
for tens or hundreds of filters which is not uncommon.

6
00:00:26.260 --> 00:00:33.150
We still have a huge amount of parameters we can use pooling layers to actually reduce this pulling

7
00:00:33.150 --> 00:00:35.900
layers except convolution layers as input.

8
00:00:35.940 --> 00:00:40.890
Here we see a very simple example of fitting in direct input images to a conversational air and then

9
00:00:40.890 --> 00:00:43.610
the result of the compositional error to the pulling layer.

10
00:00:43.610 --> 00:00:48.820
And as we just discussed the convolution layer has many filters and then a fair dealing of color images.

11
00:00:48.900 --> 00:00:54.430
There's a filter per color channel so we get very large sensors here in this compositional layer.

12
00:00:54.540 --> 00:00:59.880
And even if there is still local connectivity to go from input to convolution layer we still have a

13
00:00:59.880 --> 00:01:05.450
lot of parameters so as I mentioned there convolution players will often have many filters.

14
00:01:05.580 --> 00:01:07.350
Here we just have a single filter being shown.

15
00:01:07.350 --> 00:01:12.360
But realistically we have many filters and then a filter per color channel and we think of these as

16
00:01:12.360 --> 00:01:16.700
these large tensor objects and we want to do is reduce this.

17
00:01:16.770 --> 00:01:22.650
So let's just take a single filter and see how well we would apply a pooling layer to the single filter.

18
00:01:22.650 --> 00:01:25.500
And eventually this will expand to many filters.

19
00:01:25.500 --> 00:01:31.350
Now there's different types of pulleys layers and they use different sub sampling or down sampling techniques

20
00:01:31.740 --> 00:01:34.370
which is often what people also call pulling layers.

21
00:01:34.380 --> 00:01:39.830
They'll call them sub sampling or down sampling layers and you'll see why in just a second so we're

22
00:01:39.830 --> 00:01:44.830
going to do is reduce the size of this four by four filter using sub sampling.

23
00:01:44.910 --> 00:01:50.550
So what we're gonna do here is we're going to use the max pulling layer and what we have to decide on

24
00:01:50.640 --> 00:01:56.550
is the window size and then the stride length or stride count and what we're going to do is essentially

25
00:01:56.820 --> 00:02:01.100
very similar to the same way we apply an image Col or image filter on top of an image.

26
00:02:01.260 --> 00:02:04.130
We apply this pooling window on top of this filter.

27
00:02:04.350 --> 00:02:10.620
So we have this two by two window and we're going to Australia to pass it along this filter and then

28
00:02:10.680 --> 00:02:12.520
grab the max values here.

29
00:02:12.580 --> 00:02:18.870
Is Max pulling so out of 1 3 2 and 4 the max values for and continue with this.

30
00:02:18.880 --> 00:02:22.890
This is the max value of nine and this four by four or two by two.

31
00:02:23.160 --> 00:02:26.430
And this two by two window we get again max value of nine.

32
00:02:26.610 --> 00:02:27.800
And then over here on the bottom right.

33
00:02:27.810 --> 00:02:29.830
The max value is three.

34
00:02:29.850 --> 00:02:35.520
And while we do lose some information and doing this you can see that the general behavior has actually

35
00:02:35.550 --> 00:02:36.760
still been kept.

36
00:02:36.780 --> 00:02:43.470
The general information of the top left and bottom right is that those values or along that diagonal

37
00:02:43.740 --> 00:02:48.690
seemed to be less than the diagonals going from bottom left to top right.

38
00:02:48.690 --> 00:02:55.150
So we actually still get to keep that information except now we're dealing with just four parameters

39
00:02:55.180 --> 00:02:57.810
instead of the previous 16 parameters.

40
00:02:57.880 --> 00:03:02.830
So we've greatly reduced number of parameters here while still being able to keep the general information

41
00:03:04.350 --> 00:03:05.550
with average pulling.

42
00:03:05.550 --> 00:03:10.500
You did the exact same process except in this case instead of taking the max value you just average

43
00:03:10.530 --> 00:03:17.240
out those values so you can tell that this would greatly reduce our number of parameters.

44
00:03:17.340 --> 00:03:23.910
Which is why we feed in convolution layers into pooling layers this pooling layer will end up removing

45
00:03:23.970 --> 00:03:30.460
a lot of information and even a small pooling kernel of two by two a frustrated two removes about 75

46
00:03:30.510 --> 00:03:36.480
percent of the data that's input it into it however hopefully those general trends will still be true

47
00:03:36.660 --> 00:03:42.740
throughout the pooling layer and other really common technique to try to help out with the training

48
00:03:42.740 --> 00:03:48.370
time and over fitting problems a conversational neural network could face is the dropout layer.

49
00:03:48.370 --> 00:03:53.270
I've already talked a little bit about this but dropout can be thought of as a form of regularization

50
00:03:53.330 --> 00:03:58.910
to prevent overfishing and the way it works is during training units are randomly dropped which essentially

51
00:03:59.090 --> 00:04:04.340
just means you turn them off and what you do is you provide a percentage start between 0 and 1.

52
00:04:04.430 --> 00:04:10.070
You can say something like zero point five and what that means is as you go through training randomly

53
00:04:10.070 --> 00:04:15.620
50 percent of those neurons in that layer are going to be turned off so they don't over fit too much

54
00:04:15.620 --> 00:04:18.750
to the actual training data.

55
00:04:18.760 --> 00:04:23.210
So again this helps and prevents units from CO adapting too much.

56
00:04:23.300 --> 00:04:28.050
Now there's also I should point out some really famous convolution all neural network architectures.

57
00:04:28.250 --> 00:04:35.020
There's at five Alex net a Google net or google it resonate and you can check out the resource links

58
00:04:35.020 --> 00:04:39.910
to papers discussing these architectures though it's really cool now is given what you know about the

59
00:04:39.910 --> 00:04:44.950
theory behind compositional neural networks you can now take a look at these images that describe the

60
00:04:44.950 --> 00:04:47.790
actual compositional now networks and understand what's happening.

61
00:04:47.870 --> 00:04:53.740
They're essentially just different order rings of either a pooling layer or a convolutions layer or

62
00:04:53.740 --> 00:05:00.760
a densely fully connected layer etc. It's just the size of them what order they belong in and that is

63
00:05:00.760 --> 00:05:02.770
the network itself.

64
00:05:02.860 --> 00:05:08.180
So you can see here an example of Alex net and you can also see here how they visualize the convolution

65
00:05:08.200 --> 00:05:14.730
layers and as you get further and further along the network they begin to learn more complex patterns.

66
00:05:14.890 --> 00:05:20.110
And so here again is Alex net and you can see here we have Max pulling layers along with some dense

67
00:05:20.110 --> 00:05:22.560
layers there's also convolution layers et cetera.

68
00:05:22.660 --> 00:05:27.940
It's just the size and order and how many layers the side to use that essentially makes up these famous

69
00:05:27.940 --> 00:05:28.810
architectures.

70
00:05:28.810 --> 00:05:31.750
They can easily look up online.

71
00:05:31.890 --> 00:05:35.780
Now keep in mind convolution only one that networks can have all types of architectures.

72
00:05:35.790 --> 00:05:40.770
We showed the example of going from input to convolution the pulling layer but it's also really common

73
00:05:40.770 --> 00:05:45.330
to feed compositional layers into each other into a pulling layer etc..

74
00:05:45.390 --> 00:05:50.340
Or maybe you decide to go convolution pulling convolution pulling and that works really well for your

75
00:05:50.340 --> 00:05:51.260
images.

76
00:05:51.360 --> 00:05:58.230
There's really no wrong way to run these experiments of what accomplished on your own that work should

77
00:05:58.230 --> 00:06:03.660
look like the best way to figure out what the best network for you is is to just try different combinations

78
00:06:03.990 --> 00:06:10.420
and then use your metrics to decide which networks worked better than others.

79
00:06:11.720 --> 00:06:17.060
Now keep in mind at the end of all these networks you're going to have some sort of function that fully

80
00:06:17.060 --> 00:06:22.070
connects the results from the previous layer and then has an output layer which has the same number

81
00:06:22.070 --> 00:06:24.230
of neurons as a number of classes.

82
00:06:24.230 --> 00:06:28.490
So here we have a probably the simplest compositional neuron network you can have it just go from input

83
00:06:28.790 --> 00:06:35.100
to convolution the pulling to some sort of fully connected layer which then leads to the output okay.

84
00:06:35.260 --> 00:06:40.960
So now we learned about convolution layers and pulling layers and the way these networks all work together

85
00:06:41.320 --> 00:06:45.540
let's go ahead and finally coat out our own convolution neural network.

86
00:06:45.580 --> 00:06:46.120
I'll see you there.
