1
00:00:05,620 --> 00:00:06,940
Welcome back everyone.

2
00:00:06,940 --> 00:00:12,540
Previously we just saw how to run a simple recurrent neural network on our sine wave theta.

3
00:00:12,550 --> 00:00:17,890
Let's go ahead and check out how the performance compares to using Ellis teams.

4
00:00:17,950 --> 00:00:25,180
We also saw that it can take a long time to train these recurrent neural networks as we saw up here.

5
00:00:25,180 --> 00:00:29,350
And we also know that it could get noisy as we train for more more epochs.

6
00:00:29,350 --> 00:00:34,960
So let's introduce how we can use early stopping in conjunction with the fact that we're fitting to

7
00:00:34,960 --> 00:00:40,330
a generator because passing in the validation data in our case we need to pass it in in the same batch

8
00:00:40,330 --> 00:00:46,210
shape as a generator is doing so essentially to create two generators one for our training data and

9
00:00:46,210 --> 00:00:52,470
one for our validation or test data to do this we'll start off by setting up our early stopping just

10
00:00:52,470 --> 00:01:03,430
as before we'll say from tensor flow Dr. Harris that callbacks import early stopping and we'll create

11
00:01:03,430 --> 00:01:08,940
an early stop variable just before by saying early stopping in our case we're going to also going to

12
00:01:08,940 --> 00:01:15,990
monitor that validation loss and we can decide on a patients basically how many epochs are you going

13
00:01:15,990 --> 00:01:23,880
to keep waiting until this early stop actually takes to effect and for recurring neural networks.

14
00:01:23,880 --> 00:01:28,950
I would recommend a higher patients and just patients equals zero because they can get pretty noisy

15
00:01:28,950 --> 00:01:29,550
sometimes.

16
00:01:29,550 --> 00:01:34,830
So it's really nice to wait a couple more epochs just to make sure that we're not in a noisy territory

17
00:01:34,860 --> 00:01:36,970
and then going back down with our loss.

18
00:01:37,740 --> 00:01:40,230
Okay so there's are early stopping mechanism.

19
00:01:40,230 --> 00:01:43,670
Now we need to do is create a validation generator.

20
00:01:44,010 --> 00:01:52,110
So I will say validation generator is equal to and I'm going to use the same time series generator as

21
00:01:52,110 --> 00:01:58,890
before except this time it's our scale test data that's the source of the X in our scale test data that's

22
00:01:58,890 --> 00:02:06,930
the source of the Y and then I need to define length equal to length and then batch size is also equal

23
00:02:06,930 --> 00:02:08,350
to 1.

24
00:02:08,400 --> 00:02:14,400
Now pay attention to what happens when I try to just run this as is I will get an error and this is

25
00:02:14,520 --> 00:02:17,340
a really common error especially for beginners.

26
00:02:17,340 --> 00:02:21,870
So they set everything up just that with the training generator and they think well what's actually

27
00:02:21,870 --> 00:02:22,860
going on here.

28
00:02:22,890 --> 00:02:30,630
Well here's the problem right now our validation set is essentially looking at the exact same length

29
00:02:31,110 --> 00:02:34,040
as the entirety of our test set.

30
00:02:34,110 --> 00:02:43,440
So what needs to happen is this scaled test dataset must be greater than the length chosen for our batches.

31
00:02:43,440 --> 00:02:49,200
And that's essentially a sacrifice we have to make in order to actually run this validation generator.

32
00:02:49,260 --> 00:02:55,440
And the reason again we're getting this error is because right now it's trying to essentially follow

33
00:02:55,590 --> 00:02:57,750
this protocol and it's going to be disallowed.

34
00:02:57,750 --> 00:03:04,500
You can't have your start index plus the length of your training batch equal to 50 when our end index

35
00:03:04,530 --> 00:03:10,770
is essentially 1 short of it because our length of the batch is the exact same size as our test set

36
00:03:11,070 --> 00:03:14,820
which doesn't make sense we're essentially missing that future singular y point.

37
00:03:15,300 --> 00:03:21,410
So what we'll have to do is also redefine our original generator to have a shorter length.

38
00:03:21,840 --> 00:03:27,680
So we're going to have to and you can do this in another cell in the same cell but we're going to say

39
00:03:27,680 --> 00:03:31,080
length it can't be the same size or scale test data.

40
00:03:31,280 --> 00:03:36,950
So previously our scale test data that was going to be a length of 50 we'll go ahead and shorten it

41
00:03:36,950 --> 00:03:41,660
by one to make sure everything's OK so now we'll say generator.

42
00:03:41,660 --> 00:03:48,140
And this is now our training generator is a time series generator passing our skilled training data

43
00:03:49,460 --> 00:03:59,070
as a source of our X and Y and then length is equal to length and the batch size is one.

44
00:03:59,330 --> 00:04:07,790
And now that the length of our batches is shorter than our scale test set we should be OK and essentially

45
00:04:07,790 --> 00:04:13,760
what the validation generator is going to do is going to keep testing on that test range as we actually

46
00:04:13,760 --> 00:04:14,660
predict.

47
00:04:14,660 --> 00:04:18,110
So now what it can do is take forty nine points and predict.

48
00:04:18,110 --> 00:04:22,670
Point number 50 and keep that in mind that technically we're actually just checking the accuracy of

49
00:04:22,670 --> 00:04:28,100
one of these points because of how close our test data is to our length.

50
00:04:28,100 --> 00:04:33,230
If we had it as 50 that wouldn't make sense for the validation set because our validation set is only

51
00:04:33,230 --> 00:04:33,790
50 long.

52
00:04:33,800 --> 00:04:38,540
We will need that fifty first point to actually check against which is why we were getting that error.

53
00:04:38,540 --> 00:04:43,730
So again make sure that if you start creating these validation generators the length here of this batch

54
00:04:43,940 --> 00:04:47,750
has to be at least one shorter than your test data.

55
00:04:47,750 --> 00:04:51,020
Otherwise you'll be missing that predicted point.

56
00:04:51,020 --> 00:04:51,540
OK.

57
00:04:51,710 --> 00:04:54,750
So now that that's ready to go we have our generators in place.

58
00:04:54,800 --> 00:04:57,170
Let's go ahead and create our models.

59
00:04:57,200 --> 00:05:04,160
So I'm going to just copy paste the same model we created before I mean comet out these previous test

60
00:05:04,160 --> 00:05:14,650
predictions and scale data will come back here grab our model so I will copy this scroll all the way

61
00:05:14,650 --> 00:05:21,250
down here paste it in and we're we're going to do here is the only thing we need to do is during our

62
00:05:21,280 --> 00:05:25,930
first step we need to add in the fact that we're producing a validation generator.

63
00:05:25,930 --> 00:05:33,000
The other thing we're going to do is that of a simple Arnon call we'll call else team we'll go ahead

64
00:05:33,090 --> 00:05:41,750
and run that and then we'll say model fit generator and then say generator.

65
00:05:41,800 --> 00:05:46,450
And in this case you can make epochs pretty large because we're working on this validation generator

66
00:05:47,080 --> 00:05:56,700
that we can say our validation data is equal to this validation generator which is nice and then we

67
00:05:56,700 --> 00:06:03,090
just have to make sure to add in that callback that we just defined by saying callbacks is equal to

68
00:06:03,210 --> 00:06:08,040
and in the list we just pass an early stop and then we'll go ahead and run this.

69
00:06:08,040 --> 00:06:12,040
So we set it for 20 epochs hopefully doesn't need to train for actually 20 epochs.

70
00:06:12,150 --> 00:06:15,230
I'm going to fast forward in time until this is done training.

71
00:06:15,240 --> 00:06:15,620
OK.

72
00:06:15,630 --> 00:06:18,850
So I finished training this they only had a train for six epochs.

73
00:06:18,870 --> 00:06:24,570
Let's go ahead and run our evaluation on the test set just as we did before and we can use the exact

74
00:06:24,570 --> 00:06:26,140
same code for this.

75
00:06:26,310 --> 00:06:34,670
So we'll come up here reset our test predictions go ahead and copy this come back down here evaluate

76
00:06:34,670 --> 00:06:40,790
the test predictions for that range and the other thing we're also going to do is make sure that we

77
00:06:41,090 --> 00:06:44,660
do the inverse transform for our test predictions.

78
00:06:44,660 --> 00:06:52,050
So I'm going to run this just before and essentially I just copy these three lines from our notebook.

79
00:06:52,160 --> 00:06:56,810
But it's the exact same mindset that before we'll say true predictions is equal to the inverse transparent

80
00:06:56,830 --> 00:06:58,130
this test predictions.

81
00:06:58,130 --> 00:07:02,630
I'm going to overwrite my current test predictions to be true predictions but we can do is go ahead

82
00:07:02,630 --> 00:07:09,180
and call this Ellis time predictions is equal to true predictions and then we'll run this and we'll

83
00:07:09,210 --> 00:07:11,780
have three columns.

84
00:07:12,000 --> 00:07:19,980
And tonight I can see the predictions from my normal aren't in the predictions from the Ellis team here

85
00:07:20,040 --> 00:07:21,000
in green.

86
00:07:21,060 --> 00:07:26,010
And we can see that the green tends to be performing really quite well towards the end although it's

87
00:07:26,100 --> 00:07:28,230
overshooting here in the middle.

88
00:07:28,230 --> 00:07:33,420
And that is also kind of an artifact of the fact that we're essentially really just focusing on that

89
00:07:33,420 --> 00:07:38,940
last and prediction point which makes sense given the way that we're using a batch length of forty nine

90
00:07:38,940 --> 00:07:40,440
and our test set was 50.

91
00:07:40,440 --> 00:07:48,540
So it actually might be better to either increase the test data and keep the length of 49 or 50 or keep

92
00:07:48,540 --> 00:07:57,540
the test data at 50 and then lower the actual length of that batch size so here are all our comparisons

93
00:07:57,870 --> 00:08:01,360
against the actual data itself.

94
00:08:01,390 --> 00:08:05,760
And now let's go ahead and see how it works if we were to forecast this into the future.

95
00:08:05,760 --> 00:08:09,450
So let's imagine that I want to actually forecast this beyond 50.

96
00:08:09,450 --> 00:08:14,140
Recall that our original data frame if I plot the data out it only goes up to 50.

97
00:08:14,220 --> 00:08:20,040
So let's see how we can forecast essentially a sine wave or something similar to it beyond that X is

98
00:08:20,040 --> 00:08:21,270
equal to 50.

99
00:08:21,330 --> 00:08:24,930
So what we should be doing here is I should be retraining on all my data.

100
00:08:25,410 --> 00:08:31,470
So I'm going to essentially copy and paste a couple of commands from the notebook.

101
00:08:31,470 --> 00:08:33,370
So this is all stuff we've seen before.

102
00:08:33,480 --> 00:08:40,380
I will scale all my data so fit transform on all my data because now I'm forecasting into the future

103
00:08:40,710 --> 00:08:44,940
and what I have to decide here is that I have to look either at this orange line or the screen line

104
00:08:45,000 --> 00:08:47,990
and decide you know what I'm satisfied with this performance.

105
00:08:48,000 --> 00:08:51,390
Let's go ahead and retrain and everything and forecast into the future.

106
00:08:51,420 --> 00:08:58,590
So this is me scaling everything so we have our full scale data and then we're going to do is we'll

107
00:08:58,590 --> 00:09:01,640
go ahead and create our generator.

108
00:09:01,980 --> 00:09:05,880
So we'll do this off the scaled full data now.

109
00:09:06,100 --> 00:09:10,780
Go ahead and create that generator and then we'll use the same model as before.

110
00:09:10,780 --> 00:09:13,030
So let's read the fine our model again.

111
00:09:13,030 --> 00:09:15,030
We'll go ahead and say models equal to sequential.

112
00:09:15,040 --> 00:09:18,800
Grab this guy come back down here.

113
00:09:19,270 --> 00:09:21,270
Define our model.

114
00:09:21,460 --> 00:09:24,610
And then finally let's go ahead and fit our model to the generator.

115
00:09:24,610 --> 00:09:34,060
So say model the fit generator and we'll say fit it to the generator and then previously it took if

116
00:09:34,060 --> 00:09:38,260
you look on the Ellis Tam data set here it took six epochs.

117
00:09:38,260 --> 00:09:42,730
Let's just go ahead and train for six epochs was the epochs is equal to six.

118
00:09:42,730 --> 00:09:48,600
Go ahead and run that and I'm going to fast forward in time until that's done training.

119
00:09:48,710 --> 00:09:49,040
OK.

120
00:09:49,040 --> 00:09:50,330
This is done training.

121
00:09:50,330 --> 00:09:59,700
So what I'm going to do is come back and use our same loop that we did earlier so we'll paste it here.

122
00:09:59,720 --> 00:10:01,850
Except now I'm not predicting on my test range.

123
00:10:01,940 --> 00:10:05,460
Instead I'm going to forecast.

124
00:10:05,750 --> 00:10:10,100
And here I get to decide how many spaces do I want to forecast into the future.

125
00:10:10,100 --> 00:10:13,900
So for i in range what am I actually going to forecast.

126
00:10:13,910 --> 00:10:16,520
So let's go ahead and forecast.

127
00:10:16,820 --> 00:10:22,850
Let's say twenty five points into the future and then what I'm going to do is instead of calling these

128
00:10:23,150 --> 00:10:29,030
test predictions these are really just forecasts and there's no way I can evaluate these truly because

129
00:10:29,030 --> 00:10:32,710
my original data set doesn't have anything to compare these values to.

130
00:10:32,840 --> 00:10:34,960
So we'll go ahead and run this.

131
00:10:35,750 --> 00:10:37,660
And now I have my forecast.

132
00:10:37,850 --> 00:10:45,410
So I have my original data frame and I need to take my forecast inverse it or invert the transformation.

133
00:10:45,470 --> 00:10:57,780
So let's say the forecast is equal to scalar dot inverse transform on my forecast and now that the forecast

134
00:10:57,870 --> 00:11:05,250
is inverted all I need to do is take my forecast and get an index for it that corresponds to the points

135
00:11:05,580 --> 00:11:08,250
that it was actually forecasting for.

136
00:11:08,250 --> 00:11:13,800
So I know that my original data frame if I take a look at it it ends at fifty point zero which means

137
00:11:13,860 --> 00:11:20,280
with a step size of point one here my very first x points or X index for my forecasting should be at

138
00:11:20,280 --> 00:11:21,510
fifty point one.

139
00:11:21,960 --> 00:11:23,520
So how do we actually see that.

140
00:11:23,520 --> 00:11:25,380
Well I'll just create a forecast index.

141
00:11:25,410 --> 00:11:35,830
Using that logic I'll say my forecast index is equal to NPR range starting at fifty point one.

142
00:11:35,830 --> 00:11:43,610
Go to in this case I have to think how many points that I actually predict into the future so if I do

143
00:11:43,610 --> 00:11:50,030
a little math here I know I predicted twenty five points into the future with a step size of zero point

144
00:11:50,030 --> 00:11:51,050
one.

145
00:11:51,050 --> 00:11:55,710
So that's going to be a total of 2.5 added to this guy.

146
00:11:55,730 --> 00:12:01,710
So that should be 50 to point six swaps.

147
00:12:01,720 --> 00:12:02,500
There we go.

148
00:12:02,500 --> 00:12:06,680
So that should be my X range with a step size of zero point one.

149
00:12:06,730 --> 00:12:08,480
So that's my forecast index.

150
00:12:08,590 --> 00:12:13,600
So let's make sure that we'll check the length of my forecast index and it's twenty five points which

151
00:12:13,600 --> 00:12:16,530
is the exact same length as my forecast.

152
00:12:16,540 --> 00:12:21,670
There just a little bit of math there to make sure those X's line up with my predicted y values and

153
00:12:21,670 --> 00:12:30,280
then we're going to do so simply plot it will say Keelty dot plot plot my original data it's index versus

154
00:12:30,340 --> 00:12:31,710
sine here.

155
00:12:31,810 --> 00:12:33,530
So that's my original data.

156
00:12:33,710 --> 00:12:42,630
And on the same plot we'll say PDT plot plot my forecast index versus my forecast.

157
00:12:42,820 --> 00:12:43,510
And there you have it.

158
00:12:43,510 --> 00:12:45,730
We can see those twenty five points.

159
00:12:45,820 --> 00:12:51,490
And the reason you see a big gap here from this point to this point is because these are two separate

160
00:12:52,270 --> 00:12:53,530
essentially series.

161
00:12:53,530 --> 00:12:56,590
So there's no line that automatically connects them here.

162
00:12:56,650 --> 00:13:03,190
However what you could do is bind these together using PD dot concatenation or contact and then it would

163
00:13:03,190 --> 00:13:05,720
just be one continuous data frame.

164
00:13:05,740 --> 00:13:06,010
All right.

165
00:13:06,550 --> 00:13:07,120
So that's it.

166
00:13:07,120 --> 00:13:13,200
We were successfully able to compare against a test set but also show you how to forecast into the future.

167
00:13:13,300 --> 00:13:20,710
Coming up next we're going to do is we are going to show you how to run all of this on a real time series

168
00:13:20,770 --> 00:13:21,890
data set.

169
00:13:21,910 --> 00:13:23,070
OK thanks.

170
00:13:23,110 --> 00:13:23,770
And I'll see you there.
