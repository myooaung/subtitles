1
00:00:05,400 --> 00:00:11,390
Welcome everyone to our first lecture in the solutions for these project exercise questions.

2
00:00:11,400 --> 00:00:14,420
We'll begin with the exploratory data analysis section.

3
00:00:14,430 --> 00:00:15,090
Let's get started.

4
00:00:15,490 --> 00:00:22,180
OK here I am at the exercise notebook and I start off by running the first couple of starter code cells.

5
00:00:22,350 --> 00:00:29,160
So that's importing the data that allows us to run our feature information function as well as loading

6
00:00:29,160 --> 00:00:31,900
in the actual data set that we'll be working with.

7
00:00:32,400 --> 00:00:34,070
So it looks like that's all loaded up.

8
00:00:34,260 --> 00:00:37,430
Next let's begin exploratory data analysis.

9
00:00:37,470 --> 00:00:42,270
So as I mentioned before it's always a good idea especially of classification problems to do account

10
00:00:42,270 --> 00:00:48,690
plot to explore the actual balancing of your labels.

11
00:00:48,690 --> 00:00:52,860
So we'll say S.A. count plot and we'll say lone status

12
00:00:56,030 --> 00:00:59,190
and say data is equal to the F.

13
00:00:59,270 --> 00:01:01,470
So that's how you can create a count plot here.

14
00:01:01,520 --> 00:01:05,510
And I would say this is an unbalanced or imbalanced problem.

15
00:01:05,510 --> 00:01:11,780
Notice that we have a lot more entries of people that fully pay off their loans than we have people

16
00:01:11,780 --> 00:01:13,080
that did not pay back.

17
00:01:13,100 --> 00:01:18,860
And this is really common for things like classification problems that have to do with fraud or spam.

18
00:01:18,910 --> 00:01:26,750
There's a lot less instances of fraud or spam than there are of legitimate actions such as a legitimate

19
00:01:26,780 --> 00:01:32,290
email or a legitimate credit card purchase or a legitimate loan where it was fully paid off.

20
00:01:32,300 --> 00:01:33,990
So that's something to keep in mind.

21
00:01:34,030 --> 00:01:39,680
And what that means is we can expect to probably do very well in terms of accuracy but our precision

22
00:01:39,680 --> 00:01:44,860
and recall are going to be the true metrics that we'll have to evaluate our model based off of.

23
00:01:44,930 --> 00:01:49,670
And we should expect to perform that well on those particular metrics due to the fact that we have a

24
00:01:49,670 --> 00:01:52,340
very imbalanced dataset here.

25
00:01:52,340 --> 00:01:57,920
So next we want to create a histogram of the loan amount column lots of different ways we can do this

26
00:01:58,290 --> 00:02:06,290
by the easiest way is to simply call a distribution plot on that column so we can call the F loan amount

27
00:02:06,290 --> 00:02:07,150
here.

28
00:02:07,280 --> 00:02:15,260
And since I just want the actual histogram I'll say Katie e is equal to False and if you just run that

29
00:02:15,490 --> 00:02:20,150
that basically gives you the basics of the histogram then you can begin playing around with things like

30
00:02:20,150 --> 00:02:21,190
the bins.

31
00:02:21,200 --> 00:02:25,670
So if you wanted more beans you can increase the number of beans there and you can also play around

32
00:02:25,670 --> 00:02:33,710
with things like size so you can always say Pulte figure fig size is equal to some tuple.

33
00:02:33,800 --> 00:02:37,360
So usually for his grams you want them long but a little shorter.

34
00:02:37,550 --> 00:02:39,700
So you get something that looks like this.

35
00:02:39,710 --> 00:02:40,480
OK.

36
00:02:40,700 --> 00:02:45,740
So lots different ways you can do that but essentially something to notice here is you see these spikes

37
00:02:45,740 --> 00:02:49,070
happening at these even money amounts which kind of make sense.

38
00:02:49,070 --> 00:02:54,440
So clearly these bean spikes are happening at something like an even ten thousand dollar alone instead

39
00:02:54,440 --> 00:02:59,150
of a spike at some random value like eight thousand three hundred and thirty three.

40
00:02:59,150 --> 00:03:04,010
So that's what these little spikes are essentially indicating that there are certain amounts that are

41
00:03:04,130 --> 00:03:06,220
basically standard loans.

42
00:03:06,260 --> 00:03:11,930
OK so let's go ahead and explore the correlation between the continuous feature variables so we can

43
00:03:11,930 --> 00:03:18,710
easily do this by simply just saying the F and then calculating the correlation as such.

44
00:03:18,710 --> 00:03:23,960
So just the simple method call we've seen this already a bunch of times throughout our lectures.

45
00:03:24,080 --> 00:03:27,080
We've also seen a little bit of how we can visualize it.

46
00:03:27,200 --> 00:03:37,130
So what we can visualize it is by calling S.A. heat map on this particular correlation and we can also

47
00:03:37,130 --> 00:03:40,340
say annotation is equal to true.

48
00:03:40,340 --> 00:03:46,940
So we have those actual links for you in case you're interested in those and I will go ahead and change

49
00:03:46,970 --> 00:03:56,020
the color mapping to be see map there this just because for me that's always a little clearer.

50
00:03:56,050 --> 00:04:01,390
So if you run this just by itself you'll get this kind of really shrunk down heat map so something can

51
00:04:01,390 --> 00:04:01,810
do.

52
00:04:01,870 --> 00:04:05,560
First off is expand on the size say Pulte figure.

53
00:04:05,800 --> 00:04:10,990
And this should always go before your seaborne command say fig size and let's make this quite a bit

54
00:04:10,990 --> 00:04:11,450
larger.

55
00:04:11,470 --> 00:04:13,140
Something like twelve by seven.

56
00:04:13,270 --> 00:04:16,450
You run that and it will be a lot more improved.

57
00:04:16,600 --> 00:04:21,610
But something to note here is that depending on your version of that plot lib you'll notice that the

58
00:04:21,610 --> 00:04:27,310
bottom and the top are actually kind of cut off here and you can check out the links we provided for

59
00:04:27,310 --> 00:04:29,290
you for help with resizing.

60
00:04:29,290 --> 00:04:34,450
So specifically this second one will actually talk about that little error and that's due to Matt polyp

61
00:04:34,750 --> 00:04:36,230
not playing well Seabourn.

62
00:04:36,400 --> 00:04:40,390
So the way you can edit that is by messing around with the Y limits.

63
00:04:40,480 --> 00:04:42,730
So there's lots of different solutions.

64
00:04:42,760 --> 00:04:48,970
So one way we show this in the solutions notebook ourselves is after we do the Seabourn call simply

65
00:04:48,970 --> 00:04:54,170
say t y limb and they say go from 10 to 0 or something like that.

66
00:04:54,400 --> 00:04:56,920
And that will stretch out the actual heat map.

67
00:04:56,940 --> 00:04:57,650
OK.

68
00:04:57,850 --> 00:05:02,920
So that's our heat map we can see the various relationships between the features and obviously you would

69
00:05:02,920 --> 00:05:10,340
get a perfect correlation along the diagonal so moving along here we're going to see is you should have

70
00:05:10,340 --> 00:05:14,210
noticed almost perfect correlation with this installment feature.

71
00:05:14,210 --> 00:05:15,430
So if we come back up here.

72
00:05:15,440 --> 00:05:21,790
Notice that the loan amount has a zero point nine five correlation with this installment.

73
00:05:21,800 --> 00:05:23,390
So that's quite interesting.

74
00:05:23,390 --> 00:05:28,490
So let's explore this feature further we want to make sure that we're not accidentally leaking data

75
00:05:28,550 --> 00:05:31,730
from our features into our label.

76
00:05:31,730 --> 00:05:36,380
So we always make sure that there's not a single feature that is a perfect predictor of the label because

77
00:05:36,680 --> 00:05:41,720
that basically indicates that it's not really a feature it's probably just some duplicate information

78
00:05:41,780 --> 00:05:43,490
that's very similar to the label.

79
00:05:43,520 --> 00:05:45,330
So let's go ahead and print that out.

80
00:05:45,380 --> 00:05:55,140
We'll say feature information on that installment so we go ahead and run this and the installment is

81
00:05:55,140 --> 00:05:57,390
the monthly payment owed by the bar.

82
00:05:57,390 --> 00:05:58,750
If the loan Originates.

83
00:05:58,770 --> 00:06:06,040
So keyword being if and then we also say feature info on the loan amount

84
00:06:09,340 --> 00:06:12,810
and this is the listed amount of the loan applied for by the bar.

85
00:06:12,850 --> 00:06:18,310
So it pretty much makes sense that the installments and the actual loan amount would be extremely correlated

86
00:06:18,640 --> 00:06:24,940
because they're essentially correlated by some sort of internal formula that this company uses which

87
00:06:24,940 --> 00:06:30,100
kind of makes sense if you loan someone out one million dollars you would expect that following some

88
00:06:30,100 --> 00:06:35,020
formula your payments your monthly payment instalments are going to be quite high and you'll probably

89
00:06:35,020 --> 00:06:40,060
use that same formula even if you loan someone a thousand dollars and then those payments will be likely

90
00:06:40,060 --> 00:06:41,590
correlated to be much less.

91
00:06:41,590 --> 00:06:48,760
So they're clearly using some sort of formula that is just a direct function of the loan amount to figure

92
00:06:48,760 --> 00:06:50,130
out what the installment should be.

93
00:06:50,170 --> 00:06:52,960
And we can always just do a scatter plot to confirm this.

94
00:06:52,960 --> 00:07:00,450
We can say S.A. scatter plot and we can view this high correlation.

95
00:07:00,450 --> 00:07:09,220
So we see X installment Y is equal to loan amount and then data is equal to the.

96
00:07:09,520 --> 00:07:13,480
So we run that and we'll be able to see these actual scatter plots.

97
00:07:13,480 --> 00:07:17,860
And you can do things like turn off the marker edge make Alpha a little lighter et cetera.

98
00:07:18,820 --> 00:07:24,640
OK so next we want to create a box plot showing the relationship between the loan status and the loan

99
00:07:24,700 --> 00:07:25,500
amount.

100
00:07:25,510 --> 00:07:31,540
So going to answer the question is there a relationship between maybe really expensive loans and not

101
00:07:31,540 --> 00:07:36,070
being able to pay them off or very low amount loans and then fully paying those off.

102
00:07:36,910 --> 00:07:40,560
So what we do is we simply say get a box plot

103
00:07:43,570 --> 00:07:54,370
on our loan status as the x axis and then the y axis will be our loan amount and our data still remains

104
00:07:54,370 --> 00:08:00,760
that data frame so this allows us to explore the relationship and in general it looks like that pretty

105
00:08:00,760 --> 00:08:03,620
similar charged off loans.

106
00:08:03,640 --> 00:08:11,200
On average you can see this box plot is slightly higher meaning that if our loan amount is higher we

107
00:08:11,200 --> 00:08:15,850
have a slight increase in the likelihood of it being charged off which again intuitively makes sense

108
00:08:15,850 --> 00:08:18,820
that it's harder to pay back larger loans than it is.

109
00:08:18,820 --> 00:08:21,360
Smaller loans so they're extremely similar here.

110
00:08:21,370 --> 00:08:25,780
So this isn't a key indicator of whether or not someone's going to pay off their loan.

111
00:08:25,780 --> 00:08:30,670
The actual amount they take off but there is a slight relationship there that we can see from this box

112
00:08:30,670 --> 00:08:37,100
plot and we can do this by just calculating summary statistics for the loan amount grouped by the loan

113
00:08:37,100 --> 00:08:38,720
status.

114
00:08:38,720 --> 00:08:49,130
So I can say the following I'll say the F group by loan status and then if I just grouped by loan status

115
00:08:50,180 --> 00:08:55,050
and then ask for describe it will show me this for all the columns.

116
00:08:55,100 --> 00:09:01,310
So notice here there's kind of a really large data frame when really all I'm interested in in this particular

117
00:09:01,310 --> 00:09:09,740
case this is what the questions asking for is the loan amount and this essentially shows us the quantitative

118
00:09:09,740 --> 00:09:12,530
numbers behind this box plot.

119
00:09:12,530 --> 00:09:17,000
So if you ever get a case like this that the box plot is a little hard to read you can always compare

120
00:09:17,000 --> 00:09:18,440
the averages here.

121
00:09:18,440 --> 00:09:25,210
So you can see the charged off average price is a little higher than the fully paid loan.

122
00:09:25,260 --> 00:09:25,790
OK.

123
00:09:25,910 --> 00:09:30,980
So again all this is indicating is the averages of the loans for people that aren't able to pay them

124
00:09:30,980 --> 00:09:35,360
back are slightly higher than the averages for people that do pay off their loans.

125
00:09:35,360 --> 00:09:36,870
That's what's in the care of the box plot.

126
00:09:36,920 --> 00:09:40,420
And if it's a little hard to read you can always just manually check this out.

127
00:09:40,490 --> 00:09:44,130
So that's what these tests are trying to get you to realize next.

128
00:09:44,140 --> 00:09:50,140
Let's go ahead and explore the great and so great columns that lending club attributes to the loans

129
00:09:50,320 --> 00:09:54,460
and then the first question is what are the unique possible grades and sub grades.

130
00:09:54,670 --> 00:09:56,630
This should be pretty straightforward.

131
00:09:56,710 --> 00:10:04,780
You can just simply grab the grade column and then ask for unique off of this and you should be able

132
00:10:04,780 --> 00:10:13,190
to do the same thing for the sub great column simply say unique and we can see right away that these

133
00:10:13,190 --> 00:10:18,960
sub grades basically contain the information of the actual grade itself because it contains the letter

134
00:10:18,960 --> 00:10:21,560
grade and then some sort of sub character.

135
00:10:21,630 --> 00:10:27,480
And if we ever wanted information on what it represents we can only say ft info and then pass on something

136
00:10:27,480 --> 00:10:28,920
like sub grade.

137
00:10:28,920 --> 00:10:32,530
And it will report back the lending club assigned loan sub grade.

138
00:10:32,530 --> 00:10:32,750
Okay.

139
00:10:33,910 --> 00:10:39,250
So we scroll down here and we want to create account plot per grade and set the hue to the loan status

140
00:10:39,250 --> 00:10:39,970
label.

141
00:10:40,060 --> 00:10:45,490
And this way we can see if there is differentiation between fully paying off your loan or having it

142
00:10:45,670 --> 00:10:55,700
be charged off based off your grade so we'll say S.A. count plot we'll say X is equal to grain.

143
00:10:57,330 --> 00:11:00,610
Data is our data frame and here the hue.

144
00:11:00,660 --> 00:11:03,240
We'll go ahead and have it be our lone status

145
00:11:06,780 --> 00:11:07,890
we run that.

146
00:11:08,040 --> 00:11:11,490
And here we can see the kind of a clear relationship.

147
00:11:11,640 --> 00:11:17,460
But what's a little hard to tell here is the ordering of the actual grades.

148
00:11:17,580 --> 00:11:22,200
So notice that we're starting with B and then going a c e d e f g.

149
00:11:22,200 --> 00:11:23,070
So it would be nice.

150
00:11:23,070 --> 00:11:27,690
And what we're gonna do in the next problem our next task is actually show you or have you figure out

151
00:11:27,720 --> 00:11:30,490
how to reorder these x axis ticks.

152
00:11:30,630 --> 00:11:38,100
But essentially what this is showing is the percentage of charged off loans looks like it's increasing

153
00:11:38,370 --> 00:11:40,320
as the letter grade gets higher.

154
00:11:40,320 --> 00:11:47,350
So it looks like the best customers are given a grade of a second best given a grade of B C D s etc.

155
00:11:48,300 --> 00:11:54,330
and we can do this by actually comparing the ratios here so let's take a further look at this.

156
00:11:54,380 --> 00:11:56,120
Let's actually do it by sub grade.

157
00:11:56,690 --> 00:12:01,460
So we may need to actually resize to try to get this plot but what I'm going to first do is get a count

158
00:12:01,460 --> 00:12:06,480
plot of these sub grades to see this distribution throughout the entire dataset.

159
00:12:06,590 --> 00:12:07,880
How many a ones do we have.

160
00:12:07,880 --> 00:12:09,750
How many a twos do we have etc..

161
00:12:09,920 --> 00:12:14,900
And we can see from the answer it looks like the majorities are a B's and C's which kind of makes sense

162
00:12:15,170 --> 00:12:19,180
because these are clearly the riskier loans because they're more likely to be charged off.

163
00:12:19,310 --> 00:12:25,820
Based off what we've seen here on the overall grades notice that the fully paid versus charged off rates

164
00:12:26,120 --> 00:12:30,220
almost look the same for someone in the G grade category.

165
00:12:30,260 --> 00:12:33,790
So how do we actually show this count plot per sub grade.

166
00:12:33,800 --> 00:12:45,190
Well we simply say S.A. that count plot and then we'll say X is equal to sub grade.

167
00:12:45,430 --> 00:12:52,990
Recall there's an underscore there and then our data is equal to def.

168
00:12:53,000 --> 00:12:56,240
Now if you just run this plot you'll get something that looks like this.

169
00:12:56,270 --> 00:12:58,400
So the first thing you should fix is the size of this plot.

170
00:12:59,090 --> 00:13:07,560
So do that by saying Pulte figure fig size is equal to that's going to make this told by four.

171
00:13:07,600 --> 00:13:08,350
Okay.

172
00:13:08,350 --> 00:13:10,820
So that takes care of the sizing.

173
00:13:10,870 --> 00:13:15,700
However what I want to be able to do is reorder that x axis.

174
00:13:15,790 --> 00:13:22,300
So if you do a little bit of research on the count plot in seaborne essentially just go to the seaborne

175
00:13:22,900 --> 00:13:28,690
API or tutorial page and then look up count plot say it'll be here in the categorical plots.

176
00:13:28,690 --> 00:13:33,970
You'll notice that there's actually an order parameter which is just the list of strings so that's the

177
00:13:33,970 --> 00:13:35,250
order you wanted in.

178
00:13:35,410 --> 00:13:36,860
Let's go ahead and figure that out.

179
00:13:37,330 --> 00:13:46,950
So we're going to do here is we'll say our sub grade order desired is equal to will come back up here

180
00:13:47,010 --> 00:13:52,110
and use what we did before where we printed out the actual unique sub grades.

181
00:13:52,110 --> 00:13:59,240
So we'll copy that and then we'll just sort them using basic Python so base Python has this sort of

182
00:13:59,240 --> 00:14:06,130
function and essentially what we're doing here is we resize the plot and now we have this list of the

183
00:14:06,130 --> 00:14:10,510
sub grade order which is this sorted call of the unique sub grades.

184
00:14:10,720 --> 00:14:17,780
And then I'll pass that in as my order here so I'll go and say so.

185
00:14:17,780 --> 00:14:19,130
Great order.

186
00:14:19,220 --> 00:14:19,850
Run that.

187
00:14:19,970 --> 00:14:22,190
And now you should see everything ordered.

188
00:14:22,190 --> 00:14:26,600
The last thing to note here is something I disliked is the color seemed to be too similar.

189
00:14:26,600 --> 00:14:33,290
Between a one or the eight groups and the G groups to then I just chose a palette that basically doesn't

190
00:14:33,290 --> 00:14:34,380
allow for that.

191
00:14:34,640 --> 00:14:40,910
And in my case after exploring the documentation on a map plot lib I like to call warm so it can hear

192
00:14:41,000 --> 00:14:45,260
the essentially better grades are bluer and the worse grades are redder.

193
00:14:45,280 --> 00:14:53,340
OK so here we can see that it essentially looks like F and G so grades don't get paid back that often.

194
00:14:53,340 --> 00:14:57,800
So you want to isolate those and recreate the count plot just for those upgrades.

195
00:14:57,840 --> 00:14:59,350
You also notice that appear.

196
00:14:59,360 --> 00:15:03,600
It also asked you to maybe feel free to play around the hue.

197
00:15:03,660 --> 00:15:10,110
So on this second plot we just had the lone status hue so we can kind of compare that as well so you

198
00:15:10,110 --> 00:15:21,210
can always do that by just coming up here and saying Hugh is equal to lone status and then you get that

199
00:15:21,210 --> 00:15:21,780
plot.

200
00:15:21,780 --> 00:15:26,020
So lots of information here that we can deem just from the visualization.

201
00:15:26,250 --> 00:15:29,510
And clearly these worst grade categories.

202
00:15:29,550 --> 00:15:34,590
It looks like the charged off rate is almost the same as the fully paid rate so it might be worth investigating

203
00:15:34,590 --> 00:15:36,780
if it's even worth giving people loans.

204
00:15:36,780 --> 00:15:42,030
If we're gonna grade them a G or an F and what we're gonna do here is we're essentially going to kind

205
00:15:42,030 --> 00:15:48,090
of zoom in on that little section of the plot and the way we're gonna do that is simply the exact same

206
00:15:48,090 --> 00:15:52,390
code but we're going to do a quick filter first using panties.

207
00:15:52,410 --> 00:15:57,250
So I'm going to essentially copy and paste this code come back down here

208
00:16:01,250 --> 00:16:09,620
paste it here and what I'll do here is say I just want f and g so I'll say F and G is equal to my data

209
00:16:09,620 --> 00:16:23,200
frame where my data frame grade is equal to g pipe operator or were the grade is equal to F and then

210
00:16:23,200 --> 00:16:26,410
I'll wrap these guys in parentheses to make sure I don't get an error

211
00:16:29,750 --> 00:16:35,180
and then the rest of these lines of code where we have d f I'll just replace that with F and G so we'll

212
00:16:35,210 --> 00:16:39,920
grab our sub great order there and we'll set our data there.

213
00:16:40,020 --> 00:16:45,680
Okay so all we're doing is essentially subset in the data frame and then doing the exact same plots

214
00:16:45,740 --> 00:16:54,450
as above so if we run that now we can see the fully paid status versus charge off status for these essentially

215
00:16:54,450 --> 00:16:55,930
worse sub grades.

216
00:16:55,960 --> 00:17:01,830
You'll notice that if you're graded G5 the likelihood is almost the same as fully paying off your loan

217
00:17:01,980 --> 00:17:05,510
versus being charged off on the loan okay.

218
00:17:05,520 --> 00:17:11,070
We have one more plot to create in order to create it we have to complete first this task which is create

219
00:17:11,100 --> 00:17:17,610
a new column called loan repaid which will contain a one at the loan status was fully paid and a zero.

220
00:17:17,610 --> 00:17:24,090
If it was charged off so right now our label column is such that it's strings and I want to change that.

221
00:17:24,090 --> 00:17:26,370
So essentially map to a 1 and 0.

222
00:17:26,520 --> 00:17:34,570
So lots of different ways we can do this but one way is to simply say my lone status.

223
00:17:34,760 --> 00:17:41,400
Go ahead and map the fully paid and I can just copy these.

224
00:17:41,500 --> 00:17:43,260
You can grab this source of a unique call.

225
00:17:43,450 --> 00:17:55,640
But go ahead and map fully paid to be one and then map charged off to be zero and then we wanted you

226
00:17:55,640 --> 00:18:03,500
to set this as a new column and we'll set this as a new column called Lone underscore repaid and this

227
00:18:03,500 --> 00:18:07,710
will actually be the label column that we use when working of tensor flow.

228
00:18:07,730 --> 00:18:12,320
So go ahead and run that and then you should be able to then view both of them.

229
00:18:12,320 --> 00:18:14,230
So let's go ahead and show that.

230
00:18:14,240 --> 00:18:20,420
So we have loan repaid comma loan status.

231
00:18:20,420 --> 00:18:22,730
Just see those two and we can see that it worked.

232
00:18:22,730 --> 00:18:23,570
So loan repaid.

233
00:18:23,600 --> 00:18:25,260
It's a one if it's got fully paid.

234
00:18:25,340 --> 00:18:25,840
It's a zero.

235
00:18:25,850 --> 00:18:27,100
If it was charged off.

236
00:18:27,170 --> 00:18:32,270
So now that allows us to complete our last visualization which we've actually already done in previous

237
00:18:32,270 --> 00:18:33,050
lectures.

238
00:18:33,050 --> 00:18:36,880
So it's technically a challenge task but there's a helpful link in case you need help.

239
00:18:37,490 --> 00:18:44,180
And what we wanted to do is essentially do this plot that shows which numeric features have the highest

240
00:18:44,180 --> 00:18:46,150
correlation with the actual label.

241
00:18:46,280 --> 00:18:50,700
And we did this in our classification tasks or in our classification lectures before.

242
00:18:50,700 --> 00:18:52,680
But let's go ahead and show you again how to do it.

243
00:18:52,760 --> 00:18:56,440
First it actually calculate those correlations.

244
00:18:56,450 --> 00:19:03,240
Next step is to only grab that loan repaid column after that.

245
00:19:03,280 --> 00:19:11,620
What you can do is a plot kind equals bar and that gives you the very basics of what this plot is doing.

246
00:19:11,620 --> 00:19:18,020
However one thing to notice is loan repaid is going to be included and it's not sorted.

247
00:19:18,040 --> 00:19:25,780
So what we can do here is before we call plot we'll go ahead and say sought those values saw underscore

248
00:19:25,780 --> 00:19:26,940
values.

249
00:19:27,370 --> 00:19:31,630
You plot that out and you get the sorted version here.

250
00:19:31,630 --> 00:19:36,060
However it makes sense that loan repaid is perfectly correlated for loan replace repaid.

251
00:19:36,100 --> 00:19:44,190
So we will go ahead and drop loan repaid and I don't need to specify axes because this is actually now

252
00:19:44,220 --> 00:19:49,610
a series from the correlation data frame run that.

253
00:19:49,730 --> 00:19:56,360
And now you will get back the exact same plot here so you can see that interest rate has essentially

254
00:19:56,360 --> 00:20:01,040
the highest negative correlation with whether or not someone's going to repay their loan which kind

255
00:20:01,040 --> 00:20:01,460
of makes sense.

256
00:20:01,460 --> 00:20:05,960
Maybe if you have a extremely high interest rate you're going to find it harder to pay off that loan.

257
00:20:05,960 --> 00:20:06,640
OK.

258
00:20:06,770 --> 00:20:08,750
So that concludes this.

259
00:20:08,780 --> 00:20:14,300
First section of the exercise where we just explore the data and perform visualizations.

260
00:20:14,330 --> 00:20:19,430
I would highly encourage you to not just do the visualizations here in the notebook but play around

261
00:20:19,450 --> 00:20:23,210
the data yourself and see if you can answer any questions that you have.

262
00:20:23,360 --> 00:20:27,950
Based off your domain knowledge and based off what features are interesting to you.

263
00:20:27,950 --> 00:20:33,740
Thanks and I'll see you at the next lecture where we continue with Section 2 on data pre processing.

264
00:20:33,770 --> 00:20:34,340
I'll see you there.
