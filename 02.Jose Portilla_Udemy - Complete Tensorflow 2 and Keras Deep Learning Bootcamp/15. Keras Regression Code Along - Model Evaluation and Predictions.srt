1
00:00:05,240 --> 00:00:09,590
Welcome back everyone to part three of our Caris regression coda long project.

2
00:00:09,710 --> 00:00:15,440
So we just in the previous lecture ended up training our model and fitting to that training set.

3
00:00:15,440 --> 00:00:20,780
Now it's time to explore and evaluation on not just our test data but also being able to predict the

4
00:00:20,780 --> 00:00:23,020
price of a new house given its features.

5
00:00:23,030 --> 00:00:23,700
Let's get started.

6
00:00:24,480 --> 00:00:29,190
OK here we are in the notebook where we left off last time we just finished training for those 400 epochs.

7
00:00:29,210 --> 00:00:33,900
Well I'm going to do now is explore what my model history looks like now.

8
00:00:33,900 --> 00:00:40,490
So recall we can get a history of those losses by saying model that history that history and it returns

9
00:00:40,490 --> 00:00:40,930
back.

10
00:00:40,940 --> 00:00:47,840
This dictionary however because we passed in the validation data tuple what I can now do is want to

11
00:00:47,840 --> 00:00:56,170
convert this to a data frame I not just get my loss on my training set but I also get this other variable

12
00:00:56,170 --> 00:00:59,850
called Val underscore loss and this is my loss on that test set.

13
00:00:59,860 --> 00:01:06,730
That validation data and now I can directly compare the loss on training versus the lost on test or

14
00:01:06,730 --> 00:01:11,980
validation in order to see if I'm over fitting to the training data on my model.

15
00:01:11,980 --> 00:01:14,930
And the best way to do that is by simply plotting these.

16
00:01:15,040 --> 00:01:25,240
So I will say losses is equal to that data frame and then I can say losses that plot and I can directly

17
00:01:25,240 --> 00:01:31,950
compare the plot behavior of my blue training loss versus my orange validation loss.

18
00:01:32,080 --> 00:01:38,170
And this is exactly the kind of signal we want where there is decrease in both the training loss and

19
00:01:38,170 --> 00:01:39,640
the validation loss.

20
00:01:39,640 --> 00:01:44,050
And then there is no increase so far in the validation set.

21
00:01:44,110 --> 00:01:47,690
And actually what that means is technically we could have continued training.

22
00:01:47,740 --> 00:01:51,450
Now you'll notice that towards the tail end we're actually not improving that much.

23
00:01:51,460 --> 00:01:57,490
So after 400 epochs it looks like we're kind of hovering around this particular lost value and the decreasing

24
00:01:57,610 --> 00:02:04,720
is happening much slower but because the validation loss is also going down that's an indicator that

25
00:02:04,720 --> 00:02:09,700
we could continue training without over fitting to our training data.

26
00:02:09,700 --> 00:02:14,800
If you saw this orange line began to spike after some of these epochs so it started to go up and up

27
00:02:14,800 --> 00:02:15,400
and up.

28
00:02:15,470 --> 00:02:20,260
That means your over fitting to the train data because now you have a much larger loss on your validation

29
00:02:20,260 --> 00:02:20,890
data.

30
00:02:21,010 --> 00:02:26,170
And later on in the lectures we'll see an example of that which will allow us to then actually implement

31
00:02:26,170 --> 00:02:28,720
what's known as early stopping in this case.

32
00:02:28,750 --> 00:02:31,290
This is pretty much the perfect behavior you want to see.

33
00:02:31,420 --> 00:02:35,790
You want to see training loss and validation loss go down and then continue down together.

34
00:02:35,800 --> 00:02:39,870
So there's no over fitting that we can see occurring here OK.

35
00:02:40,280 --> 00:02:43,610
So now let's do some evaluation on our test data.

36
00:02:44,180 --> 00:02:47,190
So what we can do is a variety of methods on this.

37
00:02:47,330 --> 00:02:55,360
You can say from us can learn that metrics import and we can import things like the mean square error

38
00:02:56,370 --> 00:03:02,430
the mean absolute error and we can also even if we want get an explain variance score.

39
00:03:02,430 --> 00:03:05,670
So what we do here is we grab our predictions

40
00:03:09,200 --> 00:03:18,080
by saying model that predict and we're gonna predict on the test set so we run that and now recall we

41
00:03:18,080 --> 00:03:23,060
have our list of predictions and we're going to do is simply compare these to what we know are the correct

42
00:03:23,060 --> 00:03:30,890
values so we can call mean squared error or mean absolute error we can do both and what we do is we

43
00:03:30,890 --> 00:03:32,680
first pass in y true.

44
00:03:32,720 --> 00:03:37,490
So recall that is why test and then we compare that to our predictions.

45
00:03:38,120 --> 00:03:44,000
So our total means caught error here is this value is a very large value which kind of makes sense because

46
00:03:44,000 --> 00:03:45,960
we're dealing with the prices of houses.

47
00:03:46,040 --> 00:03:47,050
So we're Squaring those.

48
00:03:47,050 --> 00:03:48,470
So it should be a large value.

49
00:03:48,470 --> 00:03:49,760
This is really hard to interpret.

50
00:03:49,760 --> 00:03:54,980
So what we can do is either get the root mean square error by taking the square root of this either

51
00:03:54,980 --> 00:03:58,600
by running Ed pew or NDP square root.

52
00:03:58,640 --> 00:04:05,240
This is our square root error or root means square or we can do is also get mean absolute error.

53
00:04:05,240 --> 00:04:10,550
So I mean absolute error it's really easy to interpret because essentially just what is your average

54
00:04:10,610 --> 00:04:13,400
absolute error across all your predictions.

55
00:04:13,490 --> 00:04:18,080
So it can say why test versus predictions and it looks like our mean absolute error.

56
00:04:18,080 --> 00:04:21,380
So on average we're off by about one hundred thousand dollars.

57
00:04:21,410 --> 00:04:23,640
Now is that good or is that bad.

58
00:04:23,690 --> 00:04:27,800
Again we have to take into account the actual data frame itself.

59
00:04:27,950 --> 00:04:34,220
So we have to take into account our price column off the original data frame called describe on it and

60
00:04:34,220 --> 00:04:37,040
see what kind of values we're actually dealing with.

61
00:04:37,040 --> 00:04:42,140
So recall that the mean it looks like it's five point four times tend to the five.

62
00:04:42,170 --> 00:04:48,350
So if we actually grab this and put it in here as a number we'll report back that the average price

63
00:04:48,350 --> 00:04:52,280
of the house is around five hundred forty thousand dollars.

64
00:04:52,280 --> 00:04:56,750
In our case our mean absolute error is about one hundred thousand dollars so that's not really that

65
00:04:56,750 --> 00:04:57,340
great.

66
00:04:57,500 --> 00:05:00,020
Or off by around 20 percent.

67
00:05:00,020 --> 00:05:01,420
So not great.

68
00:05:01,490 --> 00:05:02,750
Not horrible either.

69
00:05:02,760 --> 00:05:08,240
We can also do is use and explain the variance score to try to get a deeper understanding of our evaluation

70
00:05:08,240 --> 00:05:10,460
metrics here.

71
00:05:10,460 --> 00:05:15,440
So I can use explain variance score and if you do shift time here they'll essentially explain what's

72
00:05:15,440 --> 00:05:16,420
actually happening here.

73
00:05:16,430 --> 00:05:19,450
So the best possible score is one point zero.

74
00:05:19,520 --> 00:05:25,770
And what this does it tells you how much variance is being explained by your actual model.

75
00:05:25,840 --> 00:05:32,390
You take a look at the online documentation for further examples of how this actually works and how

76
00:05:32,390 --> 00:05:33,730
it actually is calculated.

77
00:05:33,860 --> 00:05:41,320
But what we can do here is same as before has an R Y test values versus our predictions and we're getting

78
00:05:41,340 --> 00:05:44,160
explained variance score of somewhere around zero point eight.

79
00:05:44,190 --> 00:05:46,290
So in this case zero point seven nine.

80
00:05:46,320 --> 00:05:49,130
So that's just merely OK.

81
00:05:49,140 --> 00:05:51,510
Again it really depends on the context.

82
00:05:51,510 --> 00:05:55,520
Do we have a previous model that actually performs better than this.

83
00:05:55,530 --> 00:06:00,590
We also notice that technically we could still keep training and keep lowering this loss.

84
00:06:00,630 --> 00:06:05,910
So maybe it's worth it to try to keep training on the training data since we technically haven't actually

85
00:06:05,910 --> 00:06:10,010
reached over fitting on it quite yet due to our analysis here.

86
00:06:10,050 --> 00:06:16,560
Well we can also compare is our predictions and we can plot them out against a perfect fit.

87
00:06:17,250 --> 00:06:27,170
So recall that previously what we did we did a scatter plot of white test versus our predictions and

88
00:06:27,170 --> 00:06:28,920
we can see the way they fit here.

89
00:06:29,060 --> 00:06:36,240
And what I can do is make this a little larger so I can say Pulte figure thick size is equal to let's

90
00:06:36,240 --> 00:06:40,020
say 12 by six in order to fit everything nicely.

91
00:06:40,020 --> 00:06:43,410
Now in a perfect world this would be a straight line.

92
00:06:43,470 --> 00:06:49,560
Now we can compare by saying PDT plot and I'm going to plot y test

93
00:06:52,310 --> 00:07:02,540
against y test and I'll just say this is a red line by saying ah and now this red line represents the

94
00:07:02,630 --> 00:07:05,790
best or the basically the perfect prediction line.

95
00:07:05,810 --> 00:07:09,980
You'll notice that we're basically being punished here by these outliers.

96
00:07:09,980 --> 00:07:15,230
So these really expensive houses were actually not good at predicting that price but we're pretty good

97
00:07:15,590 --> 00:07:21,490
at predicting the prices of houses between zero and two million dollars is actually not so bad.

98
00:07:21,500 --> 00:07:27,400
There's clearly a good fit here between our test and our predictions and that's essentially what explained

99
00:07:27,410 --> 00:07:34,820
variance score is trying to report back to you in the form of a single number what may be worth it is

100
00:07:34,820 --> 00:07:40,180
to retrain our model just on that bottom ninety nine percent of houses.

101
00:07:40,220 --> 00:07:47,960
And so if we come up to a situation where our maybe sale price is over three million dollars we'll just

102
00:07:47,960 --> 00:07:54,080
say sorry our model's not good enough for this and we'll only refit to that bottom 99 percent.

103
00:07:54,080 --> 00:07:58,640
Again it really depends on the context and what questions you're trying to answer and what problems

104
00:07:58,640 --> 00:08:00,580
you're trying to solve.

105
00:08:00,620 --> 00:08:01,260
OK.

106
00:08:01,370 --> 00:08:06,130
So finally let's show you how you would use your model to predict on a brand new house.

107
00:08:06,140 --> 00:08:09,690
So let's take a look at our original data frame.

108
00:08:09,950 --> 00:08:12,800
We'll go ahead and just pick the very first house here.

109
00:08:12,830 --> 00:08:19,200
So let's say the F and what we'll do is we're gonna drop the price of this house.

110
00:08:19,520 --> 00:08:27,660
So say drop the price along axis is equal to 1 and then just grab the very first house here.

111
00:08:27,680 --> 00:08:28,650
So what this is.

112
00:08:28,700 --> 00:08:31,770
These are only the features of a new house and market.

113
00:08:31,790 --> 00:08:37,610
So let's say a new house is coming onto the market and you want to sell it in October 2014.

114
00:08:37,610 --> 00:08:42,320
And you know these various features of the house you know how many betters it has you know how many

115
00:08:42,320 --> 00:08:43,900
bathrooms it has et.

116
00:08:44,090 --> 00:08:47,110
You know its condition whether or not it's waterfront et cetera.

117
00:08:47,120 --> 00:08:52,190
So we have all these features for a new house coming onto the market.

118
00:08:52,190 --> 00:08:55,610
Now the next step is to actually scale this single house data.

119
00:08:55,760 --> 00:09:01,470
Recall that our model is trained on scaled versions of the features which means we can actually pass

120
00:09:01,470 --> 00:09:08,100
in these features raw and instead what we need to do is say single house grab those values.

121
00:09:08,100 --> 00:09:11,490
So now it's a nun pie array but the shape is actually off.

122
00:09:11,490 --> 00:09:14,610
Notice there's only one set of braces or brackets there.

123
00:09:14,610 --> 00:09:21,750
I need to reshape this to be negative one by 19 and you'll notice now that essentially adds that extra

124
00:09:21,750 --> 00:09:27,720
set of brackets there which is the shape expected negative one just basically means keep those old dimensions

125
00:09:27,750 --> 00:09:29,320
along the axes.

126
00:09:29,430 --> 00:09:37,920
So now that I have it in the correct shape I should be able to say scalar that transform on this.

127
00:09:37,920 --> 00:09:45,510
And now I have the skilled versions of everything and now we'll reset this to be our single house.

128
00:09:45,510 --> 00:09:53,490
So now that I have my single house I'll say models that predict on my single house run this and now

129
00:09:53,490 --> 00:09:56,120
I have the predicted price that this will sell out.

130
00:09:56,400 --> 00:10:03,410
And if I take a look at the f then the very first item there just show one the true price.

131
00:10:03,410 --> 00:10:08,900
It sold that was two hundred twenty one thousand dollars and I'm predicting it will sell a two hundred

132
00:10:08,990 --> 00:10:10,550
eighty eight thousand dollars.

133
00:10:10,550 --> 00:10:17,600
So it looks like we are kind of overshooting here and again that may be an issue when we're trying to

134
00:10:17,600 --> 00:10:19,680
fit to these extreme values.

135
00:10:19,700 --> 00:10:26,840
So an interesting next step to actually undertake would be to retrain your model by dropping out maybe

136
00:10:26,840 --> 00:10:32,690
the top 1 or 2 percent of values and see if that can reduce your means squared error on your data set.

137
00:10:32,750 --> 00:10:36,660
But for right now I would say we're pretty much done with this project.

138
00:10:36,740 --> 00:10:41,900
We've been able to do a little bit of fixed engineering do a little bit of exploratory data analysis

139
00:10:42,230 --> 00:10:49,220
create and train a model and then get back a relatively reasonable model in order to predict the prices

140
00:10:49,220 --> 00:10:50,080
of houses.

141
00:10:50,090 --> 00:10:54,790
It's not like we're predicting 2 billion dollars on a 200 grand house.

142
00:10:54,830 --> 00:10:59,290
Instead we're relatively in the range of what a house could sell it.

143
00:10:59,390 --> 00:11:04,640
And it looks like we're more or less explaining quite a bit of variance up to 80 percent of the variance

144
00:11:05,090 --> 00:11:06,800
in the pricing.

145
00:11:06,800 --> 00:11:07,380
Okay.

146
00:11:07,760 --> 00:11:10,340
So that's it for this lecture coming up next.

147
00:11:10,340 --> 00:11:15,350
We're going to begin to dive deeper into a lot of these topics based on things like batch sizes and

148
00:11:15,380 --> 00:11:16,840
early stopping in our model.

149
00:11:16,940 --> 00:11:21,560
And we'll do that by taking a look at classification tasks through tensor flow.

150
00:11:21,590 --> 00:11:22,610
I'll see you at the next lecture.
