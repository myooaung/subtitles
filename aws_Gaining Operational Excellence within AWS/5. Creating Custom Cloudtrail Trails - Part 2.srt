1
00:00:00,940 --> 00:00:02,740
[Autogenerated] Okay, Welcome back.

2
00:00:02,740 --> 00:00:05,030
Now picking up where we left off.

3
00:00:05,030 --> 00:00:07,940
Let's go ahead and open our trails here,

4
00:00:07,940 --> 00:00:11,740
and I want to go in to our trail that we just created.

5
00:00:11,740 --> 00:00:15,120
So within this config screen we can see, logging is on.

6
00:00:15,120 --> 00:00:17,020
So this is enabled.

7
00:00:17,020 --> 00:00:20,040
We see our settings that we set here,

8
00:00:20,040 --> 00:00:22,890
but what I'm looking for here is the S3 bucket.

9
00:00:22,890 --> 00:00:24,410
So let me open this.

10
00:00:24,410 --> 00:00:26,890
And while that loads, you can notice that it says,

11
00:00:26,890 --> 00:00:30,840
Hey, last log file delivered at this particular time.

12
00:00:30,840 --> 00:00:32,740
So if I go to S3,

13
00:00:32,740 --> 00:00:35,850
you'll notice that it actually takes us to this specific

14
00:00:35,850 --> 00:00:39,190
trails prefix that we saw earlier.

15
00:00:39,190 --> 00:00:42,790
So it's our bucket that a W s logs,

16
00:00:42,790 --> 00:00:46,680
theater count IDE and then CloudTrail and then within

17
00:00:46,680 --> 00:00:48,870
here we have our different regions.

18
00:00:48,870 --> 00:00:53,440
So let's go to us East to you can see the date is populating,

19
00:00:53,440 --> 00:00:56,840
so we have year, month,

20
00:00:56,840 --> 00:01:03,240
day of month and then it'll start saving files on a regular basis.

21
00:01:03,240 --> 00:01:07,500
Now, these error gzip files and I actually opened one of these up.

22
00:01:07,500 --> 00:01:11,890
So we can view what they look like and you can see that it's simply a JSON

23
00:01:11,890 --> 00:01:17,530
file with the event that happened So this is exactly what we would see in

24
00:01:17,530 --> 00:01:20,840
our CloudTrail trails under our event history.

25
00:01:20,840 --> 00:01:26,170
It's just captured in a zipped up log file for consumption whenever we want,

26
00:01:26,170 --> 00:01:31,140
and it's stored for a long period of time longer than the default 90 days.

27
00:01:31,140 --> 00:01:33,040
Let me switch back here.

28
00:01:33,040 --> 00:01:35,640
Let me close S3.

29
00:01:35,640 --> 00:01:41,190
And the very last thing I want to touch on is this CloudWatch logs section

30
00:01:41,190 --> 00:01:45,170
down here so we can actually push our CloudTrail events,

31
00:01:45,170 --> 00:01:46,340
too.

32
00:01:46,340 --> 00:01:47,350
CloudWatch.

33
00:01:47,350 --> 00:01:51,730
We create a log group name here so I can call it CloudTrail.

34
00:01:51,730 --> 00:01:53,390
And then, for the sake of this,

35
00:01:53,390 --> 00:01:56,570
lets mimic like it's going to a bucket that's shared

36
00:01:56,570 --> 00:02:01,300
with other CloudTrail accounts, and we'll give it a prefix of our account IDE.

37
00:02:01,300 --> 00:02:06,080
So we should see a CloudTrail a Count IDE CloudWatch Law Group.

38
00:02:06,080 --> 00:02:11,140
I'll click continue, and this brings us to a role creation screen.

39
00:02:11,140 --> 00:02:13,090
So what this is saying is, Hey,

40
00:02:13,090 --> 00:02:17,130
we have to create a role that will be assumed by CloudTrail

41
00:02:17,130 --> 00:02:21,700
to perform these specific operations, and if you look here,

42
00:02:21,700 --> 00:02:26,620
it's simply allowing us to create a log stream as well as put log

43
00:02:26,620 --> 00:02:30,540
events into that log stream so we'll leave this as is,

44
00:02:30,540 --> 00:02:32,040
I'll click, allow.

45
00:02:32,040 --> 00:02:35,240
We get a successful message and it brings us back.

46
00:02:35,240 --> 00:02:40,640
So now, at the bottom, it's validating our role and we actually got an error.

47
00:02:40,640 --> 00:02:42,300
So let's go through this again.

48
00:02:42,300 --> 00:02:45,840
I'll click allow or let me view details first.

49
00:02:45,840 --> 00:02:50,140
Okay, I'll click allow.

50
00:02:50,140 --> 00:02:51,150
And there we go.

51
00:02:51,150 --> 00:02:53,060
So we just had a transient era there.

52
00:02:53,060 --> 00:02:54,740
But it's fixed now.

53
00:02:54,740 --> 00:02:56,100
So what this does?

54
00:02:56,100 --> 00:02:59,680
It should be pushing to CloudWatch within this region.

55
00:02:59,680 --> 00:03:03,720
So let me open up CloudWatch.

56
00:03:03,720 --> 00:03:09,040
I'll look at my log groups and you can see we have our trail Law group here.

57
00:03:09,040 --> 00:03:10,750
So if I go into this,

58
00:03:10,750 --> 00:03:14,620
we'll see we have a log stream now an important note here

59
00:03:14,620 --> 00:03:17,130
since we're only having this single account,

60
00:03:17,130 --> 00:03:22,310
this is what it looks like account IDE CloudTrail us East to the region,

61
00:03:22,310 --> 00:03:24,940
so there'll be one for each region.

62
00:03:24,940 --> 00:03:28,140
But if we were part of an organization and we were

63
00:03:28,140 --> 00:03:31,070
pushing to an organization law group,

64
00:03:31,070 --> 00:03:37,020
what would happen here is each organization would have its own log stream.

65
00:03:37,020 --> 00:03:39,490
So we can see several log streams here,

66
00:03:39,490 --> 00:03:42,750
depending on the amount of sub accounts that we have.

67
00:03:42,750 --> 00:03:47,750
Let's go ahead, open up this log stream and we can view events in here,

68
00:03:47,750 --> 00:03:52,620
so this makes it a little bit easier to manage than downloading it from S3,

69
00:03:52,620 --> 00:03:55,640
unzipping it and then viewing it from there.

70
00:03:55,640 --> 00:03:58,390
And you see, it's literally what we just looked at.

71
00:03:58,390 --> 00:04:01,120
It's a CloudTrail event in JSON form.

72
00:04:01,120 --> 00:04:03,340
Put in as a log message.

73
00:04:03,340 --> 00:04:05,490
Now, one last thing before we do.

74
00:04:05,490 --> 00:04:09,740
If I go ahead and go to law groups, I select this one.

75
00:04:09,740 --> 00:04:12,840
A key aspect of this is under actions.

76
00:04:12,840 --> 00:04:17,660
We can do several things we can export our data to S3 as needed,

77
00:04:17,660 --> 00:04:21,450
which more than likely is not necessary if you're pushing to a

78
00:04:21,450 --> 00:04:25,770
singular as three bucket we can stream to a Lambda to perform

79
00:04:25,770 --> 00:04:30,590
actions based on those events coming in or we can even stream to

80
00:04:30,590 --> 00:04:33,240
Amazon Elastic search service.

81
00:04:33,240 --> 00:04:33,540
Now,

82
00:04:33,540 --> 00:04:37,500
a use case for this might be some type of dashboard that you wanna

83
00:04:37,500 --> 00:04:41,370
build that quickly lays out in a visual form.

84
00:04:41,370 --> 00:04:44,620
What kind of events error receiving and for Lambda

85
00:04:44,620 --> 00:04:50,210
I can talk from personal experience, we have used this based on a metric filter,

86
00:04:50,210 --> 00:04:53,540
so it streams events for a certain IFilter,

87
00:04:53,540 --> 00:04:54,920
and when it receives that event,

88
00:04:54,920 --> 00:04:58,310
it acts on it and sends either an alert or it corrects

89
00:04:58,310 --> 00:05:01,240
the action during the indication.

90
00:05:01,240 --> 00:05:05,270
So just remember that these options are available for you to use.

91
00:05:05,270 --> 00:05:08,090
You can push CloudTrail to CloudWatch.

92
00:05:08,090 --> 00:05:09,860
And then, with those law groups,

93
00:05:09,860 --> 00:05:13,430
you could go ahead and stream to a Lambda Function or ELASTICSEARCH

94
00:05:13,430 --> 00:05:17,670
services and these error known as subscription filters.

95
00:05:17,670 --> 00:05:19,540
So just keep that in mind.

96
00:05:19,540 --> 00:05:27,000
We're gonna go ahead and in this clip here and then in the next one will have a module wrap up and review.

