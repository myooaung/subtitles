1
00:00:00,590 --> 00:00:07,610
Heyes welcome to this new tutorial in the previous one we installed Anaconda tenso flow and our chat

2
00:00:07,640 --> 00:00:09,220
but virtual environment.

3
00:00:09,440 --> 00:00:15,370
And in this new d'hotel we're going to get our data set which is the only thing missing right now.

4
00:00:15,380 --> 00:00:21,890
We already created our Chad but that fell in which will implement the whole more all that is the whole

5
00:00:21,890 --> 00:00:22,190
Chad.

6
00:00:22,200 --> 00:00:28,960
But but to do this we need a data set to train this jet but and this is what we'll get to toile.

7
00:00:29,030 --> 00:00:36,410
So this dataset is called the Cornell movie corpus data set and it's basically a data set containing

8
00:00:36,530 --> 00:00:42,200
thousands of conversations from 600 plus movies between many characters.

9
00:00:42,200 --> 00:00:43,840
So let's have a look at this data.

10
00:00:43,910 --> 00:00:49,900
Let's enter here in Google Cornell movie dialogue corpus.

11
00:00:49,940 --> 00:00:53,740
That's the one just press enter and just take the first link.

12
00:00:53,750 --> 00:00:59,870
So you just need to add to a Cornell movie Diala corpus then take the first link and there we go.

13
00:00:59,900 --> 00:01:01,140
That's the dataset.

14
00:01:01,190 --> 00:01:08,060
So let's have a look as a description says this corpus contains a large meta data rich collection of

15
00:01:08,060 --> 00:01:12,950
fictional conversations extracted from raw movie scripts.

16
00:01:12,950 --> 00:01:19,940
So in total two hundred and twenty thousand five hundred seventy nine conversational exchanges between

17
00:01:20,150 --> 00:01:23,000
10000 pairs of movie characters.

18
00:01:23,210 --> 00:01:29,810
Not that then it evolves nine thousand thirty five characters from six hundred and seventeen movies

19
00:01:30,440 --> 00:01:39,710
and in total 340000 713 utterances are perfect so let's download it to download it.

20
00:01:39,710 --> 00:01:47,510
You simply need to click on the zip file here and this will start the download which you should get

21
00:01:47,600 --> 00:01:49,520
in a matter of seconds.

22
00:01:49,520 --> 00:01:50,510
I just got it.

23
00:01:50,550 --> 00:01:54,760
So let's go to my download folder on my computer.

24
00:01:54,800 --> 00:01:55,510
Here we are.

25
00:01:55,550 --> 00:01:59,710
And here is the Cornell movie dialog's corpus Doucette.

26
00:01:59,840 --> 00:02:02,300
So let's double click on it and zip it.

27
00:02:02,540 --> 00:02:03,320
And there we go.

28
00:02:03,320 --> 00:02:05,130
It contains several files.

29
00:02:05,330 --> 00:02:10,180
So now we have to make the difference between meta data and the real data.

30
00:02:10,240 --> 00:02:13,820
Meta data is like the data I will not use for the training.

31
00:02:13,880 --> 00:02:20,840
So it's things like to ratings or the movie that comes from like some description or data and we don't

32
00:02:20,840 --> 00:02:22,490
need that of course we just need.

33
00:02:22,670 --> 00:02:27,590
Well basically the conversations between the characters and that's what we'll get now and that's what

34
00:02:27,620 --> 00:02:34,530
will directly put in our deep and anti-father there because we just want what's necessary for us.

35
00:02:34,670 --> 00:02:39,710
But feel free to have a look at the other files like this one you can see an interesting paper that

36
00:02:39,710 --> 00:02:41,640
will give you some relevant information.

37
00:02:41,930 --> 00:02:47,300
Then you have some meta data here about the movie characters then some other method data here about

38
00:02:47,300 --> 00:02:54,340
the movie titles then some read me script that will give you some more descriptions but the things we'll

39
00:02:54,350 --> 00:02:58,050
need for a chat but is actually just two files.

40
00:02:58,070 --> 00:03:03,360
These are the movie conversations that me and the movie lines here.

41
00:03:03,590 --> 00:03:04,160
The rest.

42
00:03:04,160 --> 00:03:08,380
We actually don't care because we actually won't use it for the training.

43
00:03:08,570 --> 00:03:14,000
However let's have a look at these two hour movie conversations that the XTi and movie lines that tasty.

44
00:03:14,300 --> 00:03:15,830
Let's start with movie lines.

45
00:03:15,900 --> 00:03:23,180
Some movie lines as you can see contains some extracts of scripts taken from movies.

46
00:03:23,180 --> 00:03:29,180
So for example I'm going to open it with let's see Sublime Text and let's have a look.

47
00:03:29,180 --> 00:03:36,650
So as you can see it contains several columns separated by these strings here plus plus plus dollar

48
00:03:36,830 --> 00:03:37,740
plus plus plus.

49
00:03:37,940 --> 00:03:44,630
So that's the first column second column third column force column and Fix column the first column is

50
00:03:44,630 --> 00:03:45,980
just an idea.

51
00:03:46,150 --> 00:03:51,270
It is the idea of the line said by some character in some specific movie.

52
00:03:51,290 --> 00:03:55,970
Then the second column speaking of the character is actually the character.

53
00:03:56,270 --> 00:03:57,970
Eumenes user here.

54
00:03:57,980 --> 00:04:04,900
So for example if we take these first two lines here that a conversation between user zero and user

55
00:04:04,910 --> 00:04:05,580
2.

56
00:04:05,960 --> 00:04:08,960
Then the third column is the movie.

57
00:04:09,080 --> 00:04:14,740
So it is indexed by and a number so that movie Zero here.

58
00:04:15,140 --> 00:04:21,680
Then the fourth column is the name of the actor while the character and this is actually some meta data

59
00:04:21,710 --> 00:04:24,370
which we won't use to train our chat but.

60
00:04:24,560 --> 00:04:27,670
And finally the last column is the line.

61
00:04:27,860 --> 00:04:30,350
So what does this line mean.

62
00:04:30,350 --> 00:04:37,820
Well it means that Bianka who is indexed by use of zero in movie Zero says they do not.

63
00:04:37,910 --> 00:04:41,930
And then if we take the second line well that's taken from the same movie.

64
00:04:42,020 --> 00:04:42,980
Movie zero.

65
00:04:43,160 --> 00:04:47,440
But this time it's used to named Cameron that says they do too.

66
00:04:47,460 --> 00:04:50,350
And actually the script goes this way.

67
00:04:50,360 --> 00:04:52,590
Kamman starts to say they do too.

68
00:04:52,670 --> 00:04:55,520
That's the input and Bianka replies.

69
00:04:55,610 --> 00:04:56,400
They do not.

70
00:04:56,660 --> 00:04:57,290
OK.

71
00:04:57,440 --> 00:05:05,650
So that's an extract from a movie Zero between two users use zero and you to younker and Cameron and

72
00:05:05,650 --> 00:05:08,050
that's one conversation.

73
00:05:08,050 --> 00:05:11,420
And we have other conversations with most of the time.

74
00:05:11,470 --> 00:05:14,350
One input and one out but not all the time.

75
00:05:14,350 --> 00:05:22,220
As you can see for example here we have a huge conversation starting from here H-60 to eight sixty two.

76
00:05:22,330 --> 00:05:28,070
So we have a long conversation here between the young can camera Blanquette Cameron the young guy Cameron

77
00:05:28,130 --> 00:05:28,550
young.

78
00:05:28,590 --> 00:05:34,810
Cameron Well that's actually from the same movie with the same users obviously but a different extract

79
00:05:34,810 --> 00:05:35,610
from the movie.

80
00:05:35,650 --> 00:05:37,290
I don't know if you recognize the movie.

81
00:05:37,480 --> 00:05:43,150
I don't but this is a conversation on which Archie had but will be trained.

82
00:05:43,360 --> 00:05:48,610
All right so it's important for you to understand well the structure of the data set.

83
00:05:48,640 --> 00:05:54,430
This is movie lines that THC which basically contains several conversations between some characters

84
00:05:54,430 --> 00:05:56,830
taken from different movies.

85
00:05:56,830 --> 00:05:57,100
All right.

86
00:05:57,100 --> 00:05:59,020
So we're going to close this now.

87
00:05:59,840 --> 00:06:07,310
And we're going to open the other interesting dataset which is movie conversation that takes me I'm

88
00:06:07,310 --> 00:06:10,810
going to open it with Sublime Text as well.

89
00:06:10,850 --> 00:06:11,640
And there we go.

90
00:06:11,960 --> 00:06:15,620
So as you can see it's almost the same except that this time we don't have the lines.

91
00:06:15,740 --> 00:06:18,710
We have the conversations.

92
00:06:18,710 --> 00:06:24,240
Each row of this dataset corresponds to one single conversation.

93
00:06:24,470 --> 00:06:30,590
So as you can see in each conversation we have several lines and these lines in one same conversation

94
00:06:30,650 --> 00:06:33,760
are all the lines composing the conversation.

95
00:06:33,860 --> 00:06:39,950
And this is important because the previous dataset didn't somehow separate the conversation so we need

96
00:06:39,950 --> 00:06:46,900
this data set to make sure we distinguish two different conversations on which Archibold will be trained.

97
00:06:47,240 --> 00:06:47,480
All right.

98
00:06:47,480 --> 00:06:48,620
So let's close this.

99
00:06:48,860 --> 00:06:50,730
And therefore that's all we need.

100
00:06:50,870 --> 00:06:56,780
So what we're going to do now is take these two three XTi fell these two datasets.

101
00:06:56,990 --> 00:06:57,990
I'm going to copy them.

102
00:06:58,170 --> 00:07:04,820
I just copy them Kamensky or Control-C on Windows and I'm going to go to my desktop where I created

103
00:07:05,030 --> 00:07:07,250
the deep end and it is a folder.

104
00:07:07,340 --> 00:07:14,690
So let's go inside and let's just paste the dataset composed of movie conversations RTX the movie lines

105
00:07:14,690 --> 00:07:22,570
that TSC and congratulations you have all you need to implement the chad but just one shot that you

106
00:07:22,690 --> 00:07:23,150
fell.

107
00:07:23,170 --> 00:07:27,200
Which will contain the whole implementation of the job but including how we build it how we train it

108
00:07:27,200 --> 00:07:28,400
and how we test it.

109
00:07:28,460 --> 00:07:33,060
And these two files which compose the day is it.

110
00:07:33,200 --> 00:07:33,860
That's it.

111
00:07:33,860 --> 00:07:37,180
So if you're ready let's start from the next tutorial.

112
00:07:37,220 --> 00:07:40,260
And actually in the next story we'll start part 1.

113
00:07:40,340 --> 00:07:41,590
Data Processing.

114
00:07:41,750 --> 00:07:46,930
This is not the funniest part but let's try to make it with enthusiasm so that we can get to part two

115
00:07:46,940 --> 00:07:49,070
without even noticing.

116
00:07:49,070 --> 00:07:50,520
All right so I'll see you the next it's oil.

117
00:07:50,540 --> 00:07:52,340
And until then and even I'll be.
