1
00:00:00,420 --> 00:00:05,940
Hello and welcome back to the course on deep learning I hope you're as excited about this section of

2
00:00:05,940 --> 00:00:08,610
the course on recurrent neural networks as I am.

3
00:00:08,740 --> 00:00:18,020
We're slowly venturing into the very complex very forward looking and cutting edge areas of deep learning

4
00:00:18,030 --> 00:00:20,310
and this is going to be very very fun.

5
00:00:20,310 --> 00:00:25,020
So today we're going to talk about how we're going to approach this section which contains so many different

6
00:00:25,020 --> 00:00:30,210
complex topics so many concepts that we need to get our head around.

7
00:00:30,210 --> 00:00:35,760
All right so in this section we will learn first of all the idea behind a recurrent neural networks.

8
00:00:35,760 --> 00:00:42,180
We'll see how they compare to the human brain will understand what makes them unique and special as

9
00:00:42,180 --> 00:00:45,410
compared to regular artificial neural networks.

10
00:00:45,490 --> 00:00:53,130
Then we'll talk about the vanishing gradient problem something that has been a major roadblock in or

11
00:00:53,130 --> 00:00:58,800
had been a major roadblock in the development and utilization of recurrent neural networks something

12
00:00:58,800 --> 00:01:01,930
that prevented them from being what they are now.

13
00:01:02,100 --> 00:01:06,040
And then we will move onto the solution.

14
00:01:06,300 --> 00:01:12,220
One of the most popular solutions to the vanishing Green problem the long short term memory or ellis

15
00:01:12,220 --> 00:01:15,050
T.M. neural networks and we'll talk about their architecture.

16
00:01:15,080 --> 00:01:16,290
They are very exciting tutorials.

17
00:01:16,290 --> 00:01:23,910
One of my favorite topics and we will find out exactly how they work and what what that complex structure

18
00:01:23,940 --> 00:01:25,120
is inside them.

19
00:01:25,120 --> 00:01:32,100
We'll break it down into simple terms and you will be able to walk away with a pretty solid understanding

20
00:01:32,160 --> 00:01:33,290
of LSD.

21
00:01:33,920 --> 00:01:35,910
And then we'll talk about the practical intuition.

22
00:01:35,910 --> 00:01:40,390
So in that Prius we will have a practical example of using LACMA.

23
00:01:40,410 --> 00:01:47,090
But in this practical intuition trail we'll look at some great examples posted by one of the researchers

24
00:01:47,100 --> 00:01:53,190
one of the most well-known researchers in the space and will understand even better on an intuitive

25
00:01:53,190 --> 00:01:56,970
level how Ellis teams actually work how they think will be like.

26
00:01:56,970 --> 00:02:02,190
Neuroscientists trying to understand what's going on in the brain of an Ellis team is going to be very

27
00:02:02,190 --> 00:02:03,280
exciting as well.

28
00:02:03,570 --> 00:02:10,530
And then at the end we'll have an extra tutorial on him variations something special something you don't

29
00:02:10,530 --> 00:02:16,530
really have to take this tutorial but it's very quick just to get you up to speed on what other options

30
00:02:16,530 --> 00:02:23,670
of LACMA exist out there in the world what other architectures you might come across in your work.

31
00:02:23,910 --> 00:02:27,360
So hopefully you're excited and ready to get started.

32
00:02:27,510 --> 00:02:29,760
And I can't wait to see the next tutorial.

33
00:02:29,760 --> 00:02:31,690
Until then enjoy deep learning.
