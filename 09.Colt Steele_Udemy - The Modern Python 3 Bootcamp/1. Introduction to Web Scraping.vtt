WEBVTT
1
00:00:00.300 --> 00:00:06.450
A welcome back to a really exciting in my opinion exciting section on a topic that I personally love

2
00:00:06.480 --> 00:00:09.040
as a developer I also love to teach it.

3
00:00:09.060 --> 00:00:12.830
It's fun and it combines a lot of the things we've learned.

4
00:00:12.840 --> 00:00:16.920
It's also a little dangerous or sketchy or morally grey.

5
00:00:17.130 --> 00:00:19.380
So we'll talk about ethics and a little bit.

6
00:00:19.380 --> 00:00:22.750
It's just a fun topic and that topic is web scraping.

7
00:00:22.770 --> 00:00:26.740
So before we actually talk about what that is what it means and dive into the code.

8
00:00:26.760 --> 00:00:28.990
Let's just quickly run through our objectives.

9
00:00:29.010 --> 00:00:31.590
As always there's only a couple.

10
00:00:31.590 --> 00:00:36.960
First we want to define what web scraping actually is and we'll talk about some of those issues around

11
00:00:36.960 --> 00:00:37.250
it.

12
00:00:37.380 --> 00:00:42.900
Well then dive into code and use both the requests module that we've already seen and something called

13
00:00:42.900 --> 00:00:48.280
beautiful soup which we haven't seen and we'll use them together to download and parse him out.

14
00:00:48.870 --> 00:00:52.540
Then we'll explain and go over some common issues with web scraping.

15
00:00:52.800 --> 00:00:57.840
So not not the same as these issues these are the ethical issues here down here.

16
00:00:57.840 --> 00:01:02.550
We're going to talk about some technical problems that can arise when you're scraping.

17
00:01:02.820 --> 00:01:08.490
And then finally we'll talk about some other tools in Python that you can use to kind of bolster your

18
00:01:08.490 --> 00:01:12.800
web scrapers make things better potentially solve some of these problems.

19
00:01:13.130 --> 00:01:13.660
OK.

20
00:01:13.800 --> 00:01:15.300
So those are the objectives.

21
00:01:15.360 --> 00:01:20.280
But in this video we're just going to focus on this first thing talking about what Scraping is and then

22
00:01:20.280 --> 00:01:22.540
identifying some of the big issues around it.

23
00:01:22.770 --> 00:01:25.990
Let's begin by just talking about what web scraping actually is.

24
00:01:26.070 --> 00:01:28.710
And then why you would potentially do it.

25
00:01:28.710 --> 00:01:29.680
So what is scraping.

26
00:01:29.790 --> 00:01:35.550
Well Scraping is just the act of writing code in Python or any other language.

27
00:01:35.550 --> 00:01:42.420
So it's you know Java Sea swift It doesn't have to be Python and the idea is to write code that programmatically

28
00:01:42.540 --> 00:01:44.500
get data from a web page.

29
00:01:44.580 --> 00:01:47.100
So there's you know millions of web pages out there.

30
00:01:47.100 --> 00:01:50.790
They have data on them and there is usually an HMO.

31
00:01:50.880 --> 00:01:54.890
Sometimes they come in the form of an API where we can get on data.

32
00:01:55.080 --> 00:01:56.920
In that case we wouldn't scrape.

33
00:01:57.000 --> 00:02:01.860
But if there is no other option and you need data and the only format you can find it in is actually

34
00:02:01.920 --> 00:02:05.450
on a web page as HMO for humans to read.

35
00:02:05.580 --> 00:02:12.100
We can still write code that is going to be able to scrape the data we want out of all of that complex.

36
00:02:12.220 --> 00:02:16.230
Tim L So I'll show you an example in moment of why you would do this.

37
00:02:16.530 --> 00:02:18.210
But there's really three main steps.

38
00:02:18.210 --> 00:02:25.110
The first is we write Python code to go get a web page or we might automate it and have it get a thousand

39
00:02:25.230 --> 00:02:27.160
pages an hour or more.

40
00:02:27.180 --> 00:02:32.370
Usually we slow it down too so we don't to attract suspicion but the idea is that you get code or you

41
00:02:32.370 --> 00:02:38.340
get H.T. mail back after you request it and then we have to parse through it and extract the data we

42
00:02:38.340 --> 00:02:44.480
want and then do something with it whether we are manipulating the data or analyzing the data.

43
00:02:44.670 --> 00:02:45.600
We're aggregating it.

44
00:02:45.600 --> 00:02:48.370
We're putting in a database some sort of file.

45
00:02:48.450 --> 00:02:49.890
We just do something with that data.

46
00:02:49.910 --> 00:02:51.120
That's the whole idea.

47
00:02:51.120 --> 00:02:53.750
We're trying to get data so that we can use it.

48
00:02:53.760 --> 00:02:56.280
So that's a high level overview of what Scraping is.

49
00:02:56.610 --> 00:02:59.180
But why would you ever need to do that or want to do it.

50
00:02:59.460 --> 00:03:02.850
And this is where we start to get into that gray area I mentioned.

51
00:03:02.880 --> 00:03:03.970
So why scrape.

52
00:03:04.170 --> 00:03:09.640
Well let's say that you want some data from a website that doesn't provide it to you.

53
00:03:09.660 --> 00:03:13.000
It doesn't provide an API application programming interface.

54
00:03:13.020 --> 00:03:18.390
There's no easy way for you to write code to get just the data you want what you could do is scrape

55
00:03:18.390 --> 00:03:22.650
the data off of that web page for example here is Craigslist.

56
00:03:22.650 --> 00:03:24.460
We are not going to scrape Craigslist.

57
00:03:24.460 --> 00:03:26.290
I'll explain why in a moment.

58
00:03:26.430 --> 00:03:33.840
But if we wanted to hypothetically I wanted to do some analysis of rent apartment rentals two bedroom

59
00:03:33.840 --> 00:03:37.580
apartments in San Francisco and charge them overtime or something.

60
00:03:37.590 --> 00:03:42.330
Or I wanted to be able to understand you know when rents went up and down over the course of a year

61
00:03:42.540 --> 00:03:47.270
what's the best best month historically for me to buy an apartment or to rent an apartment.

62
00:03:47.280 --> 00:03:52.800
Is there a time that's cheaper at the holidays this summer that sort of thing to do that I need the

63
00:03:52.800 --> 00:03:53.340
data.

64
00:03:53.430 --> 00:03:58.870
And Craigslist doesn't have a nice API as far as I know that that allows you to do that.

65
00:03:58.890 --> 00:04:03.870
You can use and just ask for you know give me all of your current apartments or give me all the apartment

66
00:04:03.870 --> 00:04:12.240
rents from 2015 what we could do instead is write Python and ask that Python script to request this

67
00:04:12.240 --> 00:04:13.230
web page.

68
00:04:13.440 --> 00:04:15.240
And if this is all that we needed.

69
00:04:15.360 --> 00:04:20.660
I mean remember this has aged him all that we're seeing as humans it's been displayed for us.

70
00:04:20.790 --> 00:04:27.630
But if we view the page source this is our lovely mess of code we get all of this comes back and this

71
00:04:27.630 --> 00:04:29.190
is where scraping gets messy.

72
00:04:29.190 --> 00:04:33.030
We have to identify where the information is that we want.

73
00:04:33.180 --> 00:04:35.160
And let's see if I can find an example.

74
00:04:35.280 --> 00:04:43.590
Here's one listing I believe all of this and we have things like the date we have the title lovely home

75
00:04:43.590 --> 00:04:45.290
with a beautiful garden view.

76
00:04:45.510 --> 00:04:48.190
We have the price and twenty five hundred.

77
00:04:48.480 --> 00:04:52.460
Here's another one bath top floor skylight with parking.

78
00:04:52.620 --> 00:04:54.120
Four thousand ninety five.

79
00:04:54.120 --> 00:04:55.800
The neighborhood.

80
00:04:55.800 --> 00:05:00.130
And you can see that it's not only stored here it's stored reliable way.

81
00:05:00.130 --> 00:05:06.210
So the neighborhood is always in this span if you haven't seen him all this might be a little bit difficult

82
00:05:06.460 --> 00:05:11.560
but you should be able to pick up quick enough to understand that the neighborhood on every result is

83
00:05:11.560 --> 00:05:18.460
always wrapped in this tag called spanne that says class equals result hood hood short for neighborhood.

84
00:05:18.460 --> 00:05:20.030
Same thing up here.

85
00:05:20.500 --> 00:05:23.280
Here's one class equals result Hood.

86
00:05:23.290 --> 00:05:29.410
And then this is a neighborhood S.F. San Francisco State University slash Portola which it's called

87
00:05:29.410 --> 00:05:30.630
Portola not Portola.

88
00:05:30.710 --> 00:05:32.500
And just thought at that recently.

89
00:05:32.560 --> 00:05:35.120
So there's all these you know information here.

90
00:05:35.320 --> 00:05:41.920
We can request this web page get all of this data back and all of this extra crap that we don't want

91
00:05:42.220 --> 00:05:43.920
if all I wanted were the rents.

92
00:05:44.020 --> 00:05:47.650
Then this is a lot of work but we can do it it would work.

93
00:05:47.650 --> 00:05:50.050
There's nothing making this this each time.

94
00:05:50.080 --> 00:05:50.760
It's not private.

95
00:05:50.770 --> 00:05:55.070
I mean that's the point is that we go to it as humans in the browser we see it.

96
00:05:55.240 --> 00:05:58.180
There's nothing stopping our code from going here as well.

97
00:05:58.210 --> 00:06:04.070
It takes a little extra work to finesse it and get what we want out of here but it's absolutely possible.

98
00:06:04.420 --> 00:06:09.080
So to wrap that up you want data from a web page you want to analyze it you want to store it.

99
00:06:09.400 --> 00:06:11.220
You maybe you want to steal it.

100
00:06:11.260 --> 00:06:16.390
This is like I said this is the ethical part and you can't get it otherwise there is no API there is

101
00:06:16.390 --> 00:06:21.850
no CSP file download you can't download a database containing all the information.

102
00:06:21.850 --> 00:06:26.700
If that's the case you can scrape to get the data instead of manually.

103
00:06:26.710 --> 00:06:31.330
I mean you could pay people a lot of money to go and just copy and paste things and put them in a file

104
00:06:31.330 --> 00:06:32.350
for you.

105
00:06:32.450 --> 00:06:35.620
But if you wanted to do this for every you know Craigslist has.

106
00:06:35.740 --> 00:06:40.420
I don't know how many cities but a couple of thousand across the U.S. I'd imagine if you wanted to get

107
00:06:40.420 --> 00:06:46.900
apartment rents in all of those cities every day you would need a lot of money and an army of online

108
00:06:46.900 --> 00:06:48.890
clickers and copiers and posters.

109
00:06:48.910 --> 00:06:50.880
So instead you can scrape and automate all of it.
