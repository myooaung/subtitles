WEBVTT
1
00:00:00.300 --> 00:00:03.540
Which brings us to is it OK.

2
00:00:03.780 --> 00:00:04.840
Is this bad.

3
00:00:04.950 --> 00:00:06.900
Am I in trouble for doing this.

4
00:00:06.930 --> 00:00:09.110
And the answer is yes and no.

5
00:00:09.240 --> 00:00:10.830
It really really depends.

6
00:00:11.040 --> 00:00:13.020
Let's just run through the bullet points first.

7
00:00:13.200 --> 00:00:17.870
Some websites just don't want you to scrape them just like in Python.

8
00:00:17.970 --> 00:00:22.230
You know we can make variable's kind of private pseudo private.

9
00:00:22.230 --> 00:00:23.710
We can ask people please.

10
00:00:23.730 --> 00:00:28.450
This is not for you to use outside the class but there's nothing stopping them.

11
00:00:28.740 --> 00:00:33.760
Kind of the same thing with scraping a lot of developers and companies try and make their data harder

12
00:00:33.790 --> 00:00:34.650
just scrape.

13
00:00:34.650 --> 00:00:37.880
They're constantly updating the team out changing structures.

14
00:00:37.880 --> 00:00:39.850
Let's talk about that in a moment as well.

15
00:00:40.140 --> 00:00:46.200
And they try and make it hard but they can't actually prevent you from doing it because by making their

16
00:00:46.350 --> 00:00:51.900
team available to all of their users they're making it available to any user who wants to write code

17
00:00:51.910 --> 00:00:52.640
descript.

18
00:00:52.860 --> 00:00:58.890
But there is a system in place there's a way for a web site to tell you that they want or don't want

19
00:00:58.890 --> 00:01:03.000
certain pages to be accessed by programatic your code.

20
00:01:03.210 --> 00:01:05.700
And it's called the robot's text file.

21
00:01:05.700 --> 00:01:11.160
And this is a Web site's way of saying we don't want any code accessing all of these pages but this

22
00:01:11.160 --> 00:01:13.670
page is OK but it is not law.

23
00:01:13.680 --> 00:01:14.660
It's not rule.

24
00:01:14.670 --> 00:01:16.620
It's just convention.

25
00:01:16.620 --> 00:01:22.260
And sometimes people might say it's wishful thinking on the part of the Web sites for example I'm now

26
00:01:22.260 --> 00:01:28.290
on I am D-B let's say that I wanted to I don't know download data about directors and I was trying to

27
00:01:28.290 --> 00:01:33.330
figure out you know the I don't know some statistics about how many female directors there are on all

28
00:01:33.330 --> 00:01:39.240
of I am D.B I would scrape all directors data and maybe I want to find you know what city in England

29
00:01:39.240 --> 00:01:43.090
has produced the most directors is something crazy like that.

30
00:01:43.110 --> 00:01:49.520
Well we could go and find all directors and then for each page we would get some information whatever

31
00:01:49.520 --> 00:01:50.780
you want.

32
00:01:50.790 --> 00:01:51.800
Remember it's H-2 him.

33
00:01:51.800 --> 00:01:53.480
It's a lot messier than what we see.

34
00:01:53.640 --> 00:02:00.970
But before we do anything if we were a thoughtful developer we could consult the robots that TXI file.

35
00:02:01.080 --> 00:02:04.040
So it's IMT B.Com slash robots that T.

36
00:02:04.290 --> 00:02:06.210
And this is the guidelines.

37
00:02:06.420 --> 00:02:11.400
And you can see it's actually kind of funny for some reason they've singled out Yahoo's slurper crawler

38
00:02:11.730 --> 00:02:15.670
and that code and they've disallowed almost everything.

39
00:02:16.050 --> 00:02:22.490
I think they may have allowed it to do a little bit more than what they've disallowed for everyone else.

40
00:02:22.500 --> 00:02:23.900
So there's two sections on here.

41
00:02:23.970 --> 00:02:33.420
If you are Yahoo's code versus everyone else and everyone else basically has everything disallowed every

42
00:02:33.420 --> 00:02:34.580
part of the page.

43
00:02:34.980 --> 00:02:36.360
And if we compare that.

44
00:02:36.600 --> 00:02:43.290
I haven't actually gone through it compared but I'm not sure if they're allowed or disallowed more or

45
00:02:43.290 --> 00:02:45.090
fewer items.

46
00:02:45.100 --> 00:02:50.640
It's not it's unclear to me but it doesn't matter because what we can see here is that pretty much everything

47
00:02:50.640 --> 00:02:51.410
is disallowed.

48
00:02:51.540 --> 00:02:57.020
So things like movies we can't look at slash movies with code or we're not supposed to comment.

49
00:02:57.360 --> 00:03:03.910
Actors actresses TV schedules awards directors everything that we would care about.

50
00:03:04.060 --> 00:03:06.200
It's unavailable to us according to this.

51
00:03:06.270 --> 00:03:10.770
Like you said it's not set in stone but this is what they're asking us not to do.

52
00:03:10.770 --> 00:03:14.500
Compare this to the robots that textfile on rhythm school but.

53
00:03:14.730 --> 00:03:19.820
This is a boot camp in San Francisco that I work with and a couple of my friends started it.

54
00:03:19.860 --> 00:03:21.550
You can see it's a lot more forgiving.

55
00:03:21.870 --> 00:03:28.220
User Agent star means anyone wherever you're coming from you're allowed to access everything.

56
00:03:28.380 --> 00:03:30.150
That's what this is signifying here.

57
00:03:30.450 --> 00:03:32.140
So it's way more forgiving.

58
00:03:32.160 --> 00:03:36.430
There's no exceptions there's no disallows compared to I am D-B.

59
00:03:36.480 --> 00:03:41.100
One thing I'd like to point out is that if you are scraping you want to be polite either way if you're

60
00:03:41.100 --> 00:03:46.430
doing it with the blessing of the website or you're doing it sneakily you want to.

61
00:03:46.430 --> 00:03:51.040
If you're making a ton of requests like if we were trying to scrape Craigslist not that we should.

62
00:03:51.160 --> 00:03:52.840
And I'll tell you why in just a second.

63
00:03:52.860 --> 00:03:54.780
There's been some lawsuits involved.

64
00:03:54.960 --> 00:04:01.170
But if we wanted to try that and we wanted to get every page not just the high level data for the apartments

65
00:04:01.200 --> 00:04:06.840
but I wanted the full description where I have to actually open up each apartment and click on a link

66
00:04:07.050 --> 00:04:11.310
or programmatically request it then that means might be working with.

67
00:04:11.310 --> 00:04:14.520
I don't know a hundred thousand or more a day.

68
00:04:14.580 --> 00:04:18.990
We want to space the requests out so we don't want to just constantly be making these requests one after

69
00:04:18.990 --> 00:04:20.910
another over and over and over.

70
00:04:20.940 --> 00:04:22.800
Way faster than any human would.

71
00:04:23.010 --> 00:04:26.210
And that's for one reason that's to be polite.

72
00:04:26.280 --> 00:04:28.120
We don't want to overload their servers.

73
00:04:28.260 --> 00:04:35.610
But also if they notice if the developers or a server notices 100000 requests coming from one IP address

74
00:04:35.870 --> 00:04:38.390
and it's very clear that somebody is scraping them.

75
00:04:38.820 --> 00:04:43.320
So you want to be POLITES you want to space things out if you're going to be repeated the scraping over

76
00:04:43.320 --> 00:04:44.680
and over and over.

77
00:04:44.700 --> 00:04:47.150
So now I have a cautionary tale.

78
00:04:47.310 --> 00:04:50.620
So this Craigslist Inc versus three taps Inc.

79
00:04:50.760 --> 00:04:52.980
It has a Wikipedia page the lawsuit.

80
00:04:53.670 --> 00:04:59.100
As far as I'm no legal scholar but this was big news back in the day of some developer circles when

81
00:04:59.100 --> 00:05:05.370
Moses couple of years ago 2012 where a court case there was a court case where this company three taps

82
00:05:05.400 --> 00:05:10.590
inquere scraping Craigslist and using their data to build they weren't just analyzing it like I was

83
00:05:10.590 --> 00:05:11.350
talking about.

84
00:05:11.460 --> 00:05:13.980
They built another web site I believe.

85
00:05:14.310 --> 00:05:19.020
And what happened is that Craigslist didn't approve of that and they weren't able to just sue immediately.

86
00:05:19.020 --> 00:05:22.410
So it's not like I'm not giving legal advice.

87
00:05:22.680 --> 00:05:24.180
Just a disclaimer here.

88
00:05:24.180 --> 00:05:30.520
As far as I understand you could not be sued or go to jail or be fined or something simply for scraping.

89
00:05:30.780 --> 00:05:36.810
But once a cease and desist letter has been sent this says that sending a cease and desist letter and

90
00:05:36.900 --> 00:05:43.080
acting an IP address block is sufficient notice of online trespassing which a plaintiff can use to claim

91
00:05:43.080 --> 00:05:45.180
a violation of the computer fraud and abuse act.

92
00:05:45.180 --> 00:05:47.040
So Craigslist wasn't a fan that found out about it.

93
00:05:47.040 --> 00:05:51.560
They sent a cease and desist and they blocked the IP address of three taps Inc.

94
00:05:51.810 --> 00:05:55.020
That was enough to basically count all men trespassing.

95
00:05:55.020 --> 00:05:58.500
In the end Craigslist won three taps had to shut down.

96
00:05:58.500 --> 00:06:03.690
They had to pay a million dollars which was donated to the electronic frontier Foundation.

97
00:06:03.700 --> 00:06:06.190
And yeah I think that's pretty much it.

98
00:06:06.210 --> 00:06:11.520
Overall the point that I'm trying to make here is that Scraping is potentially problematic and you do

99
00:06:11.520 --> 00:06:16.830
want to be careful you don't want to just launch a Web site or a company that you know relies on scraping

100
00:06:17.190 --> 00:06:19.740
and especially if you do get a cease and desist.

101
00:06:19.770 --> 00:06:23.870
Like I said or they block your IP address then you probably should stop scraping.

102
00:06:24.030 --> 00:06:27.050
And I thought Craigslist was not involved with this sort of thing anymore.

103
00:06:27.060 --> 00:06:32.700
But in doing the search to find that Wikipedia page I found this article just from a couple or I guess

104
00:06:32.700 --> 00:06:39.600
about a year ago now that this company Red pad was sued by Craigslist and they were scraping data from

105
00:06:39.600 --> 00:06:42.200
Craigslist and making their own front end.

106
00:06:42.210 --> 00:06:43.700
I'm not sure of the details.

107
00:06:43.830 --> 00:06:47.880
But there is a 60 million dollar penalty that rad pad had to pay.

108
00:06:47.920 --> 00:06:52.670
And if you're interested I think what Redpath actually did was that they went on Craigslist and you

109
00:06:52.690 --> 00:06:58.590
know Craigslist generates these e-mails for you these like obfuscated hidden e-mails that you can reply

110
00:06:58.590 --> 00:06:59.250
to.

111
00:06:59.250 --> 00:07:03.660
I think they were scraping and grabbing all of those e-mail addresses and then sending e-mails and spamming

112
00:07:03.660 --> 00:07:05.030
them something like that.

113
00:07:05.040 --> 00:07:06.850
So that's why the penalty was so massive.

114
00:07:07.080 --> 00:07:07.410
OK.

115
00:07:07.470 --> 00:07:13.190
So you can see it's a really messy world of scraping and just of Internet privacy in general.

116
00:07:13.230 --> 00:07:17.410
So we're going to stay away from anything potentially in that gray area.

117
00:07:17.430 --> 00:07:22.120
We're going to scrape my own sites and sites that I've worked on where we have permission to scrape.

118
00:07:22.320 --> 00:07:28.410
I just I didn't feel good about sending thousands of people potentially to go scrape some site that

119
00:07:28.410 --> 00:07:33.900
may change their mind and that also ties into the fact that when a web site changes if they catch on

120
00:07:33.900 --> 00:07:36.600
that they're being scraped off and they will change urged.

121
00:07:36.610 --> 00:07:38.880
Tim Allen basically break your code.

122
00:07:38.880 --> 00:07:41.120
And I didn't want that to happen in this course as well.

123
00:07:41.130 --> 00:07:43.170
So we have some other examples.

124
00:07:43.170 --> 00:07:44.160
We will be scraping.

125
00:07:44.160 --> 00:07:49.230
You can take what you learned in this section and apply it anywhere but just be responsible like I said

126
00:07:49.680 --> 00:07:50.190
we'll get.
