WEBVTT
1
00:00:01.680 --> 00:00:04.950
Hello everyone and welcome to this lecture and this lecture.

2
00:00:05.010 --> 00:00:08.430
We're going to talk about everything important.

3
00:00:08.730 --> 00:00:15.810
Activation function Okay so call of the blue activation function which is the electrified linear unit

4
00:00:15.900 --> 00:00:17.370
function on it.

5
00:00:17.450 --> 00:00:17.860
OK.

6
00:00:17.910 --> 00:00:22.160
Obviously it looks you know kind of very intimidating but trust me it's really simple.

7
00:00:22.560 --> 00:00:26.650
So if you get a call from previous lecture here we had our image.

8
00:00:26.880 --> 00:00:30.450
And the first step that we apply the convolution first layer.

9
00:00:30.660 --> 00:00:35.880
Okay which is kind of in a bunch of feature detectors or kernel's if you as a member we can do like

10
00:00:35.880 --> 00:00:38.960
blurring we can do like sharpening.

11
00:00:39.240 --> 00:00:45.460
And here this is kind of you know like a kid like gum like different variations of our image that contain

12
00:00:45.480 --> 00:00:48.600
the most important and critical information out of our image.

13
00:00:48.600 --> 00:00:49.090
Right.

14
00:00:49.410 --> 00:00:49.840
OK.

15
00:00:50.190 --> 00:00:55.440
And what we do afterwards before we apply we'll call the pwning which is going to be discussing in the

16
00:00:55.440 --> 00:00:58.760
next lecture we apply what we call it here.

17
00:00:58.980 --> 00:01:03.600
LIEU activation function for critics define the linear activation function.

18
00:01:03.600 --> 00:01:08.550
Simply put Luni ears are used to add non-linearity in the future map.

19
00:01:09.060 --> 00:01:16.850
It can be used to enhance what we call it how the image is carried out or the feature map is carried.

20
00:01:16.920 --> 00:01:23.550
Simply put would that elude us is that if any value is below zero it will set it to zero.

21
00:01:23.730 --> 00:01:30.180
So if it's any value it slips a negative it will be zero and after the words if it's positive we're

22
00:01:30.180 --> 00:01:36.810
just going to pass along the exact same values or f of Y actual function of y not equal to Y in a very

23
00:01:36.810 --> 00:01:43.400
separate for storekeeper's kind of like like 45 degrees straight line.

24
00:01:43.590 --> 00:01:48.130
That's for positive values however for negative values which is going to kill these values.

25
00:01:48.280 --> 00:01:51.570
So any negative values are going to kill it to make it said it to zero.

26
00:01:52.020 --> 00:01:53.120
What's the essence of it.

27
00:01:53.120 --> 00:01:54.700
Like why do we do with this.

28
00:01:54.820 --> 00:01:57.960
Let's take a look at this specific practical example.

29
00:01:58.050 --> 00:02:01.250
Let's assume that we have here our feature detectors.

30
00:02:01.320 --> 00:02:02.730
So that's our feature detector.

31
00:02:02.790 --> 00:02:03.300
OK.

32
00:02:03.660 --> 00:02:04.920
So if you take a look.

33
00:02:04.950 --> 00:02:06.570
Let's assume that he'll you know that's.

34
00:02:06.640 --> 00:02:09.560
After we apply our current wrong or our feature detector.

35
00:02:09.810 --> 00:02:14.340
Here we have you know let's say 7 10 minus 5 2 and so on.

36
00:02:14.460 --> 00:02:20.810
What we do with that we take that image and then we feed that image to our guilloux activation function.

37
00:02:20.880 --> 00:02:23.370
We're rectified limited unit function.

38
00:02:24.090 --> 00:02:28.540
What happens is if you take a look here 7 because the value of 7 is positive.

39
00:02:28.560 --> 00:02:30.870
Well it's here somewhere here.

40
00:02:30.870 --> 00:02:36.810
So then the relo we're going to pass it along with the hue and become 7 as is 10 then becomes 10 as

41
00:02:36.810 --> 00:02:38.560
is minus 5.

42
00:02:38.580 --> 00:02:39.990
Then it will be set to zero.

43
00:02:40.020 --> 00:02:42.740
It's kind of like kind of like suppressing it.

44
00:02:42.780 --> 00:02:46.280
It's kind of killing any values that are below zero.

45
00:02:46.710 --> 00:02:54.120
If it's two becomes two if it's 1 1 and so 1 so key or simply put any value of a negative becomes set

46
00:02:54.120 --> 00:02:54.740
to zero.

47
00:02:54.750 --> 00:02:56.890
Kind of suppressing all the values.

48
00:02:57.200 --> 00:02:58.560
Okay what's the advantage of this.

49
00:02:58.560 --> 00:03:00.030
Like what's the point of this.

50
00:03:00.330 --> 00:03:01.570
So what happens here.

51
00:03:01.710 --> 00:03:03.710
Now you have your feature.

52
00:03:04.020 --> 00:03:06.900
It's kind of becomes more scattered.

53
00:03:07.140 --> 00:03:12.470
So here you have instead of having defined values within the features we have let's say 7 10 and then

54
00:03:12.480 --> 00:03:17.730
minus 5 and then minus 6 was kind of like a very high kind of variations were happiness here.

55
00:03:17.730 --> 00:03:22.110
Here you have kind of you know like all of them are asio's all of them are flat and he have kind of

56
00:03:22.110 --> 00:03:22.860
you all sit in like.

57
00:03:22.860 --> 00:03:24.960
Think of it as kind of bunch of mountains.

58
00:03:25.080 --> 00:03:28.710
Like here for example of this kind of a little bit of mountain that's kind of you know make a little

59
00:03:28.710 --> 00:03:34.770
bit make the picture pops up a little bit and there's the overall idea by adding non-linearity within

60
00:03:34.770 --> 00:03:38.510
our network by applying that elu activation function.

61
00:03:38.790 --> 00:03:45.030
So again your objective there are new ways to increase So call this period city of our matrix or make

62
00:03:45.030 --> 00:03:48.110
it like more care and make it you know kind of fear.

63
00:03:48.120 --> 00:03:50.580
Little bit here we have a certain feature in here.

64
00:03:50.580 --> 00:03:54.750
We have a certain feature and here we have a pretty much important feature in here.

65
00:03:54.900 --> 00:03:57.150
Anywhere else just a bunch of zeros.

66
00:03:57.200 --> 00:04:00.240
OK so that would make it all make the job a little bit easier.

67
00:04:00.240 --> 00:04:03.960
When you move forward to the full you connected or fishing in a network.

68
00:04:04.080 --> 00:04:11.160
To be able to detect the features more easily or the one of the more in one of the most important here

69
00:04:11.190 --> 00:04:15.550
for a video exhibition function in the gradient does not vanish.

70
00:04:15.570 --> 00:04:17.080
What do you mean here.

71
00:04:17.100 --> 00:04:20.350
If you look at it you'll see that basically the line we're going to keep going forever.

72
00:04:20.400 --> 00:04:25.140
So if you have let's say like a game like a value of let's say a million the outcome was going to be

73
00:04:25.140 --> 00:04:26.000
million too.

74
00:04:26.250 --> 00:04:29.190
So the gregan does not vanish just keep going.

75
00:04:29.190 --> 00:04:31.840
It's like 45 degrees keep going.

76
00:04:31.840 --> 00:04:32.650
Whatever.

77
00:04:32.760 --> 00:04:36.350
However here if we let's say up leitman another activation function.

78
00:04:36.410 --> 00:04:40.830
What collets sigmoid activation function which looks like this.

79
00:04:40.950 --> 00:04:43.740
You will see that it saturated a little bit.

80
00:04:43.770 --> 00:04:48.290
So simply put if we apply it input let's say let's say like lodged in put it say 10.

81
00:04:48.570 --> 00:04:54.300
You'll find the output the supressed to one which as you know kind of kind of like saturating the outwits

82
00:04:54.330 --> 00:04:56.490
which is why I'm not interested in here.

83
00:04:56.490 --> 00:04:59.310
We don't want the features of the feature let's say to be situated.

84
00:04:59.310 --> 00:04:59.860
Let's take a.

85
00:05:00.440 --> 00:05:03.020
Five available for 10 for example.

86
00:05:03.110 --> 00:05:08.990
Actually we wanted to see these very Asians or these spurious city were how scattered the future is

87
00:05:08.990 --> 00:05:10.320
within our future.

88
00:05:10.490 --> 00:05:11.140
All right.

89
00:05:11.720 --> 00:05:12.350
Okay.

90
00:05:12.800 --> 00:05:13.250
All right.

91
00:05:13.260 --> 00:05:15.110
And that's pretty much what I have for this section.

92
00:05:15.110 --> 00:05:16.550
I hope you guys enjoyed it.

93
00:05:16.550 --> 00:05:21.980
And in the future section we're going to learn how can we do Max pooling and flattening and then we're

94
00:05:21.980 --> 00:05:27.230
going to be pretty much ready to start coding our network in Jupiter notebook.

95
00:05:27.230 --> 00:05:30.360
I hope it doesn't do the lecture and see you in the next lecture.
