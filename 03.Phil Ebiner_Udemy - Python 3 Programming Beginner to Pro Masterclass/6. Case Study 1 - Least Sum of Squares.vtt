WEBVTT
1
00:00:00.480 --> 00:00:02.500
Hello everyone and welcome to this lecture.

2
00:00:03.000 --> 00:00:09.240
And the biggest lecture we gave an overview of this simple linear regression and we we now know the

3
00:00:09.350 --> 00:00:12.880
details of the model equation which is why sequence to explore B.

4
00:00:13.050 --> 00:00:18.780
And we know right now that the objective is to obtain the parameters which is M and B indicating the

5
00:00:18.780 --> 00:00:22.740
slope of the line and indicate indicating the intercept which is a white intercept.

6
00:00:22.850 --> 00:00:23.400
All right.

7
00:00:23.680 --> 00:00:31.440
To keep in this lecture we're going to just cover in a very high level technique will we call at least

8
00:00:31.530 --> 00:00:32.710
some of squares.

9
00:00:32.730 --> 00:00:33.260
Okay.

10
00:00:33.570 --> 00:00:39.450
Which is simply the technique used to pain that straightline which is the straightline that simply best

11
00:00:39.450 --> 00:00:40.750
fits the data.

12
00:00:41.130 --> 00:00:45.090
So again that's back to our example which is let's assume that we have our temperature here on the x

13
00:00:45.090 --> 00:00:45.540
axis.

14
00:00:45.540 --> 00:00:46.440
In degrees C.

15
00:00:47.340 --> 00:00:49.230
On the y axis he had we have our revenue.

16
00:00:49.500 --> 00:00:51.850
And here we have couple of points in here.

17
00:00:52.140 --> 00:00:53.820
And let's assume that you know again.

18
00:00:53.850 --> 00:00:55.800
Again go ahead with the simple thing it aggression.

19
00:00:55.800 --> 00:00:58.990
So we know that the equation you know might be a straight line.

20
00:00:59.010 --> 00:01:04.680
My problem is here right now is a kit which straightline would be this line or maybe it's been this

21
00:01:04.680 --> 00:01:08.190
line or maybe a line like going you know horizontal efforts.

22
00:01:08.220 --> 00:01:09.130
I don't know.

23
00:01:09.390 --> 00:01:11.180
So how can we or pain that print.

24
00:01:11.290 --> 00:01:12.990
You know the slope of the line.

25
00:01:13.020 --> 00:01:18.700
The B as well the intercept of the line we use a picnic on a square method.

26
00:01:18.780 --> 00:01:19.370
OK.

27
00:01:19.710 --> 00:01:24.570
So again we're not going to dig in too much into the mathematics of it but we're just going to give

28
00:01:24.570 --> 00:01:27.570
you an overview of what's happening just from a very high level.

29
00:01:27.570 --> 00:01:27.930
Why.

30
00:01:27.930 --> 00:01:33.570
Because in the short one once we go to the Jupiter notebook and the esky learn library will see that

31
00:01:33.600 --> 00:01:40.110
we can do this in a very very easy for just one line of code the two lines of code that does of these

32
00:01:40.130 --> 00:01:41.230
stuff for you or for us.

33
00:01:41.300 --> 00:01:42.030
Right.

34
00:01:42.750 --> 00:01:51.330
So the first step when we update the least square of fitting is that we simply draw perpendicular lines

35
00:01:51.360 --> 00:01:52.890
between the points.

36
00:01:53.060 --> 00:01:53.490
OK.

37
00:01:53.820 --> 00:01:55.940
And that kind of arbitrary line.

38
00:01:55.950 --> 00:01:57.330
So we assume that we have.

39
00:01:57.480 --> 00:01:59.590
Maybe that line is this line.

40
00:01:59.850 --> 00:02:05.540
So we do that we drop perpendicular lines connecting the points down to that let's say light.

41
00:02:05.550 --> 00:02:07.620
And again that line is not the final line.

42
00:02:07.710 --> 00:02:12.150
We can change the slope as we as we please we can change the way into south as we please.

43
00:02:12.150 --> 00:02:14.450
This just in an arbitrary venue.

44
00:02:14.800 --> 00:02:21.340
Next step is we calculate what we call the residual or the offset or eight.

45
00:02:21.530 --> 00:02:27.540
And again let's say we have to give kind of a very important kind of introduction to the name in the

46
00:02:27.540 --> 00:02:28.650
naming convention.

47
00:02:28.920 --> 00:02:34.140
So this point here or these points these are what we call the actual points.

48
00:02:34.140 --> 00:02:34.500
Why.

49
00:02:34.500 --> 00:02:38.400
Because these are attuned to training data that we use.

50
00:02:38.760 --> 00:02:42.500
And that's why we call it why I OK in the indicating in index.

51
00:02:42.580 --> 00:02:43.720
And that's what we call it actually.

52
00:02:43.740 --> 00:02:46.000
This is the actual true value.

53
00:02:46.680 --> 00:02:47.400
What about here.

54
00:02:47.490 --> 00:02:52.630
This what on this point simply is what we call the estimate and that's what we call it Y hat.

55
00:02:52.730 --> 00:02:59.790
With that hand that means estimate it is kind of fitted it's kind of coming from that specific straight

56
00:02:59.790 --> 00:03:00.140
line.

57
00:03:00.230 --> 00:03:00.640
OK.

58
00:03:00.810 --> 00:03:06.210
Which is again kind of a guess coming from the model and that's what I call a prediction or estimated

59
00:03:06.420 --> 00:03:07.130
value.

60
00:03:07.350 --> 00:03:10.380
And these points I will call the actual or true value.

61
00:03:10.830 --> 00:03:17.310
So the first step is we calculate the difference between the actual point and the estimated point.

62
00:03:17.400 --> 00:03:19.290
And there's this distance we call it deep.

63
00:03:19.370 --> 00:03:19.860
All right.

64
00:03:20.100 --> 00:03:27.120
And that's again he has a distance value D quints to y hat minus y where it indicates an index indicating

65
00:03:27.120 --> 00:03:30.510
for example of this is point 1 1 to 1.

66
00:03:30.600 --> 00:03:35.950
This equates to you what is 3 4 and 5 for example.

67
00:03:36.450 --> 00:03:38.240
The next step is what we do.

68
00:03:38.410 --> 00:03:40.580
If we open.

69
00:03:40.730 --> 00:03:41.180
OK.

70
00:03:41.280 --> 00:03:48.840
The difference between this which is solid D or I do that we squared that value and then we some some

71
00:03:48.930 --> 00:03:53.120
of the residuals for all the points so we all in the D for this.

72
00:03:53.150 --> 00:03:58.020
For example a point we'll put in again the D here for this point will turn the D for this point and

73
00:03:58.020 --> 00:03:58.730
so on.

74
00:03:59.010 --> 00:04:03.780
We squared all these values with some of them up and then we'll pin the minimum venue.

75
00:04:04.020 --> 00:04:07.470
And that's why it's called the minimum or at least some of squeers.

76
00:04:07.470 --> 00:04:14.880
So we are paying the sum of squares so we sum up all the squares of the residuals and then we can kind

77
00:04:14.880 --> 00:04:20.530
of you apply kind of optimization function to coupling the minimum venue or the least value.

78
00:04:20.760 --> 00:04:23.220
Once you are in that minimum value that set.

79
00:04:23.240 --> 00:04:24.020
Congratulations.

80
00:04:24.020 --> 00:04:30.170
That means you were able to obtain the best or perfect line that reduces simply the error.

81
00:04:30.450 --> 00:04:32.810
Then that line here whatever that line is might be.

82
00:04:32.810 --> 00:04:38.160
This line might be for example lenola climb up a little bit maybe a line down here a little bit but

83
00:04:38.160 --> 00:04:40.480
the overall idea is that line is the line.

84
00:04:40.500 --> 00:04:46.170
The perfect line that minimizes the error or minimized the distance.

85
00:04:46.170 --> 00:04:49.870
The summation of distances between the points.

86
00:04:49.950 --> 00:04:56.670
Any of these points and that line and this technique is all of the least sum of squares and it's really

87
00:04:56.670 --> 00:04:59.580
powerful technique and that's actually King we be using.

88
00:04:59.610 --> 00:05:05.190
When we jump to the optimal book to obtain our best fit line.

89
00:05:05.390 --> 00:05:05.990
Ah.

90
00:05:06.430 --> 00:05:09.690
OK let's go through these couple of points here.

91
00:05:09.690 --> 00:05:15.370
Lee squid fishing is a way to find the best fit curve or line for the set of points.

92
00:05:15.780 --> 00:05:20.560
Again this is a line which is the best fit line that we can use for all these couple of points.

93
00:05:20.610 --> 00:05:24.320
The sum of squares of the offsets will qualify residuals.

94
00:05:24.340 --> 00:05:26.710
These basically error.

95
00:05:26.900 --> 00:05:31.410
Then you will of the area which is the difference between our actual points and our.

96
00:05:31.410 --> 00:05:38.580
It is our estimated point what we call the predicted point that coming out from the from the model they

97
00:05:38.590 --> 00:05:45.850
are used mainly to estimate the best fit curve or like least square method is used to open the efficiency

98
00:05:45.920 --> 00:05:46.660
M and B.

99
00:05:46.960 --> 00:05:51.210
So the objective again of this technique is to paint a straight line one say they all know that line

100
00:05:51.490 --> 00:05:53.280
then congratulations that's perfect.

101
00:05:53.290 --> 00:05:57.940
Then I know the end of the line which is a strip of the line and then you know the B which is the y

102
00:05:57.970 --> 00:05:59.280
intercept of the line.

103
00:05:59.380 --> 00:06:03.730
And that means there was a built or pain in the mathematical model that govern the relationship between

104
00:06:03.730 --> 00:06:05.690
the temperature and our area.

105
00:06:05.900 --> 00:06:07.210
Perfect.

106
00:06:07.460 --> 00:06:08.250
All right.

107
00:06:08.710 --> 00:06:14.410
So just one quick overview before we jump into the educational book a very important kind of review

108
00:06:14.470 --> 00:06:15.780
of the.

109
00:06:16.060 --> 00:06:17.510
How can we perform the teeling.

110
00:06:17.770 --> 00:06:23.540
So when we perform the training in general what we do is that we open the inspired data set OK you it

111
00:06:23.560 --> 00:06:28.950
all the data points that we have and then we divide the dataset into two sets.

112
00:06:28.990 --> 00:06:32.730
It's what we call a training set end testing set.

113
00:06:32.840 --> 00:06:33.210
All right.

114
00:06:33.340 --> 00:06:39.030
And kind of the rule of thumb that we use 75 percent for seining and 25 percent for testing.

115
00:06:39.370 --> 00:06:45.700
What do you mean by this so simply let's assume that we have here for example 100 samples there and

116
00:06:45.700 --> 00:06:46.400
compete again.

117
00:06:46.420 --> 00:06:47.510
Temperature points.

118
00:06:47.650 --> 00:06:54.110
And the revenue what we do is we divide these points into 75 percent training samples.

119
00:06:54.130 --> 00:06:58.960
So again let's say this point we're get to be from trott's training this point for example we're going

120
00:06:58.960 --> 00:06:59.830
to be fortini.

121
00:06:59.980 --> 00:07:04.130
However these two points let's say we're going to be dedicated meaningful testing.

122
00:07:04.330 --> 00:07:12.360
So simply we divide the hundred samples into 75 samples for trailing and 25 percent for testing.

123
00:07:12.580 --> 00:07:14.240
What's the objective of this.

124
00:07:14.290 --> 00:07:21.250
The objective of this is that we wanted to ensure that our model is in general is able to generalize

125
00:07:21.250 --> 00:07:22.570
the data set.

126
00:07:22.570 --> 00:07:23.490
What do we mean by this.

127
00:07:23.500 --> 00:07:29.890
Again we what we mean is that we want it to perform the training on a specific dataset.

128
00:07:29.980 --> 00:07:32.540
Well let's say 75 teeny samples.

129
00:07:32.620 --> 00:07:34.790
And then once out modern trained.

130
00:07:34.940 --> 00:07:35.180
OK.

131
00:07:35.220 --> 00:07:36.670
That's a very important point.

132
00:07:36.670 --> 00:07:44.380
We think that teen model which is again why equals to X plus and B with known values for M and B and

133
00:07:44.380 --> 00:07:49.720
we wanted to apply a testing dataset which is a 25 semples that we have you.

134
00:07:49.840 --> 00:07:57.730
The key element the key point here is that this 25 samples that these samples have never been seen by

135
00:07:57.760 --> 00:08:00.150
the train model in the past.

136
00:08:00.160 --> 00:08:06.550
So one key element that we need to make sure that none of these 25 points have venues doing training.

137
00:08:06.830 --> 00:08:10.660
Okay and that's the ability to test out model capability.

138
00:08:10.660 --> 00:08:16.100
So we wanted to test the model we want to test the model simply on data sets that has never been seen.

139
00:08:16.480 --> 00:08:16.890
Okay.

140
00:08:16.930 --> 00:08:21.940
Let's take a look at another example it's assumed that we wanted for instance to let's say terrene self

141
00:08:21.940 --> 00:08:28.840
driving car for example to let's say classify traffic signs when it sees it sees as a stop sign it says

142
00:08:28.870 --> 00:08:30.030
Okay that's a stop sign.

143
00:08:30.160 --> 00:08:33.350
If it is let's say a sign that means a yield sign and so on.

144
00:08:33.430 --> 00:08:37.860
What we do with it we train the model the routine the car to identify these traffic signs.

145
00:08:38.200 --> 00:08:41.850
And what we do is that we take this car and then we put it on the road.

146
00:08:41.920 --> 00:08:42.680
Okay.

147
00:08:43.030 --> 00:08:49.720
On the road hasn't seen any of this data before it has seen any of these traffic signs on the actual

148
00:08:49.720 --> 00:08:51.390
testing before.

149
00:08:51.580 --> 00:08:58.630
And that's the key element that's how we can actually test the power of our network is by again using

150
00:08:58.630 --> 00:09:02.040
the testing data set that has never been seen during training for us.

151
00:09:02.340 --> 00:09:03.000
All right.

152
00:09:03.400 --> 00:09:04.170
And that's it.

153
00:09:04.180 --> 00:09:06.160
That's pretty much all what we have for this lecture.

154
00:09:06.160 --> 00:09:06.890
Let's see.

155
00:09:07.000 --> 00:09:12.660
Let's recap so what we have done here so far is that we will know how can we open the modern Premier

156
00:09:12.670 --> 00:09:14.730
it is using these squares.

157
00:09:14.860 --> 00:09:20.620
Again we are in the error or the deal of the residuals between the actual points and the estimate of

158
00:09:20.620 --> 00:09:27.180
points for all the points we simply Square them some them up and we are upping the minimum then.

159
00:09:27.520 --> 00:09:33.010
Once you're paying the minimum value then we are lucky then that we're able to obtain the best line

160
00:09:33.040 --> 00:09:38.980
or the best value for N and B that minimizes all that error venues and that's it.

161
00:09:38.980 --> 00:09:43.310
Once we have that model then we can use it afterwards for testing.

162
00:09:43.360 --> 00:09:47.860
A key element or key point that we need to make sure that this thing data points that had never been

163
00:09:47.860 --> 00:09:54.280
seen but never been seen by the model during tea or ETs and now we are ready to actually go ahead and

164
00:09:54.280 --> 00:09:58.440
try to model simple aggression in his book or book.

165
00:09:58.460 --> 00:10:01.500
I hope you guys enjoy their lecture and see you in the next election.
