WEBVTT
1
00:00:01.040 --> 00:00:04.290
[Autogenerated] it would be a little sad if we did all this cool

2
00:00:04.290 --> 00:00:08.460
stuff to set up load balancers and auto scaling groups but then

3
00:00:08.460 --> 00:00:12.230
we didn't get to try them out kind of like if I showed you a

4
00:00:12.230 --> 00:00:14.740
really nice sports car, sat you down in it.

5
00:00:14.740 --> 00:00:18.620
Got you totally pumped to drive it and then said time's up,

6
00:00:18.620 --> 00:00:21.740
gotta go well I'm not going to leave you hanging.

7
00:00:21.740 --> 00:00:26.220
Let's see what this puppy can do with our scaling policies in place.

8
00:00:26.220 --> 00:00:28.760
We can put a little load on our application and

9
00:00:28.760 --> 00:00:31.340
watch the instances scale as needed.

10
00:00:31.340 --> 00:00:33.320
There are many ways you can simulate load,

11
00:00:33.320 --> 00:00:37.240
you could disable browser cache and refresh a bunch of times.

12
00:00:37.240 --> 00:00:39.950
A simpler and more automated way is to use a tool

13
00:00:39.950 --> 00:00:42.840
like j meter or Apache benchmark.

14
00:00:42.840 --> 00:00:47.480
I already have Apache benchmark installed so I'm going to use that to simulate

15
00:00:47.480 --> 00:00:52.510
load on the load balancer and trigger scaling and my command line I'll enter the

16
00:00:52.510 --> 00:01:01.150
command a B dash in 100 dash C five and then the URL for the load balancer with

17
00:01:01.150 --> 00:01:04.370
a trailing slash and the http protocol.

18
00:01:04.370 --> 00:01:08.270
This will send a total of 100 requests to my load balancer at a

19
00:01:08.270 --> 00:01:11.440
maximum of five concurrent requests at a time.

20
00:01:11.440 --> 00:01:14.640
You may need to run this command several times to generate

21
00:01:14.640 --> 00:01:16.730
enough traffic to trigger the alarm.

22
00:01:16.730 --> 00:01:18.170
After _______ this off,

23
00:01:18.170 --> 00:01:21.750
I'm going to time warp the video again as the cloudwatch alarm needs

24
00:01:21.750 --> 00:01:27.250
about five minutes to do aggregating before it triggers Now if I update

25
00:01:27.250 --> 00:01:29.760
the activity history in my auto scaling group,

26
00:01:29.760 --> 00:01:32.740
you can see that it is _______ off a new instance.

27
00:01:32.740 --> 00:01:35.730
It will take a few minutes before this is completely in service,

28
00:01:35.730 --> 00:01:39.410
but it looks like everything worked perfectly based on

29
00:01:39.410 --> 00:01:41.660
our policies and scaling group details.

30
00:01:41.660 --> 00:01:44.980
The group will scale up to a maximum of four instances.

31
00:01:44.980 --> 00:01:48.440
If the load continues to trip the cloudwatch alarm,

32
00:01:48.440 --> 00:01:51.620
I'm time warping the video again here to about 15 minutes

33
00:01:51.620 --> 00:01:54.490
after I triggered the load and network out.

34
00:01:54.490 --> 00:01:57.970
Traffic should have gone below the alarm we had and are scaling

35
00:01:57.970 --> 00:02:01.150
group should have shrunk back down to two instances.

36
00:02:01.150 --> 00:02:05.040
Let's take a look at our activity history again refreshing it.

37
00:02:05.040 --> 00:02:13.000
You can see that the auto scaling group terminated the instance that was no longer needed based on our scaling policies.

