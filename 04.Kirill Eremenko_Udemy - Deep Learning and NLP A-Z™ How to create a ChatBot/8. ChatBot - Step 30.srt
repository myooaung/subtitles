1
00:00:00,590 --> 00:00:05,280
Hello and welcome to this new tutorial and this one we're going to do something very important.

2
00:00:05,300 --> 00:00:08,890
We're going to get the training predictions and the test predictions.

3
00:00:09,080 --> 00:00:13,620
So just to make sure you understand we're not starting the training yet.

4
00:00:13,620 --> 00:00:18,020
There is the whole process of the training and you'll see precisely when it starts that's going to be

5
00:00:18,020 --> 00:00:20,990
from the moment we start the for loop over the epochs.

6
00:00:21,170 --> 00:00:27,200
But now we have to get the training predictions and the desperate actions when fitting the model with

7
00:00:27,320 --> 00:00:30,860
the inputs we loaded in this specific line of code.

8
00:00:31,040 --> 00:00:37,020
So here we loaded the inputs the target which is what we need to feed the to on that work with.

9
00:00:37,130 --> 00:00:42,920
And therefore right now what we need to do is get the training and test predictions when in putting

10
00:00:43,160 --> 00:00:47,960
these inputs and targets and learning rate and keep probability into the neural network.

11
00:00:48,000 --> 00:00:49,030
So let's do this.

12
00:00:49,040 --> 00:00:54,290
The good news you know what the good news is is that we have the perfect function for this that will

13
00:00:54,290 --> 00:01:00,660
directly return what we want and that function is of course the last function we made in part two to

14
00:01:00,680 --> 00:01:04,860
stick to sec model which represents of course the whole sectors like.

15
00:01:04,940 --> 00:01:10,740
But as you can see it's a function that returns in the end the training predictions and the test predictions.

16
00:01:10,940 --> 00:01:16,720
So this is going to be a very good stuff to toile we're just going to use this function and input all

17
00:01:16,730 --> 00:01:22,030
its arguments one by one that we now made ready in the previews to toils.

18
00:01:22,070 --> 00:01:24,940
Indeed we prepared the sequence length.

19
00:01:25,010 --> 00:01:30,560
We have the budget size that was in the hyper parameters and the first code section and this part 3.

20
00:01:30,620 --> 00:01:36,580
We also have to keep probability we have the targets and inputs things to the model inputs function.

21
00:01:36,620 --> 00:01:40,020
We got previously and we also have all these parameters.

22
00:01:40,100 --> 00:01:47,060
Basically we have everything to use this sect to sect model function and return the training prediction

23
00:01:47,150 --> 00:01:48,650
and the test predictions.

24
00:01:48,650 --> 00:01:49,640
So let's do this.

25
00:01:49,730 --> 00:01:55,160
It's going to be very easy we'll just have to enter the arguments that the set to signal function one

26
00:01:55,160 --> 00:01:56,060
by one.

27
00:01:56,060 --> 00:02:01,550
All right so since this function returns to training predictions and desperations very simply we're

28
00:02:01,550 --> 00:02:10,680
going to introduce two new variables that are going to be our training predictions and our test predictions.

29
00:02:10,690 --> 00:02:11,560
All right.

30
00:02:11,560 --> 00:02:17,590
Our training operation in our desperations not to be confused with the local variable in the sector

31
00:02:17,600 --> 00:02:25,040
signal function that we defined this time it's the real variables that we will use later on in the training.

32
00:02:25,300 --> 00:02:35,860
So training breaks and desperations that are going to be returned by our SEC to SEC all function.

33
00:02:35,950 --> 00:02:39,410
And now let's put the arguments one by one.

34
00:02:39,550 --> 00:02:42,440
The first one is the inputs.

35
00:02:42,490 --> 00:02:46,370
However I noticed these are not yet in the right shape.

36
00:02:46,480 --> 00:02:52,030
And if you followed one of our other courses like the machinery course or the deep green course I sometimes

37
00:02:52,030 --> 00:02:59,620
used the reshape function by nuns by to reshape the diamond sions of a tensor or a number array when

38
00:02:59,620 --> 00:03:03,810
working with by to get it in the right shape for the model.

39
00:03:03,850 --> 00:03:05,280
And actually that's what we have to do here.

40
00:03:05,290 --> 00:03:08,960
The inputs so far are not in the right shape.

41
00:03:09,040 --> 00:03:12,040
So we going to use kind of the same thing as the reshape function.

42
00:03:12,040 --> 00:03:19,120
By and by but since were working with tons of flow this function is going to be the reverse function

43
00:03:19,450 --> 00:03:20,940
that is going to take the inputs.

44
00:03:21,070 --> 00:03:22,860
Let's not forget the parenthesis here.

45
00:03:23,050 --> 00:03:28,110
The reverse function that basically reverses the dimensions of a tensor.

46
00:03:28,120 --> 00:03:34,630
All right but then remembering the reshape function by non-bio we have to specify minus 1 and 1 to reverse

47
00:03:34,630 --> 00:03:37,210
dimensions of this tensor shape and intensively.

48
00:03:37,210 --> 00:03:43,060
We do it this way with the second argument here which is going to be in square brackets minus 1.

49
00:03:43,090 --> 00:03:49,360
I will of course give the documentation of both this reverse function by tens of flow and the reshape

50
00:03:49,360 --> 00:03:50,600
function by an umpire.

51
00:03:50,920 --> 00:03:53,190
So there we go with our first argument.

52
00:03:53,200 --> 00:03:58,680
So now let's move onto the second argument which I remind is the target.

53
00:03:58,680 --> 00:03:59,910
All right so there we go.

54
00:03:59,950 --> 00:04:06,320
Targets which were already loaded here by calling our modeling function target.

55
00:04:06,580 --> 00:04:13,930
Then the next argument we have to input is to keep probability which is the probability of keeping the

56
00:04:13,930 --> 00:04:17,490
neuron activated during each iteration of the training.

57
00:04:17,620 --> 00:04:19,800
And we got this key parameter at line.

58
00:04:19,810 --> 00:04:26,500
Two hundred and ninety seven that we will later connect to the keep probability variable that we created

59
00:04:26,500 --> 00:04:30,850
at line two hundred and ninety and that is a specific entity of the tensor flow API.

60
00:04:30,970 --> 00:04:32,460
So we will connect that later.

61
00:04:32,530 --> 00:04:38,590
But what we have to input here in this sector signal function is make sure to understand the key prob

62
00:04:38,920 --> 00:04:42,410
variable returns by the model input function and that's it.

63
00:04:42,430 --> 00:04:47,800
The key probability tens of loci will actually connect them later when running the session with the

64
00:04:47,800 --> 00:04:53,910
run method of our session object and that will be in the big for loop over the epochs of the training.

65
00:04:54,100 --> 00:04:55,270
So keep it up.

66
00:04:55,510 --> 00:05:02,370
Then the next one is the batch size All right always working with batches when doing deep learning.

67
00:05:02,450 --> 00:05:08,450
And we get our budget size here 64 meaning that there are going to be 64 inputs and targets in each

68
00:05:08,450 --> 00:05:15,650
batch batch size then the next one is the sequence length which we just got here.

69
00:05:15,740 --> 00:05:22,370
And then the next argument is going to be the length of our answers.

70
00:05:22,520 --> 00:05:26,010
Words 2 and dictionary.

71
00:05:26,240 --> 00:05:33,280
Then I'm going to copy this because the next argument is going to be the land of the questions words

72
00:05:33,460 --> 00:05:34,590
in the dictionary.

73
00:05:34,670 --> 00:05:36,020
So perfect.

74
00:05:36,020 --> 00:05:44,990
Then the next argument is going to be the encoding embedding size which I remind is the number of columns

75
00:05:45,260 --> 00:05:46,780
in the embeddings matrix.

76
00:05:46,790 --> 00:05:49,680
Each of these columns corresponding to an embedding value.

77
00:05:49,820 --> 00:05:56,420
And then again I'm going to copy this because the next argument after that is going to be the embedding

78
00:05:56,420 --> 00:05:57,390
size.

79
00:05:57,500 --> 00:06:03,100
This time the decoding matrix the decoding embedding size.

80
00:06:03,410 --> 00:06:12,460
All right then the next argument is going to be the Arnon size which we also got here and the hyper

81
00:06:12,470 --> 00:06:15,960
parameters the size of 512.

82
00:06:16,160 --> 00:06:16,900
All right.

83
00:06:17,120 --> 00:06:22,960
And then two more arguments to go the next one is the number of layers.

84
00:06:23,120 --> 00:06:29,410
And that again we got when setting the hyper parameters number of layers equal 3.

85
00:06:29,480 --> 00:06:35,830
Meaning that there are going to be three layers in the cells of our record neural networks both the

86
00:06:35,840 --> 00:06:39,840
one of the encoder and the one of the decoder to numb layers.

87
00:06:39,890 --> 00:06:48,250
And finally the last one which is our dictionary questions words to it.

88
00:06:48,260 --> 00:06:56,000
So basically now we are ready to execute this code section execute to get our training protections in

89
00:06:56,000 --> 00:06:57,970
our test predictions.

90
00:06:58,010 --> 00:06:58,700
Perfect.

91
00:06:58,760 --> 00:07:03,060
So now we're getting closer and closer to the big loop of the training.

92
00:07:03,110 --> 00:07:04,270
But we're not there yet.

93
00:07:04,280 --> 00:07:09,710
We have a few remaining steps to do and we'll do them in the next intervals toils until then Id been

94
00:07:09,710 --> 00:07:10,110
on the.
