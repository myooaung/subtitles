WEBVTT
1
00:00:00.890 --> 00:00:04.280
Hello welcome back to the course on deep natural language processing.

2
00:00:04.530 --> 00:00:07.960
Today we're talking about Bean search decoding.

3
00:00:07.980 --> 00:00:13.710
In fact we're going to talk about two things we talk about greedy decoding versus the search decoding

4
00:00:14.100 --> 00:00:20.010
and the reason for that will become very apparent as soon as we start discussing both.

5
00:00:20.010 --> 00:00:22.230
So let's dive straight into it.

6
00:00:22.230 --> 00:00:31.710
3-D decoding this is the name that was given to the most obvious most natural or like kind of like first

7
00:00:33.450 --> 00:00:39.000
the first thing that pops into your mind when you think of how are we going to come up with results

8
00:00:39.030 --> 00:00:42.220
from our sequence to sequence.

9
00:00:42.300 --> 00:00:43.620
So let's have a look.

10
00:00:43.740 --> 00:00:51.180
We in the input into the network and then it produces the first word it produces like it gives us probabilities

11
00:00:51.180 --> 00:00:56.610
for 20000 words we select and then we will know the one of the highest.

12
00:00:56.610 --> 00:00:58.430
And in this case it say I'm.

13
00:00:58.920 --> 00:01:04.020
And then we just pick that one with the highest probability and then we continue as remembering the

14
00:01:04.020 --> 00:01:07.020
next that we feed.

15
00:01:07.200 --> 00:01:13.450
We look for the next word and we feel that that word I'm back into the network and then comes up with

16
00:01:13.450 --> 00:01:19.780
an explore another 20000 scores for the words and then we pick the one with the highest score.

17
00:01:19.780 --> 00:01:23.010
In this case it's going to be here.

18
00:01:23.650 --> 00:01:30.340
And then again we feed in that words here and a network and we see what the network produces on the

19
00:01:30.340 --> 00:01:33.830
next step and it reduces end of sentence.

20
00:01:33.880 --> 00:01:34.630
And so that's it.

21
00:01:34.630 --> 00:01:37.500
So that would be our response here would be.

22
00:01:37.510 --> 00:01:41.620
So there's our inputs like Who are you back in Australia.

23
00:01:41.740 --> 00:01:49.120
And the answer would be I'm here and that's that's the whole process.

24
00:01:49.120 --> 00:01:55.330
And the reason it's called Greeley's because every time we just pick the word with the highest probability

25
00:01:55.330 --> 00:02:01.160
like we're very greedy we only look at the one with the highest or that's how you can remember it.

26
00:02:01.270 --> 00:02:09.470
On the other hand we have Bheem search decoding which is a bit more sophisticated so we feed in the

27
00:02:09.490 --> 00:02:14.020
input into the network but then instead of looking at just the one word with the highest probability

28
00:02:14.020 --> 00:02:22.070
for the first bot We'll look at the very top three for example as with hyperbolas it could be top 3

29
00:02:22.100 --> 00:02:27.930
could be top 10 it's it's up to you to decide how many beam's you want but if you look at three then

30
00:02:27.940 --> 00:02:30.090
you'll have three B's and this time we have.

31
00:02:30.100 --> 00:02:30.540
Yes.

32
00:02:30.550 --> 00:02:38.450
Iman thanks as we remember from previous example Indeed I'm has perhaps a higher score and yes untax

33
00:02:38.470 --> 00:02:41.230
have lower scores but nevertheless we're going to look at all three.

34
00:02:41.320 --> 00:02:49.210
Then the way to think about is like at this point the universe splits into three and we have three versions

35
00:02:49.210 --> 00:02:54.360
of our sequence to sequence we have one version where the first word is yes we have another version

36
00:02:54.370 --> 00:02:58.070
where the first word is I'm and we have another version where the first word is sex.

37
00:02:58.270 --> 00:03:02.680
And they're like now from here they're like developing independent.

38
00:03:02.790 --> 00:03:09.580
Now we for this sequence the sequence model where the first word is yes we now look at the second word

39
00:03:09.610 --> 00:03:11.820
we we feed in the word yes.

40
00:03:11.830 --> 00:03:19.730
Back into that model and we see what it produces it produces these possible options for the second word.

41
00:03:19.750 --> 00:03:21.320
Same thing happens here.

42
00:03:21.400 --> 00:03:23.890
We feed in this word back into a.

43
00:03:23.950 --> 00:03:28.160
In this universe it produces these options for the second.

44
00:03:28.390 --> 00:03:32.780
And same thing happens here with it in this for back in 2012 we look at the options for second work

45
00:03:33.250 --> 00:03:35.880
and these are the options and so on.

46
00:03:35.890 --> 00:03:42.760
So we keep doing that every time it splits and so on and so on and so on and then we get some options.

47
00:03:42.760 --> 00:03:43.940
We get some results.

48
00:03:44.760 --> 00:03:58.080
And the way we look at the way we pick the winner in this case is we look at the highest joint probability

49
00:03:58.140 --> 00:04:00.330
across the whole team.

50
00:04:00.330 --> 00:04:03.770
So in this case as you can see it might be a different result.

51
00:04:03.800 --> 00:04:08.340
It might be yes I'm back end of sentence as I recall previously.

52
00:04:08.460 --> 00:04:10.020
Our winner was.

53
00:04:10.020 --> 00:04:11.060
Let's go back.

54
00:04:11.490 --> 00:04:13.690
Our winner was in Greeley decoding was.

55
00:04:13.830 --> 00:04:17.490
I'm here and here are winners.

56
00:04:17.490 --> 00:04:18.540
Yes I'm back.

57
00:04:18.690 --> 00:04:20.130
And the reason why it's different.

58
00:04:20.130 --> 00:04:28.900
It can be different is because in the case of I'm here the word I'm had the highest score of these three.

59
00:04:29.070 --> 00:04:32.880
And so that's why we picked it and therefore we completely limited our choice.

60
00:04:32.880 --> 00:04:34.470
We never even saw these beams.

61
00:04:34.470 --> 00:04:35.550
We never saw these.

62
00:04:35.590 --> 00:04:42.300
And then the word here was highest and so we took that and knew that that was the only option too simply

63
00:04:42.300 --> 00:04:44.220
because we limited it at the very start.

64
00:04:44.470 --> 00:04:45.750
What how like.

65
00:04:45.750 --> 00:04:51.480
However even though the word might have a higher score than the word yes.

66
00:04:51.710 --> 00:04:53.260
Overall this beam.

67
00:04:53.270 --> 00:04:54.410
Yes I'm back.

68
00:04:54.410 --> 00:05:04.180
U.S. might have a higher joint probability joint score across the whole team than this team itself.

69
00:05:04.190 --> 00:05:14.060
So is probably better to allow probabilities the joint probability of these responses of the beam itself

70
00:05:14.150 --> 00:05:21.050
is could could be higher than the one that we had in Agreed Ikoyi meaning that it's a better fit for

71
00:05:21.050 --> 00:05:21.990
our answer.

72
00:05:22.490 --> 00:05:25.740
So that's something to look out for.

73
00:05:25.760 --> 00:05:31.940
And as you can see the beams they grow very quickly so if you start with three then you have nine we

74
00:05:31.940 --> 00:05:33.010
have 27.

75
00:05:33.020 --> 00:05:40.720
And just keeps growing from there though there is a way to limit this so you can.

76
00:05:40.820 --> 00:05:48.260
The technique that can be applied is called truncating the beams and that means is at the start of the

77
00:05:48.260 --> 00:05:53.000
input then you have three then goes to nine and again some of them are really like us.

78
00:05:53.420 --> 00:05:56.850
But that doesn't truncate that like it can happen can't make it happen.

79
00:05:56.990 --> 00:06:03.860
But the point is that then here once the three at nine or even a bit further you the algorithm will

80
00:06:03.860 --> 00:06:12.470
look at the beams that have already have a very low joint probability.

81
00:06:12.470 --> 00:06:15.100
So like let's say thanks.

82
00:06:15.140 --> 00:06:17.600
Please something.

83
00:06:17.700 --> 00:06:19.460
So maybe this be in play.

84
00:06:19.460 --> 00:06:23.840
Thanks pre-sent might like it logically might not be the best response.

85
00:06:23.840 --> 00:06:27.410
Like if you think about it from a point of view of human interaction.

86
00:06:27.410 --> 00:06:32.360
But also like the joint probability of the bee might be low and then therefore the algorithm would just

87
00:06:32.360 --> 00:06:35.270
throw it away it won't it won't continue looking at that one.

88
00:06:35.450 --> 00:06:39.950
And then why throw away this one in my driveway this one might throw away this one and this one and

89
00:06:39.950 --> 00:06:48.500
this one like this one maybe and the ones that have larger abilities where it looks like they won't

90
00:06:48.500 --> 00:06:55.040
be the winners in the end or they won't be in the top three or however much we are many options looking

91
00:06:55.170 --> 00:06:55.580
for.

92
00:06:55.670 --> 00:07:04.550
It looks like they are going to just lead to some optimal results anyway so the algorithm can't throw

93
00:07:04.550 --> 00:07:07.350
them away and that way what can happen is you get all three.

94
00:07:07.350 --> 00:07:13.310
Nine and then some will get truncate and you might go back to like four or five or three and then again

95
00:07:13.730 --> 00:07:16.320
like expand and contract expand contract.

96
00:07:16.460 --> 00:07:24.150
And so that way you're still benefiting from that different variety coming from the beams.

97
00:07:24.470 --> 00:07:31.010
But at the same time you're not falling victim to like exploding beams where the competition cost is

98
00:07:32.300 --> 00:07:33.190
unbearable.

99
00:07:33.410 --> 00:07:39.680
So that's that's an option and just good to know that it's there because that means it's not a lost

100
00:07:39.680 --> 00:07:47.540
cause to look at the search decoding because it is possible to do because we have techniques to limit

101
00:07:47.600 --> 00:07:49.320
that exposure.

102
00:07:49.700 --> 00:07:57.650
And by the way this is this is I think this is a very interesting way of reading result.

103
00:07:57.670 --> 00:08:05.240
What I was going to say about like by the way this reminds me reminds us of what we started this whole

104
00:08:05.240 --> 00:08:08.850
process with is that first initial email.

105
00:08:08.870 --> 00:08:15.460
So here if you look back down here you can see that there's three options here.

106
00:08:15.470 --> 00:08:21.800
So now you can you can say that you know where they came from because that's exactly the kind of they

107
00:08:21.800 --> 00:08:26.240
came from that be inserted decoding that they.

108
00:08:26.540 --> 00:08:35.240
These are three different beams that were picked as the three winners across the options that were provided

109
00:08:35.240 --> 00:08:36.320
by this algorithm.

110
00:08:36.320 --> 00:08:38.030
How cool is that.

111
00:08:38.030 --> 00:08:44.750
We started off and we went through a very long journey but we did get to our end goal and now we know

112
00:08:44.750 --> 00:08:45.900
where these come from.

113
00:08:46.070 --> 00:08:53.330
And moreover there is of course more techniques for instance as techniques that will help with the variability

114
00:08:53.330 --> 00:08:56.870
of the beams so to make them not look like all the same.

115
00:08:56.890 --> 00:08:58.250
Yes I'm around this and that.

116
00:08:58.270 --> 00:08:59.300
Yes I'm here.

117
00:08:59.300 --> 00:09:00.520
You know that would be boring.

118
00:09:00.650 --> 00:09:07.270
There are techniques that help make sure that they're not all identical or close to identical but nevertheless

119
00:09:07.340 --> 00:09:13.640
like we've got in the core of the algorithm and now when you look at your G-mail app next time if you're

120
00:09:13.640 --> 00:09:19.120
using it you will like you'll see these and you'll be reminded and you'll know where they came from.

121
00:09:19.130 --> 00:09:20.040
So there you go.

122
00:09:20.060 --> 00:09:23.400
Really enjoyed discussing this with you.

123
00:09:23.420 --> 00:09:25.030
I hope you enjoyed it too.

124
00:09:25.250 --> 00:09:27.090
And I look forward to seeing you next hour.

125
00:09:27.110 --> 00:09:31.110
Until then enjoy deep natural language processing.
