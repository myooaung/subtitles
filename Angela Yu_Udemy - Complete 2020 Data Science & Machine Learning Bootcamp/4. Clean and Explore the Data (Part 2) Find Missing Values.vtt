WEBVTT
1
00:00:00.270 --> 00:00:00.720
All right.

2
00:00:00.750 --> 00:00:07.080
So let's take a closer look what we've got inside of our Boston dataset bunch.

3
00:00:07.350 --> 00:00:15.720
Before we were talking about the attributes of this object the thing is in machine learning this word

4
00:00:15.930 --> 00:00:21.750
attribute is gonna be used in a different context in machine learning the features of a data set are

5
00:00:21.750 --> 00:00:30.870
typically represented as the columns in a table and these columns you'll often see refer to as the attributes

6
00:00:31.140 --> 00:00:33.390
of a data set.

7
00:00:33.390 --> 00:00:39.570
In other words when using this word attribute and the machine learning context we will refer to a feature

8
00:00:39.690 --> 00:00:42.040
or an independent variable.

9
00:00:42.180 --> 00:00:46.370
And this is what we're going to be using to predict a house price.

10
00:00:46.770 --> 00:00:53.360
So yeah the word attribute is used both in Python as well as in machine learning but unfortunately the

11
00:00:53.370 --> 00:01:00.990
mean completely different things so speaking of features let's pull up the features of our dataset in

12
00:01:00.990 --> 00:01:09.420
the python notebook and we can do this again using the Boston underscore data set object which has an

13
00:01:09.450 --> 00:01:19.410
attribute called feature underscore names let's print this out here we can see all the feature names

14
00:01:19.740 --> 00:01:23.120
of our data set in a nice little array.

15
00:01:23.430 --> 00:01:30.990
Again the desired function was really really handy in ascertaining that our bunch has a attribute called

16
00:01:30.990 --> 00:01:32.820
feature underscore names.

17
00:01:32.940 --> 00:01:39.150
So these are the kind of niceties that you're going to get with a toy dataset like this.

18
00:01:39.150 --> 00:01:48.960
Now taking a look at these feature names the question you might ask is Where is the house price.

19
00:01:48.960 --> 00:01:51.890
Where is the price of the houses.

20
00:01:51.900 --> 00:01:58.290
Because we've got a bunch of abbreviations here and none of them seem to suggest anything about the

21
00:01:58.290 --> 00:02:02.920
values of the houses that we're looking to estimate.

22
00:02:02.940 --> 00:02:06.440
So this means that this is hidden somewhere else.

23
00:02:06.450 --> 00:02:14.010
The key thing what we're trying to predict is found in an attribute called target.

24
00:02:14.040 --> 00:02:26.110
So Boston underscore data set don't target well bring up the actual prices of the houses.

25
00:02:26.110 --> 00:02:30.870
This is why we didn't get a separate column for the house prices earlier.

26
00:02:30.880 --> 00:02:35.400
The house prices are actually found somewhere else in our bunch.

27
00:02:35.400 --> 00:02:39.900
Object now looking at these house prices.

28
00:02:40.130 --> 00:02:44.510
You might be wondering 24 21 34.

29
00:02:44.990 --> 00:02:49.230
These look like they're the prices for toy houses or something.

30
00:02:49.370 --> 00:02:54.890
They don't look high enough to be the dollar values of actual houses because no house could possibly

31
00:02:54.890 --> 00:02:57.100
cost the twenty four dollars right.

32
00:02:57.680 --> 00:02:59.720
Unless of course you buy it off.

33
00:02:59.720 --> 00:03:07.550
Ali express or something sort of thing to note is that these units are actually in thousands.

34
00:03:07.550 --> 00:03:13.440
So these are the actual prices in thousands.

35
00:03:13.530 --> 00:03:15.970
I'm going to add this here as a comment.

36
00:03:15.980 --> 00:03:22.080
So if you come back to this note book in three months time this is still going to make sense now.

37
00:03:22.620 --> 00:03:29.460
Now working with a bunch of object in the notebook is all very well and good but one of the most common

38
00:03:29.460 --> 00:03:35.010
types of objects that you're actually going to be encountering in your work as a machine learning expert

39
00:03:35.100 --> 00:03:39.030
or as a data scientist is the pandas.

40
00:03:39.150 --> 00:03:44.800
Data from the pandas data frame is gonna be our main workhorse.

41
00:03:45.390 --> 00:03:50.100
So let me add a little section heading here to commemorate this.

42
00:03:50.480 --> 00:04:01.570
At a subheading here that reads data exploration with pandas data frames and what I want to do is I'm

43
00:04:01.570 --> 00:04:10.240
going to create a variable here called data and I'm going to have this variable hold on to our pandas

44
00:04:10.240 --> 00:04:19.040
data frame object and the way we're going to create this data frame is using the pandas module.

45
00:04:19.120 --> 00:04:25.310
So before writing any more code here I'm going to have to import this pen.

46
00:04:25.320 --> 00:04:26.070
This module right.

47
00:04:26.080 --> 00:04:35.420
I can just write PD dot data frame without importing my pandas module first.

48
00:04:35.590 --> 00:04:38.200
So I'm going to pause here for a second.

49
00:04:38.320 --> 00:04:48.100
Go back up to the top where I've got all my input statements and then write import pandas as PD and

50
00:04:48.250 --> 00:04:58.660
head shift enter now can come back down here and actually make use of our module to construct our data

51
00:04:58.660 --> 00:05:02.630
frame from our Boston underscored data set.

52
00:05:02.830 --> 00:05:06.460
We're going supply some arguments between these parentheses.

53
00:05:06.550 --> 00:05:16.770
The first argument is called data and we're gonna set that equal to Boston underscore dataset dot data.

54
00:05:16.810 --> 00:05:24.540
So this is gonna be the NUM pi array contained inside of our Boston data set bunch.

55
00:05:24.640 --> 00:05:32.050
The next argument columns it's gonna be the argument for the column names and we're gonna set that equal

56
00:05:32.050 --> 00:05:39.190
to Boston on a score data set don't feature underscore names.

57
00:05:39.880 --> 00:05:45.340
And what this code will do is it will create a panda's data frame

58
00:05:48.890 --> 00:05:54.420
now remember how our price our house prices will not be included in this.

59
00:05:54.500 --> 00:05:56.420
So going to add those separately.

60
00:05:56.420 --> 00:06:01.230
Now I'm going to add a column uh with the price.

61
00:06:01.280 --> 00:06:01.880
Yeah.

62
00:06:01.880 --> 00:06:11.170
Our target to the data frame the way we want to do this is by using our data frame variable which is

63
00:06:11.170 --> 00:06:15.040
called data having some square brackets after it.

64
00:06:15.040 --> 00:06:18.700
And in those square brackets I want to supply a column name.

65
00:06:18.760 --> 00:06:26.680
So when I call this column price all caps and I'm going to set it equal to Boston underscore dataset

66
00:06:28.120 --> 00:06:29.620
dot target.

67
00:06:30.600 --> 00:06:31.050
Okay.

68
00:06:31.060 --> 00:06:35.880
So let's head shift and sit together and see if we get any errors.

69
00:06:36.050 --> 00:06:38.320
How good.

70
00:06:38.360 --> 00:06:45.080
Let me add a few more cells here and then we can continue to explore our data and I'll show you a couple

71
00:06:45.080 --> 00:06:55.350
of tricks using the pandas data from the thing is oftentimes your data frame will be huge.

72
00:06:55.380 --> 00:06:59.730
This one just has five hundred and six rows.

73
00:06:59.730 --> 00:07:06.880
But oftentimes you're gonna be working with data frames with many thousands of rows or tens of thousands.

74
00:07:07.040 --> 00:07:14.630
So the question is how can you get a glimpse of the data inside a huge data frame without printing out

75
00:07:14.870 --> 00:07:17.120
all of the values.

76
00:07:17.240 --> 00:07:21.620
And for that pandas gives us two data frame methods.

77
00:07:21.620 --> 00:07:23.810
The first one is called Head.

78
00:07:23.960 --> 00:07:27.870
And the second one is called tail.

79
00:07:27.980 --> 00:07:36.170
Let me show you how you'd use them if we were to write data and hit shift enter our notebook would output

80
00:07:36.920 --> 00:07:47.310
a whole bunch of rows but if we wanted to just take a gander at the first couple of rows in the data

81
00:07:47.310 --> 00:07:57.410
frame say rows 0 through 4 for example we could write data dot head parentheses and hitting shift into

82
00:07:57.540 --> 00:08:08.330
what we see instead are rows 0 through 4 This will give us an idea of the kind of values that are contained

83
00:08:08.450 --> 00:08:16.720
inside of our roads and our columns without having to look at an enormous amount of data so let me add

84
00:08:16.780 --> 00:08:23.300
a little comment here that says the top rows look like this.

85
00:08:23.410 --> 00:08:32.320
Now it follows that data dot tail parentheses will show us the rows at the bottom of the data frame

86
00:08:32.350 --> 00:08:40.100
right rows at bottom of data frame look like this.

87
00:08:43.560 --> 00:08:52.170
Scrolling down we can see that rows 501 through 505 have this kind of data inside of them.

88
00:08:52.170 --> 00:08:59.190
I personally really like these two methods for looking at the top part of the data and the bottom part

89
00:08:59.190 --> 00:09:04.910
of the data just to get an idea of what we're working with.

90
00:09:05.320 --> 00:09:12.880
Now if we wanted to figure out how many rows are data frame has or we just wanted to retrieve the rows

91
00:09:13.240 --> 00:09:18.130
in each column there's a handy little method called count.

92
00:09:18.430 --> 00:09:30.190
So data don't count parentheses will show us the number of rows and that's for each column.

93
00:09:30.190 --> 00:09:30.730
Check it out

94
00:09:33.720 --> 00:09:39.250
in the output below you see the number of entries per column.

95
00:09:39.270 --> 00:09:44.810
So each column has five hundred and six entries.

96
00:09:44.970 --> 00:09:53.430
Now coming back to this topic of language and lingo and jargon you'll often hear the number of data

97
00:09:53.430 --> 00:09:59.460
points or rows being referred to as the number of instances.

98
00:09:59.460 --> 00:10:03.810
So here we've got and 506 instances.

99
00:10:04.080 --> 00:10:11.190
This is how this would instance is used in the context of machine learning and the important thing to

100
00:10:11.190 --> 00:10:18.900
note here is that this word instance means something completely different to a programmer to a python

101
00:10:18.900 --> 00:10:19.770
programmer.

102
00:10:19.770 --> 00:10:23.100
An instance is an object.

103
00:10:23.100 --> 00:10:31.320
In other words our data object right here is an instance of a data frame a data frame would be the general

104
00:10:31.320 --> 00:10:38.670
category and a particular data frame namely our data frame which we've stored inside our variable here

105
00:10:39.270 --> 00:10:42.380
would then be referred to as an instance.

106
00:10:42.390 --> 00:10:49.420
So yeah the word instance again has a different meaning in machine learning and in programming.

107
00:10:49.530 --> 00:10:52.940
Again this is just something to be aware of.

108
00:10:53.010 --> 00:11:04.160
Moving onto our next topic let's add a few more cells here and make the first one a markdown cell where

109
00:11:04.160 --> 00:11:16.310
we're going to add a subheading called Cleaning data check for missing values so when you're doing your

110
00:11:16.310 --> 00:11:24.290
data exploration oftentimes you're going to look for problems in your data set and dealing with missing

111
00:11:24.290 --> 00:11:30.950
data is definitely a kind of problem that you have to address because I guarantee you that your machine

112
00:11:30.950 --> 00:11:37.220
learning algorithm is gonna get really confused and give you really terrible answers if you haven't

113
00:11:37.370 --> 00:11:43.260
addressed this ahead of time and are feeding clean data to your algorithm.

114
00:11:43.460 --> 00:11:50.570
So you might remember how we've addressed the missing values when we were analyzing our movie revenues.

115
00:11:50.570 --> 00:11:56.870
The problem that we're confronted with at the moment is how do we find the missing values and how do

116
00:11:56.870 --> 00:11:59.100
we find them quickly.

117
00:11:59.120 --> 00:12:08.660
Pandas actually has a function called is no and this function will return to us a table if any of the

118
00:12:08.660 --> 00:12:11.090
values were missing.

119
00:12:11.090 --> 00:12:15.660
Now let me show you how you use it since this function comes from the pandas module.

120
00:12:15.660 --> 00:12:23.720
We're gonna have to access it through PD dot is null and that's an argument we can have to pass in the

121
00:12:24.050 --> 00:12:26.750
data that we want the function to check.

122
00:12:26.750 --> 00:12:35.000
So if stored all of this inside our data data frame and hitting shift enter on this will now return

123
00:12:35.000 --> 00:12:35.780
to us.

124
00:12:35.990 --> 00:12:46.070
Hey hold table where each entry is either false meaning no missing values or true which means missing

125
00:12:46.070 --> 00:12:47.160
values.

126
00:12:47.240 --> 00:12:55.280
You can see this is a huge table right Jupiter notebook is not even showing us the entire table here.

127
00:12:55.340 --> 00:13:05.930
So the question is how would we know if there are any missing values in this entire table of 506 entries

128
00:13:07.740 --> 00:13:14.130
and the answer is we can chain another method call onto this one.

129
00:13:14.130 --> 00:13:19.400
So we've caught our table back and it's a table of true and false entries.

130
00:13:19.710 --> 00:13:30.150
And if we chain a method called any parentheses and hit shift enter then what we get is we got pandas

131
00:13:30.240 --> 00:13:37.620
checking all the columns and telling us if there are any missing values in any of the columns.

132
00:13:37.680 --> 00:13:44.420
Now I don't know if you've heard the word null before but no does not mean the value 0.

133
00:13:44.430 --> 00:13:51.930
So if a variable is equal to the value null it contains nothing which is very very different from the

134
00:13:51.930 --> 00:14:00.810
variable having the value 0 and the Internet has decided that the best way to summarize this is as a

135
00:14:00.840 --> 00:14:02.760
picture of a problem.

136
00:14:02.790 --> 00:14:10.290
I wouldn't wish upon anyone in a public restroom on the left we have the dispenser containing the value

137
00:14:10.290 --> 00:14:14.940
zero and on the right we have the dispenser containing the value.

138
00:14:15.030 --> 00:14:24.550
No this is no method changed with the any method is super handy for figuring out if there are any missing

139
00:14:24.550 --> 00:14:31.750
values in your dataset because if there is a missing value in one of the columns then instead of this

140
00:14:31.750 --> 00:14:38.920
would false being printed here you will see the word true and then you might have to dig into the data

141
00:14:39.280 --> 00:14:41.160
and fix the problem.

142
00:14:41.170 --> 00:14:48.370
Now let me show you an alternative way of doing this check because this first method here is null and

143
00:14:48.460 --> 00:14:51.820
any belong to the pandas module.

144
00:14:51.820 --> 00:15:00.910
The next method I'm going to show you the alternative belongs to the data frame instead typing data

145
00:15:01.330 --> 00:15:10.330
dot info so using our data object and then calling the info method on it will show us not only if there

146
00:15:10.330 --> 00:15:17.800
are any null values but it'll also show us a whole bunch of other information including the number of

147
00:15:17.860 --> 00:15:28.140
entries or rows the number of columns the names of the columns if any of the columns have a no value

148
00:15:29.010 --> 00:15:34.620
and also the type of object that each column contains.

149
00:15:34.620 --> 00:15:42.120
In our case all of the columns contain float 64 type objects.

150
00:15:42.120 --> 00:15:45.880
Now if you're new to programming this will look super jargon.

151
00:15:46.230 --> 00:15:48.540
So let me explain what this means.

152
00:15:48.600 --> 00:15:57.240
A float is programming jargon for a floating point number what's the floating point number nothing special.

153
00:15:57.240 --> 00:16:03.900
It just refers to a decimal number to a floating point number has a decimal point but something like

154
00:16:04.050 --> 00:16:06.260
an integer does not.

155
00:16:06.330 --> 00:16:11.490
In other words Python has different categories for different types of numbers.

156
00:16:11.700 --> 00:16:19.710
So this number 64 at the end of the word float shows us that the category that we're working with here

157
00:16:20.250 --> 00:16:25.870
is a large and precise decimal number in this case.

158
00:16:25.900 --> 00:16:35.290
I've got a 64 bit floating point number that takes up 64 bits of memory and that would be in contrast

159
00:16:35.290 --> 00:16:45.130
to less precise numbers like a float 32 or a float sixteen Hey float 64 number contains twice as many

160
00:16:45.130 --> 00:16:49.200
digits and takes up twice as much memory as a float 32.

161
00:16:49.660 --> 00:16:51.670
So that's what that means.

162
00:16:51.910 --> 00:16:58.830
In any case the good news is that we have no missing values which is great.

163
00:16:58.840 --> 00:17:00.550
One less thing to worry about.

164
00:17:00.700 --> 00:17:06.530
So now we can start to explore our features that are contained in the dataset.

165
00:17:06.900 --> 00:17:15.790
It's time to demystify these mysterious sounding columns like R.M. Knox and this can wait to see you

166
00:17:15.790 --> 00:17:16.720
in the next lesson.
