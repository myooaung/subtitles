WEBVTT
1
00:00:00.150 --> 00:00:01.260
Welcome back everyone.

2
00:00:01.260 --> 00:00:03.040
It's good to see you here again.

3
00:00:03.040 --> 00:00:07.430
And this session we're going to move into visualising CNN.

4
00:00:07.590 --> 00:00:10.720
Let's start with the Africa key texture itself.

5
00:00:10.950 --> 00:00:19.470
What you see here is a video G 16 which is use 16 stands for the title here is very deep convolution

6
00:00:19.470 --> 00:00:20.770
all networks.

7
00:00:20.880 --> 00:00:27.630
So the DG If you look at this architecture there are 16 layers here.

8
00:00:27.780 --> 00:00:36.600
The layout count is based on one to the convolution layer tree for another two convolution near one

9
00:00:36.600 --> 00:00:37.470
two three.

10
00:00:37.470 --> 00:00:46.110
So we've gone four plus three Now Seven Seven plus three more makes it ten nine plus three more makes

11
00:00:46.110 --> 00:00:55.110
it thirteen plus three more fully connected layer that is not shown here but I will show you in the

12
00:00:55.110 --> 00:01:03.610
actual so-called paper itself if you look at see that's the configuration that you are looking at here

13
00:01:04.590 --> 00:01:05.770
in terms of the sea.

14
00:01:05.770 --> 00:01:13.360
This is the 16 weight layers you have one two three four five six seven eight nine ten eleven twelve

15
00:01:13.360 --> 00:01:22.890
thirteen plus the three fully connected the down here the next max players are not shown what we are

16
00:01:22.890 --> 00:01:34.460
interested in and specifically are the convolution layers is designated as seal and B to D it's always

17
00:01:34.460 --> 00:01:41.300
a mystery for for the longest time how neural network actually see the wall what kind of images does

18
00:01:41.300 --> 00:01:41.750
it see.

19
00:01:42.230 --> 00:01:47.870
So the best way to actually visualize this is to understand how each layer actually work.

20
00:01:47.870 --> 00:01:51.760
So that's really the purpose of this session where we'll start with.

21
00:01:51.860 --> 00:01:58.680
And just to gain an appreciation of the actual kernel itself what exactly is the kernel.

22
00:01:58.730 --> 00:02:03.820
Let's come over to a store start or IO which I've open up for him

23
00:02:09.370 --> 00:02:13.650
now an image kernel is basically what is called a small matrix.

24
00:02:13.780 --> 00:02:20.610
This is used to apply effects on the actual picture itself could be blurring could be sharpening and

25
00:02:20.620 --> 00:02:27.160
many many various so-called effects that you're trying to apply to the picture itself in machine learning

26
00:02:27.190 --> 00:02:33.490
is called feature extraction and we convoluted through it and in future session we're going to look

27
00:02:33.490 --> 00:02:35.800
at the mathematics beside it.

28
00:02:35.800 --> 00:02:40.050
Now first of all let's start with an image.

29
00:02:40.060 --> 00:02:46.870
Now you can see that this is a blur image as you move your mouse along and you notice that as I'm moving

30
00:02:46.870 --> 00:02:49.920
along it follows along on the left hand side.

31
00:02:49.990 --> 00:02:57.040
The actual core numbers to go with it you can see that high is 2 5 5 when I move to the black spot.

32
00:02:57.070 --> 00:02:59.640
The number approaches zero.

33
00:02:59.650 --> 00:03:09.170
So the number doesn't make or represent the actual color as from height or the way to black and ignore

34
00:03:09.190 --> 00:03:11.510
the shades in between.

35
00:03:11.830 --> 00:03:21.260
Now let me move up now if you apply a kernel ledges pick a blur Colonel and you will see that the images

36
00:03:21.260 --> 00:03:23.630
becomes more blur.

37
00:03:23.630 --> 00:03:28.460
That's because of the red cubes.

38
00:03:28.550 --> 00:03:34.630
Can you see the red cubes of that nine red cubes that's moving around on the left side.

39
00:03:34.670 --> 00:03:41.090
So when you actually choose this blur three by three matrix which is a nine cubes here as we moving

40
00:03:41.090 --> 00:03:46.340
along while actually applying the so-called blurring effect on it.

41
00:03:46.340 --> 00:03:51.120
Now these three by three red cubes are core kernels.

42
00:03:51.340 --> 00:03:58.130
Every time when you actually apply these kernel and the actual so-called Operation is core convolution

43
00:03:58.940 --> 00:04:04.970
it actually changes the underlying pictures on the left hand side is our input image as we apply the

44
00:04:05.000 --> 00:04:09.650
So core kernel you get the output image on the right.

45
00:04:09.650 --> 00:04:15.900
So there are other so-called handcrafted kernel we can choose bottom so well.

46
00:04:15.920 --> 00:04:21.710
And this is what you get the bottom so well this is what the three by three looks like is minus one

47
00:04:21.710 --> 00:04:25.120
minus two minus 1 0 0 0 1 2 1.

48
00:04:25.210 --> 00:04:25.740
Okay.

49
00:04:25.760 --> 00:04:33.110
So as you take the actual picture and apply the kernel to it the right hand pictures is the output that

50
00:04:33.110 --> 00:04:40.890
you receive of course you can choose a whole lot of others you can add boss ID and a few others that's

51
00:04:40.890 --> 00:04:43.280
the basic concept of Colonel.

52
00:04:43.350 --> 00:04:45.250
You have your basic image.

53
00:04:45.330 --> 00:04:53.040
You apply a colonel out come with is the output image will have the effect applied to it by the colonel

54
00:04:53.040 --> 00:04:55.200
itself.

55
00:04:55.200 --> 00:05:01.540
Now as you can see here there are a few common ones that is being listed.

56
00:05:01.800 --> 00:05:08.190
What we actually wanted to look at is how those these Colonel actually work.

57
00:05:08.310 --> 00:05:13.350
You can actually do more playing around with this pictures as you can see you can actually change the

58
00:05:13.350 --> 00:05:19.870
three by three kernels a little bit to obtain the effects that you your you want to actually obtain.

59
00:05:19.890 --> 00:05:26.220
So that's really the basic idea is you can actually look at a few other guidance down here like image

60
00:05:26.220 --> 00:05:26.820
colonel here.

61
00:05:26.820 --> 00:05:28.360
It's quite a good guide as well.

62
00:05:28.390 --> 00:05:34.840
And although there is also a good guide and Wikipedia on the CNN How does it work.

63
00:05:34.860 --> 00:05:42.570
Let let's come back here other things that I do want to show you is where we can actually visualize

64
00:05:42.580 --> 00:05:46.090
and understand the actual convolution network itself.

65
00:05:46.590 --> 00:05:49.120
So you look at the layer 1.

66
00:05:49.200 --> 00:05:54.890
This is what you actually see is a three by three and ish cube here each block.

67
00:05:54.890 --> 00:05:56.440
Here is another three by three.

68
00:05:56.850 --> 00:06:06.090
So the layer one you can see these are all edges and they are fairly simple patterns as you go to deeper

69
00:06:06.090 --> 00:06:06.530
layer.

70
00:06:06.540 --> 00:06:08.820
So this is layer 1 as you move to layer two.

71
00:06:08.820 --> 00:06:14.570
You can see that the patterns start to get more complicated and they actually get to lay a three.

72
00:06:14.580 --> 00:06:16.260
It gets even more complicated.

73
00:06:16.260 --> 00:06:18.620
The right hand side are the input images.

74
00:06:18.630 --> 00:06:22.940
The left hand side is how this D.A. to CNN actually see.

75
00:06:23.130 --> 00:06:25.960
You can see some of the wheel.

76
00:06:26.160 --> 00:06:28.170
Which of the cars come through.

77
00:06:28.170 --> 00:06:33.250
You can see some of these honeycomb comes true from the original picture.

78
00:06:33.360 --> 00:06:36.660
And this is the original layer too.

79
00:06:36.740 --> 00:06:42.580
You notice that the layer to these are more straight edges as you come to layer 3.

80
00:06:42.620 --> 00:06:51.260
The actual pictures or the patterns the futures cannot start to actually pick up more more complex structures

81
00:06:51.290 --> 00:06:55.760
and patterns as you go to layer for a start to become more abstract.

82
00:06:55.760 --> 00:07:01.580
You can see some of the patterns of the nose and facial features of the dog.

83
00:07:01.580 --> 00:07:06.650
And that's really the idea once you get to layer five you see even more complex you can do you start

84
00:07:06.650 --> 00:07:13.530
to have curves in circles and look a whole lot of patterns start being actually observed here.

85
00:07:13.580 --> 00:07:16.010
This is the basic idea of CNN.

86
00:07:16.010 --> 00:07:25.640
You start off with the simple shapes the edges the corners and start to build up more and more and more

87
00:07:25.640 --> 00:07:27.010
complex pattern.

88
00:07:27.080 --> 00:07:30.790
The deeper you go into the layer itself.

89
00:07:31.340 --> 00:07:34.320
This is a link that I provided here.

90
00:07:34.340 --> 00:07:37.260
I would like highly encourage you to actually watch it.

91
00:07:37.280 --> 00:07:44.030
I won't go through that here myself but I'll provide that link so that you can actually open it up in

92
00:07:44.030 --> 00:07:48.450
your PBF to observe or at least watch his talk.

93
00:07:48.470 --> 00:07:49.820
This is done.

94
00:07:49.820 --> 00:08:00.360
If I remember correctly last year you might even be the year before this actually.

95
00:08:00.360 --> 00:08:06.610
Here you can actually see the last year during the the conference.

96
00:08:06.720 --> 00:08:08.060
Octavia works for Google.

97
00:08:08.070 --> 00:08:13.530
He is also founder of a company later Toronto was bought over by Google.

98
00:08:13.530 --> 00:08:20.970
He basically demonstrated to you how convolution No Leah actually CNN architecture actually work.

99
00:08:20.970 --> 00:08:26.150
Do watch that video just to help you to develop some intuition of it.

100
00:08:26.160 --> 00:08:31.190
What I wanted to do is actually show you Adam Hartley's Web site.

101
00:08:31.220 --> 00:08:33.270
Again this is the link provided for you.

102
00:08:33.360 --> 00:08:37.560
And we're going to go straight to it.

103
00:08:37.580 --> 00:08:44.810
This is where you draw your number here and you can see each layer is visibility.

104
00:08:44.810 --> 00:08:45.080
OK.

105
00:08:45.080 --> 00:08:50.330
So what we will do here is that we will actually start drawing let us say we want to draw a simple number

106
00:08:50.620 --> 00:08:51.450
one.

107
00:08:52.010 --> 00:08:52.320
OK.

108
00:08:52.330 --> 00:08:55.190
Immediately you can actually see the different layering.

109
00:08:55.570 --> 00:08:56.010
OK.

110
00:08:56.030 --> 00:08:57.290
Different.

111
00:08:57.290 --> 00:09:02.720
So call how the each and every one of these kernel actually works.

112
00:09:02.720 --> 00:09:08.690
So if we show the input there or hide it the employer's gone the convolution layer.

113
00:09:08.690 --> 00:09:14.820
This is the first layer or high that if we look at the down sampling which is the max pulley that is

114
00:09:14.840 --> 00:09:15.710
now gone.

115
00:09:15.890 --> 00:09:23.900
If we look at the hide layer to see if I actually come over here and see if I can change it to to 2D

116
00:09:29.000 --> 00:09:32.510
OK well it's gone too far.

117
00:09:41.260 --> 00:09:41.620
OK.

118
00:09:41.690 --> 00:09:43.530
What we were looking at are the 3-D.

119
00:09:43.910 --> 00:09:46.990
Let's have a look at the 2D visualization.

120
00:09:47.000 --> 00:09:49.400
It's easier to visualize using these.

121
00:09:50.520 --> 00:09:50.810
OK.

122
00:09:50.810 --> 00:09:53.190
So if I draw one here OK.

123
00:09:53.240 --> 00:09:57.710
So this is the first one is the input layer.

124
00:09:57.770 --> 00:10:00.890
The second one that's the convolution layer.

125
00:10:01.010 --> 00:10:06.890
If we look at layer numbers two you notice that the image is high these so that you can actually see

126
00:10:06.890 --> 00:10:08.120
where we are looking at.

127
00:10:08.120 --> 00:10:16.170
Notice that the picture the patterns is substantially more complex as you get to convolution the 2 and

128
00:10:16.190 --> 00:10:18.350
down sampling and fully connected.

129
00:10:18.380 --> 00:10:21.770
As you can see is actually just one roll.

130
00:10:21.770 --> 00:10:27.940
Oh yeah one row of pixel is no longer a matrix is just one row of pixels.

131
00:10:27.930 --> 00:10:32.630
That's that's how fully connected layer works it's just basically one rule.

132
00:10:32.810 --> 00:10:33.860
And that's the output layer.

133
00:10:34.550 --> 00:10:38.120
And notice that it did picks up correctly that it is indeed a one.

134
00:10:38.120 --> 00:10:41.980
So let's start though again with stop to now.

135
00:10:42.050 --> 00:10:44.950
Let's have a look at our convolution layer too.

136
00:10:45.110 --> 00:10:48.920
Again you can see that there are a few things that's being picked up here.

137
00:10:48.920 --> 00:10:51.420
So this picks up the bottom layer.

138
00:10:51.980 --> 00:10:52.900
Okay.

139
00:10:53.180 --> 00:10:56.390
If we look at this one it picks up the left edges.

140
00:10:56.570 --> 00:11:02.450
If you look at this picks up the top edges this one pick up the right edges and take this pick up the

141
00:11:02.450 --> 00:11:03.770
left edges.

142
00:11:04.010 --> 00:11:11.660
This again pick up the bottom edges the glow the lights in that part are the actual edges that this

143
00:11:11.840 --> 00:11:15.190
layer this kernel here actually picks up.

144
00:11:15.470 --> 00:11:20.790
You notice that that's basically you know each of these kernel kind of like a few too.

145
00:11:20.930 --> 00:11:29.030
In fact that's the name that is also used to describe these either kernel or future.

146
00:11:29.090 --> 00:11:30.520
It picks up different things.

147
00:11:30.530 --> 00:11:30.950
OK.

148
00:11:30.950 --> 00:11:32.940
You notice that they are different.

149
00:11:33.080 --> 00:11:37.350
So core edges are being activated or excited.

150
00:11:37.430 --> 00:11:43.370
You can see as I mentioned before this is the bottom layer the edges the horizontal edges both from

151
00:11:43.370 --> 00:11:45.190
the bottom up.

152
00:11:45.230 --> 00:11:48.220
This is from the top layer from top down.

153
00:11:48.260 --> 00:11:49.990
This is from right edges.

154
00:11:50.180 --> 00:11:55.970
This is left edges and this is right edges but towards the right a little bit and also towards the left

155
00:11:55.970 --> 00:11:56.370
and a little bit.

156
00:11:56.370 --> 00:12:00.410
So that's kind of like how convolution layer works.

157
00:12:00.410 --> 00:12:08.410
And but it's substantially different when you come to the layer two of CNN convolution layer.

158
00:12:08.570 --> 00:12:13.530
You can't really discern what it actually picks up anymore.

159
00:12:13.550 --> 00:12:19.350
So if we go back to this and look at how it actually connects.

160
00:12:19.780 --> 00:12:20.100
Yeah.

161
00:12:20.110 --> 00:12:24.260
Again you can really see what is actually being picked up.

162
00:12:24.260 --> 00:12:30.480
It comes from noticed that there are four sources that come from four sources.

163
00:12:30.480 --> 00:12:32.170
This comes from four sources.

164
00:12:32.210 --> 00:12:32.420
Yeah.

165
00:12:32.540 --> 00:12:34.760
So that's this come from three sources.

166
00:12:34.910 --> 00:12:41.630
And the actual down sampling is just from instead of If I roughly guessed is this is more like 20 by

167
00:12:41.630 --> 00:12:49.880
20 matrix this go down to maybe a half 10 by 10 metrics a shot of counting the Matrix itself down something

168
00:12:49.880 --> 00:12:59.140
just reduce the number of pixels and then the convolution layer perform another future ring of the so

169
00:12:59.160 --> 00:13:01.980
called down sample layer.

170
00:13:02.430 --> 00:13:09.430
So that's another visualization technique to highlight to you how CNN actually works.

171
00:13:09.480 --> 00:13:10.560
You have the input layer

172
00:13:13.500 --> 00:13:19.830
which we talked about the employer then you have to convolution layer which applied different filter

173
00:13:19.830 --> 00:13:29.430
to it to extract key features makes pulling is to reduce the so-called features reduce down sampling

174
00:13:29.430 --> 00:13:37.530
followed by you have another two convolution layer and in and then for and four there as you go right

175
00:13:37.560 --> 00:13:47.040
there are other links here for you to visualize just now was the Adam Halley's website also provided

176
00:13:47.040 --> 00:13:51.930
to either link for you to actually play around with it below for the intuition for now that's really

177
00:13:51.930 --> 00:13:57.090
what I wanted to cover hopefully from this lesson you actually get some appreciation and understanding

178
00:13:57.420 --> 00:14:03.450
of how each of these convolution layer works and then when we come back we're going to go into the more

179
00:14:03.450 --> 00:14:09.500
technical part I understand all the different available types of layers and how they all work together.
