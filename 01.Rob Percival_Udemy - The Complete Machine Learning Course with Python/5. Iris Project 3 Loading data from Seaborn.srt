1
00:00:00,540 --> 00:00:01,080
Welcome back.

2
00:00:01,080 --> 00:00:06,870
Previously what we've done is import couple libraries for the purpose of data analysis.

3
00:00:06,870 --> 00:00:09,720
The number pi depends is the seaborne as far as the map.

4
00:00:09,730 --> 00:00:15,630
Look we have them fully utilized and yet work we have done though is that we didn't make use of panders

5
00:00:15,630 --> 00:00:19,200
to read the ARIAs dataset into memory.

6
00:00:19,200 --> 00:00:26,910
So right now having done all of that renaming the columns hey we're going to compare the same dataset

7
00:00:27,360 --> 00:00:31,650
which is provided for within C bond itself.

8
00:00:31,650 --> 00:00:40,870
Now bearing in mind that I mentioned before the name Pi which is let's come back here a little bit the

9
00:00:40,870 --> 00:00:44,230
version that we use num pi is version 1.

10
00:00:44,250 --> 00:00:49,910
So it's no longer in beta both pandas as far as C bond are still in beta.

11
00:00:49,970 --> 00:00:52,330
OK so zero point two five and zero point nine.

12
00:00:52,330 --> 00:00:59,660
So they can the actual API core they're using like reads yes we can change.

13
00:00:59,740 --> 00:01:00,320
OK.

14
00:01:00,340 --> 00:01:04,510
Which is why I just know the minus one threw out an error and the last lesson.

15
00:01:04,570 --> 00:01:06,190
But those are things to keep in mind.

16
00:01:06,880 --> 00:01:14,680
But again usually the error message provide sufficient information for you to actually make correction

17
00:01:14,710 --> 00:01:17,500
or deal with the problem or to them to be.

18
00:01:17,500 --> 00:01:24,580
I did show you how to actually go to Google just search the error message and then you see some kind.

19
00:01:24,580 --> 00:01:30,650
So has already asked a question in the stack overflow to how to do with it right.

20
00:01:30,650 --> 00:01:36,290
This is to show you and the C bond which we use as an S to denote that that you can actually load the

21
00:01:36,680 --> 00:01:37,190
data set.

22
00:01:37,190 --> 00:01:43,010
There are some toy data sets that you are deep in preloaded and c bone for you to make use of.

23
00:01:43,040 --> 00:01:48,860
So let's run that so load data said we are looking for the iris and storing into the variable core Iris

24
00:01:49,400 --> 00:01:56,000
and let's have a look at the first five records with data and show enough as you can see here the the

25
00:01:56,270 --> 00:02:02,170
data already is straight from seaborne look similar but also different at the same time.

26
00:02:02,180 --> 00:02:09,770
You notice that the column name is a bit different is the that they use the underscore to connect the

27
00:02:09,770 --> 00:02:12,220
two terms separately.

28
00:02:12,240 --> 00:02:18,050
Length instead of what we use is actually just space and the other one is that when it comes to the

29
00:02:18,050 --> 00:02:26,290
class we call it class that species and they've stripped off the iris dash and leave it.

30
00:02:26,920 --> 00:02:33,810
I think then the other two but inspecting the raw data it looks roughly similar.

31
00:02:33,990 --> 00:02:35,740
I don't think they're exactly the same.

32
00:02:35,740 --> 00:02:41,640
There will be some variation but that's ok at least from the surface of it.

33
00:02:41,850 --> 00:02:48,050
You can tell that they are the same data more or less to a large extent that's useful for that purpose.

34
00:02:48,150 --> 00:02:54,450
And you can see here that once somebody has 60 kinda loaded the data set it makes it a lot easier for

35
00:02:54,450 --> 00:02:55,560
you to utilize it.

36
00:02:55,620 --> 00:03:05,540
So let's make use of data frame that describe which is a method is provided for within the pandas itself.

37
00:03:05,910 --> 00:03:11,970
So if you look at this described to you that the number count or conversely tell us how many rolls of

38
00:03:11,970 --> 00:03:19,140
data that you have is 150 or so and gives you some basic information several length for point eight

39
00:03:19,560 --> 00:03:24,990
with history on all five pedal lengths three point seven five panel with this one line nine so that

40
00:03:25,290 --> 00:03:26,780
these are descriptive stats.

41
00:03:26,790 --> 00:03:27,200
Okay.

42
00:03:27,250 --> 00:03:29,470
This is probably why it's called this describe.

43
00:03:29,970 --> 00:03:31,340
You have to mean you have.

44
00:03:31,340 --> 00:03:38,370
STV means towards the end deviation of the minimum 25 percentile fiftieth percentile seventy fifth percentile

45
00:03:38,400 --> 00:03:39,230
and maximum.

46
00:03:40,350 --> 00:03:45,750
If you're not familiar with what I just said there like means standard deviation minimum and maximum

47
00:03:45,740 --> 00:03:51,170
and the percentile you probably want to refreshed at slightly beyond the scope.

48
00:03:51,560 --> 00:03:57,590
I assume that prerequisites of the foundation that you already have those basic foundation of knowledge.

49
00:03:57,630 --> 00:04:00,150
Otherwise this costs we're just going to be run too long.

50
00:04:00,450 --> 00:04:04,040
But don't be too concerned with that just google it.

51
00:04:04,110 --> 00:04:09,540
Most information already online somewhere that you can actually quickly refer to it just to refresh

52
00:04:09,540 --> 00:04:12,590
yourself but is useful to know that.

53
00:04:13,040 --> 00:04:13,330
OK.

54
00:04:13,380 --> 00:04:18,140
So this is the dev from what we had before which is this DNA here.

55
00:04:18,150 --> 00:04:18,400
All right.

56
00:04:18,420 --> 00:04:25,810
So if we look at the iris which is from the dataset is from si bon let's have a look at the describe.

57
00:04:25,830 --> 00:04:26,940
And just to compare.

58
00:04:26,940 --> 00:04:28,530
Are they vastly different.

59
00:04:28,530 --> 00:04:35,580
So looking at it broadly they look almost the same.

60
00:04:35,740 --> 00:04:41,050
Almost I say almost because yes they have hundred and fifty rows of data.

61
00:04:41,080 --> 00:04:48,150
But I do notice that the sample with mean is a bit different OK.

62
00:04:48,170 --> 00:04:49,400
And this.

63
00:04:49,400 --> 00:04:49,990
Yep the.

64
00:04:50,090 --> 00:04:52,880
Likewise the pedal length is a bit different.

65
00:04:52,880 --> 00:04:54,650
The pedal with is a bit different.

66
00:04:54,720 --> 00:04:59,400
And some of these are probably because of the treatment of the data.

67
00:04:59,420 --> 00:05:05,390
Then once you actually go down the track of learning machine learning and data science you will very

68
00:05:05,390 --> 00:05:12,710
very quickly come to an appreciation that the data are usually very very dirty yes dirty.

69
00:05:12,860 --> 00:05:13,250
Okay.

70
00:05:13,250 --> 00:05:19,400
There are a lot of manipulation cleaning sorting managing that you have to do to actually get it to

71
00:05:19,400 --> 00:05:24,910
a steady state whereby you can see properly analyze it.

72
00:05:24,940 --> 00:05:33,410
No I just wanted to highlight to you that despite the fact that they are two same data set there are

73
00:05:33,440 --> 00:05:41,920
some variation OK there the DNA of which the data frame which we store imported from hundreds of cells

74
00:05:42,380 --> 00:05:48,770
using pendants to imported the raw data set is directly from the UCI in machine learning repository

75
00:05:48,950 --> 00:05:56,390
and Iris which is of course from seaborne and likewise spawning state extract this Dalek directly from

76
00:05:56,390 --> 00:06:00,740
UCI as well because they're all from the same source file which is Robert.

77
00:06:01,580 --> 00:06:02,720
What's his name again.

78
00:06:02,930 --> 00:06:08,930
Robert Fisher is all from the same source but somehow along the way something change.

79
00:06:09,120 --> 00:06:14,340
So that's really to actually give you a rough idea and just the appreciation that these things can and

80
00:06:14,340 --> 00:06:15,860
do happen.

81
00:06:15,900 --> 00:06:22,680
So moving on from there I just want to you illustrate to you that you can actually use this method call

82
00:06:22,800 --> 00:06:28,950
in full and I'm going to print it to the screen that gives you some really quick summary information.

83
00:06:28,980 --> 00:06:39,420
How many rows of data the type of data you have the length with in the form of float 64 and species

84
00:06:39,420 --> 00:06:41,490
is in the form of an object.

85
00:06:41,510 --> 00:06:43,800
OK so keep that in mind.

86
00:06:43,830 --> 00:06:55,420
You have four objects four floats right or float 64 and one object and and I'm using slightly more bonds.

87
00:06:56,080 --> 00:07:07,030
Panda features which is grouping them I'm saying the data frame call Iris grouped them by the column

88
00:07:07,050 --> 00:07:18,090
core species and using a chain method size to tell me the number of observations for those respective

89
00:07:18,090 --> 00:07:20,530
species that it's in the data.

90
00:07:20,550 --> 00:07:27,620
So so looking at this we have three different classes or three different species that those of us in

91
00:07:27,640 --> 00:07:33,390
color Virginia occur each of them have a size of 50 count of 50.

92
00:07:33,620 --> 00:07:37,960
So that's the one part to keep in mind then you can see that there are balance.

93
00:07:38,020 --> 00:07:38,270
OK.

94
00:07:38,300 --> 00:07:41,750
Fifty each which is useful for the purpose of our exercise.

95
00:07:42,300 --> 00:07:42,590
OK.

96
00:07:42,620 --> 00:07:47,760
So for that I hope that you've found that useful just a clue a quick summary.

97
00:07:47,760 --> 00:07:55,070
What have we done so far with the previous lessons we extract the data directly from the UCI machine

98
00:07:55,070 --> 00:08:04,750
learning already provided to you in the form of CSP in the data directory and you read it using independence

99
00:08:04,810 --> 00:08:07,390
reads yes we method.

100
00:08:07,390 --> 00:08:07,790
OK.

101
00:08:07,850 --> 00:08:11,420
That one there and this lesson we cover.

102
00:08:11,420 --> 00:08:16,880
How do you load the same toy data set directly from bond itself.

103
00:08:17,120 --> 00:08:24,670
And we make use of some basic descriptive statistics methodology or methods as provided for in pandas

104
00:08:25,240 --> 00:08:32,300
in the follow describe which allows you to see information very quickly in the math in the ways of Count

105
00:08:32,900 --> 00:08:37,700
the Ways and Means standard deviation and the percentiles plus the minimal maximum as well.
