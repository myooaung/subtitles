1
00:00:00,360 --> 00:00:01,290
Welcome back everyone.

2
00:00:01,290 --> 00:00:06,250
And this session we're going to move into transfer learning right.

3
00:00:06,450 --> 00:00:13,410
One of the things that we've done so far is that we've trained a model a simple one at that and we've

4
00:00:13,410 --> 00:00:17,640
turned trained to identify cats and dogs.

5
00:00:17,640 --> 00:00:19,430
That's all very well.

6
00:00:19,440 --> 00:00:25,560
Of course you can start using it to apply to other pictures of dogs and cats.

7
00:00:25,620 --> 00:00:34,610
The natural question then is this if others have run similar training and if they have done training

8
00:00:34,640 --> 00:00:44,480
on massive massively large image data set and obtain state of the art accuracy can we use their model

9
00:00:45,170 --> 00:00:52,220
for predicting pictures or classifying cats and dogs and all the other animals as well.

10
00:00:52,220 --> 00:00:59,060
The answer turns out to be a resounding yes and that's core transfer learning.

11
00:00:59,060 --> 00:01:06,230
That's what we actually going to go and dig into this is really exciting for you because now you get

12
00:01:06,230 --> 00:01:14,480
the benefit of utilizing trainings that's been done by Google's Facebook and utilized the model that

13
00:01:14,480 --> 00:01:15,260
they share.

14
00:01:15,400 --> 00:01:22,000
And out in the open open sourced for you to actually apply to your day to day use or your business use.

15
00:01:22,130 --> 00:01:23,950
And it turns out to be highly effective.

16
00:01:23,960 --> 00:01:27,930
So this way we actually going to going to have look at it now.

17
00:01:27,980 --> 00:01:34,190
So that's the basic ideas of transfer learning and the file that we're going to look at is called cats

18
00:01:34,190 --> 00:01:35,300
and dogs.

19
00:01:35,300 --> 00:01:36,640
But underscore transfer.

20
00:01:36,660 --> 00:01:37,670
And it's called learning.

21
00:01:37,670 --> 00:01:39,550
So let's dig into that right now.

22
00:01:39,560 --> 00:01:42,380
So this is the file we're still working with cats and dogs.

23
00:01:42,540 --> 00:01:50,600
And let me just pull up our previous training so that you can actually have a reference recall that

24
00:01:50,600 --> 00:01:54,910
we last did the data augmentation.

25
00:01:55,400 --> 00:02:00,260
Let's put this up.

26
00:02:00,480 --> 00:02:04,770
Let me pull up the performance so that you can actually have a comparison.

27
00:02:04,980 --> 00:02:12,750
We after 100 epochs we reach about 80 percent in terms of follow more like eighty four percent in terms

28
00:02:12,750 --> 00:02:14,900
of validation 83 82.

29
00:02:14,990 --> 00:02:21,450
OK just eighty three as high as we weigh whether we observe in terms of validation accuracy.

30
00:02:21,570 --> 00:02:28,310
So let's see if we can actually do likewise if we actually apply this.

31
00:02:28,470 --> 00:02:37,450
Now remember we did talk about veggie 16 and we're going to make use of that once again the usual and

32
00:02:37,450 --> 00:02:42,510
we just walk through the coat with you important umpire in both pandas against TV to implant.

33
00:02:42,870 --> 00:02:44,550
Oh these are exactly the same.

34
00:02:44,550 --> 00:02:50,400
The rose is 128 and importing always and as has utility for data copy.

35
00:02:50,400 --> 00:02:52,250
So these codes are exactly the same.

36
00:02:52,260 --> 00:02:53,340
No change.

37
00:02:53,340 --> 00:02:57,740
We're still working with four thousand data sets training data sets.

38
00:02:57,740 --> 00:03:05,010
Two thousand cards two thousand dogs and 500 validation for both cats and dogs so that means a thousand

39
00:03:05,700 --> 00:03:07,760
pictures of cats and dogs.

40
00:03:07,770 --> 00:03:08,910
Right.

41
00:03:09,390 --> 00:03:10,140
From Karas.

42
00:03:10,140 --> 00:03:16,520
The good thing about Chris is that there are some built in models rigid you 16 is one of them.

43
00:03:17,100 --> 00:03:24,790
And we're going to instantiate a model call using veggie juice extend that's already available in the.

44
00:03:24,990 --> 00:03:32,520
So we're going to call that model is it could do veggie 16 and have a look at the.

45
00:03:32,550 --> 00:03:35,250
So call veggies

46
00:03:38,270 --> 00:03:39,190
architecture.

47
00:03:39,230 --> 00:03:39,470
All right.

48
00:03:39,470 --> 00:03:42,400
So this is a summary of the architecture.

49
00:03:42,410 --> 00:03:42,650
All right.

50
00:03:42,650 --> 00:03:46,460
We have the input there's the original sizes two to four.

51
00:03:46,460 --> 00:03:47,730
That's OK.

52
00:03:48,140 --> 00:03:55,120
And then we have to convolution layer and it makes pulling lamb another two more convolution layer another

53
00:03:55,130 --> 00:04:03,340
makes pulling Layer 3 convolution Layer 1 next pool trick convolution one makes for treacle solution

54
00:04:03,880 --> 00:04:08,280
one next for finally flatten to density connected or fully connected.

55
00:04:08,300 --> 00:04:19,550
Dense layer and prediction there's 1000 classes because divided you was originally trained on 1000 data

56
00:04:19,580 --> 00:04:22,870
sets or classes of pictures.

57
00:04:22,880 --> 00:04:23,720
Right.

58
00:04:24,380 --> 00:04:24,650
OK.

59
00:04:24,680 --> 00:04:33,230
So we are removing the so-called top the top are the so-called two fully connected layer including the

60
00:04:33,230 --> 00:04:34,580
prediction.

61
00:04:34,580 --> 00:04:41,900
So when we actually now look at it not just that it stops at the block five pulling layer and there's

62
00:04:41,960 --> 00:04:46,450
no fully connected layer of flatten fully connected layer at all.

63
00:04:46,820 --> 00:04:47,110
OK.

64
00:04:47,150 --> 00:04:54,890
So right again this part is we are importing the from Kerry's should this line of code is unnecessary

65
00:04:55,130 --> 00:04:55,780
from Kerry's.

66
00:04:55,790 --> 00:04:58,280
We import David G G 16.

67
00:04:58,460 --> 00:05:05,810
We are using from the layers import completion to D makes pulling to the global average pulling flatten

68
00:05:05,840 --> 00:05:10,290
dens and drop out and also carers and top model.

69
00:05:10,310 --> 00:05:10,610
Right.

70
00:05:10,610 --> 00:05:11,470
If you look at this.

71
00:05:12,230 --> 00:05:20,900
This is the key part here we are in a way you can call it performing a surgery on our models looking

72
00:05:20,900 --> 00:05:31,040
carefully what you notice is that we are actually removing a few items we have removed the flatten the

73
00:05:31,070 --> 00:05:33,160
fully connected layers.

74
00:05:33,160 --> 00:05:34,030
OK.

75
00:05:34,070 --> 00:05:37,730
And the question now is that if we have removed those.

76
00:05:37,790 --> 00:05:43,130
How does our model actually perform predictions of the cats and dogs.

77
00:05:43,160 --> 00:05:50,210
This is where we actually I'm going to show you but the base model is going to base on a B Jiji 16 and

78
00:05:50,210 --> 00:05:58,220
the weights of the of the neural network is based on based on what was the originally changing which

79
00:05:58,220 --> 00:05:59,880
is the image in it.

80
00:06:00,070 --> 00:06:00,390
OK.

81
00:06:00,410 --> 00:06:09,020
The image net is the massive database that's provided by Stanford to train all the images and we are

82
00:06:09,020 --> 00:06:15,800
removing the top meaning those two connected layer has been removed and the input shape is this at 1

83
00:06:15,800 --> 00:06:20,040
2 8 by 1 2 8.

84
00:06:20,170 --> 00:06:29,000
So that's the model and we store the output to the variable x and then we're performing what's call

85
00:06:29,410 --> 00:06:38,420
a global average pulling in and basically after the base model we apply a global average pulling instead

86
00:06:38,420 --> 00:06:47,390
of Max pulling and followed by a densely connected layer and followed by the prediction layer which

87
00:06:47,390 --> 00:06:48,150
is sigmoid.

88
00:06:48,150 --> 00:06:54,250
In this case rather than soft Max sigmoid being two class problems.

89
00:06:54,290 --> 00:06:58,510
Are the binary one that we've looked at before and that's it.

90
00:06:58,600 --> 00:07:06,130
And we instantiate our model by input being the base model which is the Virgin G 16 and the output as

91
00:07:06,130 --> 00:07:11,410
the prediction that we've defined based on these four lines here.

92
00:07:11,440 --> 00:07:11,760
All right.

93
00:07:11,790 --> 00:07:18,160
The images connect this force so that you can actually clearly see they are connected this way and we

94
00:07:18,460 --> 00:07:26,320
have to loop through each of those layers that we looked at before all of these plot 1 2 5 here and

95
00:07:26,560 --> 00:07:31,150
set it to no training OK.

96
00:07:31,200 --> 00:07:37,960
So we're looping through them and have all the weights that's already been pre-teen pre train frozen.

97
00:07:38,410 --> 00:07:45,340
OK so that's what this laser dot chain equals two false means do not train them because we want to retain

98
00:07:45,970 --> 00:07:52,180
or borrow the learnings from that was done from the original image OK.

99
00:07:52,470 --> 00:07:57,780
So the next thing is that we do need to compile our model.

100
00:07:57,940 --> 00:08:05,200
This is the same as what we've done so far followed by these we're not doing any data augmentation here.

101
00:08:05,420 --> 00:08:10,880
So everything is is exactly as it was before and now is the training.

102
00:08:11,210 --> 00:08:14,560
OK we're training instead of 30 now 50 epoch.

103
00:08:14,660 --> 00:08:19,880
Just to compare and let's have a look at the performance down here.

104
00:08:19,880 --> 00:08:20,850
All right.

105
00:08:20,850 --> 00:08:21,100
Right.

106
00:08:21,170 --> 00:08:32,930
So looking at this I'll let you take a moment to breathe it in look at the validation accuracy the training

107
00:08:32,930 --> 00:08:42,760
accuracy is almost a hundred percent the validation accuracy It's around ninety five percent Yes ninety

108
00:08:42,770 --> 00:08:53,900
five percent and that's really why this is so powerful and it's so crucial to actually take note of

109
00:08:53,900 --> 00:09:01,970
the so-called validation accuracy in terms of the predictability or predictive power of prediction of

110
00:09:01,970 --> 00:09:06,090
this transfer learning the training losses around point eight.

111
00:09:06,140 --> 00:09:12,800
It's a little higher than the model but that's OK because we actually have a very large model with lots

112
00:09:12,800 --> 00:09:17,300
of flexibility so that the so-called Lost bounce would be a little bit on the higher side.

113
00:09:17,870 --> 00:09:25,670
But more importantly is this accuracy score here both the training accuracy is really high and the validation

114
00:09:25,670 --> 00:09:27,820
accuracy is really high as well.

115
00:09:27,890 --> 00:09:35,800
And the conclusion that you can only draw all of these is this it means that prior training prior learning

116
00:09:35,850 --> 00:09:46,700
that is done by this architecture which is rigid 16 him 16 stands for 16 layers is useful in the task

117
00:09:46,700 --> 00:09:54,680
that we're trying to solve here which is trying to separate out cat versus dogs and that's therein lies

118
00:09:54,680 --> 00:10:00,410
the one key lesson that I want to share with you is is this is a really powerful technique called transfer

119
00:10:00,410 --> 00:10:07,520
learning and hopefully that impresses upon you to actually use this technique even more.

120
00:10:07,520 --> 00:10:16,190
A big part of it is because most of us don't have the computational power or ability like Google Facebook

121
00:10:16,190 --> 00:10:22,080
and the likes the tech companies have done all this training they've outsourced it.

122
00:10:22,190 --> 00:10:27,200
If you are a small medium enterprise you can actually leverage on this and run with it and you will

123
00:10:27,200 --> 00:10:29,650
solve most of the problems that you have.

124
00:10:29,720 --> 00:10:31,300
Of course there are some constraints.

125
00:10:31,330 --> 00:10:38,600
If these are all the trains or animals and you try to use it to identify cars or machine parts it might

126
00:10:38,600 --> 00:10:47,300
not perform so well it ought to be that they are in similar few and highly encourage you to look into

127
00:10:47,300 --> 00:10:52,670
this a little bit more just to actually learn how you can you can protect potentially users in your

128
00:10:52,670 --> 00:10:57,100
day to day problem and some of the business problem that you may face with that I'm going to stop.

129
00:10:57,110 --> 00:10:58,280
Thank you once again for watching.
